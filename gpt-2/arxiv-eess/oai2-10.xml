<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2020-03-01T07:02:41Z</responseDate>
<request verb="ListRecords" resumptionToken="4250076|9001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07062</identifier>
 <datestamp>2019-11-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07062</id><created>2019-07-23</created><updated>2019-11-22</updated><authors><author><keyname>Rezk</keyname><forenames>Nesma M.</forenames></author><author><keyname>Purnaprajna</keyname><forenames>Madhura</forenames></author><author><keyname>Nordstr&#xf6;m</keyname><forenames>Tomas</forenames></author><author><keyname>Ul-Abdin</keyname><forenames>Zain</forenames></author></authors><title>Recurrent Neural Networks: An Embedded Computing Perspective</title><categories>cs.NE eess.SP</categories><comments>Submitted to IEEE Access</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent Neural Networks (RNNs) are a class of machine learning algorithms
used for applications with time-series and sequential data. Recently, a strong
interest has emerged to execute RNNs on embedded devices. However, RNN
requirements of high computational capability and large memory space is
difficult to be met. In this paper, we review the existing implementations of
RNN models on embedded platforms and discuss the methods adopted to overcome
the limitations of embedded systems.
  We define the objectives of mapping RNN algorithms on embedded platforms and
the challenges facing their realization. Then, we explain the components of
RNNs models from an implementation perspective. Furthermore, we discuss the
optimizations applied on RNNs to run efficiently on embedded platforms.
Additionally, we compare the defined objectives with the implementations and
highlight some open research questions and aspects currently not addressed for
embedded RNNs.
  Overall, applying algorithmic optimizations on RNN models and decreasing the
memory access overhead is vital to reach high efficiency. To further increase
the achievable efficiency, the article points up the more promising
optimizations to be applied in future research. Additionally, this article
observes that high performance has been targeted by many implementations while
flexibility was still less attempted. Thus, the article provides some
guidelines for RNNs hardware designers to support flexibility in a better
manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07067</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07067</id><created>2019-07-22</created><authors><author><keyname>Huang</keyname><forenames>Chaoran</forenames></author><author><keyname>de Lima</keyname><forenames>Thomas Ferreira</forenames></author><author><keyname>Jha</keyname><forenames>Aashu</forenames></author><author><keyname>Abbaslou</keyname><forenames>Siamak</forenames></author><author><keyname>Tait</keyname><forenames>Alexander N.</forenames></author><author><keyname>Shastri</keyname><forenames>Bhavin J.</forenames></author><author><keyname>Prucnal</keyname><forenames>Paul R.</forenames></author></authors><title>Programmable Silicon Photonic Optical Thresholder</title><categories>physics.app-ph eess.SP physics.optics</categories><comments>4 pages, 5 figures, letter</comments><doi>10.1109/LPT.2019.2948903</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We experimentally demonstrate an all-optical programmable thresholder on a
silicon photonic circuit. By exploiting the nonlinearities in a
resonator-enhanced Mach-Zehnder interferometer (MZI), the proposed optical
thresholder can discriminate two optical signals with very similar amplitudes.
We experimentally achieve a signal contrast enhancement of 40, which leads to a
bit error rate (BER) improvement by 5 orders of magnitude and a receiver
sensitivity improvement of 11 dB. We present the thresholding function of our
device and validate the function with experimental data. Furthermore, we
investigate potential device speed improvement by reducing the carrier
lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07105</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07105</id><created>2019-08-19</created><authors><author><keyname>Wu</keyname><forenames>Manxi</forenames></author><author><keyname>Amin</keyname><forenames>Saurabh</forenames></author></authors><title>Information Design for Regulating Traffic Flows under Uncertain Network
  State</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traffic navigation services have gained widespread adoption in recent years.
The route recommendations generated by these services often leads to severe
congestion on urban streets, raising concerns from neighboring residents and
city authorities. This paper is motivated by the question: How can a
transportation authority design an information structure to induce a preferred
equilibrium traffic flow pattern in uncertain network state conditions? We
approach this question from a Bayesian persuasion viewpoint. We consider a
basic routing game with two parallel routes and an uncertain state that affects
the travel cost on one of the routes. The authority sends a noisy signal of the
state to a given fraction of travelers. The information structure (i.e.,
distribution of signals in each state) chosen by the authority creates a
heterogeneous information environment for the routing game. The solution
concept governing the travelers' route choices is Bayesian Wardrop Equilibrium.
We design an information structure to minimize the average traffic spillover --
the amount of equilibrium route flow exceeding a certain threshold -- on one of
the routes. We provide an analytical characterization of the optimal
information structure for any fraction of travelers receiving the signal. We
find that it can achieve the minimum spillover so long as the fraction of
travelers receiving the signal is larger than a threshold (smaller than 1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07107</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07107</id><created>2019-08-19</created><updated>2019-09-30</updated><authors><author><keyname>Borthakur</keyname><forenames>Debanjan</forenames></author><author><keyname>Grace</keyname><forenames>Victoria</forenames></author><author><keyname>Batchelor</keyname><forenames>Paul</forenames></author><author><keyname>Dubey</keyname><forenames>Harishchandra</forenames></author><author><keyname>Mankodiya</keyname><forenames>Kunal</forenames></author></authors><title>Fuzzy C-Means Clustering and Sonification of HRV Features</title><categories>cs.HC cs.LG cs.SD eess.AS stat.ML</categories><comments>5 pages, 5 figures</comments><journal-ref>2019 the IEEE/ACM 4th International Conference on Connected
  Health: Applications, Systems and Engineering Technologies: EdgeDL
  WorkshopAt: Washington, D.C, sep- 25-27</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear and non-linear measures of heart rate variability (HRV) are widely
investigated as non-invasive indicators of health. Stress has a profound impact
on heart rate, and different meditation techniques have been found to modulate
heartbeat rhythm. This paper aims to explore the process of identifying
appropriate metrices from HRV analysis for sonification. Sonification is a type
of auditory display involving the process of mapping data to acoustic
parameters. This work explores the use of auditory display in aiding the
analysis of HRV leveraged by unsupervised machine learning techniques.
Unsupervised clustering helps select the appropriate features to improve the
sonification interpretability. Vocal synthesis sonification techniques are
employed to increase comprehension and learnability of the processed data
displayed through sound. These analyses are early steps in building a real-time
sound-based biofeedback training system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07108</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07108</id><created>2019-08-19</created><authors><author><keyname>Choi</keyname><forenames>Jinho</forenames></author></authors><title>Matched-Filter based Backscatter Communication for IoT Devices over
  Ambient OFDM Carrier</title><categories>cs.IT eess.SP math.IT</categories><comments>11 pages, IEEE JIoT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study backscatter communication (BC) for power-limited
devices that are connected to a network for the Internet of Things (IoT), where
joint estimation and detection is carried out at a receiver to detect signals
from a backscatter device (BD) with ambient orthogonal frequency division
multiplexing (OFDM) carrier. In conventional BC, in order to avoid the
difficulty of the carrier estimation, the energy detector is usually considered
at a receiver at the cost of poor performance. To improve the performance, in
this paper, we consider a novel approach that allows the carrier estimation at
the receiver via joint estimation and detection. In particular, in the proposed
approach, the matched-filtering at the BD (for the transmitter filter) is
employed to impose a certain property that allows efficient and reliable
carrier estimation via joint estimation and detection. Through the performance
analysis and simulation results, we show that the matched-filtering at the BD
in the proposed approach can improve the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07109</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07109</id><created>2019-08-19</created><authors><author><keyname>Muehlebach</keyname><forenames>Michael</forenames></author></authors><title>The Silver Ratio and its Relation to Controllability</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note investigates the controllability of two unstable second-order
systems that are coupled through a common input. These dynamics occur for
different types of inverted-pendulum systems. Controllability is quantified by
the volume of the state-space that can be reached with unit energy, provided
that the system starts and ends at the origin. It is shown that controllability
is maximized when the ratio between the time constants amounts to the silver
ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07115</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07115</id><created>2019-08-19</created><authors><author><keyname>Khoshkholgh</keyname><forenames>Mohammad G.</forenames></author><author><keyname>Leung</keyname><forenames>Victor C. M.</forenames></author></authors><title>Energy-Efficient Cooperative Caching in UAV Networks</title><categories>cs.IT eess.SP math.IT</categories><comments>15 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  For an unmanned aerial vehicle (UAV) enabled network we investigate the
energy-efficiency (EE) of joint caching and cooperative communication
(Fog-RAN). Since UAVs are battery- and cache-limited, placing the popular
contents in the caches and managing the energy expenditure of UAVs become
crucial. We formulate the energy consumption of UAVs as an aggregate of
communication/caching, hovering, and vertical displacement energies, and then
devise an optimization problem for optimally assigning contents to caches and
choosing the height of UAVs. Adopting tools from stochastic geometry, we also
derive the EE in a numerically tractable form as a function of density, the
radius of the cooperation zone, cache size, main communication/physical
characteristics of UAVs, and influential environmental parameters. We develop
two content placement strategies with low computational complexity. The
conducted numerical results demonstrate that by adopting these algorithms one
is able to improve EE by up to 800% compared to common content placement
schemes, e.g., the least-frequently used (LRU), the most-popular, and Hit-rate.
Furthermore, while under LRU and Hit-rate schemes there is no benefit in
vertically displacing UAVs, under our algorithms one is able to increase EE by
at most 600%. Importantly, via our algorithms one can increase the size of
cooperation zone in order to steadily increase EE, which is not the cases of
LRU, the most-popular, and Hit-rate schemes. We finally observe that there is
optimal values for density and cache-size of UAVs, granting maximum EE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07126</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07126</id><created>2019-08-19</created><authors><author><keyname>Trindade</keyname><forenames>Isabela</forenames></author><author><keyname>Boas</keyname><forenames>Brenda Vilas</forenames></author><author><keyname>Klautau</keyname><forenames>Aldebaro</forenames></author></authors><title>Evaluation of Simplified Methodology for Obtaining mmWave MIMO Channels
  from Ray-Tracing Simulations</title><categories>eess.SP</categories><comments>2 pages, XXXVI Simposio Brasileiro De Telecomunicacoes E
  Processamento De Sinais - SBrT2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of higher frequencies and MIMO is important in many 5G use cases.
However, the available channel models for millimeter waves (mmWaves) currently
demand investigation and the number of measurements is still limited. Using
simulators is a current practice in mmWave MIMO research and ray tracing is
considered one of the most accurate techniques. Due to the relatively long time
of ray tracing simulations, it is common practice to adopt a simplified
simulation methodology in which omnidirectional antennas are simulated and,
later, the results are used together with a geometrical model to consider that
antenna arrays were used. This allows flexibility and decreases the overall
time spent with simulations. This paper investigates the corresponding
assumptions and how accurate are the results of the simplified methodology when
compared to effectively using antenna arrays in the ray tracing simulation. The
preliminary results indicate that the distance between transmitter and receiver
needs to be sufficiently large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07170</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07170</id><created>2019-08-20</created><authors><author><keyname>Frid-Adar</keyname><forenames>Maayan</forenames></author><author><keyname>Amer</keyname><forenames>Rula</forenames></author><author><keyname>Greenspan</keyname><forenames>Hayit</forenames></author></authors><title>Endotracheal Tube Detection and Segmentation in Chest Radiographs using
  Synthetic Data</title><categories>eess.IV cs.CV</categories><comments>Accepted to MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chest radiographs are frequently used to verify the correct intubation of
patients in the emergency room. Fast and accurate identification and
localization of the endotracheal (ET) tube is critical for the patient. In this
study we propose a novel automated deep learning scheme for accurate detection
and segmentation of the ET tubes. Development of automatic systems using deep
learning networks for classification and segmentation require large annotated
data which is not always available. Here we present an approach for
synthesizing ET tubes in real X-ray images. We suggest a method for training
the network, first with synthetic data and then with real X-ray images in a
fine-tuning phase, which allows the network to train on thousands of cases
without annotating any data. The proposed method was tested on 477 real chest
radiographs from a public dataset and reached AUC of 0.99 in classifying the
presence vs. absence of the ET tube, along with outputting high quality ET tube
segmentation maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07226</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07226</id><created>2019-08-20</created><authors><author><keyname>&#xd6;ktem</keyname><forenames>Alp</forenames></author><author><keyname>Farr&#xfa;s</keyname><forenames>Mireia</forenames></author><author><keyname>Bonafonte</keyname><forenames>Antonio</forenames></author></authors><title>Prosodic Phrase Alignment for Machine Dubbing</title><categories>cs.CL cs.MM cs.SD eess.AS</categories><comments>Interspeech 2019 pre-print</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dubbing is a type of audiovisual translation where dialogues are translated
and enacted so that they give the impression that the media is in the target
language. It requires a careful alignment of dubbed recordings with the lip
movements of performers in order to achieve visual coherence. In this paper, we
deal with the specific problem of prosodic phrase synchronization within the
framework of machine dubbing. Our methodology exploits the attention mechanism
output in neural machine translation to find plausible phrasing for the
translated dialogue lines and then uses them to condition their synthesis. Our
initial work in this field records comparable speech rate ratio to professional
dubbing translation, and improvement in terms of lip-syncing of long dialogue
lines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07247</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07247</id><created>2019-08-20</created><authors><author><keyname>Saraf</keyname><forenames>Nilay</forenames></author><author><keyname>Bemporad</keyname><forenames>Alberto</forenames></author></authors><title>An efficient non-condensed approach for linear and nonlinear model
  predictive control with bounded variables</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new approach to solving linear and nonlinear model
predictive control (MPC) problems that requires minimal memory footprint and
throughput and is particularly suitable when the model and/or controller
parameters change at runtime. Typically MPC requires two phases: 1) construct
an optimization problem based on the given MPC parameters (prediction model,
tuning weights, prediction horizon, and constraints), which results in a
quadratic or nonlinear programming problem, and then 2) call an optimization
algorithm to solve the resulting problem. In the proposed approach the problem
construction step is systematically eliminated, as in the optimization
algorithm problem matrices are expressed in terms of abstract functions of the
MPC parameters. We present a unifying algorithmic framework based on active-set
methods with bounded variables that can cope with linear, nonlinear, and
adaptive MPC variants based on a broad class of models. The theoretical and
numerical results demonstrate the potential, applicability, and efficiency of
the proposed framework for practical real-time embedded MPC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07307</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07307</id><created>2019-08-20</created><authors><author><keyname>Hu</keyname><forenames>Gang</forenames></author><author><keyname>Liu</keyname><forenames>Lingbo</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author><author><keyname>Song</keyname><forenames>Jie</forenames></author><author><keyname>Kwok</keyname><forenames>K. C. S.</forenames></author></authors><title>Investigation of wind pressures on tall building under interference
  effects using machine learning techniques</title><categories>cs.LG eess.SP stat.ML</categories><comments>15 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference effects of tall buildings have attracted numerous studies due to
the boom of clusters of tall buildings in megacities. To fully understand the
interference effects of buildings, it often requires a substantial amount of
wind tunnel tests. Limited wind tunnel tests that only cover part of
interference scenarios are unable to fully reveal the interference effects.
This study used machine learning techniques to resolve the conflicting
requirement between limited wind tunnel tests that produce unreliable results
and a completed investigation of the interference effects that is costly and
time-consuming. Four machine learning models including decision tree, random
forest, XGBoost, generative adversarial networks (GANs), were trained based on
30% of a dataset to predict both mean and fluctuating pressure coefficients on
the principal building. The GANs model exhibited the best performance in
predicting these pressure coefficients. A number of GANs models were then
trained based on different portions of the dataset ranging from 10% to 90%. It
was found that the GANs model based on 30% of the dataset is capable of
predicting both mean and fluctuating pressure coefficients under unseen
interference conditions accurately. By using this GANs model, 70% of the wind
tunnel test cases can be saved, largely alleviating the cost of this kind of
wind tunnel testing study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07311</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07311</id><created>2019-08-20</created><authors><author><keyname>Bitar</keyname><forenames>Glenn</forenames></author><author><keyname>Lekkas</keyname><forenames>Anastasios M.</forenames></author><author><keyname>Breivik</keyname><forenames>Morten</forenames></author></authors><title>Improvements to Warm-Started Optimized Trajectory Planning for ASVs</title><categories>eess.SY cs.SY</categories><comments>9 pages, 6 figures, 2 tables. Preprint as submitted to a special
  issue on Maritime Robotics and Control Systems of the International Journal
  of Control, Automation and Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present improvements to a recently developed method for trajectory
planning for autonomous surface vehicles (ASVs) in terms of run time. The
original method combines two types of planners: An A* implementation that
quickly finds the global shortest piecewise linear path on a uniformly
discretized map, and an optimal control-based trajectory planner which takes
into account ASV dynamics. Firstly, we propose an improvement to the
discretization of the map by switching to a Voronoi diagram rather than the
uniform discretization, which offers a far more sparse search tree for the A*
implementation. Secondly, modifications to the path refinement are made, as
suggested in a paper by Bhattacharya and Gavrilova. The changes result in a
reduction to the run time of the first part of the method of 85% for an example
scenario while maintaining the same level of optimality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07324</identifier>
 <datestamp>2020-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07324</id><created>2019-08-20</created><updated>2020-01-02</updated><authors><author><keyname>Sudharsan</keyname><forenames>Bharath</forenames></author><author><keyname>Chockalingam</keyname><forenames>Manigandan</forenames></author></authors><title>A Microphone Array and Voice Algorithm based Smart Hearing Aid</title><categories>cs.SD eess.AS</categories><doi>10.5120/ijca2019919295</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Approximately 6.2% of the world's population (466 million people) suffer from
disabling hearing impairment [1]. Hearing impairment impacts negatively on
one's education, financial success [2][3], cognitive development in childhood
[4], including increased risk of dementia in older adulthood [5]. Lack of or
reduced social interaction due to hearing impairment affects creating or
maintaining healthy relationships at home, school and work [5]. Hence, hearing
impairment genuinely affects the overall quality of life and wellbeing.
  The cocktail party effect, which is a healthy hearing individual's ability to
understand one voice in a cacophony of other voices or sounds, is an important
ability lacking in people with hearing impairment. This inability results in
difficulties with simple daily activities such as partaking in group
discussions or conversing in noisy restaurants [6]. This smart hearing aid aims
to provide much-needed assistance with understanding speech in noisy
environments. For example, if a person wants to partake in a group discussion,
he/she needs to place the microphone array based unit on a flat surface in
front of him/her, such as a table. When conversations take place, the
microphone array will capture and process sound from all directions,
intelligently prioritise and provide the lead speaker's voice by suppressing
unwanted noises, including speeches of other people. This device selects and
alternates voices between speakers automatically using voice algorithms.
Additionally, the user has the option of further fine-tuning the acoustic
parameters as needed through a smartphone interface. This paper describes the
development and functions of this new Smart Hearing Aid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07335</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07335</id><created>2019-08-01</created><authors><author><keyname>Piran</keyname><forenames>Md. Jalil</forenames></author><author><keyname>Suh</keyname><forenames>Doug Young</forenames></author></authors><title>Learning-Driven Wireless Communications, towards 6G</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fifth generation (5G) of wireless communication is in its infancy, and
its evolving versions will be launched over the coming years. However,
according to exposing the inherent constraints of 5G and the emerging
applications and services with stringent requirements e.g. latency, energy/bit,
traffic capacity, peak data rate, and reliability, telecom researchers are
turning their attention to conceptualize the next generation of wireless
communications, i.e. 6G. In this paper, we investigate 6G challenges,
requirements, and trends. Furthermore, we discuss how artificial intelligence
(AI) techniques can contribute to 6G. Based on the requirements and solutions,
we identify some new fascinating services and use-cases of 6G, which can not be
supported by 5G appropriately. Moreover, we explain some research directions
that lead to the successful conceptualization and implementation of 6G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07337</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07337</id><created>2019-07-31</created><authors><author><keyname>Sharma</keyname><forenames>Shree Krishna</forenames></author><author><keyname>Woungang</keyname><forenames>Isaac</forenames></author><author><keyname>Anpalagan</keyname><forenames>Alagan</forenames></author><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author></authors><title>Towards Tactile Internet in Beyond 5G Era: Recent Advances, Current
  Issues and Future Directions</title><categories>cs.NI eess.SP</categories><comments>40 pages, 4 figures, 8 tables, submitted to IEEE Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tactile Internet (TI) is envisioned to create a paradigm shift from the
content-oriented communications to steer/control-based communications by
enabling real-time transmission of haptic information (i.e., touch, actuation,
motion, vibration, surface texture) over Internet in addition to the
conventional audiovisual and data traffics. This emerging TI technology is
expected to create numerous opportunities for technology markets in a wide
variety of applications ranging from teleoperation systems and AR/VR to
automotive safety and eHealthcare towards addressing the complex problems of
human society. However, the realization of TI over wireless media in the
upcoming 5G and beyond networks creates various non-conventional communication
challenges and stringent requirements. To this end, this paper aims to provide
a holistic view on wireless TI along with a thorough review of the existing
literature, to identify and analyze the involved technical issues, to highlight
potential solutions and to propose future research directions. First, starting
with the vision of TI and recent advances and a review of related
survey/overview articles, we present a generalized framework for wireless TI in
the Beyond 5G Era including a TI architecture, main technical requirements, key
application areas and potential enabling technologies. Subsequently, we provide
a comprehensive review of the existing TI works by broadly categorizing them
into three main paradigms; namely, haptic communications, wireless AR/VR, and
autonomous, intelligent and cooperative mobility systems. Next, potential
enabling technologies across physical/MAC and network layers are identified and
discussed in detail. Also, security and privacy issues of TI applications are
discussed along with some promising enablers. Finally, we present some open
research challenges and recommend promising future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07344</identifier>
 <datestamp>2020-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07344</id><created>2019-08-20</created><updated>2019-11-09</updated><authors><author><keyname>Chen</keyname><forenames>Chen</forenames></author><author><keyname>Ouyang</keyname><forenames>Cheng</forenames></author><author><keyname>Tarroni</keyname><forenames>Giacomo</forenames></author><author><keyname>Schlemper</keyname><forenames>Jo</forenames></author><author><keyname>Qiu</keyname><forenames>Huaqi</forenames></author><author><keyname>Bai</keyname><forenames>Wenjia</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author></authors><title>Unsupervised Multi-modal Style Transfer for Cardiac MR Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><comments>STACOM 2019 camera-ready. Winner of Multi-sequence Cardiac MR
  Segmentation Challenge (MS-CMRSeg 2019) https://zmiclab.github.io/mscmrseg19/</comments><doi>10.1007/978-3-030-39074-7_22</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we present a fully automatic method to segment cardiac
structures from late-gadolinium enhanced (LGE) images without using labelled
LGE data for training, but instead by transferring the anatomical knowledge and
features learned on annotated balanced steady-state free precession (bSSFP)
images, which are easier to acquire. Our framework mainly consists of two
neural networks: a multi-modal image translation network for style transfer and
a cascaded segmentation network for image segmentation. The multi-modal image
translation network generates realistic and diverse synthetic LGE images
conditioned on a single annotated bSSFP image, forming a synthetic LGE training
set. This set is then utilized to fine-tune the segmentation network
pre-trained on labelled bSSFP images, achieving the goal of unsupervised LGE
image segmentation. In particular, the proposed cascaded segmentation network
is able to produce accurate segmentation by taking both shape prior and image
appearance into account, achieving an average Dice score of 0.92 for the left
ventricle, 0.83 for the myocardium, and 0.88 for the right ventricle on the
test set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07355</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07355</id><created>2019-08-16</created><authors><author><keyname>Orbes-Arteaga</keyname><forenames>Mauricio</forenames></author><author><keyname>Cardoso</keyname><forenames>Jorge</forenames></author><author><keyname>S&#xf8;rensen</keyname><forenames>Lauge</forenames></author><author><keyname>Igel</keyname><forenames>Christian</forenames></author><author><keyname>Ourselin</keyname><forenames>Sebastien</forenames></author><author><keyname>Modat</keyname><forenames>Marc</forenames></author><author><keyname>Nielsen</keyname><forenames>Mads</forenames></author><author><keyname>Pai</keyname><forenames>Akshay</forenames></author></authors><title>Knowledge distillation for semi-supervised domain adaptation</title><categories>cs.LG eess.IV stat.ML</categories><comments>MLCN MICCAI workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the absence of sufficient data variation (e.g., scanner and protocol
variability) in annotated data, deep neural networks (DNNs) tend to overfit
during training. As a result, their performance is significantly lower on data
from unseen sources compared to the performance on data from the same source as
the training data. Semi-supervised domain adaptation methods can alleviate this
problem by tuning networks to new target domains without the need for annotated
data from these domains. Adversarial domain adaptation (ADA) methods are a
popular choice that aim to train networks in such a way that the features
generated are domain agnostic. However, these methods require careful
dataset-specific selection of hyperparameters such as the complexity of the
discriminator in order to achieve a reasonable performance. We propose to use
knowledge distillation (KD) -- an efficient way of transferring knowledge
between different DNNs -- for semi-supervised domain adaption of DNNs. It does
not require dataset-specific hyperparameter tuning, making it generally
applicable. The proposed method is compared to ADA for segmentation of white
matter hyperintensities (WMH) in magnetic resonance imaging (MRI) scans
generated by scanners that are not a part of the training set. Compared with
both the baseline DNN (trained on source domain only and without any adaption
to target domain) and with using ADA for semi-supervised domain adaptation, the
proposed method achieves significantly higher WMH dice scores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07362</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07362</id><created>2019-08-20</created><updated>2019-11-11</updated><authors><author><keyname>Chatterjee</keyname><forenames>Chandra Churh</forenames></author><author><keyname>Krishna</keyname><forenames>Gopal</forenames></author></authors><title>A Novel method for IDC Prediction in Breast Cancer Histopathology images
  using Deep Residual Neural Networks</title><categories>eess.IV cs.CV</categories><comments>Accepted at 2nd International Conference on Intelligent Communication
  and Computational Techniques,2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Invasive ductal carcinoma (IDC), which is also sometimes known as the
infiltrating ductal carcinoma, is the most regular form of breast cancer. It
accounts for about 80% of all breast cancers. According to the American Cancer
Society, more than 180,000 women in the United States are diagnosed with
invasive breast cancer each year. The survival rate associated with this form
of cancer is about 77% to 93% depending on the stage at which they are being
diagnosed. The invasiveness and the frequency of the occurrence of these
disease makes it one of the difficult cancers to be diagnosed. Our proposed
methodology involves diagnosing the invasive ductal carcinoma with a deep
residual convolution network to classify the IDC affected histopathological
images from the normal images. The dataset for the purpose used is a benchmark
dataset known as the Breast Histopathology Images. The microscopic RGB images
are converted into a seven channel image matrix, which is then fed to the
network. The proposed model produces a 99.29% accurate approach towards the
prediction of IDC in the histopathology images with an AUROC score of 0.9996.
Classification ability of the model is tested using standard performance
metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07369</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07369</id><created>2019-08-20</created><authors><author><keyname>Chistiakov</keyname><forenames>I. A.</forenames></author><author><keyname>Nikulin</keyname><forenames>A. A.</forenames></author><author><keyname>Gartseev</keyname><forenames>I. B.</forenames></author></authors><title>Pedestrian Dead-Reckoning Algorithms For Dual Foot-Mounted Inertial
  Sensors</title><categories>eess.SY cs.SY eess.SP</categories><comments>The data used in the article are available for downloading at
  http://gartseev.ru/projects/mkins2019</comments><journal-ref>Proc. 26th Saint Petersburg International Conference on Integrated
  Navigation Systems (ICINS), IEEE, May 2019, pp.1-8</journal-ref><doi>10.23919/ICINS.2019.8769341</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes algorithms for reconstruction of closed-loop pedestrian
trajectories based on two foot-mounted inertial measurement units (IMU). The
first proposed algorithm allows calculation of a trajectory using measurements
from only one IMU. The second algorithm uses data from both foot-mounted IMUs
simultaneously. Both algorithms are based on the Kalman filter and the
assumption that while a foot is on the ground its velocity is supposed to be
zero. Two methods for comparing the obtained trajectories are proposed,
advantages and disadvantages of each method are indicated and a way to optimize
the computation time is presented. In addition, a method is proposed for
constructing one generalized trajectory of human motion based on the
trajectories of each leg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07406</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07406</id><created>2019-07-24</created><authors><author><keyname>Sawadsitang</keyname><forenames>Suttinee</forenames></author><author><keyname>Niyato</keyname><forenames>Dusit</forenames></author><author><keyname>Tan</keyname><forenames>Puay Siew</forenames></author><author><keyname>Nutanong</keyname><forenames>Sarana</forenames></author></authors><title>Multi-Objective Optimization for Drone Delivery</title><categories>eess.SP</categories><comments>5 pages, 4 figures</comments><journal-ref>2019 IEEE 90th Vehicular Technology Conference: VTC2019-Fall</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, an unmanned aerial vehicle (UAV), as known as drone, has become an
alternative means of package delivery. Although the drone delivery scheduling
has been studied in recent years, most existing models are formulated as a
single objective optimization problem. However, in practice, the drone delivery
scheduling has multiple objectives that the shipper has to achieve. Moreover,
drone delivery typically faces with unexpected events, e.g., breakdown or
unable to takeoff, that can significantly affect the scheduling problem.
Therefore, in this paper, we propose a multi-objective and three-stage
stochastic optimization model for the drone delivery scheduling, called
multi-objective optimization for drone delivery (MODD) system. To handle the
the multi-objective optimization in the MODD system, we apply
$\varepsilon$-constraint method. The performance evaluation is performed by
using a real dataset from Singapore delivery services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07407</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07407</id><created>2019-08-12</created><authors><author><keyname>Omer</keyname><forenames>Ala Eldin</forenames></author><author><keyname>Shaker</keyname><forenames>George</forenames></author><author><keyname>Safavi-Naeini</keyname><forenames>Safieddin</forenames></author><author><keyname>Alqui&#xe9;</keyname><forenames>Georges</forenames></author><author><keyname>Deshours</keyname><forenames>Frederique</forenames></author><author><keyname>Kokabi</keyname><forenames>Hamid</forenames></author></authors><title>Triple-Poles Complementary Split Ring Resonator for Sensing Diabetics
  Glucose Levels at cm-Band</title><categories>physics.med-ph cs.HC eess.SP</categories><comments>4 pages, 5 figures, conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microwave sensors are very promising for sensing the blood glucose levels
non-invasively for their non-ionizing nature, miniaturized sizing, and low
health risks for diabetics. All these features offer the possibility for
realizing a portable non-invasive glucose sensor for monitoring glucose levels
in real time. In this article, we propose a triple poles complementary split
ring resonator (CSRR) produced on a FR4 substrate in microstrip technology in
the cm-wave band (1-6 GHz). The proposed bio-sensor can detect the small
variations in the dielectric properties (relative permittivity and dielectric
losses) of glucose in the blood mimicking aqueous solutions due their intense
interaction with the electromagnetic field at harmonic resonances. The
resonator exhibits higher sensitivity performance at the different resonances
compared to the single and double-poles counterparts as demonstrated by
simulations in a 3D full-wave EM solver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07408</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07408</id><created>2019-08-20</created><authors><author><keyname>Chen</keyname><forenames>Xihan</forenames></author><author><keyname>Cheng</keyname><forenames>Hei Victor</forenames></author><author><keyname>Liu</keyname><forenames>An</forenames></author><author><keyname>Shen</keyname><forenames>Kaiming</forenames></author><author><keyname>Zhao</keyname><forenames>Min-Jian</forenames></author></authors><title>Mixed-Timescale Beamforming and Power Splitting for Massive MIMO Aided
  SWIPT IoT Network</title><categories>cs.IT eess.SP math.IT math.OC</categories><comments>An extended version of a manuscript submitted to IEEE WCL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional simultaneous wireless information and power transfer (SWIPT) with
power splitting assumes perfect channel state information (CSI), which is
difficult to obtain especially in the massive multiple-input-multiple-output
(MIMO) regime. In this letter, we consider a mixed-timescale joint beamforming
and power splitting (MJBP) scheme to maximize general utility functions under a
power constraint in the downlink of a massive MIMO SWIPT IoT network. In this
scheme, the transmit digital beamformer is adapted to the imperfect CSI, while
the receive power splitters are adapted to the long-term channel statistics
only due to the consideration of hardware limit and signaling overhead. The
formulated optimization problem is solved using a mixed-timescale online
stochastic successive convex approximation (MO-SSCA) algorithm. Simulation
results reveal significant gain over the baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07409</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07409</id><created>2019-08-17</created><updated>2019-08-21</updated><authors><author><keyname>Bhaduri</keyname><forenames>Ritwik</forenames></author><author><keyname>Bonnerjee</keyname><forenames>Soham</forenames></author><author><keyname>Roy</keyname><forenames>Subhrajyoty</forenames></author></authors><title>Onset detection: A new approach to QBH system</title><categories>stat.AP cs.IR cs.SD eess.AS</categories><comments>30 pages, 26 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Query by Humming (QBH) is a system to provide a user with the song(s) which
the user hums to the system. Current QBH method requires the extraction of
onset and pitch information in order to track similarity with various versions
of different songs. However, we here focus on detecting precise onsets only and
use them to build a QBH system which is better than existing methods in terms
of speed and memory and empirically in terms of accuracy. We also provide
statistical analogy for onset detection functions and provide a measure of
error in our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07466</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07466</id><created>2019-08-15</created><authors><author><keyname>Nguyen</keyname><forenames>Dinh C.</forenames></author><author><keyname>Pathirana</keyname><forenames>Pubudu N.</forenames></author><author><keyname>Ding</keyname><forenames>Ming</forenames></author><author><keyname>Seneviratne</keyname><forenames>Aruna</forenames></author></authors><title>Secure Computation Offloading in Blockchain based IoT Networks with Deep
  Reinforcement Learning</title><categories>eess.SP</categories><comments>This work has been submitted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In current Internet of Things (IoT) networks, mobile edge-cloud computation
offloading (MECCO) has been regarded as a promising means to support
delay-sensitive IoT applications. However, offloading mobile tasks to cloud is
vulnerable to security risks due to malicious mobile devices (MDs). How to
implement offloading to solve computation problems of MDs while guaranteeing
high security in mobile cloud is challenging. In this paper, we investigate
simultaneously the security and offloading problems in a multi-user MECCO
system on mobile cloud blockchain. First, to improve offloading security, we
propose a trustworthy access control using blockchain, which protects clouds
against illegal offloading behaviours. Then, to tackle the intensive
computation issues of authorized MDs, we formulate a computation offloading
problem by jointly optimizing the offloading decisions and the allocation of
computing resource and radio bandwidth. This optimization problem aims to
minimize the long-term system costs of latency and energy consumption among all
MDs. To solve the proposed offloading problem, we develop a novel deep
reinforcement learning (DRL) algorithm by using advanced deep Q-network. We
evaluate our framework towards access control and offloading performances by
both real experiments and numerical simulations, showing significant advantages
over existing schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07467</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07467</id><created>2019-08-15</created><authors><author><keyname>Nguyen</keyname><forenames>Dinh C.</forenames></author><author><keyname>Pathirana</keyname><forenames>Pubudu N.</forenames></author><author><keyname>Ding</keyname><forenames>Ming</forenames></author><author><keyname>Seneviratne</keyname><forenames>Aruna</forenames></author></authors><title>Privacy-Preserved Task Offloading in Mobile Blockchain with Deep
  Reinforcement Learning</title><categories>eess.SP</categories><comments>This work has been submitted to IEEE Transactions on Network and
  Service Management (under revision)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blockchain technology with its secure, transparent and decentralized nature
has been recently employed in many mobile applications. However, the mining
process in mobile blockchain requires high computational and storage capability
of mobile devices, which would hinder blockchain applications in mobile
systems. To meet this challenge, we propose a mobile edge computing (MEC) based
blockchain network where multi-mobile users (MUs) act as miners to offload
their mining tasks to a nearby MEC server via wireless channels. Specially, we
formulate task offloading and user privacy preservation as a joint optimization
problem which is modelled as a Markov decision process, where our objective is
to minimize the long-term system offloading costs and maximize the privacy
levels for all blockchain users. We first propose a reinforcement learning
(RL)-based offloading scheme which enables MUs to make optimal offloading
decisions based on blockchain transaction states and wireless channel qualities
between MUs and MEC server. To further improve the offloading performances for
larger-scale blockchain scenarios, we then develop a deep RL algorithm by using
deep Q-network which can efficiently solve large state space without any prior
knowledge of the system dynamics. Simulation results show that the proposed
RL-based offloading schemes significantly enhance user privacy, and reduce the
energy consumption as well as computation latency with minimum offloading costs
in comparison with the benchmark offloading schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07483</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07483</id><created>2019-08-20</created><updated>2020-01-17</updated><authors><author><keyname>Wan</keyname><forenames>Cheng</forenames></author><author><keyname>McHill</keyname><forenames>Andrew W.</forenames></author><author><keyname>Klerman</keyname><forenames>Elizabeth</forenames></author><author><keyname>Sano</keyname><forenames>Akane</forenames></author></authors><title>Sensor-Based Estimation of Dim Light Melatonin Onset (DLMO) Using
  Features of Two Time Scales</title><categories>cs.LG eess.SP stat.ML</categories><comments>13 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Circadian rhythms influence multiple essential biological activities
including sleep, performance, and mood. The dim light melatonin onset (DLMO) is
the gold standard for measuring human circadian phase. The collection of DLMO
is expensive and time-consuming since multiple saliva or blood samples are
required overnight in special conditions, and the samples must then be assayed
for melatonin. Recently, several non-invasive approaches have been designed for
estimating DLMO. These methods collect daily sampled data (e.g., sleep
onset/offset times) or frequently sampled data (e.g., light exposure/skin
temperature/physical activity collected every minute) to train learning models
for estimating DLMO. One limitation of these studies was that they only
leveraged one time-scale data. We propose a two-step framework for estimating
DLMO using data from both time scales. The first step summarizes data from
before the current day, while the second step combines this summary with
frequently sampled data of the current day. We evaluate three moving average
models that input sleep timing data as the first step and use recurrent neural
network models as the second step. The results using data from 207
undergraduates show that our two-step model with two time-scale features has
statistically significantly lower root-mean-square errors than models that use
either daily sampled data or frequently sampled data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07488</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07488</id><created>2019-08-20</created><updated>2020-01-13</updated><authors><author><keyname>Klautau</keyname><forenames>Aldebaro</forenames></author><author><keyname>Gonz&#xe1;lez-Prelcic</keyname><forenames>Nuria</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>LIDAR Data for Deep Learning-Based mmWave Beam-Selection</title><categories>eess.SP</categories><comments>10 pages, IEEE; update: fixed typo</comments><doi>10.1109/LWC.2019.2899571</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave communication systems can leverage information from sensors
to reduce the overhead associated with link configuration. LIDAR (light
detection and ranging) is one sensor widely used in autonomous driving for high
resolution mapping and positioning. This paper shows how LIDAR data can be used
for line-of-sight detection and to reduce the overhead in millimeter wave
beam-selection. In the proposed distributed architecture, the base station
broadcasts its position. The connected vehicle leverages its LIDAR data to
suggest a set of beams selected via a deep convolutional neural network.
Co-simulation of communications and LIDAR in a vehicle-to-infrastructure (V2I)
scenario confirm that LIDAR can help configuring mmWave V2I links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07494</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07494</id><created>2019-08-20</created><updated>2020-01-13</updated><authors><author><keyname>Batista</keyname><forenames>Pedro</forenames></author><author><keyname>Khan</keyname><forenames>Shah Nawaz</forenames></author><author><keyname>&#xd6;hl&#xe9;n</keyname><forenames>Peter</forenames></author><author><keyname>Klautau</keyname><forenames>Aldebaro</forenames></author></authors><title>Tenant-Aware Slice Admission Control using Neural Networks-Based Policy
  Agent</title><categories>eess.SP</categories><comments>14 pages; update: fixed typo</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G networks will provide the platform for deploying large number of
tenant-associated management, control and end-user applications having
different resource requirements at the infrastructure level. In this context,
the 5G infrastructure provider must optimize the infrastructure resource
utilization and increase its revenue by intelligently admitting network slices
that bring the most revenue to the system. In addition, it must ensure that
resources can be scaled dynamically for the deployed slices when there is a
demand for them from the deployed slices. In this paper, we present a neural
networks-driven policy agent for network slice admission that learns the
characteristics of the slices deployed by the network tenants from their
resource requirements profile and balances the costs and benefits of slice
admission against resource management and orchestration costs. The policy agent
learns to admit the most profitable slices in the network while ensuring their
resource demands can be scaled elastically. We present the system model, the
policy agent architecture and results from simulation study showing an
increased revenue for infra-structure provider compared to other relevant slice
admission strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07503</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07503</id><created>2019-08-20</created><authors><author><keyname>Trindade</keyname><forenames>Igor</forenames></author><author><keyname>Nahum</keyname><forenames>Cleverson</forenames></author><author><keyname>Novaes</keyname><forenames>Camila</forenames></author><author><keyname>Cederholm</keyname><forenames>Daniel</forenames></author><author><keyname>Patra</keyname><forenames>Gyanesh</forenames></author><author><keyname>Klautau</keyname><forenames>Aldebaro</forenames></author></authors><title>C-RAN Virtualization with OpenAirInterface</title><categories>eess.SP cs.NI</categories><comments>2 pages, XXXVII Simp\'osio Brasileiro De Telecomunica\C{C}\~Oes E
  Processamento De Sinais - SBrT2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  C-RAN virtualization is a research topic with great interest since it allows
to share baseband processing resources.Therefore, in this work, we report the
implementation of a virtualized LTE testbed environment of C-RAN by integrating
the OpenAirInterface (OAI) with Docker. Using the test bed,we conducted a
workload study to understand the computation resource demand of C-RAN software.
Virtualization in containers has proven to be effective in creating a
functional 4G network which achieves realistic results to facilitate research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07516</identifier>
 <datestamp>2020-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07516</id><created>2019-08-19</created><updated>2020-02-11</updated><authors><author><keyname>Whiteley</keyname><forenames>William</forenames></author><author><keyname>Luk</keyname><forenames>Wing K.</forenames></author><author><keyname>Gregor</keyname><forenames>Jens</forenames></author></authors><title>DirectPET: Full Size Neural Network PET Reconstruction from Sinogram
  Data</title><categories>eess.IV cs.CV physics.med-ph</categories><comments>Submitted to the Journal of Medical Imaging</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: Neural network image reconstruction directly from measurement data
is a relatively new field of research, that until now has been limited to
producing small single-slice images (e.g., 1x128x128). This paper proposes a
novel and more efficient network design for Positron Emission Tomography called
DirectPET which is capable of reconstructing multi-slice image volumes (i.e.,
16x400x400) from sinograms.
  Approach: Large-scale direct neural network reconstruction is accomplished by
addressing the associated memory space challenge through the introduction of a
specially designed Radon inversion layer. Using patient data, we compare the
proposed method to the benchmark Ordered Subsets Expectation Maximization
(OSEM) algorithm using signal-to-noise ratio, bias, mean absolute error and
structural similarity measures. In addition, line profiles and full-width
half-maximum measurements are provided for a sample of lesions.
  Results: DirectPET is shown capable of producing images that are
quantitatively and qualitatively similar to the OSEM target images in a
fraction of the time. We also report on an experiment where DirectPET is
trained to map low count raw data to normal count target images demonstrating
the method's ability to maintain image quality under a low dose scenario.
  Conclusion: The ability of DirectPET to quickly reconstruct high-quality,
multi-slice image volumes suggests potential clinical viability of the method.
However, design parameters and performance boundaries need to be fully
established before adoption can be considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07517</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07517</id><created>2019-08-19</created><authors><author><keyname>Liu</keyname><forenames>Yuan</forenames></author><author><keyname>Cheng</keyname><forenames>Zhongwei</forenames></author><author><keyname>Liu</keyname><forenames>Jie</forenames></author><author><keyname>Yassin</keyname><forenames>Bourhan</forenames></author><author><keyname>Nan</keyname><forenames>Zhe</forenames></author><author><keyname>Luo</keyname><forenames>Jiebo</forenames></author></authors><title>AI for Earth: Rainforest Conservation by Acoustic Surveillance</title><categories>cs.SD cs.DB cs.LG eess.AS</categories><comments>Accepted to KDD2019 Workshop on Data Mining and AI for Conservation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Saving rainforests is a key to halting adverse climate changes. In this
paper, we introduce an innovative solution built on acoustic surveillance and
machine learning technologies to help rainforest conservation. In particular,
We propose new convolutional neural network (CNN) models for environmental
sound classification and achieved promising preliminary results on two
datasets, including a public audio dataset and our real rainforest sound
dataset. The proposed audio classification models can be easily extended in an
automated machine learning paradigm and integrated in cloud-based services for
real world deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07519</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07519</id><created>2019-08-20</created><authors><author><keyname>Tao</keyname><forenames>Wenjin</forenames></author><author><keyname>Leu</keyname><forenames>Ming C.</forenames></author><author><keyname>Yin</keyname><forenames>Zhaozheng</forenames></author></authors><title>Multi-Modal Recognition of Worker Activity for Human-Centered
  Intelligent Manufacturing</title><categories>cs.CV cs.HC cs.LG eess.IV eess.SP</categories><comments>17 pages, 8 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a human-centered intelligent manufacturing system, sensing and
understanding of the worker's activity are the primary tasks. In this paper, we
propose a novel multi-modal approach for worker activity recognition by
leveraging information from different sensors and in different modalities.
Specifically, a smart armband and a visual camera are applied to capture
Inertial Measurement Unit (IMU) signals and videos, respectively. For the IMU
signals, we design two novel feature transform mechanisms, in both frequency
and spatial domains, to assemble the captured IMU signals as images, which
allow using convolutional neural networks to learn the most discriminative
features. Along with the above two modalities, we propose two other modalities
for the video data, at the video frame and video clip levels, respectively.
Each of the four modalities returns a probability distribution on activity
prediction. Then, these probability distributions are fused to output the
worker activity classification result. A worker activity dataset of 6
activities is established, which at present contains 6 common activities in
assembly tasks, i.e., grab a tool/part, hammer a nail, use a power-screwdriver,
rest arms, turn a screwdriver, and use a wrench. The developed multi-modal
approach is evaluated on this dataset and achieves recognition accuracies as
high as 97% and 100% in the leave-one-out and half-half experiments,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07568</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07568</id><created>2019-08-20</created><authors><author><keyname>Amani</keyname><forenames>Nahid</forenames></author><author><keyname>Parsaeefard</keyname><forenames>Saeedeh</forenames></author><author><keyname>Taheri</keyname><forenames>Hassan</forenames></author><author><keyname>Pedram</keyname><forenames>Hossein</forenames></author></authors><title>Power-Efficient Resource Allocation in Massive MIMO Aided Cloud RANs</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the power-efficient resource allocation problem in a
cloud radio access network (C-RAN). The C-RAN architecture consists of a set of
base-band units (BBUs) which are connected to a set of radio remote heads
(RRHs) equipped with massive multiple input multiple output (MIMO), via
fronthaul links with limited capacity. We formulate the power-efficient
optimization problem in C-RANs as a joint resource allocation problem in order
to jointly allocate the RRH and transmit power to each user, and fronthaul
links and BBUs assign to active RRHs while satisfying the minimum required rate
of each user. To solve this non-convex optimization problem we suggest
iterative algorithm with two-step based on the complementary geometric
programming (CGP) and the successive convex approximation (SCA). The simulation
results indicate that our proposed scheme can significantly reduce the total
transmission power by switching off the under-utilized RRHs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07590</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07590</id><created>2019-08-20</created><authors><author><keyname>Ge</keyname><forenames>Songwei</forenames></author><author><keyname>Xuan</keyname><forenames>Curtis</forenames></author><author><keyname>Song</keyname><forenames>Ruihua</forenames></author><author><keyname>Zou</keyname><forenames>Chao</forenames></author><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Zhou</keyname><forenames>Jin</forenames></author></authors><title>From Text to Sound: A Preliminary Study on Retrieving Sound Effects to
  Radio Stories</title><categories>cs.IR cs.CL cs.SD eess.AS</categories><comments>In the Proceedings of the 42nd International ACM SIGIR Conference on
  Research and Development in Information Retrieval (SIGIR 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sound effects play an essential role in producing high-quality radio stories
but require enormous labor cost to add. In this paper, we address the problem
of automatically adding sound effects to radio stories with a retrieval-based
model. However, directly implementing a tag-based retrieval model leads to high
false positives due to the ambiguity of story contents. To solve this problem,
we introduce a retrieval-based framework hybridized with a semantic inference
model which helps to achieve robust retrieval results. Our model relies on
fine-designed features extracted from the context of candidate triggers. We
collect two story dubbing datasets through crowdsourcing to analyze the setting
of adding sound effects and to train and test our proposed methods. We further
discuss the importance of each feature and introduce several heuristic rules
for the trade-off between precision and recall. Together with the
text-to-speech technology, our results reveal a promising automatic pipeline on
producing high-quality radio stories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07619</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07619</id><created>2019-08-20</created><authors><author><keyname>Badawi</keyname><forenames>Diaa</forenames></author><author><keyname>Ayhan</keyname><forenames>Tuba</forenames></author><author><keyname>Ozev</keyname><forenames>Sule</forenames></author><author><keyname>Yang</keyname><forenames>Chengmo</forenames></author><author><keyname>Orailoglu</keyname><forenames>Alex</forenames></author><author><keyname>&#xc7;etin</keyname><forenames>A. Enis</forenames></author></authors><title>Detecting Gas Vapor Leaks Using Uncalibrated Sensors</title><categories>eess.SP cs.LG</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Chemical and infra-red sensors generate distinct responses under similar
conditions because of sensor drift, noise or resolution errors. In this work,
we use different time-series data sets obtained by infra-red and E-nose sensors
in order to detect Volatile Organic Compounds (VOCs) and Ammonia vapor leaks.
We process time-series sensor signals using deep neural networks (DNN). Three
neural network algorithms are utilized for this purpose. Additive neural
networks (termed AddNet) are based on a multiplication-devoid operator and
consequently exhibit energy-efficiency compared to regular neural networks. The
second algorithm uses generative adversarial neural networks so as to expose
the classifying neural network to more realistic data points in order to help
the classifier network to deliver improved generalization. Finally, we use
conventional convolutional neural networks as a baseline method and compare
their performance with the two aforementioned deep neural network algorithms in
order to evaluate their effectiveness empirically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07623</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07623</id><created>2019-08-20</created><authors><author><keyname>Qin</keyname><forenames>Chen</forenames></author><author><keyname>Bai</keyname><forenames>Wenjia</forenames></author><author><keyname>Schlemper</keyname><forenames>Jo</forenames></author><author><keyname>Petersen</keyname><forenames>Steffen E.</forenames></author><author><keyname>Piechnik</keyname><forenames>Stefan K.</forenames></author><author><keyname>Neubauer</keyname><forenames>Stefan</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author></authors><title>Joint Motion Estimation and Segmentation from Undersampled Cardiac MR
  Image</title><categories>eess.IV cs.CV</categories><comments>This work is published at MLMIR 2018: Machine Learning for Medical
  Image Reconstruction</comments><doi>10.1007/978-3-030-00129-2_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accelerating the acquisition of magnetic resonance imaging (MRI) is a
challenging problem, and many works have been proposed to reconstruct images
from undersampled k-space data. However, if the main purpose is to extract
certain quantitative measures from the images, perfect reconstructions may not
always be necessary as long as the images enable the means of extracting the
clinically relevant measures. In this paper, we work on jointly predicting
cardiac motion estimation and segmentation directly from undersampled data,
which are two important steps in quantitatively assessing cardiac function and
diagnosing cardiovascular diseases. In particular, a unified model consisting
of both motion estimation branch and segmentation branch is learned by
optimising the two tasks simultaneously. Additional corresponding fully-sampled
images are incorporated into the network as a parallel sub-network to enhance
and guide the learning during the training process. Experimental results using
cardiac MR images from 220 subjects show that the proposed model is robust to
undersampled data and is capable of predicting results that are close to that
from fully-sampled ones, while bypassing the usual image reconstruction stage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07653</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07653</id><created>2019-07-30</created><authors><author><keyname>Sultan</keyname><forenames>Kashif</forenames></author><author><keyname>Ali</keyname><forenames>Hazrat</forenames></author><author><keyname>Anwaar</keyname><forenames>Haris</forenames></author><author><keyname>Nkabiti</keyname><forenames>Kabo Poloko</forenames></author><author><keyname>Ahamd</keyname><forenames>Adeel</forenames></author><author><keyname>Zhang</keyname><forenames>Zhongshan</forenames></author></authors><title>Understanding and Partitioning Mobile Traffic using Internet Activity
  Records Data -- A Spatiotemporal Approach</title><categories>cs.NI cs.LG eess.SP stat.ML</categories><comments>2019 28th Wireless and Optical Communications Conference (WOCC)</comments><doi>10.1109/WOCC.2019.8770653</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The internet activity records (IARs) of a mobile cellular network posses
significant information which can be exploited to identify the network's
efficacy and the mobile users' behavior. In this work, we extract useful
information from the IAR data and identify a healthy predictability of
spatio-temporal pattern within the network traffic. The information extracted
is helpful for network operators to plan effective network configuration and
perform management and optimization of network's resources. We report
experimentation on spatiotemporal analysis of IAR data of the Telecom Italia.
Based on this, we present mobile traffic partitioning scheme. Experimental
results of the proposed model is helpful in modelling and partitioning of
network traffic patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07656</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07656</id><created>2019-08-16</created><updated>2019-11-30</updated><authors><author><keyname>Alam</keyname><forenames>Mahbubul</forenames></author><author><keyname>Samad</keyname><forenames>Manar D.</forenames></author><author><keyname>Vidyaratne</keyname><forenames>Lasitha</forenames></author><author><keyname>Glandon</keyname><forenames>Alexander</forenames></author><author><keyname>Iftekharuddin</keyname><forenames>Khan M.</forenames></author></authors><title>Survey on Deep Neural Networks in Speech and Vision Systems</title><categories>cs.CV cs.LG cs.NE cs.SD eess.AS eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This survey presents a review of state-of-the-art deep neural network
architectures, algorithms, and systems in vision and speech applications.
Recent advances in deep artificial neural network algorithms and architectures
have spurred rapid innovation and development of intelligent vision and speech
systems. With availability of vast amounts of sensor data and cloud computing
for processing and training of deep neural networks, and with increased
sophistication in mobile and embedded technology, the next-generation
intelligent systems are poised to revolutionize personal and commercial
computing. This survey begins by providing background and evolution of some of
the most successful deep learning models for intelligent vision and speech
systems to date. An overview of large-scale industrial research and development
efforts is provided to emphasize future trends and prospects of intelligent
vision and speech systems. Robust and efficient intelligent systems demand
low-latency and high fidelity in resource-constrained hardware platforms such
as mobile devices, robots, and automobiles. Therefore, this survey also
provides a summary of key challenges and recent successes in running deep
neural networks on hardware-restricted platforms, i.e. within limited memory,
battery life, and processing capabilities. Finally, emerging applications of
vision and speech across disciplines such as affective computing, intelligent
transportation, and precision medicine are discussed. To our knowledge, this
paper provides one of the most comprehensive surveys on the latest developments
in intelligent vision and speech applications from the perspectives of both
software and hardware systems. Many of these emerging technologies using deep
neural networks show tremendous promise to revolutionize research and
development for future vision and speech systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07674</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07674</id><created>2019-08-20</created><authors><author><keyname>Alasti</keyname><forenames>Hadi</forenames></author></authors><title>Efficient Sensing of Correlated Spatiotemporal Signals: A Stochastic
  Gradient Approach</title><categories>eess.SP eess.IV</categories><comments>5 pages, 7 figures, article</comments><doi>10.1109/LSP.2019.2945125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A significantly low cost and tractable progressive learning approach is
proposed and discussed for efficient spatiotemporal monitoring of a completely
unknown, two dimensional correlated signal distribution in localized wireless
sensor field. The spatial distribution is compressed into a number of its
contour lines and only those sensors that their sensor observations are in a
$\Delta$ margin of the contour levels are reporting to the information fusion
center (IFC). The proposed algorithm progressively finds the model parameters
in iterations, by using extrapolation in curve fitting, and stochastic gradient
method for spatial monitoring. The IFC tracks the signal variations using these
parameters, over time. The monitoring performance and the cost of the proposed
algorithm are discussed, in this letter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07689</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07689</id><created>2019-08-18</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Li</keyname><forenames>Zhi</forenames></author><author><keyname>Chen</keyname><forenames>Liang</forenames></author><author><keyname>Li</keyname><forenames>Guoqing</forenames></author></authors><title>A false data injection attack method for generator dynamic state
  estimation</title><categories>eess.SY cs.SY eess.SP</categories><comments>in Chinese, Accepted by Transactions of China Electrotechnical
  Society</comments><journal-ref>Transactions of China Electrotechnical Society 34 (2019) 3651-3660</journal-ref><doi>10.19595/j.cnki.1000-6753.tces.181150</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate and reliable dynamic state quantities of generators are very
important for real-time monitoring and control of the power system. The
emergence of cyber attacks has brought new challenges to the state estimation
of generators. Especially, false data injection (FDI) attacks deteriorate the
accuracy of state estimation by injecting the false data into the measurement
device. In this regard, this paper proposes for the first time an FDI attack
model based on the dynamic state estimation of generators. Firstly, Taylor's
formula was used to linearize the generator's measurement equation. Secondly,
according to the principle that the measurement residuals before and after the
FDI attack are equal, the expressions of the attack vectors were established,
and they were applied to the measurement quantities to avoid the conventional
bad data detection. Thereby, the FDI attacks were successfully implemented.
Then, three attack scenarios were set according to the degree of the FDI
attacks, and they were tested by the cubature Kalman filter (CKF) and the
robust cubature Kalman filter (RCKF). Finally, the simulation results of the
IEEE 9-bus system and the New England 16-machine 68-bus system verify the
effectiveness of the proposed FDI attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07691</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07691</id><created>2019-08-20</created><authors><author><keyname>Li</keyname><forenames>Nan</forenames></author><author><keyname>Kolmanovsky</keyname><forenames>Ilya</forenames></author><author><keyname>Girard</keyname><forenames>Anouck</forenames></author></authors><title>Detection-averse optimal and receding-horizon control for Markov
  decision processes</title><categories>eess.SY cs.SY math.OC</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a Markov decision process (MDP), where the ego
agent has a nominal objective to pursue while needs to hide its state from
detection by an adversary. After formulating the problem, we first propose a
value iteration (VI) approach to solve it. To overcome the &quot;curse of
dimensionality&quot; and thus gain scalability to larger-sized problems, we then
propose a receding-horizon optimization (RHO) approach to obtain approximate
solutions. We use examples to illustrate and compare the VI and RHO approaches,
and to show the potential of our problem formulation for practical
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07696</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07696</id><created>2019-08-20</created><authors><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>First 20 Years of Green Radios</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Green radios jointly consider the spectrum efficiency and the energy
efficiency in wireless networks in order to provide sustainable development. In
the past two decades, various green radio solutions for different types of
terminals and radio access networks have been developed, some of which have
been used in the designs of wireless products. In this paper, we provide a
historical view on some fundamental works and practical issues. In addition to
providing a comprehensive overview on theoretical achievements, we also discuss
several important power saving solutions with notable engineering impacts, such
as Doherty power amplifier and separated baseband unit - remote radio unit
architecture, which might be overlooked in previous publications. Moreover,
with the huge growth of wireless traffic in the near future, green radio design
for future wireless networks shall involve an end-to-end energy efficiency
investigation of mobile terminals, radio access and core networks, and
different applications. By introducing green radio schemes for advanced
terminals and future wireless networks, this article will not only be
beneficial for readers with only preliminary background in communications and
signal processing but also have reference and historical values for researchers
and practical engineers in the area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07699</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07699</id><created>2019-08-20</created><authors><author><keyname>Cui</keyname><forenames>Chunfeng</forenames></author><author><keyname>Hawkins</keyname><forenames>Cole</forenames></author><author><keyname>Zhang</keyname><forenames>Zheng</forenames></author></authors><title>Tensor Methods for Generating Compact Uncertainty Quantification and
  Deep Learning Models</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tensor methods have become a promising tool to solve high-dimensional
problems in the big data era. By exploiting possible low-rank tensor
factorization, many high-dimensional model-based or data-driven problems can be
solved to facilitate decision making or machine learning. In this paper, we
summarize the recent applications of tensor computation in obtaining compact
models for uncertainty quantification and deep learning. In uncertainty
analysis where obtaining data samples is expensive, we show how tensor methods
can significantly reduce the simulation or measurement cost. To enable the
deployment of deep learning on resource-constrained hardware platforms, tensor
methods can be used to significantly compress an over-parameterized neural
network model or directly train a small-size model from scratch via
optimization or statistical techniques. Recent Bayesian tensorized neural
networks can automatically determine their tensor ranks in the training
process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07704</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07704</id><created>2019-08-21</created><authors><author><keyname>Nishio</keyname><forenames>Mizuho</forenames></author><author><keyname>Fujimoto</keyname><forenames>Koji</forenames></author><author><keyname>Togashi</keyname><forenames>Kaori</forenames></author></authors><title>Lung segmentation on chest x-ray images in patients with severe abnormal
  findings using deep learning</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rationale and objectives: Several studies have evaluated the usefulness of
deep learning for lung segmentation using chest x-ray (CXR) images with small-
or medium-sized abnormal findings. Here, we built a database including both CXR
images with severe abnormalities and experts' lung segmentation results, and
aimed to evaluate our network's efficacy in lung segmentation from these
images. Materials and Methods: For lung segmentation, CXR images from the
Japanese Society of Radiological Technology (JSRT, N = 247) and Montgomery
databases (N = 138), were included, and 65 additional images depicting severe
abnormalities from a public database were evaluated and annotated by a
radiologist, thereby adding lung segmentation results to these images. Baseline
U-net was used to segment the lungs in images from the three databases.
Subsequently, the U-net network architecture was automatically optimized for
lung segmentation from CXR images using Bayesian optimization. Dice similarity
coefficient (DSC) was calculated to confirm segmentation. Results: Our results
demonstrated that using baseline U-net yielded poorer lung segmentation results
in our database than those in the JSRT and Montgomery databases, implying that
robust segmentation of lungs may be difficult because of severe abnormalities.
The DSC values with baseline U-net for the JSRT, Montgomery and our databases
were 0.979, 0.941, and 0.889, respectively, and with optimized U-net, 0.976,
0.973, and 0.932, respectively. Conclusion: For robust lung segmentation, the
U-net architecture was optimized via Bayesian optimization, and our results
demonstrate that the optimized U-net was more robust than baseline U-net in
lung segmentation from CXR images with large-sized abnormalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07726</identifier>
 <datestamp>2020-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07726</id><created>2019-08-21</created><authors><author><keyname>Vesal</keyname><forenames>Sulaiman</forenames></author><author><keyname>Ravikumar</keyname><forenames>Nishant</forenames></author><author><keyname>Maier</keyname><forenames>Andreas</forenames></author></authors><title>Automated Multi-sequence Cardiac MRI Segmentation Using Supervised
  Domain Adaptation</title><categories>eess.IV cs.CV</categories><comments>Accepted at STACOM-MICCAI 2019</comments><doi>10.1007/978-3-030-39074-7_32</doi><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Left ventricle segmentation and morphological assessment are essential for
improving diagnosis and our understanding of cardiomyopathy, which in turn is
imperative for reducing risk of myocardial infarctions in patients.
Convolutional neural network (CNN) based methods for cardiac magnetic resonance
(CMR) image segmentation rely on supervision with pixel-level annotations, and
may not generalize well to images from a different domain. These methods are
typically sensitive to variations in imaging protocols and data acquisition.
Since annotating multi-sequence CMR images is tedious and subject to inter- and
intra-observer variations, developing methods that can automatically adapt from
one domain to the target domain is of great interest. In this paper, we propose
an approach for domain adaptation in multi-sequence CMR segmentation task using
transfer learning that combines multi-source image information. We first train
an encoder-decoder CNN on T2-weighted and balanced-Steady State Free Precession
(bSSFP) MR images with pixel-level annotation and fine-tune the same network
with a limited number of Late Gadolinium Enhanced-MR (LGE-MR) subjects, to
adapt the domain features. The domain-adapted network was trained with just
four LGE-MR training samples and obtained an average Dice score of $\sim$85.0\%
on the test set comprises of 40 LGE-MR subjects. The proposed method
significantly outperformed a network without adaptation trained from scratch on
the same set of LGE-MR training data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07727</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07727</id><created>2019-08-21</created><authors><author><keyname>Bruns</keyname><forenames>Steffen</forenames></author><author><keyname>Wolterink</keyname><forenames>Jelmer M.</forenames></author><author><keyname>van Hamersvelt</keyname><forenames>Robbert W.</forenames></author><author><keyname>Leiner</keyname><forenames>Tim</forenames></author><author><keyname>I&#x161;gum</keyname><forenames>Ivana</forenames></author></authors><title>CNN-Based Segmentation of the Cardiac Chambers and Great Vessels in
  Non-Contrast-Enhanced Cardiac CT</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/SJeqoqAaFV</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Quantification of cardiac structures in non-contrast CT (NCCT) could improve
cardiovascular risk stratification. However, setting a manual reference to
train a fully convolutional network (FCN) for automatic segmentation of NCCT
images is hardly feasible, and an FCN trained on coronary CT angiography (CCTA)
images would not generalize to NCCT. Therefore, we propose to train an FCN with
virtual non-contrast (VNC) images from a dual-layer detector CT scanner and a
reference standard obtained on perfectly aligned CCTA images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07729</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07729</id><created>2019-08-21</created><authors><author><keyname>Valiulahi</keyname><forenames>Iman</forenames></author><author><keyname>Parvaresh</keyname><forenames>Farzad</forenames></author><author><keyname>Beheshti</keyname><forenames>Ali Asghar</forenames></author></authors><title>Eliminating Impulsive Noise in Pilot-Aided OFDM Channels via Dual of
  Penalized Atomic Norm</title><categories>cs.IT eess.SP math.IT</categories><doi>10.1109/LCOMM.2019.2935438</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel estimator for pilot-aided orthogonal
frequency division multiplexing (OFDM) channels in an additive Gaussian and
impulsive perturbation environment. Due to sensor failure which might happen
because of man-made noise, a number of measurements in high rate communication
systems is often corrupted by impulsive noise. High power impulsive noise is
generally an obstacle for OFDM systems as valuable information will be
completely lost. To overcome this concern, an objective function based on a
penalized atomic norm minimization (PANM) is provided in order to promote the
sparsity of time dispersive channels and impulsive noise. The corresponding
dual problem of the PANM is then converted to tractable semidefinite
programming. It has shown that one can simultaneously estimate the time
dispersive channels in a continuous dictionary and the location of impulsive
noise using the dual problem. Several numerical experiments are carried out to
evaluate the performance of the proposed estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07736</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07736</id><created>2019-08-21</created><authors><author><keyname>Bayramoglu</keyname><forenames>Neslihan</forenames></author><author><keyname>Tiulpin</keyname><forenames>Aleksei</forenames></author><author><keyname>Hirvasniemi</keyname><forenames>Jukka</forenames></author><author><keyname>Nieminen</keyname><forenames>Miika T.</forenames></author><author><keyname>Saarakkala</keyname><forenames>Simo</forenames></author></authors><title>Adaptive Segmentation of Knee Radiographs for Selecting the Optimal ROI
  in Texture Analysis</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purposes of this study were to investigate: 1) the effect of placement of
region-of-interest (ROI) for texture analysis of subchondral bone in knee
radiographs, and 2) the ability of several texture descriptors to distinguish
between the knees with and without radiographic osteoarthritis (OA). Bilateral
posterior-anterior knee radiographs were analyzed from the baseline of OAI and
MOST datasets. A fully automatic method to locate the most informative region
from subchondral bone using adaptive segmentation was developed. We used an
oversegmentation strategy for partitioning knee images into the compact regions
that follow natural texture boundaries. LBP, Fractal Dimension (FD), Haralick
features, Shannon entropy, and HOG methods were computed within the standard
ROI and within the proposed adaptive ROIs. Subsequently, we built logistic
regression models to identify and compare the performances of each texture
descriptor and each ROI placement method using 5-fold cross validation setting.
Importantly, we also investigated the generalizability of our approach by
training the models on OAI and testing them on MOST dataset.We used area under
the receiver operating characteristic (ROC) curve (AUC) and average precision
(AP) obtained from the precision-recall (PR) curve to compare the results. We
found that the adaptive ROI improves the classification performance (OA vs.
non-OA) over the commonly used standard ROI (up to 9% percent increase in AUC).
We also observed that, from all texture parameters, LBP yielded the best
performance in all settings with the best AUC of 0.840 [0.825, 0.852] and
associated AP of 0.804 [0.786, 0.820]. Compared to the current state-of-the-art
approaches, our results suggest that the proposed adaptive ROI approach in
texture analysis of subchondral bone can increase the diagnostic performance
for detecting the presence of radiographic OA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07750</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07750</id><created>2019-08-21</created><authors><author><keyname>Chen</keyname><forenames>Zezhou</forenames></author><author><keyname>Liu</keyname><forenames>Zhaoxiang</forenames></author><author><keyname>Hu</keyname><forenames>Huan</forenames></author><author><keyname>Bai</keyname><forenames>Jinqiang</forenames></author><author><keyname>Lian</keyname><forenames>Shiguo</forenames></author><author><keyname>Shi</keyname><forenames>Fuyuan</forenames></author><author><keyname>Wang</keyname><forenames>Kai</forenames></author></authors><title>A Realistic Face-to-Face Conversation System based on Deep Neural
  Networks</title><categories>cs.CV cs.SD eess.AS eess.IV</categories><comments>Accepted to ICCV 2019 workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To improve the experiences of face-to-face conversation with avatar, this
paper presents a novel conversation system. It is composed of two
sequence-to-sequence models respectively for listening and speaking and a
Generative Adversarial Network (GAN) based realistic avatar synthesizer. The
models exploit the facial action and head pose to learn natural human
reactions. Based on the models' output, the synthesizer uses the Pixel2Pixel
model to generate realistic facial images. To show the improvement of our
system, we use a 3D model based avatar driving scheme as a reference. We train
and evaluate our neural networks with the data from ESPN shows. Experimental
results show that our conversation system can generate natural facial reactions
and realistic facial images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07755</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07755</id><created>2019-08-21</created><authors><author><keyname>Nikandish</keyname><forenames>Gholamreza</forenames></author><author><keyname>Staszewski</keyname><forenames>Robert Bogdan</forenames></author><author><keyname>Zhu</keyname><forenames>Anding</forenames></author></authors><title>Breaking Bandwidth Limit: A Review of Broadband Doherty Power Amplifier
  Design for 5G</title><categories>eess.SP</categories><comments>This paper has been accepted for publication in IEEE Microwave
  Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Doherty power amplifier (DPA) has been extensively explored in the past
and has become one of the most widely used power amplifier (PA) architectures
in cellular base stations. The classical DPA suffers intrinsic bandwidth
constrains which limit its application in future 5G wireless transmitters. In
this paper, we present a comprehensive review of the DPA bandwidth enhancement
techniques proposed in literature in order to provide a thorough understanding
of the DPA's broadband design for high-efficiency 5G wireless transmitters. We
elaborate on the main bandwidth limitation sources and provide circuit design
insights. We then follow with an overview of bandwidth enhancement techniques
developed for the DPA, including modified load-modulation networks, frequency
response optimization, parasitic compensation, post-matching, as well as
distributed DPA, dual-input digital DPA, transformer-based power-combining PA,
and transformer-less load modulated PA architectures. Furthermore, challenges
and design techniques for integrated circuit (IC) implementation of broadband
DPAs are discussed, including a review of circuits developed in CMOS, SiGe, and
GaN processes, and operating in RF and mm-Wave frequencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07758</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07758</id><created>2019-08-21</created><authors><author><keyname>Li</keyname><forenames>Peihao</forenames></author><author><keyname>Laleg-Kirati</keyname><forenames>Taous Meriem</forenames></author></authors><title>Signal denoising based on the Schr\&quot;odinger operator's eigenspectrum and
  a curvature constraint</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a new Signal processing method, named Semi-Classical Signal
Analysis (SCSA), has been proposed for denoising Magnetic Resonance
Spectroscopy (MRS) signals. It is based on the Schr\&quot;odinger Operator's
eigenspectrum. It allows an efficient noise reduction while preserving MRS
signal's peaks. In this paper, we propose to extend this approach to different
signals, in particular pulse shaped signals, by including an optimization that
considers curvature constraints. The performance of the method is measured by
analyzing noisy signal data and comparing with other denoising methods. Results
indicate that the proposed method not only produces good denoising performance
but also guarantees the peaks are well preserved in the denoising process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07765</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07765</id><created>2019-08-21</created><authors><author><keyname>Landau</keyname><forenames>Yuval</forenames></author><author><keyname>Kiryati</keyname><forenames>Nahum</forenames></author></authors><title>Dataset Growth in Medical Image Analysis Research</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical image analysis studies usually require medical image datasets for
training, testing and validation of algorithms. The need is underscored by the
deep learning revolution and the dominance of machine learning in recent
medical image analysis research. Nevertheless, due to ethical and legal
constraints, commercial conflicts and the dependence on busy medical
professionals, medical image analysis researchers have been described as &quot;data
starved&quot;. Due to the lack of objective criteria for sufficiency of dataset
size, the research community implicitly sets ad-hoc standards by means of the
peer review process. We hypothesize that peer review requires researchers to
report the use of ever-increasing datasets as one condition for acceptance of
their work to reputable publication venues. To test this hypothesis, we scanned
the proceedings of the eminent MICCAI (Medical Image Computing and
Computer-Assisted Intervention) conferences from 2011 to 2018. From a total of
2136 articles, we focused on 907 papers involving human datasets of MRI
(Magnetic Resonance Imaging), CT (Computed Tomography) and fMRI (functional
MRI) images. For each modality, for each of the years 2011-2018 we calculated
the average, geometric mean and median number of human subjects used in that
year's MICCAI articles. The results corroborate the dataset growth hypothesis.
Specifically, the annual median dataset size in MICCAI articles has grown
roughly 3-10 times from 2011 to 2018, depending on the imaging modality.
Statistical analysis further supports the dataset growth hypothesis and reveals
exponential growth of the geometric mean dataset size, with annual growth of
about 21% for MRI, 24% for CT and 31% for fMRI. In slight analogy to Moore's
law, the results can provide guidance about trends in the expectations of the
medical image analysis community regarding dataset size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07774</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07774</id><created>2019-08-21</created><authors><author><keyname>Amer</keyname><forenames>Ramy</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Marchetti</keyname><forenames>Nicola</forenames></author></authors><title>Mobility in the Sky: Performance and Mobility Analysis for
  Cellular-Connected UAVs</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing connectivity to unmanned aerial vehicle-user equipments such as
drones or flying taxis is a major challenge for tomorrow cellular systems. In
this paper, the use of coordinated multi-point transmission for providing
seamless connectivity to UAV user equipments is investigated. In particular, a
network of clustered ground base stations that cooperatively serve a number of
UAVUEs is considered. Two scenarios are studied: scenarios with static,
hovering UAV user equipments and scenarios with mobile UAV-UEs. Under a maximum
ratio transmission, a novel framework is developed and leveraged to derive
upper and lower bounds on the UAV-UE coverage probability for both scenarios.
Using the derived results, the effects of various system parameters such as
collaboration distance, UAVUE altitude, and UAV-UE velocity on the achievable
performance are studied. Results reveal that, for both static and mobile UAV
user equipments, when the BS antennas are tilted downwards, the coverage
probability of a high-altitude UAV-UE is upper bounded by that of ground users
regardless of the transmission scheme. Moreover, for low
signal-to-interference-ratio thresholds, it is shown that CoMP transmission can
improve the coverage probability of UAV user equipments, e.g., from 28% under
the nearest association scheme to 60% for a collaboration distance of 200m.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07794</identifier>
 <datestamp>2019-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07794</id><created>2019-08-21</created><updated>2019-11-12</updated><authors><author><keyname>Kaltenbacher</keyname><forenames>Stefan</forenames></author><author><keyname>Steinberger</keyname><forenames>Martin</forenames></author><author><keyname>Horn</keyname><forenames>Martin</forenames></author></authors><title>Pipe Roughness Identification of Water Distribution Networks: The Full
  Turbulent Case</title><categories>eess.SY cs.SY</categories><journal-ref>Journal of Applied Mathematical Modelling, 2019, ISSN 0307-904X,
  (https://www.sciencedirect.com/science/article/pii/S0307904X19306766?via%3Dihub)</journal-ref><doi>10.1016/j.apm.2019.11.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a technique to identify individual pipe roughness
parameters in a water distribution network by means of the inversion of the
steady-state hydraulic network equations. By enabling the reconstruction of
these hydraulic friction parameters to be reliable, this technique improves the
conventional model's accuracy and thereby promises to enhance model-based
leakage detection and localization. As it is the case in so-called fireflow
tests, this methodology is founded on the premise to measure the pressure
distributed at a subset of nodes in the network's graph while assuming the
nodal consumption to be known. Beside of the proposed problem formulation,
which is restricted to only allow turbulent flow in each of the network's pipes
initially, developed algorithms are presented and evaluated using simulation
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07803</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07803</id><created>2019-08-21</created><authors><author><keyname>Khan</keyname><forenames>Gulam Dastagir</forenames></author><author><keyname>Chen</keyname><forenames>Zhiyong</forenames></author><author><keyname>Yan</keyname><forenames>Yamin</forenames></author></authors><title>Event-Triggered Output Synchronization of Heterogeneous Nonlinear
  Multi-Agents</title><categories>eess.SY cs.SY</categories><comments>12 pages, 5 figures, IEEE transaction</comments><journal-ref>CYB-E-2019-04-0672</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper addresses the output synchronization problem for heterogeneous
nonlinear multi-agent systems with distributed event-based controllers.
Employing the two-step synchronization process, we first outline the
distributed event-triggered consensus controllers for linear reference models
under a directed communication topology. It is further shown that the
subsequent triggering instants are based on intermittent communication.
Secondly, by using certain input-to-state stability (ISS) property, we design
an event-triggered perturbed output regulation controller for each nonlinear
multi-agent. The ISS technique used in this paper is based on the milder
condition that each agent has a certain ISS property from input (actuator)
disturbance to state rather than measurement (sensor) disturbance to state.
With the two-step design, the objective of output synchronization is
successfully achieved with Zeno behavior avoided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07824</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07824</id><created>2019-08-12</created><authors><author><keyname>Adler</keyname><forenames>Amir</forenames></author><author><keyname>Araya-Polo</keyname><forenames>Mauricio</forenames></author><author><keyname>Poggio</keyname><forenames>Tomaso</forenames></author></authors><title>Deep Recurrent Architectures for Seismic Tomography</title><categories>physics.geo-ph eess.IV eess.SP</categories><comments>Published in the 81st EAGE Conference and Exhibition, 2019</comments><doi>10.3997/2214-4609.201901512</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces novel deep recurrent neural network architectures for
Velocity Model Building (VMB), which is beyond what Araya-Polo et al 2018
pioneered with the Machine Learning-based seismic tomography built with
convolutional non-recurrent neural network. Our investigation includes the
utilization of basic recurrent neural network (RNN) cells, as well as Long
Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) cells. Performance
evaluation reveals that salt bodies are consistently predicted more accurately
by GRU and LSTM-based architectures, as compared to non-recurrent
architectures. The results take us a step closer to the final goal of a
reliable fully Machine Learning-based tomography from pre-stack data, which
when achieved will reduce the VMB turnaround from weeks to days.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07834</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07834</id><created>2019-08-19</created><authors><author><keyname>Singam</keyname><forenames>Caitlyn A. K.</forenames></author></authors><title>Implementation of a Low-Cost Flight Tracking System for High-Altitude
  Ballooning</title><categories>eess.SP cs.SY eess.SY</categories><comments>12 pages, 6 figures</comments><doi>10.2514/1.I010679</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High altitude balloons (HABs) are typically tracked via GPS data sent via
real-time radio-based communication systems such as the Automated Packet
Reporting System (APRS). Prefabricated APRS-compatible tracker modules have
made it trivial to transmit GPS coordinates and payload parameters in
compliance with the requisite AX.25 protocol. However, in order to receive and
track APRS signals, conventional methodologies call for the use of a Very High
Frequency (VHF) receiver to demodulate signals transmitted on the 440/144 MHz
APRS frequencies, along with a compatible antenna and custom methodology for
visualizing the HAB's location on a map. The entire assembly is typically
costly, cumbersome, and may require an internet connection in order to obtain
real-time visualization of the HAB's location. This paper describes a low-cost,
handheld system based on open-source software that operates independently of an
internet connection. The miniaturized system is suited to tracking done either
from a vehicle or on foot, and is cost-effective enough to be within the means
of nearly any HAB user. The paper also discusses preliminary test results and
further applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07841</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07841</id><created>2019-08-20</created><authors><author><keyname>Soler</keyname><forenames>Maxime</forenames></author><author><keyname>Petitfrere</keyname><forenames>Martin</forenames></author><author><keyname>Darche</keyname><forenames>Gilles</forenames></author><author><keyname>Plainchault</keyname><forenames>Melanie</forenames></author><author><keyname>Conche</keyname><forenames>Bruno</forenames></author><author><keyname>Tierny</keyname><forenames>Julien</forenames></author></authors><title>Ranking Viscous Finger Simulations to an Acquired Ground Truth with
  Topology-aware Matchings</title><categories>physics.geo-ph cs.CG cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This application paper presents a novel framework based on topological data
analysis for the automatic evaluation and ranking of viscous finger simulation
runs in an ensemble with respect to a reference acquisition. Individual fingers
in a given time-step are associated with critical point pairs in the distance
field to the injection point, forming persistence diagrams. Different metrics,
based on optimal transport, for comparing time-varying persistence diagrams in
this specific applicative case are introduced. We evaluate the relevance of the
rankings obtained with these metrics, both qualitatively thanks to a
lightweight web visual interface, and quantitatively by studying the deviation
from a reference ranking suggested by experts. Extensive experiments show the
quantitative superiority of our approach compared to traditional alternatives.
Our web interface allows experts to conveniently explore the produced rankings.
We show a complete viscous fingering case study demonstrating the utility of
our approach in the context of porous media fluid flow, where our framework can
be used to automatically discard physically-irrelevant simulation runs from the
ensemble and rank the most plausible ones. We document an in-situ
implementation to lighten I/O and performance constraints arising in the
context of parametric studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07849</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07849</id><created>2019-08-19</created><authors><author><keyname>Alfarraj</keyname><forenames>Motaz</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Semi-supervised Sequence Modeling for Elastic Impedance Inversion</title><categories>physics.geo-ph cs.LG eess.SP stat.ML</categories><comments>A manuscript in Interpretation. arXiv admin note: text overlap with
  arXiv:1905.13412</comments><doi>10.1190/INT-2018-0250.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent applications of machine learning algorithms in the seismic domain have
shown great potential in different areas such as seismic inversion and
interpretation. However, such algorithms rarely enforce geophysical constraints
- the lack of which might lead to undesirable results. To overcome this issue,
we have developed a semi-supervised sequence modeling framework based on
recurrent neural networks for elastic impedance inversion from multi-angle
seismic data. Specifically, seismic traces and elastic impedance (EI) traces
are modeled as a time series. Then, a neural-network-based inversion model
comprising convolutional and recurrent neural layers is used to invert seismic
data for EI. The proposed workflow uses well-log data to guide the inversion.
In addition, it uses seismic forward modeling to regularize the training and to
serve as a geophysical constraint for the inversion. The proposed workflow
achieves an average correlation of 98% between the estimated and target EI
using 10 well logs for training on a synthetic data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07885</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07885</id><created>2019-08-21</created><authors><author><keyname>Meng</keyname><forenames>Qingjie</forenames></author><author><keyname>Pawlowski</keyname><forenames>Nick</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author><author><keyname>Kainz</keyname><forenames>Bernhard</forenames></author></authors><title>Representation Disentanglement for Multi-task Learning with application
  to Fetal Ultrasound</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the biggest challenges for deep learning algorithms in medical image
analysis is the indiscriminate mixing of image properties, e.g. artifacts and
anatomy. These entangled image properties lead to a semantically redundant
feature encoding for the relevant task and thus lead to poor generalization of
deep learning algorithms. In this paper we propose a novel representation
disentanglement method to extract semantically meaningful and generalizable
features for different tasks within a multi-task learning framework. Deep
neural networks are utilized to ensure that the encoded features are maximally
informative with respect to relevant tasks, while an adversarial regularization
encourages these features to be disentangled and minimally informative about
irrelevant tasks. We aim to use the disentangled representations to generalize
the applicability of deep neural networks. We demonstrate the advantages of the
proposed method on synthetic data as well as fetal ultrasound images. Our
experiments illustrate that our method is capable of learning disentangled
internal representations. It outperforms baseline methods in multiple tasks,
especially on images with new properties, e.g. previously unseen artifacts in
fetal ultrasound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07902</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07902</id><created>2019-08-21</created><authors><author><keyname>Wei</keyname><forenames>Renjie</forenames></author><author><keyname>Ma</keyname><forenames>Kang</forenames></author></authors><title>Energy Management of Airport Service Electric Vehicles to Match
  Renewable Generation through Rollout Approach</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional diesel-based airport service vehicles are characterized by a
heavy-duty, high-usage-frequency nature and a high carbon intensity per vehicle
per hour. Transforming these vehicles into electric vehicles would reduce CO2
emissions and potentially save energy costs in the context of rising fuel
prices, if a proper energy management of airport service electric vehicles
(ASEVs) is performed. To perform such an energy management, this paper proposes
a new customized rollout approach, as a near-optimal control method for a new
ASEV dynamics model, which models the ASEV states, their transitions over time,
and how control decisions affect them. The rollout approach yields a
near-optimal control strategy for the ASEVs to transport luggage and to charge
batteries, with the objective to minimize the operation cost, which
incentivizes the charging of the ASEVs to match renewable generation. Case
studies demonstrate that the rollout approach effectively overcomes the &quot;curse
of dimensionality&quot;. On both typical summer and winter days, the rollout
algorithm results in a total cost approximately 10% less than that of the
underlying &quot;greedy charging&quot; heuristic, which charges a battery whenever its
state of charge is not the maximum. The rollout algorithm is proven to be
adaptive towards flight schedule changes at short notice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07926</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07926</id><created>2019-08-21</created><authors><author><keyname>Tang</keyname><forenames>Yuxing</forenames></author><author><keyname>Tang</keyname><forenames>Youbao</forenames></author><author><keyname>Sandfort</keyname><forenames>Veit</forenames></author><author><keyname>Xiao</keyname><forenames>Jing</forenames></author><author><keyname>Summers</keyname><forenames>Ronald M.</forenames></author></authors><title>TUNA-Net: Task-oriented UNsupervised Adversarial Network for Disease
  Recognition in Cross-Domain Chest X-rays</title><categories>eess.IV cs.CV</categories><comments>MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we exploit the unsupervised domain adaptation problem for
radiology image interpretation across domains. Specifically, we study how to
adapt the disease recognition model from a labeled source domain to an
unlabeled target domain, so as to reduce the effort of labeling each new
dataset. To address the shortcoming of cross-domain, unpaired image-to-image
translation methods which typically ignore class-specific semantics, we propose
a task-driven, discriminatively trained, cycle-consistent generative
adversarial network, termed TUNA-Net. It is able to preserve 1) low-level
details, 2) high-level semantic information and 3) mid-level feature
representation during the image-to-image translation process, to favor the
target disease recognition task. The TUNA-Net framework is general and can be
readily adapted to other learning tasks. We evaluate the proposed framework on
two public chest X-ray datasets for pneumonia recognition. The TUNA-Net model
can adapt labeled adult chest X-rays in the source domain such that they appear
as if they were drawn from pediatric X-rays in the unlabeled target domain,
while preserving the disease semantics. Extensive experiments show the
superiority of the proposed method as compared to state-of-the-art unsupervised
domain adaptation approaches. Notably, TUNA-Net achieves an AUC of 96.3% for
pediatric pneumonia classification, which is very close to that of the
supervised approach (98.1%), but without the need for labels on the target
domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07933</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07933</id><created>2019-08-06</created><authors><author><keyname>Bastos</keyname><forenames>Felipe Henrique Bastos e</forenames></author><author><keyname>Nascimento</keyname><forenames>Ingrid</forenames></author><author><keyname>J&#xfa;nior</keyname><forenames>Aldebaro Barreto da Rocha Klautau</forenames></author></authors><title>Ambiente de Simula\c{c}\~oes Utilizando Tra\c{c}ado de Raios com Ondas
  Milim\'etricas e MIMO Para VANTs</title><categories>eess.SP</categories><comments>2 pages, in Portuguese, XXXVI Simposio Brasilero De
  Telecomunica\c{C}\~OES E Processamento De Sinais - SBrT2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of UAVs tends to increase in the coming years, it is of great
importance to study forms of communication with these aerial models. This paper
presents a simulations environment that combines simulators of traffic, flight
and ray tracing, to generates a large amounts of propagation data between
terrestrial transmitters and aerial vehicles in 5G networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07934</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07934</id><created>2019-08-04</created><updated>2019-08-22</updated><authors><author><keyname>Li</keyname><forenames>Xiangyi</forenames></author><author><keyname>Wu</keyname><forenames>Huaming</forenames></author></authors><title>Spatio-Temporal Representation with Deep Neural Recurrent Network in
  MIMO CSI Feedback</title><categories>eess.SP cs.LG</categories><comments>5pages, 6figures, 14conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multiple-input multiple-output (MIMO) systems, it is crucial of utilizing
the available channel state information (CSI) at the transmitter for precoding
to improve the performance of frequency division duplex (FDD) networks. One of
the mainchallenges is to compress a large amount of CSI in CSI feedback
transmission in massive MIMO systems. In this paper, we propose a deep learning
(DL)-based approach that uses a deep recurrent neural network (RNN) to learn
temporal correlation and adopts depthwise separable convolution to shrink the
model. The feature extraction module is also elaborately devised by
studyingdecoupled spatio-temporal feature representations in different
structures. Experimental results demonstrate that the proposed approach
outperforms existing DL-based methods in terms of recovery quality and
accuracy, which can also achieve remarkable robustness at low compression ratio
(CR).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07942</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07942</id><created>2019-08-12</created><authors><author><keyname>Yoon</keyname><forenames>Insik</forenames></author><author><keyname>Jerry</keyname><forenames>Matthew</forenames></author><author><keyname>Datta</keyname><forenames>Suman</forenames></author><author><keyname>Raychowdhury</keyname><forenames>Arijit</forenames></author></authors><title>Design space exploration of Ferroelectric FET based Processing-in-Memory
  DNN Accelerator</title><categories>cs.ET cs.NE eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we quantify the impact of device limitations on the
classification accuracy of an artificial neural network, where the synaptic
weights are implemented in a Ferroelectric FET (FeFET) based in-memory
processing architecture. We explore a design-space consisting of the resolution
of the analog-to-digital converter, number of bits per FeFET cell, and the
neural network depth. We show how the system architecture, training models and
overparametrization can address some of the device limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07951</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07951</id><created>2019-08-18</created><updated>2019-10-08</updated><authors><author><keyname>Lee</keyname><forenames>Vincent</forenames></author><author><keyname>OBrien</keyname><forenames>Dominic</forenames></author></authors><title>Secure practical indoor optical wireless communications using quantum
  key distribution</title><categories>eess.SP cs.NI</categories><comments>12 pages, 13 figures</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Quantum Key Distribution (QKD) can guarantee security for practical indoor
optical wireless environments. The key challenges are to mitigate artificial
lighting and ambient light at the receiver. A new spectral region for QKD is
proposed and an ideal QKD link model is simulated with experimental ambient
light power measurements. Simulation, modelling, and analysis indicates that
the carbon dioxide and water absorption band (1370 nm) is a new wavelength
region for QKD operation in indoor optical wireless environments. For a
feasible QKD link, approximately 20 dB of signal to noise ratio (SNR) is
required and a maximum quantum bit error rate (QBER) of 11% when using the BB84
protocol. Links in the new spectral region with a FOV of several degrees are
feasible, depending on available components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07952</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07952</id><created>2019-08-19</created><authors><author><keyname>Baena</keyname><forenames>A.</forenames></author><author><keyname>Londo&#xf1;o</keyname><forenames>H.</forenames></author><author><keyname>Enciso</keyname><forenames>G.</forenames></author><author><keyname>Toresan</keyname><forenames>W.</forenames></author><author><keyname>Remolina</keyname><forenames>E.</forenames></author></authors><title>Comparative analysis of methods to estimate the tire/road friction
  coefficient applied to traffic accident reconstruction</title><categories>eess.SP physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The measure of the friction factor in the location of the event is very
important to get accurate inputs to model the accident, as the friction factor
depends on environmental conditions and the dynamics of the event. In some
low-middle income countries, accident reconstruction experts, usually don't
have the feasibility to acquire expensive equipment as high precision
accelerometers; therefore, it is important to identify a low-cost method that
provides data quality comparable with high precision equipment. This study
presents a comparison of three methods: VC4000PC accelerometer, sensor kinetics
mobile app and video analysis by tracker (free software). The methods have been
compared experimentally for emergency braking with blocked wheel, as well as
using ABS. Data from the three methods were recorded simultaneously. Data
analysis was made applying inferential statistics. The results indicate that
the data collected with the smartphone app ensure good accuracy and does not
provide significant variance in comparison with the accelerometer. On the other
hand, the data obtained by video analysis shows a good linear relationship with
the accelerometer; however, it shows some statistical evidence of differences
related to precision and variances in comparison with accelerometer device. The
confidence interval, absolute error, and other estimators have been obtained
for the smartphone method, to promote the optimal using by the experts to get
parameters on site and apply to a traffic accident reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07957</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07957</id><created>2019-08-21</created><updated>2020-01-10</updated><authors><author><keyname>Kirschbaum</keyname><forenames>Elke</forenames></author><author><keyname>Bailoni</keyname><forenames>Alberto</forenames></author><author><keyname>Hamprecht</keyname><forenames>Fred A.</forenames></author></authors><title>DISCo: Deep learning, Instance Segmentation, and Correlations for cell
  segmentation in calcium imaging videos</title><categories>q-bio.NC cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Calcium imaging is one of the most important tools in neurophysiology as it
enables the observation of neuronal activity for hundreds of cells in parallel
and at single-cell resolution. In order to use the data gained with calcium
imaging, it is necessary to extract individual cells and their activity from
the recordings. We present DISCo, a novel approach for the cell segmentation in
calcium imaging videos. We use temporal information from the recordings in a
computationally efficient way by computing correlations between pixels and
combine it with shape-based information to identify active as well as
non-active cells. We first learn to predict whether two pixels belong to the
same cell; this information is summarized in an undirected, edge-weighted grid
graph which we then partition. In so doing, we approximately solve the NP-hard
correlation clustering problem with a recently proposed greedy algorithm.
Evaluating our method on the Neurofinder public benchmark shows that DISCo
outperforms all existing models trained on these datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07964</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07964</id><created>2019-08-21</created><authors><author><keyname>Tucker</keyname><forenames>Nathaniel</forenames></author><author><keyname>Moradipari</keyname><forenames>Ahmadreza</forenames></author><author><keyname>Alizadeh</keyname><forenames>Mahnoosh</forenames></author></authors><title>Constrained Thompson Sampling for Real-Time Electricity Pricing with
  Grid Reliability Constraints</title><categories>eess.SY cs.SY</categories><comments>10 pages, 6 figures, Preprint</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We consider the problem of an aggregator attempting to learn customers' load
flexibility models while implementing a load shaping program by means of
broadcasting daily dispatch signals. We adopt a multi-armed bandit formulation
to account for the stochastic and unknown nature of customers' responses to
dispatch signals. We propose a constrained Thompson sampling heuristic,
Con-TS-RTP, that accounts for various possible aggregator objectives (e.g., to
reduce demand at peak hours, integrate more intermittent renewable generation,
track a desired daily load profile, etc) and takes into account the operational
constraints of a distribution system to avoid potential grid failures as a
result of uncertainty in the customers' response. We provide a discussion on
the regret bounds for our algorithm as well as a discussion on the operational
reliability of the distribution system's constraints being upheld throughout
the learning process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07967</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07967</id><created>2019-08-21</created><updated>2019-08-31</updated><authors><author><keyname>Ntontin</keyname><forenames>K.</forenames></author><author><keyname>Song</keyname><forenames>J.</forenames></author><author><keyname>Di Renzo</keyname><forenames>M.</forenames></author></authors><title>Multi-Antenna Relaying and Reconfigurable Intelligent Surfaces:
  End-to-End SNR and Achievable Rate</title><categories>eess.SP cs.IT math.IT</categories><comments>unpublished report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, we summarize the end-to-end signal-to-noise ratio and the
rate of half-duplex, full-duplex, amplify-and-forward, and decode-and-forward
relay-aided communications, and well as the signal-to-noise ratio and the rate
of the emerging technology known as reconfigurable intelligent surfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07996</identifier>
 <datestamp>2019-12-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.07996</id><created>2019-08-19</created><updated>2019-12-08</updated><authors><author><keyname>Scholl</keyname><forenames>Tessina H.</forenames></author><author><keyname>Gr&#xf6;ll</keyname><forenames>Lutz</forenames></author><author><keyname>Hagenmeyer</keyname><forenames>Veit</forenames></author></authors><title>Time Delay in the Swing Equation: A Variety of Bifurcations</title><categories>math.DS cs.SY eess.SY</categories><comments>12 pages, 6 figures, &quot;The following article has been accepted by
  'Chaos: An Interdisciplinary Journal of Nonlinear Science'. After it is
  published, it will be found at https://aip.scitation.org/journal/cha.&quot;</comments><doi>10.1063/1.5122784</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper addresses the swing equation with additional delayed
damping as an example for pendulum-like systems. In this context, it is proved
that recurring sub- and supercritical Hopf bifurcations occur if time delay is
increased. To this end, a general formula for the first Lyapunov coefficient in
second order systems with additional delayed damping and delay-free
nonlinearity is given. In so far the paper extends results about stability
switching of equilibria in linear time delay systems from Cooke and Grossman.
In addition to the analytical results, periodic solutions are numerically dealt
with. The numerical results demonstrate how a variety of qualitative behaviors
is generated in the simple swing equation by only introducing time delay in a
damping term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08004</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08004</id><created>2019-08-21</created><authors><author><keyname>Dang</keyname><forenames>Yaman</forenames></author><author><keyname>Anand</keyname><forenames>Deepak</forenames></author><author><keyname>Sethi</keyname><forenames>Amit</forenames></author></authors><title>Pixel-wise Segmentation of Right Ventricle of Heart</title><categories>eess.IV cs.CV</categories><comments>Accepted at IEEE TENCON 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  One of the first steps in the diagnosis of most cardiac diseases, such as
pulmonary hypertension, coronary heart disease is the segmentation of
ventricles from cardiac magnetic resonance (MRI) images. Manual segmentation of
the right ventricle requires diligence and time, while its automated
segmentation is challenging due to shape variations and illdefined borders. We
propose a deep learning based method for the accurate segmentation of right
ventricle, which does not require post-processing and yet it achieves the
state-of-the-art performance of 0.86 Dice coefficient and 6.73 mm Hausdorff
distance on RVSC-MICCAI 2012 dataset. We use a novel adaptive cost function to
counter extreme class-imbalance in the dataset. We present a comprehensive
comparative study of loss functions, architectures, and ensembling techniques
to build a principled approach for biomedical segmentation tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08035</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08035</id><created>2019-08-20</created><authors><author><keyname>Fu</keyname><forenames>Yunguan</forenames></author><author><keyname>Robu</keyname><forenames>Maria R.</forenames></author><author><keyname>Koo</keyname><forenames>Bongjin</forenames></author><author><keyname>Schneider</keyname><forenames>Crispin</forenames></author><author><keyname>van Laarhoven</keyname><forenames>Stijn</forenames></author><author><keyname>Stoyanov</keyname><forenames>Danail</forenames></author><author><keyname>Davidson</keyname><forenames>Brian</forenames></author><author><keyname>Clarkson</keyname><forenames>Matthew J.</forenames></author><author><keyname>Hu</keyname><forenames>Yipeng</forenames></author></authors><title>More unlabelled data or label more data? A study on semi-supervised
  laparoscopic image segmentation</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Accepted to MICCAI MIL3ID 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Improving a semi-supervised image segmentation task has the option of adding
more unlabelled images, labelling the unlabelled images or combining both, as
neither image acquisition nor expert labelling can be considered trivial in
most clinical applications. With a laparoscopic liver image segmentation
application, we investigate the performance impact by altering the quantities
of labelled and unlabelled training data, using a semi-supervised segmentation
algorithm based on the mean teacher learning paradigm. We first report a
significantly higher segmentation accuracy, compared with supervised learning.
Interestingly, this comparison reveals that the training strategy adopted in
the semi-supervised algorithm is also responsible for this observed
improvement, in addition to the added unlabelled data. We then compare
different combinations of labelled and unlabelled data set sizes for training
semi-supervised segmentation networks, to provide a quantitative example of the
practically useful trade-off between the two data planning strategies in this
surgical guidance application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08044</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08044</id><created>2019-08-21</created><authors><author><keyname>Yao</keyname><forenames>Jian</forenames></author><author><keyname>Al-Dahle</keyname><forenames>Ahmad</forenames></author></authors><title>Coarse-to-fine Optimization for Speech Enhancement</title><categories>cs.SD cs.LG eess.AS</categories><journal-ref>Interspeech 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose the coarse-to-fine optimization for the task of
speech enhancement. Cosine similarity loss [1] has proven to be an effective
metric to measure similarity of speech signals. However, due to the large
variance of the enhanced speech with even the same cosine similarity loss in
high dimensional space, a deep neural network learnt with this loss might not
be able to predict enhanced speech with good quality. Our coarse-to-fine
strategy optimizes the cosine similarity loss for different granularities so
that more constraints are added to the prediction from high dimension to
relatively low dimension. In this way, the enhanced speech will better resemble
the clean speech. Experimental results show the effectiveness of our proposed
coarse-to-fine optimization in both discriminative models and generative
models. Moreover, we apply the coarse-to-fine strategy to the adversarial loss
in generative adversarial network (GAN) and propose dynamic perceptual loss,
which dynamically computes the adversarial loss from coarse resolution to fine
resolution. Dynamic perceptual loss further improves the accuracy and achieves
state-of-the-art results compared with other generative models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08071</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08071</id><created>2019-08-21</created><updated>2019-09-10</updated><authors><author><keyname>Hatamizadeh</keyname><forenames>Ali</forenames></author><author><keyname>Terzopoulos</keyname><forenames>Demetri</forenames></author><author><keyname>Myronenko</keyname><forenames>Andriy</forenames></author></authors><title>End-to-End Boundary Aware Networks for Medical Image Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted to MICCAI Machine Learning in Medical Imaging (MLMI 2019)</comments><journal-ref>MLMI 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fully convolutional neural networks (CNNs) have proven to be effective at
representing and classifying textural information, thus transforming image
intensity into output class masks that achieve semantic image segmentation. In
medical image analysis, however, expert manual segmentation often relies on the
boundaries of anatomical structures of interest. We propose boundary aware CNNs
for medical image segmentation. Our networks are designed to account for organ
boundary information, both by providing a special network edge branch and
edge-aware loss terms, and they are trainable end-to-end. We validate their
effectiveness on the task of brain tumor segmentation using the BraTS 2018
dataset. Our experiments reveal that our approach yields more accurate
segmentation results, which makes it promising for more extensive application
to medical image segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08074</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08074</id><created>2019-08-21</created><authors><author><keyname>Sun</keyname><forenames>Haoliang</forenames></author><author><keyname>Mehta</keyname><forenames>Ronak</forenames></author><author><keyname>Zhou</keyname><forenames>Hao H.</forenames></author><author><keyname>Huang</keyname><forenames>Zhichun</forenames></author><author><keyname>Johnson</keyname><forenames>Sterling C.</forenames></author><author><keyname>Prabhakaran</keyname><forenames>Vivek</forenames></author><author><keyname>Singh</keyname><forenames>Vikas</forenames></author></authors><title>DUAL-GLOW: Conditional Flow-Based Generative Model for Modality Transfer</title><categories>eess.IV cs.CV</categories><journal-ref>ICCV 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Positron emission tomography (PET) imaging is an imaging modality for
diagnosing a number of neurological diseases. In contrast to Magnetic Resonance
Imaging (MRI), PET is costly and involves injecting a radioactive substance
into the patient. Motivated by developments in modality transfer in vision, we
study the generation of certain types of PET images from MRI data. We derive
new flow-based generative models which we show perform well in this small
sample size regime (much smaller than dataset sizes available in standard
vision tasks). Our formulation, DUAL-GLOW, is based on two invertible networks
and a relation network that maps the latent spaces to each other. We discuss
how given the prior distribution, learning the conditional distribution of PET
given the MRI image reduces to obtaining the conditional distribution between
the two latent codes w.r.t. the two image types. We also extend our framework
to leverage 'side' information (or attributes) when available. By controlling
the PET generation through 'conditioning' on age, our model is also able to
capture brain FDG-PET (hypometabolism) changes, as a function of age. We
present experiments on the Alzheimers Disease Neuroimaging Initiative (ADNI)
dataset with 826 subjects, and obtain good performance in PET image synthesis,
qualitatively and quantitatively better than recent works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08098</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08098</id><created>2019-08-21</created><authors><author><keyname>Yang</keyname><forenames>Zhixiong</forenames></author><author><keyname>Bajwa</keyname><forenames>Waheed U.</forenames></author></authors><title>BRIDGE: Byzantine-resilient Decentralized Gradient Descent</title><categories>stat.ML cs.DC cs.LG cs.MA eess.SP</categories><comments>18 pages, 1 figure, 1 table; preprint of a conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decentralized optimization techniques are increasingly being used to learn
machine learning models from data distributed over multiple locations without
gathering the data at any one location. Unfortunately, methods that are
designed for faultless networks typically fail in the presence of node
failures. In particular, Byzantine failures---corresponding to the scenario in
which faulty/compromised nodes are allowed to arbitrarily deviate from an
agreed-upon protocol---are the hardest to safeguard against in decentralized
settings. This paper introduces a Byzantine-resilient decentralized gradient
descent (BRIDGE) method for decentralized learning that, when compared to
existing works, is more efficient and scalable in higher-dimensional settings
and that is deployable in networks having topologies that go beyond the star
topology. The main contributions of this work include theoretical analysis of
BRIDGE for strongly convex learning objectives and numerical experiments
demonstrating the efficacy of BRIDGE for both convex and nonconvex learning
tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08099</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08099</id><created>2019-08-21</created><authors><author><keyname>Enz</keyname><forenames>Christian</forenames></author><author><keyname>Caizzone</keyname><forenames>Antonino</forenames></author><author><keyname>Boukhayma</keyname><forenames>Assim</forenames></author><author><keyname>Krummenacher</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Simple Thermal Noise Estimation of Switched Capacitor Circuits Based on
  OTAs -- Part I: Amplifiers with Capacitive Feedback</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a simple method for estimating the thermal noise voltage
variance in passive and active switched-capacitor (SC) circuits using
operational transconductance amplifiers (OTA). The proposed method is based on
the Bode theorem for passive network which is extended to active circuits based
on OTAs with capacitive feedback. It allows for a precise estimation of the
thermal noise voltage variance by simple inspection of three equivalent
circuits avoiding the calculation of any transfer functions nor integrals. In
this Part I, the method is applied to SC amplifiers and track&amp;hold circuits and
successfully validated by means of transient noise simulations. Part II extends
the application of the method to integrators and active SC filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08109</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08109</id><created>2019-08-21</created><authors><author><keyname>Enz</keyname><forenames>Christian</forenames></author><author><keyname>Rengifo</keyname><forenames>Sammy Cerida</forenames></author><author><keyname>Boukhayma</keyname><forenames>Assim</forenames></author><author><keyname>Krummenacher</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Simple Thermal Noise Estimation of Switched Capacitor Circuits Based on
  OTAs -- Part II: SC Filters</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Part I of this paper, we have shown how to calculate the thermal noise
voltage variances in switched-capacitor (SC) circuits using operational
transconductance amplifiers (OTAs) with capacitive feedback by using the
extended Bode theorem. The method allows a precise estimation of the thermal
noise voltage variances by simple circuit inspection without the calculation of
any transfer functions nor integrals. While Part I focuses on SC amplifiers and
track&amp;hold circuits, Part II shows how to use the extended Bode theorem for SC
filters. It validates the method on the basic integrator and then on a
first-order low-pass filter by comparing the analytical results to transient
noise simulations showing an excellent match.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08124</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08124</id><created>2019-08-21</created><updated>2019-09-22</updated><authors><author><keyname>Gilman</keyname><forenames>Mikhail</forenames></author><author><keyname>Tsynkov</keyname><forenames>Semyon</forenames></author></authors><title>Statistical characterization of scattering delay in synthetic aperture
  radar imaging</title><categories>eess.IV</categories><comments>31 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distinguishing between the instantaneous and delayed scatterers in synthetic
aperture radar (SAR) images is important for target identification and
characterization. To perform this task, one can use the autocorrelation
analysis of coordinate-delay images. However, due to the range-delay ambiguity
the difference in the correlation properties between the instantaneous and
delayed targets may be small. Moreover, the reliability of discrimination is
affected by speckle, which is ubiquitous in SAR images, and requires
statistical treatment.
  Previously, we have developed a maximum likelihood based approach for
discriminating between the instantaneous and delayed targets in SAR images. To
test it, we employed simple statistical models. They allowed us to simulate
ensembles of images that depend on various parameters, including aperture width
and target contrast.
  In the current paper, we enhance our previously developed methodology by
establishing confidence levels for the discrimination between the instantaneous
and delayed scatterers. Our procedure takes into account the difference in
thresholds for different target contrasts without making any assumptions about
the statistics of those contrasts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08130</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08130</id><created>2019-08-21</created><authors><author><keyname>Sayeed</keyname><forenames>Md Abu</forenames></author><author><keyname>Mohanty</keyname><forenames>Saraju P.</forenames></author><author><keyname>Kougianos</keyname><forenames>Elias</forenames></author></authors><title>cSeiz: An Edge-Device for Accurate Seizure Detection and Control for
  Smart Healthcare</title><categories>eess.SP cs.SY eess.SY</categories><comments>24 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Epilepsy is one of the most common neurological disorders affecting up to 1%
of the world's population and approximately 2.5 million people in the United
States. Seizures in more than 30% of epilepsy patients are refractory to
anti-epileptic drugs. An important biomedical research effort is focused on the
development of an energy efficient implantable device for the real-time control
of seizures. In this paper we propose an Internet of Medical Things (IoMT)
based automated seizure detection and drug delivery system (DDS) for the
control of seizures. The proposed system will detect seizures and inject a fast
acting anti-convulsant drug at the onset to suppress seizure progression. The
drug injection is performed in two stages. Initially, the seizure detector
detects the seizure from the electroencephalography (EEG) signal using a
hyper-synchronous signal detection circuit and a signal rejection algorithm
(SRA). In the second stage, the drug is released in the seizure onset area upon
seizure detection. The design was validated using a system-level simulation and
consumer electronics proof of concept. The proposed seizure detector reports a
sensitivity of 96.9% and specificity of 97.5%. The use of minimal circuitry
leads to a considerable reduction of power consumption compared to previous
approaches. The proposed approach can be generalized to other sensor modalities
and the use of both wearable and implantable solutions, or a combination of the
two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08160</identifier>
 <datestamp>2019-11-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08160</id><created>2019-08-21</created><updated>2019-11-07</updated><authors><author><keyname>Sun</keyname><forenames>Xuecong</forenames></author><author><keyname>Jia</keyname><forenames>Han</forenames></author><author><keyname>Zhang</keyname><forenames>Zhe</forenames></author><author><keyname>Yang</keyname><forenames>Yuzhen</forenames></author><author><keyname>Sun</keyname><forenames>Zhaoyong</forenames></author><author><keyname>Yang</keyname><forenames>Jun</forenames></author></authors><title>Sound Localization and Separation in Three-dimensional Space Using a
  Single Microphone with a Metamaterial Enclosure</title><categories>cs.SD eess.AS physics.app-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional approaches to sound localization and separation are based on
microphone arrays in artificial systems. Inspired by the selective perception
of human auditory system, we design a multi-source listening system which can
separate simultaneous overlapping sounds and localize the sound sources in
three-dimensional space, using only a single microphone with a metamaterial
enclosure. The enclosure modifies the frequency response of the microphone in a
direction-dependent way by giving each direction a signature. Thus, the
information about the location and audio content of sound sources can be
experimentally reconstructed from the modulated mixed signals using compressive
sensing algorithm. Owing to the low computational complexity of the proposed
reconstruction algorithm, the designed system can also be applied in source
identification and tracking. The effectiveness of the system in multiple real
scenarios has been proved through multiple random listening tests. The proposed
metamaterial-based single-sensor listening system opens a new way of sound
localization and separation, which can be applied to intelligent scene
monitoring and robot audition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08164</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08164</id><created>2019-08-21</created><authors><author><keyname>Bi</keyname><forenames>Qi</forenames></author><author><keyname>Qin</keyname><forenames>Kun</forenames></author><author><keyname>Zhang</keyname><forenames>Han</forenames></author><author><keyname>Han</keyname><forenames>Wenjun</forenames></author><author><keyname>Li</keyname><forenames>Zhili</forenames></author><author><keyname>Xu</keyname><forenames>Kai</forenames></author></authors><title>Building change detection based on multi-scale filtering and grid
  partition</title><categories>eess.IV cs.CV</categories><comments>8 pages, 6 figures, conference paper</comments><journal-ref>10th IAPR Workshop on Pattern Recognition in Remote Sensing
  (PRRS),2018,1-6</journal-ref><doi>10.1109/PRRS.2018.8486194</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Building change detection is of great significance in high resolution remote
sensing applications. Multi-index learning, one of the state-of-the-art
building change detection methods, still has drawbacks like incapability to
find change types directly and heavy computation consumption of MBI. In this
paper, a two-stage building change detection method is proposed to address
these problems. In the first stage, a multi-scale filtering building index
(MFBI) is calculated to detect building areas in each temporal with fast speed
and moderate accuracy. In the second stage, images and the corresponding
building maps are partitioned into grids. In each grid, the ratio of building
areas in time T2 and time T1 is calculated. Each grid is classified into one of
the three change patterns, i.e., significantly increase, significantly decrease
and approximately unchanged. Exhaustive experiments indicate that the proposed
method can detect building change types directly and outperform the current
multi-index learning method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08165</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08165</id><created>2019-08-21</created><authors><author><keyname>Guan</keyname><forenames>Sihai</forenames></author><author><keyname>Meng</keyname><forenames>Chun</forenames></author><author><keyname>Biswal</keyname><forenames>Bharat</forenames></author></authors><title>Optimal step-size of least mean absolute fourth algorithm in low SNR</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a need to improve the capability of the adaptive filtering algorithm
against Gaussian or multiple types of non-Gaussian noises, time-varying system,
and systems with low SNR. In this paper, we propose an optimized least mean
absolute fourth (OPLMF) algorithm, especially for a time-varying unknown system
with low signal-noise-rate (SNR). The optimal step-size of OPLMF is obtained by
minimizing the mean-square deviation (MSD) at any given moment in time. In
addition, the mean convergence and steady-state error of OPLMF are derived.
Also the theoretical computational complexity of OPLMF is analyzed.
Furthermore, the simulation experiment results of system identification are
used to illustrate the principle and efficiency of the OPLMF algorithm. The
performance of the algorithm is analyzed mathematically and validated
experimentally. Simulation results demonstrate that the proposed OPLMF is
superior to the normalized LMF (NLMF) and variable step-size of LMF using
quotient form (VSSLMFQ) algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08176</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08176</id><created>2019-08-21</created><updated>2019-10-15</updated><authors><author><keyname>Zhou</keyname><forenames>Yuren</forenames></author><author><keyname>Lork</keyname><forenames>Clement</forenames></author><author><keyname>Li</keyname><forenames>Wen-Tai</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Keow</keyname><forenames>Yeong Ming</forenames></author></authors><title>Benchmarking air-conditioning energy performance of residential rooms
  based on regression and clustering techniques</title><categories>eess.SY cs.LG cs.SY</categories><comments>38 pages (single column), 7 figures, 6 tables. This manuscript is
  accepted for publication in Applied Energy 253 (2019): 113548. Please refer
  to the published version at
  https://www.sciencedirect.com/science/article/pii/S030626191931222X</comments><journal-ref>Applied Energy 253 (2019): 113548</journal-ref><doi>10.1016/j.apenergy.2019.113548</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Air conditioning (AC) accounts for a critical portion of the global energy
consumption. To improve its energy performance, it is important to fairly
benchmark its energy performance and provide the evaluation feedback to users.
However, this task has not been well tackled in the residential sector. In this
paper, we propose a data-driven approach to fairly benchmark the AC energy
performance of residential rooms. First, regression model is built for each
benchmarked room so that its power consumption can be predicted given different
weather conditions and AC settings. Then, all the rooms are clustered based on
their areas and usual AC temperature set points. Lastly, within each cluster,
rooms are benchmarked based on their predicted power consumption under uniform
weather conditions and AC settings. A real-world case study was conducted with
data collected from 44 residential rooms. Results show that the constructed
regression models have an average prediction accuracy of 85.1% in
cross-validation tests, and support vector regression with Gaussian kernel is
the overall most suitable model structure for building the regression model. In
the clustering step, 44 rooms are successfully clustered into seven clusters.
By comparing the benchmarking scores generated by the proposed approach with
two sets of scores computed from historical power consumption data, we
demonstrate that the proposed approach is able to eliminate the influences of
room areas, weather conditions, and AC settings on the benchmarking results.
Therefore, the proposed benchmarking approach is valid and fair. As a
by-product, the approach is also shown to be useful to investigate how room
areas, weather conditions, and AC settings affect the AC power consumption of
rooms in real life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08180</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08180</id><created>2019-08-21</created><authors><author><keyname>Zheng</keyname><forenames>Xiangtian</forenames></author><author><keyname>Wang</keyname><forenames>Bin</forenames></author><author><keyname>Kalathil</keyname><forenames>Dileep</forenames></author><author><keyname>Xie</keyname><forenames>Le</forenames></author></authors><title>Networked Synthetic Dynamic PMU Data Generation: A Generative
  Adversarial Network Approach</title><categories>eess.SP</categories><comments>This manuscript has been submitted to IEEE Transactions on Power
  Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a machine learning-based approach to synthetically
create multiple phasor measurement unit (PMU) data streams at different buses
in a power system. In contrast to the existing literature of creating synthetic
power grid network and then using simulation software to output synthetic PMU
data, we propose a generative adversarial network (GAN) based approach to
synthesize multiple PMU measurement streams directly from historical data. The
proposed method can simultaneously create multiple PMU measurement streams that
reflect practically meaningful electromechanical dynamics which observe the
Kirchhoff's laws. We further validate the synthetic data via the statistical
resemblance and the modal analysis. The efficacy of this new approach is
demonstrated by numerical studies on a 39-bus system and a 200-bus system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08185</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08185</id><created>2019-08-21</created><authors><author><keyname>Li</keyname><forenames>Chunyu</forenames></author><author><keyname>Monno</keyname><forenames>Yusuke</forenames></author><author><keyname>Hidaka</keyname><forenames>Hironori</forenames></author><author><keyname>Okutomi</keyname><forenames>Masatoshi</forenames></author></authors><title>Pro-Cam SSfM: Projector-Camera System for Structure and Spectral
  Reflectance from Motion</title><categories>cs.CV cs.GR eess.IV</categories><comments>Accepted by ICCV 2019. Project homepage:
  http://www.ok.sc.e.titech.ac.jp/res/PCSSfM/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel projector-camera system for practical and
low-cost acquisition of a dense object 3D model with the spectral reflectance
property. In our system, we use a standard RGB camera and leverage an
off-the-shelf projector as active illumination for both the 3D reconstruction
and the spectral reflectance estimation. We first reconstruct the 3D points
while estimating the poses of the camera and the projector, which are
alternately moved around the object, by combining multi-view structured light
and structure-from-motion (SfM) techniques. We then exploit the projector for
multispectral imaging and estimate the spectral reflectance of each 3D point
based on a novel spectral reflectance estimation model considering the
geometric relationship between the reconstructed 3D points and the estimated
projector positions. Experimental results on several real objects demonstrate
that our system can precisely acquire a dense 3D model with the full spectral
reflectance property using off-the-shelf devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08187</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08187</id><created>2019-08-21</created><authors><author><keyname>Nunnari</keyname><forenames>Fabrizio</forenames></author><author><keyname>Sonntag</keyname><forenames>Daniel</forenames></author></authors><title>A CNN toolbox for skin cancer classification</title><categories>eess.IV cs.CV cs.LG</categories><comments>DFKI Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a software toolbox for the configuration of deep neural networks
in the domain of skin cancer classification. The implemented software
architecture allows developers to quickly set up new convolutional neural
network (CNN) architectures and hyper-parameter configurations. At the same
time, the user interface, manageable as a simple spreadsheet, allows
non-technical users to explore different configuration settings that need to be
explored when switching to different data sets. In future versions, meta
leaning frameworks can be added, or AutoML systems that continuously improve
over time. Preliminary results, conducted with two CNNs in the context melanoma
detection on dermoscopic images, quantify the impact of image augmentation,
image resolution, and rescaling filter on the overall detection performance and
training time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08193</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08193</id><created>2019-08-22</created><authors><author><keyname>Alasti</keyname><forenames>Hadi</forenames></author></authors><title>Dynamic Weight Importance Sampling for Low Cost Spatiotemporal Sensing</title><categories>eess.SP</categories><comments>5 pages, 6 figures, article</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple and low cost dynamic weight importance sampling (DWIS)
implementation is presented and discussed for spatiotemporal sensing of unknown
correlated signals in sensor field. The spatial signal is compressed into its
contour lines and a partitioned subset of sensors that their observations are
in a given margin of the contour levels, is used for importance sampling. The
selected sensor population is changed dynamically to maintain the low cost and
acceptable spatial signal estimation from limited observations. The estimation
performance, cost and convergence of the proposed approach is evaluated for
spatial and temporal monitoring, using three different contour level definition
schemes. The results show that using DWIS and modeling the spatial signal with
contour lines is low cost. In this study the presence of noise in sensor
observations is ignored. The number of participant sensors is taken as modeling
cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08195</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08195</id><created>2019-08-22</created><authors><author><keyname>Go</keyname><forenames>Chihiro</forenames></author><author><keyname>Kinoshita</keyname><forenames>Yuma</forenames></author><author><keyname>Shiota</keyname><forenames>Sayaka</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>An Image Fusion Scheme for Single-Shot High Dynamic Range Imaging with
  Spatially Varying Exposures</title><categories>eess.IV cs.CV</categories><doi>10.1587/transfun.E102.A.1856</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel multi-exposure image fusion (MEF) scheme for
single-shot high dynamic range imaging with spatially varying exposures (SVE).
Single-shot imaging with SVE enables us not only to produce images without
color saturation regions from a single-shot image, but also to avoid ghost
artifacts in the producing ones. However, the number of exposures is generally
limited to two, and moreover it is difficult to decide the optimum exposure
values before the photographing. In the proposed scheme, a scene segmentation
method is applied to input multi-exposure images, and then the luminance of the
input images is adjusted according to both of the number of scenes and the
relationship between exposure values and pixel values. The proposed method with
the luminance adjustment allows us to improve the above two issues. In this
paper, we focus on dual-ISO imaging as one of single-shot imaging. In an
experiment, the proposed scheme is demonstrated to be effective for single-shot
high dynamic range imaging with SVE, compared with conventional MEF schemes
with exposure compensation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08204</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08204</id><created>2019-08-22</created><authors><author><keyname>Yoo</keyname><forenames>Yong-Ho</forenames></author><author><keyname>Kim</keyname><forenames>Ue-Hwan</forenames></author><author><keyname>Kim</keyname><forenames>Jong-Hwan</forenames></author></authors><title>Convolutional Recurrent Reconstructive Network for Spatiotemporal
  Anomaly Detection in Solder Paste Inspection</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Surface mount technology (SMT) is a process for producing printed circuit
boards. Solder paste printer (SPP), package mounter, and solder reflow oven are
used for SMT. The board on which the solder paste is deposited from the SPP is
monitored by solder paste inspector (SPI). If SPP malfunctions due to the
printer defects, the SPP produces defective products, and then abnormal
patterns are detected by SPI. In this paper, we propose a convolutional
recurrent reconstructive network (CRRN), which decomposes the anomaly patterns
generated by the printer defects, from SPI data. CRRN learns only normal data
and detects anomaly pattern through reconstruction error. CRRN consists of a
spatial encoder (S-Encoder), a spatiotemporal encoder and decoder
(ST-Encoder-Decoder), and a spatial decoder (S-Decoder). The ST-Encoder-Decoder
consists of multiple convolutional spatiotemporal memories (CSTMs) with
ST-Attention mechanism. CSTM is developed to extract spatiotemporal patterns
efficiently. Additionally, a spatiotemporal attention (ST-Attention) mechanism
is designed to facilitate transmitting information from the ST-Encoder to the
ST-Decoder, which can solve the long-term dependency problem. We demonstrate
the proposed CRRN outperforms the other conventional models in anomaly
detection. Moreover, we show the discriminative power of the anomaly map
decomposed by the proposed CRRN through the printer defect classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08233</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08233</id><created>2019-08-22</created><authors><author><keyname>Sun</keyname><forenames>Yao</forenames></author><author><keyname>Li</keyname><forenames>Lang</forenames></author><author><keyname>Shi</keyname><forenames>Guangze</forenames></author><author><keyname>Hou</keyname><forenames>Xiaochao</forenames></author><author><keyname>Su</keyname><forenames>Mei</forenames></author></authors><title>Power Factor Angle Droop Control-A General Decentralized Control of
  Cascaded inverters</title><categories>eess.SY cs.SY math.OC</categories><comments>4 pages, 6 figures</comments><msc-class>93C95</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter proposes a general decentralized control of cascaded
inverters-power factor angle droop control. Compared to the existing control
strategies, it has the following attractive benefits: 1) it is suitable for
both grid-connected and islanded modes; 2) Seamless transition between
different modes can be obtained; 3) stability condition in the grid-connected
mode is independent of the transmission line impedance; 4) it is suited for any
types of loads in islanded modes; 5) multi-equilibrium point problem is
avoided; 6) it is suitable for four quadrant operation. The small signal
stability of the control is proved. And the feasibility of the proposed method
is verified by simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08245</identifier>
 <datestamp>2019-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08245</id><created>2019-08-22</created><updated>2019-12-17</updated><authors><author><keyname>Wang</keyname><forenames>Jiexiang</forenames></author><author><keyname>Li</keyname><forenames>Tao</forenames></author><author><keyname>Zhang</keyname><forenames>Xiwei</forenames></author></authors><title>Distributed Cooperative Online Estimation With Random Observation
  Matrices, Communication Graphs and Time-Delays</title><categories>eess.SP cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze convergence of distributed cooperative online estimation
algorithms by a network of multiple nodes via information exchanging in an
uncertain environment. Each node has a linear observation of an unknown
parameter with randomly time-varying observation matrices. The underlying
communication network is modeled by a sequence of random digraphs and is
subjected to nonuniform random time-varying delays in channels. Each node runs
an online estimation algorithm consisting of a consensus term taking a weighted
sum of its own estimate and delayed estimates of neighbors, and an innovation
term processing its own new measurement at each time step. By stochastic
time-varying system, martingale convergence theories and the binomial expansion
of random matrix products, we transform the convergence analysis of the
algorithm into that of the mathematical expectation of random matrix products.
Firstly, for the delay-free case, we show that the algorithm gains can be
designed properly such that all nodes' estimates converge to the real parameter
in mean square and almost surely if the observation matrices and communication
graphs satisfy the stochastic spatial-temporal persistence of excitation
condition. Especially, this condition holds for Markovian switching
communication graphs and observation matrices, if the stationary graph is
balanced with a spanning tree and the measurement model is spatially-temporally
jointly observable. Secondly, for the case with time-delays, we introduce delay
matrices to model the random time-varying communication delays between nodes,
and propose a mean square convergence condition, which quantitatively shows the
intensity of spatial-temporal persistence of excitation to overcome
time-delays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08251</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08251</id><created>2019-08-22</created><authors><author><keyname>Jansen</keyname><forenames>Mari&#xeb;lle J. A.</forenames></author><author><keyname>Kuijf</keyname><forenames>Hugo J.</forenames></author><author><keyname>Pluim</keyname><forenames>Josien P. W.</forenames></author></authors><title>Optimal input configuration of dynamic contrast enhanced MRI in
  convolutional neural networks for liver segmentation</title><categories>eess.IV cs.CV</categories><comments>Submitted to SPIE Medical Imaging 2019</comments><doi>10.1117/12.2506770</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Most MRI liver segmentation methods use a structural 3D scan as input, such
as a T1 or T2 weighted scan. Segmentation performance may be improved by
utilizing both structural and functional information, as contained in dynamic
contrast enhanced (DCE) MR series. Dynamic information can be incorporated in a
segmentation method based on convolutional neural networks in a number of ways.
In this study, the optimal input configuration of DCE MR images for
convolutional neural networks (CNNs) is studied. The performance of three
different input configurations for CNNs is studied for a liver segmentation
task. The three configurations are I) one phase image of the DCE-MR series as
input image; II) the separate phases of the DCE-MR as input images; and III)
the separate phases of the DCE-MR as channels of one input image. The three
input configurations are fed into a dilated fully convolutional network and
into a small U-net. The CNNs were trained using 19 annotated DCE-MR series and
tested on another 19 annotated DCE-MR series. The performance of the three
input configurations for both networks is evaluated against manual annotations.
The results show that both neural networks perform better when the separate
phases of the DCE-MR series are used as channels of an input image in
comparison to one phase as input image or the separate phases as input images.
No significant difference between the performances of the two network
architectures was found for the separate phases as channels of an input image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08254</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08254</id><created>2019-08-22</created><authors><author><keyname>Jansen</keyname><forenames>Mari&#xeb;lle J. A.</forenames></author><author><keyname>Veldhuis</keyname><forenames>Wouter B.</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Maarten S.</forenames></author><author><keyname>Pluim</keyname><forenames>Josien P. W.</forenames></author></authors><title>Motion correction of dynamic contrast enhanced MRI of the liver</title><categories>eess.IV cs.CV</categories><doi>10.1117/12.2253842</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Motion correction of dynamic contrast enhanced magnetic resonance images
(DCE-MRI) is a challenging task, due to changes in image appearance. In this
study a groupwise registration, using a principle component analysis (PCA)
based metric,1 is evaluated for clinical DCE MRI of the liver. The groupwise
registration transforms the images to a common space, rather than to a
reference volume as conventional pairwise methods do, and computes the
similarity metric on all volumes simultaneously. This groupwise registration
method is compared to a pairwise approach using a mutual information metric.
Clinical DCE MRI of the abdomen of eight patients were included. Per patient
one lesion in the liver was manually segmented in all temporal images (N=16).
The registered images were compared for accuracy, spatial and temporal
smoothness after transformation, and lesion volume change. Compared to a
pairwise method or no registration, groupwise registration provided better
alignment. In our recently started clinical study groupwise registered clinical
DCE MRI of the abdomen of nine patients were scored by three radiologists.
Groupwise registration increased the assessed quality of alignment. The gain in
reading time for the radiologist was estimated to vary from no difference to
almost a minute. A slight increase in reader confidence was also observed.
Registration had no added value for images with little motion. In conclusion,
the groupwise registration of DCE MR images results in better alignment than
achieved by pairwise registration, which is beneficial for clinical assessment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08279</identifier>
 <datestamp>2020-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08279</id><created>2019-08-22</created><authors><author><keyname>Yang</keyname><forenames>Xiqi</forenames></author><author><keyname>Zhang</keyname><forenames>Qingfeng</forenames></author><author><keyname>Li</keyname><forenames>Zhan</forenames></author></authors><title>Contour Detection in Cassini ISS images based on Hierarchical Extreme
  Learning Machine and Dense Conditional Random Field</title><categories>astro-ph.IM cs.CV eess.IV</categories><doi>10.1088/1674-4527/20/1/11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Cassini ISS (Imaging Science Subsystem) images, contour detection is often
performed on disk-resolved object to accurately locate their center. Thus, the
contour detection is a key problem. Traditional edge detection methods, such as
Canny and Roberts, often extract the contour with too much interior details and
noise. Although the deep convolutional neural network has been applied
successfully in many image tasks, such as classification and object detection,
it needs more time and computer resources. In the paper, a contour detection
algorithm based on H-ELM (Hierarchical Extreme Learning Machine) and DenseCRF
(Dense Conditional Random Field) is proposed for Cassini ISS images. The
experimental results show that this algorithm's performance is better than both
traditional machine learning methods such as SVM, ELM and even deep
convolutional neural network. And the extracted contour is closer to the actual
contour. Moreover, it can be trained and tested quickly on the general
configuration of PC, so can be applied to contour detection for Cassini ISS
images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08280</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08280</id><created>2019-08-22</created><updated>2020-01-13</updated><authors><author><keyname>Aydogdu</keyname><forenames>Canan</forenames></author><author><keyname>Keskin</keyname><forenames>Musa Furkan</forenames></author><author><keyname>Garcia</keyname><forenames>Nil</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Bliss</keyname><forenames>Daniel W.</forenames></author></authors><title>RadChat: Spectrum Sharing for Automotive Radar Interference Mitigation</title><categories>cs.IT eess.SP math.IT</categories><comments>14 pages, 17 figures, 1 table, published in IEEE Transactions on
  Intelligent Transportation Systems</comments><doi>10.1109/TITS.2019.2959881</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the automotive sector, both radars and wireless communication are
susceptible to interference. However, combining the radar and communication
systems, i.e., radio frequency (RF) communications and sensing convergence, has
the potential to mitigate interference in both systems. This article analyses
the mutual interference of spectrally coexistent frequency modulated continuous
wave (FMCW) radar and communication systems in terms of occurrence probability
and impact, and introduces RadChat, a distributed networking protocol for
mitigation of interference among FMCW based automotive radars, including
self-interference, using radar communications. The results show that RadChat
can significantly reduce radar mutual interference in single-hop vehicular
networks in less than 80 ms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08294</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08294</id><created>2019-08-22</created><authors><author><keyname>Nguyen</keyname><forenames>Hoai-Thu</forenames></author><author><keyname>Croisille</keyname><forenames>Pierre</forenames></author><author><keyname>Viallon</keyname><forenames>Magalie</forenames></author><author><keyname>Leclerc</keyname><forenames>Sarah</forenames></author><author><keyname>Grange</keyname><forenames>Sylvain</forenames></author><author><keyname>Grange</keyname><forenames>R&#xe9;mi</forenames></author><author><keyname>Bernard</keyname><forenames>Olivier</forenames></author><author><keyname>Grenier</keyname><forenames>Thomas</forenames></author></authors><title>Robustly segmenting quadriceps muscles of ultra-endurance athletes with
  weakly supervised U-Net</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/HJlVDNRV5E</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  In this study, segmentation of quadriceps muscle heads of ultra-endurance
athletes was done using a multi-atlas segmentation and corrective leaning
framework where the registration based multi-atlas segmentation step was
replaced with weakly supervised U-Net. For the case with remarkably different
morphology, our method produced improved accuracy, while reduced significantly
the computation time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08307</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08307</id><created>2019-08-22</created><authors><author><keyname>&#xd6;zbulak</keyname><forenames>G&#xf6;khan</forenames></author></authors><title>Image Colorization By Capsule Networks</title><categories>eess.IV cs.CV</categories><comments>Accepted to New Trends in Image Restoration and Enhancement(NTIRE)
  Workshop at CVPR 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a simple topology of Capsule Network (CapsNet) is investigated
for the problem of image colorization. The generative and segmentation
capabilities of the original CapsNet topology, which is proposed for image
classification problem, is leveraged for the colorization of the images by
modifying the network as follows:1) The original CapsNet model is adapted to
map the grayscale input to the output in the CIE Lab colorspace, 2) The feature
detector part of the model is updated by using deeper feature layers inherited
from VGG-19 pre-trained model with weights in order to transfer low-level image
representation capability to this model, 3) The margin loss function is
modified as Mean Squared Error (MSE) loss to minimize the
image-to-imagemapping. The resulting CapsNet model is named as Colorizer
Capsule Network (ColorCapsNet).The performance of the ColorCapsNet is evaluated
on the DIV2K dataset and promising results are obtained to investigate Capsule
Networks further for image colorization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08314</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08314</id><created>2019-08-22</created><authors><author><keyname>Donnot</keyname><forenames>Benjamin</forenames><affiliation>TAU</affiliation></author><author><keyname>Donon</keyname><forenames>Balthazar</forenames><affiliation>TAU</affiliation></author><author><keyname>Guyon</keyname><forenames>Isabelle</forenames><affiliation>TAU</affiliation></author><author><keyname>Liu</keyname><forenames>Zhengying</forenames><affiliation>TAU</affiliation></author><author><keyname>Marot</keyname><forenames>Antoine</forenames><affiliation>TAU</affiliation></author><author><keyname>Panciatici</keyname><forenames>Patrick</forenames><affiliation>TAU</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>TAU</affiliation></author></authors><title>LEAP nets for power grid perturbations</title><categories>eess.SP cs.LG stat.ML</categories><proxy>ccsd</proxy><journal-ref>ESANN, Apr 2019, Bruges, Belgium</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel neural network embedding approach to model power
transmission grids, in which high voltage lines are disconnected and
reconnected with one-another from time to time, either accidentally or
willfully. We call our architeture LEAP net, for Latent Encoding of Atypical
Perturbation. Our method implements a form of transfer learning, permitting to
train on a few source domains, then generalize to new target domains, without
learning on any example of that domain. We evaluate the viability of this
technique to rapidly assess cu-rative actions that human operators take in
emergency situations, using real historical data, from the French high voltage
power grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08329</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08329</id><created>2019-08-22</created><authors><author><keyname>Wessel</keyname><forenames>J&#xf6;ran</forenames></author><author><keyname>Heinrich</keyname><forenames>Mattias P.</forenames></author><author><keyname>von Berg</keyname><forenames>Jens</forenames></author><author><keyname>Franz</keyname><forenames>Astrid</forenames></author><author><keyname>Saalbach</keyname><forenames>Axel</forenames></author></authors><title>Sequential Rib Labeling and Segmentation in Chest X-Ray using Mask R-CNN</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/SJxuHzLjFV</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mask R-CNN is a state-of-the-art network architecture for the detection and
segmentation of object instances in the computer vision domain. In this
contribution, it is used to localize, label and segment individual ribs in
anterior-posterior chest X-ray images. For this purpose, several extensions
have been made to the original architecture, in order to address the specific
challenges of this application. This includes the use of rib specific networks,
facilitating dedicated anchor boxes sampled from a training set, as well as a
sequential processing of all ribs. Here, the segmentation result of the upper
neighbor rib is used as additional input to the network. This approach is the
first addressing both rib segmentation and anatomical labeling in chest
radiographs. The results are comparable or even better than existing methods
aiming only at segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08338</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08338</id><created>2019-08-22</created><updated>2019-09-27</updated><authors><author><keyname>Panayiotou</keyname><forenames>Tania</forenames></author><author><keyname>Savva</keyname><forenames>Giannis</forenames></author><author><keyname>Tomkos</keyname><forenames>Ioannis</forenames></author><author><keyname>Ellinas</keyname><forenames>Georgios</forenames></author></authors><title>Centralized and Distributed Machine Learning-Based QoT Estimation for
  Sliceable Optical Networks</title><categories>cs.NI cs.LG eess.SP</categories><comments>accepted for presentation at the IEEE GLOBECOM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic network slicing has emerged as a promising and fundamental framework
for meeting 5G's diverse use cases. As machine learning (ML) is expected to
play a pivotal role in the efficient control and management of these networks,
in this work we examine the ML-based Quality-of-Transmission (QoT) estimation
problem under the dynamic network slicing context, where each slice has to meet
a different QoT requirement. We examine ML-based QoT frameworks with the aim of
finding QoT model/s that are fine-tuned according to the diverse QoT
requirements. Centralized and distributed frameworks are examined and compared
according to their accuracy and training time. We show that the distributed QoT
models outperform the centralized QoT model, especially as the number of
diverse QoT requirements increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08380</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08380</id><created>2019-07-01</created><authors><author><keyname>Carmichael</keyname><forenames>Zachariah</forenames></author><author><keyname>Syed</keyname><forenames>Humza</forenames></author><author><keyname>Kudithipudi</keyname><forenames>Dhireesha</forenames></author></authors><title>Analysis of Wide and Deep Echo State Networks for Multiscale
  Spatiotemporal Time Series Forecasting</title><categories>eess.SP cs.LG cs.NE stat.ML</categories><comments>10 pages, 10 figures, Proceedings of the Neuro-inspired Computational
  Elements Workshop (NICE '19), March 26-28, 2019, Albany, NY, USA</comments><doi>10.1145/3320288.3320303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Echo state networks are computationally lightweight reservoir models inspired
by the random projections observed in cortical circuitry. As interest in
reservoir computing has grown, networks have become deeper and more intricate.
While these networks are increasingly applied to nontrivial forecasting tasks,
there is a need for comprehensive performance analysis of deep reservoirs. In
this work, we study the influence of partitioning neurons given a budget and
the effect of parallel reservoir pathways across different datasets exhibiting
multi-scale and nonlinear dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08431</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08431</id><created>2019-08-21</created><updated>2019-08-27</updated><authors><author><keyname>Kl&#xe4;ser</keyname><forenames>Kerstin</forenames></author><author><keyname>Varsavsky</keyname><forenames>Thomas</forenames></author><author><keyname>Markiewicz</keyname><forenames>Pawel</forenames></author><author><keyname>Vercauteren</keyname><forenames>Tom</forenames></author><author><keyname>Atkinson</keyname><forenames>David</forenames></author><author><keyname>Thielemans</keyname><forenames>Kris</forenames></author><author><keyname>Hutton</keyname><forenames>Brian</forenames></author><author><keyname>Cardoso</keyname><forenames>M Jorge</forenames></author><author><keyname>Ourselin</keyname><forenames>Sebastien</forenames></author></authors><title>Improved MR to CT synthesis for PET/MR attenuation correction using
  Imitation Learning</title><categories>eess.IV cs.CV cs.LG physics.med-ph</categories><comments>Aceppted at SASHIMI2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to synthesise Computed Tomography images - commonly known as
pseudo CT, or pCT - from MRI input data is commonly assessed using an
intensity-wise similarity, such as an L2-norm between the ground truth CT and
the pCT. However, given that the ultimate purpose is often to use the pCT as an
attenuation map ($\mu$-map) in Positron Emission Tomography Magnetic Resonance
Imaging (PET/MRI), minimising the error between pCT and CT is not necessarily
optimal. The main objective should be to predict a pCT that, when used as
$\mu$-map, reconstructs a pseudo PET (pPET) which is as close as possible to
the gold standard PET. To this end, we propose a novel multi-hypothesis deep
learning framework that generates pCTs by minimising a combination of the
pixel-wise error between pCT and CT and a proposed metric-loss that itself is
represented by a convolutional neural network (CNN) and aims to minimise
subsequent PET residuals. The model is trained on a database of 400 paired
MR/CT/PET image slices. Quantitative results show that the network generates
pCTs that seem less accurate when evaluating the Mean Absolute Error on the pCT
(69.68HU) compared to a baseline CNN (66.25HU), but lead to significant
improvement in the PET reconstruction - 115a.u. compared to baseline 140a.u.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08453</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08453</id><created>2019-08-22</created><authors><author><keyname>Abdelhamed</keyname><forenames>Abdelrahman</forenames></author><author><keyname>Brubaker</keyname><forenames>Marcus A.</forenames></author><author><keyname>Brown</keyname><forenames>Michael S.</forenames></author></authors><title>Noise Flow: Noise Modeling with Conditional Normalizing Flows</title><categories>cs.CV cs.LG eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Modeling and synthesizing image noise is an important aspect in many computer
vision applications. The long-standing additive white Gaussian and
heteroscedastic (signal-dependent) noise models widely used in the literature
provide only a coarse approximation of real sensor noise. This paper introduces
Noise Flow, a powerful and accurate noise model based on recent normalizing
flow architectures. Noise Flow combines well-established basic parametric noise
models (e.g., signal-dependent noise) with the flexibility and expressiveness
of normalizing flow networks. The result is a single, comprehensive, compact
noise model containing fewer than 2500 parameters yet able to represent
multiple cameras and gain factors. Noise Flow dramatically outperforms existing
noise models, with 0.42 nats/pixel improvement over the camera-calibrated noise
level functions, which translates to 52% improvement in the likelihood of
sampled noise. Noise Flow represents the first serious attempt to go beyond
simple parametric models to one that leverages the power of deep learning and
data-driven noise distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08466</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08466</id><created>2019-08-21</created><updated>2019-08-25</updated><authors><author><keyname>Zhou</keyname><forenames>Xiao-Yun</forenames></author><author><keyname>Li</keyname><forenames>Peichao</forenames></author><author><keyname>Wang</keyname><forenames>Zhao-Yang</forenames></author><author><keyname>Yang</keyname><forenames>Guang-Zhong</forenames></author></authors><title>U-Net Training with Instance-Layer Normalization</title><categories>eess.IV cs.CV cs.LG</categories><comments>8 pages, 3 figures, accepted by MICCAI-MMMI 2019 workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Normalization layers are essential in a Deep Convolutional Neural Network
(DCNN). Various normalization methods have been proposed. The statistics used
to normalize the feature maps can be computed at batch, channel, or instance
level. However, in most of existing methods, the normalization for each layer
is fixed. Batch-Instance Normalization (BIN) is one of the first proposed
methods that combines two different normalization methods and achieve diverse
normalization for different layers. However, two potential issues exist in BIN:
first, the Clip function is not differentiable at input values of 0 and 1;
second, the combined feature map is not with a normalized distribution which is
harmful for signal propagation in DCNN. In this paper, an Instance-Layer
Normalization (ILN) layer is proposed by using the Sigmoid function for the
feature map combination, and cascading group normalization. The performance of
ILN is validated on image segmentation of the Right Ventricle (RV) and Left
Ventricle (LV) using U-Net as the network architecture. The results show that
the proposed ILN outperforms previous traditional and popular normalization
methods with noticeable accuracy improvements for most validations, supporting
the effectiveness of the proposed ILN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08476</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08476</id><created>2019-08-20</created><authors><author><keyname>Lolla</keyname><forenames>Sadhana</forenames></author><author><keyname>Zhao</keyname><forenames>Amy</forenames></author></authors><title>WiFi Motion Detection: A Study into Efficacy and Classification</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  WiFi and security pose both an issue and act as a growing presence in
everyday life. Today's motions detection implementations are severely lacking
in the areas of secrecy, scope, and cost. To combat this problem, we aim to
develop a motion detection system that utilizes WiFi Channel State Information
(CSI), which describes how a wireless signal propagates from the transmitter to
the receiver. The goal of this study is to develop a real-time motion detection
and classification system that is discreet, cost-effective, and easily
implementable. The system would only require an Ubuntu laptop with an Intel
Ultimate N WiFi Link 5300 and a standard router. The system will be developed
in two parts: (1) a robust system to track CSI variations in real-time, and (2)
an algorithm to classify the motion. The system used to track CSI variance in
real-time was completed in August 2018. Initial results show that introduction
of motion to a previously motionless area is detected with high confidence. We
present the development of (1) anomaly detection, utilizing the moving average
filter implemented in the initial program and/or unsupervised machine learning,
and (2) supervised machine learning algorithms to classify a set of simple
motions using a proposed feature extraction methods. Lastly, classification
methods such as Decision Tree, Naive Bayes, and Long Short-Term Memory can be
used to classify basic actions regardless of speed, location, or orientation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08485</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08485</id><created>2019-08-22</created><authors><author><keyname>Vilisov</keyname><forenames>V. Ya.</forenames></author><author><keyname>Murashkin</keyname><forenames>B. Yu.</forenames></author><author><keyname>Kulikov</keyname><forenames>A. I.</forenames></author></authors><title>Simulation Model of Two-Robot Cooperation in Common Operating
  Environment</title><categories>cs.RO cs.AI cs.CY cs.SY eess.SY</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article considers a simulation modelling problem related to the chess
game process occurring between two three-tier manipulators. The objective of
the game construction lies in developing the procedure of effective control of
the autonomous manipulator robots located in a common operating environment.
The simulation model is a preliminary stage of building a natural complex that
would provide cooperation of several manipulator robots within a common
operating environment. The article addresses issues of training and research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08505</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08505</id><created>2019-08-22</created><authors><author><keyname>Zerman</keyname><forenames>Emin</forenames></author><author><keyname>Rana</keyname><forenames>Aakanksha</forenames></author><author><keyname>Smolic</keyname><forenames>Aljosa</forenames></author></authors><title>ColorNet -- Estimating Colorfulness in Natural Images</title><categories>cs.MM cs.GR cs.LG eess.IV</categories><comments>Accepted to IEEE International Conference on Image Processing (ICIP)
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Measuring the colorfulness of a natural or virtual scene is critical for many
applications in image processing field ranging from capturing to display. In
this paper, we propose the first deep learning-based colorfulness estimation
metric. For this purpose, we develop a color rating model which simultaneously
learns to extracts the pertinent characteristic color features and the mapping
from feature space to the ideal colorfulness scores for a variety of natural
colored images. Additionally, we propose to overcome the lack of adequate
annotated dataset problem by combining/aligning two publicly available
colorfulness databases using the results of a new subjective test which employs
a common subset of both databases. Using the obtained subjectively annotated
dataset with 180 colored images, we finally demonstrate the efficacy of our
proposed model over the traditional methods, both quantitatively and
qualitatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08535</identifier>
 <datestamp>2020-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08535</id><created>2019-08-23</created><updated>2020-01-08</updated><authors><author><keyname>Tao</keyname><forenames>Yang</forenames></author><author><keyname>Ktistis</keyname><forenames>Christos</forenames></author><author><keyname>Zhao</keyname><forenames>Yifei</forenames></author><author><keyname>Yin</keyname><forenames>Wuliang</forenames></author><author><keyname>Peyton</keyname><forenames>Anthony J</forenames></author></authors><title>A Class D Power Amplifier for Multi-Frequency Eddy Current Testing Based
  on Multi-Simultaneous-Frequency Selective Harmonic Elimination Pulse Width
  Modulation</title><categories>eess.SY cs.SY eess.SP physics.ins-det</categories><doi>10.1109/TIE.2019.2947842</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Efficiency and multisimultaneous-frequency (MSF) output capability are two
major criteria characterizing the performance of a power amplifier in the
application of multifrequency eddy current testing (MECT). Switch-mode power
amplifiers are known to have a very high efficiency, yet they have rarely been
adopted in the instrumental development of MECT. In addition, switch-mode power
amplifiers themselves are lacking in the research literature for MSF
capability. In this article, a Class D power amplifier is designed so as to
address the two issues. An MSF selective harmonic elimination pulsewidth
modulation method is proposed to generate alternating magnetic fields, which
are rich in selected harmonics. A field-programmable-gate-array-based
experimental system has been developed to verify the design. Results show that
the proposed methodology is capable of generating high MSF currents in the
transmitting coil with a low distortion of signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08584</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08584</id><created>2019-08-22</created><authors><author><keyname>Wang</keyname><forenames>Beinan</forenames></author><author><keyname>Glossner</keyname><forenames>John</forenames></author><author><keyname>Iancu</keyname><forenames>Daniel</forenames></author><author><keyname>Gaydadjiev</keyname><forenames>Georgi N.</forenames></author></authors><title>Feedbackward Decoding for Semantic Segmentation</title><categories>cs.CV cs.CL eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel approach for semantic segmentation that uses an encoder in
the reverse direction to decode. Many semantic segmentation networks adopt a
feedforward encoder-decoder architecture. Typically, an input is first
downsampled by the encoder to extract high-level semantic features and
continues to be fed forward through the decoder module to recover low-level
spatial clues. Our method works in an alternative direction that lets
information flow backward from the last layer of the encoder towards the first.
The encoder performs encoding in the forward pass and the same network performs
decoding in the backward pass. Therefore, the encoder itself is also the
decoder. Compared to conventional encoder-decoder architectures, ours doesn't
require additional layers for decoding and further reuses the encoder weights
thereby reducing the total number of parameters required for processing. We
show by using only the 13 convolutional layers from VGG-16 plus one tiny
classification layer, our model significantly outperforms other frequently
cited models that are also adapted from VGG-16. On the Cityscapes semantic
segmentation benchmark, our model uses 50.0% less parameters than SegNet and
achieves an 18.1% higher &quot;IoU class&quot; score; it uses 28.3% less parameters than
DeepLab LargeFOV and the achieved &quot;IoU class&quot; score is 3.9% higher; it uses
89.1% fewer parameters than FCN-8s and the achieved &quot;IoU class&quot; score is 3.1%
higher. Our code will be publicly available on Github later.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08588</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08588</id><created>2019-08-22</created><authors><author><keyname>Juarez</keyname><forenames>Antonio Garcia-Uceda</forenames></author><author><keyname>Selvan</keyname><forenames>Raghavendra</forenames></author><author><keyname>Saghir</keyname><forenames>Zaigham</forenames></author><author><keyname>de Bruijne</keyname><forenames>Marleen</forenames></author></authors><title>A joint 3D UNet-Graph Neural Network-based method for Airway
  Segmentation from chest CTs</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an end-to-end deep learning segmentation method by combining a 3D
UNet architecture with a graph neural network (GNN) model. In this approach,
the convolutional layers at the deepest level of the UNet are replaced by a
GNN-based module with a series of graph convolutions. The dense feature maps at
this level are transformed into a graph input to the GNN module. The
incorporation of graph convolutions in the UNet provides nodes in the graph
with information that is based on node connectivity, in addition to the local
features learnt through the downsampled paths. This information can help
improve segmentation decisions. By stacking several graph convolution layers,
the nodes can access higher order neighbourhood information without substantial
increase in computational expense. We propose two types of node connectivity in
the graph adjacency: i) one predefined and based on a regular node
neighbourhood, and ii) one dynamically computed during training and using the
nearest neighbour nodes in the feature space. We have applied this method to
the task of segmenting the airway tree from chest CT scans. Experiments have
been performed on 32 CTs from the Danish Lung Cancer Screening Trial dataset.
We evaluate the performance of the UNet-GNN models with two types of graph
adjacency and compare it with the baseline UNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08631</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08631</id><created>2019-08-22</created><authors><author><keyname>Honghan</keyname><forenames>Li</forenames></author><author><keyname>Matsunaga</keyname><forenames>Daiki</forenames></author><author><keyname>Matsui</keyname><forenames>Tsubasa S.</forenames></author><author><keyname>Aosaki</keyname><forenames>Hiroki</forenames></author><author><keyname>Deguchi</keyname><forenames>Shinji</forenames></author></authors><title>Image based cellular contractile force evaluation with small-world
  network inspired CNN: SW-UNet</title><categories>physics.bio-ph cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an image-based cellular contractile force evaluation method using
a machine learning technique. We use a special substrate that exhibits wrinkles
when cells grab the substrate and contract, and the wrinkles can be used to
visualize the force magnitude and direction. In order to extract wrinkles from
the microscope images, we develop a new CNN (convolutional neural network)
architecture SW-UNet (small-world U-Net), which is a CNN that reflects the
concept of the small-world network. The SW-UNet shows better performance in
wrinkle segmentation task compared to other methods: the error (Euclidean
distance) of SW-UNet is 4.9 times smaller than 2D-FFT (fast Fourier transform)
based segmentation approach, and is 2.9 times smaller than U-Net. As a
demonstration, we compare the contractile force of U2OS (human osteosarcoma)
cells and show that cells with a mutation in the KRAS oncogne show larger force
compared to the wild-type cells. Our new machine learning based algorithm
provides us an efficient, automated and accurate method to evaluate the cell
contractile force.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08649</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08649</id><created>2019-08-22</created><updated>2020-02-08</updated><authors><author><keyname>Yang</keyname><forenames>Zhixiong</forenames></author><author><keyname>Gang</keyname><forenames>Arpita</forenames></author><author><keyname>Bajwa</keyname><forenames>Waheed U.</forenames></author></authors><title>Adversary-resilient Distributed and Decentralized Statistical Inference
  and Machine Learning</title><categories>stat.ML cs.CR cs.DC cs.LG eess.SP</categories><comments>24 pages, 6 figures, 2 tables; IEEE Signal Processing Magazine, May
  2020 (Special Issue on &quot;Distributed, Streaming Machine Learning&quot;)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the last few decades have witnessed a huge body of work devoted to
inference and learning in distributed and decentralized setups, much of this
work assumes a non-adversarial setting in which individual nodes---apart from
occasional statistical failures---operate as intended within the algorithmic
framework. In recent years, however, cybersecurity threats from malicious
non-state actors and rogue entities have forced practitioners and researchers
to rethink the robustness of distributed and decentralized algorithms against
adversarial attacks. As a result, we now have a plethora of algorithmic
approaches that guarantee robustness of distributed and/or decentralized
inference and learning under different adversarial threat models. Driven in
part by the world's growing appetite for data-driven decision making, however,
securing of distributed/decentralized frameworks for inference and learning
against adversarial threats remains a rapidly evolving research area. In this
article, we provide an overview of some of the most recent developments in this
area under the threat model of Byzantine attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08668</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08668</id><created>2019-08-23</created><authors><author><keyname>Tripathi</keyname><forenames>Kumud</forenames></author><author><keyname>Rao</keyname><forenames>K. Sreenivasa</forenames></author></authors><title>VOP Detection for Read and Conversation Speech using CWT Coefficients
  and Phone Boundaries</title><categories>eess.AS cs.SD</categories><comments>21 pages, 8 figures, 4 tables, article</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel approach for accurate detection of the
vowel onset points (VOPs). VOP is the instant at which the vowel begins in the
speech signal. Precise identification of VOPs is important for various speech
applications such as speech segmentation and speech rate modification. The
existing methods detect the majority of VOPs within 40 ms deviation, and it may
not be appropriate for the above speech applications. To address this issue, we
proposed a two-stage approach for accurate detection of VOPs. At the first
stage, VOPs are detected using continuous wavelet transform coefficients, and
the position of the detected VOPs are corrected using the phone boundaries in
the second stage. The phone boundaries are detected by the spectral transition
measure method. Experiments are done using TIMIT and Bengali speech corpora.
Performance of the proposed approach is compared with two standard signal
processing based methods. The evaluation results show that the proposed method
performs better than the existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08669</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08669</id><created>2019-08-23</created><updated>2019-09-26</updated><authors><author><keyname>Quan</keyname><forenames>Xiangjun</forenames></author><author><keyname>Hu</keyname><forenames>Qinran</forenames></author><author><keyname>Huang</keyname><forenames>Alex Q.</forenames></author><author><keyname>Dou</keyname><forenames>Xiaobo</forenames></author><author><keyname>Wu</keyname><forenames>Zaijun</forenames></author></authors><title>A Novel Synchronous Reference Frame Frequency-Locked Loop</title><categories>eess.SY cs.SY</categories><comments>4 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter proposes a new design of frequency-locked loop (FLL) which is
based on synchronous (dq) reference frame instead of stationary
({\alpha}\b{eta}) reference frame. First, a synchronous reference frame FLL
(briefly called SRF-FLL0) equivalent to the conventional FLL is proposed. Then
the SRF-FLL0 is improved by utilizing the phase error to acquire a better
performance. The small-signal modeling and parameter tuning of the improved
synchronous reference frame FLL (SRF-FLL) are presented. Finally, the
theoretical analysis and experiment results verify the superiority and
effectiveness of proposed SRF-FLL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08702</identifier>
 <datestamp>2020-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08702</id><created>2019-08-23</created><updated>2020-02-13</updated><authors><author><keyname>Braganza</keyname><forenames>Oliver</forenames></author></authors><title>A simple model suggesting economically rational sample-size choice
  drives irreproducibility</title><categories>econ.GN cs.SY eess.SY q-fin.EC stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several systematic studies have suggested that a large fraction of published
research is not reproducible. One probable reason for low reproducibility is
insufficient sample size, resulting in low power and low positive predictive
value. It has been suggested that insufficient sample-size choice is driven by
a combination of scientific competition and 'positive publication bias'. Here
we formalize this intuition in a simple model, in which scientists choose
economically rational sample sizes, balancing the cost of experimentation with
income from publication. Specifically, assuming that a scientist's income
derives only from 'positive' findings (positive publication bias) and that
individual samples cost a fixed amount, allows to leverage basic statistical
formulas into an economic optimality prediction. We find that if effects have
i) low base probability, ii) small effect size or iii) low grant income per
publication, then the rational (economically optimal) sample size is small.
Furthermore, for plausible distributions of these parameters we find a robust
emergence of a bimodal distribution of obtained statistical power and low
overall reproducibility rates, both matching empirical findings. Finally, we
explore conditional equivalence testing as a means to align economic incentives
with adequate sample sizes. Overall, the model describes a simple mechanism
explaining both the prevalence and the persistence of small sample sizes, and
is well suited for empirical validation. It proposes economic rationality, or
economic pressures, as a principal driver of irreproducibility and suggests
strategies to change this.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08717</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08717</id><created>2019-08-23</created><authors><author><keyname>Garnerin</keyname><forenames>Mahault</forenames></author><author><keyname>Rossato</keyname><forenames>Solange</forenames></author><author><keyname>Besacier</keyname><forenames>Laurent</forenames></author></authors><title>Gender Representation in French Broadcast Corpora and Its Impact on ASR
  Performance</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted to ACM Workshop AI4TV</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the gender representation in four major corpora of French
broadcast. These corpora being widely used within the speech processing
community, they are a primary material for training automatic speech
recognition (ASR) systems. As gender bias has been highlighted in numerous
natural language processing (NLP) applications, we study the impact of the
gender imbalance in TV and radio broadcast on the performance of an ASR system.
This analysis shows that women are under-represented in our data in terms of
speakers and speech turns. We introduce the notion of speaker role to refine
our analysis and find that women are even fewer within the Anchor category
corresponding to prominent speakers. The disparity of available data for both
gender causes performance to decrease on women. However this global trend can
be counterbalanced for speaker who are used to speak in the media when
sufficient amount of data is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08719</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08719</id><created>2019-08-23</created><authors><author><keyname>Al-Obiedollah</keyname><forenames>Haitham</forenames></author><author><keyname>Cumanan</keyname><forenames>Kanapathippillai</forenames></author><author><keyname>Burr</keyname><forenames>Alister G.</forenames></author><author><keyname>Tang</keyname><forenames>Jie</forenames></author><author><keyname>Rahulamathavan</keyname><forenames>Yogachandran</forenames></author><author><keyname>Ding</keyname><forenames>Zhiguo</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author></authors><title>On Energy Harvesting of Hybrid TDMA-NOMA Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate energy harvesting capabilities of
non-orthogonal multiple access (NOMA) scheme integrated with the conventional
time division multiple access (TDMA) scheme, which is referred to as hybrid
TDMA-NOMA system. In a such hybrid scheme, users are divided into a number of
groups, with the total time allocated for transmission is shared between these
groups through multiple time slots. In particular, a time slot is assigned to
serve each group, whereas the users in the corresponding group are served based
on power-domain NOMA technique. Furthermore, simultaneous wireless power and
information transfer technique is utilized to simultaneously harvest energy and
decode information at each user. Therefore, each user splits the received
signal into two parts, namely, energy harvesting part and information decoding
part. In particular, we jointly determine the power allocation and power
splitting ratios for all users to minimize the transmit power under minimum
rate and minimum energy harvesting requirements at each user. Furthermore, this
joint design is a non-convex problem in nature. Hence, we employ successive
interference cancellation to overcome these non-convexity issues and determine
the design parameters (i.e., the power allocations and the power splitting
ratios). In simulation results, we demonstrate the performance of the proposed
hybrid TDMA-NOMA design and show that it outperforms the conventional TDMA
scheme in terms of transmit power consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08746</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08746</id><created>2019-08-23</created><authors><author><keyname>Valverde</keyname><forenames>Juan Miguel</forenames></author><author><keyname>Shatillo</keyname><forenames>Artem</forenames></author><author><keyname>de Feo</keyname><forenames>Riccardo</forenames></author><author><keyname>Gr&#xf6;hn</keyname><forenames>Olli</forenames></author><author><keyname>Sierra</keyname><forenames>Alejandra</forenames></author><author><keyname>Tohka</keyname><forenames>Jussi</forenames></author></authors><title>Automatic Rodent Brain MRI Lesion Segmentation with Fully Convolutional
  Networks</title><categories>eess.IV cs.CV</categories><comments>Accepted to Machine Learning in Medical Imaging (MLMI 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manual segmentation of rodent brain lesions from magnetic resonance images
(MRIs) is an arduous, time-consuming and subjective task that is highly
important in pre-clinical research. Several automatic methods have been
developed for different human brain MRI segmentation, but little research has
targeted automatic rodent lesion segmentation. The existing tools for
performing automatic lesion segmentation in rodents are constrained by strict
assumptions about the data. Deep learning has been successfully used for
medical image segmentation. However, there has not been any deep learning
approach specifically designed for tackling rodent brain lesion segmentation.
In this work, we propose a novel Fully Convolutional Network (FCN), RatLesNet,
for the aforementioned task. Our dataset consists of 131 T2-weighted rat brain
scans from 4 different studies in which ischemic stroke was induced by
transient middle cerebral artery occlusion. We compare our method with two
other 3D FCNs originally developed for anatomical segmentation (VoxResNet and
3D-U-Net) with 5-fold cross-validation on a single study and a generalization
test, where the training was done on a single study and testing on three
remaining studies. The labels generated by our method were quantitatively and
qualitatively better than the predictions of the compared methods. The average
Dice coefficient achieved in the 5-fold cross-validation experiment with the
proposed approach was 0.88, between 3.7% and 38% higher than the compared
architectures. The presented architecture also outperformed the other FCNs at
generalizing on different studies, achieving the average Dice coefficient of
0.79.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08747</identifier>
 <datestamp>2020-02-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08747</id><created>2019-08-23</created><updated>2020-02-21</updated><authors><author><keyname>Di Renzo</keyname><forenames>M.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Ntontin</keyname><forenames>K.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Song</keyname><forenames>J.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Danufane</keyname><forenames>F. H.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Qian</keyname><forenames>X.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Lazarakis</keyname><forenames>F.</forenames><affiliation>Shitz</affiliation></author><author><keyname>de Rosny</keyname><forenames>J.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Phan-Huy</keyname><forenames>D. -T.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Simeone</keyname><forenames>O.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Zhang</keyname><forenames>R.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Debbah</keyname><forenames>M.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Lerosey</keyname><forenames>G.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Fink</keyname><forenames>M.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Tretyakov</keyname><forenames>S.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>S.</forenames><affiliation>Shitz</affiliation></author></authors><title>Reconfigurable Intelligent Surfaces vs. Relaying: Differences,
  Similarities, and Performance Comparison</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted for journal publication (revised version)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconfigurable intelligent surfaces (RISs) have the potential of realizing
the emerging concept of smart radio environments by leveraging the unique
properties of meta-surfaces. In this article, we discuss the potential
applications of RISs in wireless networks that operate at high-frequency bands,
e.g., millimeter wave (30-100 GHz) and sub-millimeter wave (greater than 100
GHz) frequencies. When used in wireless networks, RISs may operate in a manner
similar to relays. This paper elaborates on the key differences and
similarities between RISs that are configured to operate as anomalous
reflectors and relays. In particular, we illustrate numerical results that
highlight the spectral efficiency gains of RISs when their size is sufficiently
large as compared with the wavelength of the radio waves. In addition, we
discuss key open issues that need to be addressed for unlocking the potential
benefits of RISs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08769</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08769</id><created>2019-08-23</created><updated>2019-10-23</updated><authors><author><keyname>Kamtue</keyname><forenames>Kawisorn</forenames></author><author><keyname>Euchukanonchai</keyname><forenames>Kasina</forenames></author><author><keyname>Wanvarie</keyname><forenames>Dittaya</forenames></author><author><keyname>Pratanwanich</keyname><forenames>Naruemon</forenames></author></authors><title>Lukthung Classification Using Neural Networks on Lyrics and Audios</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>ICSEC 2019 (accepted)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music genre classification is a widely researched topic in music information
retrieval (MIR). Being able to automatically tag genres will benefit music
streaming service providers such as JOOX, Apple Music, and Spotify for their
content-based recommendation. However, most studies on music classification
have been done on western songs which differ from Thai songs. Lukthung, a
distinctive and long-established type of Thai music, is one of the most popular
music genres in Thailand and has a specific group of listeners. In this paper,
we develop neural networks to classify such Lukthung genre from others using
both lyrics and audios. Words used in Lukthung songs are particularly poetical,
and their musical styles are uniquely composed of traditional Thai instruments.
We leverage these two main characteristics by building a lyrics model based on
bag-of-words (BoW), and an audio model using a convolutional neural network
(CNN) architecture. We then aggregate the intermediate features learned from
both models to build a final classifier. Our results show that the proposed
three models outperform all of the standard classifiers where the combined
model yields the best $F_1$ score of 0.86, allowing Lukthung classification to
be applicable to personalized recommendation for Thai audience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08807</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08807</id><created>2019-08-22</created><authors><author><keyname>Wu</keyname><forenames>Hao</forenames></author><author><keyname>Zhu</keyname><forenames>Ziyu</forenames></author><author><keyname>Wang</keyname><forenames>Jiayi</forenames></author><author><keyname>Zheng</keyname><forenames>Nanning</forenames></author><author><keyname>Chen</keyname><forenames>Badong</forenames></author></authors><title>An encoding framework with brain inner state for natural image
  identification</title><categories>q-bio.NC cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural encoding and decoding, which aim to characterize the relationship
between stimuli and brain activities, have emerged as an important area in
cognitive neuroscience. Traditional encoding models, which focus on feature
extraction and mapping, consider the brain as an input-output mapper without
inner states. In this work, inspired by the fact that human brain acts like a
state machine, we proposed a novel encoding framework that combines information
from both the external world and the inner state to predict brain activity. The
framework comprises two parts: forward encoding model that deals with visual
stimuli and inner state model that captures influence from intrinsic
connections in the brain. The forward model can be any traditional encoding
model, making the framework flexible. The inner state model is a linear model
to utilize information in the prediction residuals of the forward model. The
proposed encoding framework can achieve much better performance on natural
image identification from fMRI response than forwardonly models. The
identification accuracy will decrease slightly with the dataset size
increasing, but remain relatively stable with different identification methods.
The results confirm that the new encoding framework is effective and robust
when used for brain decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08813</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08813</id><created>2019-08-22</created><updated>2019-10-16</updated><authors><author><keyname>Karantaidis</keyname><forenames>Georgios</forenames></author><author><keyname>Kotropoulos</keyname><forenames>Constantine</forenames></author></authors><title>Efficient Capon-Based Approach Exploiting Temporal Windowing For
  Electric Network Frequency Estimation</title><categories>eess.SP cs.CV</categories><comments>6 pages, 1 figure, IEEE International Workshop on Machine Learning
  For Signal Processing (MLSP) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electric Network Frequency (ENF) fluctuations constitute a powerful tool in
multimedia forensics. An efficient approach for ENF estimation is introduced
with temporal windowing based on the filter-bank Capon spectral estimator. A
type of Gohberg-Semencul factorization of the model covariance matrix is used
due to the Toeplitz structure of the covariance matrix. Moreover, this approach
uses, for the first time in the field of ENF, a temporal window, not
necessarily the rectangular one, at the stage preceding spectral estimation.
Krylov matrices are employed for fast implementation of matrix inversions. The
proposed approach outperforms the state-of-the-art methods in ENF estimation,
when a short time window of $1$ second is employed in power recordings. In
speech recordings, the proposed approach yields highly accurate results with
respect to both time complexity and accuracy. Moreover, the impact of different
temporal windows is studied. The results show that even the most trivial
methods for ENF estimation, such as the Short-Time Fourier Transform, can
provide better results than the most recent state-of-the-art methods, when a
temporal window is employed. The correlation coefficient is used to measure the
ENF estimation accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08815</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08815</id><created>2019-08-23</created><authors><author><keyname>Garc&#xed;a-Fern&#xe1;ndez</keyname><forenames>&#xc1;ngel F.</forenames></author><author><keyname>Svensson</keyname><forenames>Lennart</forenames></author></authors><title>Spooky effect in optimal OSPA estimation and how GOSPA solves it</title><categories>eess.SP cs.CV stat.ML</categories><comments>This paper received the third best paper award at the 22nd
  International Conference on Information Fusion, Ottawa, Canada, 2019. Matlab
  code of the GOSPA metric can be found in https://github.com/abusajana/GOSPA .
  Additional information on MTT can be found in the online course
  https://www.youtube.com/channel/UCa2-fpj6AV8T6JK1uTRuFpw</comments><journal-ref>Proceedings of the 22nd International Conference on Information
  Fusion, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show the spooky effect at a distance that arises in optimal
estimation of multiple targets with the optimal sub-pattern assignment (OSPA)
metric. This effect refers to the fact that if we have several independent
potential targets at distant locations, a change in the probability of
existence of one of them can completely change the optimal estimation of the
rest of the potential targets. As opposed to OSPA, the generalised OSPA (GOSPA)
metric ($\alpha=2$) penalises localisation errors for properly detected
targets, false targets and missed targets. As a consequence, optimal GOSPA
estimation aims to lower the number of false and missed targets, as well as the
localisation error for properly detected targets, and avoids the spooky effect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08819</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08819</id><created>2019-08-23</created><authors><author><keyname>Garc&#xed;a-Fern&#xe1;ndez</keyname><forenames>&#xc1;ngel F.</forenames></author><author><keyname>Xia</keyname><forenames>Yuxuan</forenames></author><author><keyname>Granstr&#xf6;m</keyname><forenames>Karl</forenames></author><author><keyname>Svensson</keyname><forenames>Lennart</forenames></author><author><keyname>Williams</keyname><forenames>Jason L.</forenames></author></authors><title>Gaussian implementation of the multi-Bernoulli mixture filter</title><categories>eess.SP cs.CV stat.AP</categories><comments>Matlab code of the MBM and PMBM filters is provided in
  https://github.com/Agarciafernandez/MTT . Additional information on MTT
  including PMBM and MBM filters can be found in the online course
  https://www.youtube.com/channel/UCa2-fpj6AV8T6JK1uTRuFpw</comments><journal-ref>Proceedings of the 22nd International Conference on Information
  Fusion, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the Gaussian implementation of the multi-Bernoulli
mixture (MBM) filter. The MBM filter provides the filtering (multi-target)
density for the standard dynamic and radar measurement models when the birth
model is multi-Bernoulli or multi-Bernoulli mixture. Under linear/Gaussian
models, the single target densities of the MBM mixture admit Gaussian
closed-form expressions. Murty's algorithm is used to select the global
hypotheses with highest weights. The MBM filter is compared with other
algorithms in the literature via numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08837</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08837</id><created>2019-08-23</created><authors><author><keyname>Yang</keyname><forenames>Xin</forenames></author><author><keyname>Mei</keyname><forenames>Haiyang</forenames></author><author><keyname>Zhang</keyname><forenames>Jiqing</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author><author><keyname>Yin</keyname><forenames>Baocai</forenames></author><author><keyname>Zhang</keyname><forenames>Qiang</forenames></author><author><keyname>Wei</keyname><forenames>Xiaopeng</forenames></author></authors><title>DRFN: Deep Recurrent Fusion Network for Single-Image Super-Resolution
  with Large Factors</title><categories>cs.CV eess.IV</categories><journal-ref>IEEE Transactions on Multimedia ( Volume: 21 , Issue: 2 , Feb.
  2019 ) 328 - 337</journal-ref><doi>10.1109/TMM.2018.2863602</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, single-image super-resolution has made great progress owing to the
development of deep convolutional neural networks (CNNs). The vast majority of
CNN-based models use a pre-defined upsampling operator, such as bicubic
interpolation, to upscale input low-resolution images to the desired size and
learn non-linear mapping between the interpolated image and ground truth
high-resolution (HR) image. However, interpolation processing can lead to
visual artifacts as details are over-smoothed, particularly when the
super-resolution factor is high. In this paper, we propose a Deep Recurrent
Fusion Network (DRFN), which utilizes transposed convolution instead of bicubic
interpolation for upsampling and integrates different-level features extracted
from recurrent residual blocks to reconstruct the final HR images. We adopt a
deep recurrence learning strategy and thus have a larger receptive field, which
is conducive to reconstructing an image more accurately. Furthermore, we show
that the multi-level fusion structure is suitable for dealing with image
super-resolution problems. Extensive benchmark evaluations demonstrate that the
proposed DRFN performs better than most current deep learning methods in terms
of accuracy and visual effects, especially for large-scale images, while using
fewer parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08847</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08847</id><created>2019-08-23</created><authors><author><keyname>Yildirim</keyname><forenames>G&#xf6;khan</forenames></author><author><keyname>Jetchev</keyname><forenames>Nikolay</forenames></author><author><keyname>Vollgraf</keyname><forenames>Roland</forenames></author><author><keyname>Bergmann</keyname><forenames>Urs</forenames></author></authors><title>Generating High-Resolution Fashion Model Images Wearing Custom Outfits</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>Accepted to the International Conference on Computer Vision, ICCV
  2019, Workshop on Computer Vision for Fashion, Art and Design</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visualizing an outfit is an essential part of shopping for clothes. Due to
the combinatorial aspect of combining fashion articles, the available images
are limited to a pre-determined set of outfits. In this paper, we broaden these
visualizations by generating high-resolution images of fashion models wearing a
custom outfit under an input body pose. We show that our approach can not only
transfer the style and the pose of one generated outfit to another, but also
create realistic images of human bodies and garments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08854</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08854</id><created>2019-08-23</created><updated>2019-09-03</updated><authors><author><keyname>Xie</keyname><forenames>Yuxing</forenames></author><author><keyname>Tian</keyname><forenames>Jiaojiao</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author></authors><title>A Review of Point Cloud Semantic Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted by IEEE Geoscience and Remote Sensing Magazine; corrected
  typos (3 Sep 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3D Point Cloud Semantic Segmentation (PCSS) is attracting increasing
interest, due to its applicability in remote sensing, computer vision and
robotics, and due to the new possibilities offered by deep learning techniques.
In order to provide a needed up-to-date review of recent developments in PCSS,
this article summarizes existing studies on this topic. Firstly, we outline the
acquisition and evolution of the 3D point cloud from the perspective of remote
sensing and computer vision, as well as the published benchmarks for PCSS
studies. Then, traditional and advanced techniques used for Point Cloud
Segmentation (PCS) and PCSS are reviewed and compared. Finally, important
issues and open questions in PCSS studies are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08856</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08856</id><created>2019-08-23</created><authors><author><keyname>G&#xf3;rriz</keyname><forenames>Marc</forenames></author><author><keyname>Antony</keyname><forenames>Joseph</forenames></author><author><keyname>McGuinness</keyname><forenames>Kevin</forenames></author><author><keyname>Gir&#xf3;-i-Nieto</keyname><forenames>Xavier</forenames></author><author><keyname>O'Connor</keyname><forenames>Noel E.</forenames></author></authors><title>Assessing Knee OA Severity with CNN attention-based end-to-end
  architectures</title><categories>eess.IV cs.CV cs.LG</categories><comments>Proceedings of the 2nd International Conference on Medical Imaging
  with Deep Learning</comments><journal-ref>Proceedings of The 2nd International Conference on Medical Imaging
  with Deep Learning, PMLR 102:197-214, 2019</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This work proposes a novel end-to-end convolutional neural network (CNN)
architecture to automatically quantify the severity of knee osteoarthritis (OA)
using X-Ray images, which incorporates trainable attention modules acting as
unsupervised fine-grained detectors of the region of interest (ROI). The
proposed attention modules can be applied at different levels and scales across
any CNN pipeline helping the network to learn relevant attention patterns over
the most informative parts of the image at different resolutions. We test the
proposed attention mechanism on existing state-of-the-art CNN architectures as
our base models, achieving promising results on the benchmark knee OA datasets
from the osteoarthritis initiative (OAI) and multicenter osteoarthritis study
(MOST). All code from our experiments will be publicly available on the github
repository: https://github.com/marc-gorriz/KneeOA-CNNAttention
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08870</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08870</id><created>2019-08-23</created><authors><author><keyname>Byrne</keyname><forenames>Nick</forenames></author><author><keyname>Clough</keyname><forenames>James R.</forenames></author><author><keyname>Valverde</keyname><forenames>Isra</forenames></author><author><keyname>Montana</keyname><forenames>Giovanni</forenames></author><author><keyname>King</keyname><forenames>Andrew P.</forenames></author></authors><title>Topology-preserving augmentation for CNN-based segmentation of
  congenital heart defects from 3D paediatric CMR</title><categories>eess.IV cs.CV cs.LG</categories><comments>To be published at MICCAI PIPPI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Patient-specific 3D printing of congenital heart anatomy demands an accurate
segmentation of the thin tissue interfaces which characterise these diagnoses.
Even when a label set has a high spatial overlap with the ground truth,
inaccurate delineation of these interfaces can result in topological errors.
These compromise the clinical utility of such models due to the anomalous
appearance of defects. CNNs have achieved state-of-the-art performance in
segmentation tasks. Whilst data augmentation has often played an important
role, we show that conventional image resampling schemes used therein can
introduce topological changes in the ground truth labelling of augmented
samples. We present a novel pipeline to correct for these changes, using a
fast-marching algorithm to enforce the topology of the ground truth labels
within their augmented representations. In so doing, we invoke the idea of
cardiac contiguous topology to describe an arbitrary combination of congenital
heart defects and develop an associated, clinically meaningful metric to
measure the topological correctness of segmentations. In a series of five-fold
cross-validations, we demonstrate the performance gain produced by this
pipeline and the relevance of topological considerations to the segmentation of
congenital heart defects. We speculate as to the applicability of this approach
to any segmentation task involving morphologically complex targets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08872</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08872</id><created>2019-08-23</created><authors><author><keyname>Kovalchukov</keyname><forenames>Roman</forenames></author><author><keyname>Moltchanov</keyname><forenames>Dmitri</forenames></author><author><keyname>Gaidamaka</keyname><forenames>Yuliya</forenames></author><author><keyname>Bobrikova</keyname><forenames>Ekaterina</forenames></author></authors><title>An Accurate Approximation of Resource Request Distributions in
  Millimeter Wave 3GPP New Radio Systems</title><categories>cs.NI eess.SP</categories><comments>The 19th International Conference on Next Generation Wired/Wireless
  Networks and Systems (New2An 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently standardized millimeter wave-based 3GPP New Radio technology is
expected to become an enabler for both enhanced Mobile Broadband (eMBB) and
ultra-reliable low latency communication (URLLC) services specified to future
5G systems. One of the first steps in mathematical modeling of such systems is
the characterization of the session resource request probability mass function
(pmf) as a function of the channel conditions, cell size, application demands,
user location and system parameters including modulation and coding schemes
employed at the air interface. Unfortunately, this pmf cannot be expressed via
elementary functions. In this paper, we develop an accurate approximation of
the sought pmf. First, we show that Normal distribution provides a fairly
accurate approximation to the cumulative distribution function (CDF) of the
signal-to-noise ratio for communication systems operating in the millimeter
frequency band, further allowing evaluating the resource request pmf via error
function. We also investigate the impact of shadow fading on the resource
request pmf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08873</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08873</id><created>2019-08-23</created><authors><author><keyname>Abedin</keyname><forenames>Jaynal</forenames></author><author><keyname>Antony</keyname><forenames>Joseph</forenames></author><author><keyname>McGuinness</keyname><forenames>Kevin</forenames></author><author><keyname>Moran</keyname><forenames>Kieran</forenames></author><author><keyname>O'Connor</keyname><forenames>Noel E</forenames></author><author><keyname>Rebholz-Schuhmann</keyname><forenames>Dietrich</forenames></author><author><keyname>Newell</keyname><forenames>John</forenames></author></authors><title>Predicting knee osteoarthritis severity: comparative modeling based on
  patient's data and plain X-ray images</title><categories>eess.IV cs.CV cs.LG</categories><comments>Published in Nature Scientific Reports, 2019</comments><journal-ref>Scientific reports 9, no. 1 (2019): 5761</journal-ref><doi>10.1038/s41598-019-42215-9</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Knee osteoarthritis (KOA) is a disease that impairs knee function and causes
pain. A radiologist reviews knee X-ray images and grades the severity level of
the impairments according to the Kellgren and Lawrence grading scheme; a
five-point ordinal scale (0--4). In this study, we used Elastic Net (EN) and
Random Forests (RF) to build predictive models using patient assessment data
(i.e. signs and symptoms of both knees and medication use) and a convolution
neural network (CNN) trained using X-ray images only. Linear mixed effect
models (LMM) were used to model the within subject correlation between the two
knees. The root mean squared error for the CNN, EN, and RF models was 0.77,
0.97, and 0.94 respectively. The LMM shows similar overall prediction accuracy
as the EN regression but correctly accounted for the hierarchical structure of
the data resulting in more reliable inference. Useful explanatory variables
were identified that could be used for patient monitoring before X-ray imaging.
Our analyses suggest that the models trained for predicting the KOA severity
levels achieve comparable results when modeling X-ray images and patient data.
The subjectivity in the KL grade is still a primary concern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08892</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08892</id><created>2019-08-23</created><authors><author><keyname>Hossan</keyname><forenames>Md Tanvir</forenames></author></authors><title>Localization using Optical Camera Communication and Photogrammetry for
  Wireless Networking Applications</title><categories>eess.SP</categories><comments>100 pages, 46 figures, MSc thesis paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Localization defines a term to describe the identifying process of a location
within the space of two-dimensional (2D) space or three-dimensional (3D). A
localization scheme is an important concern for connecting sensor nodes in
remote locations. The demand of localization in wireless networking is
increased due to the availability of mobile devices as well as scope for
billion-dollar market in e-commence sector. Moreover, a new era has written
with internet-of-things, which boost this demand 100 times than ever before.
Importance of localization applications is considered in both indoor and
outdoor environments. Due to several advantages, LED and camera based
positioning is more demanding over radio frequency based localization. Using
the existing light-emitting diodes (LEDs) based illumination infrastructure it
is possible to compute the coordinates of the camera, whereas cameras are
embedded/installed in mobile objects, such as smartphone, vehicle. Optical
camera communication (OCC) and photogrammetry are two important technologies to
measure the position of these mobile objects. These technologies based
localization scheme for both smartphone and vehicle should be cost effective
and can be deployed with little modification of the existing infrastructures. I
proposed two different schemes (i.e., indoor and outdoor environments) to
localize these objects with OCC and photogrammetry techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08898</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08898</id><created>2019-08-23</created><authors><author><keyname>Kim</keyname><forenames>Sunwoo</forenames></author><author><keyname>Maity</keyname><forenames>Mrinmoy</forenames></author><author><keyname>Kim</keyname><forenames>Minje</forenames></author></authors><title>Incremental Binarization On Recurrent Neural Networks For Single-Channel
  Source Separation</title><categories>eess.AS cs.LG cs.SD eess.SP</categories><comments>5 pages, 1 figure, 2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP 2019)</comments><doi>10.1109/ICASSP.2019.8682595</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a Bitwise Gated Recurrent Unit (BGRU) network for the
single-channel source separation task. Recurrent Neural Networks (RNN) require
several sets of weights within its cells, which significantly increases the
computational cost compared to the fully-connected networks. To mitigate this
increased computation, we focus on the GRU cells and quantize the feedforward
procedure with binarized values and bitwise operations. The BGRU network is
trained in two stages. The real-valued weights are pretrained and transferred
to the bitwise network, which are then incrementally binarized to minimize the
potential loss that can occur from a sudden introduction of quantization. As
the proposed binarization technique turns only a few randomly chosen parameters
into their binary versions, it gives the network training procedure a chance to
gently adapt to the partly quantized version of the network. It eventually
achieves the full binarization by incrementally increasing the amount of
binarization over the iterations. Our experiments show that the proposed BGRU
method produces source separation results greater than that of a real-valued
fully connected network, with 11-12 dB mean Signal-to-Distortion Ratio (SDR). A
fully binarized BGRU still outperforms a Bitwise Neural Network (BNN) by 1-2 dB
even with less number of layers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08900</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08900</id><created>2019-08-23</created><authors><author><keyname>Cisek</keyname><forenames>Grzegorz</forenames></author><author><keyname>Zieli&#x144;ski</keyname><forenames>Tomasz P.</forenames></author></authors><title>Frequency-Domain Modeling of OFDM Transmission with Insufficient Cyclic
  Prefix using Toeplitz Matrices</title><categories>eess.SP cs.NI</categories><comments>Conference: IEEE VTC-Fall 2018, 5 pages, 3 figures</comments><journal-ref>In proc. IEEE 88th Vehicular Technology Conference (VTC-Fall),
  Chicago, USA, 27-30 August 2018</journal-ref><doi>10.1109/VTCFall.2018.8690835</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel mathematical framework is proposed to model Intersymbol Interference
(ISI) phenomenon in wireless communication systems based on Orthogonal
Frequency Division Multiplexing (OFDM) with or without cyclic prefix. The
framework is based on a new formula to calculate the Fast Fourier Transform
(FFT) of a triangular Toeplitz matrix, which is derived and proven in this
paper. It is shown that distortion inducted by the ISI from a given subcarrier
is the most significant for the closest subcarriers and the contribution decays
as the distance between subcarriers grows. According to numerical experiments,
knowledge of ISI coefficients concentrated around the diagonal of Channel
Frequency Response (CFR) matrix improves the receiver's error floor
significantly. The potential use of the framework for real-time frequency
domain channel simulation was also investigated and demonstrated to be more
efficient than conventional time domain Tapped Delay Line (TDL) model when a
number of simulated users is high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08918</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08918</id><created>2019-08-20</created><authors><author><keyname>Lamarca</keyname><forenames>Jose</forenames></author><author><keyname>Parashar</keyname><forenames>Shaifali</forenames></author><author><keyname>Bartoli</keyname><forenames>Adrien</forenames></author><author><keyname>Montiel</keyname><forenames>J. M. M.</forenames></author></authors><title>DefSLAM: Tracking and Mapping of Deforming Scenes from Monocular
  Sequences</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first monocular SLAM capable of operating in deforming scenes
in real-time. Our DefSLAM approach fuses isometric Shape-from-Template (SfT)
and Non-Rigid Structure-from-Motion (NRSfM) techniques to deal with the
exploratory sequences typical of SLAM. A deformation tracking thread recovers
the pose of the camera and the deformation of the observed map at frame rate by
means of SfT. A deformation mapping thread runs in parallel to update the
template at keyframe rate by means of NRSfM with a batch of covisible
keyframes. In our experiments, DefSLAM processes sequences of deforming scenes
both in a laboratory controlled experiment and in medical endoscopy sequences,
being able to produce accurate 3D models of the scene with respect to the
moving camera.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08930</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08930</id><created>2019-08-20</created><authors><author><keyname>Mahdizadehaghdam</keyname><forenames>Shahin</forenames></author><author><keyname>Panahi</keyname><forenames>Ashkan</forenames></author><author><keyname>Krim</keyname><forenames>Hamid</forenames></author></authors><title>Sparse Generative Adversarial Network</title><categories>cs.CV cs.LG eess.IV</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new approach to Generative Adversarial Networks (GANs) to
achieve an improved performance with additional robustness to its so-called and
well recognized mode collapse. We first proceed by mapping the desired data
onto a frame-based space for a sparse representation to lift any limitation of
small support features prior to learning the structure. To that end we start by
dividing an image into multiple patches and modifying the role of the
generative network from producing an entire image, at once, to creating a
sparse representation vector for each image patch. We synthesize an entire
image by multiplying generated sparse representations to a pre-trained
dictionary and assembling the resulting patches. This approach restricts the
output of the generator to a particular structure, obtained by imposing a Union
of Subspaces (UoS) model to the original training data, leading to more
realistic images, while maintaining a desired diversity. To further regularize
GANs in generating high-quality images and to avoid the notorious mode-collapse
problem, we introduce a third player in GANs, called reconstructor. This player
utilizes an auto-encoding scheme to ensure that first, the input-output
relation in the generator is injective and second each real image corresponds
to some input noise. We present a number of experiments, where the proposed
algorithm shows a remarkably higher inception score compared to the equivalent
conventional GANs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08947</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08947</id><created>2019-08-24</created><updated>2019-09-04</updated><authors><author><keyname>Yousefi</keyname><forenames>Sahar</forenames></author><author><keyname>Hirschler</keyname><forenames>Lydiane</forenames></author><author><keyname>van der Plas</keyname><forenames>Merlijn</forenames></author><author><keyname>Elmahdy</keyname><forenames>Mohamed S.</forenames></author><author><keyname>Sokooti</keyname><forenames>Hessam</forenames></author><author><keyname>Van Osch</keyname><forenames>Matthias</forenames></author><author><keyname>Staring</keyname><forenames>Marius</forenames></author></authors><title>Fast Dynamic Perfusion and Angiography Reconstruction using an
  end-to-end 3D Convolutional Neural Network</title><categories>eess.IV cs.CV</categories><comments>11 pages, 4 figures, 1 table, conference paper, accepted in MLMIR2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hadamard time-encoded pseudo-continuous arterial spin labeling (te-pCASL) is
a signal-to-noise ratio (SNR)-efficient MRI technique for acquiring dynamic
pCASL signals that encodes the temporal information into the labeling according
to a Hadamard matrix. In the decoding step, the contribution of each sub-bolus
can be isolated resulting in dynamic perfusion scans. When acquiring te-ASL
both with and without flow-crushing, the ASL-signal in the arteries can be
isolated resulting in 4D-angiographic information. However, obtaining
multi-timepoint perfusion and angiographic data requires two acquisitions. In
this study, we propose a 3D Dense-Unet convolutional neural network with a
multi-level loss function for reconstructing multi-timepoint perfusion and
angiographic information from an interleaved $50\%$-sampled crushed and
$50\%$-sampled non-crushed data, thereby negating the additional scan time. We
present a framework to generate dynamic pCASL training and validation data,
based on models of the intravascular and extravascular te-pCASL signals. The
proposed network achieved SSIM values of $97.3 \pm 1.1$ and $96.2 \pm 11.1$
respectively for 4D perfusion and angiographic data reconstruction for 313 test
data-sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08966</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08966</id><created>2019-08-23</created><authors><author><keyname>Shah</keyname><forenames>Syed Hashim Ali</forenames></author><author><keyname>Aditya</keyname><forenames>Sundar</forenames></author><author><keyname>Dutta</keyname><forenames>Sourjya</forenames></author><author><keyname>Slezak</keyname><forenames>Christopher</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author></authors><title>Power Efficient Discontinuous Reception in THz and mmWave Wireless
  Systems</title><categories>eess.SP</categories><comments>The paper has been accepted and presented at IEEE SPAWC 2019. It is
  yet to be published on IEEE Xplore</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Discontinuous reception (DRX), where a user equip-ment (UE) temporarily
disables its receiver, is a critical power saving feature in modern cellular
systems. DRX is likely tobe particularly aggressively used in the mmWave and
THzfrequencies due to the high front end power consumption. A keychallenge of
DRX in these frequencies is that individual links are directional and highly
susceptible to blockage. MmWave and THz UEs will therefore likely need to
monitor multiple cells in multiple directions to ensure continuous reliable
connectivity.This work proposes a novel, heuristic algorithm to dynamically
select the cells to monitor to attempt to optimally trade-off link reliability
and power consumption. The paper provides preliminary estimates of connected
mode DRX mode consumption using detailed and realistic statistical models of
blockers at both 28 and 140 GHz. It is found that although blockage dynamics
are faster at 140 GHz, reliable connectivity at low power can be maintained
with sufficient macro-diversity and link prediction
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08976</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08976</id><created>2019-08-23</created><authors><author><keyname>Gupta</keyname><forenames>Udit</forenames></author><author><keyname>Reagen</keyname><forenames>Brandon</forenames></author><author><keyname>Pentecost</keyname><forenames>Lillian</forenames></author><author><keyname>Donato</keyname><forenames>Marco</forenames></author><author><keyname>Tambe</keyname><forenames>Thierry</forenames></author><author><keyname>Rush</keyname><forenames>Alexander M.</forenames></author><author><keyname>Wei</keyname><forenames>Gu-Yeon</forenames></author><author><keyname>Brooks</keyname><forenames>David</forenames></author></authors><title>MASR: A Modular Accelerator for Sparse RNNs</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent neural networks (RNNs) are becoming the de facto solution for
speech recognition. RNNs exploit long-term temporal relationships in data by
applying repeated, learned transformations. Unlike fully-connected (FC) layers
with single vector matrix operations, RNN layers consist of hundreds of such
operations chained over time. This poses challenges unique to RNNs that are not
found in convolutional neural networks (CNNs) or FC models, namely large
dynamic activation. In this paper we present MASR, a principled and modular
architecture that accelerates bidirectional RNNs for on-chip ASR. MASR is
designed to exploit sparsity in both dynamic activations and static weights.
The architecture is enhanced by a series of dynamic activation optimizations
that enable compact storage, ensure no energy is wasted computing null
operations, and maintain high MAC utilization for highly parallel accelerator
designs. In comparison to current state-of-the-art sparse neural network
accelerators (e.g., EIE), MASR provides 2x area 3x energy, and 1.6x performance
benefits. The modular nature of MASR enables designs that efficiently scale
from resource-constrained low-power IoT applications to large-scale, highly
parallel datacenter deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08979</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08979</id><created>2019-08-23</created><authors><author><keyname>Jaiswal</keyname><forenames>Mimansa</forenames></author><author><keyname>Aldeneh</keyname><forenames>Zakaria</forenames></author><author><keyname>Provost</keyname><forenames>Emily Mower</forenames></author></authors><title>Controlling for Confounders in Multimodal Emotion Classification via
  Adversarial Learning</title><categories>cs.LG cs.CL cs.SD eess.AS stat.ML</categories><comments>10 pages, ICMI 2019</comments><doi>10.1145/3340555.3353731</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various psychological factors affect how individuals express emotions. Yet,
when we collect data intended for use in building emotion recognition systems,
we often try to do so by creating paradigms that are designed just with a focus
on eliciting emotional behavior. Algorithms trained with these types of data
are unlikely to function outside of controlled environments because our
emotions naturally change as a function of these other factors. In this work,
we study how the multimodal expressions of emotion change when an individual is
under varying levels of stress. We hypothesize that stress produces modulations
that can hide the true underlying emotions of individuals and that we can make
emotion recognition algorithms more generalizable by controlling for variations
in stress. To this end, we use adversarial networks to decorrelate stress
modulations from emotion representations. We study how stress alters acoustic
and lexical emotional predictions, paying special attention to how modulations
due to stress affect the transferability of learned emotion recognition models
across domains. Our results show that stress is indeed encoded in trained
emotion classifiers and that this encoding varies across levels of emotions and
across the lexical and acoustic modalities. Our results also show that emotion
recognition models that control for stress during training have better
generalizability when applied to new domains, compared to models that do not
control for stress during training. We conclude that is is necessary to
consider the effect of extraneous psychological factors when building and
testing emotion recognition models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08982</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08982</id><created>2019-08-23</created><authors><author><keyname>Naidji</keyname><forenames>Ilyes</forenames></author><author><keyname>Smida</keyname><forenames>Moncef Ben</forenames></author><author><keyname>Khalgui</keyname><forenames>Mohamed</forenames></author><author><keyname>Bachir</keyname><forenames>Abdelmalik</forenames></author></authors><title>Non Cooperative Game Theoretic Approach for Residential Energy
  Management in Smart Grid</title><categories>eess.SY cs.SY</categories><comments>The 32nd Annual European Simulation and Modelling Conference</comments><journal-ref>in Proc. ESM conference 32 (2018) 164-170</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Demand side management (DSM) is one of the main functionalities of the smart
grid as it allows the consumer to adjust its energy consumption for an
efficient energy management. Most of the existing DSM techniques aim at
minimizing the energy cost while not considering the comfort of consumers.
Therefore, maintaining a trade-off between these two conflicting objectives is
still a challenging task. This paper proposes a novel DSM approach for
residential consumers based on a non-cooperative game theoretic approach, where
each player is encouraged to reshape its electricity consumption pattern
through the dynamic pricing policy applied by the smart grid operator. The
players are guided to select the best strategy that consists of scheduling
their electric appliances in order to minimize the daily energy cost and their
discomfort level. The Nash Equilibrium of the energy management game is
achieved using Non-Sorting Genetic Algorithm NSGA-II. Simulation results show
the effectiveness of the distributed non cooperative game approach for the
residential energy management problem where an appreciable energy cost
reduction is reached while maintaining the discomfort in an acceptable level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08992</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.08992</id><created>2019-08-13</created><authors><author><keyname>Wijekoon</keyname><forenames>Anjana</forenames></author><author><keyname>Wiratunga</keyname><forenames>Nirmalie</forenames></author><author><keyname>Cooper</keyname><forenames>Kay</forenames></author></authors><title>MEx: Multi-modal Exercises Dataset for Human Activity Recognition</title><categories>cs.CV cs.AI cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MEx: Multi-modal Exercises Dataset is a multi-sensor, multi-modal dataset,
implemented to benchmark Human Activity Recognition(HAR) and Multi-modal Fusion
algorithms. Collection of this dataset was inspired by the need for recognising
and evaluating quality of exercise performance to support patients with
Musculoskeletal Disorders(MSD). We select 7 exercises regularly recommended for
MSD patients by physiotherapists and collected data with four sensors a
pressure mat, a depth camera and two accelerometers. The dataset contains three
data modalities; numerical time-series data, video data and pressure sensor
data posing interesting research challenges when reasoning for HAR and Exercise
Quality Assessment. This paper presents our evaluation of the dataset on number
of standard classification algorithms for the HAR task by comparing different
feature representation algorithms for each sensor. These results set a
reference performance for each individual sensor that expose their strengths
and weaknesses for the future tasks. In addition we visualise pressure mat data
to explore the potential of the sensor to capture exercise performance quality.
With the recent advancement in multi-modal fusion, we also believe MEx is a
suitable dataset to benchmark not only HAR algorithms, but also fusion
algorithms of heterogeneous data types in multiple application domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09000</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09000</id><created>2019-08-15</created><authors><author><keyname>Jaramillo-Avila</keyname><forenames>Uziel</forenames></author><author><keyname>Anderson</keyname><forenames>Sean R.</forenames></author></authors><title>Foveated image processing for faster object detection and recognition in
  embedded systems using deep convolutional neural networks</title><categories>cs.CV eess.IV</categories><journal-ref>Biomimetic and Biohybrid Systems (2019) 193--204</journal-ref><doi>10.1007/978-3-030-24741-6_17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object detection and recognition algorithms using deep convolutional neural
networks (CNNs) tend to be computationally intensive to implement. This
presents a particular challenge for embedded systems, such as mobile robots,
where the computational resources tend to be far less than for workstations. As
an alternative to standard, uniformly sampled images, we propose the use of
foveated image sampling here to reduce the size of images, which are faster to
process in a CNN due to the reduced number of convolution operations. We
evaluate object detection and recognition on the Microsoft COCO database, using
foveated image sampling at different image sizes, ranging from 416x416 to 96x96
pixels, on an embedded GPU -- an NVIDIA Jetson TX2 with 256 CUDA cores. The
results show that it is possible to achieve a 4x speed-up in frame rates, from
3.59 FPS to 15.24 FPS, using 416x416 and 128x128 pixel images respectively. For
foveated sampling, this image size reduction led to just a small decrease in
recall performance in the foveal region, to 92.0% of the baseline performance
with full-sized images, compared to a significant decrease to 50.1% of baseline
recall performance in uniformly sampled images, demonstrating the advantage of
foveated sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09003</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09003</id><created>2019-08-14</created><authors><author><keyname>Sai</keyname><forenames>S. Mohan</forenames></author><author><keyname>Gopichand</keyname><forenames>G.</forenames></author><author><keyname>Reddy</keyname><forenames>C. Vikas</forenames></author><author><keyname>Teja</keyname><forenames>K. Mona</forenames></author></authors><title>High Accurate Unhealthy Leaf Detection</title><categories>cs.CV eess.IV</categories><comments>Page 4, 5 with 1 figure, and page 6 with 2 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  India is an agriculture-dependent country. As we all know that farming is the
backbone of our country it is our responsibility to preserve the crops.
However, we cannot stop the destruction of crops by natural calamities at least
we have to try to protect our crops from diseases. To, detect a plant disease
we need a fast automatic way. So, this paper presents a model to identify the
particular disease of plant leaves at early stages so that we can prevent or
take a remedy to stop spreading of the disease. This proposed model is made
into five sessions. Image preprocessing includes the enhancement of the low
light image done using inception modules in CNN. Low-resolution image
enhancement is done using an Adversarial Neural Network. This also includes
Conversion of RGB Image to YCrCb color space. Next, this paper presents a
methodology for image segmentation which is an important aspect for identifying
the disease symptoms. This segmentation is done using the genetic algorithm.
Due to this process the segmentation of the leaf Image this helps in detection
of the leaf mage automatically and classifying. Texture extraction is done
using the statistical model called GLCM and finally, the classification of the
diseases is done using the SVM using Different Kernels with the high accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09005</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09005</id><created>2019-08-18</created><authors><author><keyname>Klikunova</keyname><forenames>Anna</forenames></author><author><keyname>Khoperskov</keyname><forenames>Alexander</forenames></author></authors><title>Creation of digital elevation models for river floodplains</title><categories>cs.CV eess.IV physics.geo-ph</categories><comments>10 pages, 9 figures, V International conference Information
  Technology and Nanotechnology. Session Image Processing and Earth Remote
  Sensing (IPERS-ITNT 2019), Samara, Russia, May 21-24, 2019</comments><msc-class>86-08, 76D99</msc-class><journal-ref>CEUR Workshop Proceedings, 2019, vol.2391, pp.275-284</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A procedure for constructing a digital elevation model (DEM) of the northern
part of the Volga-Akhtuba interfluve is described. The basis of our DEM is the
elevation matrix of Shuttle Radar Topography Mission (SRTM) for which we
carried out the refinement and updating of spatial data using satellite
imagery, GPS data, depth measurements of the River Volga and River Akhtuba
stream beds. The most important source of high-altitude data for the
Volga-Akhtuba floodplain (VAF) can be the results of observations of the
coastlines dynamics of small reservoirs (lakes, eriks, small channels) arising
in the process of spring flooding and disappearing during low-flow periods. A
set of digitized coastlines at different times of flooding can significantly
improve the quality of the DEM. The method of constructing a digital elevation
model includes an iterative procedure that uses the results of morphostructural
analysis of the DEM and the numerical hydrodynamic simulations of the VAF
flooding based on the shallow water model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09006</identifier>
 <datestamp>2019-12-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09006</id><created>2019-08-16</created><authors><author><keyname>Liu</keyname><forenames>Jeffrey</forenames></author><author><keyname>Strohschein</keyname><forenames>David</forenames></author><author><keyname>Samsi</keyname><forenames>Siddharth</forenames></author><author><keyname>Weinert</keyname><forenames>Andrew</forenames></author></authors><title>Large Scale Organization and Inference of an Imagery Dataset for Public
  Safety</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>Accepted for publication IEEE HPEC 2019</comments><doi>10.1109/HPEC.2019.8916437</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video applications and analytics are routinely projected as a stressing and
significant service of the Nationwide Public Safety Broadband Network. As part
of a NIST PSCR funded effort, the New Jersey Office of Homeland Security and
Preparedness and MIT Lincoln Laboratory have been developing a computer vision
dataset of operational and representative public safety scenarios. The scale
and scope of this dataset necessitates a hierarchical organization approach for
efficient compute and storage. We overview architectural considerations using
the Lincoln Laboratory Supercomputing Cluster as a test architecture. We then
describe how we intelligently organized the dataset across LLSC and evaluated
it with large scale imagery inference across terabytes of data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09009</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09009</id><created>2019-08-19</created><authors><author><keyname>Oladipupo</keyname><forenames>Gideon Gbenga</forenames></author></authors><title>Development of a Robotic System for Automatic Wheel Removal and Fitting</title><categories>cs.CV cs.RO eess.IV</categories><comments>8 pages, 17 figures and 3 tables</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This paper discusses the image processing and computer vision algorithms for
real time detection and tracking of a sample wheel of a vehicle. During the
manual tyre changing process, spinal and other muscular injuries are common and
even more serious injuries have been recorded when occasionally, tyres fail
(burst) during this process. It, therefore, follows that the introduction of a
robotic system to take over this process would be a welcome development. This
work discusses various useful applicable algorithms, Circular Hough Transform
(CHT) as well as Continuously adaptive mean shift (Camshift) and provides some
of the software solutions which can be deployed with a robotic mechanical arm
to make the task of tyre changing faster, safer and more efficient. Image
acquisition and software to accurately detect and classify specific objects of
interest were implemented successfully, outcomes were discussed and areas for
further studies suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09033</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09033</id><created>2019-08-23</created><authors><author><keyname>Zhang</keyname><forenames>Weite</forenames></author><author><keyname>Gomez-Sousa</keyname><forenames>Hipolito</forenames></author><author><keyname>Heredia-Juesas</keyname><forenames>Juan</forenames></author><author><keyname>Martinez-Lorenzo</keyname><forenames>Jose A.</forenames></author></authors><title>Single-Frequency Imaging and Material Characterization using
  Reconfigurable Reflectarrays</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a physical and geometrical optics based single-frequency
imaging scheme is proposed for personal screening systems using multiple
reconfigurable reflectarrays. This scheme is able to not only reconstruct
profiles of potential threat objects on human body, but also identify their
materials in terms of their complex relative permittivities. Both simulation
and experiment are carried out to detect dielectric objects at a microwave
frequency of 24.16 GHz. The object profiles and complex relative permittivities
are obtained with both high accuracy and computational efficiency, which show
great potentials for security imaging where inspection of human body for threat
materials, such as narcotics, explosives, and other types of contraband, is
very common.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09034</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09034</id><created>2019-08-23</created><authors><author><keyname>Guo</keyname><forenames>Yi</forenames></author><author><keyname>Rotea</keyname><forenames>Mario</forenames></author><author><keyname>Summers</keyname><forenames>Tyler</forenames></author></authors><title>Stochastic Dynamic Programming for Wind Farm Power Maximization</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wind farms can increase annual energy production (AEP) with advanced control
algorithms by coordinating the set points of individual turbine controllers
across the farm. However, it remains a significant challenge to achieve
performance improvements in practice because of the difficulty of utilizing
models that capture pertinent complex aerodynamic phenomena while remaining
amenable to control design. We formulate a multi-stage stochastic optimal
control problem for wind farm power maximization and show that it can be solved
analytically via dynamic programming. In particular, our model incorporates
state- and input-dependent multiplicative noise whose distributions capture
stochastic wind fluctuations. The optimal control policies and value functions
explicitly incorporate the moments of these distributions, establishing a
connection between wind flow data and optimal feedback control. We illustrate
the results with numerical experiments that demonstrate the advantages of our
approach over existing methods based on deterministic models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09043</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09043</id><created>2019-08-23</created><authors><author><keyname>Hassan-Moghaddam</keyname><forenames>Sepideh</forenames></author><author><keyname>Jovanovi&#x107;</keyname><forenames>Mihailo R.</forenames></author></authors><title>Proximal gradient flow and Douglas-Rachford splitting dynamics: global
  exponential stability via integral quadratic constraints</title><categories>math.OC cs.LG cs.SY eess.SY math.DS</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many large-scale and distributed optimization problems can be brought into a
composite form in which the objective function is given by the sum of a smooth
term and a nonsmooth regularizer. Such problems can be solved via a proximal
gradient method and its variants, thereby generalizing gradient descent to a
nonsmooth setup. In this paper, we view proximal algorithms as dynamical
systems and leverage techniques from control theory to study their global
properties. In particular, for problems with strongly convex objective
functions, we utilize the theory of integral quadratic constraints to prove
global exponential stability of the differential equations that govern the
evolution of proximal gradient and Douglas-Rachford splitting flows. In our
analysis, we use the fact that these algorithms can be interpreted as
variable-metric gradient methods on the forward-backward and the
Douglas-Rachford envelopes and exploit structural properties of the nonlinear
terms that arise from the gradient of the smooth part of the objective function
and the proximal operator associated with the nonsmooth regularizer. We also
demonstrate that these envelopes can be obtained from the augmented Lagrangian
associated with the original nonsmooth problem and establish conditions for
global exponential convergence even in the absence of strong convexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09047</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09047</id><created>2019-08-23</created><authors><author><keyname>Singh</keyname><forenames>Rohit</forenames></author><author><keyname>Sicker</keyname><forenames>Douglas</forenames></author></authors><title>Parameter Modeling for Small-Scale Mobility in Indoor THz Communication</title><categories>cs.NI eess.SP</categories><comments>To appear in IEEE GLOBECOM 2019. The document has 6 pages, 16
  figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite such challenges as high path loss and equipment cost, THz
communication is becoming one of the potentially viable means through which
ultra-high data rate can be achieved. To compensate for the high path loss, we
present parameter modeling for indoor THz communication. To maximize efficient
and opportunistic use of resources, we analyze the potential workarounds for a
single access point to satisfy most of the mobile terminals by varying such
parameters as humidity, distance, frequency windows, beamwidths, antenna
placement, and user mobility type. One promising parameter is antenna
beamwidth, where narrower beams results in higher antenna gain. However, this
can lead to &quot;\textit{beamwidth dilemma}&quot; scenario, where narrower beamwidth can
result in significant outages due to device mobility and orientation. In this
paper, we address this challenge by presenting a mobility model that performs
an extensive analysis of different human mobility scenarios, where each
scenario has different data rate demands and movement patterns. We observe that
for mobile users, there are optimal beamwidths that are affected by the
mobility type (high mobility, constrained mobility, and low mobility) and AP
placement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09049</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09049</id><created>2019-08-23</created><authors><author><keyname>Park</keyname><forenames>Sangwoo</forenames></author><author><keyname>Jang</keyname><forenames>Hyeryung</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Kang</keyname><forenames>Joonhyuk</forenames></author></authors><title>Learning to Demodulate from Few Pilots via Offline and Online
  Meta-Learning</title><categories>eess.SP cs.IT math.IT</categories><comments>submitted for journal publication, subsumes (arXiv:1903.02184)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers an Internet-of-Things (IoT) scenario in which devices
transmit sporadically using short packets with few pilot symbols over a fading
channel. Devices are characterized by unique transmission non-idealities, such
as amplifiers' non-linear transfer functions. The number of pilots is generally
insufficient to obtain an accurate estimate of the end-to-end channel, which
includes the effects of fading and of the transmission-side distortion. This
paper proposes to tackle this problem by using meta-learning. Accordingly,
pilots from previous IoT transmissions are used as meta-training data in order
to train a demodulator that is able to quickly adapt to new end-to-end channel
conditions from few pilots. Various state-of-the-art meta-learning schemes are
adapted to the problem at hand and evaluated, including MAML, FOMAML, REPTILE,
and CAVIA. Both offline and online solutions are developed. In the latter case,
an integrated online meta-learning and adaptive pilot number selection scheme
is proposed. Numerical results validate the advantages of meta-learning as
compared to training schemes that either do not leverage prior transmissions or
apply a standard joint learning algorithms on previously received data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09060</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09060</id><created>2019-08-23</created><authors><author><keyname>Wu</keyname><forenames>Zhengyang</forenames></author><author><keyname>Rajendran</keyname><forenames>Srivignesh</forenames></author><author><keyname>van As</keyname><forenames>Tarrence</forenames></author><author><keyname>Zimmermann</keyname><forenames>Joelle</forenames></author><author><keyname>Badrinarayanan</keyname><forenames>Vijay</forenames></author><author><keyname>Rabinovich</keyname><forenames>Andrew</forenames></author></authors><title>EyeNet: A Multi-Task Network for Off-Axis Eye Gaze Estimation and User
  Understanding</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Eye gaze estimation and simultaneous semantic understanding of a user through
eye images is a crucial component in Virtual and Mixed Reality; enabling energy
efficient rendering, multi-focal displays and effective interaction with 3D
content. In head-mounted VR/MR devices the eyes are imaged off-axis to avoid
blocking the user's gaze, this view-point makes drawing eye related inferences
very challenging. In this work, we present EyeNet, the first single deep neural
network which solves multiple heterogeneous tasks related to eye gaze
estimation and semantic user understanding for an off-axis camera setting. The
tasks include eye segmentation, blink detection, emotive expression
classification, IR LED glints detection, pupil and cornea center estimation. To
train EyeNet end-to-end we employ both hand labelled supervision and model
based supervision. We benchmark all tasks on MagicEyes, a large and new dataset
of 587 subjects with varying morphology, gender, skin-color, make-up and
imaging conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09064</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09064</id><created>2019-08-23</created><authors><author><keyname>Banagar</keyname><forenames>Morteza</forenames></author><author><keyname>Dhillon</keyname><forenames>Harpreet S.</forenames></author></authors><title>Fundamentals of Drone Cellular Network Analysis under Random Waypoint
  Mobility Model</title><categories>cs.IT eess.SP math.IT</categories><comments>Journal submission based on this work is available at
  arXiv:1908.05243</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the first stochastic geometry-based performance
analysis of a drone cellular network in which drone base stations (DBSs) are
initially distributed based on a Poisson point process (PPP) and move according
to a random waypoint (RWP) mobility model. The serving DBS for a typical user
equipment (UE) on the ground is selected based on the nearest neighbor
association policy. We further assume two service models for the serving DBS:
(i) UE independent model (UIM), and (ii) UE dependent model (UDM). All the
other DBSs are considered as interfering DBSs for the typical UE. We introduce
a simplified RWP (SRWP) mobility model to describe the movement of interfering
DBSs and characterize its key distributional properties that are required for
our analysis. Building on these results, we analyze the interference field as
seen by the typical UE for both the UIM and the UDM using displacement theorem,
which forms the basis for characterizing the average rate at the typical UE as
a function of time. To the best of our knowledge, this is the first work that
analyzes the performance of a mobile drone network in which the drones follow
an RWP mobility model on an infinite plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09067</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09067</id><created>2019-08-23</created><authors><author><keyname>Eminaga</keyname><forenames>Okyaz</forenames></author><author><keyname>Abbas</keyname><forenames>Mahmoud</forenames></author><author><keyname>Kunder</keyname><forenames>Christian</forenames></author><author><keyname>Loening</keyname><forenames>Andreas M.</forenames></author><author><keyname>Shen</keyname><forenames>Jeanne</forenames></author><author><keyname>Brooks</keyname><forenames>James D.</forenames></author><author><keyname>Langlotz</keyname><forenames>Curtis P.</forenames></author><author><keyname>Rubin</keyname><forenames>Daniel L.</forenames></author></authors><title>Plexus Convolutional Neural Network (PlexusNet): A novel neural network
  architecture for histologic image analysis</title><categories>q-bio.QM cs.AI cs.CV eess.IV q-bio.TO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different convolutional neural network (CNN) models have been tested for
their application in histologic imaging analyses. However, these models are
prone to overfitting due to their large parameter capacity, requiring more data
and expensive computational resources for model training. Given these
limitations, we developed and tested PlexusNet for histologic evaluation using
a single GPU by a batch dimension of 16x512x512x3. We utilized 62 Hematoxylin
and eosin stain (H&amp;E) annotated histological images of radical prostatectomy
cases from TCGA-PRAD and Stanford University, and 24 H&amp;E whole-slide images
with hepatocellular carcinoma from TCGA-LIHC diagnostic histology images. Base
models were DenseNet, Inception V3, and MobileNet and compared with PlexusNet.
The dice coefficient (DSC) was evaluated for each model. PlexusNet delivered
comparable classification performance (DSC at patch level: 0.89) for H&amp;E
whole-slice images in distinguishing prostate cancer from normal tissues. The
parameter capacity of PlexusNet is 9 times smaller than MobileNet or 58 times
smaller than Inception V3, respectively. Similar findings were observed in
distinguishing hepatocellular carcinoma from non-cancerous liver histologies
(DSC at patch level: 0.85). As conclusion, PlexusNet represents a novel model
architecture for histological image analysis that achieves classification
performance comparable to the base models while providing orders-of-magnitude
memory savings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09070</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09070</id><created>2019-08-23</created><authors><author><keyname>Noormohammadpour</keyname><forenames>Max</forenames></author><author><keyname>Srivastava</keyname><forenames>Ajitesh</forenames></author><author><keyname>Raghavendra</keyname><forenames>Cauligi S.</forenames></author></authors><title>Optimizing Inter-Datacenter Tail Flow Completion Times using Best
  Worst-case Routing</title><categories>cs.NI cs.PF cs.SY eess.SY</categories><comments>Accepted for publication in the 2019 57th Annual Allerton Conference
  on Communication, Control, and Computing (Allerton)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flow routing over inter-datacenter networks is a well-known problem where the
network assigns a path to a newly arriving flow potentially according to the
network conditions and the properties of the new flow. An essential system-wide
performance metric for a routing algorithm is the flow completion times, which
affect the performance of applications running across multiple datacenters.
Current static and dynamic routing approaches do not take advantage of flow
size information in routing, which is practical in a controlled environment
such as inter-datacenter networks that are managed by the datacenter operators.
In this paper, we discuss Best Worst-case Routing (BWR), which aims at
optimizing the tail completion times of long-running flows over
inter-datacenter networks with non-uniform link capacities. Since finding the
path with the best worst-case completion time for a new flow is NP-Hard, we
investigate two heuristics, BWRH and BWRHF, which use two different upper
bounds on the worst-case completion times for routing. We evaluate BWRH and
BWRHF against several real WAN topologies and multiple traffic patterns.
Although BWRH better models the BWR problem, BWRH and BWRHF show negligible
difference across various system-wide performance metrics, while BWRHF being
significantly faster. Furthermore, we show that compared to other popular
routing heuristics, BWRHF can reduce the mean and tail flow completion times by
over $1.5\times$ and $2\times$, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09089</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09089</id><created>2019-08-24</created><authors><author><keyname>Hamza-Lup</keyname><forenames>Felix G.</forenames></author><author><keyname>Iacob</keyname><forenames>Ionut E.</forenames></author><author><keyname>Khan</keyname><forenames>Sushmita</forenames></author></authors><title>Web-enabled Intelligent System for Continuous Sensor Data Processing and
  Visualization</title><categories>eess.SP cs.HC</categories><journal-ref>ACM (2019)</journal-ref><doi>10.1145/3329714.3338127</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large number of sensors deployed in recent years in various setups and
their data is readily available in dedicated databases or in the cloud. Of
particular interest is real-time data processing and 3D visualization in
web-based user interfaces that facilitate spatial information understanding and
sharing, hence helping the decision making process for all the parties
involved. In this research, we provide a prototype system for near real-time,
continuous X3D-based visualization of processed sensor data for two significant
applications: thermal monitoring for residential/commercial buildings and
nitrogen cycle monitoring in water beds for aquaponics systems. As sensors are
sparsely placed, in each application, where they collect data for large periods
(of up to one year), we employ a Finite Differences Method and a Neural
Networks model to approximate data distribution in the entire volume.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09090</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09090</id><created>2019-08-24</created><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Huo</keyname><forenames>Yiming</forenames></author><author><keyname>Zhan</keyname><forenames>Jinlong</forenames></author><author><keyname>Wang</keyname><forenames>Dongming</forenames></author><author><keyname>Dong</keyname><forenames>Xiaodai</forenames></author><author><keyname>You</keyname><forenames>Xiaohu</forenames></author></authors><title>ADMM Enabled Hybrid Precoding in Wideband Distributed Phased Arrays
  Based MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 5 figures, accepted for publication at the 90th IEEE
  Vehicular Technology Conference (IEEE VTC Fall 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed phased arrays based multiple-input multiple-output (DPA-MIMO) is
a recently proposed highly reconfigurable architecture enabling both spatial
multiplexing and beamforming in millimeter-wave (mmWave) systems. In this work,
we focus on coping with the hybrid precoding for the wideband DPA-MIMO system
with orthogonal frequency division multiplexing (OFDM) modulation. More
specifically, we propose an alternating direction method of multipliers (ADMM)
enabled hybrid precoding approach based on an alternating optimization
framework, abbreviated to ADMM-AltMin, for such cooperative array-of-subarrays
structures. Simulation results show that the proposed ADMM-AltMin method
achieves favourable performance with practical quantization of phase shifters
taken into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09140</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09140</id><created>2019-08-24</created><authors><author><keyname>Wang</keyname><forenames>Shanshan</forenames></author><author><keyname>Chen</keyname><forenames>Yanxia</forenames></author><author><keyname>Xiao</keyname><forenames>Taohui</forenames></author><author><keyname>Ke</keyname><forenames>Ziwen</forenames></author><author><keyname>Liu</keyname><forenames>Qiegen</forenames></author><author><keyname>Zheng</keyname><forenames>Hairong</forenames></author></authors><title>LANTERN: learn analysis transform network for dynamic magnetic resonance
  imaging with small dataset</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes to learn analysis transform network for dynamic magnetic
resonance imaging (LANTERN) with small dataset. Integrating the strength of
CS-MRI and deep learning, the proposed framework is highlighted in three
components: (i) The spatial and temporal domains are sparsely constrained by
using adaptively trained CNN. (ii) We introduce an end-to-end framework to
learn the parameters in LANTERN to solve the difficulty of parameter selection
in traditional methods. (iii) Compared to existing deep learning reconstruction
methods, our reconstruction accuracy is better when the amount of data is
limited. Our model is able to fully exploit the redundancy in spatial and
temporal of dynamic MR images. We performed quantitative and qualitative
analysis of cardiac datasets at different acceleration factors (2x-11x) and
different undersampling modes. In comparison with state-of-the-art methods,
extensive experiments show that our method achieves consistent better
reconstruction performance on the MRI reconstruction in terms of three
quantitative metrics (PSNR, SSIM and HFEN) under different undersamling
patterns and acceleration factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09148</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09148</id><created>2019-08-24</created><authors><author><keyname>W&#x142;odarczyk</keyname><forenames>Tomasz</forenames></author><author><keyname>P&#x142;otka</keyname><forenames>Szymon</forenames></author><author><keyname>Trzci&#x144;ski</keyname><forenames>Tomasz</forenames></author><author><keyname>Rokita</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>Sochacki-W&#xf3;jcicka</keyname><forenames>Nicole</forenames></author><author><keyname>Lipa</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>W&#xf3;jcicki</keyname><forenames>Jakub</forenames></author></authors><title>Estimation of preterm birth markers with U-Net segmentation network</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Accepted at MICCAI Workshop on Perinatal, Preterm and Paediatric
  Image analysis (PIPPI) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preterm birth is the most common cause of neonatal death. Current diagnostic
methods that assess the risk of preterm birth involve the collection of
maternal characteristics and transvaginal ultrasound imaging conducted in the
first and second trimester of pregnancy. Analysis of the ultrasound data is
based on visual inspection of images by gynaecologist, sometimes supported by
hand-designed image features such as cervical length. Due to the complexity of
this process and its subjective component, approximately 30% of spontaneous
preterm deliveries are not correctly predicted. Moreover, 10% of the predicted
preterm deliveries are false-positives. In this paper, we address the problem
of predicting spontaneous preterm delivery using machine learning. To achieve
this goal, we propose to first use a deep neural network architecture for
segmenting prenatal ultrasound images and then automatically extract two
biophysical ultrasound markers, cervical length (CL) and anterior cervical
angle (ACA), from the resulting images. Our method allows to estimate
ultrasound markers without human oversight. Furthermore, we show that CL and
ACA markers, when combined, allow us to decrease false-negative ratio from 30%
to 18%. Finally, contrary to the current approaches to diagnostics methods that
rely only on gynaecologist's expertise, our method introduce objectively
obtained results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09167</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09167</id><created>2019-08-24</created><authors><author><keyname>Benenati</keyname><forenames>Emilio</forenames></author><author><keyname>Colombino</keyname><forenames>Marcello</forenames></author><author><keyname>Dall'Anese</keyname><forenames>Emiliano</forenames></author></authors><title>A tractable formulation for multi-period linearized optimal power flow
  in presence of thermostatically controlled loads</title><categories>eess.SY cs.SY</categories><comments>8 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a convex reformulation of a nonlinear constrained
optimization problem for Markov decision processes, and applies the technical
findings to optimal control problems for an ensemble of thermostatically
controlled loads (TCLs). The paper further explores the formulation and
solution of a (linearized) AC optimal power flow problem when one or more
ensembles of TCLs are connected to a power network. In particular, a receding
horizon controller is proposed, to simultaneously compute the optimal
set-points of distributed energy resources (DERs) in the grid and the optimal
switching signal for the TCLs. This formulation takes into account hardware
constraints of the DERs, operational constraints of the grid (e.g., voltage
limits), comfort of the TCL users, and ancillary services provision at the
substation. Numerical results are provided to verify the effectiveness of the
proposed methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09191</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09191</id><created>2019-08-24</created><authors><author><keyname>Ratnasingam</keyname><forenames>Sivalogeswaran</forenames></author></authors><title>Deep Camera: A Fully Convolutional Neural Network for Image Signal
  Processing</title><categories>eess.IV cs.CV</categories><comments>11 pages, 6 figures, conference:ICCV 2019 workshop: Learning for
  Computational Imaging (LCI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A conventional camera performs various signal processing steps sequentially
to reconstruct an image from a raw Bayer image. When performing these
processing in multiple stages the residual error from each stage accumulates in
the image and degrades the quality of the final reconstructed image. In this
paper, we present a fully convolutional neural network (CNN) to perform defect
pixel correction, denoising, white balancing, exposure correction, demosaicing,
color transform, and gamma encoding. To our knowledge, this is the first CNN
trained end-to-end to perform the entire image signal processing pipeline in a
camera. The neural network was trained using a large image database of raw
Bayer images. Through extensive experiments, we show that the proposed CNN
based image signal processing system performs better than the conventional
signal processing pipelines that perform the processing sequentially.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09215</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09215</id><created>2019-08-24</created><updated>2019-08-27</updated><authors><author><keyname>Guo</keyname><forenames>Pengfei</forenames></author><author><keyname>Li</keyname><forenames>Dawei</forenames></author><author><keyname>Li</keyname><forenames>Xingde</forenames></author></authors><title>Customized OCT images compression scheme with deep neural network</title><categories>eess.IV cs.CV</categories><comments>One of author disagrees to release this paper at Arxiv</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We customize an end-to-end image compression framework for retina OCT images
based on deep convolutional neural networks (CNNs). The customized compression
scheme consists of three parts: data Preprocessing, compression CNNs, and
reconstruction CNNs. Data preprocessing module reduces the speckle noise of the
OCT images and the segments out the region of interest. We added customized
skip connections between the compression CNNs and the reconstruction CNNs to
reserve the detail information and trained the two nets together with the
semantic segmented image patches from data preprocessing module. To train the
two networks sensitive to both low frequency information and high frequency
information, we adopted an objective function with two parts: A PatchGAN
discriminator to judge the high frequency information and a differentiable
MS-SSIM penalty to evaluate the low frequency information. The proposed
framework was trained and evaluated on a publicly available OCT dataset. The
evaluation showed above 99% similarity in terms of multi-scale structural
similarity (MS-SSIM) when the compression ratio is as high as 40. Furthermore,
the reconstructed images of compression ratio 80 from the proposed framework
even have better quality than that of compression ratio 20 from JPEG by visual
comparison. The testing result outperforms JPEG in term of both of MS-SSIM and
visualization, which is more obvious as the increase of compression ratio. Our
preliminary result indicates the huge potential of deep neural networks on
customized medical image compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09236</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09236</id><created>2019-08-24</created><updated>2019-10-16</updated><authors><author><keyname>Kusnur</keyname><forenames>Tushar</forenames></author><author><keyname>Mukherjee</keyname><forenames>Shohin</forenames></author><author><keyname>Saxena</keyname><forenames>Dhruv Mauria</forenames></author><author><keyname>Fukami</keyname><forenames>Tomoya</forenames></author><author><keyname>Koyama</keyname><forenames>Takayuki</forenames></author><author><keyname>Salzman</keyname><forenames>Oren</forenames></author><author><keyname>Likhachev</keyname><forenames>Maxim</forenames></author></authors><title>A Planning Framework for Persistent, Multi-UAV Coverage with Global
  Deconfliction</title><categories>cs.RO cs.AI cs.SY eess.SY</categories><comments>12th Conference on Field and Service Robotics, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Planning for multi-robot coverage seeks to determine collision-free paths for
a fleet of robots, enabling them to collectively observe points of interest in
an environment. Persistent coverage is a variant of traditional coverage where
coverage-levels in the environment decay over time. Thus, robots have to
continuously revisit parts of the environment to maintain a desired
coverage-level. Facilitating this in the real world demands we tackle numerous
subproblems. While there exist standard solutions to these subproblems, there
is no complete framework that addresses all of their individual challenges as a
whole in a practical setting. We adapt and combine these solutions to present a
planning framework for persistent coverage with multiple unmanned aerial
vehicles (UAVs). Specifically, we run a continuous loop of goal assignment and
globally deconflicting, kinodynamic path planning for multiple UAVs. We
evaluate our framework in simulation as well as the real world. In particular,
we demonstrate that (i) our framework exhibits graceful coverage given
sufficient resources, we maintain persistent coverage; if resources are
insufficient (e.g., having too few UAVs for a given size of the enviornment),
coverage-levels decay slowly and (ii) planning with global deconfliction in our
framework incurs a negligibly higher price compared to other weaker, more local
collision-checking schemes. (Video: https://youtu.be/aqDs6Wymp5Q)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09244</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09244</id><created>2019-08-24</created><authors><author><keyname>Zhu</keyname><forenames>Lingling</forenames></author><author><keyname>Shu</keyname><forenames>Feng</forenames></author><author><keyname>Shen</keyname><forenames>Tong</forenames></author></authors><title>Two High-Performance Amplitude Beamforming Schemes for Secure Precise
  Communication and Jamming with Phase Alignment</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To severely weaken the eavesdropper's ability to intercept confidential
message (CM), a precise jamming (PJ) idea is proposed by making use of the
concept of secure precise wireless transmission (SPWT). Its basic idea is to
focus the transmit energy of artificial noise (AN) onto the neighborhood of
eavesdropper (Eve) by using random subcarrier selection (RSS), directional
modulation, phase alignment (PA), and amplitude beamforming (AB). By doing so,
Eve will be seriously interfered with AN. Here, the conventional joint
optimization of phase and amplitude is converted into two independent phase and
amplitude optimization problems. Considering PJ and SPWT require PA, the joint
optimization problem reduces to an amplitude optimization problem. Then, two
efficient AB schemes are proposed: leakage and maximizing receive
power(Max-RP). With existing equal AB (EAB) as a performance reference,
simulation results show that the proposed Max-RP and leakage AB methods perform
much better than conventional method in terms of both bit-error-rate (BER) and
secrecy rate (SR) at medium and high signal-to-noise ratio regions. The
performance difference between the two proposed leakage and Max-RP amplitude
beamformers is trivial. Additionally, we also find the fact that all three AB
schemes EA, Max-RP, and leakage can form two main peaks of AN and CM around Eve
and the desired receiver (Bob), respectively. This is what we call PJ and SPWT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09250</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09250</id><created>2019-08-25</created><authors><author><keyname>Kadam</keyname><forenames>Sujay D.</forenames></author></authors><title>An I + PI Controller Structure for Integrating Processes with Dead-Time:
  Application to Depth Control of an Autonomous Underwater Vehicle</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a feedforward plus feedback controller structure with I
and PI controllers for control of an integrating process with dead time.
Guidelines for controller gain selection based on time domain specifications of
damping factor and natural frequency are provided along with simulations
indicating the selectivity of process response. The utility of proposed
controller structure is shown by simulating the depth control of a nonlinear
autonomous underwater vehicle system by the proposed controller structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09262</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09262</id><created>2019-08-25</created><authors><author><keyname>Murugesan</keyname><forenames>Balamurali</forenames></author><author><keyname>S</keyname><forenames>Vijaya Raghavan</forenames></author><author><keyname>Sarveswaran</keyname><forenames>Kaushik</forenames></author><author><keyname>Ram</keyname><forenames>Keerthi</forenames></author><author><keyname>Sivaprakasam</keyname><forenames>Mohanasankar</forenames></author></authors><title>Recon-GLGAN: A Global-Local context based Generative Adversarial Network
  for MRI Reconstruction</title><categories>eess.IV cs.CV</categories><comments>Accepted at MLMIR-MICCAIW 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Magnetic resonance imaging (MRI) is one of the best medical imaging
modalities as it offers excellent spatial resolution and soft-tissue contrast.
But, the usage of MRI is limited by its slow acquisition time, which makes it
expensive and causes patient discomfort. In order to accelerate the
acquisition, multiple deep learning networks have been proposed. Recently,
Generative Adversarial Networks (GANs) have shown promising results in MRI
reconstruction. The drawback with the proposed GAN based methods is it does not
incorporate the prior information about the end goal which could help in better
reconstruction. For instance, in the case of cardiac MRI, the physician would
be interested in the heart region which is of diagnostic relevance while
excluding the peripheral regions. In this work, we show that incorporating
prior information about a region of interest in the model would offer better
performance. Thereby, we propose a novel GAN based architecture, Reconstruction
Global-Local GAN (Recon-GLGAN) for MRI reconstruction. The proposed model
contains a generator and a context discriminator which incorporates global and
local contextual information from images. Our model offers significant
performance improvement over the baseline models. Our experiments show that the
concept of a context discriminator can be extended to existing GAN based
reconstruction models to offer better performance. We also demonstrate that the
reconstructions from the proposed method give segmentation results similar to
fully sampled images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09287</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09287</id><created>2019-08-25</created><authors><author><keyname>Ghojogh</keyname><forenames>Benyamin</forenames></author><author><keyname>Karray</keyname><forenames>Fakhri</forenames></author><author><keyname>Crowley</keyname><forenames>Mark</forenames></author></authors><title>Principal Component Analysis Using Structural Similarity Index for
  Images</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Paper for the methods named &quot;Image Structural Component Analysis
  (ISCA)&quot; and &quot;Kernel Image Structural Component Analysis (Kernel ISCA)&quot;</comments><journal-ref>International Conference on Image Analysis and Recognition,
  Springer, pp. 77-88, 2019</journal-ref><doi>10.1007/978-3-030-27202-9_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the advances of deep learning in specific tasks using images, the
principled assessment of image fidelity and similarity is still a critical
ability to develop. As it has been shown that Mean Squared Error (MSE) is
insufficient for this task, other measures have been developed with one of the
most effective being Structural Similarity Index (SSIM). Such measures can be
used for subspace learning but existing methods in machine learning, such as
Principal Component Analysis (PCA), are based on Euclidean distance or MSE and
thus cannot properly capture the structural features of images. In this paper,
we define an image structure subspace which discriminates different types of
image distortions. We propose Image Structural Component Analysis (ISCA) and
also kernel ISCA by using SSIM, rather than Euclidean distance, in the
formulation of PCA. This paper provides a bridge between image quality
assessment and manifold learning opening a broad new area for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09288</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09288</id><created>2019-08-25</created><authors><author><keyname>Ghojogh</keyname><forenames>Benyamin</forenames></author><author><keyname>Karray</keyname><forenames>Fakhri</forenames></author><author><keyname>Crowley</keyname><forenames>Mark</forenames></author></authors><title>Locally Linear Image Structural Embedding for Image Structure Manifold
  Learning</title><categories>stat.ML cs.CV cs.LG eess.IV</categories><comments>This is the paper for the methods named &quot;Locally Linear Image
  Structural Embedding (LLISE)&quot; and &quot;Kernel Locally Linear Image Structural
  Embedding (Kernel LLISE)&quot;</comments><journal-ref>International Conference on Image Analysis and Recognition,
  Springer, pp. 126-138, 2019</journal-ref><doi>10.1007/978-3-030-27202-9_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of existing manifold learning methods rely on Mean Squared Error (MSE)
or $\ell_2$ norm. However, for the problem of image quality assessment, these
are not promising measure. In this paper, we introduce the concept of an image
structure manifold which captures image structure features and discriminates
image distortions. We propose a new manifold learning method, Locally Linear
Image Structural Embedding (LLISE), and kernel LLISE for learning this
manifold. The LLISE is inspired by Locally Linear Embedding (LLE) but uses SSIM
rather than MSE. This paper builds a bridge between manifold learning and image
fidelity assessment and it can open a new area for future investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09289</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09289</id><created>2019-08-25</created><authors><author><keyname>Lu</keyname><forenames>Jinhui</forenames></author><author><keyname>Wang</keyname><forenames>Yuntian</forenames></author><author><keyname>Liu</keyname><forenames>Tingting</forenames></author><author><keyname>Zhuang</keyname><forenames>Zhihong</forenames></author><author><keyname>Zhou</keyname><forenames>Xiaobo</forenames></author><author><keyname>Shu</keyname><forenames>Feng</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>UAV-Enabled Uplink Non-Orthogonal Multiple Access System: Joint
  Deployment and Power Control</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to overcome the inherent latency in multi-user unmanned aerial
vehicle (UAV) networks with orthogonal multiple access (OMA). In this paper, we
investigate the UAV enabled uplink non-orthogonal multiple access (NOMA)
network, where a UAV is deployed to collect the messages transmitted by ground
users. In order to maximize the sum rate of all users and to meet the quality
of service (QoS) requirement, we formulate an optimization problem, in which
the UAV deployment position and the power control are jointly optimized. This
problem is non-convex and some variables are binary, and thus it is a typical
NP hard problem. In this paper, an iterative algorithm is proposed with the
assistance of successive convex approximate (SCA) technique and the penalty
function method. In order to reduce the high computational complexity of the
iterative algorithm, a low complexity approximation algorithm is then proposed,
which can achieve a similar performance compared to the iterative algorithm.
Compared with OMA scheme and conventional NOMA scheme, numerical results show
that our proposed algorithms can efficiently improve the sum rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09295</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09295</id><created>2019-08-25</created><updated>2019-10-01</updated><authors><author><keyname>Li</keyname><forenames>Quan-Lin</forenames></author><author><keyname>Li</keyname><forenames>Yi-Meng</forenames></author><author><keyname>Ma</keyname><forenames>Jing-Yu</forenames></author><author><keyname>Liu</keyname><forenames>Heng-Li</forenames></author></authors><title>A Complete Algebraic Transformational Solution for the Optimal Dynamic
  Policy in Inventory Rationing across Two Demand Classes</title><categories>math.OC cs.CE cs.SY eess.SY</categories><comments>62 pages; 7 figures</comments><msc-class>90B05, 90B22, 90B30, 60J27, 90C40, 93E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we apply the sensitivity-based optimization to propose and
develop a complete algebraic transformational solution for the optimal dynamic
rationing policy in inventory rationing across two demand classes. Our results
provide a unified framework to set up a new transformational threshold type
structure for the optimal dynamic rationing policy. Based on this, we can
provide a complete description that the optimal dynamic rationing policy is
either of critical rationing level (i.e. threshold type or a static rationing
policy) or of no critical rationing level. Also, two basic classifications can
be described by means of our algebraic transformational solution. To this end,
we first establish a policy-based birth-death process and set up a more general
reward (or cost) function with respect to both states and policies of the
birth-death process, hence this gives our policy optimal problem. Then we set
up a policy-based Poisson equation, which, together with a performance
difference equation, characterizes monotonicity and optimality of the long-run
average profit of the rationing inventory system. Finally, we apply the
sensitivity-based optimization to construct a threshold type policy to further
study the rationing inventory system. Furthermore, we use some numerical
experiments to verify our theoretic results and computational validity, and
specifically, compare the optimal dynamic rationing policy with the optimal
threshold type rationing policy from two different policy spaces. We hope that
the methodology and results developed in this paper can shed light to the study
of rationing inventory systems, and will open a series of potentially promising
research by means of the sensitivity-based optimization and our algebraic
transformational solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09298</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09298</id><created>2019-08-25</created><updated>2019-08-28</updated><authors><author><keyname>Chen</keyname><forenames>Jingkun</forenames></author><author><keyname>Li</keyname><forenames>Hongwei</forenames></author><author><keyname>Zhang</keyname><forenames>Jianguo</forenames></author><author><keyname>Menze</keyname><forenames>Bjoern</forenames></author></authors><title>Adversarial Convolutional Networks with Weak Domain-Transfer for
  Multi-Sequence Cardiac MR Images Segmentation</title><categories>eess.IV cs.CV</categories><comments>9 pages, 4 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis and modeling of the ventricles and myocardium are important in the
diagnostic and treatment of heart diseases. Manual delineation of those tissues
in cardiac MR (CMR) scans is laborious and time-consuming. The ambiguity of the
boundaries makes the segmentation task rather challenging. Furthermore, the
annotations on some modalities such as Late Gadolinium Enhancement (LGE) MRI,
are often not available. We propose an end-to-end segmentation framework based
on convolutional neural network (CNN) and adversarial learning. A dilated
residual U-shape network is used as a segmentor to generate the prediction
mask; meanwhile, a CNN is utilized as a discriminator model to judge the
segmentation quality. To leverage the available annotations across modalities
per patient, a new loss function named weak domain-transfer loss is introduced
to the pipeline. The proposed model is evaluated on the public dataset released
by the challenge organizer in MICCAI 2019, which consists of 45 sets of
multi-sequence CMR images. We demonstrate that the proposed adversarial
pipeline outperforms baseline deep-learning methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09323</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09323</id><created>2019-08-25</created><authors><author><keyname>Konda</keyname><forenames>Rohit</forenames></author><author><keyname>Ames</keyname><forenames>Aaron D.</forenames></author><author><keyname>Coogan</keyname><forenames>Samuel</forenames></author></authors><title>Characterizing Safety: Minimal Barrier Functions from Scalar Comparison
  Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Verifying set invariance, considered a fundamental problem in dynamical
systems theory and practically motivated by problems in safety assurance, has
classical solutions stemming from the seminal work by Nagumo. Defining sets via
a smooth barrier function constraint inequality results in computable flow
conditions for guaranteeing set invariance. While a majority of these historic
results on set invariance consider flow conditions on the boundary, recent
results on control barrier functions extended these conditions to the entire
set - although they still reduced to the classic Nagumo conditions on the
boundary and thus require regularity conditions on the barrier function. This
paper fully characterizes set invariance through minimal barrier functions by
directly appealing to a comparison result to define a novel flow condition over
the entire domain of the system. A considerable benefit of this approach is the
removal of regularity assumptions of the barrier function. This paper also
outlines necessary and sufficient conditions for a valid differential
inequality condition, giving the minimum conditions for this type of approach
and allowing for the verification of the largest class of invariant sets. We
also show when minimal barrier functions are necessary and sufficient for set
invariance. This paper further discusses extensions into time varying and
control formulations, and outlines the connections between the proposed minimal
barrier function and the historic boundary-based conditions for set invariance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09334</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09334</id><created>2019-08-25</created><updated>2019-09-04</updated><authors><author><keyname>He</keyname><forenames>Binqi</forenames></author><author><keyname>Bi</keyname><forenames>Suzhi</forenames></author><author><keyname>Xing</keyname><forenames>Hong</forenames></author><author><keyname>Lin</keyname><forenames>Xiaohui</forenames></author></authors><title>Collaborative Computation Offloading in Wireless Powered Mobile-Edge
  Computing Systems</title><categories>cs.NI eess.SP</categories><comments>The paper is accepted for publication by IEEE GLOBECOM 2019, at
  Waikoloa, HI, USA, in Dec. 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a novel user cooperation model in a wireless powered
mobile edge computing system where two wireless users harvest wireless power
transferred by one energy node and can offload part of their computation tasks
to an edge server (ES) for remote execution. In particular, we consider that
the direct communication link between one user to the ES is blocked, such that
the other user acts as a relay to forward its offloading data to the server.
Meanwhile, instead of forwarding all the received task data, we also allow the
helping user to compute part of the received task locally to reduce the
potentially high energy and time cost on task offloading to the ES. Our aim is
to maximize the amount of data that can be processed within a given time frame
of the two users by jointly optimizing the amount of task data computed at each
device (users and ES), the system time allocation, the transmit power and CPU
frequency of the users. We propose an efficient method to find the optimal
solution and show that the proposed user cooperation can effectively enhance
the computation performance of the system compared to other representative
benchmark methods under different scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09336</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09336</id><created>2019-08-25</created><updated>2019-09-30</updated><authors><author><keyname>Li</keyname><forenames>Kaihan</forenames></author><author><keyname>Benkhelifa</keyname><forenames>Fatma</forenames></author><author><keyname>McCann</keyname><forenames>Julie</forenames></author></authors><title>Resource Allocation for Non-Orthogonal Multiple Access (NOMA) Enabled
  LPWA Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>IEEE Global Communications Conference (Globecom'2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the resource allocation for uplink
non-orthogonal multiple access (NOMA) enabled low-power wide-area (LPWA)
networks to support the massive connectivity of users/nodes. Here, LPWA nodes
communicate with a central gateway through resource blocks like channels,
transmission times, bandwidths, etc. The nodes sharing the same resource blocks
suffer from intra-cluster interference and possibly inter-cluster interference,
which makes current LPWA networks unable to support the massive connectivity.
Using the minimum transmission rate metric to highlight the interference
reduction that results from the addition of NOMA, and while assuring user
throughput fairness, we decompose the minimum rate maximization optimization
problem into three sub-problems. First, a low-complexity sub-optimal nodes
clustering scheme is proposed assigning nodes to channels based on their
normalized channel gains. Then, two types of transmission time allocation
algorithms are proposed that either assure fair or unfair transmission time
allocation between LPWA nodes sharing the same channel. For a given channel and
transmission time allocation, we further propose an optimal power allocation
scheme. Simulation evaluations demonstrate approximately 100dB improvement of
the selected metric for a single network with 4000 active nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09346</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09346</id><created>2019-08-25</created><updated>2019-10-28</updated><authors><author><keyname>Yang</keyname><forenames>Weida</forenames></author></authors><title>Dedge-AGMNet: A Robust Multi-task Learning Network for Stereo Matching
  and Depth Edge Detection</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, end-to-end convolutional neural networks have achieved remarkable
success in disparity estimation tasks. However, these neural networks usually
have difficulty in finding correct correspondences in ill-posed regions, such
as texture-less areas, edge details, and small objects. This paper proposes an
atrous granular multi-scale network based on depth edge
subnetwork(Dedge-AGMNet) to overcome the difficulty above. This work has the
following contributions. On one hand, the devised depth edge subnetwork
provides the geometric knowledge and depth edge constraints. To incorporate the
depth edge cues efficiently, the depth edge-spatial pyramid pooling(Dedge-SPP)
module fuses the depth edge features to the disparity estimation branch. And
the loss functions are proposed respectively for supervised and unsupervised
tasks, which can improve the adaptability of the depth edge auxiliary network.
On the other, the designed granular convolution is very suitable for
constructing the atrous granular multi-scale (AGM) module. AGM module could
capture multi-scale context information that requires fewer parameters and
consumes fewer computational resources. In summary,the depth edge cues and
multi-scale context information are both beneficial to explore potential
corresponding points in ill-posed regions. Integrating the ranks of different
stereo datasets, our network outperforms other stereo matching networks and
shows very strong robustness for different environments. The Dedge-AGMNet
advances state-of-the-art performances on the Sceneflow, KITTI 2012 and KITTI
2015 benchmark datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09370</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09370</id><created>2019-08-25</created><authors><author><keyname>Johnson</keyname><forenames>Brandon</forenames></author><author><keyname>Gibson</keyname><forenames>Nathan L.</forenames></author><author><keyname>Cotilla-Sanchez</keyname><forenames>Eduardo</forenames></author></authors><title>A Coupled Karhunen--Lo\`eve and Anisotropic Sparse Grid Interpolation
  Method for the Probabilistic Load Flow Problem</title><categories>eess.SP</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the traditional load flow analysis, a key assumption is that the input
variables, i.e., generator output and customer demand, are fixed in time and
the associated response has no variability. This assumption, however, is no
longer valid as the adoption of renewable energy resources add more variability
and uncertainty to the modern electrical system. Addressing these concerns is
the definition of the Probabilistic Load Flow (PLF) problem. The challenge of
the PLF problem lies in handling high-dimensional input uncertainties and the
non-linearity of the load flow equations. The most straightforward way to
address these problems, but at the cost of computational time, is to perform a
Monte Carlo method. This work, however, solves these problems--accuracy,
high-dimensionality, and computational time--with a coupled Karhunen--Lo\`{e}ve
(KL) expansion and Anisotropic Sparse Grid algorithm. The proposed method is
implemented and tested on the IEEE 118-bus test system and a modernized version
of the IEEE Reliability Test System--1996, the Reliability Test System--Grid
Modernization Lab Consortium (RTS-GMLC). Results for the 194-dimensional case
show a decrease in computational time when compared to the 10,000 sample Monte
Carlo method given a bound on mean and standard deviation error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09379</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09379</id><created>2019-08-25</created><authors><author><keyname>Yurduseven</keyname><forenames>Okan</forenames></author><author><keyname>Elsdon</keyname><forenames>Michael</forenames></author></authors><title>Indirect Microwave Holography and Through Wall Imaging</title><categories>physics.app-ph eess.SP</categories><comments>12 pages, 20 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, a review of indirect microwave holography for through-wall
imaging is presented. Indirect microwave holography is an imaging technique,
enabling the complex object scattered fields (amplitude and phase) to be
mathematically recovered from intensity-only, scalar microwave measurements. By
removing the requirement to use vector measurement equipment to directly
measure the complex fields, indirect microwave holography significantly reduces
the cost of the imaging system and simplifies the hardware implementation. The
application of a back-propagation algorithm enables the reconstructed amplitude
and phase images to be obtained at the plane of the concealed object. In order
to demonstrate the validity of the reviewed approach, experimental work is
carried out on a metallic gun concealed under a 5 cm thick plywood wall and it
is demonstrated that the indirect microwave holographic TWI can produce good
resolution amplitude and phase images when back-propagation is applied. TWI of
a concealed dielectric box representing non-metallic ordnance is also performed
to demonstrate the ability of the technique to reconstruct through-wall images
of concealed dielectric objects. An investigation of the resolution
characteristics of the system suggests diffraction limited resolution can be
achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09401</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09401</id><created>2019-08-25</created><authors><author><keyname>Pan</keyname><forenames>Zhimeng</forenames></author><author><keyname>Rodriguez</keyname><forenames>Brian</forenames></author><author><keyname>Menon</keyname><forenames>Rajesh</forenames></author></authors><title>Machine-learning enables Image Reconstruction and Classification in a
  &quot;see-through&quot; camera</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate that image reconstruction can be achieved via a convolutional
neural network for a &quot;see-through&quot; computational camera comprised of a
transparent window and a CMOS image sensor. Furthermore, we compared
classification results using a classifier network for the raw sensor data vs
the reconstructed images. The results suggest that similar classification
accuracy is likely possible in both cases with appropriate network
optimizations. All networks were trained and tested for the MNIST (6 classes),
EMNIST and the Kanji49 datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09411</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09411</id><created>2019-08-25</created><updated>2020-02-02</updated><authors><author><keyname>Chae</keyname><forenames>Byung Gyu</forenames></author></authors><title>Methods for extending viewing-angle of holographic image by using
  digital hologram with high numerical aperture</title><categories>physics.optics eess.IV</categories><comments>22 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the angular field of view (AFOV) of a holographic image
reconstructed from the digital Fresnel hologram in holographic display. The
theoretical analysis reveals that the AFOV of a holographic image is
fundamentally determined by the hologram numerical aperture (HNA) other than a
diffraction angle of pixel pitch of a pixelated modulator. This property is
proved for various types of the digital holograms by using a numerical
simulation and optical experiments. The high-HNA hologram reconstructs the
image with a high viewing-angle, although the image contraction is inevitable
due to the Nyquist sampling criterion. We propose the method for extending the
viewing-angle of a holographic image in the manner of increasing the object
size during the high-HNA hologram synthesis and removing the high-order
aliasing images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09414</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09414</id><created>2019-08-25</created><updated>2019-10-15</updated><authors><author><keyname>Lim</keyname><forenames>Sungjun</forenames></author><author><keyname>Lee</keyname><forenames>Sang-Eun</forenames></author><author><keyname>Chang</keyname><forenames>Sunghoe</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>CycleGAN with a Blur Kernel for Deconvolution Microscopy: Optimal
  Transport Geometry</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deconvolution microscopy has been extensively used to improve the resolution
of the widefield fluorescent microscopy. However, classical deconvolution
approaches require the measurement or estimation of the point spread function
(PSF), and are usually computationally expensive. Recently, convolutional
neural network (CNN) approaches have been extensively studied as fast and high
performance alternatives. Unfortunately, the CNN approaches usually require
matched high resolution images for supervised training. In this paper, we
present a novel unsupervised cycle-consistent generative adversarial network
(cycleGAN) with a linear blur kernel, which can be used for both blind- and
non-blind image deconvolution. In contrast to the conventional cycleGAN
approaches that require two generators, the proposed cycleGAN approach needs
only a single generator, which significantly improves the robustness of network
training. We show that the proposed architecture is indeed a dual formulation
of an optimal transport problem that uses a special form of penalized least
squares as transport cost. Experimental results using simulated and real
experimental data confirm the efficacy of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09431</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09431</id><created>2019-08-25</created><authors><author><keyname>Liu</keyname><forenames>Weijian</forenames></author><author><keyname>Liu</keyname><forenames>Jun</forenames></author><author><keyname>Gao</keyname><forenames>Yongchan</forenames></author><author><keyname>Wang</keyname><forenames>Guoshi</forenames></author><author><keyname>Wang</keyname><forenames>Yong-Liang</forenames></author></authors><title>Multichannel signal detection in interference and noise when signal
  mismatch happens</title><categories>eess.SP stat.AP stat.OT</categories><doi>10.1016/j.sigpro.2019.107268</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of detecting a multichannel signal in
interference and noise when signal mismatch happens. We first propose two
selective detectors, since their strong selectivity is preferred in some
situations. However, these two detectors would not be suitable candidates if a
robust detector is needed. To overcome this shortcoming, we then devise a
tunable detector, which is parametrized by a non-negative scaling factor,
referred to as the tunable parameter. By adjusting the tunable parameter, the
proposed detector can smoothly change its capability in rejecting or robustly
detecting a mismatch signal. Moreover, one selective detector and the tunable
detector with an appropriate tunable parameter can provide nearly the same
detection performance as existing detectors in the absence of signal mismatch.
We obtain analytical expressions for the probabilities of detection (PDs) and
probabilities of false alarm (PFAs) of the three proposed detectors, which are
verified by Monte Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09444</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09444</id><created>2019-08-25</created><authors><author><keyname>Hasan</keyname><forenames>Monowar</forenames></author><author><keyname>Mohan</keyname><forenames>Sibin</forenames></author></authors><title>Protecting Actuators in Safety-Critical IoT Systems from Control
  Spoofing Attacks</title><categories>cs.CR cs.SY eess.SY</categories><comments>2nd Workshop on the Internet of Things Security and Privacy - Iot
  S&amp;P'19, November 15, 2019, London, United Kingdom. ACM ISBN:
  978-1-4503-6838-4/19/11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a framework called Contego-TEE to secure
Internet-of-Things (IoT) edge devices with timing requirements from control
spoofing attacks where an adversary sends malicious control signals to the
actuators. We use a trusted computing base available in commodity processors
(such as ARM TrustZone) and propose an invariant checking mechanism to ensure
the security and safety of the physical system. A working prototype of
Contego-TEE was developed using embedded Linux kernel. We demonstrate the
feasibility of our approach for a robotic vehicle running on an ARM-based
platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09445</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09445</id><created>2019-08-25</created><authors><author><keyname>Zhu</keyname><forenames>Zheng</forenames></author><author><keyname>Zou</keyname><forenames>Wei</forenames></author><author><keyname>Huang</keyname><forenames>Guan</forenames></author><author><keyname>Du</keyname><forenames>Dalong</forenames></author><author><keyname>Huang</keyname><forenames>Chang</forenames></author></authors><title>High Performance Visual Object Tracking with Unified Convolutional
  Networks</title><categories>cs.RO cs.CV eess.IV</categories><comments>Extended version of [arXiv:1711.04661] our UCT tracker in ICCV
  VOT2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNN) based tracking approaches have shown
favorable performance in recent benchmarks. Nonetheless, the chosen CNN
features are always pre-trained in different tasks and individual components in
tracking systems are learned separately, thus the achieved tracking performance
may be suboptimal. Besides, most of these trackers are not designed towards
real-time applications because of their time-consuming feature extraction and
complex optimization details. In this paper, we propose an end-to-end framework
to learn the convolutional features and perform the tracking process
simultaneously, namely, a unified convolutional tracker (UCT). Specifically,
the UCT treats feature extractor and tracking process both as convolution
operation and trains them jointly, which enables learned CNN features are
tightly coupled with tracking process. During online tracking, an efficient
model updating method is proposed by introducing peak-versus-noise ratio (PNR)
criterion, and scale changes are handled efficiently by incorporating a scale
branch into network. Experiments are performed on four challenging tracking
datasets: OTB2013, OTB2015, VOT2015 and VOT2016. Our method achieves leading
performance on these benchmarks while maintaining beyond real-time speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09449</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09449</id><created>2019-08-25</created><authors><author><keyname>Tushar</keyname><forenames>Wayes</forenames></author><author><keyname>Saha</keyname><forenames>Tapan Kumar</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Morstyn</keyname><forenames>Thomas</forenames></author><author><keyname>Nahid-Al-Masood</keyname></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Bean</keyname><forenames>Richard</forenames></author></authors><title>Grid Influenced Peer-to-Peer Energy Trading</title><categories>eess.SY cs.GT cs.SY</categories><comments>10 pages, accepted for publication</comments><journal-ref>IEEE Transactions on Smart Grid, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a peer-to-peer energy trading scheme that can help the
centralized power system to reduce the total electricity demand of its
customers at the peak hour. To do so, a cooperative Stackelberg game is
formulated, in which the centralized power system acts as the leader that needs
to decide on a price at the peak demand period to incentivize prosumers to not
seeking any energy from it. The prosumers, on the other hand, act as followers
and respond to the leader's decision by forming suitable coalitions with
neighboring prosumers in order to participate in P2P energy trading to meet
their energy demand. The properties of the proposed Stackelberg game are
studied. It is shown that the game has a unique and stable Stackelberg
equilibrium, as a result of the stability of prosumers' coalitions. At the
equilibrium, the leader chooses its strategy using a derived closed-form
expression, while the prosumers choose their equilibrium coalition structure.
An algorithm is proposed that enables the centralized power system and the
prosumers to reach the equilibrium solution. Numerical case studies demonstrate
the beneficial properties of the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09460</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09460</id><created>2019-08-26</created><authors><author><keyname>Li</keyname><forenames>Nan</forenames></author><author><keyname>Kolmanovsky</keyname><forenames>Ilya</forenames></author><author><keyname>Girard</keyname><forenames>Anouck</forenames></author></authors><title>A Reference Governor for Nonlinear Systems with Disturbance Inputs Based
  on Logarithmic Norms and Quadratic Programming</title><categories>eess.SY cs.SY math.OC</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note describes a reference governor design for a continuous-time
nonlinear system with an additive disturbance. The design is based on
predicting the response of the nonlinear system by the response of a linear
model with a set-bounded prediction error, where a state-and-input dependent
bound on the prediction error is explicitly characterized using logarithmic
norms. The online optimization is reduced to a convex quadratic program with
linear inequality constraints. Two numerical examples are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09466</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09466</id><created>2019-08-26</created><authors><author><keyname>Mao</keyname><forenames>Yanbing</forenames></author><author><keyname>Jafarnejadsani</keyname><forenames>Hamidreza</forenames></author><author><keyname>Zhao</keyname><forenames>Pan</forenames></author><author><keyname>Akyol</keyname><forenames>Emrah</forenames></author><author><keyname>Hovakimyan</keyname><forenames>Naira</forenames></author></authors><title>Novel Stealthy Attack and Defense Strategies for Networked Control
  Systems</title><categories>eess.SY cs.DC cs.MA cs.SY</categories><comments>Submitted for Publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies novel attack and defense strategies, based on a class of
stealthy attacks, namely the zero-dynamics attack (ZDA), for multi-agent
control systems. ZDA poses a formidable security challenge since its attack
signal is hidden in the null-space of the state-space representation of the
control system and hence it can evade conventional detection methods. An
intuitive defense strategy builds on changing the aforementioned representation
via switching through a set of carefully crafted topologies. In this paper, we
propose realistic ZDA variations where the attacker is aware of this
topology-switching strategy, and hence employs the following policies to avoid
detection: (i) &quot;pause (update and resume) attack&quot; before (after) topology
switching to evade detection; (ii) cooperate with a concurrent stealthy
topology attack that alters network topology at switching times, such that the
original ZDA is feasible under the corrupted topology. We first systematically
study the proposed ZDA variations, and then develop defense strategies against
them under the realistic assumption that the defender has no knowledge of
attack starting, pausing, and resuming times and the number of misbehaving
agents. Particularly, we characterize conditions for detectability of the
proposed ZDA variations, in terms of the network topologies to be maintained,
the set of agents to be monitored, and the measurements of the monitored agents
that should be extracted, while simultaneously preserving the privacy of the
states of the non-monitored agents. We then propose an attack detection
algorithm based on the Luenberger observer, using the characterized
detectability conditions. We provide numerical simulation results to
demonstrate our theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09471</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09471</id><created>2019-08-26</created><authors><author><keyname>Lou</keyname><forenames>Yang</forenames></author><author><keyname>He</keyname><forenames>Yaodong</forenames></author><author><keyname>Wang</keyname><forenames>Lin</forenames></author><author><keyname>Chen</keyname><forenames>Guanrong</forenames></author></authors><title>Predicting Network Controllability Robustness: A Convolutional Neural
  Network Approach</title><categories>eess.SY cs.LG cs.SY</categories><comments>12 pages, 7 figures. This manuscript is submitted for possible
  publication</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Network controllability measures how well a networked system can be
controlled to a target state, and its robustness reflects how well the system
can maintain the controllability against malicious attacks by means of
node-removals or edge-removals. The measure of network controllability is
quantified by the number of external control inputs needed to recover or to
retain the controllability after the occurrence of an unexpected attack. The
measure of the network controllability robustness, on the other hand, is
quantified by a sequence of values that record the remaining controllability of
the network after a sequence of attacks. Traditionally, the controllability
robustness is determined by attack simulations, which is computationally time
consuming. In this paper, a method to predict the controllability robustness
based on machine learning using a convolutional neural network is proposed,
motivated by the observations that 1) there is no clear correlation between the
topological features and the controllability robustness of a general network,
2) the adjacency matrix of a network can be regarded as a gray-scale image, and
3) the convolutional neural network technique has proved successful in image
processing without human intervention. Under the new framework, a fairly large
number of training data generated by simulations are used to train a
convolutional neural network for predicting the controllability robustness
according to the input network-adjacency matrices, without performing
conventional attack simulations. Extensive experimental studies were carried
out, which demonstrate that the proposed framework for predicting
controllability robustness of different network configurations is accurate and
reliable with very low overheads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09484</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09484</id><created>2019-08-26</created><authors><author><keyname>Hung</keyname><forenames>Hsiao-Tzu</forenames></author><author><keyname>Wang</keyname><forenames>Chung-Yang</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author><author><keyname>Wang</keyname><forenames>Hsin-Min</forenames></author></authors><title>Improving Automatic Jazz Melody Generation by Transfer Learning
  Techniques</title><categories>cs.SD cs.LG eess.AS</categories><comments>8 pages, Accepted to APSIPA ASC(Asia-Pacific Signal and Information
  Processing Association Annual Summit and Conference ) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we tackle the problem of transfer learning for Jazz automatic
generation. Jazz is one of representative types of music, but the lack of Jazz
data in the MIDI format hinders the construction of a generative model for
Jazz. Transfer learning is an approach aiming to solve the problem of data
insufficiency, so as to transfer the common feature from one domain to another.
In view of its success in other machine learning problems, we investigate
whether, and how much, it can help improve automatic music generation for
under-resourced musical genres. Specifically, we use a recurrent variational
autoencoder as the generative model, and use a genre-unspecified dataset as the
source dataset and a Jazz-only dataset as the target dataset. Two transfer
learning methods are evaluated using six levels of source-to-target data
ratios. The first method is to train the model on the source dataset, and then
fine-tune the resulting model parameters on the target dataset. The second
method is to train the model on both the source and target datasets at the same
time, but add genre labels to the latent vectors and use a genre classifier to
improve Jazz generation. The evaluation results show that the second method
seems to perform better overall, but it cannot take full advantage of the
genre-unspecified dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09487</identifier>
 <datestamp>2019-12-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09487</id><created>2019-08-26</created><authors><author><keyname>Zare</keyname><forenames>Armin</forenames></author><author><keyname>Georgiou</keyname><forenames>Tryphon T.</forenames></author><author><keyname>Jovanovi&#x107;</keyname><forenames>Mihailo R.</forenames></author></authors><title>Stochastic dynamical modeling of turbulent flows</title><categories>physics.flu-dyn cs.LG cs.SY eess.SY math.OC</categories><comments>To appear in the Annual Review of Control, Robotics, and Autonomous
  Systems</comments><doi>10.1146/annurev-control-053018-023843</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advanced measurement techniques and high performance computing have made
large data sets available for a wide range of turbulent flows that arise in
engineering applications. Drawing on this abundance of data, dynamical models
can be constructed to reproduce structural and statistical features of
turbulent flows, opening the way to the design of effective model-based flow
control strategies. This review describes a framework for completing
second-order statistics of turbulent flows by models that are based on the
Navier-Stokes equations linearized around the turbulent mean velocity. Systems
theory and convex optimization are combined to address the inherent uncertainty
in the dynamics and the statistics of the flow by seeking a suitable
parsimonious correction to the prior linearized model. Specifically, dynamical
couplings between states of the linearized model dictate structural constraints
on the statistics of flow fluctuations. Thence, colored-in-time stochastic
forcing that drives the linearized model is sought to account for and reconcile
dynamics with available data (i.e., partially known second order statistics).
The number of dynamical degrees of freedom that are directly affected by
stochastic excitation is minimized as a measure of model parsimony. The
spectral content of the resulting colored-in-time stochastic contribution can
alternatively be seen to arise from a low-rank structural perturbation of the
linearized dynamical generator, pointing to suitable dynamical corrections that
may account for the absence of the nonlinear interactions in the linearized
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09501</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09501</id><created>2019-08-26</created><authors><author><keyname>Saeed</keyname><forenames>Nasir</forenames></author><author><keyname>Elzanaty</keyname><forenames>Ahmed</forenames></author><author><keyname>Almorad</keyname><forenames>Heba</forenames></author><author><keyname>Dahrouj</keyname><forenames>Hayssam</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>CubeSat Communications: Recent Advances and Future Challenges</title><categories>eess.SP cs.NI</categories><comments>Submitted to IEEE Communications Surveys and Tutorials</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research in the emerging space industry is becoming more and more
attractive, given the increasing number of space-related applications. One
primary entity of current space research is the design of miniaturized
satellites, known as CubeSats, due to their numerous applications and low
design and deployment cost. The new paradigm of connected space through
CubeSats enables a wide range of applications such as Earth remote sensing,
space exploration, and rural connectivity. CubeSats further provide a
complimentary connectivity solution to the pervasive Internet of things (IoT)
networks, leading to a globally connected cyber-physical system. This paper
presents a holistic overview of different aspects of CubeSat missions, and
provides a thorough review on the topic, both from academic and industrial
perspectives. We further present the recent advances in the area of CubeSats
communications with an emphasis on constellation and coverage issues, channel
modeling, modulation and coding, and networking. The paper finally identifies
several future research directions on CubeSats communications, namely Internet
of space things, low power long range networks, machine learning for resource
allocation in CubeSats, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09506</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09506</id><created>2019-08-26</created><updated>2019-09-05</updated><authors><author><keyname>Ohnishi</keyname><forenames>Motoya</forenames></author><author><keyname>Notomista</keyname><forenames>Gennaro</forenames></author><author><keyname>Sugiyama</keyname><forenames>Masashi</forenames></author><author><keyname>Egerstedt</keyname><forenames>Magnus</forenames></author></authors><title>Constraint Learning for Control Tasks with Limited Duration Barrier
  Functions</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When deploying autonomous agents in unstructured environments over sustained
periods of time, adaptability and robustness oftentimes outweigh optimality as
a primary consideration. In other words, safety and survivability constraints
play a key role and in this paper, we present a novel, constraint-learning
framework for control tasks built on the idea of constraints-driven control.
However, since control policies that keep a dynamical agent within state
constraints over infinite horizons are not always available, this work instead
considers constraints that can be satisfied over a sufficiently long time
horizon T &gt; 0, which we refer to as limited-duration safety. Consequently,
value function learning can be used as a tool to help us find limited-duration
safe policies. We show that, in some applications, the existence of
limited-duration safe policies is actually sufficient for long-duration
autonomy. This idea is illustrated on a swarm of simulated robots that are
tasked with covering a given area, but that sporadically need to abandon this
task to charge batteries. We show how the battery-charging behavior naturally
emerges as a result of the constraints. Additionally, using a cart-pole
simulation environment, we show how a control policy can be efficiently
transferred from the source task, balancing the pole, to the target task,
moving the cart to one direction without letting the pole fall down.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09515</identifier>
 <datestamp>2020-02-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09515</id><created>2019-08-26</created><authors><author><keyname>&#xd6;ktem</keyname><forenames>Ozan</forenames></author><author><keyname>Pouchol</keyname><forenames>Camille</forenames></author><author><keyname>Verdier</keyname><forenames>Olivier</forenames></author></authors><title>Spatiotemporal PET reconstruction using ML-EM with learned diffeomorphic
  deformation</title><categories>eess.IV cs.CV cs.LG</categories><doi>10.1007/978-3-030-33843-5_14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Patient movement in emission tomography deteriorates reconstruction quality
because of motion blur. Gating the data improves the situation somewhat: each
gate contains a movement phase which is approximately stationary. A standard
method is to use only the data from a few gates, with little movement between
them. However, the corresponding loss of data entails an increase of noise.
Motion correction algorithms have been implemented to take into account all the
gated data, but they do not scale well, especially not in 3D. We propose a
novel motion correction algorithm which addresses the scalability issue. Our
approach is to combine an enhanced ML-EM algorithm with deep learning based
movement registration. The training is unsupervised, and with artificial data.
We expect this approach to scale very well to higher resolutions and to 3D, as
the overall cost of our algorithm is only marginally greater than that of a
standard ML-EM algorithm. We show that we can significantly decrease the noise
corresponding to a limited number of gates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09523</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09523</id><created>2019-08-26</created><authors><author><keyname>Sattiraju</keyname><forenames>Raja</forenames></author><author><keyname>Weinand</keyname><forenames>Andreas</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>AI-assisted PHY technologies for 6G and beyond wireless networks</title><categories>eess.SP</categories><comments>Published in The 1st 6G WIRELESS SUMMIT, 24-25 Mar 2019, Levi,
  Finland</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine Learning (ML) and Artificial Intelligence(AI) have become alternative
approaches in wireless networksbeside conventional approaches such as model
based solutionconcepts. Whereas traditional design concepts include the
mod-elling of the behaviour of the underlying processes, AI basedapproaches
allow to design network functions by learning frominput data which is supposed
to get mapped to specific outputs(training). Additionally, new input/output
relations can be learntduring the deployement phase of the function (online
learning)and make AI based solutions flexible, in order to react to
newsituations. Especially, new introduced use cases such as UltraReliable Low
Latency Communication (URLLC) and MassiveMachine Type Communications (MMTC) in
5G make this ap-proach necessary, as the network complexity is further
enhancedcompared to networks mainly designed for human driven traffic(4G, 5G
xMBB). The focus of this paper is to illustrate exemplaryapplications of AI
techniques at the Physical Layer (PHY) offuture wireless systems and therfore
they can be seen as candidatetechnologies for e.g. 6G systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09526</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09526</id><created>2019-08-26</created><authors><author><keyname>Li</keyname><forenames>Rui</forenames></author><author><keyname>Pan</keyname><forenames>Zhibin</forenames></author><author><keyname>Wang</keyname><forenames>Yang</forenames></author><author><keyname>Wang</keyname><forenames>Ping</forenames></author></authors><title>A Convolutional Neural Network with Mapping Layers for Hyperspectral
  Image Classification</title><categories>eess.IV cs.CV</categories><comments>UNDER REVIEW ON IEEE TRANS. GEOSCI. REMOTE SEN</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a convolutional neural network with mapping layers
(MCNN) for hyperspectral image (HSI) classification. The proposed mapping
layers map the input patch into a low dimensional subspace by multilinear
algebra. We use our mapping layers to reduce the spectral and spatial
redundancy and maintain most energy of the input. The feature extracted by our
mapping layers can also reduce the number of following convolutional layers for
feature extraction. Our MCNN architecture avoids the declining accuracy with
increasing layers phenomenon of deep learning models for HSI classification and
also saves the training time for its effective mapping layers. Furthermore, we
impose the 3-D convolutional kernel on convolutional layer to extract the
spectral-spatial features for HSI. We tested our MCNN on three datasets of
Indian Pines, University of Pavia and Salinas, and we achieved the
classification accuracy of 98.3%, 99.5% and 99.3%, respectively. Experimental
results demonstrate that the proposed MCNN can significantly improve the
classification accuracy and save much time consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09529</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09529</id><created>2019-08-26</created><authors><author><keyname>Fourni&#xe9;</keyname><forenames>&#xc9;ric</forenames></author><author><keyname>Baer-Beck</keyname><forenames>Matthias</forenames></author><author><keyname>Stierstorfer</keyname><forenames>Karl</forenames></author></authors><title>CT Field of View Extension Using Combined Channels Extension and Deep
  Learning Methods</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/SygfANaVcN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  This paper proposes a method to extend the field of view of computed
tomography images. In a first step, the field of view is increased by
extrapolating linearly the outer channels in the sinogram space. The modified
sinogram is then used to reconstruct extended field of view (EFoV) images
containing artifacts due to the channels extension. In a second step, those
artifacts are reduced by a deep learning network in image space. The proposed
method has been evaluated on a collection of clinical scans. The resulting
volumes have been checked for consistency and plausibility and compared to an
existing state of the art EFoV method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09560</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09560</id><created>2019-08-26</created><authors><author><keyname>Jud</keyname><forenames>Christoph</forenames></author><author><keyname>Nguyen</keyname><forenames>Damien</forenames></author><author><keyname>Giger</keyname><forenames>Alina</forenames></author><author><keyname>Sandk&#xfc;hler</keyname><forenames>Robin</forenames></author><author><keyname>Krieger</keyname><forenames>Miriam</forenames></author><author><keyname>Lomax</keyname><forenames>Tony</forenames></author><author><keyname>Salomir</keyname><forenames>Rares</forenames></author><author><keyname>Bieri</keyname><forenames>Oliver</forenames></author><author><keyname>Cattin</keyname><forenames>Philippe C.</forenames></author></authors><title>Accelerated Motion-Aware MR Imaging via Motion Prediction from K-Space
  Center</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motion has been a challenge for magnetic resonance (MR) imaging ever since
the MR has been invented. Especially in volumetric imaging of thoracic and
abdominal organs, motion-awareness is essential for reducing motion artifacts
in the final image. A recently proposed MR imaging approach copes with motion
by observing the motion patterns during the acquisition. Repetitive scanning of
the k-space center region enables the extraction of the patient motion while
acquiring the remaining part of the k-space. Due to highly redundant
measurements of the center, the required scanning time of over 11 min and the
reconstruction time of 2 h exceed clinical applicability though. We propose an
accelerated motion-aware MR imaging method where the motion is inferred from
small-sized k-space center patches and an initial training phase during which
the characteristic movements are modeled. Thereby, acquisition times are
reduced by a factor of almost 2 and reconstruction times by two orders of
magnitude. Moreover, we improve the existing motion-aware approach with a
systematic temporal shift correction to achieve a sharper image reconstruction.
We tested our method on 12 volunteers and scanned their lungs and abdomen under
free breathing. We achieved equivalent to higher reconstruction quality using
the motion-prediction compared to the slower existing approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09593</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09593</id><created>2019-08-26</created><authors><author><keyname>Tarun</keyname><forenames>Anjali</forenames></author><author><keyname>Behjat</keyname><forenames>Hamid</forenames></author><author><keyname>Abramian</keyname><forenames>David</forenames></author><author><keyname>Van De Ville</keyname><forenames>Dimitri</forenames></author></authors><title>Structural mediation of human brain activity revealed by white-matter
  interpolation of fMRI</title><categories>q-bio.NC eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Anatomy of the human brain constrains the formation of large-scale functional
networks. Here, given measured brain activity in gray matter, we interpolate
these functional signals into the white matter on a structurally-informed
high-resolution voxel-level brain grid. The interpolated volumes reflect the
underlying anatomical information, revealing white matter structures that
mediate functional signal flow between temporally coherent gray matter regions.
Functional connectivity analyses of the interpolated volumes reveal an enriched
picture of the default mode network (DMN) and its subcomponents, including how
white matter bundles support their formation, thus transcending currently known
spatial patterns that are limited within the gray matter only. These
subcomponents have distinct structure-function patterns, each of which are
differentially recruited during tasks, demonstrating plausible structural
mechanisms for functional switching between task-positive and -negative
components. This work opens new avenues for integration of brain structure and
function and demonstrates how global patterns of activity arise from a
collective interplay of signal propagation along different white matter
pathways.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09604</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09604</id><created>2019-08-26</created><authors><author><keyname>Lan</keyname><forenames>Hao</forenames></author><author><keyname>Tong</keyname><forenames>Yin</forenames></author><author><keyname>Guo</keyname><forenames>Jin</forenames></author><author><keyname>Seatzu</keyname><forenames>Carla</forenames></author></authors><title>Verification of Detectability Using Petri Nets and Detector</title><categories>eess.SY cs.SY</categories><comments>8 pages, 5 figures. arXiv admin note: substantial text overlap with
  arXiv:1903.09298, arXiv:1903.07827</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detectability describes the property of a system to uniquely determine, after
a finite number of observations, the current and subsequent states. In this
paper, to reduce the complexity of checking the detectability properties in the
framework of bounded labeled Petri nets, we use a new tool, which is called
detector, to verifying the strong detectability and periodically strong
detectability. First, an approach, which is based on the reachable graph and
its detector, is proposed. Then, we develop a novel approach which is based on
the analysis of the detector of the basis reachability graph. Without computing
the whole reachability space, and without building the observer, the proposed
approaches are more efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09634</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09634</id><created>2019-08-23</created><authors><author><keyname>Tripathi</keyname><forenames>Kumud</forenames></author><author><keyname>Reddy</keyname><forenames>M. Kiran</forenames></author><author><keyname>Rao</keyname><forenames>K. Sreenivasa</forenames></author></authors><title>Multilingual and Multimode Phone Recognition System for Indian Languages</title><categories>eess.AS cs.SD eess.SP</categories><comments>33 pages, 5 figures, 6 tables, article</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to develop a flexible framework capable of
automatically recognizing phonetic units present in a speech utterance of any
language spoken in any mode. In this study, we considered two modes of speech:
conversation, and read modes in four Indian languages, namely, Telugu, Kannada,
Odia, and Bengali. The proposed approach consists of two stages: (1) Automatic
speech mode classification (SMC) and (2) Automatic phonetic recognition using
mode-specific multilingual phone recognition system (MPRS). In this work, the
vocal tract and excitation source features are considered for speech mode
classification (SMC) task. SMC systems are developed using multilayer
perceptron (MLP). Further, vocal tract, excitation source, and tandem features
are used to build the deep neural network (DNN)-based MPRSs. The performance of
the proposed approach is compared with mode-dependent MPRSs. Experimental
results show that the proposed approach which combines both SMC and MPRS into a
single system outperforms the baseline mode-dependent MPRSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09637</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09637</id><created>2019-08-22</created><authors><author><keyname>Liu</keyname><forenames>Zihan</forenames></author><author><keyname>Huang</keyname><forenames>Bo</forenames></author><author><keyname>Cui</keyname><forenames>Yuqi</forenames></author><author><keyname>Xu</keyname><forenames>Yifan</forenames></author><author><keyname>Zhang</keyname><forenames>Bo</forenames></author><author><keyname>Zhu</keyname><forenames>Lixia</forenames></author><author><keyname>Wang</keyname><forenames>Yang</forenames></author><author><keyname>Jin</keyname><forenames>Lei</forenames></author><author><keyname>Wu</keyname><forenames>Dongrui</forenames></author></authors><title>Multi-Task Deep Learning with Dynamic Programming for Embryo Early
  Development Stage Classification from Time-Lapse Videos</title><categories>eess.IV cs.CY cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time-lapse is a technology used to record the development of embryos during
in-vitro fertilization (IVF). Accurate classification of embryo early
development stages can provide embryologists valuable information for assessing
the embryo quality, and hence is critical to the success of IVF. This paper
proposes a multi-task deep learning with dynamic programming (MTDL-DP) approach
for this purpose. It first uses MTDL to pre-classify each frame in the
time-lapse video to an embryo development stage, and then DP to optimize the
stage sequence so that the stage number is monotonically non-decreasing, which
usually holds in practice. Different MTDL frameworks, e.g., one-to-many,
many-to-one, and many-to-many, are investigated. It is shown that the
one-to-many MTDL framework achieved the best compromise between performance and
computational cost. To our knowledge, this is the first study that applies MTDL
to embryo early development stage classification from time-lapse videos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09656</identifier>
 <datestamp>2019-11-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09656</id><created>2019-08-26</created><updated>2019-11-04</updated><authors><author><keyname>Li</keyname><forenames>Chengxi</forenames></author><author><keyname>He</keyname><forenames>You</forenames></author><author><keyname>Wang</keyname><forenames>Xueqian</forenames></author><author><keyname>Li</keyname><forenames>Gang</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author></authors><title>Distributed Detection of Sparse Stochastic Signals via Fusion of 1-bit
  Local Likelihood Ratios</title><categories>eess.SP</categories><comments>5 pages,2 figures, published in IEEE Signal Processing Letters (SPL)</comments><journal-ref>IEEE Signal Processing Letters, vol. 26, no. 12, pp. 1738-1742,
  Dec. 2019</journal-ref><doi>10.1109/LSP.2019.2945193</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider the detection of sparse stochastic signals with
sensor networks (SNs), where the fusion center (FC) collects 1-bit data from
the local sensors and then performs global detection. For this problem, a newly
developed 1-bit locally most powerful test (LMPT) detector requires 3.3Q
sensors to asymptotically achieve the same detection performance as the
centralized LMPT (cLMPT) detector with Q sensors. This 1-bit LMPT detector is
based on 1-bit quantized observations without any additional processing at the
local sensors. However, direct quantization of observations is not the most
efficient processing strategy at the sensors since it incurs unnecessary
information loss. In this letter, we propose an improved-1-bit LMPT (Im-1-bit
LMPT) detector that fuses local 1-bit quantized likelihood ratios (LRs) instead
of directly quantized local observations. In addition, we design the
quantization thresholds at the local sensors to ensure asymptotically optimal
detection performance of the proposed detector. It is shown theoretically and
numerically that, with the designed quantization thresholds, the proposed
Im-1-bit LMPT detector for the detection of sparse signals requires less number
of sensor nodes to compensate for the performance loss caused by 1-bit
quantization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09707</identifier>
 <datestamp>2019-11-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09707</id><created>2019-08-26</created><updated>2019-11-15</updated><authors><author><keyname>Walker</keyname><forenames>Thayne T.</forenames></author><author><keyname>Sturtevant</keyname><forenames>Nathan R.</forenames></author></authors><title>Collision Detection for Agents in Multi-Agent Pathfinding</title><categories>cs.RO cs.CG cs.GR cs.MA cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work on the multi-agent pathfinding problem (MAPF) has begun to study
agents with motion that is more complex, for example, with non-unit action
durations and kinematic constraints. An important aspect of MAPF is collision
detection. Many collision detection approaches exist, but often suffer from
issues such as high computational cost or causing false negative or false
positive detections. In practice, these issues can result in problems that
range from inefficiency and annoyance to catastrophic. The main contribution of
this technical report is to provide a high-level overview of major categories
of collision detection, along with methods of collision detection and
anticipatory collision avoidance for agents that are both computationally
efficient and highly accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09730</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09730</id><created>2019-08-21</created><authors><author><keyname>Guan</keyname><forenames>Sihai</forenames></author><author><keyname>Meng</keyname><forenames>Chun</forenames></author><author><keyname>Biswal</keyname><forenames>Bharat</forenames></author></authors><title>Diffusion probabilistic LMS algorithm</title><categories>eess.SP</categories><comments>13 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel diffusion estimation algorithm is proposed from a
probabilistic perspective by combining diffusion strategy and the probabilistic
least-mean-squares (PLMS) at all agents. The proposed method diffusion
probabilistic LMS (DPLMS) is more robust to input signal and impulsive
interference than the DSE-LMS, DRVSSLMS and DLLAD algorithms. Instead of
minimizing the estimate error, the DPLMS algorithm is derived from
approximating the posterior distribution with an isotropic Gaussian
distribution. The stability of mean performance and computational complexity
are analyzed theoretically. Results from the simulation indicate that the DPLMS
algorithm is more robust to input signal and impulsive interference than the
DSE-LMS, DRVSSLMS and DLLAD algorithms. These results suggest that the DPLMS
algorithm can perform better in identifying the unknown coefficients under the
complex and changeable impulsive interference environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09738</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09738</id><created>2019-08-26</created><authors><author><keyname>Pusateri</keyname><forenames>Ernest</forenames></author><author><keyname>Van Gysel</keyname><forenames>Christophe</forenames></author><author><keyname>Botros</keyname><forenames>Rami</forenames></author><author><keyname>Badaskar</keyname><forenames>Sameer</forenames></author><author><keyname>Hannemann</keyname><forenames>Mirko</forenames></author><author><keyname>Oualil</keyname><forenames>Youssef</forenames></author><author><keyname>Oparin</keyname><forenames>Ilya</forenames></author></authors><title>Connecting and Comparing Language Model Interpolation Techniques</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we uncover a theoretical connection between two language model
interpolation techniques, count merging and Bayesian interpolation. We compare
these techniques as well as linear interpolation in three scenarios with
abundant training data per component model. Consistent with prior work, we show
that both count merging and Bayesian interpolation outperform linear
interpolation. We include the first (to our knowledge) published comparison of
count merging and Bayesian interpolation, showing that the two techniques
perform similarly. Finally, we argue that other considerations will make
Bayesian interpolation the preferred approach in most circumstances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09753</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09753</id><created>2019-08-26</created><authors><author><keyname>Good</keyname><forenames>John</forenames></author><author><keyname>Berriman</keyname><forenames>G. Bruce</forenames></author></authors><title>Image Processing in Python With Montage</title><categories>astro-ph.IM eess.IV</categories><comments>4 pages, 1 figure. Submitted to Proceedings of ADASS XXVIII</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Montage image mosaic engine has found wide applicability in astronomy
research, integration into processing environments, and is an examplar
application for the development of advanced cyber-infrastructure. It is written
in C to provide performance and portability. Linking C/C++ libraries to the
Python kernel at run time as binary extensions allows them to run under Python
at compiled speeds and enables users to take advantage of all the functionality
in Python. We have built Python binary extensions of the 59 ANSI-C modules that
make up version 5 of the Montage toolkit. This has involved a turning the code
into a C library, with driver code fully separated to reproduce the calling
sequence of the command-line tools; and then adding Python and C linkage code
with the Cython library, which acts as a bridge between general C libraries and
the Python interface. We will demonstrate how to use these Python binary
extensions to perform image processing, including reprojecting and resampling
images, rectifying background emission to a common level, creation of image
mosaics that preserve the calibration and astrometric fidelity of the input
images, creating visualizations with an adaptive stretch algorithm, processing
HEALPix images, and analyzing and managing image metadata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09762</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09762</id><created>2019-08-26</created><authors><author><keyname>Ju</keyname><forenames>Shihao</forenames></author><author><keyname>Kanhere</keyname><forenames>Ojas</forenames></author><author><keyname>Xing</keyname><forenames>Yunchou</forenames></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author></authors><title>A Millimeter-Wave Channel Simulator NYUSIM with Spatial Consistency and
  Human Blockage</title><categories>cs.IT eess.SP math.IT</categories><comments>6 pages, 7 figures, 2019 IEEE GLOBECOM</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate channel modeling and simulation are indispensable for
millimeter-wave wideband communication systems that employ
electrically-steerable and narrow beam antenna arrays. Three important channel
modeling components, spatial consistency, human blockage, and outdoor-to-indoor
penetration loss, were proposed in the 3rd Generation Partnership Project
Release 14 for mmWave communication system design. This paper presents NYUSIM
2.0, an improved channel simulator which can simulate spatially consistent
channel realizations based on the existing drop-based channel simulator NYUSIM
1.6.1. A geometry-based approach using multiple reflection surfaces is proposed
to generate spatially correlated and time-variant channel coefficients. Using
results from 73 GHz pedestrian measurements for human blockage, a four-state
Markov model has been implemented in NYUSIM to simulate dynamic human blockage
shadowing loss. To model the excess path loss due to penetration into
buildings, a parabolic model for outdoor-to-indoor penetration loss has been
adopted from the 5G Channel Modeling special interest group and implemented in
NYUSIM 2.0. This paper demonstrates how these new modeling capabilities
reproduce realistic data when implemented in Monte Carlo fashion using NYUSIM
2.0, making it a valuable measurement-based channel simulator for
fifth-generation and beyond mmWave communication system design and evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09765</identifier>
 <datestamp>2019-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09765</id><created>2019-08-26</created><updated>2019-12-03</updated><authors><author><keyname>Xing</keyname><forenames>Yunchou</forenames></author><author><keyname>Kanhere</keyname><forenames>Ojas</forenames></author><author><keyname>Ju</keyname><forenames>Shihao</forenames></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author></authors><title>Indoor Wireless Channel Properties at Millimeter Wave and Sub-Terahertz
  Frequencies</title><categories>eess.SP cs.NI</categories><comments>6 pages, 5 figures, Globecom conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides indoor reflection, scattering, transmission, and
large-scale path loss measurements and models, which describe the main
propagation mechanisms at millimeter wave and Terahertz frequencies. Channel
properties for common building materials (drywall and clear glass) are
carefully studied at 28, 73, and 140 GHz using a wideband sliding correlation
based channel sounder system with rotatable narrow-beam horn antennas.
Reflection coefficient is shown to linearly increase as the incident angle
increases, and lower reflection loss (e.g., stronger reflections) are observed
as frequencies increase for a given incident angle. Although backscatter from
drywall is present at 28, 73, and 140 GHz, smooth surfaces (like drywall) are
shown to be modeled as a simple reflected surface, since the scattered power is
20 dB or more below the reflected power over the measured range of frequency
and angles. Partition loss tends to increase with frequency, but the amount of
loss is material dependent. Both clear glass and drywall are shown to induce a
depolarizing effect, which becomes more prominent as frequency increases.
Indoor propagation measurements and large-scale indoor path loss models at 140
GHz are provided, revealing similar path loss exponent and shadow fading as
observed at 28 and 73 GHz. The measurements and models in this paper can be
used for future wireless system design and other applications within buildings
for frequencies above 100 GHz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09766</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09766</id><created>2019-08-26</created><authors><author><keyname>Pham</keyname><forenames>Hong Thinh</forenames></author><author><keyname>Pham</keyname><forenames>Ngoc Nam</forenames></author><author><keyname>Nguyen</keyname><forenames>Huu Thanh</forenames></author><author><keyname>Marshall</keyname><forenames>Alan</forenames></author><author><keyname>Truong</keyname><forenames>Thu Huong</forenames></author></authors><title>A Hybrid of Adaptation and Dynamic Routing based on SDN for Improving
  QoE in HTTP Adaptive VBR Video Streaming</title><categories>cs.NI cs.SY eess.SY</categories><comments>14 pages, 17 figures, IJCSNS International Journal of Computer
  Science and Network Security,
  http://paper.ijcsns.org/07_book/201907/20190708.pdf</comments><journal-ref>VOL.19 No.7, July 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, HTTP Adaptive Streaming HAS has received significant attention from
both industry and academia based on its ability to enhancing media streaming
services over the Internet. Recent research solutions that have tried to
improve HAS by adaptation at the client side only may not be completely
effective without interacting with routing decisions in the upper layers. In
this paper, we address the aforementioned issue by proposing a dynamic
bandwidth allocation and management architecture for streaming video flows to
improve users satisfaction. We also introduce an initial cross layer hybrid
method that combines quality adaptation of variable bitrate video streaming
over the HTTP protocol at the client side and SDN based dynamical routing. This
scheme is enabled by the Software Defined Networking architecture that is now
being considered as an emerging paradigm that disassociates the forwarding
process from the routing process. SDN brings flexibility and the ability to
flexibly change routing solutions, in turn resulting in dynamically improving
the services provided in the application layer. Our experimental results show
that the proposed solution offers significantly higher overall bitrates as well
as smoother viewing experience than existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09773</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09773</id><created>2019-08-26</created><authors><author><keyname>Kanhere</keyname><forenames>Ojas</forenames></author><author><keyname>Ju</keyname><forenames>Shihao</forenames></author><author><keyname>Xing</keyname><forenames>Yunchou</forenames></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author></authors><title>Map-Assisted Millimeter Wave Localization for Accurate Position Location</title><categories>cs.IT eess.SP math.IT</categories><comments>GLOBECOM 2019 - 2019 IEEE Global Communications Conference, Hawaii,
  U.S.A, Dec. 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate precise positioning at millimeter wave frequencies is possible due
to the large available bandwidth that permits precise on-the-fly time of flight
measurements using conventional air interface standards. In addition, narrow
antenna beamwidths may be used to determine the angles of arrival and departure
of the multipath components between the base station and mobile users. By
combining accurate temporal and angular information of multipath components
with a 3-D map of the environment (that may be built by each user or downloaded
a-priori), robust localization is possible, even in non-line-of-sight
environments. In this work, we develop an accurate 3-D ray tracer for an indoor
office environment and demonstrate how the fusion of angle of departure and
time of flight information in concert with a 3-D map of a typical large office
environment provides a mean accuracy of 12.6 cm in line-of-sight and 16.3 cm in
non-line-of-sight, over 100 receiver distances ranging from 1.5 m to 24.5 m
using a single base station. We show how increasing the number of base stations
improves the average non-line-of-sight position location accuracy to 5.5 cm at
21 locations with a maximum propagation distance of 24.5 m.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09775</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09775</id><created>2019-08-26</created><authors><author><keyname>De Silva</keyname><forenames>D. D. N.</forenames></author><author><keyname>Vithanage</keyname><forenames>H. W. M. K.</forenames></author><author><keyname>Fernando</keyname><forenames>K. S. D.</forenames></author><author><keyname>Piyatilake</keyname><forenames>I. T. S.</forenames></author></authors><title>Multi-Path Learnable Wavelet Neural Network for Image Classification</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the remarkable success of deep learning in pattern recognition, deep
network models face the problem of training a large number of parameters. In
this paper, we propose and evaluate a novel multi-path wavelet neural network
architecture for image classification with far less number of trainable
parameters. The model architecture consists of a multi-path layout with several
levels of wavelet decompositions performed in parallel followed by fully
connected layers. These decomposition operations comprise wavelet neurons with
learnable parameters, which are updated during the training phase using the
back-propagation algorithm. We evaluate the performance of the introduced
network using common image datasets without data augmentation except for SVHN
and compare the results with influential deep learning models. Our findings
support the possibility of reducing the number of parameters significantly in
deep neural networks without compromising its accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09779</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09779</id><created>2019-08-26</created><updated>2019-11-17</updated><authors><author><keyname>Palodhi</keyname><forenames>Kanik</forenames></author><author><keyname>Chatterjee</keyname><forenames>Joydeep</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Rupamoy</forenames></author><author><keyname>Dey</keyname><forenames>S.</forenames></author><author><keyname>Ghosh</keyname><forenames>Sanjay K.</forenames></author><author><keyname>Maulik</keyname><forenames>Atanu</forenames></author><author><keyname>Raha</keyname><forenames>Sibaji</forenames></author></authors><title>Convolution based hybrid image processing technique for microscopic
  images of etch-pits in Nuclear Track Detectors</title><categories>physics.ins-det eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel image processing technique based on convolution is developed for
analyzing the etch-pit images in Nuclear Track Detectors (NTDs). The outcomes
of the application of the proposed method on the different types of NTDs (e.g.,
CR-39, PET) containing etch-pit openings of different sizes and shapes
(circular and elliptical) is presented. Promising results have been obtained
for both identifying and counting the etch-pits in NTDs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09799</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09799</id><created>2019-08-26</created><authors><author><keyname>Kim</keyname><forenames>Sunwoo</forenames></author><author><keyname>Kim</keyname><forenames>Minje</forenames></author></authors><title>Nearest Neighbor Search-Based Bitwise Source Separation Using
  Discriminant Winner-Take-All Hashing</title><categories>eess.AS cs.AI</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an iteration-free source separation algorithm based on
Winner-Take-All (WTA) hash codes, which is a faster, yet accurate alternative
to a complex machine learning model for single-channel source separation in a
resource-constrained environment. We first generate random permutations with
WTA hashing to encode the shape of the multidimensional audio spectrum to a
reduced bitstring representation. A nearest neighbor search on the hash codes
of an incoming noisy spectrum as the query string results in the closest
matches among the hashed mixture spectra. Using the indices of the matching
frames, we obtain the corresponding ideal binary mask vectors for denoising.
Since both the training data and the search operation are bitwise, the
procedure can be done efficiently in hardware implementations. Experimental
results show that the WTA hash codes are discriminant and provide an affordable
dictionary search mechanism that leads to a competent performance compared to a
comprehensive model and oracle masking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09801</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09801</id><created>2019-08-23</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Sun</keyname><forenames>Kai</forenames></author></authors><title>Differential Transformation of a Motor Load Model for Time-Domain
  Simulation</title><categories>eess.SY cs.SY eess.SP math.OC</categories><comments>2 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Differential Transformation (DT) method has demonstrated its potential in
speeding up power system time-domain simulation by our previous work. This
letter further derives DTs about a motor load model and proves that the
nonlinear current injection equation about a motor load can be transformed into
a linear equation by means of DT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09806</identifier>
 <datestamp>2020-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09806</id><created>2019-08-26</created><updated>2020-02-25</updated><authors><author><keyname>Kim</keyname><forenames>Hyowon</forenames></author><author><keyname>Granstr&#xf6;m</keyname><forenames>Karl</forenames></author><author><keyname>Gao</keyname><forenames>Lin</forenames></author><author><keyname>Battistelli</keyname><forenames>Giorgio</forenames></author><author><keyname>Kim</keyname><forenames>Sunwoo</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author></authors><title>5G mmWave Cooperative Positioning and Mapping using Multi-Model PHD
  Filter and Map Fusion</title><categories>eess.SP</categories><comments>This work has been accepted in the IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G millimeter wave (mmWave) signals can enable accurate positioning in
vehicular networks when the base station and vehicles are equipped with large
antenna arrays. However, radio-based positioning suffers from multipath signals
generated by different types of objects in the physical environment. Multipath
can be turned into a benefit, by building up a radio map (comprising the number
of objects, object type, and object state) and using this map to exploit all
available signal paths for positioning. We propose a new method for cooperative
vehicle positioning and mapping of the radio environment, comprising a
multiple-model probability hypothesis density filter and a map fusion routine,
which is able to consider different types of objects and different fields of
views. Simulation results demonstrate the performance of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09825</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09825</id><created>2019-08-09</created><authors><author><keyname>Zhang</keyname><forenames>Erlei</forenames></author><author><keyname>Yang</keyname><forenames>Zi</forenames></author><author><keyname>Seiler</keyname><forenames>Stephen</forenames></author><author><keyname>Chen</keyname><forenames>Mingli</forenames></author><author><keyname>Lu</keyname><forenames>Weiguo</forenames></author><author><keyname>Gu</keyname><forenames>Xuejun</forenames></author></authors><title>Breast Ultrasound Computer-Aided Diagnosis Using Structure-Aware Triplet
  Path Networks</title><categories>eess.IV cs.CV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1904.01076</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Breast ultrasound (US) is an effective imaging modality for breast cancer
detec-tion and diagnosis. The structural characteristics of breast lesion play
an im-portant role in Computer-Aided Diagnosis (CAD). In this paper, a novel
struc-ture-aware triplet path networks (SATPN) was designed to integrate
classifica-tion and two image reconstruction tasks to achieve accurate
diagnosis on US im-ages with small training dataset. Specifically, we enhance
clinically-approved breast lesion structure characteristics though converting
original breast US imag-es to BIRADS-oriented feature maps (BFMs) with a
distance-transformation coupled Gaussian filter. Then, the converted BFMs were
used as the inputs of SATPN, which performed lesion classification task and two
unsupervised stacked convolutional Auto-Encoder (SCAE) networks for benign and
malignant image reconstruction tasks, independently. We trained the SATPN with
an alter-native learning strategy by balancing image reconstruction error and
classification label prediction error. At the test stage, the lesion label was
determined by the weighted voting with reconstruction error and label
prediction error. We com-pared the performance of the SATPN with TPN using
original image as input and our previous developed semi-supervised deep
learning methods using BFMs as inputs. Experimental results on two breast US
datasets showed that SATPN ranked the best among the three networks, with
classification accuracy around 93.5%. These findings indicated that SATPN is
promising for effective breast US lesion CAD using small datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09826</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09826</id><created>2019-08-20</created><authors><author><keyname>Eletreby</keyname><forenames>Rashad</forenames></author><author><keyname>Yagan</keyname><forenames>Osman</forenames></author></authors><title>Secure Connectivity of Heterogeneous Wireless Sensor Networks Under a
  Heterogeneous On-Off Channel Model</title><categories>eess.SP cs.IT math.CO math.IT math.PR</categories><comments>Submitted. arXiv admin note: text overlap with arXiv:1604.00460,
  arXiv:1610.07576</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the secure connectivity of wireless sensor
networks utilizing the heterogeneous random key predistribution scheme, where
each sensor node is classified as class-$i$ with probability $\mu_i$ for
$i=1,\ldots,r$ with $\mu_i&gt;0$ and $\sum_{i=1}^r \mu_i=1$. A class-$i$ sensor is
given $K_i$ cryptographic keys selected uniformly at random from a key pool of
size $P$. After deployment, two nodes can communicate securely if they share at
least one cryptographic key. We consider the wireless connectivity of the
network using a heterogeneous on-off channel model, where the channel between a
class-$i$ node and a class-$j$ node is on (respectively, off) with probability
$\alpha_{ij}$ (respectively, $1-\alpha_{ij}$) for $i,j=1,\ldots,r$.
Collectively, two sensor nodes are adjacent if they i) share a cryptographic
key and ii) have a wireless channel in between that is on. We model the overall
network using a composite random graph obtained by the intersection of
inhomogeneous random key graphs (IRKG) $\mathbb{K}(n;\pmb{\mu},\pmb{K},P)$ with
inhomogeneous Erd\H{o}s-R\'enyi graphs (IERG) $\mathbb{G}(n;\pmb{\mu},
\pmb{\alpha})$. The former graph is naturally induced by the heterogeneous
random key predistribution scheme, while the latter is induced by the
heterogeneous on-off channel model. More specifically, two nodes are adjacent
in the composite graph if they are i) adjacent in the IRKG i.e., share a
cryptographic key and ii) adjacent in the IERG, i.e., have an available
wireless channel. We investigate the connectivity of the composite random graph
and present conditions (in the form of zero-one laws) on how to scale its
parameters so that it i) has no secure node which is isolated and ii) is
securely connected, both with high probability when the number of nodes gets
large. We also present numerical results to support these zero-one laws in the
finite-node regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09828</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09828</id><created>2019-08-23</created><authors><author><keyname>Huang</keyname><forenames>Xianan</forenames></author><author><keyname>Li</keyname><forenames>Boqi</forenames></author><author><keyname>Peng</keyname><forenames>Huei</forenames></author><author><keyname>Auld</keyname><forenames>Joshua A.</forenames></author><author><keyname>Sokolov</keyname><forenames>Vadim O.</forenames></author></authors><title>Eco-Mobility-on-Demand Fleet Control with Ride-Sharing</title><categories>stat.AP cs.RO eess.SP math.OC</categories><comments>arXiv admin note: text overlap with arXiv:1801.08602</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shared Mobility-on-Demand using automated vehicles can reduce energy
consumption and cost for future mobility. However, its full potential in energy
saving has not been fully explored. An algorithm to minimize fleet fuel
consumption while satisfying customers travel time constraints is developed in
this paper. Numerical simulations with realistic travel demand and route choice
are performed, showing that if fuel consumption is not considered, the MOD
service can increase fleet fuel consumption due to increased empty vehicle
mileage. With fuel consumption as part of the cost function, we can reduce
total fuel consumption by 12 percent while maintaining a high level of mobility
service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09873</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09873</id><created>2019-08-26</created><updated>2019-09-05</updated><authors><author><keyname>G&#xf3;rriz</keyname><forenames>Marc</forenames></author><author><keyname>Mrak</keyname><forenames>Marta</forenames></author><author><keyname>Smeaton</keyname><forenames>Alan F.</forenames></author><author><keyname>O'Connor</keyname><forenames>Noel E.</forenames></author></authors><title>End-to-End Conditional GAN-based Architectures for Image Colourisation</title><categories>eess.IV cs.CV cs.LG</categories><comments>IEEE 21st International Workshop on Multimedia Signal Processing,
  27-29 Sept 2019, Kuala Lumpur, Malaysia</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this work recent advances in conditional adversarial networks are
investigated to develop an end-to-end architecture based on Convolutional
Neural Networks (CNNs) to directly map realistic colours to an input greyscale
image. Observing that existing colourisation methods sometimes exhibit a lack
of colourfulness, this paper proposes a method to improve colourisation
results. In particular, the method uses Generative Adversarial Neural Networks
(GANs) and focuses on improvement of training stability to enable better
generalisation in large multi-class image datasets. Additionally, the
integration of instance and batch normalisation layers in both generator and
discriminator is introduced to the popular U-Net architecture, boosting the
network capabilities to generalise the style changes of the content. The method
has been tested using the ILSVRC 2012 dataset, achieving improved automatic
colourisation results compared to other methods based on GANs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09935</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09935</id><created>2019-08-26</created><authors><author><keyname>Fitwi</keyname><forenames>Alem</forenames></author><author><keyname>Chen</keyname><forenames>Yu</forenames></author><author><keyname>Zhu</keyname><forenames>Sencun</forenames></author></authors><title>No Peeking through My Windows: Conserving Privacy in Personal Drones</title><categories>cs.CR cs.CV eess.IV</categories><comments>To be presented at The Fifth IEEE Annual International Smart Cities
  Conference (ISC2 2019), Casablanca, Morocco, October 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The drone technology has been increasingly used by many tech-savvy consumers,
a number of defense companies, hobbyists and enthusiasts during the last ten
years. Drones often come in various sizes and are designed for a multitude of
purposes. Nowadays many people have small-sized personal drones for
entertainment, filming, or transporting items from one place to another.
However, personal drones lack a privacy-preserving mechanism. While in mission,
drones often trespass into the personal territories of other people and capture
photos or videos through windows without their knowledge and consent. They may
also capture video or pictures of people walking, sitting, or doing private
things within the drones' reach in clear form without their go permission. This
could potentially invade people's personal privacy. This paper, therefore,
proposes a lightweight privacy-preserving-by-design method that prevents drones
from peeking through windows of houses and capturing people doing private
things at home. It is a fast window object detection and scrambling technology
built based on image-enhancing, morphological transformation, segmentation and
contouring processes (MASP). Besides, a chaotic scrambling technique is
incorporated into it for privacy purpose. Hence, this mechanism detects window
objects in every image or frame of a real-time video and masks them chaotically
to protect the privacy of people. The experimental results validated that the
proposed MASP method is lightweight and suitable to be employed in drones,
considered as edge devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09944</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09944</id><created>2019-08-26</created><authors><author><keyname>Zhu</keyname><forenames>Bin</forenames></author><author><keyname>Ferrante</keyname><forenames>Augusto</forenames></author><author><keyname>Karlsson</keyname><forenames>Johan</forenames></author><author><keyname>Zorzi</keyname><forenames>Mattia</forenames></author></authors><title>M^2-Spectral Estimation: A Relative Entropy Approach</title><categories>math.OC eess.SP</categories><comments>14 pages in IEEE-TAC double-column template, 6 figures</comments><msc-class>30E05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with M^2-signals, namely multivariate (or vector-valued)
signals defined over a multidimensional domain. In particular, we propose an
optimization technique to solve the covariance extension problem for stationary
random vector fields. The multidimensional Itakura-Saito distance is employed
as an optimization criterion to select the solution among the spectra
satisfying a finite number of moment constraints. In order to avoid
technicalities that may happen on the boundary of the feasible set, we deal
with the discrete version of the problem where the multidimensional integrals
are approximated by Riemann sums. The spectrum solution is also discrete, which
occurs naturally when the underlying random field is periodic. We show that a
solution to the discrete problem exists, is unique and depends smoothly on the
problem data. Therefore, we have a well-posed problem whose solution can be
tuned in a smooth manner. Finally, we have applied our theory to the target
parameter estimation problem in an integrated system of automotive modules.
Simulation results show that our spectral estimator has promising performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09950</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09950</id><created>2019-08-26</created><updated>2019-08-29</updated><authors><author><keyname>Rego</keyname><forenames>Brenner S.</forenames></author><author><keyname>Raffo</keyname><forenames>Guilherme V.</forenames></author><author><keyname>Scott</keyname><forenames>Joseph K.</forenames></author><author><keyname>Raimondo</keyname><forenames>Davide M.</forenames></author></authors><title>Guaranteed methods based on constrained zonotopes for set-valued state
  estimation of nonlinear discrete-time systems</title><categories>math.OC cs.SY eess.SY math.DS</categories><comments>This includes the supplement &quot;Supplementary material for: Guaranteed
  methods based on constrained zonotopes for set-valued state estimation of
  nonlinear discrete-time systems&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents new methods for set-valued state estimation of nonlinear
discrete-time systems with unknown-but-bounded uncertainties. A single time
step involves propagating an enclosure of the system states through the
nonlinear dynamics (prediction), and then enclosing the intersection of this
set with a bounded-error measurement (update). When these enclosures are
represented by simple sets such as intervals, ellipsoids, parallelotopes, and
zonotopes, certain set operations can be very conservative. Yet, using general
convex polytopes is much more computationally demanding. To address this, this
paper presents two new methods, a mean value extension and a first-order Taylor
extension, for efficiently propagating constrained zonotopes through nonlinear
mappings. These extend existing methods for zonotopes in a consistent way.
Examples show that these extensions yield tighter prediction enclosures than
zonotopic estimation methods, while largely retaining the computational
benefits of zonotopes. Moreover, they enable tighter update enclosures because
constrained zonotopes can represent intersections much more accurately than
zonotopes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09953</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09953</id><created>2019-08-26</created><authors><author><keyname>Wright</keyname><forenames>Matthew A.</forenames></author><author><keyname>Horowitz</keyname><forenames>Roberto</forenames></author><author><keyname>Kurzhanskiy</keyname><forenames>Alex A.</forenames></author></authors><title>Macroscopic Modeling, Calibration, and Simulation of Managed
  Lane-Freeway Networks, Part II: Network-scale Calibration and Case Studies</title><categories>eess.SY cs.SY math.OC</categories><comments>Part I is here: arXiv:1609.09470</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Part I of this paper series, several macroscopic traffic model elements
for mathematically describing freeway networks equipped with managed lane
facilities were proposed. These modeling techniques seek to capture at the
macroscopic the complex phenomena that occur on managed lane-freeway networks,
where two parallel traffic flows interact with each other both in the physical
sense (how and where cars flow between the two lane groups) and the
physiological sense (how driving behaviors are changed by being adjacent to a
quantitatively and qualitatively different traffic flow).
  The local descriptions we developed in Part I are not the only modeling
complexity introduced in managed lane-freeway networks. The complex topologies
mean that network-scale modeling of a freeway corridor is increased in
complexity as well. The already-difficult model calibration problem for a
dynamic model of a freeway becomes more complex when the freeway becomes, in
effect, two interrelating flow streams. In the present paper, we present an
iterative-learning-based approach to calibrating our model's physical and
driver-behavioral parameters. We consider the common situation where a complex
traffic model needs to be calibrated to recreate real-world baseline traffic
behavior, such that counterfactuals can be generated by training purposes. Our
method is used to identify traditional freeway parameters as well as the
proposed parameters that describe managed lane-freeway-network-specific
behaviors. We validate our model and calibration methodology with case studies
of simulations of two managed lane-equipped California freeways.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09993</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09993</id><created>2019-08-26</created><authors><author><keyname>Luo</keyname><forenames>Ziqian</forenames></author><author><keyname>Zeng</keyname><forenames>Xiangrui</forenames></author><author><keyname>Bao</keyname><forenames>Zhipeng</forenames></author><author><keyname>Xu</keyname><forenames>Min</forenames></author></authors><title>Deep Learning-Based Strategy for Macromolecules Classification with
  Imbalanced Data from Cellular Electron Cryotomography</title><categories>eess.IV cs.CV cs.LG q-bio.QM</categories><comments>13 pages. arXiv admin note: text overlap with arXiv:1710.09412,
  arXiv:1710.05381, arXiv:1708.02002 by other authors</comments><journal-ref>2019 International Joint Conference on Neural Networks (IJCNN)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning model trained by imbalanced data may not work satisfactorily
since it could be determined by major classes and thus may ignore the classes
with small amount of data. In this paper, we apply deep learning based
imbalanced data classification for the first time to cellular macromolecular
complexes captured by Cryo-electron tomography (Cryo-ET). We adopt a range of
strategies to cope with imbalanced data, including data sampling, bagging,
boosting, Genetic Programming based method and. Particularly, inspired from
Inception 3D network, we propose a multi-path CNN model combining focal loss
and mixup on the Cryo-ET dataset to expand the dataset, where each path had its
best performance corresponding to each type of data and let the network learn
the combinations of the paths to improve the classification performance. In
addition, extensive experiments have been conducted to show our proposed method
is flexible enough to cope with different number of classes by adjusting the
number of paths in our multi-path model. To our knowledge, this work is the
first application of deep learning methods of dealing with imbalanced data to
the internal tissue classification of cell macromolecular complexes, which
opened up a new path for cell classification in the field of computational
biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09998</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.09998</id><created>2019-08-26</created><authors><author><keyname>Kwon</keyname><forenames>Gukyeong</forenames></author><author><keyname>Prabhushankar</keyname><forenames>Mohit</forenames></author><author><keyname>Temel</keyname><forenames>Dogancan</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Distorted Representation Space Characterization Through Backpropagated
  Gradients</title><categories>cs.CV eess.IV</categories><comments>5 pages, 5 figures, 2 tables, ICIP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we utilize weight gradients from backpropagation to
characterize the representation space learned by deep learning algorithms. We
demonstrate the utility of such gradients in applications including perceptual
image quality assessment and out-of-distribution classification. The
applications are chosen to validate the effectiveness of gradients as features
when the test image distribution is distorted from the train image
distribution. In both applications, the proposed gradient based features
outperform activation features. In image quality assessment, the proposed
approach is compared with other state of the art approaches and is generally
the top performing method on TID 2013 and MULTI-LIVE databases in terms of
accuracy, consistency, linearity, and monotonic behavior. Finally, we analyze
the effect of regularization on gradients using CURE-TSR dataset for
out-of-distribution classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10009</identifier>
 <datestamp>2020-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10009</id><created>2019-08-26</created><updated>2020-01-01</updated><authors><author><keyname>Gao</keyname><forenames>Peng</forenames></author><author><keyname>Zhang</keyname><forenames>Qiquan</forenames></author><author><keyname>Wang</keyname><forenames>Fei</forenames></author><author><keyname>Xiao</keyname><forenames>Liyi</forenames></author><author><keyname>Fujita</keyname><forenames>Hamido</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author></authors><title>Learning Reinforced Attentional Representation for End-to-End Visual
  Tracking</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted by Information Sciences</comments><doi>10.1016/j.ins.2019.12.084</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although numerous recent tracking approaches have made tremendous advances in
the last decade, achieving high-performance visual tracking remains a
challenge. In this paper, we propose an end-to-end network model to learn
reinforced attentional representation for accurate target object discrimination
and localization. We utilize a novel hierarchical attentional module with long
short-term memory and multi-layer perceptrons to leverage both inter- and
intra-frame attention to effectively facilitate visual pattern emphasis.
Moreover, we incorporate a contextual attentional correlation filter into the
backbone network to make our model trainable in an end-to-end fashion. Our
proposed approach not only takes full advantage of informative geometries and
semantics but also updates correlation filters online without fine-tuning the
backbone network to enable the adaptation of variations in the target object's
appearance. Extensive experiments conducted on several popular benchmark
datasets demonstrate that our proposed approach is effective and
computationally efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10012</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10012</id><created>2019-08-27</created><updated>2019-10-19</updated><authors><author><keyname>Wu</keyname><forenames>Yuanwei</forenames></author><author><keyname>Zhang</keyname><forenames>Ziming</forenames></author><author><keyname>Wang</keyname><forenames>Guanghui</forenames></author></authors><title>Unsupervised Deep Feature Transfer for Low Resolution Image
  Classification</title><categories>cs.CV cs.LG eess.IV</categories><comments>4 pages, accepted to ICCV19 Workshop and Challenge on Real-World
  Recognition from Low-Quality Images and Videos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a simple while effective unsupervised deep feature
transfer algorithm for low resolution image classification. No fine-tuning on
convenet filters is required in our method. We use pre-trained convenet to
extract features for both high- and low-resolution images, and then feed them
into a two-layer feature transfer network for knowledge transfer. A SVM
classifier is learned directly using these transferred low resolution features.
Our network can be embedded into the state-of-the-art deep neural networks as a
plug-in feature enhancement module. It preserves data structures in feature
space for high resolution images, and transfers the distinguishing features
from a well-structured source domain (high resolution features space) to a not
well-organized target domain (low resolution features space). Extensive
experiments on VOC2007 test set show that the proposed method achieves
significant improvements over the baseline of using feature extraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10017</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10017</id><created>2019-08-27</created><authors><author><keyname>Ma</keyname><forenames>Xiaolong</forenames></author><author><keyname>Yuan</keyname><forenames>Geng</forenames></author><author><keyname>Lin</keyname><forenames>Sheng</forenames></author><author><keyname>Ding</keyname><forenames>Caiwen</forenames></author><author><keyname>Yu</keyname><forenames>Fuxun</forenames></author><author><keyname>Liu</keyname><forenames>Tao</forenames></author><author><keyname>Wen</keyname><forenames>Wujie</forenames></author><author><keyname>Chen</keyname><forenames>Xiang</forenames></author><author><keyname>Wang</keyname><forenames>Yanzhi</forenames></author></authors><title>Tiny but Accurate: A Pruned, Quantized and Optimized Memristor Crossbar
  Framework for Ultra Efficient DNN Implementation</title><categories>eess.SP cs.AR cs.ET cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The state-of-art DNN structures involve intensive computation and high memory
storage. To mitigate the challenges, the memristor crossbar array has emerged
as an intrinsically suitable matrix computation and low-power acceleration
framework for DNN applications. However, the high accuracy solution for extreme
model compression on memristor crossbar array architecture is still waiting for
unraveling. In this paper, we propose a memristor-based DNN framework which
combines both structured weight pruning and quantization by incorporating
alternating direction method of multipliers (ADMM) algorithm for better pruning
and quantization performance. We also discover the non-optimality of the ADMM
solution in weight pruning and the unused data path in a structured pruned
model. Motivated by these discoveries, we design a software-hardware
co-optimization framework which contains the first proposed Network
Purification and Unused Path Removal algorithms targeting on post-processing a
structured pruned model after ADMM steps. By taking memristor hardware
constraints into our whole framework, we achieve extreme high compression ratio
on the state-of-art neural network structures with minimum accuracy loss. For
quantizing structured pruned model, our framework achieves nearly no accuracy
loss after quantizing weights to 8-bit memristor weight representation. We
share our models at anonymous link https://bit.ly/2VnMUy0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10032</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10032</id><created>2019-08-27</created><authors><author><keyname>Mallikarjun</keyname><forenames>Chithaj</forenames></author><author><keyname>Shanbog</keyname><forenames>Niteesh S</forenames></author><author><keyname>Modi</keyname><forenames>Sangeeta</forenames></author></authors><title>Comparative Analysis of Conventional and Modified H-Bridge Inverter
  Configuration</title><categories>eess.SY cs.SY eess.SP math.DS physics.app-ph</categories><comments>Presented in International Conference on Recent Innovations in
  Electrical, Electronics and Communications Engineering (ICRIEECE-2018),
  Bhubaneswar, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a comparative analysis is presented for conventional and
modified H Bridge configuration of 5 and 7 level inverter. A modified H Bridge
converter utilizes a reduced number of switches for the same level output as
compared to the conventional H-Bridge configuration. The lower number of
switches will result in reduced switching losses, installation cost and
converter cost. MATLAB/SIMULINK software is used for simulation of the
different configurations used for the comparison. R and RL type of load are
used and the corresponding voltage waveform is analyzed for its harmonic
content. It can be seen from the results obtained that the Total Harmonic
Distortion (THD) in the modified and conventional 7 level configuration is less
than that of the 5 level inverter configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10044</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10044</id><created>2019-08-27</created><authors><author><keyname>Jose</keyname><forenames>John Anthony C.</forenames></author><author><keyname>Ching</keyname><forenames>Phoebe Mae L.</forenames></author><author><keyname>Cabatuan</keyname><forenames>Melvin K.</forenames></author></authors><title>Development of a Robust Depth-Pressure Estimation Algorithm for a
  Vision-Based Breast Self-Examination Guidance System</title><categories>eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the case of breast cancer, as with most cancers, early detection can
significantly improve a person's chances of survival. This makes it important
for there to be an effective and accessible means of regularly checking for
manifestations of the disease. A vision-based guidance system (VBGS) for breast
self-examination (BSE) is one way to improve a person's ability to detect the
cancerous systems. In response to this need, this study sought to develop a
depth-pressure estimation algorithm for the proposed VBGS. A large number of
BSE videos were used to train the model, and these samples were segmented
according to breast size, which was found to be a differentiation factor in the
depth-pressure estimation. The result was an algorithm that was applicable for
universal use. In addition to these, several feature extraction schemes were
tested with the objective of making the algorithm functional on average
technology. It was found that Law's Textures Histogram and Local Binary Pattern
Global Histogram were the most effective in estimating pressure using visual
data. Moreover, combinations of the two schemes further improved the accuracy
of the model in estimation. The resulting algorithm was thereby fit to be used
by the average consumer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10055</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10055</id><created>2019-08-27</created><authors><author><keyname>Okamoto</keyname><forenames>Yuki</forenames></author><author><keyname>Imoto</keyname><forenames>Keisuke</forenames></author><author><keyname>Komatsu</keyname><forenames>Tatsuya</forenames></author><author><keyname>Takamichi</keyname><forenames>Shinnosuke</forenames></author><author><keyname>Yagyu</keyname><forenames>Takumi</forenames></author><author><keyname>Yamanishi</keyname><forenames>Ryosuke</forenames></author><author><keyname>Yamashita</keyname><forenames>Yoichi</forenames></author></authors><title>Overview of Tasks and Investigation of Subjective Evaluation Methods in
  Environmental Sound Synthesis and Conversion</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synthesizing and converting environmental sounds have the potential for many
applications such as supporting movie and game production, data augmentation
for sound event detection and scene classification. Conventional works on
synthesizing and converting environmental sounds are based on a physical
modeling or concatenative approach. However, there are a limited number of
works that have addressed environmental sound synthesis and conversion with
statistical generative models; thus, this research area is not yet well
organized. In this paper, we review problem definitions, applications, and
evaluation methods of environmental sound synthesis and conversion. We then
report on environmental sound synthesis using sound event labels, in which we
focus on the current performance of statistical environmental sound synthesis
and investigate how we should conduct subjective experiments on environmental
sound synthesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10056</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10056</id><created>2019-08-27</created><authors><author><keyname>Nguyen</keyname><forenames>Nhan Thanh</forenames></author><author><keyname>Lee</keyname><forenames>Kyungchun</forenames></author></authors><title>Unequally Sub-connected Architecture for Hybrid Beamforming in Massive
  MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A variety of hybrid analog-digital beamforming architectures have recently
been proposed for massive multiple-input multiple-output (MIMO) systems to
reduce energy consumption and the cost of implementation. In the analog
processing network of these architectures, the practical sub-connected
structure requires lower power consumption and hardware complexity than the
fully connected structure but cannot fully exploit the beamforming gains, which
leads to a loss in overall performance. In this work, we propose a novel
unequal sub-connected architecture for hybrid combining at the receiver of a
massive MIMO system that employs unequal numbers of antennas in sub-antenna
arrays. The optimal design of the proposed architecture is analytically
derived, and includes antenna allocation and channel ordering schemes.
Simulation results show that an enhancement of up to 10% can be attained in the
total achievable rate by unequally assigning antennas to sub-arrays in the
sub-connected system at the cost of a marginal increase in power consumption.
Furthermore, in order to reduce the computational complexity involved in
finding the optimal number of antennas connected to each radio frequency (RF)
chain, we propose three low-complexity antenna allocation algorithms. The
simulation results show that they can yield a significant reduction in
complexity while achieving near-optimal performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10062</identifier>
 <datestamp>2019-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10062</id><created>2019-08-27</created><updated>2019-11-18</updated><authors><author><keyname>Xu</keyname><forenames>Yicheng</forenames></author><author><keyname>Chu</keyname><forenames>Hongyun</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Joint Timing Offset and Channel Estimation for Multi-user Universal
  Filtered Multi-Carrier Uplink</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1902.09177</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The universal filtered multi-carrier (UFMC) system, which groups and filters
subcarriers before transmission, is a potential multi-carrier modulation
technique for the emerging Machine-Type Communications. Given the relaxed time
synchronization requirement of UFMC, we design a novel joint timing offset and
channel estimation method for multi-user UFMC uplink transmission. The joint
estimation problem is formulated based on atomic norm minimization (ANM) that
enhances the sparsity of timing offsets in the continuous frequency domain.
Simulation results show that the proposed method can achieve considerable
performance gain, as compared with existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10079</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10079</id><created>2019-08-27</created><updated>2019-09-04</updated><authors><author><keyname>Xu</keyname><forenames>Jiahua</forenames></author><author><keyname>Luo</keyname><forenames>Ziyuan</forenames></author><author><keyname>Zhou</keyname><forenames>Wei</forenames></author><author><keyname>Zhang</keyname><forenames>Wenyuan</forenames></author><author><keyname>Chen</keyname><forenames>Zhibo</forenames></author></authors><title>Quality Assessment of Stereoscopic 360-degree Images from
  Multi-viewports</title><categories>eess.IV cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective quality assessment of stereoscopic panoramic images becomes a
challenging problem owing to the rapid growth of 360-degree contents. Different
from traditional 2D image quality assessment (IQA), more complex aspects are
involved in 3D omnidirectional IQA, especially unlimited field of view (FoV)
and extra depth perception, which brings difficulty to evaluate the quality of
experience (QoE) of 3D omnidirectional images. In this paper, we propose a
multi-viewport based fullreference stereo 360 IQA model. Due to the freely
changeable viewports when browsing in the head-mounted display (HMD), our
proposed approach processes the image inside FoV rather than the projected one
such as equirectangular projection (ERP). In addition, since overall QoE
depends on both image quality and depth perception, we utilize the features
estimated by the difference map between left and right views which can reflect
disparity. The depth perception features along with binocular image qualities
are employed to further predict the overall QoE of 3D 360 images. The
experimental results on our public Stereoscopic OmnidirectionaL Image quality
assessment Database (SOLID) show that the proposed method achieves a
significant improvement over some well-known IQA metrics and can accurately
reflect the overall QoE of perceived images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10087</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10087</id><created>2019-08-27</created><authors><author><keyname>Luo</keyname><forenames>Ziyuan</forenames></author><author><keyname>Zhou</keyname><forenames>Wei</forenames></author><author><keyname>Shi</keyname><forenames>Likun</forenames></author><author><keyname>Chen</keyname><forenames>Zhibo</forenames></author></authors><title>No-Reference Light Field Image Quality Assessment Based on Micro-Lens
  Image</title><categories>eess.IV cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Light field image quality assessment (LF-IQA) plays a significant role due to
its guidance to Light Field (LF) contents acquisition, processing and
application. The LF can be represented as 4-D signal, and its quality depends
on both angular consistency and spatial quality. However, few existing LF-IQA
methods concentrate on effects caused by angular inconsistency. Especially,
no-reference methods lack effective utilization of 2-D angular information. In
this paper, we focus on measuring the 2-D angular consistency for LF-IQA. The
Micro-Lens Image (MLI) refers to the angular domain of the LF image, which can
simultaneously record the angular information in both horizontal and vertical
directions. Since the MLI contains 2-D angular information, we propose a
No-Reference Light Field image Quality assessment model based on MLI (LF-QMLI).
Specifically, we first utilize Global Entropy Distribution (GED) and Uniform
Local Binary Pattern descriptor (ULBP) to extract features from the MLI, and
then pool them together to measure angular consistency. In addition, the
information entropy of Sub-Aperture Image (SAI) is adopted to measure spatial
quality. Extensive experimental results show that LF-QMLI achieves the
state-of-the-art performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10088</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10088</id><created>2019-08-27</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>He</keyname><forenames>Runnan</forenames></author><author><keyname>Wang</keyname><forenames>Kuanquan</forenames></author><author><keyname>Li</keyname><forenames>Qince</forenames></author><author><keyname>Sun</keyname><forenames>Qiang</forenames></author><author><keyname>Zhao</keyname><forenames>Na</forenames></author><author><keyname>Zhang</keyname><forenames>Henggui</forenames></author></authors><title>Automatic Detection of ECG Abnormalities by using an Ensemble of Deep
  Residual Networks with Attention</title><categories>cs.LG eess.SP stat.ML</categories><comments>8 pages, 2 figures, conference</comments><msc-class>68T10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heart disease is one of the most common diseases causing morbidity and
mortality. Electrocardiogram (ECG) has been widely used for diagnosing heart
diseases for its simplicity and non-invasive property. Automatic ECG analyzing
technologies are expected to reduce human working load and increase diagnostic
efficacy. However, there are still some challenges to be addressed for
achieving this goal. In this study, we develop an algorithm to identify
multiple abnormalities from 12-lead ECG recordings. In the algorithm pipeline,
several preprocessing methods are firstly applied on the ECG data for
denoising, augmentation and balancing recording numbers of variant classes. In
consideration of efficiency and consistency of data length, the recordings are
padded or truncated into a medium length, where the padding/truncating time
windows are selected randomly to sup-press overfitting. Then, the ECGs are used
to train deep neural network (DNN) models with a novel structure that combines
a deep residual network with an attention mechanism. Finally, an ensemble model
is built based on these trained models to make predictions on the test data
set. Our method is evaluated based on the test set of the First China ECG
Intelligent Competition dataset by using the F1 metric that is regarded as the
harmonic mean between the precision and recall. The resultant overall F1 score
of the algorithm is 0.875, showing a promising performance and potential for
practical use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10092</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10092</id><created>2019-08-27</created><authors><author><keyname>Wang</keyname><forenames>Xueyi</forenames></author><author><keyname>Li</keyname><forenames>Lantian</forenames></author><author><keyname>Wang</keyname><forenames>Dong</forenames></author></authors><title>VAE-based Domain Adaptation for Speaker Verification</title><categories>eess.AS cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep speaker embedding has achieved satisfactory performance in speaker
verification. By enforcing the neural model to discriminate the speakers in the
training set, deep speaker embedding (called `x-vectors`) can be derived from
the hidden layers. Despite its good performance, the present embedding model is
highly domain sensitive, which means that it often works well in domains whose
acoustic condition matches that of the training data (in-domain), but degrades
in mismatched domains (out-of-domain). In this paper, we present a domain
adaptation approach based on Variational Auto-Encoder (VAE). This model
transforms x-vectors to a regularized latent space; within this latent space, a
small amount of data from the target domain is sufficient to accomplish the
adaptation. Our experiments demonstrated that by this VAE-adaptation approach,
speaker embeddings can be easily transformed to the target domain, leading to
noticeable performance improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10097</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10097</id><created>2019-08-27</created><authors><author><keyname>Jiang</keyname><forenames>Yuna</forenames></author><author><keyname>Ge</keyname><forenames>Xiaohu</forenames></author><author><keyname>Zhong</keyname><forenames>Yi</forenames></author><author><keyname>Mao</keyname><forenames>Guoqiang</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author></authors><title>A New Small-World IoT Routing Mechanism based on Cayley Graphs</title><categories>cs.NI eess.SP</categories><comments>12 pages,11 figures,journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An increasing number of low-power Internet of Things (IoT) devices will be
widely deployed in the near future. Considering the short-range communication
of low-power devices, multi-hop transmissions will become an important
transmission mechanism in IoT networks. It is crucial for lowpower devices to
transmit data over long distances via multihop in a low-delay and reliable way.
Small-world characteristics of networks indicate that the network has an
advantage of a small Average Shortest-path Length (ASL) and a high Average
Clustering Coefficient (ACC). In this paper, a new IoT routing mechanism
considering small-world characteristics is proposed to reduce the delay and
improve the reliability. The ASL and ACC are derived for performance analysis
of small-world characteristics in IoT networks based on Cayley graphs. Besides,
the reliability and delay models are proposed for Small-World IoT based on
Cayley grapHs (SWITCH). Simulation results demonstrate that SWITCH has lower
delay and better reliability than that of conventional Nearest Neighboring
Routing (NNR). Moreover, the maximum delay of SWITCH is reduced by 50.6%
compared with that by NNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10120</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10120</id><created>2019-08-27</created><updated>2020-02-02</updated><authors><author><keyname>Ghavamirad</keyname><forenames>Roohollah</forenames></author><author><keyname>Sadeghzadeh</keyname><forenames>Ramezan Ali</forenames></author><author><keyname>Sebt</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Naderi</keyname><forenames>Amir Hossein</forenames></author></authors><title>Range resolution improvement for two close targets by using the FM
  signals</title><categories>eess.SP</categories><comments>3 pages, 10 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have focused on the improvement of the range resolution of
two close targets by using FM signal. Two algorithms comprise IFFT and MUSIC
have been used to reach our goals. On both algorithms, we have tried to improve
the range resolution by using more FM channels. The simulation results show
that the music method by using the same FM channel gives us a good range
resolution twice as well as IFFT method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10121</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10121</id><created>2019-08-27</created><authors><author><keyname>Qussous</keyname><forenames>Ramiz</forenames></author><author><keyname>K&#xfc;nzel</keyname><forenames>Thomas</forenames></author><author><keyname>Weidlich</keyname><forenames>Anke</forenames></author></authors><title>Effects of a Coal Phase-Out on Market Dynamics: Results from a
  Simulation Model for Germany</title><categories>eess.SY cs.SY</categories><comments>Accepted conference proceedings paper for the EEM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling power market dynamics is increasingly challenging, as both spatial
and temporal imbalances of demand and supply are becoming more pronounced with
higher shares of variable renewable energy (VRE). Therefore, a high-resolution
spatial and temporal distribution of both VRE and conventional generation, as
well as the load, is necessary for modeling the effect of policy measures on
the electricity market. Besides, technical constraints must be considered in
detail, as they fundamentally influence market outcomes. This contribution
presents the results and findings from a power market simulation model for the
case of the German market zone under different scenarios phasing out coal-fired
power generation. It is shown that the developed spatially resolved model can
realistically reproduce market outcomes and is, therefore, suitable for the
analysis of future scenarios with increased VRE integration and reduced
conventional generation capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10133</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10133</id><created>2019-08-27</created><authors><author><keyname>Perez-Lopez</keyname><forenames>Andres</forenames></author><author><keyname>Fonseca</keyname><forenames>Eduardo</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>A hybrid parametric-deep learning approach for sound event localization
  and detection</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>5 pages, 5 figures, submitted to DCASE2019 Workshop</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This work describes and discusses an algorithm submitted to the Sound Event
Localization and Detection Task of DCASE2019 Challenge. The proposed
methodology relies on parametric spatial audio analysis for source localization
and detection, combined with a deep learning-based monophonic event classifier.
The evaluation of the proposed algorithm yields overall results comparable to
the baseline system. The main highlight is a reduction of the localization
error on the evaluation dataset by a factor of 2.6, compared with the baseline
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10137</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10137</id><created>2019-08-27</created><authors><author><keyname>Kusche</keyname><forenames>Roman</forenames></author><author><keyname>Ryschka</keyname><forenames>Martin</forenames></author></authors><title>Combining Bioimpedance and EMG Measurements for Reliable Muscle
  Contraction Detection</title><categories>physics.med-ph eess.SP</categories><doi>10.1109/JSEN.2019.2936171</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: Muscle contractions are commonly detected by performing EMG
measurements. The major disadvantage of this technique is that mechanical
disturbances to the electrodes are in the same frequency and magnitude range as
the desired signal. In this work we propose an approach and a realized
measurement system to combine EMG and bioimpedance measurements for higher
reliabilities of muscle contraction detections. Methods: We propose the
development of a modular four-channel measurement system, whereat each channel
is capable of acquiring EMG, the bioimpedance magnitude and phase,
simultaneously. The modules are synchronized by an additional interface board,
which communicates with a PC. A graphical user interface enables to control the
bioimpedance excitation current in a range from 100 {\mu}A to 1 mA in a
frequency range from 50 kHz to 333 kHz. Results: A system characterization
demonstrated that bioimpedance magnitude changes of less than 250 ppm and phase
changes below 0.05{\deg} can be detected reliably. Measurements from a subject
have shown the timing relationship between EMG and bioimpedance signals as well
as their robustness against mechanical disturbances. A measurement of five
exemplary hand gestures has demonstrated the increase of usable information for
detecting muscle contractions. Conclusion: Bioimpedance measurements of muscles
provide useful information about contractions. Furthermore, the usage of a
known high-frequency excitation current enables a reliable differentiation
between the actual information and disturbances. Significance: By combining EMG
and bioimpedance measurements, muscle contractions can be detected much more
reliably. This setup can be adopted to prostheses and many other human-computer
interfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10142</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10142</id><created>2019-08-27</created><updated>2019-10-17</updated><authors><author><keyname>Sato</keyname><forenames>Shigeyoshi</forenames></author><author><keyname>Weidlich</keyname><forenames>Anke</forenames></author></authors><title>Analysis of Avoided Transmission Through Decentralized Photovoltaic and
  Battery Storage Systems</title><categories>eess.SY cs.SY</categories><comments>Submitted to IEEE Transactions on Sustainable Energy</comments><journal-ref>IEEE Transactions on Sustainable Energy 2019</journal-ref><doi>10.1109/TSTE.2019.2946446</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decentralized renewable energy systems can be low-carbon power sources, and
promoters of local economies. It is often argued that decentralized generation
also helps reducing transmission costs, as generation is closer to the load,
thus utilizing the transmission system less. The research presented here
addresses the question whether or not, or under what circumstances this effect
of avoided transmission can actually be seen for a community-operated cluster
of photovoltaic (PV) power plants in two sample locations, one in Germany and
one in Japan. For the analysis, the newly developed instrument of MPI-MPE
diagrams is used, which plot the maximum power import (MPI) and maximum power
export (MPE) in relation to the reference case of no local generation. Results
reveal that for moderately sized PV systems without battery storage, avoided
transmission can be seen in the Japanese model location, but not in Germany. It
was also found that an additional battery storage can lead to avoided
transmission in both locations, even for large sizes of installed PV capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10168</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10168</id><created>2019-08-27</created><authors><author><keyname>Ando</keyname><forenames>Ki</forenames></author><author><keyname>Igarashi</keyname><forenames>Hiroshi</forenames></author><author><keyname>Shinoda</keyname><forenames>Hiroyuki</forenames></author><author><keyname>Mutsukura</keyname><forenames>Nobuki</forenames></author></authors><title>Improvement of photosynthetic rate evaluation by plant bioelectric
  potential using illuminating information and a neural network</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The plant bioelectric potential is believed to be a suitable real-time and
noninvasive method that can be used to evaluate plant activities, such as the
photosynthetic reaction. The amplitude of the bioelectric potential response
when plants are illuminated is correlated with the photosynthetic rate.
However, practically, the bioelectric potential is affected by various
cultivation parameters. This study analyzes the relationship between the
bioelectric potential response and the illuminating parameters using a neural
network to improve the accuracy of the photosynthetic rate evaluation. The
variation of the illuminating colors to the plant affected the relationship
between the amplitude of the bioelectric potential response and the
photosynthetic rate; therefore, evaluating the photosynthetic rate using the
amplitude is difficult. The analysis result shows that the correlation
coefficient between the actual measured photosynthetic rate and the estimated
photosynthetic rate by the neural network is 0.95. The photosynthetic rate
evaluation using the bioelectric potential response is improved and this
correlation coefficient is greater than that analyzed by the neural network
using only the illuminating parameters. This result indicates that the
information on the plant bioelectric potential response contributed to the
accurate estimation of the photosynthetic rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10174</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10174</id><created>2019-08-27</created><authors><author><keyname>Antenucci</keyname><forenames>Andrea</forenames></author><author><keyname>del Granado</keyname><forenames>Pedro Crespo</forenames></author><author><keyname>Gjorgiev</keyname><forenames>Blazhe</forenames></author><author><keyname>Sansavini</keyname><forenames>Giovanni</forenames></author></authors><title>Can models for long-term decarbonization policies guarantee security of
  power supply? A perspective from gas and power sector coupling</title><categories>eess.SY cs.SY</categories><comments>23 pages, 7 figures, 3 tables, 50 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The assessment of adequacy and security of the energy system requires the
detailed knowledge of physical and operational characteristics. In contrast,
studies concerning energy transitions employ stylized models that oftentimes
ignore the technical properties but have a lasting influence on long-term
energy policies. This paper investigates the gap between energy system planning
and operational models by linking these two perspectives: (1) a long-term
investment model with low spatial resolution and high level of aggregation, and
(2) a spatially resolved system security model that captures the
interdependences between the backbone of the electric power sector, i.e., the
electricity and the gas infrastructures. We assess EU decarbonization pathways
of the electricity sector towards 2050 by integrating the investment decisions
of the long-term planning model and the safety performance of the resulting
system operations via the security assessment model. In a large RES deployment
scenario, we investigate two flexibility options: gas power plants and
cross-country transmission expansion. Using the integrated model, we analyze
how the adequacy and security of supply under extreme short-term operational
conditions impact the long-term planning of the energy system and the
investment decision-making. We provide country specific recommendations for UK.
Results indicate weaknesses in the gas-electricity system and suggest
improvements on capacity allocation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10187</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10187</id><created>2019-08-14</created><authors><author><keyname>Carlos</keyname><forenames>M. Ricardo</forenames></author></authors><title>A Machine Learning Approach for Smartphone-based Sensing of Roads and
  Driving Style</title><categories>cs.LG eess.SP stat.ML</categories><comments>Doctoral Dissertation. Dissertation Advisors: Luis Carlos Gonz\'alez
  Gurrola and Fernando Mart\'inez</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Road transportation is of critical importance for a nation, having profound
effects in the economy, the health and life style of its people. With the
growth of cities and populations come bigger demands for mobility and safety,
creating new problems and magnifying those of the past. New tools are needed to
face the challenge, to keep roads in good conditions, their users safe, and
minimize the impact on the environment.
  This dissertation is concerned with road quality assessment and aggressive
driving, two important problems in road transportation, approached in the
context of Intelligent Transportation Systems by using Machine Learning
techniques to analyze acceleration time series acquired with smartphone-based
opportunistic sensing to automatically detect, classify, and characterize
events of interest.
  Two aspects of road quality assessment are addressed: the detection and the
characterization of road anomalies. For the first, the most widely cited works
in the literature are compared and proposals capable of equal or better
performance are presented, removing the reliance on threshold values and
reducing the computational cost and dimensionality of previous proposals. For
the second, new approaches for the estimation of pothole depth and the
functional condition of speed reducers are showed. The new problem of pothole
depth ranking is introduced, using a learning-to-rank approach to sort
acceleration signals by the depth of the potholes that they reflect.
  The classification of aggressive driving maneuvers is done with automatic
feature extraction, finding characteristically shaped subsequences in the
signals as more effective discriminants than conventional descriptors
calculated over time windows.
  Finally, all the previously mentioned tasks are combined to produce a robust
road transport evaluation platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10192</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10192</id><created>2019-08-27</created><updated>2019-08-29</updated><authors><author><keyname>Boiarov</keyname><forenames>Andrei</forenames></author><author><keyname>Tyantov</keyname><forenames>Eduard</forenames></author></authors><title>Large Scale Landmark Recognition via Deep Metric Learning</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted at CIKM 2019</comments><doi>10.1145/3357384.3357956</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel approach for landmark recognition in images that
we've successfully deployed at Mail ru. This method enables us to recognize
famous places, buildings, monuments, and other landmarks in user photos. The
main challenge lies in the fact that it's very complicated to give a precise
definition of what is and what is not a landmark. Some buildings, statues and
natural objects are landmarks; others are not. There's also no database with a
fairly large number of landmarks to train a recognition model. A key feature of
using landmark recognition in a production environment is that the number of
photos containing landmarks is extremely small. This is why the model should
have a very low false positive rate as well as high recognition accuracy.
  We propose a metric learning-based approach that successfully deals with
existing challenges and efficiently handles a large number of landmarks. Our
method uses a deep neural network and requires a single pass inference that
makes it fast to use in production. We also describe an algorithm for cleaning
landmarks database which is essential for training a metric learning model. We
provide an in-depth description of basic components of our method like neural
network architecture, the learning strategy, and the features of our metric
learning approach. We show the results of proposed solutions in tests that
emulate the distribution of photos with and without landmarks from a user
collection. We compare our method with others during these tests. The described
system has been deployed as a part of a photo recognition solution at Cloud
Mail ru, which is the photo sharing and storage service at Mail ru Group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10195</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10195</id><created>2019-08-23</created><authors><author><keyname>Sundaram</keyname><forenames>Jothi Prasanna Shanmuga</forenames></author><author><keyname>Du</keyname><forenames>Wan</forenames></author><author><keyname>Zhao</keyname><forenames>Zhiwei</forenames></author></authors><title>A Survey on LoRa Networking: Research Problems, Current Solutions and
  Open Issues</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless networks have been widely deployed for many Internet-of-Things (IoT)
applications, like smart cities and precision agriculture. Low Power Wide Area
Networking (LPWAN) is an emerging IoT networking paradigm to meet three key
requirements of IoT applications, i.e., low cost, large scale deployment and
high energy efficiency. Among all available LPWAN technologies, LoRa networking
has attracted much attention from both academia and industry, since it
specifies an open standard and allows us to build autonomous LPWAN networks
without any third-party infrastructure. Many LoRa networks have been developed
recently, e.g., managing solar plants in Carson City, Nevada, USA and power
monitoring in Lyon and Grenoble, France. However, there are still many research
challenges to develop practical LoRa networks, e.g., link coordination,
resource allocation, reliable transmissions and security. This article provides
a comprehensive survey on LoRa networks, including the technical challenges of
deploying LoRa networks and recent solutions. Based on our detailed analysis of
current solutions, some open issues of LoRa networking are discussed. The goal
of this survey paper is to inspire more works on improving the performance of
LoRa networks and enabling more practical deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10197</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10197</id><created>2019-08-23</created><authors><author><keyname>Gao</keyname><forenames>Han</forenames></author><author><keyname>Zhu</keyname><forenames>Xueyu</forenames></author><author><keyname>Wang</keyname><forenames>Jian-Xun</forenames></author></authors><title>A Bi-fidelity Surrogate Modeling Approach for Uncertainty Propagation in
  Three-Dimensional Hemodynamic Simulations</title><categories>physics.flu-dyn eess.IV physics.med-ph</categories><comments>44 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image-based computational fluid dynamics (CFD) modeling enables derivation of
hemodynamic information, which has become a paradigm in cardiovascular research
and healthcare. Nonetheless, the predictive accuracy largely depends on
precisely specified boundary conditions and model parameters, which, however,
are usually uncertain in most patient-specific cases. Quantifying the
uncertainties in model predictions due to input randomness can provide
predictive confidence and is critical to promote the transition of CFD modeling
in clinical applications. In the meantime, forward propagation of input
uncertainties often involves numerous expensive CFD simulations, which is
computationally prohibitive in most practical scenarios. This paper presents an
efficient bi-fidelity surrogate modeling framework for uncertainty
quantification (UQ) in cardiovascular simulations, by leveraging the accuracy
of high-fidelity models and efficiency of low-fidelity models. Contrary to most
data-fit surrogate models with several scalar quantities of interest, this work
aims to provide high-resolution, full-field predictions. Moreover, a novel
empirical error bound estimation approach is introduced to evaluate the
performance of the surrogate a priori. The proposed framework is tested on a
number of vascular flows with both standardized and patient-specific vessel
geometries, and different combinations of high- and low-fidelity models are
investigated. The results show that the bi-fidelity approach can achieve high
predictive accuracy with a significant reduction of computational cost,
exhibiting its merit and effectiveness. Particularly, the uncertainties from a
high-dimensional input space can be accurately propagated to clinically
relevant quantities of interest in the patient-specific case using only a
limited number of high-fidelity simulations, suggesting a good potential in
practical clinical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10198</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10198</id><created>2019-08-27</created><authors><author><keyname>Hu</keyname><forenames>Yue</forenames></author><author><keyname>Work</keyname><forenames>Dan</forenames></author></authors><title>Robust Tensor Recovery with Fiber Outliers for Traffic Events</title><categories>eess.SP cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Event detection is gaining increasing attention in smart cities research.
Large-scale mobility data serves as an important tool to uncover the dynamics
of urban transportation systems, and more often than not the dataset is
incomplete. In this article, we develop a method to detect extreme events in
large traffic datasets, and to impute missing data during regular conditions.
Specifically, we propose a robust tensor recovery problem to recover low rank
tensors under fiber-sparse corruptions with partial observations, and use it to
identify events, and impute missing data under typical conditions. Our approach
is scalable to large urban areas, taking full advantage of the spatio-temporal
correlations in traffic patterns. We develop an efficient algorithm to solve
the tensor recovery problem based on the alternating direction method of
multipliers (ADMM) framework. Compared with existing $l_1$ norm regularized
tensor decomposition methods, our algorithm can exactly recover the values of
uncorrupted fibers of a low rank tensor and find the positions of corrupted
fibers under mild conditions. Numerical experiments illustrate that our
algorithm can exactly detect outliers even with missing data rates as high as
40%, conditioned on the outlier corruption rate and the Tucker rank of the low
rank tensor. Finally, we apply our method on a real traffic dataset
corresponding to downtown Nashville, TN, USA and successfully detect the events
like severe car crashes, construction lane closures, and other large events
that cause significant traffic disruptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10205</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10205</id><created>2019-08-25</created><authors><author><keyname>Latychevskaia</keyname><forenames>Tatiana</forenames></author></authors><title>Reconstruction of missing information in diffraction patterns and
  holograms by iterative phase retrieval</title><categories>eess.IV physics.comp-ph physics.data-an physics.optics</categories><journal-ref>Optics Communications 452(1), 56-67 (2019)</journal-ref><doi>10.1016/j.optcom.2019.07.021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is demonstrated that an object distribution can be successfully retrieved
from its diffraction pattern or hologram, even if some of the measured
intensity samples are missing. The maximum allowable number of missing values
depends on the linear oversampling ratio s, where the higher the value of s,
the more intensity samples can be missing. For a real-valued object, the ratio
of missing pixels to the total number of pixels should not exceed (1 - 2/s^2)
or (1 - 1/s^2) in the acquired diffraction pattern or hologram, respectively.
For example, even 5% of the measured intensity values at an oversampling ratio
of s = 8 are sufficient to simultaneously retrieve the object distribution and
the missing intensity values. It is important that the missing intensity values
should not be concentrated in the centre, but should be randomly distributed
over the acquired diffraction pattern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10208</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10208</id><created>2019-08-25</created><updated>2019-09-11</updated><authors><author><keyname>Liu</keyname><forenames>Yucheng</forenames></author><author><keyname>Khosravan</keyname><forenames>Naji</forenames></author><author><keyname>Liu</keyname><forenames>Yulin</forenames></author><author><keyname>Stember</keyname><forenames>Joseph</forenames></author><author><keyname>Shoag</keyname><forenames>Jonathan</forenames></author><author><keyname>Barbieri</keyname><forenames>Christopher E.</forenames></author><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author><author><keyname>Jambawalikar</keyname><forenames>Sachin</forenames></author></authors><title>Cross-modality Knowledge Transfer for Prostate Segmentation from CT
  Scans</title><categories>eess.IV cs.LG physics.med-ph stat.ML</categories><comments>9 pages, 3 figures, 2019 MICCAI-DART workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Creating large scale high-quality annotations is a known challenge in medical
imaging. In this work, based on the CycleGAN algorithm, we propose leveraging
annotations from one modality to be useful in other modalities. More
specifically, the proposed algorithm creates highly realistic synthetic CT
images (SynCT) from prostate MR images using unpaired data sets. By using SynCT
images (without segmentation labels) and MR images (with segmentation labels
available), we have trained a deep segmentation network for precise delineation
of prostate from real CT scans. For the generator in our CycleGAN, the cycle
consistency term is used to guarantee that SynCT shares the identical
manually-drawn, high-quality masks originally delineated on MR images. Further,
we introduce a cost function based on structural similarity index (SSIM) to
improve the anatomical similarity between real and synthetic images. For
segmentation followed by the SynCT generation from CycleGAN, automatic
delineation is achieved through a 2.5D Residual U-Net. Quantitative evaluation
demonstrates comparable segmentation results between our SynCT and radiologist
drawn masks for real CT images, solving an important problem in medical image
segmentation field when ground truth annotations are not available for the
modality of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10219</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10219</id><created>2019-08-26</created><authors><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>de Groot</keyname><forenames>Marius</forenames></author><author><keyname>Vernooij</keyname><forenames>Meike</forenames></author><author><keyname>Ikram</keyname><forenames>Arfan</forenames></author><author><keyname>Niessen</keyname><forenames>Wiro</forenames></author><author><keyname>Bron</keyname><forenames>Esther</forenames></author></authors><title>Reproducible White Matter Tract Segmentation Using 3D U-Net on a
  Large-scale DTI Dataset</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Machine Learning in Medical Imaging (MLMI), 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tract-specific diffusion measures, as derived from brain diffusion MRI, have
been linked to white matter tract structural integrity and neurodegeneration.
As a consequence, there is a large interest in the automatic segmentation of
white matter tract in diffusion tensor MRI data. Methods based on the
tractography are popular for white matter tract segmentation. However, because
of the limited consistency and long processing time, such methods may not be
suitable for clinical practice. We therefore developed a novel convolutional
neural network based method to directly segment white matter tract trained on a
low-resolution dataset of 9149 DTI images. The method is optimized on input,
loss function and network architecture selections. We evaluated both
segmentation accuracy and reproducibility, and reproducibility of determining
tract-specific diffusion measures. The reproducibility of the method is higher
than that of the reference standard and the determined diffusion measures are
consistent. Therefore, we expect our method to be applicable in clinical
practice and in longitudinal analysis of white matter microstructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10221</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10221</id><created>2019-08-26</created><authors><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Niessen</keyname><forenames>Wiro</forenames></author><author><keyname>Klein</keyname><forenames>Stefan</forenames></author><author><keyname>de Groot</keyname><forenames>Marius</forenames></author><author><keyname>Ikram</keyname><forenames>Arfan</forenames></author><author><keyname>Vernooij</keyname><forenames>Meike</forenames></author><author><keyname>Bron</keyname><forenames>Esther</forenames></author></authors><title>A hybrid deep learning framework for integrated segmentation and
  registration: evaluation on longitudinal white matter tract changes</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>MICCAI 2019 (oral presentation)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To accurately analyze changes of anatomical structures in longitudinal
imaging studies, consistent segmentation across multiple time-points is
required. Existing solutions often involve independent registration and
segmentation components. Registration between time-points is used either as a
prior for segmentation in a subsequent time point or to perform segmentation in
a common space. In this work, we propose a novel hybrid convolutional neural
network (CNN) that integrates segmentation and registration into a single
procedure. We hypothesize that the joint optimization leads to increased
performance on both tasks. The hybrid CNN is trained by minimizing an
integrated loss function composed of four different terms, measuring
segmentation accuracy, similarity between registered images, deformation field
smoothness, and segmentation consistency. We applied this method to the
segmentation of white matter tracts, describing functionally grouped axonal
fibers, using N=8045 longitudinal brain MRI data of 3249 individuals. The
proposed method was compared with two multistage pipelines using two existing
segmentation methods combined with a conventional deformable registration
algorithm. In addition, we assessed the added value of the joint optimization
for segmentation and registration separately. The hybrid CNN yielded
significantly higher accuracy, consistency and reproducibility of segmentation
than the multistage pipelines, and was orders of magnitude faster. Therefore,
we expect it can serve as a novel tool to support clinical and epidemiological
analyses on understanding microstructural brain changes over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10235</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10235</id><created>2019-08-27</created><authors><author><keyname>Sokooti</keyname><forenames>Hessam</forenames></author><author><keyname>de Vos</keyname><forenames>Bob</forenames></author><author><keyname>Berendsen</keyname><forenames>Floris</forenames></author><author><keyname>Ghafoorian</keyname><forenames>Mohsen</forenames></author><author><keyname>Yousefi</keyname><forenames>Sahar</forenames></author><author><keyname>Lelieveldt</keyname><forenames>Boudewijn P. F.</forenames></author><author><keyname>Isgum</keyname><forenames>Ivana</forenames></author><author><keyname>Staring</keyname><forenames>Marius</forenames></author></authors><title>3D Convolutional Neural Networks Image Registration Based on Efficient
  Supervised Learning from Artificial Deformations</title><categories>eess.IV cs.CV cs.LG</categories><comments>TMI</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We propose a supervised nonrigid image registration method, trained using
artificial displacement vector fields (DVF), for which we propose and compare
three network architectures. The artificial DVFs allow training in a fully
supervised and voxel-wise dense manner, but without the cost usually associated
with the creation of densely labeled data. We propose a scheme to artificially
generate DVFs, and for chest CT registration augment these with simulated
respiratory motion. The proposed architectures are embedded in a multi-stage
approach, to increase the capture range of the proposed networks in order to
more accurately predict larger displacements. The proposed method, RegNet, is
evaluated on multiple databases of chest CT scans and achieved a target
registration error of 2.32 $\pm$ 5.33 mm and 1.86 $\pm$ 2.12 mm on SPREAD and
DIR-Lab-4DCT studies, respectively. The average inference time of RegNet with
two stages is about 2.2 s.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10245</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10245</id><created>2019-08-27</created><authors><author><keyname>Ding</keyname><forenames>Xiaorong</forenames></author><author><keyname>Yan</keyname><forenames>Bryan P</forenames></author><author><keyname>Zhang</keyname><forenames>Yuan-Ting</forenames></author><author><keyname>Liu</keyname><forenames>Jing</forenames></author><author><keyname>Su</keyname><forenames>Peng</forenames></author><author><keyname>Zhao</keyname><forenames>Ni</forenames></author></authors><title>Feature Exploration for Knowledge-guided and Data-driven Approach Based
  Cuffless Blood Pressure Measurement</title><categories>eess.SP</categories><comments>4 pages, 4 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study explores extended feature space that is indicative of blood
pressure (BP) changes for better estimation of continuous BP in an unobtrusive
way. A total of 222 features were extracted from noninvasively acquired
electrocardiogram (ECG) and photoplethysmogram (PPG) signals with the subject
undergoing coronary angiography and/or percutaneous coronary intervention,
during which intra-arterial BP was recorded simultaneously with the subject at
rest and while administering drugs to induce BP variations. The association
between the extracted features and the BP components, i.e. systolic BP (SBP),
diastolic BP (DBP), mean BP (MBP), and pulse pressure (PP) were analyzed and
evaluated in terms of correlation coefficient, cross sample entropy, and mutual
information, respectively. Results show that the most relevant indicator for
both SBP and MBP is the pulse full width at half maximum, and for DBP and PP,
the amplitude between the peak of the first derivative of PPG (dPPG) to the
valley of the second derivative of PPG (sdPPG) and the time interval between
the peak of R wave and the sdPPG, respectively. As potential inputs to either
the knowledge-guided model or data-driven method for cuffless BP calibration,
the proposed expanded features are expected to improve the estimation accuracy
of cuffless BP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10252</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10252</id><created>2019-08-27</created><authors><author><keyname>Whiteley</keyname><forenames>William</forenames></author><author><keyname>Gregor</keyname><forenames>Jens</forenames></author></authors><title>CNN-Based PET Sinogram Repair to Mitigate Defective Block Detectors</title><categories>physics.med-ph eess.IV</categories><comments>Submitted to the Journal of Physics in Medicine and Biology</comments><journal-ref>Physics in Medicine and Biology, 2019</journal-ref><doi>10.1088/1361-6560/ab4919</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Positron emission tomography (PET) scanners continue to increase sensitivity
and axial coverage by adding an ever expanding array of block detectors. As
they age, one or more block detectors may lose sensitivity due to a malfunction
or component failure. The sinogram data missing as a result thereof can lead to
artifacts and other image degradations. We propose to mitigate the effects of
malfunctioning block detectors by carrying out sinogram repair using a deep
convolutional neural network. Experiments using whole-body patient studies with
varying amounts of raw data removed are used to show that the neural network
significantly outperforms previously published methods with respect to
normalized mean squared error for raw sinograms, a multi-scale structural
similarity measure for reconstructed images and with regard to quantitative
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10256</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10256</id><created>2019-08-27</created><authors><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author></authors><title>Neural Harmonic-plus-Noise Waveform Model with Trainable Maximum Voice
  Frequency for Text-to-Speech Synthesis</title><categories>eess.AS cs.SD</categories><comments>Accepted by Speech Synthesis Workshop 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Neural source-filter (NSF) models are deep neural networks that produce
waveforms given input acoustic features. They use dilated-convolution-based
neural filter modules to filter sine-based excitation for waveform generation,
which is different from WaveNet and flow-based models. One of the NSF models,
called harmonic-plus-noise NSF (h-NSF) model, uses separate pairs of source and
neural filters to generate harmonic and noise waveform components. It is close
to WaveNet in terms of speech quality while being superior in generation speed.
  The h-NSF model can be improved even further. While h-NSF merges the harmonic
and noise components using pre-defined digital low- and high-pass filters, it
is well known that the maximum voice frequency (MVF) that separates the
periodic and aperiodic spectral bands are time-variant. Therefore, we propose a
new h-NSF model with time-variant and trainable MVF. We parameterize the
digital low- and high-pass filters as windowed-sinc filters and predict their
cut-off frequency (i.e., MVF) from the input acoustic features. Our experiments
demonstrated that the new model can predict a good trajectory of the MVF and
produce high-quality speech for a text-to-speech synthesis system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10267</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10267</id><created>2019-08-27</created><updated>2019-08-28</updated><authors><author><keyname>Deng</keyname><forenames>Sen</forenames></author><author><keyname>Wei</keyname><forenames>Mingqiang</forenames></author><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Liang</keyname><forenames>Luming</forenames></author><author><keyname>Xie</keyname><forenames>Haoran</forenames></author><author><keyname>Wang</keyname><forenames>Meng</forenames></author></authors><title>DRD-Net: Detail-recovery Image Deraining via Context Aggregation
  Networks</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image deraining is a fundamental, yet not well-solved problem in computer
vision and graphics. The traditional image deraining approaches commonly behave
ineffectively in medium and heavy rain removal, while the learning-based ones
lead to image degradations such as the loss of image details, halo artifacts
and/or color distortion. Unlike existing image deraining approaches that lack
the detail-recovery mechanism, we propose an end-to-end detail-recovery image
deraining network (termed a DRD-Net) for single images. We for the first time
introduce two sub-networks with a comprehensive loss function which synergize
to derain and recover the lost details caused by deraining. We have three key
contributions. First, we present a rain residual network to remove rain streaks
from the rainy images, which combines the squeeze-and-excitation (SE) operation
with residual blocks to make full advantage of spatial contextual information.
Second, we design a new connection style block, named structure detail context
aggregation block (SDCAB), which aggregates context feature information and has
a large reception field. Third, benefiting from the SDCAB, we construct a
detail repair network to encourage the lost details to return for eliminating
image degradations. We have validated our approach on four recognized datasets
(three synthetic and one real-world). Both quantitative and qualitative
comparisons show that our approach outperforms the state-of-the-art deraining
methods in terms of the deraining robustness and detail accuracy. The source
code has been available for public evaluation and use on GitHub.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10274</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10274</id><created>2019-08-27</created><authors><author><keyname>Fayazi</keyname><forenames>Morteza</forenames></author><author><keyname>Fotowat</keyname><forenames>Ali</forenames></author><author><keyname>Kavehvash</keyname><forenames>Zahra</forenames></author></authors><title>A Simplified Approach to Two-Port Analysis in Feedback</title><categories>eess.SY cs.SY eess.SP</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new pedagogical approach for analyzing the negative feedback
circuits is proposed. The presented approach is in fact the completed form of
the well-known two-port network analysis which is the most intuitive method for
teaching the negative feedback concept. The two-port network analysis is
rewritten in a more general and conceptual format. In analyzing the output
series feedback, the presented analysis resolves prior shortcomings. The
presented approach helps the students analyze and design all types of negative
feedback circuits more intuitively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10275</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10275</id><created>2019-08-27</created><authors><author><keyname>Celli</keyname><forenames>Fabio</forenames></author></authors><title>The Wiki Music dataset: A tool for computational analysis of popular
  music</title><categories>cs.CL cs.CY cs.SD eess.AS</categories><comments>Copyright 2019, Fabio Celli. 5 pages. Keywords: Popular Music,
  Computational Music analysis, Wikipedia, Natural Language Processing</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Is it possible use algorithms to find trends in the history of popular music?
And is it possible to predict the characteristics of future music genres? In
order to answer these questions, we produced a hand-crafted dataset with the
intent to put together features about style, psychology, sociology and
typology, annotated by music genre and indexed by time and decade. We collected
a list of popular genres by decade from Wikipedia and scored music genres based
on Wikipedia descriptions. Using statistical and machine learning techniques,
we find trends in the musical preferences and use time series forecasting to
evaluate the prediction of future music genres.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10281</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10281</id><created>2019-08-27</created><authors><author><keyname>Puch</keyname><forenames>Santi</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>Irina</forenames></author><author><keyname>Hern&#xe1;ndez</keyname><forenames>Aura</forenames></author><author><keyname>Piella</keyname><forenames>Gemma</forenames></author><author><keyname>Prchkovska</keyname><forenames>Vesna</forenames></author></authors><title>Global Planar Convolutions for improved context aggregation in Brain
  Tumor Segmentation</title><categories>eess.IV cs.CV stat.ML</categories><comments>Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain
  Injuries. BrainLes 2018</comments><doi>10.1007/978-3-030-11726-9_35</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this work, we introduce the Global Planar Convolution module as a
building-block for fully-convolutional networks that aggregates global
information and, therefore, enhances the context perception capabilities of
segmentation networks in the context of brain tumor segmentation. We implement
two baseline architectures (3D UNet and a residual version of 3D UNet, ResUNet)
and present a novel architecture based on these two architectures, ContextNet,
that includes the proposed Global Planar Convolution module. We show that the
addition of such module eliminates the need of building networks with several
representation levels, which tend to be over-parametrized and to showcase slow
rates of convergence. Furthermore, we provide a visual demonstration of the
behavior of GPC modules via visualization of intermediate representations. We
finally participate in the 2018 edition of the BraTS challenge with our best
performing models, that are based on ContextNet, and report the evaluation
scores on the validation and the test sets of the challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10312</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10312</id><created>2019-08-23</created><authors><author><keyname>Qian</keyname><forenames>Kun</forenames></author><author><keyname>Mohamed</keyname><forenames>Abduallah</forenames></author><author><keyname>Claudel</keyname><forenames>Christian</forenames></author></authors><title>Physics Informed Data Driven model for Flood Prediction: Application of
  Deep Learning in prediction of urban flood development</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flash floods in urban areas occur with increasing frequency. Detecting these
floods would greatlyhelp alleviate human and economic losses. However, current
flood prediction methods are eithertoo slow or too simplified to capture the
flood development in details. Using Deep Neural Networks,this work aims at
boosting the computational speed of a physics-based 2-D urban flood
predictionmethod, governed by the Shallow Water Equation (SWE). Convolutional
Neural Networks(CNN)and conditional Generative Adversarial Neural
Networks(cGANs) are applied to extract the dy-namics of flood from the data
simulated by a Partial Differential Equation(PDE) solver. Theperformance of the
data-driven model is evaluated in terms of Mean Squared Error(MSE) andPeak
Signal to Noise Ratio(PSNR). The deep learning-based, data-driven flood
prediction modelis shown to be able to provide precise real-time predictions of
flood development
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10313</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10313</id><created>2019-08-22</created><authors><author><keyname>Andoni</keyname><forenames>Merlinda</forenames></author><author><keyname>Robu</keyname><forenames>Valentin</forenames></author><author><keyname>Fruh</keyname><forenames>Wolf-Gerrit</forenames></author><author><keyname>Flynn</keyname><forenames>David</forenames></author></authors><title>Game-theoretic modeling of curtailment rules and network investments
  with distributed generation</title><categories>eess.SP cs.CY cs.GT</categories><comments>Preprint of final submitted version</comments><journal-ref>Applied Energy, Volume 201, 1 September 2017, Pages 174-187</journal-ref><doi>10.1016/j.apenergy.2017.05.035</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Renewable energy has achieved high penetration rates in many areas, leading
to curtailment, especially if existing network infrastructure is insufficient
and energy generated cannot be exported. In this context, Distribution Network
Operators (DNOs) face a significant knowledge gap about how to implement
curtailment rules that achieve desired operational objectives, but at the same
time minimise disruption and economic losses for renewable generators. In this
work, we study the properties of several curtailment rules widely used in UK
renewable energy projects, and their effect on the viability of renewable
generation investment. Moreover, we propose a new curtailment rule which
guarantees fair allocation of curtailment amongst all generators with minimal
disruption. Another key knowledge gap faced by DNOs is how to incentivise
private network upgrades, especially in settings where several generators can
use the same line against the payment of a transmission fee. In this work, we
provide a solution to this problem by using tools from algorithmic game theory.
Specifically, this setting can be modelled as a Stackelberg game between the
private transmission line investor and local renewable generators, who are
required to pay a transmission fee to access the line. We provide a method for
computing the empirical equilibrium of this game, using a model that captures
the stochastic nature of renewable energy generation and demand. Finally, we
use the practical setting of a grid reinforcement project from the UK and a
large dataset of wind speed measurements and demand to validate our model. We
show that charging a transmission fee as a proportion of the feed-in tariff
price between 15%-75% would allow both investors to implement their projects
and achieve desirable distribution of the profit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10315</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10315</id><created>2019-08-04</created><authors><author><keyname>Jin</keyname><forenames>Ming</forenames></author><author><keyname>Lavaei</keyname><forenames>Javad</forenames></author><author><keyname>Sojoudi</keyname><forenames>Somayeh</forenames></author><author><keyname>Baldick</keyname><forenames>Ross</forenames></author></authors><title>Boundary Defense against Cyber Threat for Power System Operation</title><categories>eess.SP stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The operation of power grids is becoming increasingly data-centric. While the
abundance of data could improve the efficiency of the system, it poses major
reliability challenges. In particular, state estimation aims to learn the
behavior of the network from data but an undetected attack on this problem
could lead to a large-scale blackout. Nevertheless, understanding vulnerability
of state estimation against cyber attacks has been hindered by the lack of
tools studying the topological and data-analytic aspects of the network.
Algorithmic robustness is of critical need to extract reliable information from
abundant but untrusted grid data. We propose a robust state estimation
framework that leverages network sparsity and data abundance. For a large-scale
power grid, we quantify, analyze, and visualize the regions of the network
prone to cyber attacks. We also propose an optimization-based graphical
boundary defense mechanism to identify the border of the geographical area
whose data has been manipulated. The proposed method does not allow a local
attack to have a global effect on the data analysis of the entire network,
which enhances the situational awareness of the grid especially in the face of
adversity. The developed mathematical framework reveals key geometric and
algebraic factors that can affect algorithmic robustness and is used to study
the vulnerability of the U.S. power grid in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10335</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10335</id><created>2019-08-27</created><authors><author><keyname>Halder</keyname><forenames>Shirsendu Sukanta</forenames></author><author><keyname>Lalonde</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author><author><keyname>de Charette</keyname><forenames>Raoul</forenames></author></authors><title>Physics-Based Rendering for Improving Robustness to Rain</title><categories>cs.CV cs.GR cs.LG eess.IV</categories><comments>ICCV 2019. Supplementary pdf / videos available on project page</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To improve the robustness to rain, we present a physically-based rain
rendering pipeline for realistically inserting rain into clear weather images.
Our rendering relies on a physical particle simulator, an estimation of the
scene lighting and an accurate rain photometric modeling to augment images with
arbitrary amount of realistic rain or fog. We validate our rendering with a
user study, proving our rain is judged 40% more realistic that
state-of-the-art. Using our generated weather augmented Kitti and Cityscapes
dataset, we conduct a thorough evaluation of deep object detection and semantic
segmentation algorithms and show that their performance decreases in degraded
weather, on the order of 15% for object detection and 60% for semantic
segmentation. Furthermore, we show refining existing networks with our
augmented images improves the robustness of both object detection and semantic
segmentation algorithms. We experiment on nuScenes and measure an improvement
of 15% for object detection and 35% for semantic segmentation compared to
original rainy performance. Augmented databases and code are available on the
project page.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10338</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10338</id><created>2019-08-27</created><updated>2019-09-06</updated><authors><author><keyname>Elliott</keyname><forenames>Ryan T.</forenames></author><author><keyname>Arabshahi</keyname><forenames>Payman</forenames></author><author><keyname>Kirschen</keyname><forenames>Daniel S.</forenames></author></authors><title>A Generalized PSS Architecture for Balancing Transient and Small-Signal
  Response</title><categories>eess.SY cs.SY math.OC</categories><comments>11 pages, 17 figures, 2 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  For decades, power system stabilizers paired with high initial response
automatic voltage regulators have served as an effective means of meeting
sometimes conflicting system stability requirements. Driven primarily by
increases in power electronically-coupled generation and load, the dynamics of
large-scale power systems are rapidly changing. Electric grids are losing
inertia and traditional sources of voltage support and oscillation damping. The
system load is becoming stiffer with respect to changes in voltage. In
parallel, advancements in wide-area measurement technology have made it
possible to implement control strategies that act on information transmitted
over long distances in nearly real time. In this paper, we present a power
system stabilizer architecture that can be viewed as a generalization of the
standard $\Delta\omega$-type stabilizer. The control strategy utilizes a
real-time estimate of the center-of-inertia speed derived from wide-area
measurements. This approach creates a flexible set of trade-offs between
transient and small-signal response, making synchronous generators better able
to adapt to changes in system dynamics. The phenomena of interest are examined
using a two-area test case and a reduced-order model of the North American
Western Interconnection. To validate the key findings under realistic
conditions, we employ a state-of-the-art co-simulation platform called HELICS
to combine high-fidelity power system and communication network models. The
benefits of the proposed control strategy are retained even under pessimistic
assumptions of communication network performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10356</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10356</id><created>2019-08-27</created><authors><author><keyname>Koohbanani</keyname><forenames>Navid Alemi</forenames></author><author><keyname>Jahanifar</keyname><forenames>Mostafa</forenames></author><author><keyname>Gooya</keyname><forenames>Ali</forenames></author><author><keyname>Rajpoot</keyname><forenames>Nasir</forenames></author></authors><title>Nuclear Instance Segmentation using a Proposal-Free Spatially Aware Deep
  Learning Framework</title><categories>eess.IV q-bio.TO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nuclear segmentation in histology images is a challenging task due to
significant variations in the shape and appearance of nuclei. One of the main
hurdles in nuclear instance segmentation is overlapping nuclei where a smart
algorithm is needed to separate each nucleus. In this paper, we introduce a
proposal-free deep learning based framework to address these challenges. To
this end, we propose a spatially-aware network (SpaNet) to capture spatial
information in a multi-scale manner. A dual-head variation of the SpaNet is
first utilized to predict the pixel-wise segmentation and centroid detection
maps of nuclei. Based on these outputs, a single-head SpaNet predicts the
positional information related to each nucleus instance. Spectral clustering
method is applied on the output of the last SpaNet, which utilizes the nuclear
mask and the Gaussian-like detection map for determining the connected
components and associated cluster identifiers, respectively. The output of the
clustering method is the final nuclear instance segmentation mask. We applied
our method on a publicly available multi-organ data set and achieved
state-of-the-art performance for nuclear segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10357</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10357</id><created>2019-08-27</created><updated>2019-11-24</updated><authors><author><keyname>Cheng</keyname><forenames>Bowen</forenames></author><author><keyname>Xiao</keyname><forenames>Bin</forenames></author><author><keyname>Wang</keyname><forenames>Jingdong</forenames></author><author><keyname>Shi</keyname><forenames>Honghui</forenames></author><author><keyname>Huang</keyname><forenames>Thomas S.</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author></authors><title>Bottom-up Higher-Resolution Networks for Multi-Person Pose Estimation</title><categories>cs.CV cs.LG eess.IV</categories><comments>Code is available at
  https://github.com/HRNet/Higher-HRNet-Human-Pose-Estimation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bottom-up multi-person pose estimation methods have difficulties in
predicting the correct pose for small persons due to challenges in scale
variation. In this paper, we present a Higher-Resolution Network (HigherHRNet)
to learn high-resolution feature pyramids. Equipped with mutli-resolution
supervision for training and multiresolution aggregation for inference, the
proposed approach is able to solve the scale variation challenge in bottom-up
multi-person pose estimation and localize the keypoints, especially for small
person, more precisely. The feature pyramid in HigherHRNet consists of the
feature map output from HRNet and the upsampled higherresolution one through a
transposed convolution. HigherHRNet outperforms the previous best bottom-up
method by 2.5% AP for medium person on COCO test-dev, showing its effectiveness
in handling scale variation. Furthermore, HigherHRNet achieves a
state-of-the-art result of 70.5% AP on COCO test-dev without using refinement
or other post-processing techniques, surpassing all existing bottom-up methods.
The code and models are available at
https://github.com/HRNet/Higher-HRNet-Human-Pose-Estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10362</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10362</id><created>2019-08-27</created><authors><author><keyname>Jiao</keyname><forenames>Long</forenames></author><author><keyname>Wang</keyname><forenames>Ning</forenames></author><author><keyname>Wang</keyname><forenames>Pu</forenames></author><author><keyname>Alipour-Fanid</keyname><forenames>Amir</forenames></author><author><keyname>Tang</keyname><forenames>Jie</forenames></author><author><keyname>Zeng</keyname><forenames>Kai</forenames></author></authors><title>Physical Layer Key Generation in 5G Wireless Networks</title><categories>eess.SP cs.CR cs.IT math.IT</categories><comments>This work has been accepted by the IEEE Wireless Communications
  Magzine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bloom of the fifth generation (5G) communication and beyond serves as a
catalyst for physical layer key generation techniques. In 5G communications
systems, many challenges in traditional physical layer key generation schemes,
such as co-located eavesdroppers, the high bit disagreement ratio, and high
temporal correlation, could be overcome. This paper lists the key-enabler
techniques in 5G wireless networks, which offer opportunities to address
existing issues in physical layer key generation. We survey the existing key
generation methods and introduce possible solutions for the existing issues.
The new solutions include applying the high signal directionality in
beamforming to resist co-located eavesdroppers, utilizing the sparsity of
millimeter wave (mmWave) channel to achieve a low bit disagreement ratio under
low signal-to-noise-ratio (SNR), and exploiting hybrid precoding to reduce the
temporal correlation among measured samples. Finally, the future trends of
physical layer key generation in 5G and beyond communications are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10391</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10391</id><created>2019-08-27</created><updated>2019-09-04</updated><authors><author><keyname>Martinez</keyname><forenames>Cristiane A. Pendeza</forenames></author><author><keyname>Abr&#xe3;o</keyname><forenames>Taufik</forenames></author><author><keyname>Durand</keyname><forenames>F&#xe1;bio Renan</forenames></author><author><keyname>Goedtel</keyname><forenames>Alessandro</forenames></author></authors><title>Hopfield Learning-based and Nonlinear Programming methods for Resource
  Allocation in OCDMA Networks</title><categories>eess.SY cs.SY eess.SP</categories><comments>29 pages, 11 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes the deployment of the Hopfield's artificial neural
network (H-NN) approach to optimally assign power in optical code division
multiple access (OCDMA) systems. Figures of merit such as feasibility of
solutions and complexity are compared with the classical power allocation
methods found in the literature, such as Sequential Quadratic Programming (SQP)
and Augmented Lagrangian Method (ALM). The analyzed methods are used to solve
constrained nonlinear optimization problems in the context of resource
allocation for optical networks, specially to deal with the energy efficiency
(EE) in OCDMA networks. The promising performance-complexity tradeoff of the
modified H-NN is demonstrated through numerical results performed in comparison
with classic methods for general problems in nonlinear programming. The
evaluation is carried out considering challenging OCDMA networks in which
different levels of QoS were considered for large numbers of optical users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10404</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10404</id><created>2019-08-27</created><updated>2019-09-02</updated><authors><author><keyname>Zhong</keyname><forenames>Zijia</forenames></author><author><keyname>Lee</keyname><forenames>Joyoung</forenames></author></authors><title>The Effectiveness of Managed Lane Strategies for the Near-term
  Deployment of Cooperative Adaptive Cruise Control</title><categories>cs.MA eess.SP</categories><comments>22 pages, 15 figures</comments><journal-ref>Transportation Research Part A: Policy and Practice 2019</journal-ref><doi>10.1016/j.tra.2019.08.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traffic simulation is a cost-effective way to test the deployment of
Cooperative Adaptive Cruise Control (CACC) vehicles in a large-scale
transportation network. By using a previously developed microscopic simulation
testbed, this paper examines the impacts of four managed lane strategies for
the near-term deployment of CACC vehicles under mixed traffic conditions.
Network-wide performance measures are investigated from the perspectives of
mobility, safety, equity, and environmental impacts. In addition, the platoon
formation performance of CACC vehicles is evaluated with platoon-orientated
measures, such as the percentage of platooned CACC vehicles, average platoon
depth, and vehicle-hour-platooned that is proposed in this paper under the
imperfect DSRC communication environment. Moreover, managed lane score matrices
are developed to incorporate heterogeneous categories of performance measures,
aiming to provide a more comprehensive picture for stakeholders. The results
show that mixing CACC traffic along with non-CACC traffic across all travel
lanes is an acceptable option when the market penetration (MP) is lower than
30% for roadways where a managed lane is absent. Providing CACC with priority
access to an existing managed lane, if available, is also a good strategy for
improving the overall traffic performance when the MP is lower than 40%. When
the MP reaches above 40%, a dedicated lane for CACC vehicles is recommended, as
it provides greater opportunity for CACC vehicles to form platoons. The
facilitation of homogeneous CACC traffic flow could make further improvements
possible in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10417</identifier>
 <datestamp>2019-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10417</id><created>2019-08-27</created><updated>2019-09-12</updated><authors><author><keyname>Arsene</keyname><forenames>Corneliu</forenames></author></authors><title>Complex Deep Learning Models for Denoising of Human Heart ECG signals</title><categories>cs.LG cs.CV eess.SP stat.ML</categories><comments>51 pages, 23 figures</comments><journal-ref>EUSIPCO.2019 (Pages 11- 18)</journal-ref><doi>10.23919/EUSIPCO.2019.8902833</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Effective and powerful methods for denoising real electrocardiogram (ECG)
signals are important for wearable sensors and devices. Deep Learning (DL)
models have been used extensively in image processing and other domains with
great success but only very recently have been used in processing ECG signals.
This paper presents several DL models namely Convolutional Neural Networks
(CNNs), Long Short-Term Memory (LSTM), Restricted Boltzmann Machine (RBM)
together with the more conventional filtering methods (low pass filtering, high
pass filtering, Notch filtering) and the standard wavelet-based technique for
denoising EEG signals. These methods are trained, tested and evaluated on
different synthetic and real ECG datasets taken from the MIT PhysioNet database
and for different simulation conditions (i.e. various lengths of the ECG
signals, single or multiple records). The results show the CNN model is a
performant model that can be used for off-line denoising ECG applications where
it is satisfactory to train on a clean part of an ECG signal from an ECG
record, and then to test on the same ECG signal, which would have some high
level of noise added to it. However, for real-time applications or near-real
time applications, this task becomes more cumbersome, as the clean part of an
ECG signal is very probable to be very limited in size. Therefore the solution
put forth in this work is to train a CNN model on 1 second ECG noisy artificial
multiple heartbeat data (i.e. ECG at effort), which was generated in a first
instance based on few sequences of real signal heartbeat ECG data (i.e. ECG at
rest). Afterwards it would be possible to use the trained CNN model in real
life situations to denoise the ECG signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10424</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10424</id><created>2019-07-25</created><authors><author><keyname>Fajardo</keyname><forenames>Jes&#xfa;s E.</forenames></author><author><keyname>Galv&#xe1;n</keyname><forenames>Juli&#xe1;n</forenames></author><author><keyname>Vericat</keyname><forenames>Fernando</forenames></author><author><keyname>Carlevaro</keyname><forenames>Carlos M.</forenames></author><author><keyname>Irastorza</keyname><forenames>Ramiro M.</forenames></author></authors><title>Phaseless Microwave Imaging Of Dielectric Cylinders: An Artificial
  Neural Networks-Based Approach</title><categories>physics.app-ph eess.SP physics.med-ph</categories><comments>19 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An inverse method for parameters estimation of infinite cylinders (the
dielectric properties, location, and radius) in two dimensions from
amplitude-only microwave information is presented. To this end two different
Artificial Neural Networks (ANN) topologies are compared; Multilayer Perceptron
(MLP) and a Convolutional Neural Network (CNN). Several simulations employing
the Finite Differences in Time Domain (FDTD) method are performed to solve the
direct electromagnetic problem and generate training, validation, and test sets
for the ANN models. The magnitude of the mean errors in estimating the position
and size of the cylinder are up to (1.9 $\pm$ 3.3) mm and (0.2 $\pm$ 0.8) mm
for the MLP and CNN, respectively. The magnitude of the mean percentage
relative errors in estimating the dielectric properties of the cylinder are up
to (6.5 $\pm$ 13.8) % and (0.0 $\pm$ 7.2) % for the MLP and CNN, respectively.
The errors in the parameters estimation from the MLP model are low, however,
significantly lower errors were obtained with the CNN model. A validation
example is shown using a simulation in three dimensions. Measurement examples
with homogeneous and heterogeneous cylinders are presented aiming to prove the
feasibility of the described method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10432</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10432</id><created>2019-08-27</created><authors><author><keyname>Taherisadr</keyname><forenames>Mojtaba</forenames></author><author><keyname>Joneidi</keyname><forenames>Mohsen</forenames></author><author><keyname>Rahnavard</keyname><forenames>Nazanin</forenames></author></authors><title>EEG Signal Dimensionality Reduction and Classification using Tensor
  Decomposition and Deep Convolutional Neural Networks</title><categories>eess.SP eess.IV math.SP</categories><comments>2019 IEEE International Workshop on Machine Learning for Signal
  Processing</comments><journal-ref>2019 IEEE International Workshop on Machine Learning for Signal
  Processing</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new deep learning-based electroencephalography (EEG) signal analysis
framework is proposed. While deep neural networks, specifically convolutional
neural networks (CNNs), have gained remarkable attention recently, they still
suffer from high dimensionality of the training data. Two-dimensional input
images of CNNs are more vulnerable to be redundant versus one-dimensional input
time-series of conventional neural networks. In this study, we propose a new
dimensionality reduction framework for reducing the dimension of CNN inputs
based on the tensor decomposition of the time-frequency representation of EEG
signals. The proposed tensor decomposition-based dimensionality reduction
algorithm transforms a large set of slices of the input tensor to a concise set
of slices which are called super-slices. Employing super-slices not only
handles the artifacts and redundancies of the EEG data but also reduces the
dimension of the CNNs training inputs. We also consider different
time-frequency representation methods for EEG image generation and provide a
comprehensive comparison among them. We test our proposed framework on HCB-MIT
data and as results show our approach outperforms other previous studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10441</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10441</id><created>2019-07-30</created><authors><author><keyname>Mishra</keyname><forenames>Rishabh Bhooshan</forenames></author><author><keyname>Kumar</keyname><forenames>S Santosh</forenames></author><author><keyname>Mukhiya</keyname><forenames>Ravindra</forenames></author></authors><title>Modeling and FEM-based Simulations of Composite Membrane based Circular
  Capacitive Pressure Sensor</title><categories>physics.app-ph eess.SP</categories><comments>International Conference on VLSI, Communication and Signal Processing
  (VCAS 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Micro-electro-mechanical Systems (MEMS) based pressure sensors and
acoustic devices, deflection of a membrane is utilized for pressure or sound
measurements. Due to advantages of capacitive pressure sensor over
piezoresistive pressure sensors (low power consumption, less sensitive to
temperature drift, higher dynamic range, high sensitivity), capacitive pressure
sensors are the 2nd largest useable MEMS-based sensor after piezoresistive
pressure sensors. We present a normal capacitive pressure sensor, for
continuous sensing of normal and abnormal Intraocular Pressure (IOP). The
composite membrane of the sensor is made of three materials, i.e., Si, SiO2 and
Si3N4. The membrane deflection, capacitance variation, mechanical sensitivity,
capacitive sensitivity and non-linearity are discussed in this work.
Mathematical modeling is performed for analytical simulation, which is also
compared with Finite Element Method (FEM) simulations. MATLAB is used for
analytical simulations and CoventorWare is used for FEM simulations. The
variation in analytical result of deflection in membrane w.r.t. FEM result is
about 7.19%, and for capacitance, the variation is about 2.7% at maximum
pressure of 8 kPa. The non-linearity is about 4.2492% for the proposed sensor
for fabrication using surface micro-machining process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10454</identifier>
 <datestamp>2020-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10454</id><created>2019-08-27</created><updated>2020-02-11</updated><authors><author><keyname>Tajbakhsh</keyname><forenames>Nima</forenames></author><author><keyname>Jeyaseelan</keyname><forenames>Laura</forenames></author><author><keyname>Li</keyname><forenames>Qian</forenames></author><author><keyname>Chiang</keyname><forenames>Jeffrey</forenames></author><author><keyname>Wu</keyname><forenames>Zhihao</forenames></author><author><keyname>Ding</keyname><forenames>Xiaowei</forenames></author></authors><title>Embracing Imperfect Datasets: A Review of Deep Learning Solutions for
  Medical Image Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted for publication in the journal of Medical Image Analysis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The medical imaging literature has witnessed remarkable progress in
high-performing segmentation models based on convolutional neural networks.
Despite the new performance highs, the recent advanced segmentation models
still require large, representative, and high quality annotated datasets.
However, rarely do we have a perfect training dataset, particularly in the
field of medical imaging, where data and annotations are both expensive to
acquire. Recently, a large body of research has studied the problem of medical
image segmentation with imperfect datasets, tackling two major dataset
limitations: scarce annotations where only limited annotated data is available
for training, and weak annotations where the training data has only sparse
annotations, noisy annotations, or image-level annotations. In this article, we
provide a detailed review of the solutions above, summarizing both the
technical novelties and empirical results. We further compare the benefits and
requirements of the surveyed methodologies and provide our recommended
solutions. We hope this survey article increases the community awareness of the
techniques that are available to handle imperfect medical image segmentation
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10468</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10468</id><created>2019-08-27</created><authors><author><keyname>Lanfredi</keyname><forenames>Ricardo Bigolin</forenames></author><author><keyname>Schroeder</keyname><forenames>Joyce D.</forenames></author><author><keyname>Vachet</keyname><forenames>Clement</forenames></author><author><keyname>Tasdizen</keyname><forenames>Tolga</forenames></author></authors><title>Adversarial regression training for visualizing the progression of
  chronic obstructive pulmonary disease with chest x-rays</title><categories>eess.IV cs.CV cs.GR</categories><comments>Accepted for MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge of what spatial elements of medical images deep learning methods
use as evidence is important for model interpretability, trustiness, and
validation. There is a lack of such techniques for models in regression tasks.
We propose a method, called visualization for regression with a generative
adversarial network (VR-GAN), for formulating adversarial training specifically
for datasets containing regression target values characterizing disease
severity. We use a conditional generative adversarial network where the
generator attempts to learn to shift the output of a regressor through creating
disease effect maps that are added to the original images. Meanwhile, the
regressor is trained to predict the original regression value for the modified
images. A model trained with this technique learns to provide visualization for
how the image would appear at different stages of the disease. We analyze our
method in a dataset of chest x-rays associated with pulmonary function tests,
used for diagnosing chronic obstructive pulmonary disease (COPD). For
validation, we compute the difference of two registered x-rays of the same
patient at different time points and correlate it to the generated disease
effect map. The proposed method outperforms a technique based on classification
and provides realistic-looking images, making modifications to images following
what radiologists usually observe for this disease. Implementation code is
available at https://github.com/ricbl/vrgan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10469</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10469</id><created>2019-08-27</created><authors><author><keyname>Muhanji</keyname><forenames>Steffi O.</forenames></author><author><keyname>Farid</keyname><forenames>Amro M.</forenames></author></authors><title>An Enterprise Control Methodology for the Techno-Economic Assessment of
  the Energy Water Nexus</title><categories>eess.SY cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In recent years, the energy-water nexus literature has recognized that the
electricity and water infrastructure that enable the production, distribution,
and consumption of these two commodities is fundamentally intertwined. Electric
power is used to produce, treat, distribute, and recycle water while water is
used to generate and consume electricity. In the meantime, significant
attention has been given to renewable energy integration within the context of
global climate change. While these two issues may seem unrelated, their
resolution is potentially synergistic in that renewable energy technologies not
only present low CO2 emissions but also low water-intensities. Furthermore,
because water is readily stored, it has the potential to act as a flexible
energy resource on both the supply and the demand-side of the electricity grid.
Despite these synergies, the renewable energy integration and energy-water
nexus literature have yet to methodologically converge to systematically
address potential synergies. This paper advances an enterprise control
methodology as a means of assessing the techno-economic performance of the
energy water nexus. The enterprise control methodology has been developed in
recent years to advance the methodological state of the art of renewable energy
integration studies and used recently to carry out a full-scale study for the
Independent System Operator (ISO) New England system. The methodology
quantifies day-ahead and real-time energy market production costs, dispatched
energy mixes, required operating reserves, levels of curtailment, and grid
imbalances. This energy-water nexus methodological extension now includes
flexible water-energy resources within the grid's energy resource portfolio and
quantifies the amounts of water withdrawn and consumed. The simulation
methodology is demonstrated on a modified version of the RTS-96 (RTS-GMLC) test
case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10487</identifier>
 <datestamp>2020-02-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10487</id><created>2019-08-27</created><updated>2020-02-07</updated><authors><author><keyname>Xi</keyname><forenames>Feng</forenames></author><author><keyname>Xiang</keyname><forenames>Yijian</forenames></author><author><keyname>Chen</keyname><forenames>Shengyao</forenames></author><author><keyname>Nehorai</keyname><forenames>Arye</forenames></author></authors><title>Gridless Parameter Estimation for One-Bit MIMO Radar with Time-Varying
  Thresholds</title><categories>eess.SP</categories><comments>31 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the one-bit MIMO (1b-MIMO) radar that performs one-bit
sampling with a time-varying threshold in the temporal domain and employs
compressive sensing in the spatial and Doppler domains. The goals are to
significantly reduce the hardware cost, energy consumption, and amount of
stored data. The joint angle and Doppler frequency estimations from noisy
one-bit data are studied. By showing that the effect of noise on one-bit
sampling is equivalent to that of sparse impulsive perturbations, we formulate
the one-bit $\ell_1$-regularized atomic-norm minimization (1b-ANM-L1) problem
to achieve gridless parameter estimation with high accuracy. We also develop an
iterative method for solving the 1b-ANM-L1 problem via the alternating
direction method of multipliers. The Cram$\acute{\text{e}}$r-Rao bound (CRB) of
the 1b-MIMO radar is analyzed, and the analytical performance of one-bit
sampling with two different threshold strategies is discussed. Numerical
experiments are presented to show that the 1b-MIMO radar can achieve
high-resolution parameter estimation with a largely reduced amount of data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10489</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10489</id><created>2019-08-27</created><authors><author><keyname>Yang</keyname><forenames>Junlin</forenames></author><author><keyname>Dvornek</keyname><forenames>Nicha C.</forenames></author><author><keyname>Zhang</keyname><forenames>Fan</forenames></author><author><keyname>Zhuang</keyname><forenames>Juntang</forenames></author><author><keyname>Chapiro</keyname><forenames>Julius</forenames></author><author><keyname>Lin</keyname><forenames>MingDe</forenames></author><author><keyname>Duncan</keyname><forenames>James S.</forenames></author></authors><title>Domain-Agnostic Learning with Anatomy-Consistent Embedding for
  Cross-Modality Liver Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Domain Adaptation (DA) has the potential to greatly help the generalization
of deep learning models. However, the current literature usually assumes to
transfer the knowledge from the source domain to a specific known target
domain. Domain Agnostic Learning (DAL) proposes a new task of transferring
knowledge from the source domain to data from multiple heterogeneous target
domains. In this work, we propose the Domain-Agnostic Learning framework with
Anatomy-Consistent Embedding (DALACE) that works on both domain-transfer and
task-transfer to learn a disentangled representation, aiming to not only be
invariant to different modalities but also preserve anatomical structures for
the DA and DAL tasks in cross-modality liver segmentation. We validated and
compared our model with state-of-the-art methods, including CycleGAN, Task
Driven Generative Adversarial Network (TD-GAN), and Domain Adaptation via
Disentangled Representations (DADR). For the DA task, our DALACE model
outperformed CycleGAN, TD-GAN ,and DADR with DSC of 0.847 compared to 0.721,
0.793 and 0.806. For the DAL task, our model improved the performance with DSC
of 0.794 from 0.522, 0.719 and 0.742 by CycleGAN, TD-GAN, and DADR. Further, we
visualized the success of disentanglement, which added human interpretability
of the learned meaningful representations. Through ablation analysis, we
specifically showed the concrete benefits of disentanglement for downstream
tasks and the role of supervision for better disentangled representation with
segmentation consistency to be invariant to domains with the proposed
Domain-Agnostic Module (DAM) and to preserve anatomical information with the
proposed Anatomy-Preserving Module (APM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10490</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10490</id><created>2019-08-27</created><updated>2019-08-29</updated><authors><author><keyname>Muhanji</keyname><forenames>Steffi O.</forenames></author><author><keyname>Barrows</keyname><forenames>Clayton</forenames></author><author><keyname>Macknick</keyname><forenames>Jordan</forenames></author><author><keyname>Farid</keyname><forenames>Amro M.</forenames></author></authors><title>An Enterprise Control Assessment Case Study of the Energy-Water Nexus
  for the ISO New England System</title><categories>eess.SY cs.SY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The electric power generation mix of ISO New England (ISO-NE) is
fundamentally changing. Nuclear, coal, and oil generation facilities are
retiring while natural gas, solar, and wind generation are being adopted to
replace them. Variable renewable energy (VREs) such as solar and wind present
multiple operational challenges that require new and innovative changes to how
the electricity grid is managed and controlled. Within the context of a New
England case study, this paper looks at ways in which the water supply systems
(water and wastewater treatment), and water dependent electricity generating
resources (hydro, and thermal power plants) can be operated flexibly to help
balance energy in an evolving grid. The study's methodology employs the novel
but now well published Electric Power Enterprise Control System (EPECS)
simulator to study the electric power systems operation, and the System-Level
Generic Model (SGEM) to study the associated water consumption and withdrawals.
This work studies six potential 2040 scenarios for the energy-water nexus of
the ISO-NE system. It presents a holistic analysis that quantifies power system
imbalances, normal operating reserves, energy market production costs, and
water withdrawal and consumption figures. For scenarios with a high penetration
of VREs, the study shows great potential of water resources to enhance grid
flexibility through the provision of load-following, ramping, and regulation
reserves by water resources. The work also provides significant insights on how
to jointly control the water and energy supply systems to aid in their
synergistic integration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10500</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10500</id><created>2019-08-27</created><updated>2019-08-29</updated><authors><author><keyname>Nosrati</keyname><forenames>Hamed</forenames></author><author><keyname>Aboutanios</keyname><forenames>Elias</forenames></author><author><keyname>Wang</keyname><forenames>Xiangrong</forenames></author><author><keyname>Smith</keyname><forenames>David</forenames></author></authors><title>Switch-based Hybrid Beamforming for Massive MIMO Communications in
  mmWave Bands</title><categories>eess.SP</categories><comments>Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Switch-based hybrid network is a promising implementation for beamforming in
large-scale millimetre wave (mmWave) antenna arrays. By fully exploiting the
sparse nature of the mmWave channel, such hybrid beamforming reduces complexity
and power consumption when compared with a structure based on phase shifters.
However, the difficulty of designing an optimum beamformer in the analog domain
is prohibitive due to the binary nature of such a switch-based structure. Thus,
here we propose a new method for designing a switch-based hybrid beamformer for
massive MIMO communications in mmWave bands. We first propose a method for
decoupling the joint optimization of analog and digital beamformers by
confining the problem to a rank-constrained subspace. We then approximate the
solution through two approaches: norm maximization (SHD-NM), and majorization
(SHD-QRQU). In the norm maximization method, we propose a modified sequential
convex programming (SCP) procedure that maximizes the mutual information while
addressing the mismatch incurred from approximating the log-determinant by a
Frobenius norm. In the second method, we employ a lower bound on the mutual
information by QR factorization. We also introduce linear constraints in order
to include frequently-used partially-connected structures. Finally, we show the
feasibility, and effectiveness of the proposed methods through several
numerical examples. The results demonstrate ability of the proposed methods to
track closely the spectral efficiency provided by unconstrained optimal
beamformer and phase shifting hybrid beamformer, and outperform a competitor
switch-based hybrid beamformer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10508</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10508</id><created>2019-08-27</created><authors><author><keyname>Smailagic</keyname><forenames>Asim</forenames></author><author><keyname>Costa</keyname><forenames>Pedro</forenames></author><author><keyname>Gaudio</keyname><forenames>Alex</forenames></author><author><keyname>Khandelwal</keyname><forenames>Kartik</forenames></author><author><keyname>Mirshekari</keyname><forenames>Mostafa</forenames></author><author><keyname>Fagert</keyname><forenames>Jonathon</forenames></author><author><keyname>Walawalkar</keyname><forenames>Devesh</forenames></author><author><keyname>Xu</keyname><forenames>Susu</forenames></author><author><keyname>Galdran</keyname><forenames>Adrian</forenames></author><author><keyname>Zhang</keyname><forenames>Pei</forenames></author><author><keyname>Campilho</keyname><forenames>Aur&#xe9;lio</forenames></author><author><keyname>Noh</keyname><forenames>Hae Young</forenames></author></authors><title>O-MedAL: Online Active Deep Learning for Medical Image Analysis</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>Submitted to Journal: Wiley WIREs Data Mining and Knowledge Discovery</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Active Learning methods create an optimized and labeled training set from
unlabeled data. We introduce a novel Online Active Deep Learning method for
Medical Image Analysis. We extend our MedAL active learning framework to
present new results in this paper. Experiments on three medical image datasets
show that our novel online active learning model requires significantly less
labelings, is more accurate, and is more robust to class imbalances than
existing methods. Our method is also more accurate and computationally
efficient than the baseline model. Compared to random sampling and uncertainty
sampling, the method uses 275 and 200 (out of 768) fewer labeled examples,
respectively. For Diabetic Retinopathy detection, our method attains a 5.88%
accuracy improvement over the baseline model when 80% of the dataset is
labeled, and the model reaches baseline accuracy when only 40% is labeled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10521</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10521</id><created>2019-08-27</created><authors><author><keyname>Wei</keyname><forenames>Yanyan</forenames></author><author><keyname>Zhang</keyname><forenames>Zhao</forenames></author><author><keyname>Zhang</keyname><forenames>Haijun</forenames></author><author><keyname>Hong</keyname><forenames>Richang</forenames></author><author><keyname>Wang</keyname><forenames>Meng</forenames></author></authors><title>A Coarse-to-Fine Multi-stream Hybrid Deraining Network for Single Image
  Deraining</title><categories>eess.IV cs.CV</categories><comments>Accepted by ICDM 2019 as a regular paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single image deraining task is still a very challenging task due to its
ill-posed nature in reality. Recently, researchers have tried to fix this issue
by training the CNN-based end-to-end models, but they still cannot extract the
negative rain streaks from rainy images precisely, which usually leads to an
over de-rained or under de-rained result. To handle this issue, this paper
proposes a new coarse-to-fine single image deraining framework termed
Multi-stream Hybrid Deraining Network (shortly, MH-DerainNet). To obtain the
negative rain streaks during training process more accurately, we present a new
module named dual path residual dense block, i.e., Residual path and Dense
path. The Residual path is used to reuse com-mon features from the previous
layers while the Dense path can explore new features. In addition, to
concatenate different scaled features, we also apply the idea of multi-stream
with shortcuts between cascaded dual path residual dense block based streams.
To obtain more distinct derained images, we combine the SSIM loss and
perceptual loss to preserve the per-pixel similarity as well as preserving the
global structures so that the deraining result is more accurate. Extensive
experi-ments on both synthetic and real rainy images demonstrate that our
MH-DerainNet can deliver significant improvements over several recent
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10555</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10555</id><created>2019-08-28</created><authors><author><keyname>Xu</keyname><forenames>Gang</forenames></author><author><keyname>Song</keyname><forenames>Zhigang</forenames></author><author><keyname>Sun</keyname><forenames>Zhuo</forenames></author><author><keyname>Ku</keyname><forenames>Calvin</forenames></author><author><keyname>Yang</keyname><forenames>Zhe</forenames></author><author><keyname>Liu</keyname><forenames>Cancheng</forenames></author><author><keyname>Wang</keyname><forenames>Shuhao</forenames></author><author><keyname>Ma</keyname><forenames>Jianpeng</forenames></author><author><keyname>Xu</keyname><forenames>Wei</forenames></author></authors><title>CAMEL: A Weakly Supervised Learning Framework for Histopathology Image
  Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><comments>10 pages, 9 figures, accepted by ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Histopathology image analysis plays a critical role in cancer diagnosis and
treatment. To automatically segment the cancerous regions, fully supervised
segmentation algorithms require labor-intensive and time-consuming labeling at
the pixel level. In this research, we propose CAMEL, a weakly supervised
learning framework for histopathology image segmentation using only image-level
labels. Using multiple instance learning (MIL)-based label enrichment, CAMEL
splits the image into latticed instances and automatically generates
instance-level labels. After label enrichment, the instance-level labels are
further assigned to the corresponding pixels, producing the approximate
pixel-level labels and making fully supervised training of segmentation models
possible. CAMEL achieves comparable performance with the fully supervised
approaches in both instance-level classification and pixel-level segmentation
on CAMELYON16 and a colorectal adenoma dataset. Moreover, the generality of the
automatic labeling methodology may benefit future weakly supervised learning
studies for histopathology image analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10560</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10560</id><created>2019-08-28</created><authors><author><keyname>Cai</keyname><forenames>Xiaodong</forenames></author><author><keyname>Ma</keyname><forenames>Jingyi</forenames></author><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Han</keyname><forenames>Hemin</forenames></author><author><keyname>Ma</keyname><forenames>Lili</forenames></author></authors><title>Efficient Convolutional Neural Network for FMCW Radar Based Hand Gesture
  Recognition</title><categories>cs.HC eess.SP</categories><comments>Poster in Ubicomp 2019</comments><doi>10.1145/3341162.3343768</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  FMCW radar could detect object's range, speed and Angleof-Arrival, advantages
are robust to bad weather, good range resolution, and good speed resolution. In
this paper, we consider the FMCW radar as a novel interacting interface on
laptop. We merge sequences of object's range, speed, azimuth information into
single input, then feed to a convolution neural network to learn spatial and
temporal patterns. Our model achieved 96% accuracy on test set and real-time
test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10563</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10563</id><created>2019-08-28</created><authors><author><keyname>Adhikari</keyname><forenames>Prakash</forenames></author><author><keyname>Nagesh</keyname><forenames>Prashanth K. B.</forenames></author><author><keyname>Alherthi</keyname><forenames>Fatimah</forenames></author><author><keyname>Chauhan</keyname><forenames>Subhash C.</forenames></author><author><keyname>Jaggi</keyname><forenames>Meena</forenames></author><author><keyname>Yallapu</keyname><forenames>Murali M.</forenames></author><author><keyname>Pradhan</keyname><forenames>Prabhakar</forenames></author></authors><title>Optical detection of structural properties of tumor tissues generated by
  xenografting of drug-sensitive and drug-resistant cancer cells using partial
  wave spectroscopy (PWS)</title><categories>physics.med-ph eess.IV</categories><comments>5 figures, 13 pages</comments><journal-ref>Optics Express 10 (12), 6422-6431 (2019)</journal-ref><doi>10.1364/BOE.10.006422</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quantitative measurement of structural alterations at the nanoscale level
is important for understanding the physical state of biological samples.
Studies have shown that the progression of cancer is associated with the
rearrangements of building blocks of cells/tissues such as DNA, RNA, lipids,
etc. Partial wave spectroscopy is a recently developed mesoscopic physics-based
spectroscopic imaging technique which can detect such nanoscale changes in
cells/tissues. At present, chemotherapy drug treatment is the only effective
form of treatment; however, the development of drug-resistant cancer cells is a
major challenge for this treatment. Earlier PWS analyses of prostate cancer
cells, a 2D structure, have shown that drug-resistant cancer cells have a
higher degree of structural disorder compared to drug-sensitive cancer cells.
At the same time, structural properties of the metastasize tumor grown to 3D
structure from drug-resistant and drug-sensitive cancer cells within the body
is not well studied. In this paper, the structural properties of tissues from
grown 3D tumors, generated from docetaxel drug-sensitive and drug-resistant
prostate cancer cells xenografted into a mouse model, are studied. The results
show that xenografted tumor tissues from drug-resistant cells have higher
disorder strength than the tumor generated from drug-sensitive prostate cancer
cells. Potential applications of the technique to assess chemotherapy
effectiveness in cancer treatment are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10579</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10579</id><created>2019-08-28</created><authors><author><keyname>Juhl</keyname><forenames>Kristine Aavild</forenames></author><author><keyname>Paulsen</keyname><forenames>Rasmus Reinhold</forenames></author><author><keyname>Dahl</keyname><forenames>Anders Bjorholm</forenames></author><author><keyname>Dahl</keyname><forenames>Vedrana Andersen</forenames></author><author><keyname>de Backer</keyname><forenames>Ole</forenames></author><author><keyname>Kofoed</keyname><forenames>Klaus Fuglsang</forenames></author><author><keyname>Camara</keyname><forenames>Oscar</forenames></author></authors><title>Guiding 3D U-nets with signed distance fields for creating 3D models
  from images</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/rJgzz3Y4qV</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Morphological analysis of the left atrial appendage is an important tool to
assess risk of ischemic stroke. Most deep learning approaches for 3D
segmentation is guided by binary labelmaps, which results in voxelized
segmentations unsuitable for morphological analysis. We propose to use signed
distance fields to guide a deep network towards morphologically consistent 3D
models. The proposed strategy is evaluated on a synthetic dataset of simple
geometries, as well as a set of cardiac computed tomography images containing
the left atrial appendage. The proposed method produces smooth surfaces with a
closer resemblance to the true surface in terms of segmentation overlap and
surface distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10599</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10599</id><created>2019-08-28</created><authors><author><keyname>Jamshidnejad</keyname><forenames>Anahita</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author><author><keyname>Mahjoob</keyname><forenames>Mohammad J.</forenames></author><author><keyname>De Schutter</keyname><forenames>Bart</forenames></author></authors><title>Integrated Intelligent and Predictive Control: A Multi-Agent Adaptive
  Type-2 Fuzzy Control Architecture</title><categories>eess.SY cs.SY</categories><msc-class>49-XX</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel two-layer multi-agent architecture aimed at efficient
real-time control of large-scale and complex-dynamics systems. The proposed
architecture integrates intelligent control approaches (which have a low
computation time and fit real-time applications) with model-predictive control
(which takes care of the optimality requirements of control). The bottom
control layer (intelligent-control module) includes several distributed
intelligent-control agents, the design parameters of which are tuned by the top
layer (model-predictive control module). The model-predictive control module
fulfills two significant roles: looking ahead to the effects of the control
decisions, and coordinating the intelligent-control agents of the lower control
layer. The resulting multi-agent control system has a very low computation
time, and provides adaptivity, control coordination, and aims at excellent
performance. Additionally, we give a general treatment of type-2 fuzzy
membership functions, and introduce two categories for them:
probabilistic-fuzzy (which is a novel concept introduced in this paper) and
fuzzy-fuzzy (which is a new treatment of the existing type-2 fuzzy membership
functions). The performance of the proposed modeling and control approaches are
assessed via a case study involving a simple urban traffic network: the results
show that the novel concept of probabilistic-fuzzy membership function
outperforms the type-1 and type-2 membership functions that have already been
introduced in the literature. Furthermore, the proposed two-layer integrated
multi-agent control architecture significantly outperforms a multi-agent
decentralized fuzzy control system (without coordination among the agents),
while requiring a comparable computation time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10608</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10608</id><created>2019-08-28</created><updated>2020-02-10</updated><authors><author><keyname>Ginesi</keyname><forenames>Michele</forenames></author><author><keyname>Sansonetto</keyname><forenames>Nicola</forenames></author><author><keyname>Fiorini</keyname><forenames>Paolo</forenames></author></authors><title>Overcoming Some Drawbacks of Dynamic Movement Primitives</title><categories>cs.RO cs.NA cs.SY eess.SY math.NA</categories><comments>Preprint for International Journal of Robotics Research (IJRR)
  submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic Movement Primitives (DMPs) is a framework for learning a
point-to-point trajectory from a demonstration. Despite being widely used, DMPs
still present some shortcomings that may limit their usage in real robotic
applications. Firstly, at the state of the art, mainly Gaussian basis functions
have been used to perform function approximation. Secondly, adaptation of the
trajectory generated by the DMP heavily depends on the choice of
hyperparameters and on the new desired goal position. Lastly, DMPs are a
framework for `one-shot learning', meaning that they are constrained to learn
from a unique demonstration. In this work, we present and motivate a new set of
basis functions to be used in the learning process, showing their ability to
accurately approximate functions while having both analytical and numerical
advantages w.r.t. Gaussian basis functions. Then, we show how to use the
invariance of DMPs w.r.t. affine transformations in order to make the
generalization of the trajectory robust against both the choice of
hyperparameters and new goal position, performing synthetic tests to show this
increased robustness. Finally, we propose an algorithm to extract a common
behavior from multiple observations, validating it both on a synthetic dataset
and on a dataset obtained by performing a task on a real robot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10609</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10609</id><created>2019-08-28</created><updated>2019-08-29</updated><authors><author><keyname>Liniger</keyname><forenames>Alexander</forenames></author><author><keyname>Varano</keyname><forenames>Luca</forenames></author><author><keyname>Rupenyan</keyname><forenames>Alisa</forenames></author><author><keyname>Lygeros</keyname><forenames>John</forenames></author></authors><title>Real-Time Predictive Control for Precision Machining</title><categories>eess.SY cs.SY</categories><comments>6 pages, 3 figures, Accepted for publication in 58th IEEE Conference
  on Decision and Control (CDC 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precise positioning and fast traversal times are crucial in achieving high
productivity and scale in machining. This paper compares two optimization-based
predictive control approaches that achieve high performance. In the first
approach, the contour error is defined using the global position, the position
on the path is inferred through a virtual path parameter, and the cost function
combines the corresponding states and inputs to achieve a trade-off between
high speed and positioning accuracy. The second approach is based on a local
definition of both the error and the progress along the path, and results in a
system with a reduced number of states and inputs that enables real-time
optimization. Terminal and trust region constraints are required to achieve
precise tracking of geometries where a fast or instantaneous change in
direction is present. The performance of both approaches using different
quadratic programming solvers is evaluated in simulations for geometries that
are challenging in machine tools applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10616</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10616</id><created>2019-08-28</created><authors><author><keyname>Rached</keyname><forenames>Nadhir Ben</forenames></author><author><keyname>MacKinlay</keyname><forenames>Daniel</forenames></author><author><keyname>Botev</keyname><forenames>Zdravko</forenames></author><author><keyname>Tempone</keyname><forenames>Raul</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>A Universal Splitting Estimator for the Performance Evaluation of
  Wireless Communications Systems</title><categories>cs.IT eess.SP math.IT stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a unified rare-event estimator for the performance evaluation of
wireless communication systems. The estimator is derived from the well-known
multilevel splitting algorithm. In its original form, the splitting algorithm
cannot be applied to the simulation and estimation of time-independent
problems, because splitting requires an underlying continuous-time Markov
process whose trajectories can be split. We tackle this problem by embedding
the static problem of interest within a continuous-time Markov process, so that
the target time-independent distribution becomes the distribution of the Markov
process at a given time instant. The main feature of the proposed multilevel
splitting algorithm is its large scope of applicability. For illustration, we
show how the same algorithm can be applied to the problem of estimating the
cumulative distribution function (CDF) of sums of random variables (RVs), the
CDF of partial sums of ordered RVs, the CDF of ratios of RVs, and the CDF of
weighted sums of Poisson RVs. We investigate the computational efficiency of
the proposed estimator via a number of simulation studies and find that it
compares favorably with existing estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10661</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10661</id><created>2019-08-26</created><authors><author><keyname>Yousef</keyname><forenames>Waleed A.</forenames></author><author><keyname>Abouelkahire</keyname><forenames>Ahmed A.</forenames></author><author><keyname>Almahallawi</keyname><forenames>Deyaaeldeen</forenames></author><author><keyname>Marzouk</keyname><forenames>Omar S.</forenames></author><author><keyname>Mohamed</keyname><forenames>Sameh K.</forenames></author><author><keyname>Mustafa</keyname><forenames>Waleed A.</forenames></author><author><keyname>Osama</keyname><forenames>Omar M.</forenames></author><author><keyname>Saleh</keyname><forenames>Ali A.</forenames></author><author><keyname>Abdelrazek</keyname><forenames>Naglaa M.</forenames></author></authors><title>Method and System for Image Analysis to Detect Cancer</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Breast cancer is the most common cancer and is the leading cause of cancer
death among women worldwide. Detection of breast cancer, while it is still
small and confined to the breast, provides the best chance of effective
treatment. Computer Aided Detection (CAD) systems that detect cancer from
mammograms will help in reducing the human errors that lead to missing breast
carcinoma. Literature is rich of scientific papers for methods of CAD design,
yet with no complete system architecture to deploy those methods. On the other
hand, commercial CADs are developed and deployed only to vendors' mammography
machines with no availability to public access. This paper presents a complete
CAD; it is complete since it combines, on a hand, the rigor of algorithm design
and assessment (method), and, on the other hand, the implementation and
deployment of a system architecture for public accessibility (system). (1) We
develop a novel algorithm for image enhancement so that mammograms acquired
from any digital mammography machine look qualitatively of the same clarity to
radiologists' inspection; and is quantitatively standardized for the detection
algorithms. (2) We develop novel algorithms for masses and microcalcifications
detection with accuracy superior to both literature results and the majority of
approved commercial systems. (3) We design, implement, and deploy a system
architecture that is computationally effective to allow for deploying these
algorithms to cloud for public access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10670</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10670</id><created>2019-08-28</created><authors><author><keyname>Azendorf</keyname><forenames>Florian</forenames></author><author><keyname>Dochhan</keyname><forenames>Annika</forenames></author><author><keyname>Braun</keyname><forenames>Ralf-Peter</forenames></author><author><keyname>Eiselt</keyname><forenames>Michael</forenames></author></authors><title>Long-Term Latency Measurement of Deployed Fiber</title><categories>eess.SP</categories><comments>This project has received funding from the European Union Horizon
  2020 research and innovation programme under grant agreement No 762055
  (BlueSpace Project)</comments><doi>10.1364/OFC.2019.Tu3J.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a Correlation-OTDR we measured the latency of fibers in a deployed
cable and calculated the time coefficient of the fiber temperature changes.
Annual temperature variations of 25K were estimated for the deployed fiber.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10674</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10674</id><created>2019-08-24</created><authors><author><keyname>Basu</keyname><forenames>Joydeep</forenames></author></authors><title>From design to tape-out in SCL 180nm CMOS integrated circuit fabrication
  technology</title><categories>eess.SP</categories><comments>This is preprint of article accepted for publication in IETE Journal
  of Education, published by Taylor &amp; Francis. Available online at:
  https://doi.org/10.1080/09747338.2019.1657787</comments><doi>10.1080/09747338.2019.1657787</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although India has achieved considerable capability in electronic chip
design, but developing the infrastructure for capital-intensive semiconductor
fabrication remains a challenge. The rising domestic and global demand for
electronics products, the need of enhancing the country's high-technology
talent pool, employment generation, and national security concerns dictates the
Indian Government's heightened efforts in promoting electronics hardware
manufacturing in the country. A recent milestone in this regard is the setting
up of 180nm CMOS fabrication facility at SCL, Chandigarh. The Multi Project
Wafer runs of this indigenous foundry promises to be a relatively
cost-effective option for Indian academic and R&amp;D institutions in realizing
their designed VLSI circuits. Written from the perspective of an Analog VLSI
designer, this tutorial paper strives to provide all the requisite information
and guidance that might be required in order to prepare chip designs for
submission to SCL for fabrication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10677</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10677</id><created>2019-08-22</created><authors><author><keyname>Ghorbanpour</keyname><forenames>Amin</forenames></author><author><keyname>Sohrab</keyname><forenames>Mohsen</forenames></author></authors><title>Fixed final time three-axis satellite attitude control with thrusters
  based on dynamic programming and neural networks</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the attitude control of a satellite in three-axis by
thrusters. The mathematical model of attitude dynamics and kinematics of the
satellite is represented as a switched system with sub-systems. Each sub-system
is defined according to on/off thrusters state. A training method based on
dynamic programming is utilized which can find the appropriate switching
between sub-systems such that a cost function is optimized. Furthermore to
extend the solution for a specific domain of interest neural network is used
for approximating the cost function with basis functions. The training method
is offline and it finds the optimal weights of basis functions which can be
used to find optimal switching. It is shown that the proposed method can
execute a maneuver in fixed final time and bring the attitude to final desired
condition. Moreover, the proposed method is robust against uncertainties in
system modeling. Finally, it is shown that the control scheme can be used to
design low cost attitude control unit for micro-satellite or as a backup unit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10713</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10713</id><created>2019-08-20</created><authors><author><keyname>Holweger</keyname><forenames>Jordan</forenames></author><author><keyname>Dorokhova</keyname><forenames>Marina</forenames></author><author><keyname>Bloch</keyname><forenames>Lionel</forenames></author><author><keyname>Ballif</keyname><forenames>Christophe</forenames></author><author><keyname>Wyrsch</keyname><forenames>Nicolas</forenames></author></authors><title>Unsupervised algorithm for disaggregating low-sampling-rate electricity
  consumption of households</title><categories>cs.LG eess.SP</categories><journal-ref>Sustainable Energy, Grids and Networks, Volume 19, 2019</journal-ref><doi>10.1016/j.segan.2019.100244</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Non-intrusive load monitoring (NILM) has been extensively researched over the
last decade. The objective of NILM is to identify the power consumption of
individual appliances and to detect when particular devices are on or off from
measuring the power consumption of an entire house. This information allows
households to receive customized advice on how to better manage their
electrical consumption. In this paper, we present an alternative NILM method
that breaks down the aggregated power signal into categories of appliances. The
ultimate goal is to use this approach for demand-side management to estimate
potential flexibility within the electricity consumption of households. Our
method is implemented as an algorithm combining NILM and load profile
simulation. This algorithm, based on a Markov model, allocates an activity
chain to each inhabitant of the household, deduces from the whole-house power
measurement and statistical data the appliance usage, generate the power
profile accordingly and finally returns the share of energy consumed by each
appliance category over time. To analyze its performance, the algorithm was
benchmarked against several state-of-the-art NILM algorithms and tested on
three public datasets. The proposed algorithm is unsupervised; hence it does
not require any labeled data, which are expensive to acquire. Although better
performance is shown for the supervised algorithms, our proposed unsupervised
algorithm achieves a similar range of uncertainty while saving on the cost of
acquiring labeled data. Additionally, our method requires lower computational
power compared to most of the tested NILM algorithms. It was designed for
low-sampling-rate power measurement (every 15 min), which corresponds to the
frequency range of most common smart meters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10715</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10715</id><created>2019-08-28</created><authors><author><keyname>Dilz</keyname><forenames>Roeland J.</forenames></author><author><keyname>Schr&#xf6;der</keyname><forenames>Lukas</forenames></author><author><keyname>Moriakov</keyname><forenames>Nikita</forenames></author><author><keyname>Sonke</keyname><forenames>Jan-Jakob</forenames></author><author><keyname>Teuwen</keyname><forenames>Jonas</forenames></author></authors><title>Learned SIRT for Cone Beam Computed Tomography Reconstruction</title><categories>eess.IV math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the learned simultaneous iterative reconstruction technique
(SIRT) for tomographic reconstruction. The learned SIRT algorithm is a deep
learning based reconstruction method combining model knowledge with a learned
component. The algorithm is trained by mapping raw measured data to the
reconstruction results over several iterations. The Learned SIRT algorithm is
applied to a cone beam geometry on a circular orbit, a challenging problem for
learned methods due to its 3D geometry and its inherent inability to completely
capture the patient anatomy. A comparison of 2D reconstructions is shown, where
the learned SIRT approach produces reconstructions with superior peak signal to
noise ratio (PSNR) and structural similarity (SSIM), compared to FBP, SIRT and
U-net post-processing and similar PSNR and SSIM compared to the learned primal
dual algorithm. Similar results are shown for cone beam geometry
reconstructions of a 3D Shepp Logan phantom, where we obtain between 9.9 and
28.1 dB improvement over FBP with a substantial improvement in SSIM. Finally we
show that our algorithm scales to clinically relevant problems, and performs
well when applied to measurements of a physical phantom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10722</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10722</id><created>2019-08-28</created><updated>2019-08-29</updated><authors><author><keyname>Ikemoto</keyname><forenames>Junya</forenames></author><author><keyname>Ushio</keyname><forenames>Toshimitsu</forenames></author></authors><title>Networked Control of Nonlinear Systems under Partial Observation Using
  Continuous Deep Q-Learning</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><comments>6 pages, 9 figures, Accepted for presentation in the IEEE Conference
  on Decision and Control (CDC) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a design of a model-free networked controller for a
nonlinear plant whose mathematical model is unknown. In a networked control
system, the controller and plant are located away from each other and exchange
data over a network, which causes network delays that may fluctuate randomly
due to network routing. So, in this paper, we assume that the current network
delay is not known but the maximum value of fluctuating network delays is known
beforehand. Moreover, we also assume that the sensor cannot observe all state
variables of the plant. Under these assumption, we apply continuous deep
Q-learning to the design of the networked controller. Then, we introduce an
extended state consisting of a sequence of past control inputs and outputs as
inputs to the deep neural network. By simulation, it is shown that, using the
extended state, the controller can learn a control policy robust to the
fluctuation of the network delays under the partial observation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10734</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10734</id><created>2019-08-28</created><authors><author><keyname>Wang</keyname><forenames>Peilan</forenames></author><author><keyname>Fang</keyname><forenames>Jun</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaojun</forenames></author><author><keyname>Chen</keyname><forenames>Zhi</forenames></author><author><keyname>Duan</keyname><forenames>Huiping</forenames></author><author><keyname>Li</keyname><forenames>Hongbin</forenames></author></authors><title>Intelligent Reflecting Surface-Assisted Millimeter Wave Communications:
  Joint Active and Passive Precoding Design</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (MmWave) communications is capable of supporting
multi-gigabit wireless access thanks to its abundant spectrum resource.
However, the severe path loss and high directivity make it vulnerable to
blockage events, which can be frequent in indoor and dense urban environments.
To address this issue, in this paper, we introduce intelligent reflecting
surface (IRS) as a new technology to provide effective reflected paths to
enhance coverage of mmWave signals. In this framework, we study joint active
and passive precoding design for IRS-assisted mmWave systems, where multiple
IRSs are deployed to assist the data transmission from a base station (BS) to a
single-antenna receiver. Our objective is to maximize the received signal power
by jointly optimizing the transmit precoding vector at the BS and the phase
shift parameters used by IRSs for passive beamforming. Although such an
optimization problem is generally non-convex, we show that, by exploiting some
important characteristics of mmWave channels, an optimal closed-form solution
can be derived for the single IRS case and a near-optimal analytical solution
can be obtained for the multi-IRS case. Our analysis reveals that the received
signal power increases quadratically with the number of reflecting elements for
both the single IRS and multi-IRS cases. Simulation results are included to
verify the optimality and near-optimality of our proposed solutions. Results
also show that IRSs can help create effective virtual LOS paths and thus
substantially improve robustness against blockages in mmWave communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10737</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10737</id><created>2019-08-28</created><authors><author><keyname>Li</keyname><forenames>Shichao</forenames></author><author><keyname>Cheng</keyname><forenames>Kwang-Ting</forenames></author></authors><title>Facial age estimation by deep residual decision making</title><categories>cs.CV cs.LG eess.IV</categories><comments>Following-up work for visualizing deep neural decision forest for
  facial age estimation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Residual representation learning simplifies the optimization problem of
learning complex functions and has been widely used by traditional
convolutional neural networks. However, it has not been applied to deep neural
decision forest (NDF). In this paper we incorporate residual learning into NDF
and the resulting model achieves state-of-the-art level accuracy on three
public age estimation benchmarks while requiring less memory and computation.
We further employ gradient-based technique to visualize the decision-making
process of NDF and understand how it is influenced by facial image inputs. The
code and pre-trained models will be available at
https://github.com/Nicholasli1995/VisualizingNDF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10744</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10744</id><created>2019-08-28</created><authors><author><keyname>Liu</keyname><forenames>Zhaoqiang</forenames></author><author><keyname>Scarlett</keyname><forenames>Jonathan</forenames></author></authors><title>Information-Theoretic Lower Bounds for Compressive Sensing with
  Generative Models</title><categories>cs.IT cs.LG eess.SP math.IT math.ST stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of standard compressive sensing is to estimate an unknown vector
from linear measurements under the assumption of sparsity in some basis.
Recently, it has been shown that significantly fewer measurements may be
required if the sparsity assumption is replaced by the assumption that the
unknown vector lies near the range of a suitably-chosen generative model. In
particular, in (Bora {\em et al.}, 2017) it was shown that roughly $O(k\log L)$
random Gaussian measurements suffice for accurate recovery when the $k$-input
generative model is bounded and $L$-Lipschitz, and that $O(kd \log w)$
measurements suffice for $k$-input ReLU networks with depth $d$ and width $w$.
In this paper, we establish corresponding algorithm-independent lower bounds on
the sample complexity using tools from minimax statistical analysis. In
accordance with the above upper bounds, our results are summarized as follows:
(i) We construct an $L$-Lipschitz generative model capable of generating
group-sparse signals, and show that the resulting necessary number of
measurements is $\Omega(k \log L)$; (ii) Using similar ideas, we construct
two-layer ReLU networks of high width requiring $\Omega(k \log w)$
measurements, as well as lower-width deep ReLU networks requiring $\Omega(k d)$
measurements. As a result, we establish that the scaling laws derived in (Bora
{\em et al.}, 2017) are optimal or near-optimal in the absence of further
assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10768</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10768</id><created>2019-08-28</created><updated>2020-01-11</updated><authors><author><keyname>Li</keyname><forenames>Andong</forenames></author><author><keyname>Yuan</keyname><forenames>Minmin</forenames></author><author><keyname>Zheng</keyname><forenames>Chengshi</forenames></author><author><keyname>Li</keyname><forenames>Xiaodong</forenames></author></authors><title>Convolutional Recurrent Neural Network Based Progressive Learning for
  Monaural Speech Enhancement</title><categories>cs.SD eess.AS</categories><comments>23 pages,5 figures, Submitted to Applied Acoustics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, progressive learning has shown its capacity to improve speech
quality and speech intelligibility when it is combined with deep neural network
(DNN) and long short-term memory (LSTM) based monaural speech enhancement
algorithms, especially in low signal-to-noise ratio (SNR) conditions.
Nevertheless, due to a large number of parameters and high computational
complexity, it is hard to implement in current resource-limited
micro-controllers and thus, it is essential to significantly reduce both the
number of parameters and the computational load for practical applications. For
this purpose, we propose a novel progressive learning framework with causal
convolutional recurrent neural networks called PL-CRNN, which takes advantage
of both convolutional neural networks and recurrent neural networks to
drastically reduce the number of parameters and simultaneously improve speech
quality and speech intelligibility. Numerous experiments verify the
effectiveness of the proposed PL-CRNN model and indicate that it yields
consistent better performance than the PL-DNN and PL-LSTM algorithms and also
it gets results close even better than the CRNN in terms of objective
measurements. Compared with PL-DNN, PL-LSTM, and CRNN, the proposed PL-CRNN
algorithm can reduce the number of parameters up to 93%, 97%, and 92%,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10776</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10776</id><created>2019-08-28</created><updated>2019-09-05</updated><authors><author><keyname>Qu</keyname><forenames>Qing</forenames></author><author><keyname>Li</keyname><forenames>Xiao</forenames></author><author><keyname>Zhu</keyname><forenames>Zhihui</forenames></author></authors><title>A Nonconvex Approach for Exact and Efficient Multichannel Sparse Blind
  Deconvolution</title><categories>eess.SP cs.LG eess.IV math.OC stat.ML</categories><comments>61 pages, 6 figures; short version accepted as a spotlight paper at
  NeurIPS'19; long version submitted to FoCM</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the multi-channel sparse blind deconvolution (MCS-BD) problem, whose
task is to simultaneously recover a kernel $\mathbf a$ and multiple sparse
inputs $\{\mathbf x_i\}_{i=1}^p$ from their circulant convolution $\mathbf y_i
= \mathbf a \circledast \mathbf x_i $ ($i=1,\cdots,p$). We formulate the task
as a nonconvex optimization problem over the sphere. Under mild statistical
assumptions of the data, we prove that the vanilla Riemannian gradient descent
(RGD) method, with random initializations, provably recovers both the kernel
$\mathbf a$ and the signals $\{\mathbf x_i\}_{i=1}^p$ up to a signed shift
ambiguity. In comparison with state-of-the-art results, our work shows
significant improvements in terms of sample complexity and computational
efficiency. Our theoretical results are corroborated by numerical experiments,
which demonstrate superior performance of the proposed approach over the
previous methods on both synthetic and real datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10789</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10789</id><created>2019-08-19</created><authors><author><keyname>Sousa</keyname><forenames>E. A.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>E. G.</forenames></author><author><keyname>Barroso</keyname><forenames>M. F. S.</forenames></author></authors><title>Computation of the largest Lyapunov exponent using recursive estimation
  with variable factor</title><categories>math.NA cs.NA cs.SY eess.SP eess.SY</categories><comments>SBAI 2019 - Simposio Brasileiro de Automacao Inteligente - Ouro
  Preto. 6 pages. In Portuguese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chaotic systems have been investigated in the most diverse areas. One of the
first steps in chaotic system research is the detection of chaos. The largest
Lyapunov exponent (LLE) is one of the most widely used techniques for this
purpose. Recently, techniques for calculating LLE have been developed taking
into account the error due to the finite precision of computers. Recursive
methods were employed to improve such algorithms. However, this method
uniformly weighed the data used to calculate the LLE. This paper investigates
the different weighing of the data based on the hypothesis that the initial
data have a higher precision than the last data processed by the algorithm,
since the process is subject to error accumulation. In five tested systems, the
proposed method obtained more accurate results in three. However, there was an
increase in the variance of the result obtained for two of the evaluated
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10803</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10803</id><created>2019-08-27</created><authors><author><keyname>Obeed</keyname><forenames>Mohanad</forenames></author><author><keyname>Dahrouj</keyname><forenames>Hayssam</forenames></author><author><keyname>Salhab</keyname><forenames>Anas M.</forenames></author><author><keyname>Zummo</keyname><forenames>Salam A.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>User Pairing, Link Selection and Power Allocation for Cooperative NOMA
  Hybrid VLC/RF Systems</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the promising high-data rate features of visible light communications
(VLC), they still suffer from unbalanced services due to blockages and channel
fluctuation among users. This paper introduces and evaluates a new transmission
scheme which adopts cooperative non-orthogonal multiple access (Co-NOMA) in
hybrid VLC/radio-frequency (RF) systems, so as to improve both system sum-rate
and fairness. Consider a network consisting of one VLC access point (AP) and
multiple strong and weak users, where each weak user is paired with a strong
user. Each weak user can be served either directly by the VLC AP, or via the
strong user which converts light information received through the VLC link, and
forwards the information to the weak user via the RF link. The paper then
maximizes a network-wide weighted sum-rate, so as to jointly determine the
strong-weak user-pairs, the serving link of each weak user (i.e., either direct
VLC or hybrid VLC/RF), and the power of each user message, subject to user
connectivity and transmit power constraints. The paper tackles such a
mixed-integer non-convex optimization problem using an iterative approach.
Simulations show that the proposed scheme significantly improves the VLC
network performance (i.e., sum-rate and fairness) as compared to the
conventional NOMA scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10842</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10842</id><created>2019-08-28</created><authors><author><keyname>Zhang</keyname><forenames>Tong</forenames></author><author><keyname>Jackson</keyname><forenames>Laurence H.</forenames></author><author><keyname>Uus</keyname><forenames>Alena</forenames></author><author><keyname>Clough</keyname><forenames>James R.</forenames></author><author><keyname>Story</keyname><forenames>Lisa</forenames></author><author><keyname>Rutherford</keyname><forenames>Mary A.</forenames></author><author><keyname>Hajnal</keyname><forenames>Joseph V.</forenames></author><author><keyname>Deprez</keyname><forenames>Maria</forenames></author></authors><title>Self-supervised Recurrent Neural Network for 4D Abdominal and In-utero
  MR Imaging</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted by MICCAI 2019 workshop on Machine Learning for Medical
  Image Reconstruction</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurately estimating and correcting the motion artifacts are crucial for 3D
image reconstruction of the abdominal and in-utero magnetic resonance imaging
(MRI). The state-of-art methods are based on slice-to-volume registration (SVR)
where multiple 2D image stacks are acquired in three orthogonal orientations.
In this work, we present a novel reconstruction pipeline that only needs one
orientation of 2D MRI scans and can reconstruct the full high-resolution image
without masking or registration steps. The framework consists of two main
stages: the respiratory motion estimation using a self-supervised recurrent
neural network, which learns the respiratory signals that are naturally
embedded in the asymmetry relationship of the neighborhood slices and cluster
them according to a respiratory state. Then, we train a 3D deconvolutional
network for super-resolution (SR) reconstruction of the sparsely selected 2D
images using integrated reconstruction and total variation loss. We evaluate
the classification accuracy on 5 simulated images and compare our results with
the SVR method in adult abdominal and in-utero MRI scans. The results show that
the proposed pipeline can accurately estimate the respiratory state and
reconstruct 4D SR volumes with better or similar performance to the 3D SVR
pipeline with less than 20\% sparsely selected slices. The method has great
potential to transform the 4D abdominal and in-utero MRI in clinical practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10851</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10851</id><created>2019-08-28</created><authors><author><keyname>Dai</keyname><forenames>Chengliang</forenames></author><author><keyname>Mo</keyname><forenames>Yuanhan</forenames></author><author><keyname>Angelini</keyname><forenames>Elsa</forenames></author><author><keyname>Guo</keyname><forenames>Yike</forenames></author><author><keyname>Bai</keyname><forenames>Wenjia</forenames></author></authors><title>Transfer Learning from Partial Annotations for Whole Brain Segmentation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brain MR image segmentation is a key task in neuroimaging studies. It is
commonly conducted using standard computational tools, such as FSL, SPM,
multi-atlas segmentation etc, which are often registration-based and suffer
from expensive computation cost. Recently, there is an increased interest using
deep neural networks for brain image segmentation, which have demonstrated
advantages in both speed and performance. However, neural networks-based
approaches normally require a large amount of manual annotations for optimising
the massive amount of network parameters. For 3D networks used in volumetric
image segmentation, this has become a particular challenge, as a 3D network
consists of many more parameters compared to its 2D counterpart. Manual
annotation of 3D brain images is extremely time-consuming and requires
extensive involvement of trained experts. To address the challenge with limited
manual annotations, here we propose a novel multi-task learning framework for
brain image segmentation, which utilises a large amount of automatically
generated partial annotations together with a small set of manually created
full annotations for network training. Our method yields a high performance
comparable to state-of-the-art methods for whole brain segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10862</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10862</id><created>2019-08-22</created><authors><author><keyname>Andoni</keyname><forenames>Merlinda</forenames></author><author><keyname>Robu</keyname><forenames>Valentin</forenames></author><author><keyname>Flynn</keyname><forenames>David</forenames></author><author><keyname>Fruh</keyname><forenames>Wolf-Gerrit</forenames></author></authors><title>Gibbs sampling for game-theoretic modeling of private network upgrades
  with distributed generation</title><categories>eess.SY cs.CE cs.CY cs.SY</categories><comments>Preprint of final submitted version. arXiv admin note: text overlap
  with arXiv:1908.10313</comments><journal-ref>Proceedings of 2018 IEEE PES Innovative Smart Grid Technologies
  Conference Europe (ISGT-Europe)</journal-ref><doi>10.1109/isgteurope.2018.8571545</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Renewable energy is increasingly being curtailed, due to oversupply or
network constraints. Curtailment can be partially avoided by smart grid
management, but the long term solution is network reinforcement. Network
upgrades, however, can be costly, so recent interest has focused on
incentivising private investors to participate in network investments. In this
paper, we study settings where a private renewable investor constructs a power
line, but also provides access to other generators that pay a transmission fee.
The decisions on optimal (and interdependent) renewable capacities built by
investors, affect the resulting curtailment and profitability of projects, and
can be formulated as a Stackelberg game. Optimal capacities rely jointly on
stochastic variables, such as the renewable resource at project location. In
this paper, we show how Markov chain Monte Carlo (MCMC) and Gibbs sampling
techniques, can be used to generate observations from historic resource data
and simulate multiple future scenarios. Finally, we validate and apply our
game-theoretic formulation of the investment decision, to a real network
upgrade problem in the UK.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10903</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10903</id><created>2019-08-28</created><authors><author><keyname>Yan</keyname><forenames>Xuefei</forenames></author><author><keyname>Brady</keyname><forenames>David J.</forenames></author><author><keyname>Wang</keyname><forenames>Jianqiang</forenames></author><author><keyname>Huang</keyname><forenames>Chao</forenames></author><author><keyname>Li</keyname><forenames>Zian</forenames></author><author><keyname>Yan</keyname><forenames>Songsong</forenames></author><author><keyname>Liu</keyname><forenames>Di</forenames></author><author><keyname>Ma</keyname><forenames>Zhan</forenames></author></authors><title>Compressive Sampling for Array Cameras</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While design of high performance lenses and image sensors has long been the
focus of camera development, the size, weight and power of image data
processing components is currently the primary barrier to radical improvements
in camera resolution. Here we show that Deep-Learning- Aided Compressive
Sampling (DLACS) can reduce operating power on camera-head electronics by 20x.
Traditional compressive sampling has to date been primarily applied in the
physical sensor layer, we show here that with aid from deep learning
algorithms, compressive sampling offers unique power management advantages in
digital layer compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10920</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10920</id><created>2019-08-28</created><updated>2019-09-28</updated><authors><author><keyname>Liu</keyname><forenames>Guan-Horng</forenames></author><author><keyname>Theodorou</keyname><forenames>Evangelos A.</forenames></author></authors><title>Deep Learning Theory Review: An Optimal Control and Dynamical Systems
  Perspective</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><comments>Under Submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attempts from different disciplines to provide a fundamental understanding of
deep learning have advanced rapidly in recent years, yet a unified framework
remains relatively limited. In this article, we provide one possible way to
align existing branches of deep learning theory through the lens of dynamical
system and optimal control. By viewing deep neural networks as discrete-time
nonlinear dynamical systems, we can analyze how information propagates through
layers using mean field theory. When optimization algorithms are further recast
as controllers, the ultimate goal of training processes can be formulated as an
optimal control problem. In addition, we can reveal convergence and
generalization properties by studying the stochastic dynamics of optimization
algorithms. This viewpoint features a wide range of theoretical study from
information bottleneck to statistical physics. It also provides a principled
way for hyper-parameter tuning when optimal control theory is introduced. Our
framework fits nicely with supervised learning and can be extended to other
learning problems, such as Bayesian learning, adversarial training, and
specific forms of meta learning, without efforts. The review aims to shed
lights on the importance of dynamics and optimal control when developing deep
learning theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10922</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10922</id><created>2019-08-28</created><updated>2019-10-17</updated><authors><author><keyname>Kiar</keyname><forenames>Gregory</forenames></author><author><keyname>Castro</keyname><forenames>Pablo de Oliveira</forenames></author><author><keyname>Rioux</keyname><forenames>Pierre</forenames></author><author><keyname>Petit</keyname><forenames>Eric</forenames></author><author><keyname>Brown</keyname><forenames>Shawn T.</forenames></author><author><keyname>Evans</keyname><forenames>Alan C.</forenames></author><author><keyname>Glatard</keyname><forenames>Tristan</forenames></author></authors><title>Comparing Perturbation Models for Evaluating Stability of Neuroimaging
  Pipelines</title><categories>q-bio.NC eess.IV</categories><comments>9 pages, 5 figures, 1 table, paper to be submitted at IJHPCA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lack of software reproducibility has become increasingly apparent in the
last several years, calling into question the validity of scientific findings
affected by published tools. Reproducibility issues may have numerous sources
of error, including the underlying numerical stability of algorithms and
implementations employed. Various forms of instability have been observed in
neuroimaging, including across operating system versions, minor noise
injections, and implementation of theoretically equivalent algorithms. In this
paper we explore the effect of various perturbation methods on a typical
neuroimaging pipeline through the use of i) near-epsilon noise injections, ii)
Monte Carlo Arithmetic, and iii) varying operating systems to identify the
quality and severity of their impact. The work presented here demonstrates that
even low order computational models such as the connectome estimation pipeline
that we used are susceptible to noise. This suggests that stability is a
relevant axis upon which tools should be compared, developed, or improved,
alongside more commonly considered axes such as accuracy/biological feasibility
or performance. The heterogeneity observed across participants clearly
illustrates that stability is a property of not just the data or tools
independently, but their interaction. Characterization of stability should
therefore be evaluated for specific analyses and performed on a representative
set of subjects for consideration in subsequent statistical testing.
Additionally, identifying how this relationship scales to higher-order models
is an exciting next step which will be explored. Finally, the joint application
of perturbation methods with post-processing approaches such as bagging or
signal normalization may lead to the development of more numerically stable
analyses while maintaining sensitivity to meaningful variation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10959</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10959</id><created>2019-08-28</created><updated>2019-10-01</updated><authors><author><keyname>Lau</keyname><forenames>Yenson</forenames></author><author><keyname>Qu</keyname><forenames>Qing</forenames></author><author><keyname>Kuo</keyname><forenames>Han-Wen</forenames></author><author><keyname>Zhou</keyname><forenames>Pengcheng</forenames></author><author><keyname>Zhang</keyname><forenames>Yuqian</forenames></author><author><keyname>Wright</keyname><forenames>John</forenames></author></authors><title>Short-and-Sparse Deconvolution -- A Geometric Approach</title><categories>eess.SP cs.LG eess.IV math.OC stat.ML</categories><comments>*YL and QQ contributed equally to this work; 30 figures, 45 pages;
  This version: added an experiment comparing with other methods, corrected
  typos and added references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short-and-sparse deconvolution (SaSD) is the problem of extracting localized,
recurring motifs in signals with spatial or temporal structure. Variants of
this problem arise in applications such as image deblurring, microscopy, neural
spike sorting, and more. The problem is challenging in both theory and
practice, as natural optimization formulations are nonconvex. Moreover,
practical deconvolution problems involve smooth motifs (kernels) whose spectra
decay rapidly, resulting in poor conditioning and numerical challenges. This
paper is motivated by recent theoretical advances, which characterize the
optimization landscape of a particular nonconvex formulation of SaSD. This is
used to derive a $provable$ algorithm which exactly solves certain
non-practical instances of the SaSD problem. We leverage the key ideas from
this theory (sphere constraints, data-driven initialization) to develop a
$practical$ algorithm, which performs well on data arising from a range of
application areas. We highlight key additional challenges posed by the
ill-conditioning of real SaSD problems, and suggest heuristics (acceleration,
continuation, reweighting) to mitigate them. Experiments demonstrate both the
performance and generality of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10967</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10967</id><created>2019-08-28</created><authors><author><keyname>Li</keyname><forenames>Na</forenames></author><author><keyname>Zhang</keyname><forenames>Yongfei</forenames></author><author><keyname>Zhang</keyname><forenames>Yun</forenames></author><author><keyname>Kuo</keyname><forenames>C. -C. Jay</forenames></author></authors><title>On Energy Compaction of 2D Saab Image Transforms</title><categories>eess.IV cs.MM</categories><comments>10 pages, 9 figures, to appear in Asia-Pacific Signal and Information
  Processing Association (APSIPA), which will be held on November 18-21, 2019,
  in Lanzhou, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The block Discrete Cosine Transform (DCT) is commonly used in image and video
compression due to its good energy compaction property. The Saab transform was
recently proposed as an effective signal transform for image understanding. In
this work, we study the energy compaction property of the Saab transform in the
context of intra-coding of the High Efficiency Video Coding (HEVC) standard. We
compare the energy compaction property of the Saab transform, the DCT, and the
Karhunen-Loeve transform (KLT) by applying them to different sizes of
intra-predicted residual blocks in HEVC. The basis functions of the Saab
transform are visualized. Extensive experimental results are given to
demonstrate the energy compaction capability of the Saab transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10982</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10982</id><created>2019-08-28</created><authors><author><keyname>Medra</keyname><forenames>Mostafa</forenames></author><author><keyname>Eckford</keyname><forenames>Andrew W.</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj</forenames></author></authors><title>The Effect of Channel Uncertainty on Max-Min Goodput</title><categories>eess.SP</categories><comments>Accepted in Asilomar 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the effect of channel uncertainty on the rates
reliably delivered to the users; i.e., the goodput. After the base station (BS)
designs a set of beamformers for a specific objective, the BS must select the
operating or transmission data rate for each user. However, under channel
uncertainty, higher transmission rates cause higher outage probability, and the
delivered rate drops. Since lower rates are not desirable, one must balance
between the transmission rate and outage. In this paper, we first explain how
approximating the PDF of a quadratic form with a positive definite matrix can
be used to obtain the outage probability for any set of beamfomers and
transmission rate. Then we focus on the specific case of maximizing the minimum
delivered rate, where we modify a robust beamforming approach to maximize the
resulting goodput. We then derive iterative closed-form expressions for this
case. The simulation results illustrate the efficacy of our analysis and the
significant gains that can be obtained by optimizing the goodput metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10983</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10983</id><created>2019-08-28</created><authors><author><keyname>Jiang</keyname><forenames>Yan</forenames></author><author><keyname>Pates</keyname><forenames>Richard</forenames></author><author><keyname>Mallada</keyname><forenames>Enrique</forenames></author></authors><title>Dynamic Droop Control in Low-inertia Power Systems</title><categories>eess.SY cs.SY math.OC</categories><comments>16 pages, journal submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A widely embraced approach to mitigate the dynamic degradation in low-inertia
power systems is to mimic generation response using grid-connected inverters to
restore the grid's stiffness. In this paper, we seek to challenge this approach
and advocate for a principled design based on a systematic analysis of the
performance trade-offs of inverter-based frequency control. With this aim, we
perform a qualitative and quantitative study comparing the effect of
conventional control strategies --droop control (DC) and virtual inertia (VI)--
on several performance metrics induced by $\mathcal L_2$ and $\mathcal
L_\infty$ signal norms. By extending a recently proposed modal decomposition
method, we capture the effect of step and stochastic power disturbances, and
frequency measurement noise, on the overall transient and steady-state behavior
of the system. Our analysis unveils several limitations of these solutions,
such as the inability of DC to improve dynamic frequency response without
increasing steady-state control effort, or the large frequency variance that VI
introduces in the presence of measurement noise. We further propose a novel
dynam-i-c Droop controller (iDroop) that overcomes the limitations of DC and
VI. More precisely, we show that iDroop can be tuned to achieve high noise
rejection, fast system-wide synchronization, or frequency overshoot (Nadir)
elimination without affecting the steady-state control effort share, and
propose a tuning recommendation that strikes a balance among these objectives.
Extensive numerical experimentation shows that the proposed tuning is effective
even when our proportionality assumptions are not valid, and that the
particular tuning used for Nadir elimination strikes a good trade-off among
various performance metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10992</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10992</id><created>2019-08-28</created><authors><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Pang</keyname><forenames>Ruoming</forenames></author><author><keyname>Rybach</keyname><forenames>David</forenames></author><author><keyname>He</keyname><forenames>Yanzhang</forenames></author><author><keyname>Prabhavalkar</keyname><forenames>Rohit</forenames></author><author><keyname>Li</keyname><forenames>Wei</forenames></author><author><keyname>Visontai</keyname><forenames>Mirk&#xf3;</forenames></author><author><keyname>Liang</keyname><forenames>Qiao</forenames></author><author><keyname>Strohman</keyname><forenames>Trevor</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>McGraw</keyname><forenames>Ian</forenames></author><author><keyname>Chiu</keyname><forenames>Chung-Cheng</forenames></author></authors><title>Two-Pass End-to-End Speech Recognition</title><categories>cs.CL cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The requirements for many applications of state-of-the-art speech recognition
systems include not only low word error rate (WER) but also low latency.
Specifically, for many use-cases, the system must be able to decode utterances
in a streaming fashion and faster than real-time. Recently, a streaming
recurrent neural network transducer (RNN-T) end-to-end (E2E) model has shown to
be a good candidate for on-device speech recognition, with improved WER and
latency metrics compared to conventional on-device models [1]. However, this
model still lags behind a large state-of-the-art conventional model in quality
[2]. On the other hand, a non-streaming E2E Listen, Attend and Spell (LAS)
model has shown comparable quality to large conventional models [3]. This work
aims to bring the quality of an E2E streaming model closer to that of a
conventional system by incorporating a LAS network as a second-pass component,
while still abiding by latency constraints. Our proposed two-pass model
achieves a 17%-22% relative reduction in WER compared to RNN-T alone and
increases latency by a small fraction over RNN-T.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10995</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.10995</id><created>2019-08-28</created><authors><author><keyname>Kim</keyname><forenames>Jong-Min</forenames></author><author><keyname>Jeong</keyname><forenames>You-Jin</forenames></author><author><keyname>Chung</keyname><forenames>Han-Jae</forenames></author><author><keyname>Lee</keyname><forenames>Chulhyun</forenames></author><author><keyname>Oh</keyname><forenames>Chang-Hyun</forenames></author></authors><title>Real-time interactive magnetic resonance (MR) temperature imaging in
  both aqueous and adipose tissues using cascaded deep neural networks for
  MR-guided focused ultrasound surgery (MRgFUS)</title><categories>eess.IV cs.CV</categories><comments>40 pages, 11 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To acquire the real-time interactive temperature map for aqueous and
adipose tissue, the problems of long acquisition and processing time must be
addressed. To overcome these major challenges, this paper proposes a cascaded
convolutional neural network (CNN) framework and multi-echo gradient echo
(meGRE) with a single reference variable flip angle (srVFA).
  Methods: To optimize the echo times for each method, MR images are acquired
using a meGRE sequence; meGRE images with two flip angles (FAs) and meGRE
images with a single FA are acquired during the pretreatment and treatment
stages, respectively. These images are then processed and reconstructed by a
cascaded CNN, which consists of two CNNs. The first CNN (called DeepACCnet)
performs HR complex MR image reconstruction from the LR MR image acquired
during the treatment stage, which is improved by the HR magnitude MR image
acquired during the pretreatment stage. The second CNN (called DeepPROCnet)
copes with T1 mapping.
  Results: Measurements of temperature and T1 changes obtained by meGRE
combined with srVFA and cascaded CNNs were achieved in an agarose gel phantom,
ex vivo porcine muscle, and ex vivo porcine muscle with fat layers (heating
tests), and in vivo human prostate and brain (non-heating tests). In the
heating test, the maximum differences between fiber-optic sensor and samples
are less than 1 degree Celcius. In all cases, temperature mapping using the
cascaded CNN achieved the best results in all cases. The acquisition and
processing times for the proposed method are 0.8 s and 32 ms, respectively.
  Conclusions: Real-time interactive HR MR temperature mapping for
simultaneously measuring aqueous and adipose tissue is feasible by combining a
cascaded CNN with meGRE and srVFA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11001</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11001</id><created>2019-08-28</created><authors><author><keyname>Tian</keyname><forenames>Hongzhen</forenames></author><author><keyname>Wang</keyname><forenames>Andi</forenames></author><author><keyname>Chen</keyname><forenames>Jialei</forenames></author><author><keyname>Jiang</keyname><forenames>Xuzhou</forenames></author><author><keyname>Shi</keyname><forenames>Jianjun</forenames></author><author><keyname>Zhang</keyname><forenames>Chuck</forenames></author><author><keyname>Mei</keyname><forenames>Yajun</forenames></author><author><keyname>Wang</keyname><forenames>Ben</forenames></author></authors><title>Learning the Treatment Effects on FTIR Signals Subject to Multiple
  Sources of Uncertainties</title><categories>eess.SP</categories><comments>\{copyright} 2019 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fourier-transform infrared spectroscopy (FTIR) is a versatile technique for
characterizing the chemical composition of the various uncertainties, including
baseline shift and multiplicative error. This study aims at analyzing the
effect of certain treatment on the FTIR responses subject to these
uncertainties. A two-step method is proposed to quantify the treatment effect
on the FTIR signals. First, an optimization problem is solved to calculate the
template signal by aligning the pre-treatment FTIR signals. Second, the effect
of treatment is decomposed as the pattern of modification $\mathbf{g}$ that
describes the overall treatment effect on the spectra and a vector of effect
$\boldsymbol{\delta}$ that describes the degree of modification. $\mathbf g$
and $\boldsymbol{\delta}$ are solved by another optimization problem. They have
explicit engineering interpretations and provide useful information on how the
treatment effect change the surface chemical components. The effectiveness of
the proposed method is first validated in a simulation. In a real case study,
it's used to investigate how the plasma exposure applied at various heights
affects the FTIR signal which indicates the change of the chemical composition
on the composite material. The vector of effects indicates the range of
effective plasma height, and the pattern of modification matches existing
engineering knowledge well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11013</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11013</id><created>2019-08-28</created><authors><author><keyname>Bai</keyname><forenames>Qinbo</forenames></author><author><keyname>Wang</keyname><forenames>Jintao</forenames></author><author><keyname>Zhang</keyname><forenames>Yue</forenames></author><author><keyname>Song</keyname><forenames>Jian</forenames></author></authors><title>Deep Learning based Channel Estimation Algorithm over Time Selective
  Fading Channels</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research about deep learning application for physical layer has been
received much attention in recent years. In this paper, we propose a Deep
Learning (DL) based channel estimator under time varying Rayleigh fading
channel. We build up, train and test the channel estimator using Neural Network
(NN). The proposed DL-based estimator can dynamically track the channel status
without any prior knowledge about the channel model and statistic
characteristics. The simulation results show the proposed NN estimator has
better Mean Square Error (MSE) performance compared with the traditional
algorithms and some other DL-based architectures. Furthermore, the proposed
DL-based estimator also shows its robustness with the different pilot
densities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11016</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11016</id><created>2019-08-28</created><updated>2019-11-27</updated><authors><author><keyname>Wang</keyname><forenames>Fangzhou</forenames></author><author><keyname>Li</keyname><forenames>Hongbin</forenames></author></authors><title>Joint Waveform and Receiver Design for Co-Channel Hybrid Active-Passive
  Sensing with Timing Uncertainty</title><categories>eess.SP</categories><doi>10.1109/TSP.2020.2964194</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a hybrid active-passive radar system that employs a wireless
source as a passive illuminator of opportunity (IO) and a co-channel active
radar transmitter operating in the same frequency band to seek spectral
efficiency. The hybrid system can take advantage of the strengths of passive
radar (e.g., energy efficiency, bi-/multi-static configuration, and spatial
diversity) as well as those of active radar (dedicated transmitter, flexible
transmit beam steering, waveform optimized for sensing, etc.). To mitigate the
mutual interference and location-induced timing uncertainty between the radar
and communication signals, we propose two designs for the joint optimization of
the radar waveform and receive filters. The first is a max-min (MM) criterion
that optimizes a worst-case performance metric over a timing uncertainty
interval, and the other a weighted-sum (WS) criterion that forms a weighted sum
of the performance metric at each delay within the delay uncertainty interval.
Both design criteria result in nonconvex constrained optimization problems that
are solved by sequential convex programming methods. When timing uncertainty
vanishes, the two designs become identical and admit a simpler solution.
Numerical results are presented to demonstrate the performance of the proposed
hybrid schemes in comparison with conventional active-only and passive-only
radar systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11038</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11038</id><created>2019-08-28</created><authors><author><keyname>Hu</keyname><forenames>Ye</forenames></author><author><keyname>Chen</keyname><forenames>Mingzhe</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author></authors><title>Joint Access and Backhaul Resource Management in Satellite-Drone
  Networks: A Competitive Market Approach</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of user association and resource allocation is
studied for an integrated satellite-drone network (ISDN). In the considered
model, drone base stations (DBSs) provide downlink connectivity,
supplementally, to ground users whose demand cannot be satisfied by terrestrial
small cell base stations (SBSs). Meanwhile, a satellite system and a set of
terrestrial macrocell base stations (MBSs) are used to provide resources for
backhaul connectivity for both DBSs and SBSs. For this scenario, one must
jointly consider resource management over satellite-DBS/SBS backhaul links,
MBS-DBS/SBS terrestrial backhaul links, and DBS/SBS-user radio access links as
well as user association with DBSs and SBSs. This joint user association and
resource allocation problem is modeled using a competitive market setting in
which the transmission data is considered as a good that is being exchanged
between users, DBSs, and SBSs that act as &quot;buyers&quot;, and DBSs, SBSs, MBSs, and
the satellite that act as &quot;sellers&quot;. In this market, the quality-of-service
(QoS) is used to capture the quality of the data transmission (defined as
good), while the energy consumption the buyers use for data transmission is the
cost of exchanging a good. According to the quality of goods, sellers in the
market propose quotations to the buyers to sell their goods, while the buyers
purchase the goods based on the quotation. The buyers profit from the
difference between the earned QoS and the charged price, while the sellers
profit from the difference between earned price and the energy spent for data
transmission. The buyers and sellers in the market seek to reach a Walrasian
equilibrium, at which all the goods are sold, and each of the devices' profit
is maximized. A heavy ball based iterative algorithm is proposed to compute the
Walrasian equilibrium of the formulated market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11056</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11056</id><created>2019-08-29</created><authors><author><keyname>Zheng</keyname><forenames>Guanjie</forenames></author><author><keyname>Liu</keyname><forenames>Mengqi</forenames></author><author><keyname>Wen</keyname><forenames>Tao</forenames></author><author><keyname>Wang</keyname><forenames>Hongjian</forenames></author><author><keyname>Yao</keyname><forenames>Huaxiu</forenames></author><author><keyname>Brantley</keyname><forenames>Susan L.</forenames></author><author><keyname>Li</keyname><forenames>Zhenhui</forenames></author></authors><title>Targeted Source Detection for Environmental Data</title><categories>eess.SP cs.LG stat.AP stat.ML</categories><comments>8 pages, 4 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the face of growing needs for water and energy, a fundamental
understanding of the environmental impacts of human activities becomes critical
for managing water and energy resources, remedying water pollution, and making
regulatory policy wisely. Among activities that impact the environment, oil and
gas production, wastewater transport, and urbanization are included. In
addition to the occurrence of anthropogenic contamination, the presence of some
contaminants (e.g., methane, salt, and sulfate) of natural origin is not
uncommon. Therefore, scientists sometimes find it difficult to identify the
sources of contaminants in the coupled natural and human systems. In this
paper, we propose a technique to simultaneously conduct source detection and
prediction, which outperforms other approaches in the interdisciplinary case
study of the identification of potential groundwater contamination within a
region of high-density shale gas development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11064</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11064</id><created>2019-08-29</created><authors><author><keyname>Zhang</keyname><forenames>Yue</forenames></author><author><keyname>Wu</keyname><forenames>Jiong</forenames></author><author><keyname>Zhou</keyname><forenames>Yu</forenames></author><author><keyname>Chen</keyname><forenames>Yifan</forenames></author><author><keyname>Tang</keyname><forenames>Xiaoying</forenames></author></authors><title>Coarse-to-fine Kidney Segmentation Framework Incorporating with Abnormal
  Detection and Correction</title><categories>eess.IV</categories><comments>MDBS BHE 2019, Chengdu, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we formulated the kidney segmentation task in a coarse-to-fine
fashion, predicting a coarse label based on the entire CT image and a fine
label based on the coarse segmentation and separated image patches. A key
difference between the two stages lies in how input images were preprocessed;
for the coarse segmentation, each 2D CT slice was normalized to be of the same
image size (but possible different pixel size), and for the fine segmentation,
each 2D CT slice was first resampled to be of the same pixel size and then
cropped to be of the same image size. In other words, the image inputs to the
coarse segmentation were 2D CT slices of the same image size whereas those to
the fine segmentation were 2D MR patches of the same image size as well as the
same pixel size. In addition, we design an abnormal detection method based on
component analysis and use another 2D convolutional neural network to correct
these abnormal regions between two stages. A total of 168 CT images were used
to train the proposed framework and the evaluations were conducted
qualitatively on other 42 testing images. The proposed method showed promising
results and achieved 94.53 \% averaged DSC in testing data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11082</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11082</id><created>2019-08-29</created><authors><author><keyname>Wang</keyname><forenames>Jianfeng</forenames></author><author><keyname>Zhou</keyname><forenames>Zhiyong</forenames></author><author><keyname>Yu</keyname><forenames>Jun</forenames></author></authors><title>Enhanced block sparse signal recovery based on $q$-ratio block
  constrained minimal singular values</title><categories>eess.SP cs.IT math.IT</categories><comments>arXiv admin note: text overlap with arXiv:1801.06358</comments><doi>10.1186/s13634-019-0653-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce the $q$-ratio block constrained minimal singular
values (BCMSV) as a new measure of measurement matrix in compressive sensing of
block sparse/compressive signals and present an algorithm for computing this
new measure. Both the mixed $\ell_2/\ell_q$ and the mixed $\ell_2/\ell_1$ norms
of the reconstruction errors for stable and robust recovery using block Basis
Pursuit (BBP), the block Dantzig selector (BDS) and the group lasso in terms of
the $q$-ratio BCMSV are investigated. We establish a sufficient condition based
on the $q$-ratio block sparsity for the exact recovery from the noise free BBP
and developed a convex-concave procedure to solve the corresponding non-convex
problem in the condition. Furthermore, we prove that for sub-Gaussian random
matrices, the $q$-ratio BCMSV is bounded away from zero with high probability
when the number of measurements is reasonably large. Numerical experiments are
implemented to illustrate the theoretical results. In addition, we demonstrate
that the $q$-ratio BCMSV based error bounds are tighter than the block
restricted isotropic constant based bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11092</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11092</id><created>2019-08-29</created><authors><author><keyname>Lao</keyname><forenames>Dong</forenames></author><author><keyname>Sundaramoorthi</keyname><forenames>Ganesh</forenames></author></authors><title>Minimum Delay Object Detection From Video</title><categories>cs.CV cs.LG eess.IV</categories><comments>ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of detecting objects, as they come into view, from
videos in an online fashion. We provide the first real-time solution that is
guaranteed to minimize the delay, i.e., the time between when the object comes
in view and the declared detection time, subject to acceptable levels of
detection accuracy. The method leverages modern CNN-based object detectors that
operate on a single frame, to aggregate detection results over frames to
provide reliable detection at a rate, specified by the user, in guaranteed
minimal delay. To do this, we formulate the problem as a Quickest Detection
problem, which provides the aforementioned guarantees. We derive our algorithms
from this theory. We show in experiments, that with an overhead of just 50 fps,
we can increase the number of correct detections and decrease the overall
computational cost compared to running a modern single-frame detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11121</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11121</id><created>2019-08-29</created><authors><author><keyname>D'Andrea</keyname><forenames>Carmen</forenames></author><author><keyname>Zappone</keyname><forenames>Alessio</forenames></author><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Uplink power control in cell-free massive MIMO via deep learning</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 3 figures, 4 Tables, Conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the use of a deep learning approach to perform
sum-rate-max and max-min power allocation in the uplink of a cell-free massive
MIMO network. In particular, we train a deep neural network in order to learn
the mapping between a set of input data and the optimal solution of the power
allocation strategy. Numerical results show that the presence of the pilot
contamination in the cell-free massive MIMO system does not significantly
affect the learning capabilities of the neural network, that gives near-optimal
performance. Conversely, with the introduction of the shadowing effect in the
system the performance obtained with the deep learning approach gets
significantly degraded with respect to the optimal one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11166</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11166</id><created>2019-08-29</created><authors><author><keyname>Kim</keyname><forenames>Jieon</forenames></author><author><keyname>Blasi</keyname><forenames>Saverio</forenames></author><author><keyname>Dias</keyname><forenames>Andre Seixas</forenames></author><author><keyname>Mrak</keyname><forenames>Marta</forenames></author><author><keyname>Izquierdo</keyname><forenames>Ebroul</forenames></author></authors><title>Fast Inter-Prediction based on Decision Trees for AV1 encoding</title><categories>eess.IV</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The AOMedia Video 1 (AV1) standard can achieve considerable compression
efficiency thanks to the usage of many advanced tools and improvements, such as
advanced inter-prediction modes. However, these come at the cost of high
computational complexity of encoder, which may limit the benefits of the
standard in practical applications. This paper shows that not all sequences
benefit from using all such modes, which indicates that a number of encoder
optimisations can be introduced to speed up AV1 encoding. A method based on
decision trees is proposed to selectively decide whether to test all inter
modes. Appropriate features are extracted and used to perform the decision for
each block. Experimental results show that the proposed method can reduce the
encoding time on average by 43.4\% with limited impact on the coding
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11193</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11193</id><created>2019-08-26</created><authors><author><keyname>Miranda-Villatoro</keyname><forenames>Felix A.</forenames></author><author><keyname>Forni</keyname><forenames>Fulvio</forenames></author><author><keyname>Sepulchre</keyname><forenames>Rodolphe</forenames></author></authors><title>Dissipativity analysis of negative resistance circuits</title><categories>eess.SY cs.SY math.DS math.OC</categories><msc-class>34C15, 34C25, 34C26, 34C55, 34C41, 34D45, 93C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the analysis of nonlinear circuits that interconnect
passive elements (capacitors, inductors, and resistors) with nonlinear
resistors exhibiting a range of $\it{negative}$ resistance. Such active
elements are necessary to design circuits that switch and oscillate. We
generalize the classical passivity theory of circuit analysis to account for
such non-equilibrium behaviors. The approach closely mimics the classical
methodology of (incremental) dissipativity theory, but with dissipation
inequalities that combine $\it{signed}$ storage functions and $\it{signed}$
supply rates to account for the mixture of passive and active elements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11197</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11197</id><created>2019-08-18</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Li</keyname><forenames>Kang</forenames></author></authors><title>Incorporating demand response of electric vehicles in scheduling of
  isolated microgrids with renewables using a bi-level programming approach</title><categories>eess.SP cs.SY eess.SY math.OC</categories><comments>Accepted by IEEE Access</comments><journal-ref>IEEE Access 7 (2019) 116256-116266</journal-ref><doi>10.1109/ACCESS.2019.2936487</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a novel optimal scheduling approach is proposed for isolated
microgrids (MGs) with renewable generations by incorporating demand response of
electric vehicles (EVs). First, a bi-level programming-based MG scheduling
model is proposed under real-time pricing environments, where the upper- and
lower- levels seek to minimize the MG net operating cost and the EV charging
cost. Second, a hybrid solution algorithm called JAYA-interior point method is
put forward to solve the model. And finally, the simulation results demonstrate
that incorporating demand response of electric vehicles is able to guide EV
users to actively participate in MG scheduling and achieve the peak load
shaving, which offers a fundamental way to balance the interests between MG and
EV users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11199</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11199</id><created>2019-08-23</created><updated>2019-12-07</updated><authors><author><keyname>Pianpanit</keyname><forenames>Theerasarn</forenames></author><author><keyname>Lolak</keyname><forenames>Sermkiat</forenames></author><author><keyname>Sawangjai</keyname><forenames>Phattarapong</forenames></author><author><keyname>Ditthapron</keyname><forenames>Apiwat</forenames></author><author><keyname>Marukatat</keyname><forenames>Sanparith</forenames></author><author><keyname>Chuangsuwanich</keyname><forenames>Ekapol</forenames></author><author><keyname>Wilaiprasitporn</keyname><forenames>Theerawit</forenames></author></authors><title>Interpreting deep learning prediction of the Parkinson's disease
  diagnosis from SPECT imaging</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parkinson's disease (PD) diagnosis mainly relies on the visual and
semi-quantitative analysis of medical imaging using single-photon emission
computed tomography (SPECT) with 123I-Ioflupane (DaTSCAN). Deep learning
approach has the benefits over other machine learning methods because the model
does not rely on feature extraction. However, the complexity of the deep
learning model usually results in difficulty of interpretation of the model
when uses in clinical. Several interpretation methods were created for this
approach to show the attention map which reveals important features of the
input data, giving the model interpretability. However, it is still unclear
whether these methods can be applied to explain PD diagnosis or not. In this
paper, four different models of the deep learning approach based on the
3-dimensional convolution neural network (3D-CNN) of well-established
architectures have been trained. All the models give high classification
performance of PD diagnosis with accuracy up to 95-96\%. These four models have
been used to evaluate the interpretation performance of six well-known
interpretation methods. In general, radiologists interpret SPECT images for a
healthy subject by confirming a homogeneous symmetrical comma type shape of the
I123-Ioflupane uptake in the striatal nuclei. Any other shape is interpreted as
abnormal. To evaluate the interpretation performance, the segmented striatal
nuclei of the SPECT images are chosen to be the ground truth. {\Blue Guided
backpropagation which is one of the interpretation methods shows the best
performance among all other methods. Guided backpropagation has the best
performance to generate the attention map that focuses on the location of
striatal nuclei. By using the result from guided backpropagation, 3D CNN
architecture that has the highest classification and interpretation performance
can be chosen for SPECT diagnosis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11203</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11203</id><created>2019-08-29</created><updated>2019-11-13</updated><authors><author><keyname>Rafael-Patino</keyname><forenames>Jonathan</forenames></author><author><keyname>Romascano</keyname><forenames>David</forenames></author><author><keyname>Ramirez-Manzanares</keyname><forenames>Alonso</forenames></author><author><keyname>Canales-Rodr&#xed;guez</keyname><forenames>Erick Jorge</forenames></author><author><keyname>Girard</keyname><forenames>Gabriel</forenames></author><author><keyname>Thiran</keyname><forenames>Jean-Philippe</forenames></author></authors><title>Robust Monte-Carlo Simulations in Diffusion-MRI: Effect of the substrate
  complexity and parameter choice on the reproducibility of results</title><categories>physics.med-ph eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monte-Carlo Diffusion Simulations (MCDS) have been used extensively as a
ground truth tool for the validation of microstructure models for
Diffusion-Weighted MRI. However, methodological pitfalls in the design of the
biomimicking geometrical configurations and the simulation parameters can lead
to approximation biases. Such pitfalls affect the reliability of the estimated
signal, as well as its validity and reproducibility as ground truth data. In
this work, we first present a set of experiments in order to study three
critical pitfalls encountered in the design of MCDS in the literature, namely,
the number of simulated particles and time steps, simplifications in the
intra-axonal substrate representation, and the impact of the substrate's size
on the signal stemming from the extra-axonal space. The results obtained show
important changes in the simulated signals and the recovered microstructure
features when changes in those parameters are introduced. Thereupon, driven by
our findings from the first studies, we outline a general framework able to
generate complex substrates. We show the framework's capability to overcome the
aforementioned simplifications by generating a complex crossing substrate,
which preserves the volume in the crossing area and achieves a high packing
density. The results presented in this work,along with the simulator developed,
pave the way towards more realistic and reproducible Monte-Carlo simulations
for Diffusion-Weighted MRI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11205</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11205</id><created>2019-08-27</created><authors><author><keyname>Bononi</keyname><forenames>Alberto</forenames></author><author><keyname>Antona</keyname><forenames>Jean-Christophe</forenames></author><author><keyname>Lonardi</keyname><forenames>Matteo</forenames></author><author><keyname>Carbo-M&#xe9;seguer</keyname><forenames>Alexis</forenames></author><author><keyname>Serena</keyname><forenames>Paolo</forenames></author></authors><title>The Generalized Droop Formula</title><categories>eess.SP</categories><comments>Submitted to the Journal of Lightwave Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a theoretical model that fully supports the recently disclosed
generalized droop formula (GDF) for calculating the signal-to-noise ratio (SNR)
of constant-output power (COP) amplified dispersion-uncompensated coherent
links operated at very low SNR. We compare the GDF to the better known Gaussian
noise (GN) model. A key finding is that the end-to-end model underlying the GDF
is a concatenation of per-span first-order regular perturbation (RP1) models
with end-span power renormalization. This fact allows the GDF to well reproduce
the SNR of highly nonlinear systems, well beyond the RP1 limit underlying the
GN model. The GDF is successfully extended to the case where the
bandwidth/modes of the COP amplifiers are not entirely filled by the
transmitted multiplex. Finally, the GDF is extended to constant-gain (CG)
amplifier chains and is shown to improve on known GN models of highly nonlinear
propagation with CG amplifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11207</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11207</id><created>2019-08-27</created><authors><author><keyname>Ford</keyname><forenames>William P.</forenames></author><author><keyname>Hague</keyname><forenames>Emma</forenames></author><author><keyname>McCullough</keyname><forenames>Tom</forenames></author><author><keyname>Moore</keyname><forenames>Eric</forenames></author><author><keyname>Turk</keyname><forenames>Johanna</forenames></author></authors><title>Threat determination for radiation detection from the Remote Sensing
  Laboratory</title><categories>eess.SP physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to search for radiation sources is of interest to the Homeland
Security community. The hope is to find any radiation sources which may pose a
reasonable chance for harm in a terrorist act. The best chance of success for
search operations generally comes with fielding as many detection systems as
possible. In doing this, the hoped for encounter with the threat source will
inevitably be buried in an even larger number of encounters with
non-threatening radiation sources commonly used for many medical and industrial
use. The problem then becomes effectively filtering the non-threatening
sources, and presenting the human-in-the-loop with a modest list of potential
threats. Our approach is to field a collection of detection systems which
utilize soft-sensing algorithms for the purpose of discriminating potential
threat and non-threat objects, based on a variety of machine learning
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11217</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11217</id><created>2019-08-29</created><authors><author><keyname>Zelenina</keyname><forenames>Marie</forenames></author><author><keyname>Prata</keyname><forenames>Diana</forenames></author></authors><title>Machine learning with electroencephalography features for precise
  diagnosis of depression subtypes</title><categories>eess.IV eess.SP</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/HkgAOd-TYN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Depression is a common psychiatric disorder, which causes significant patient
distress. Bipolar disorder is characterized by mood fluctuations between
depression and mania. Unipolar and bipolar depression can be easily confused
because of similar symptom profiles, but their adequate treatment plans are
different. Therefore, a precise data-driven diagnosis is essential for
successful treatment. In order to aid diagnosis, research applied machine
learning to brain imaging data, in particular to electroencephalography (EEG),
with accuracies reaching 99.5% (unipolar vs. healthy) or 85% (bipolar vs.
healthy). However, these results arise from small training sets, without
validation on independent data, and thus have a high risk of inflated
accuracies due to data over-fitting. We propose to use a bigger corpus of
realistic clinical data for training and testing and improve classification
with microstates features, which can assess the function of large-scale brain
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11218</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11218</id><created>2019-08-29</created><authors><author><keyname>Anderson</keyname><forenames>Adam</forenames></author><author><keyname>Young</keyname><forenames>Steven R.</forenames></author><author><keyname>Reed</keyname><forenames>F. Kyle</forenames></author><author><keyname>Vann</keyname><forenames>Jason M.</forenames></author></authors><title>Deep Modulation (Deepmod): A Self-Taught PHY Layer for Resilient Digital
  Communications</title><categories>eess.SP</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional physical (PHY) layer protocols contain chains of signal
processing blocks that have been mathematically optimized to transmit
information bits efficiently over noisy channels. Unfortunately, this same
optimality encourages ubiquity in wireless communication technology and
enhances the potential for catastrophic cyber or physical attacks due to
prolific knowledge of underlying physical layers. Additionally, optimal signal
processing for one channel medium may not work for another without significant
changes in the software protocol. Any truly resilient communications protocol
must be capable of immediate redeployment to meet quality of service (QoS)
demands in a wide variety of possible channel media. Contrary to many
traditional approaches which use immutable man-made signal processing blocks,
this work proposes generating real-time blocks {\it ad hoc} through a machine
learning framework, so-called deepmod, that is only relevant to the particular
channel medium being used. With this approach, traditional signal processing
blocks are replaced with machine learning graphs which are trained, used, and
discarded as needed. Our experiments show that deepmod, using the same machine
intelligence, converges to viable communication links over vastly different
channels including: radio frequency (RF), powerline communications (PLC), and
acoustic channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11219</identifier>
 <datestamp>2020-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11219</id><created>2019-08-28</created><updated>2020-02-27</updated><authors><author><keyname>Sharma</keyname><forenames>Jivitesh</forenames></author><author><keyname>Granmo</keyname><forenames>Ole-Christoffer</forenames></author><author><keyname>Goodwin</keyname><forenames>Morten</forenames></author></authors><title>Environment Sound Classification using Multiple Feature Channels and
  Attention based Deep Convolutional Neural Network</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>Attention mechanism has been added to the model to further improve
  performance and decrease the number of parameters. A data leakage was
  detected in the code, which has been fixed and the results have been updated</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we propose a model for the Environment Sound Classification
Task (ESC) that consists of multiple feature channels given as input to a Deep
Convolutional Neural Network (CNN) with Attention mechanism. The novelty of the
paper lies in using multiple feature channels consisting of Mel-Frequency
Cepstral Coefficients (MFCC), Gammatone Frequency Cepstral Coefficients (GFCC),
the Constant Q-transform (CQT) and Chromagram. Such multiple features have
never been used before for signal or audio processing. And, we employ a deeper
CNN (DCNN) compared to previous models, consisting of spatially separable
convolutions working on time and feature domain separately. Alongside, we use
attention modules that perform channel and spatial attention together. We use
some data augmentation techniques to further boost performance. Our model is
able to achieve state-of-the-art performance on all three benchmark environment
sound classification datasets, i.e. the UrbanSound8K (97.52%), ESC-10 (95.75%)
and ESC-50 (88.50%). To the best of our knowledge, this is the first time that
a single environment sound classification model is able to achieve
state-of-the-art results on all three datasets. For ESC-10 and ESC-50 datasets,
the accuracy achieved by the proposed model is beyond human accuracy of 95.7%
and 81.3% respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11221</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11221</id><created>2019-08-28</created><authors><author><keyname>Zhou</keyname><forenames>Siwang</forenames></author><author><keyname>He</keyname><forenames>Yan</forenames></author><author><keyname>Liu</keyname><forenames>Yonghe</forenames></author><author><keyname>Li</keyname><forenames>Chengqing</forenames></author></authors><title>Multi-Channel Deep Networks for Block-Based Image Compressive Sensing</title><categories>eess.IV cs.IT cs.LG math.IT stat.ML</categories><comments>12 pages, 8 figures</comments><msc-class>68Q30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Incorporating deep neural networks in image compressive sensing (CS) receives
intensive attentions recently. As deep network approaches learn the inverse
mapping directly from the CS measurements, a number of models have to be
trained, each of which corresponds to a sampling rate. This may potentially
degrade the performance of image CS, especially when multiple sampling rates
are assigned to different blocks within an image. In this paper, we develop a
multi-channel deep network for block-based image CS with performance
significantly exceeding the current state-of-the-art methods. The significant
performance improvement of the model is attributed to block-based sampling
rates allocation and model-level removal of blocking artifacts. Specifically,
the image blocks with a variety of sampling rates can be reconstructed in a
single model by exploiting inter-block correlation. At the same time, the
initially reconstructed blocks are reassembled into a full image to remove
blocking artifacts within the network by unrolling a hand-designed block-based
CS algorithm. Experimental results demonstrate that the proposed method
outperforms the state-of-the-art CS methods by a large margin in terms of
objective metrics, PSNR, SSIM, and subjective visual quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11262</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11262</id><created>2019-08-29</created><authors><author><keyname>Temel</keyname><forenames>Dogancan</forenames></author><author><keyname>Chen</keyname><forenames>Min-Hung</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Traffic Sign Detection under Challenging Conditions: A Deeper Look Into
  Performance Variations and Spectral Characteristics</title><categories>cs.CV cs.LG eess.IV eess.SP</categories><comments>13 pages, 9 figures, 4 tables. IEEE Transactions on Intelligent
  Transportation Systems, 2019</comments><acm-class>I.2; I.4; I.5</acm-class><doi>10.1109/TITS.2019.2931429</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traffic signs are critical for maintaining the safety and efficiency of our
roads. Therefore, we need to carefully assess the capabilities and limitations
of automated traffic sign detection systems. Existing traffic sign datasets are
limited in terms of type and severity of challenging conditions. Metadata
corresponding to these conditions are unavailable and it is not possible to
investigate the effect of a single factor because of simultaneous changes in
numerous conditions. To overcome the shortcomings in existing datasets, we
introduced the CURE-TSD-Real dataset, which is based on simulated challenging
conditions that correspond to adversaries that can occur in real-world
environments and systems. We test the performance of two benchmark algorithms
and show that severe conditions can result in an average performance
degradation of 29% in precision and 68% in recall. We investigate the effect of
challenging conditions through spectral analysis and show that challenging
conditions can lead to distinct magnitude spectrum characteristics. Moreover,
we show that mean magnitude spectrum of changes in video sequences under
challenging conditions can be an indicator of detection performance.
CURE-TSD-Real dataset is available online at
https://github.com/olivesgatech/CURE-TSD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11267</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11267</id><created>2019-08-19</created><authors><author><keyname>Douguet</keyname><forenames>Dominique</forenames><affiliation>IPMC, UCA</affiliation></author><author><keyname>Payan</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>UCA</affiliation></author></authors><title>SENSAAS (SENsitive Surface As A Shape): utilizing open-source algorithms
  for 3D point cloud alignment of molecules</title><categories>q-bio.BM eess.SP</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Open-source 3D data processing libraries originally developed for computer
vision and pattern recognition are used to align and compare molecular shapes
and sub-shapes. Here, a shape is represented by a set of points distributed on
the van der Waals surface of molecules. Each point is colored by its closest
atom, which itself belongs to a user defined class. The strength of this
representation is that it allows for comparisons of point clouds of different
kind of chemical entities: small molecules, peptides, proteins or cavities (the
negative image of the
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11305</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11305</id><created>2019-08-29</created><authors><author><keyname>Santander</keyname><forenames>Roberto Hern&#xe1;ndez</forenames></author><author><keyname>Casallas</keyname><forenames>Esperanza Camargo</forenames></author></authors><title>Inspection of methods of empirical mode decomposition</title><categories>eess.SP stat.ME</categories><comments>11 pages, 6 figures. Introduced in the 5th International Conference
  on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Empirical Mode Decomposition is an adaptive and local tool that extracts
underlying analytical components of a non-linear and non-stationary process, in
turn, is the basis of Hilbert Huang transform, however, there are problems such
as interfering modes or ensuring the orthogonality of decomposition. Three
variants of the algorithm are evaluated, with different experimental parameters
and on a set of 10 time series obtained from surface electromyography.
Experimental results show that obtaining low error in reconstruction with the
analytical signals obtained from a process is not a valid characteristic to
ensure that the purpose of decomposition has been fulfilled (physical
significance and no interference between modes), in addition, freedom must be
generated in the iterative processes of decomposition so that it has
consistency and does not generate biased information. This project was
developed within the framework of the research group DIGITI of the Universidad
Distrital Francisco Jos\'e de Caldas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11307</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11307</id><created>2019-08-29</created><authors><author><keyname>Bando</keyname><forenames>Yoshiaki</forenames></author><author><keyname>Sasaki</keyname><forenames>Yoko</forenames></author><author><keyname>Yoshii</keyname><forenames>Kazuyoshi</forenames></author></authors><title>Deep Bayesian Unsupervised Source Separation Based on a Complex Gaussian
  Mixture Model</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>6 pages, 2 figures, accepted for publication in 2019 IEEE
  International Workshop on Machine Learning for Signal Processing (MLSP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an unsupervised method that trains neural source
separation by using only multichannel mixture signals. Conventional neural
separation methods require a lot of supervised data to achieve excellent
performance. Although multichannel methods based on spatial information can
work without such training data, they are often sensitive to parameter
initialization and degraded with the sources located close to each other. The
proposed method uses a cost function based on a spatial model called a complex
Gaussian mixture model (cGMM). This model has the time-frequency (TF) masks and
direction of arrivals (DoAs) of sources as latent variables and is used for
training separation and localization networks that respectively estimate these
variables. This joint training solves the frequency permutation ambiguity of
the spatial model in a unified deep Bayesian framework. In addition, the
pre-trained network can be used not only for conducting monaural separation but
also for efficiently initializing a multichannel separation algorithm.
Experimental results with simulated speech mixtures showed that our method
outperformed a conventional initialization method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11308</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11308</id><created>2019-08-29</created><authors><author><keyname>Yazicioglu</keyname><forenames>Yasin</forenames></author><author><keyname>Abbas</keyname><forenames>Waseem</forenames></author><author><keyname>Shabbir</keyname><forenames>Mudassir</forenames></author></authors><title>Structural Robustness to Noise in Consensus Networks: Impact of Degrees
  and Distances, Fundamental Limits, and Extremal Graphs</title><categories>eess.SY cs.SY math.CO math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate how the graph topology influences the robustness to noise in
undirected linear consensus networks. We measure the structural robustness by
using the smallest possible value of steady state population variance of states
under the noisy consensus dynamics with edge weights from the unit interval. We
derive tight upper and lower bounds on the structural robustness of networks
based on the average distance between nodes and the average node degree. Using
the proposed bounds, we characterize the networks with different types of
robustness scaling under increasing size. Furthermore, we show that there is a
fundamental trade-off between the structural robustness and the average degree
of networks. We then show that, random k-regular graphs (the degree of each
node is k) with n nodes typically have near optimal structural robustness among
all the graphs with size n and average degree k. We also show that when k
increases properly with n, random k-regular graphs maintain a structural
robustness within a constant factor of the best possible value (corresponds to
the complete graph) while also having the minimum average degree required for
such robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11309</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11309</id><created>2019-08-29</created><authors><author><keyname>Sibechi</keyname><forenames>Radu</forenames></author><author><keyname>Booij</keyname><forenames>Olaf</forenames></author><author><keyname>Baka</keyname><forenames>Nora</forenames></author><author><keyname>Bloem</keyname><forenames>Peter</forenames></author></authors><title>Exploiting Temporality for Semi-Supervised Video Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted as workshop paper at ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, there has been remarkable progress in supervised image
segmentation. Video segmentation is less explored, despite the temporal
dimension being highly informative. Semantic labels, e.g. that cannot be
accurately detected in the current frame, may be inferred by incorporating
information from previous frames. However, video segmentation is challenging
due to the amount of data that needs to be processed and, more importantly, the
cost involved in obtaining ground truth annotations for each frame. In this
paper, we tackle the issue of label scarcity by using consecutive frames of a
video, where only one frame is annotated. We propose a deep, end-to-end
trainable model which leverages temporal information in order to make use of
easy to acquire unlabeled data. Our network architecture relies on a novel
interconnection of two components: a fully convolutional network to model
spatial information and temporal units that are employed at intermediate levels
of the convolutional network in order to propagate information through time.
The main contribution of this work is the guidance of the temporal signal
through the network. We show that only placing a temporal module between the
encoder and decoder is suboptimal (baseline). Our extensive experiments on the
CityScapes dataset indicate that the resulting model can leverage unlabeled
temporal frames and significantly outperform both the frame-by-frame image
segmentation and the baseline approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11312</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11312</id><created>2019-08-29</created><authors><author><keyname>Hou</keyname><forenames>Benjamin</forenames></author><author><keyname>Vlontzos</keyname><forenames>Athanasios</forenames></author><author><keyname>Alansary</keyname><forenames>Amir</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author><author><keyname>Kainz</keyname><forenames>Bernhard</forenames></author></authors><title>Flexible Conditional Image Generation of Missing Data with Learned
  Mental Maps</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Real-world settings often do not allow acquisition of high-resolution
volumetric images for accurate morphological assessment and diagnostic. In
clinical practice it is frequently common to acquire only sparse data (e.g.
individual slices) for initial diagnostic decision making. Thereby, physicians
rely on their prior knowledge (or mental maps) of the human anatomy to
extrapolate the underlying 3D information. Accurate mental maps require years
of anatomy training, which in the first instance relies on normative learning,
i.e. excluding pathology. In this paper, we leverage Bayesian Deep Learning and
environment mapping to generate full volumetric anatomy representations from
none to a small, sparse set of slices. We evaluate proof of concept
implementations based on Generative Query Networks (GQN) and Conditional BRUNO
using abdominal CT and brain MRI as well as in a clinical application involving
sparse, motion-corrupted MR acquisition for fetal imaging. Our approach allows
to reconstruct 3D volumes from 1 to 4 tomographic slices, with a SSIM of 0.7+
and cross-correlation of 0.8+ compared to the 3D ground truth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11313</identifier>
 <datestamp>2019-11-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11313</id><created>2019-08-29</created><updated>2019-10-11</updated><authors><author><keyname>Ismayilov</keyname><forenames>Rafail</forenames></author><author><keyname>Holfeld</keyname><forenames>Bernd</forenames></author><author><keyname>Cavalcante</keyname><forenames>Renato L. G.</forenames></author><author><keyname>Kaneko</keyname><forenames>Megumi</forenames></author></authors><title>Power and Beam Optimization for Uplink Millimeter-Wave Hotspot
  Communication Systems</title><categories>cs.NI cs.IT eess.SP math.IT math.OC</categories><doi>10.1109/WCNC.2019.8885561</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an effective interference management and beamforming mechanism for
uplink communication systems that yields fair allocation of rates. In
particular, we consider a hotspot area of a millimeter-wave (mmWave) access
network consisting of multiple user equipment (UE) in the uplink and multiple
access points (APs) with directional antennas and adjustable beam widths and
directions (beam configurations). This network suffers tremendously from
multi-beam multi-user interference, and, to improve the uplink transmission
performance, we propose a centralized scheme that optimizes the power, the beam
width, the beam direction of the APs, and the UE - AP assignments. This problem
involves both continuous and discrete variables, and it has the following
structure. If we fix all discrete variables, except for those related to the
UE-AP assignment, the resulting optimization problem can be solved optimally.
This property enables us to propose a heuristic based on simulated annealing
(SA) to address the intractable joint optimization problem with all discrete
variables. In more detail, for a fixed configuration of beams, we formulate a
weighted rate allocation problem where each user gets the same portion of its
maximum achievable rate that it would have under non-interfered conditions. We
solve this problem with an iterative fixed point algorithm that optimizes the
power of UEs and the UE - AP assignment in the uplink. This fixed point
algorithm is combined with SA to improve the beam configurations. Theoretical
and numerical results show that the proposed method improves both the UE rates
in the lower percentiles and the overall fairness in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11318</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11318</id><created>2019-08-29</created><authors><author><keyname>Franceschelli</keyname><forenames>Mauro</forenames></author><author><keyname>Pilloni</keyname><forenames>Alessandro</forenames></author><author><keyname>Gasparri</keyname><forenames>Andrea</forenames></author></authors><title>Multi-Agent Coordination of Thermostatically Controlled Loads by Smart
  Power Sockets for Electric Demand Side Management</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a multi-agent control architecture and an online
optimization method based on dynamic average consensus to coordinate the power
consumption of a large population of Thermostatically Controlled Loads (TCLs).
Our objective is to penalize peaks of power demand, smooth the load profile and
enable Demand Side Management (DSM). The proposed architecture and methods
exploit only local measurements of power consumption via Smart Power Sockets
(SPSs) with no access to their internal temperature. No centralized aggregator
of information is exploited and agents preserve their privacy by cooperating
anonymously only through consensus-based distributed estimation, robust to
node/link failure. The interactions among devices are designed to occur through
an unstructured peer-to-peer (P2P) network over the internet. The architecture
includes novel methods for parameter identification, state estimation and mixed
logical modelling of TCLs and SPSs. It is designed from a multi-agent and
plug-and-play perspective in which existing household appliances can interact
with each other in an urban environment. Finally, a novel low cost testbed is
proposed along with numerical tests and an experimental validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11329</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11329</id><created>2019-08-29</created><authors><author><keyname>Alaeddini</keyname><forenames>Atiye</forenames></author><author><keyname>Morgansen</keyname><forenames>Kristi A.</forenames></author><author><keyname>Mesbahi</keyname><forenames>Mehran</forenames></author></authors><title>Augmented State Feedback for Improving Observability of Linear Systems
  with Nonlinear Measurements</title><categories>eess.SY cs.SY</categories><comments>Accepted in System and Control Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the design of an augmented state feedback
controller for finite-dimensional linear systems with nonlinear observation
dynamics. Most of the theoretical results in the area of (optimal) feedback
design are based on the assumption that the state is available for measurement.
In this paper, we focus on finding a feedback control that avoids state
trajectories with undesirable observability properties. In particular, we
introduce an optimal control problem that specifically considers an index of
observability in the control synthesis. The resulting cost functional is a
combination of LQR-like quadratic terms and an index of observability. The main
contribution of the paper is presenting a control synthesis procedure that on
one hand, provides closed loop asymptotic stability, and addresses the
observability of the system--as a transient performance criteria--on the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11331</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11331</id><created>2019-08-29</created><authors><author><keyname>Zhong</keyname><forenames>Xin</forenames></author><author><keyname>Shih</keyname><forenames>Frank Y.</forenames></author></authors><title>A Robust Image Watermarking System Based on Deep Neural Networks</title><categories>cs.MM cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital image watermarking is the process of embedding and extracting
watermark covertly on a carrier image. Incorporating deep learning networks
with image watermarking has attracted increasing attention during recent years.
However, existing deep learning-based watermarking systems cannot achieve
robustness, blindness, and automated embedding and extraction simultaneously.
In this paper, a fully automated image watermarking system based on deep neural
networks is proposed to generalize the image watermarking processes. An
unsupervised deep learning structure and a novel loss computation are proposed
to achieve high capacity and high robustness without any prior knowledge of
possible attacks. Furthermore, a challenging application of watermark
extraction from camera-captured images is provided to validate the practicality
as well as the robustness of the proposed system. Experimental results show the
superiority performance of the proposed system as comparing against several
currently available techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11399</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11399</id><created>2019-08-29</created><authors><author><keyname>Kormilitzin</keyname><forenames>Andrey</forenames></author><author><keyname>Yang</keyname><forenames>Xinyu</forenames></author><author><keyname>Stone</keyname><forenames>William H.</forenames></author><author><keyname>Woffindale</keyname><forenames>Caroline</forenames></author><author><keyname>Nicholls</keyname><forenames>Francesca</forenames></author><author><keyname>Ribe</keyname><forenames>Elena</forenames></author><author><keyname>Nevado-Holgado</keyname><forenames>Alejo</forenames></author><author><keyname>Buckley</keyname><forenames>Noel</forenames></author></authors><title>Deep Learning for Estimating Synaptic Health of Primary Neuronal Cell
  Culture</title><categories>eess.IV cs.LG q-bio.QM stat.ML</categories><comments>11 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the morphological changes of primary neuronal cells induced by
chemical compounds is essential for drug discovery. Using the data from a
single high-throughput imaging assay, a classification model for predicting the
biological activity of candidate compounds was introduced. The image
recognition model which is based on deep convolutional neural network (CNN)
architecture with residual connections achieved accuracy of 99.6$\%$ on a
binary classification task of distinguishing untreated and treated rodent
primary neuronal cells with Amyloid-$\beta_{(25-35)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11416</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11416</id><created>2019-08-29</created><authors><author><keyname>Adler</keyname><forenames>Amir</forenames></author><author><keyname>Wax</keyname><forenames>Mati</forenames></author><author><keyname>Pantazis</keyname><forenames>Dimitrios</forenames></author></authors><title>Brain Signals Localization by Alternating Projections</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel solution to the problem of localization of brain signals.
The solution is sequential and iterative, and is based on minimizing the
least-squares (LS) criterion by the alternating projection (AP) algorithm, well
known in the context of array signal processing. Unlike existing solutions
belonging to the linearly constrained minimum variance (LCMV) and to the
multiple-signal classification (MUSIC) families, the algorithm is applicable
even in the case of a single sample and in the case of synchronous sources. The
performance of the solution is demonstrated via simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11435</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11435</id><created>2019-08-23</created><authors><author><keyname>Goodman</keyname><forenames>Dou</forenames></author><author><keyname>Li</keyname><forenames>Xingjian</forenames></author><author><keyname>Huan</keyname><forenames>Jun</forenames></author><author><keyname>Wei</keyname><forenames>Tao</forenames></author></authors><title>Improving Adversarial Robustness via Attention and Adversarial Logit
  Pairing</title><categories>cs.LG cs.CR eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Though deep neural networks have achieved the state of the art performance in
visual classification, recent studies have shown that they are all vulnerable
to the attack of adversarial examples. In this paper, we develop improved
techniques for defending against adversarial examples.First, we introduce
enhanced defense using a technique we call \textbf{Attention and Adversarial
Logit Pairing(AT+ALP)}, a method that encourages both attention map and logit
for pairs of examples to be similar. When applied to clean examples and their
adversarial counterparts, \textbf{AT+ALP} improves accuracy on adversarial
examples over adversarial training.Next,We show that our \textbf{AT+ALP} can
effectively increase the average activations of adversarial examples in the key
area and demonstrate that it focuse on more discriminate features to improve
the robustness of the model.Finally,we conducte extensive experiments using a
wide range of datasets and the experiment results show that our \textbf{AT+ALP}
achieves \textbf{the state of the art} defense.For example,on \textbf{17 Flower
Category Database}, under strong 200-iteration \textbf{PGD} gray-box and
black-box attacks where prior art has 34\% and 39\% accuracy, our method
achieves \textbf{50\%} and \textbf{51\%}.Compared with previous work,our work
is evaluated under highly challenging PGD attack:the maximum perturbation
$\epsilon \in \{0.25,0.5\}$ i.e. $L_\infty \in \{0.25,0.5\}$ with 10 to 200
attack iterations.To our knowledge, such a strong attack has not been
previously explored on a wide range of datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11463</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11463</id><created>2019-08-29</created><updated>2019-09-15</updated><authors><author><keyname>Sun</keyname><forenames>Haoqi</forenames></author><author><keyname>Ganglberger</keyname><forenames>Wolfgang</forenames></author><author><keyname>Panneerselvam</keyname><forenames>Ezhil</forenames></author><author><keyname>Leone</keyname><forenames>Michael J.</forenames></author><author><keyname>Quadri</keyname><forenames>Syed A.</forenames></author><author><keyname>Goparaju</keyname><forenames>Balaji</forenames></author><author><keyname>Tesh</keyname><forenames>Ryan A.</forenames></author><author><keyname>Akeju</keyname><forenames>Oluwaseun</forenames></author><author><keyname>Thomas</keyname><forenames>Robert J.</forenames></author><author><keyname>Westover</keyname><forenames>M. Brandon</forenames></author></authors><title>Sleep Staging from Electrocardiography and Respiration with Deep
  Learning</title><categories>q-bio.QM eess.SP q-bio.NC</categories><comments>Contains supplementary material at the end</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Study Objective: Sleep is reflected not only in the electroencephalogram but
also in heart rhythms and breathing patterns. Therefore, we hypothesize that it
is possible to accurately stage sleep based on the electrocardiogram (ECG) and
respiratory signals. Methods: Using a dataset including 8,682 polysomnographs,
we develop deep neural networks to stage sleep from ECG and respiratory
signals. Five deep neural networks consisting of convolutional networks and
long short-term memory networks are trained to stage sleep using heart and
breathing, including the timing of R peaks from ECG, abdominal and chest
respiratory effort, and the combinations of these signals. Results: ECG in
combination with the abdominal respiratory effort achieve the best performance
for staging all five sleep stages with a Cohen's kappa of 0.600 (95% confidence
interval 0.599 -- 0.602); and 0.762 (0.760 -- 0.763) for discriminating awake
vs. rapid eye movement vs. non-rapid eye movement sleep. The performance is
better for young participants and for those with a low apnea-hypopnea index,
while it is robust for commonly used outpatient medications. Conclusions: Our
results validate that ECG and respiratory effort provide substantial
information about sleep stages in a large population. It opens new
possibilities in sleep research and applications where electroencephalography
is not readily available or may be infeasible, such as in critically ill
patients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11470</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11470</id><created>2019-08-29</created><authors><author><keyname>Haqiqatnejad</keyname><forenames>Alireza</forenames></author><author><keyname>Shahbazpanahi</keyname><forenames>Shahram</forenames></author><author><keyname>Ottersten</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>A Worst-Case Performance Optimization Based Design Approach to Robust
  Symbol-Level Precoding for Downlink MU-MIMO</title><categories>eess.SP</categories><comments>10 pages, 2 figures, IEEE GlobalSIP 2019 (Accepted)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the optimization problem of symbol-level precoding (SLP)
in the downlink of a multiuser multiple-input multiple-output (MU-MIMO)
wireless system while the precoder's output is subject to partially-known
distortions. In particular, we assume a linear distortion model with bounded
additive noise. The original signal-to-interference-plus-noise ratio (SINR)
-constrained SLP problem minimizing the total transmit power is first
reformulated as a penalized unconstrained problem, which is referred to as the
relaxed robust formulation. We then adopt a worst-case design approach to
protect the users' intended symbols and the targeted constructive interference
with a desired level of confidence. Due to the non-convexity of the relaxed
robust formulation, we propose an iterative algorithm based on the block
coordinate ascent-descent method. We show through simulation results that the
proposed robust design is flexible in the sense that the CI constraints can be
relaxed so as to keep a desirable balance between achievable rate and power
consumption. Remarkably, the new formulation yields more energy-efficient
solutions for appropriate choices of the penalty parameter, compared to the
original problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11479</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11479</id><created>2019-08-29</created><authors><author><keyname>Tavafoghi</keyname><forenames>Hamidreza</forenames></author><author><keyname>Poolla</keyname><forenames>Kameshwar</forenames></author><author><keyname>Varaiya</keyname><forenames>Pravin</forenames></author></authors><title>A Queuing Approach to Parking: Modeling, Verification, and Prediction</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a queuing model of parking dynamics and a model-based prediction
method to provide real-time probabilistic forecasts of future parking
occupancy. The queuing model has a non-homogeneous arrival rate and
time-varying service time distribution. All statistical assumptions of the
model are verified using data from 29 truck parking locations, each with
between 55 and 299 parking spots. For each location and each spot the data
specifies the arrival and departure times of a truck, for 16 months of
operation. The modeling framework presented in this paper provides empirical
support for queuing models adopted in many theoretical studies and policy
designs. We discuss how our framework can be used to study parking problems in
different environments. Based on the queuing model, we propose two prediction
methods, a microscopic method and a macroscopic method, that provide a
real-time probabilistic forecast of parking occupancy for an arbitrary forecast
horizon. These model-based methods convert a probabilistic forecast problem
into a parameter estimation problem that can be tackled using classical
estimation methods such as regressions or pure machine learning algorithms. We
characterize a lower bound for an arbitrary real-time prediction algorithm. We
evaluate the performance of these methods using the truck data comparing the
outcomes of their implementations with other model-based and model-free methods
proposed in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11480</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11480</id><created>2019-08-29</created><authors><author><keyname>Hoang</keyname><forenames>Minh Tu</forenames></author><author><keyname>Zhu</keyname><forenames>Yizhou</forenames></author><author><keyname>Yuen</keyname><forenames>Brosnan</forenames></author><author><keyname>Reese</keyname><forenames>Tyler</forenames></author><author><keyname>Dong</keyname><forenames>Xiaodai</forenames></author><author><keyname>Lu</keyname><forenames>Tao</forenames></author><author><keyname>Westendorp</keyname><forenames>Robert</forenames></author><author><keyname>Xie</keyname><forenames>Michael</forenames></author></authors><title>A Soft Range Limited K-Nearest Neighbours Algorithm for Indoor
  Localization Enhancement</title><categories>eess.SP</categories><comments>Received signal strength indicator (RSSI), WiFi indoor localization,
  K-nearest neighbor (KNN), fingerprint-based localization</comments><journal-ref>IEEE Sensor Journal, vol. 18, pp.10208 - 10216, Dec. 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a soft range limited K nearest neighbours (SRL-KNN)
localization fingerprinting algorithm. The conventional KNN determines the
neighbours of a user by calculating and ranking the fingerprint distance
measured at the unknown user location and the reference locations in the
database. Different from that method, SRL-KNN scales the fingerprint distance
by a range factor related to the physical distance between the user's previous
position and the reference location in the database to reduce the spatial
ambiguity in localization. Although utilizing the prior locations, SRL-KNN does
not require knowledge of the exact moving speed and direction of the user.
Moreover, to take into account of the temporal fluctuations of the received
signal strength indicator (RSSI), RSSI histogram is incorporated into the
distance calculation. Actual on-site experiments demonstrate that the new
algorithm achieves an average localization error of $0.66$ m with $80\%$ of the
errors under $0.89$ m, which outperforms conventional KNN algorithms by $45\%$
under the same test environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11486</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11486</id><created>2019-08-29</created><authors><author><keyname>Li</keyname><forenames>Qiao</forenames></author><author><keyname>Gao</keyname><forenames>David Wenzhong</forenames></author></authors><title>Fast Scenario Reduction for Power Systems by Deep Learning</title><categories>eess.SP cs.LG</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scenario reduction is an important topic in stochastic programming problems.
Due to the random behavior of load and renewable energy, stochastic programming
becomes a useful technique to optimize power systems. Thus, scenario reduction
gets more attentions in recent years. Many scenario reduction methods have been
proposed to reduce the scenario set in a fast speed. However, the speed of
scenario reduction is still very slow, in which it takes at least several
seconds to several minutes to finish the reduction. This limitation of speed
prevents stochastic programming to be implemented in real-time optimal control
problems. In this paper, a fast scenario reduction method based on deep
learning is proposed to solve this problem. Inspired by the deep learning based
image process, recognition and generation methods, the scenario data are
transformed into a 2D image-like data and then to be fed into a deep
convolutional neural network (DCNN). The output of the DCNN will be an &quot;image&quot;
of the reduced scenario set. Since images can be processed in a very high speed
by neural networks, the scenario reduction by neural network can also be very
fast. The results of the simulation show that the scenario reduction with the
proposed DCNN method can be completed in very high speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11502</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11502</id><created>2019-08-29</created><authors><author><keyname>Monakhova</keyname><forenames>Kristina</forenames></author><author><keyname>Yurtsever</keyname><forenames>Joshua</forenames></author><author><keyname>Kuo</keyname><forenames>Grace</forenames></author><author><keyname>Antipa</keyname><forenames>Nick</forenames></author><author><keyname>Yanny</keyname><forenames>Kyrollos</forenames></author><author><keyname>Waller</keyname><forenames>Laura</forenames></author></authors><title>Learned reconstructions for practical mask-based lensless imaging</title><categories>eess.IV cs.CV</categories><doi>10.1364/OE.27.028075</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mask-based lensless imagers are smaller and lighter than traditional lensed
cameras. In these imagers, the sensor does not directly record an image of the
scene; rather, a computational algorithm reconstructs it. Typically, mask-based
lensless imagers use a model-based reconstruction approach that suffers from
long compute times and a heavy reliance on both system calibration and
heuristically chosen denoisers. In this work, we address these limitations
using a bounded-compute, trainable neural network to reconstruct the image. We
leverage our knowledge of the physical system by unrolling a traditional
model-based optimization algorithm, whose parameters we optimize using
experimentally gathered ground-truth data. Optionally, images produced by the
unrolled network are then fed into a jointly-trained denoiser. As compared to
traditional methods, our architecture achieves better perceptual image quality
and runs 20x faster, enabling interactive previewing of the scene. We explore a
spectrum between model-based and deep learning methods, showing the benefits of
using an intermediate approach. Finally, we test our network on images taken in
the wild with a prototype mask-based camera, demonstrating that our network
generalizes to natural images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11506</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11506</id><created>2019-08-29</created><updated>2019-09-01</updated><authors><author><keyname>Kudo</keyname><forenames>Akira</forenames></author><author><keyname>Kitamura</keyname><forenames>Yoshiro</forenames></author><author><keyname>Li</keyname><forenames>Yuanzhong</forenames></author><author><keyname>Iizuka</keyname><forenames>Satoshi</forenames></author><author><keyname>Simo-Serra</keyname><forenames>Edgar</forenames></author></authors><title>Virtual Thin Slice: 3D Conditional GAN-based Super-resolution for CT
  Slice Interval</title><categories>eess.IV cs.CV</categories><comments>10 pages, 6 figures, Accepted to Machine Learning for Medical Image
  Reconstruction (MLMIR) at MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many CT slice images are stored with large slice intervals to reduce storage
size in clinical practice. This leads to low resolution perpendicular to the
slice images (i.e., z-axis), which is insufficient for 3D visualization or
image analysis. In this paper, we present a novel architecture based on
conditional Generative Adversarial Networks (cGANs) with the goal of generating
high resolution images of main body parts including head, chest, abdomen and
legs. However, GANs are known to have a difficulty with generating a diversity
of patterns due to a phenomena known as mode collapse. To overcome the lack of
generated pattern variety, we propose to condition the discriminator on the
different body parts. Furthermore, our generator networks are extended to be
three dimensional fully convolutional neural networks, allowing for the
generation of high resolution images from arbitrary fields of view. In our
verification tests, we show that the proposed method obtains the best scores by
PSNR/SSIM metrics and Visual Turing Test, allowing for accurate reproduction of
the principle anatomy in high resolution. We expect that the proposed method
contribute to effective utilization of the existing vast amounts of thick CT
images stored in hospitals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11517</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11517</id><created>2019-08-29</created><updated>2019-09-11</updated><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Meng</keyname><forenames>Shengbin</forenames></author><author><keyname>Zhang</keyname><forenames>Xinfeng</forenames></author><author><keyname>Wang</keyname><forenames>Shiqi</forenames></author><author><keyname>Wang</keyname><forenames>Yue</forenames></author><author><keyname>Ma</keyname><forenames>Siwei</forenames></author></authors><title>UGC-VIDEO: perceptual quality assessment of user-generated videos</title><categories>cs.MM eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have witnessed an ever-expandingvolume of user-generated content
(UGC) videos available on the Internet. Nevertheless, progress on perceptual
quality assessmentof UGC videos still remains quite limited. There are many
distinguished characteristics of UGC videos in the complete video production
and delivery chain, and one important property closely relevant to video
quality is that there does not exist the pristine source after they are
uploaded to the hosting platform,such that they often undergo multiple
compression stages before ultimately viewed. To facilitate the UGC video
quality assessment,we created a UGC video perceptual quality assessment
database. It contains 50 source videos collected from TikTok with diverse
content, along with multiple distortion versions generated bythe compression
with different quantization levels and coding standards. Subjective quality
assessment was conducted to evaluate the video quality. Furthermore, we
benchmark the database using existing quality assessment algorithms, and
potential roomis observed to future improve the accuracy of UGC video quality
measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11535</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11535</id><created>2019-08-30</created><authors><author><keyname>Yasuda</keyname><forenames>Yusuke</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author></authors><title>Initial investigation of an encoder-decoder end-to-end TTS framework
  using marginalization of monotonic hard latent alignments</title><categories>eess.AS cs.CL cs.SD stat.ML</categories><comments>To be appeared at SSW10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end text-to-speech (TTS) synthesis is a method that directly converts
input text to output acoustic features using a single network. A recent advance
of end-to-end TTS is due to a key technique called attention mechanisms, and
all successful methods proposed so far have been based on soft attention
mechanisms. However, although network structures are becoming increasingly
complex, end-to-end TTS systems with soft attention mechanisms may still fail
to learn and to predict accurate alignment between the input and output. This
may be because the soft attention mechanisms are too flexible. Therefore, we
propose an approach that has more explicit but natural constraints suitable for
speech signals to make alignment learning and prediction of end-to-end TTS
systems more robust. The proposed system, with the constrained alignment scheme
borrowed from segment-to-segment neural transduction (SSNT), directly
calculates the joint probability of acoustic features and alignment given an
input text. The alignment is designed to be hard and monotonically increase by
considering the speech nature, and it is treated as a latent variable and
marginalized during training. During prediction, both the alignment and
acoustic features can be generated from the probabilistic distributions. The
advantages of our approach are that we can simplify many modules for the soft
attention and that we can train the end-to-end TTS model using a single
likelihood function. As far as we know, our approach is the first end-to-end
TTS without a soft attention mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11543</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11543</id><created>2019-08-30</created><authors><author><keyname>Duan</keyname><forenames>Jiajun</forenames></author><author><keyname>Li</keyname><forenames>Haifeng</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Diao</keyname><forenames>Ruisheng</forenames></author><author><keyname>Zhang</keyname><forenames>Bei</forenames></author><author><keyname>Shi</keyname><forenames>Di</forenames></author><author><keyname>Lu</keyname><forenames>Xiao</forenames></author><author><keyname>Wang</keyname><forenames>Zhiwei</forenames></author><author><keyname>Wang</keyname><forenames>Siqi</forenames></author></authors><title>A Deep Reinforcement Learning Based Approach for Optimal Active Power
  Dispatch</title><categories>math.OC eess.SP</categories><comments>The paper is accepted by IEEE Sustainable Power &amp; Energy Conference
  (iSPEC) 2019, Beijing, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stochastic and dynamic nature of renewable energy sources and power
electronic devices are creating unique challenges for modern power systems. One
such challenge is that the conventional mathematical systems models-based
optimal active power dispatch (OAPD) method is limited in its ability to handle
uncertainties caused by renewables and other system contingencies. In this
paper, a deep reinforcement learning-based (DRL) method is presented to provide
a near-optimal solution to the OAPD problem without system modeling. The DRL
agent undergoes offline training, based on which, it is able to obtain the OAPD
points under unseen scenarios, e.g., different load patterns. The DRL-based
OAPD method is tested on the IEEE 14-bus system, thereby validating its
feasibility to solve the OAPD problem. Its utility is further confirmed in that
it can be leveraged as a key component for solving future model-free AC-OPF
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11593</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11593</id><created>2019-08-30</created><authors><author><keyname>Batliner</keyname><forenames>Anton</forenames></author><author><keyname>Steidl</keyname><forenames>Stefan</forenames></author><author><keyname>Eyben</keyname><forenames>Florian</forenames></author><author><keyname>Schuller</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>On Laughter and Speech-Laugh, Based on Observations of Child-Robot
  Interaction</title><categories>cs.CL cs.SD eess.AS</categories><comments>25 pages, 3 figures</comments><msc-class>68T10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we study laughter found in child-robot interaction where it
had not been prompted intentionally. Different types of laughter and
speech-laugh are annotated and processed. In a descriptive part, we report on
the position of laughter and speech-laugh in syntax and dialogue structure, and
on communicative functions. In a second part, we report on automatic
classification performance and on acoustic characteristics, based on extensive
feature selection procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11602</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11602</id><created>2019-08-30</created><updated>2019-10-23</updated><authors><author><keyname>Xu</keyname><forenames>Xudong</forenames></author><author><keyname>Dai</keyname><forenames>Bo</forenames></author><author><keyname>Lin</keyname><forenames>Dahua</forenames></author></authors><title>Recursive Visual Sound Separation Using Minus-Plus Net</title><categories>cs.CV cs.SD eess.AS</categories><comments>accepted by ICCV2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sounds provide rich semantics, complementary to visual data, for many tasks.
However, in practice, sounds from multiple sources are often mixed together. In
this paper we propose a novel framework, referred to as MinusPlus Network
(MP-Net), for the task of visual sound separation. MP-Net separates sounds
recursively in the order of average energy, removing the separated sound from
the mixture at the end of each prediction, until the mixture becomes empty or
contains only noise. In this way, MP-Net could be applied to sound mixtures
with arbitrary numbers and types of sounds. Moreover, while MP-Net keeps
removing sounds with large energy from the mixture, sounds with small energy
could emerge and become clearer, so that the separation is more accurate.
Compared to previous methods, MP-Net obtains state-of-the-art results on two
large scale datasets, across mixtures with different types and numbers of
sounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11618</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11618</id><created>2019-08-30</created><updated>2019-09-01</updated><authors><author><keyname>Wang</keyname><forenames>Chenhao</forenames></author></authors><title>Multi-Grained Spatio-temporal Modeling for Lip-reading</title><categories>cs.CV eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lip-reading aims to recognize speech content from videos via visual analysis
of speakers' lip movements. This is a challenging task due to the existence of
homophemes-words which involve identical or highly similar lip movements, as
well as diverse lip appearances and motion patterns among the speakers. To
address these challenges, we propose a novel lip-reading model which captures
not only the nuance between words but also styles of different speakers, by a
multi-grained spatio-temporal modeling of the speaking process. Specifically,
we first extract both frame-level fine-grained features and short-term
medium-grained features by the visual front-end, which are then combined to
obtain discriminative representations for words with similar phonemes. Next, a
bidirectional ConvLSTM augmented with temporal attention aggregates
spatio-temporal information in the entire input sequence, which is expected to
be able to capture the coarse-gained patterns of each word and robust to
various conditions in speaker identity, lighting conditions, and so on. By
making full use of the information from different levels in a unified
framework, the model is not only able to distinguish words with similar
pronunciations, but also becomes robust to appearance changes. We evaluate our
method on two challenging word-level lip-reading benchmarks and show the
effectiveness of the proposed method, which also demonstrate the above claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11645</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11645</id><created>2019-08-30</created><updated>2019-10-25</updated><authors><author><keyname>Cavigelli</keyname><forenames>Lukas</forenames></author><author><keyname>Rutishauser</keyname><forenames>Georg</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>EBPC: Extended Bit-Plane Compression for Deep Neural Network Inference
  and Training Accelerators</title><categories>cs.CV cs.AR eess.IV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1810.03979</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the wake of the success of convolutional neural networks in image
classification, object recognition, speech recognition, etc., the demand for
deploying these compute-intensive ML models on embedded and mobile systems with
tight power and energy constraints at low cost, as well as for boosting
throughput in data centers, is growing rapidly. This has sparked a surge of
research into specialized hardware accelerators. Their performance is typically
limited by I/O bandwidth, power consumption is dominated by I/O transfers to
off-chip memory, and on-chip memories occupy a large part of the silicon area.
We introduce and evaluate a novel, hardware-friendly, and lossless compression
scheme for the feature maps present within convolutional neural networks. We
present hardware architectures and synthesis results for the compressor and
decompressor in 65nm. With a throughput of one 8-bit word/cycle at 600MHz, they
fit into 2.8kGE and 3.0kGE of silicon area, respectively - together the size of
less than seven 8-bit multiply-add units at the same throughput. We show that
an average compression ratio of 5.1x for AlexNet, 4x for VGG-16, 2.4x for
ResNet-34 and 2.2x for MobileNetV2 can be achieved - a gain of 45-70% over
existing methods. Our approach also works effectively for various number
formats, has a low frame-to-frame variance on the compression ratio, and
achieves compression factors for gradient map compression during training that
are even better than for inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11661</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11661</id><created>2019-08-30</created><authors><author><keyname>Hertneck</keyname><forenames>Michael</forenames></author><author><keyname>Linsenmayer</keyname><forenames>Steffen</forenames></author><author><keyname>Allg&#xf6;wer</keyname><forenames>Frank</forenames></author></authors><title>Nonlinear Dynamic Periodic Event-Triggered Control with Robustness to
  Packet Loss Based on Non-Monotonic Lyapunov Functions</title><categories>eess.SY cs.SY</categories><comments>Accepted for 58th IEEE Conference on Decision and Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the stabilization of nonlinear continuous-time dynamical
systems employing periodic event-triggered control (PETC). Assuming knowledge
of a stabilizing feedback law for the continuous-time system with a certain
convergence rate, a dynamic, state dependent PETC mechanism is designed. The
proposed mechanism guarantees on average the same worst case convergence
behavior except for tunable deviations. Furthermore, a new approach to
determine the sampling period for the proposed PETC mechanism is presented.
This approach as well as the actual trigger rule exploit the theory of
non-monotonic Lyapunov functions. An additional feature of the proposed PETC
mechanism is the possibility to integrate knowledge about packet losses in the
PETC design. The proposed PETC mechanism is illustrated with a nonlinear
numerical example from literature. This paper is the accepted version of [1],
containing also the proofs of the main results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11687</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11687</id><created>2019-07-29</created><authors><author><keyname>Ginoux</keyname><forenames>Jean-Marc</forenames><affiliation>LIS</affiliation></author><author><keyname>Meucci</keyname><forenames>Riccardo</forenames></author><author><keyname>Euzzor</keyname><forenames>Stefano</forenames></author><author><keyname>Di Garbo</keyname><forenames>Angelo</forenames></author></authors><title>Torus Breakdown in a Uni Junction Memristor</title><categories>eess.SY cs.SY eess.SP nlin.AO nlin.CD</categories><proxy>ccsd</proxy><journal-ref>International Journal of Bifurcation and Chaos, World Scientific
  Publishing, 2018, 28 (10), pp.1850128</journal-ref><doi>10.1142/S0218127418501286</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Experimental study of a uni junction transistor (UJT) has enabled to show
that this electronic component has the same features as the so-called
&quot;memristor&quot;. So, we have used the memristor's direct current (DC) vM--iM
characteristic for modeling the UJT's DC current--voltage characteristic. This
has led us to confirm on the one hand, that the UJT is a memristor and, on the
other hand, to propose a new four-dimensional autonomous dynamical system
allowing to describe experimentally observed phenomena such as the transition
from a limit cycle to torus breakdown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11711</identifier>
 <datestamp>2020-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11711</id><created>2019-08-29</created><updated>2020-02-04</updated><authors><author><keyname>Wei</keyname><forenames>Qinshuang</forenames></author><author><keyname>Pedarsani</keyname><forenames>Ramtin</forenames></author><author><keyname>Coogan</keyname><forenames>Samuel</forenames></author></authors><title>Mixed Autonomy in Ride-Sharing Networks</title><categories>eess.SY cs.SY</categories><comments>18 pages, 2 figures. arXiv admin note: text overlap with
  arXiv:1903.07707</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider ride-sharing networks served by human-driven vehicles (HVs) and
autonomous vehicles (AVs). We propose a model for ride-sharing in this mixed
autonomy setting for a multi-location network in which a ride-sharing platform
sets prices for riders, compensations for drivers of HVs, and operates AVs for
a fixed price with the goal of maximizing profits. When there are more vehicles
than riders at a location, we consider three vehicle-to-rider assignment
possibilities: rides are assigned to HVs first; rides are assigned to AVs
first; rides are assigned in proportion to the number of available HVs and AVs.
Next, for each of these priority possibilities, we establish a nonconvex
optimization problem characterizing the optimal profits for a network operating
at a steady-state equilibrium. We then provide a convex problem which we show
to have the same optimal profits, allowing for efficient computation of
equilibria, and we show that all three priority possibilities result in the
same maximum profits for the platform. Next, we show that, in some cases, there
is a regime for which the platform will choose to mix HVs and AVs in order to
maximize its profit, while in other cases, the platform will use only HVs or
only AVs, depending on the relative cost of AVs. For a specific class of
networks, we fully characterize these thresholds analytically and demonstrate
our results on an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11713</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11713</id><created>2019-08-29</created><authors><author><keyname>Hojjatinia</keyname><forenames>Sarah</forenames></author><author><keyname>Lagoa</keyname><forenames>Constantino M.</forenames></author><author><keyname>Dabbene</keyname><forenames>Fabrizio</forenames></author></authors><title>Identification of Switched Autoregressive and Switched Autoregressive
  Exogenous Systems from Large Noisy Data Sets</title><categories>eess.SY cs.SY</categories><comments>arXiv admin note: substantial text overlap with arXiv:1804.07411</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper introduces novel methodologies for the identification of
coefficients of switched autoregressive and switched autoregressive exogenous
linear models. We consider cases which system's outputs are contaminated by
possibly large values of noise for the both case of measurement noise in
switched autoregressive models and process noise in switched autoregressive
exogenous models. It is assumed that only partial information on the
probability distribution of the noise is available. Given input-output data, we
aim at identifying switched system coefficients and parameters of the
distribution of the noise, which are compatible with the collected data. We
demonstrate the efficiency of the proposed approach with several academic
examples. The method is shown to be extremely effective in the situations where
a large number of measurements is available; cases in which previous approaches
based on polynomial or mixed-integer optimization cannot be applied due to very
large computational burden.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11726</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11726</id><created>2019-08-30</created><authors><author><keyname>Varasteh</keyname><forenames>Morteza</forenames></author><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Clerckx</keyname><forenames>Bruno</forenames></author></authors><title>Learning Modulation Design for SWIPT with Nonlinear Energy Harvester:
  Large and Small Signal Power Regimes</title><categories>cs.IT eess.SP math.IT</categories><comments>arXiv admin note: text overlap with arXiv:1810.12152</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonlinear energy harvesters (EH) behave differently depending on the range of
their input power. In the literature, different models have been proposed
mainly for relatively small and large input power regimes of an EH. Due to the
complexity of the proposed nonlinear models, obtaining analytical optimal or
well performing signal designs have been extremely challenging. Relying on the
proposed models in the literature, the learning problem of modulation design
for simultaneous wireless information-power transfer (SWIPT) over a
point-to-point link is studied. Joint optimization of the transmitter and the
receiver is implemented using neural network (NN)-based autoencoders. The
results reveal that for relatively small channel input powers, as the power
demand increases at the receiver, one of the symbols is shot away from the
origin while the remaining symbols approach zero amplitude. In the very extreme
case of merely receiver power demand, the modulations are in the form of On-Off
keying signalling with a low probability of the On signal. On the other side,
for relatively large channel input powers, it is observed that as the receiver
power demand increases, a number of symbols approach zero amplitude, whereas
the others (more than one symbol) get equally high amplitudes but with
different phases. In the extreme scenario of merely receiver power demand, the
modulation resembles multiple On-Off keying signalling with different phases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11778</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11778</id><created>2019-08-30</created><authors><author><keyname>Agarwal</keyname><forenames>Aayushya</forenames></author><author><keyname>Pandey</keyname><forenames>Amritanshu</forenames></author><author><keyname>Jereminov</keyname><forenames>Marko</forenames></author><author><keyname>Pileggi</keyname><forenames>Larry</forenames></author></authors><title>Implicitly Modeling Frequency Control within Power Flow</title><categories>eess.SY cs.SY</categories><comments>To be presented at IEEE ISGT 2019 Europe, Bucharest</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we extend a circuit-based, current-voltage power flow
formulation to include frequency deviations and implicitly model generator
primary and secondary control actions as a function of their temporal
dependence. This includes extending the slack bus generator model(s) to better
represents its true behavior with frequency controls. These implicit models
obviate the need for outer iteration loops and improve the robustness of the
simulation convergence when frequency deviations are considered. The simulation
framework is highly scalable and is demonstrated on 85k+ bus systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11789</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11789</id><created>2019-08-30</created><authors><author><keyname>Yahiaoui</keyname><forenames>Marie</forenames></author><author><keyname>Rashed</keyname><forenames>Hazem</forenames></author><author><keyname>Mariotti</keyname><forenames>Letizia</forenames></author><author><keyname>Sistu</keyname><forenames>Ganesh</forenames></author><author><keyname>Clancy</keyname><forenames>Ian</forenames></author><author><keyname>Yahiaoui</keyname><forenames>Lucie</forenames></author><author><keyname>Kumar</keyname><forenames>Varun Ravi</forenames></author><author><keyname>Yogamani</keyname><forenames>Senthil</forenames></author></authors><title>FisheyeMODNet: Moving Object detection on Surround-view Cameras for
  Autonomous Driving</title><categories>cs.CV eess.IV</categories><comments>Accepted for ICCV 2019 Workshop on 360{\deg} Perception and
  Interaction. A shorter version was presented at IMVIP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Moving Object Detection (MOD) is an important task for achieving robust
autonomous driving. An autonomous vehicle has to estimate collision risk with
other interacting objects in the environment and calculate an optional
trajectory. Collision risk is typically higher for moving objects than static
ones due to the need to estimate the future states and poses of the objects for
decision making. This is particularly important for near-range objects around
the vehicle which are typically detected by a fisheye surround-view system that
captures a 360{\deg} view of the scene. In this work, we propose a CNN
architecture for moving object detection using fisheye images that were
captured in autonomous driving environment. As motion geometry is highly
non-linear and unique for fisheye cameras, we will make an improved version of
the current dataset public to encourage further research. To target embedded
deployment, we design a lightweight encoder sharing weights across sequential
images. The proposed network runs at 15 fps on a 1 teraflops automotive
embedded system at accuracy of 40% IoU and 69.5% mIoU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11799</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11799</id><created>2019-08-30</created><authors><author><keyname>Liu</keyname><forenames>Qinghui</forenames></author><author><keyname>Kampffmeyer</keyname><forenames>Michael</forenames></author><author><keyname>Jenssen</keyname><forenames>Robert</forenames></author><author><keyname>Salberg</keyname><forenames>Arnt-B&#xf8;rre</forenames></author></authors><title>Dense Dilated Convolutions Merging Network for Semantic Mapping of
  Remote Sensing Images</title><categories>cs.CV cs.LG eess.IV</categories><comments>JURSE 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a network for semantic mapping called the Dense Dilated
Convolutions Merging Network (DDCM-Net) to provide a deep learning approach
that can recognize multi-scale and complex shaped objects with similar color
and textures, such as buildings, surfaces/roads, and trees in very high
resolution remote sensing images. The proposed DDCM-Net consists of dense
dilated convolutions merged with varying dilation rates. This can effectively
enlarge the kernels' receptive fields, and, more importantly, obtain fused
local and global context information to promote surrounding discriminative
capability. We demonstrate the effectiveness of the proposed DDCM-Net on the
publicly available ISPRS Potsdam dataset and achieve a performance of 92.3%
F1-score and 86.0% mean intersection over union accuracy by only using the RGB
bands, without any post-processing. We also show results on the ISPRS Vaihingen
dataset, where the DDCM-Net trained with IRRG bands, also obtained better
mapping accuracy (89.8% F1-score) than previous state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11834</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11834</id><created>2019-08-30</created><updated>2019-11-11</updated><authors><author><keyname>Long</keyname><forenames>Shangbang</forenames></author><author><keyname>Guan</keyname><forenames>Yushuo</forenames></author><author><keyname>Wang</keyname><forenames>Bingxuan</forenames></author><author><keyname>Bian</keyname><forenames>Kaigui</forenames></author><author><keyname>Yao</keyname><forenames>Cong</forenames></author></authors><title>Rethinking Irregular Scene Text Recognition</title><categories>cs.CV cs.LG eess.IV</categories><comments>Technical report for participation in ICDAR2019-ArT recognition track</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reading text from natural images is challenging due to the great variety in
text font, color, size, complex background and etc.. The perspective distortion
and non-linear spatial arrangement of characters make it further difficult.
While rectification based method is intuitively grounded and has pushed the
envelope by far, its potential is far from being well exploited. In this paper,
we present a bag of tricks that prove to significantly improve the performance
of rectification based method. On curved text dataset, our method achieves an
accuracy of 89.6% on CUTE-80 and 76.3% on Total-Text, an improvement over
previous state-of-the-art by 6.3% and 14.7% respectively. Furthermore, our
combination of tricks helps us win the ICDAR 2019 Arbitrary-Shaped Text
Challenge (Latin script), achieving an accuracy of 74.3% on the held-out test
set. We release our code as well as data samples for further exploration at
https://github.com/Jyouhou/ICDAR2019-ArT-Recognition-Alchemy
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.11863</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1908.11863</id><created>2019-08-30</created><authors><author><keyname>Akut</keyname><forenames>Rohan</forenames></author><author><keyname>Marathe</keyname><forenames>Sumukh</forenames></author><author><keyname>Apte</keyname><forenames>Rucha</forenames></author><author><keyname>Joshi</keyname><forenames>Ishan</forenames></author><author><keyname>Kulkarni</keyname><forenames>Siddhivinayak</forenames></author></authors><title>Systematic Analysis of Image Generation using GANs</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>Accepted in IEEE ICMLDS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative Adversarial Networks have been crucial in the developments made in
unsupervised learning in recent times. Exemplars of image synthesis from text
or other images, these networks have shown remarkable improvements over
conventional methods in terms of performance. Trained on the adversarial
training philosophy, these networks aim to estimate the potential distribution
from the real data and then use this as input to generate the synthetic data.
Based on this fundamental principle, several frameworks can be generated that
are paragon implementations in several real-life applications such as art
synthesis, generation of high resolution outputs and synthesis of images from
human drawn sketches, to name a few. While theoretically GANs present better
results and prove to be an improvement over conventional methods in many
factors, the implementation of these frameworks for dedicated applications
remains a challenge. This study explores and presents a taxonomy of these
frameworks and their use in various image to image synthesis and text to image
synthesis applications. The basic GANs, as well as a variety of different niche
frameworks, are critically analyzed. The advantages of GANs for image
generation over conventional methods as well their disadvantages amongst other
frameworks are presented. The future applications of GANs in industries such as
healthcare, art and entertainment are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00014</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00014</id><created>2019-08-30</created><authors><author><keyname>Hespanhol</keyname><forenames>Pedro</forenames></author><author><keyname>Porter</keyname><forenames>Matthew</forenames></author><author><keyname>Vasudevan</keyname><forenames>Ram</forenames></author><author><keyname>Aswani</keyname><forenames>Anil</forenames></author></authors><title>Sensor Switching Control Under Attacks Detectable by Finite Sample
  Dynamic Watermarking Tests</title><categories>math.OC cs.SY eess.SY</categories><comments>13 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Control system security is enhanced by the ability to detect malicious
attacks on sensor measurements. Dynamic watermarking can detect such attacks on
linear time-invariant (LTI) systems. However, existing theory focuses on attack
detection and not on the use of watermarking in conjunction with attack
mitigation strategies. In this paper, we study the problem of switching between
two sets of sensors: One set of sensors has high accuracy but is vulnerable to
attack, while the second set of sensors has low accuracy but cannot be
attacked. The problem is to design a sensor switching strategy based on attack
detection by dynamic watermarking. This requires new theory because existing
results are not adequate to control or bound the behavior of sensor switching
strategies that use finite data. To overcome this, we develop new finite sample
hypothesis tests for dynamic watermarking in the case of bounded disturbances,
using the modern theory of concentration of measure for random matrices. Our
resulting switching strategy is validated with a simulation analysis in an
autonomous driving setting, which demonstrates the strong performance of our
proposed policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00023</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00023</id><created>2019-08-30</created><updated>2019-09-09</updated><authors><author><keyname>Chowdhury</keyname><forenames>Shwetadwip</forenames></author><author><keyname>Chen</keyname><forenames>Michael</forenames></author><author><keyname>Eckert</keyname><forenames>Regina</forenames></author><author><keyname>Ren</keyname><forenames>David</forenames></author><author><keyname>Wu</keyname><forenames>Fan</forenames></author><author><keyname>Repina</keyname><forenames>Nicole</forenames></author><author><keyname>Waller</keyname><forenames>Laura</forenames></author></authors><title>High-resolution 3D refractive index microscopy of multiple-scattering
  samples from intensity images</title><categories>eess.IV physics.comp-ph q-bio.QM</categories><comments>24 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optical diffraction tomography (ODT) reconstructs a samples volumetric
refractive index (RI) to create high-contrast, quantitative 3D visualizations
of biological samples. However, standard implementations of ODT use
interferometric systems, and so are sensitive to phase instabilities, complex
mechanical design, and coherent noise. Furthermore, their reconstruction
framework is typically limited to weakly-scattering samples, and thus excludes
a whole class of multiple-scattering samples. Here, we implement a new 3D RI
microscopy technique that utilizes a computational multi-slice beam propagation
method to invert the optical scattering process and reconstruct high-resolution
(NA&gt;1.0) 3D RI distributions of multiple-scattering samples. The method
acquires intensity-only measurements from different illumination angles, and
then solves a non-linear optimization problem to recover the sample 3D RI
distribution. We experimentally demonstrate reconstruction of samples with
varying amounts of multiple scattering: a 3T3 fibroblast cell, a cluster of C.
elegans embryos, and a whole C. elegans worm, with lateral and axial
resolutions of 250 nm and 900 nm, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00059</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00059</id><created>2019-08-30</created><authors><author><keyname>Saraswat</keyname><forenames>Govind</forenames></author><author><keyname>Khatana</keyname><forenames>Vivek</forenames></author><author><keyname>Patel</keyname><forenames>Sourav</forenames></author><author><keyname>Salapaka</keyname><forenames>Murti V.</forenames></author></authors><title>Distributed finite-time termination for consensus algorithm in switching
  topologies</title><categories>eess.SY cs.MA cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we present a finite time stopping criterion for consensus
algorithms in networks with dynamic communication topology. Recent results
provide asymptotic convergence to the consensus algorithm. However, the
asymptotic convergence of these algorithms pose a challenge in the practical
settings where the response from agents is required in finite time. To this
end, we propose a Maximum-Minimum protocol which propagates the global maximum
and minimum values of agent states (while running consensus algorithm) in the
network. We establish that global maximum and minimum values are strictly
monotonic even for a dynamic topology and can be utilized to distributively
ascertain the closeness to convergence in finite time. We show that each node
can have access to the global maximum and minimum by running the proposed
Maximum-Minimum protocol and use it as a finite time stopping criterion for the
otherwise asymptotic consensus algorithm. The practical utility of the
algorithm is illustrated through experiments where each agent is instantiated
by a NodeJS socket.io server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00082</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00082</id><created>2019-08-30</created><authors><author><keyname>Dimitriadis</keyname><forenames>Dimitrios</forenames></author></authors><title>Enhancements for Audio-only Diarization Systems</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper two different approaches to enhance the performance of the most
challenging component of a Speaker Diarization system are presented, i.e. the
speaker clustering part. A processing step is proposed enhancing the input
features with a temporal smoothing process combined with nonlinear filtering.
We, also, propose improvements on the Deep Embedded Clustering (DEC) algorithm
-- a nonlinear feature transformation. The performance of these enhancements is
compared with different clustering algorithms, such as the UISRNN, k-Means,
Spectral clustering and x-Means. The evaluation is held on three different
tasks, i.e. the AMI, DIHARD and an internal meeting transcription task. The
proposed approaches assume a known number of speakers and time segmentations
for the audio files. Since, we focus only on the clustering component of
diarization for this work, the segmentation provided is assumed perfect.
Finally, we present how supervision, in the form of given speaker profiles, can
further improve the overall diarization performance. The proposed enhancements
yield substantial relative improvements in all 3 tasks, with 20\% in AMI and
19\% better than the best diarization system for DIHARD task, when the number
of speakers is known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00089</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00089</id><created>2019-08-30</created><updated>2019-09-06</updated><authors><author><keyname>Yazdanpanah</keyname><forenames>Ali Pour</forenames></author><author><keyname>Afacan</keyname><forenames>Onur</forenames></author><author><keyname>Warfield</keyname><forenames>Simon K.</forenames></author></authors><title>Deep Plug-and-Play Prior for Parallel MRI Reconstruction</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast data acquisition in Magnetic Resonance Imaging (MRI) is vastly in demand
and scan time directly depends on the number of acquired k-space samples.
Conventional MRI reconstruction methods for fast MRI acquisition mostly relied
on different regularizers which represent analytical models of sparsity.
However, recent data-driven methods based on deep learning has resulted in
promising improvements in image reconstruction algorithms. In this paper, we
propose a deep plug-and-play prior framework for parallel MRI reconstruction
problems which utilize a deep neural network (DNN) as an advanced denoiser
within an iterative method. This, in turn, enables rapid acquisition of MR
images with improved image quality. The proposed method was compared with the
reconstructions using the clinical gold standard GRAPPA method. Our results
with undersampled data demonstrate that our method can deliver considerably
higher quality images at high acceleration factors in comparison to clinical
gold standard method for MRI reconstructions. Our proposed reconstruction
enables an increase in acceleration factor, and a reduction in acquisition time
while maintaining high image quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00145</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00145</id><created>2019-08-31</created><authors><author><keyname>Xiong</keyname><forenames>Jinhui</forenames></author><author><keyname>Richt&#xe1;rik</keyname><forenames>Peter</forenames></author><author><keyname>Heidrich</keyname><forenames>Wolfgang</forenames></author></authors><title>Stochastic Convolutional Sparse Coding</title><categories>eess.IV cs.LG stat.ML</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art methods for Convolutional Sparse Coding usually employ
Fourier-domain solvers in order to speed up the convolution operators. However,
this approach is not without shortcomings. For example, Fourier-domain
representations implicitly assume circular boundary conditions and make it hard
to fully exploit the sparsity of the problem as well as the small spatial
support of the filters. In this work, we propose a novel stochastic
spatial-domain solver, in which a randomized subsampling strategy is introduced
during the learning sparse codes. Afterwards, we extend the proposed strategy
in conjunction with online learning, scaling the CSC model up to very large
sample sizes. In both cases, we show experimentally that the proposed
subsampling strategy, with a reasonable selection of the subsampling rate,
outperforms the state-of-the-art frequency-domain solvers in terms of execution
time without losing the learning quality. Finally, we evaluate the
effectiveness of the over-complete dictionary learned from large-scale
datasets, which demonstrates an improved sparse representation of the natural
images on account of more abundant learned image features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00149</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00149</id><created>2019-08-31</created><authors><author><keyname>Lee</keyname><forenames>John</forenames></author><author><keyname>Bertrand</keyname><forenames>Nicholas P.</forenames></author><author><keyname>Rozell</keyname><forenames>Christopher J.</forenames></author></authors><title>Parallel Unbalanced Optimal Transport Regularization for Large Scale
  Imaging Problems</title><categories>eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modeling of phenomenological structure is a crucial aspect in inverse
imaging problems. One emerging modeling tool in computational imaging is the
optimal transport framework. Its ability to model geometric displacements
across an image's support gives it attractive qualities similar to those of
optical flow methods which are effective at capturing visual motion, but are
restricted to operate in significantly smaller state-spaces. Despite this
advantage, two major drawbacks make it unsuitable for general deployment: (i)
it suffers from exorbitant computational costs due to a quadratic
optimization-variable complexity, and (ii) it has a mass-balancing assumption
that limits applications with natural images. We tackle these issues
simultaneously by proposing a novel formulation for an unbalanced optimal
transport regularizer that has linear optimization-variable complexity. In
addition, we present a general parallelizable proximal method for this
regularizer, and demonstrate superior empirical performance on novel dynamical
tracking applications in synthetic and real video.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00166</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00166</id><created>2019-08-31</created><authors><author><keyname>Azad</keyname><forenames>Reza</forenames></author><author><keyname>Asadi-Aghbolaghi</keyname><forenames>Maryam</forenames></author><author><keyname>Fathy</keyname><forenames>Mahmood</forenames></author><author><keyname>Escalera</keyname><forenames>Sergio</forenames></author></authors><title>Bi-Directional ConvLSTM U-Net with Densley Connected Convolutions</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, deep learning-based networks have achieved state-of-the-art
performance in medical image segmentation. Among the existing networks, U-Net
has been successfully applied on medical image segmentation. In this paper, we
propose an extension of U-Net, Bi-directional ConvLSTM U-Net with Densely
connected convolutions (BCDU-Net), for medical image segmentation, in which we
take full advantages of U-Net, bi-directional ConvLSTM (BConvLSTM) and the
mechanism of dense convolutions. Instead of a simple concatenation in the skip
connection of U-Net, we employ BConvLSTM to combine the feature maps extracted
from the corresponding encoding path and the previous decoding up-convolutional
layer in a non-linear way. To strengthen feature propagation and encourage
feature reuse, we use densely connected convolutions in the last convolutional
layer of the encoding path. Finally, we can accelerate the convergence speed of
the proposed network by employing batch normalization (BN). The proposed model
is evaluated on three datasets of: retinal blood vessel segmentation, skin
lesion segmentation, and lung nodule segmentation, achieving state-of-the-art
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00178</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00178</id><created>2019-08-31</created><authors><author><keyname>Hashimoto</keyname><forenames>Kazumune</forenames></author><author><keyname>Yoshimura</keyname><forenames>Yuichi</forenames></author><author><keyname>Ushio</keyname><forenames>Toshimitsu</forenames></author></authors><title>Learning self-triggered controllers with Gaussian processes</title><categories>eess.SY cs.SY</categories><comments>submitted to journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the design of self-triggered controllers for
networked control systems (NCSs), where the dynamics of the plant is unknown
apriori. To deal with the unknown transition dynamics, we employ the Gaussian
process (GP) regression in order to learn the dynamics of the plant. To design
the self-triggered controller, we formulate an optimal control problem, such
that the optimal pair of the inter-communication time step and control input
can be determined based on the GP dynamics of the plant. Moreover, we provide
an overall implementation algorithm that jointly learns the dynamics of the
plant and the self-triggered controller based on a reinforcement learning
framework. Finally, a numerical simulation illustrates the effectiveness of the
proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00186</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00186</id><created>2019-08-31</created><authors><author><keyname>Wang</keyname><forenames>Xu</forenames></author><author><keyname>Yang</keyname><forenames>Xin</forenames></author><author><keyname>Dou</keyname><forenames>Haoran</forenames></author><author><keyname>Li</keyname><forenames>Shengli</forenames></author><author><keyname>Heng</keyname><forenames>Pheng-Ann</forenames></author><author><keyname>Ni</keyname><forenames>Dong</forenames></author></authors><title>Joint Segmentation and Landmark Localization of Fetal Femur in
  Ultrasound Volumes</title><categories>eess.IV cs.CV</categories><comments>Accepted by IEEE-EMBS International Conference on Biomedical and
  Health Informatics (BHI), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Volumetric ultrasound has great potentials in promoting prenatal
examinations. Automated solutions are highly desired to efficiently and
effectively analyze the massive volumes. Segmentation and landmark localization
are two key techniques in making the quantitative evaluation of prenatal
ultrasound volumes available in clinic. However, both tasks are non-trivial
when considering the poor image quality, boundary ambiguity and anatomical
variations in volumetric ultrasound. In this paper, we propose an effective
framework for simultaneous segmentation and landmark localization in prenatal
ultrasound volumes. The proposed framework has two branches where informative
cues of segmentation and landmark localization can be propagated
bidirectionally to benefit both tasks. As landmark localization tends to suffer
from false positives, we propose a distance based loss to suppress the noise
and thus enhance the localization map and in turn the segmentation. Finally, we
further leverage an adversarial module to emphasize the correspondence between
segmentation and landmark localization. Extensively validated on a volumetric
ultrasound dataset of fetal femur, our proposed framework proves to be a
promising solution to facilitate the interpretation of prenatal ultrasound
volumes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00211</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00211</id><created>2019-08-31</created><authors><author><keyname>Ahuja</keyname><forenames>Vikas</forenames></author><author><keyname>Neeluru</keyname><forenames>Vijay Kumar</forenames></author></authors><title>Robust BGA Void Detection Using Multi Directional Scan Algorithms</title><categories>eess.IV cs.CV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1907.04222</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The life time of electronic circuits board are impacted by the voids present
in soldering balls. The quality inspection of solder balls by detecting and
measuring the void is important to improve the board yield issues in electronic
circuits. In general, the inspection is carried out manually, based on 2D or 3D
X-ray images. For high quality inspection, it is difficult to detect and
measure voids accurately with high repeatability through the manual inspection
and it is time consuming process. In need of high quality and fast inspection,
various approaches were proposed for void detection. But, lacks in robustness
in dealing with various challenges like vias, reflections from the plating or
vias, inconsistent lighting, noise, void-like artefacts, various void shapes,
low resolution images and scalability to various devices. Robust BGA void
detection becomes quite difficult problem, especially if the image size is very
small (say, around 40x40) and with low contrast between void and the BGA
background (say around 7 intensity levels on a scale of 255). In this work, we
propose novel approach for void detection based on the multi directional
scanning. The proposed approach is able to segment the voids for low resolution
images and can be easily scaled to various electronic manufacturing products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00240</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00240</id><created>2019-08-31</created><authors><author><keyname>Ghani</keyname><forenames>Muhammad Usman</forenames></author><author><keyname>Karl</keyname><forenames>W. Clem</forenames></author></authors><title>Integrating Data and Image Domain Deep Learning for Limited Angle
  Tomography using Consensus Equilibrium</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted for publication in proceedings of IEEE ICCV Workshop on
  Learning for Computational Imaging (ICCVW-LCI)</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Computed Tomography (CT) is a non-invasive imaging modality with applications
ranging from healthcare to security. It reconstructs cross-sectional images of
an object using a collection of projection data collected at different angles.
Conventional methods, such as FBP, require that the projection data be
uniformly acquired over the complete angular range. In some applications, it is
not possible to acquire such data. Security is one such domain where
non-rotational scanning configurations are being developed which violate the
complete data assumption. Conventional methods produce images from such data
that are filled with artifacts. The recent success of deep learning (DL)
methods has inspired researchers to post-process these artifact laden images
using deep neural networks (DNNs). This approach has seen limited success on
real CT problems. Another approach has been to pre-process the incomplete data
using DNNs aiming to avoid the creation of artifacts altogether. Due to
imperfections in the learning process, this approach can still leave
perceptible residual artifacts. In this work, we aim to combine the power of
deep learning in both the data and image domains through a two-step process
based on the consensus equilibrium (CE) framework. Specifically, we use
conditional generative adversarial networks (cGANs) in both the data and the
image domain for enhanced performance and efficient computation and combine
them through a consensus process. We demonstrate the effectiveness of our
approach on a real security CT dataset for a challenging 90 degree
limited-angle problem. The same framework can be applied to other limited data
problems arising in applications such as electron microscopy, non-destructive
evaluation, and medical imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00270</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00270</id><created>2019-08-31</created><authors><author><keyname>Rezaei</keyname><forenames>Safiyeh</forenames></author><author><keyname>Emami</keyname><forenames>Ali</forenames></author><author><keyname>Zarrabi</keyname><forenames>Hamidreza</forenames></author><author><keyname>Rafiei</keyname><forenames>Shima</forenames></author><author><keyname>Najarian</keyname><forenames>Kayvan</forenames></author><author><keyname>Karimi</keyname><forenames>Nader</forenames></author><author><keyname>Samavi</keyname><forenames>Shadrokh</forenames></author><author><keyname>Soroushmehr</keyname><forenames>S. M. Reza</forenames></author></authors><title>Gland Segmentation in Histopathology Images Using Deep Networks and
  Handcrafted Features</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Histopathology images contain essential information for medical diagnosis and
prognosis of cancerous disease. Segmentation of glands in histopathology images
is a primary step for analysis and diagnosis of an unhealthy patient. Due to
the widespread application and the great success of deep neural networks in
intelligent medical diagnosis and histopathology, we propose a modified version
of LinkNet for gland segmentation and recognition of malignant cases. We show
that using specific handcrafted features such as invariant local binary pattern
drastically improves the system performance. The experimental results
demonstrate the competency of the proposed system against state-of-the-art
methods. We achieved the best results in testing on section B images of the
Warwick-QU dataset and obtained comparable results on section A images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00273</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00273</id><created>2019-08-31</created><authors><author><keyname>Sobhaninia</keyname><forenames>Zahra</forenames></author><author><keyname>Rafiei</keyname><forenames>Shima</forenames></author><author><keyname>Emami</keyname><forenames>Ali</forenames></author><author><keyname>Karimi</keyname><forenames>Nader</forenames></author><author><keyname>Najarian</keyname><forenames>Kayvan</forenames></author><author><keyname>Samavi</keyname><forenames>Shadrokh</forenames></author><author><keyname>Soroushmehr</keyname><forenames>S. M. Reza</forenames></author></authors><title>Fetal Ultrasound Image Segmentation for Measuring Biometric Parameters
  Using Multi-Task Deep Learning</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasound imaging is a standard examination during pregnancy that can be
used for measuring specific biometric parameters towards prenatal diagnosis and
estimating gestational age. Fetal head circumference (HC) is one of the
significant factors to determine the fetus growth and health. In this paper, a
multi-task deep convolutional neural network is proposed for automatic
segmentation and estimation of HC ellipse by minimizing a compound cost
function composed of segmentation dice score and MSE of ellipse parameters.
Experimental results on fetus ultrasound dataset in different trimesters of
pregnancy show that the segmentation results and the extracted HC match well
with the radiologist annotations. The obtained dice scores of the fetal head
segmentation and the accuracy of HC evaluations are comparable to the
state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00317</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00317</id><created>2019-08-31</created><authors><author><keyname>Beauchamp</keyname><forenames>Daniel</forenames></author><author><keyname>Chugg</keyname><forenames>Keith M.</forenames></author></authors><title>Machine Learning Based Image Calibration for a Twofold Time-Interleaved
  High Speed DAC</title><categories>eess.IV cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel image calibration algorithm for a twofold
time-interleaved DAC (TIDAC). The algorithm is based on simulated annealing,
which is often used in the field of machine learning to solve derivative free
optimization (DFO) problems. The DAC under consideration is part of a digital
transceiver core that contains a high speed ADC, microcontroller, and digital
control via a serial peripheral interface (SPI). These are used as tools for
designing an algorithm which suppresses the interleave image to the noise
floor. The algorithm is supported with experimental results in silicon on a
10-bit twofold TIDAC operating at a sample rate of 50 GS/s in 14nm CMOS
technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00318</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00318</id><created>2019-08-31</created><authors><author><keyname>Li</keyname><forenames>Weiqiang</forenames></author><author><keyname>Mu</keyname><forenames>Jiatong</forenames></author><author><keyname>Liu</keyname><forenames>Guizhong</forenames></author></authors><title>Multiple Object Tracking with Motion and Appearance Cues</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to better video quality and higher frame rate, the performance of
multiple object tracking issues has been greatly improved in recent years.
However, in real application scenarios, camera motion and noisy per frame
detection results degrade the performance of trackers significantly. High-speed
and high-quality multiple object trackers are still in urgent demand. In this
paper, we propose a new multiple object tracker following the popular
tracking-by-detection scheme. We tackle the camera motion problem with an
optical flow network and utilize an auxiliary tracker to deal with the missing
detection problem. Besides, we use both the appearance and motion information
to improve the matching quality. The experimental results on the VisDrone-MOT
dataset show that our approach can improve the performance of multiple object
tracking significantly while achieving a high efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00319</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00319</id><created>2019-09-01</created><authors><author><keyname>Wu</keyname><forenames>Han</forenames></author><author><keyname>Yang</keyname><forenames>Xueyuan</forenames></author><author><keyname>Yang</keyname><forenames>Yong</forenames></author><author><keyname>Liu</keyname><forenames>Guizhong</forenames></author></authors><title>Flow Guided Short-term Trackers with Cascade Detection for Long-term
  Tracking</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object tracking has been studied for decades, but most of the existing works
are focused on the short-term tracking. For a long sequence, the object is
often fully occluded or out of view for a long time, and existing short-term
object tracking algorithms often lose the target, and it is difficult to
re-catch the target even if it reappears again. In this paper a novel long-term
object tracking algorithm flow_MDNet_RPN is proposed, in which a tracking
result judgement module and a detection module are added to the short-term
object tracking algorithm. Experiments show that the proposed long-term
tracking algorithm is effective to the problem of target disappearance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00329</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00329</id><created>2019-09-01</created><authors><author><keyname>Liu</keyname><forenames>Wanchun</forenames></author><author><keyname>Zang</keyname><forenames>Xin</forenames></author></authors><title>Over-the-Air Computation Systems: Optimization, Analysis and Scaling
  Laws</title><categories>cs.IT eess.SP math.IT</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For future Internet of Things (IoT)-based Big Data applications (e.g., smart
cities/transportation), wireless data collection from ubiquitous massive smart
sensors with limited spectrum bandwidth is very challenging. On the other hand,
to interpret the meaning behind the collected data, it is also challenging for
edge fusion centers running computing tasks over large data sets with limited
computation capacity. To tackle these challenges, by exploiting the
superposition property of a multiple-access channel and the functional
decomposition properties, the recently proposed technique, over-the-air
computation (AirComp), enables an effective joint data collection and
computation from concurrent sensor transmissions. In this paper, we focus on a
single-antenna AirComp system consisting of $K$ sensors and one receiver (i.e.,
the fusion center). We consider an optimization problem to minimize the
computation mean-squared error (MSE) of the $K$ sensors' signals at the
receiver by optimizing the transmitting-receiving (Tx-Rx) policy, under the
peak power constraint of each sensor. Although the problem is not convex, we
derive the computation-optimal policy in closed form. Also, we comprehensively
investigate the ergodic performance of AirComp systems in terms of the average
computation MSE and the average power consumption under Rayleigh fading
channels with different Tx-Rx policies. For the computation-optimal policy, we
prove that its average computation MSE has a decay rate of $O(1/\sqrt{K})$, and
our numerical results illustrate that the policy also has a vanishing average
power consumption with the increasing $K$, which jointly show the computation
effectiveness and the energy efficiency of the policy with a large number of
sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00331</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00331</id><created>2019-09-01</created><authors><author><keyname>Pham</keyname><forenames>Tan Hung</forenames></author><author><keyname>Devalla</keyname><forenames>Sripad Krishna</forenames></author><author><keyname>Ang</keyname><forenames>Aloysius</forenames></author><author><keyname>Da</keyname><forenames>Soh Zhi</forenames></author><author><keyname>Thiery</keyname><forenames>Alexandre H.</forenames></author><author><keyname>Boote</keyname><forenames>Craig</forenames></author><author><keyname>Cheng</keyname><forenames>Ching-Yu</forenames></author><author><keyname>Koh</keyname><forenames>Victor</forenames></author><author><keyname>Girard</keyname><forenames>Michael J. A.</forenames></author></authors><title>Deep Learning Algorithms to Isolate and Quantify the Structures of the
  Anterior Segment in Optical Coherence Tomography Images</title><categories>eess.IV cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Accurate isolation and quantification of intraocular dimensions in the
anterior segment (AS) of the eye using optical coherence tomography (OCT)
images is important in the diagnosis and treatment of many eye diseases,
especially angle closure glaucoma. In this study, we developed a deep
convolutional neural network (DCNN) for the localization of the scleral spur,
and the segmentation of anterior segment structures (iris, corneo-sclera shell,
anterior chamber). With limited training data, the DCNN was able to detect the
scleral spur on unseen ASOCT images as accurately as an experienced
ophthalmologist; and simultaneously isolated the anterior segment structures
with a Dice coefficient of 95.7%. We then automatically extracted eight
clinically relevant ASOCT parameters and proposed an automated quality check
process that asserts the reliability of these parameters. When combined with an
OCT machine capable of imaging multiple radial sections, the algorithms can
provide a more complete objective assessment. This is an essential step toward
providing a robust automated framework for reliable quantification of ASOCT
scans, for applications in the diagnosis and management of angle closure
glaucoma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00341</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00341</id><created>2019-09-01</created><updated>2019-10-23</updated><authors><author><keyname>Amhoud</keyname><forenames>El-Mehdi</forenames></author><author><keyname>Ooi</keyname><forenames>Boon S.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>A Unified Statistical Model for Atmospheric Turbulence-Induced Fading in
  Orbital Angular Momentum Multiplexed FSO Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a unified statistical channel model to characterize the
atmospheric turbulence induced distortions faced by orbital angular momentum
(OAM) in free space optical (FSO) communication systems. In this channel model,
the self-channel irradiance of OAM modes as well as crosstalk irradiances
between different OAM modes are characterized by a Generalized Gamma
distribution (GGD). The latter distribution is shown to provide an excellent
match with simulated data for all regimes of atmospheric turbulence. Therefore,
it can be used to overcome the computationally complex numerical simulations to
model the propagation of OAM modes through atmospheric turbulent FSO channels.
The GGD allows obtaining very simple tractable closed-form expressions for a
variety of performance metrics. Indeed, the average capacity, the bit-error
rate, and the outage probability are derived for FSO systems using single OAM
mode transmission with direct detection. Furthermore, we extend our study to
FSO systems using OAM mode diversity to improve the performance. By using a
maximum ratio combining (MRC) at the receiver, the GGD is also shown to fit the
simulated combined received optical powers. Finally, space-time (ST) coding is
proposed to provide diversity and multiplexing gains, and the error probability
is theoretically derived under the newly proposed generic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00365</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00365</id><created>2019-09-01</created><authors><author><keyname>L.</keyname><forenames>Popov N.</forenames></author><author><keyname>A.</keyname><forenames>Artyukov I.</forenames></author><author><keyname>V.</keyname><forenames>Vinogradov A.</forenames></author><author><keyname>V.</keyname><forenames>Protopopov</forenames><suffix>V</suffix></author></authors><title>Wave packet in the phase problem in optics and ptychography</title><categories>physics.optics eess.IV physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ptychography currently seems the most natural and effective method of
approaching the diffraction limit of optical resolution. Schematic diagram of a
ptychography microscope does not contain refractive or focusing elements. It
includes a source of coherent illumination, a platform for (macroscopic)
movement of the object, and a detector for recording transmitted or reflected
radiation from the object. The detector is connected to a computer that
processes diffraction patterns. In this paper, after a brief introduction to
the history and current state of ptychography, we consider in detail the wave
packet method for calculating the wave field at a detector in the far zone. It
allows to establish the relationship between the fields on the object and the
detector up to a numerical aperture of ~1. Theoretically substantiated formulas
are proposed that determine the size and discretization step of a domain on an
object, for given sizes of detector, pixel and object to detector distance.
Based on these formulas, a comparison with the paraxial approximation for a
point source is performed, as well as modeling of ptychography imaging by the
PIE algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00384</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00384</id><created>2019-09-01</created><authors><author><keyname>Kwak</keyname><forenames>Gloria Hyun-Jung</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author></authors><title>DeepHealth: Deep Learning for Health Informatics</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>48 pages, 19 figures, under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning and deep learning have provided us with an exploration of a
whole new research era. As more data and better computational power become
available, they have been implemented in various fields. The demand for
artificial intelligence in the field of health informatics is also increasing
and we can expect to see the potential benefits of artificial intelligence
applications in healthcare. Deep learning can help clinicians diagnose disease,
identify cancer sites, identify drug effects for each patient, understand the
relationship between genotypes and phenotypes, explore new phenotypes, and
predict infectious disease outbreaks with high accuracy. In contrast to
traditional models, its approach does not require domain-specific data
pre-process, and it is expected that it will ultimately change human life a lot
in the future. Despite its notable advantages, there are some challenges on
data (high dimensionality, heterogeneity, time dependency, sparsity,
irregularity, lack of label) and model (reliability, interpretability,
feasibility, security, scalability) for practical use. This article presents a
comprehensive review of research applying deep learning in health informatics
with a focus on the last five years in the fields of medical imaging,
electronic health records, genomics, sensing, and online communication health,
as well as challenges and promising directions for future research. We
highlight ongoing popular approaches' research and identify several challenges
in building deep learning models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00390</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00390</id><created>2019-09-01</created><updated>2019-09-22</updated><authors><author><keyname>May</keyname><forenames>Philip</forenames></author></authors><title>Improved Image Augmentation for Convolutional Neural Networks by Copyout
  and CopyPairing</title><categories>cs.CV eess.IV</categories><comments>8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image augmentation is a widely used technique to improve the performance of
convolutional neural networks (CNNs). In common image shifting, cropping,
flipping, shearing and rotating are used for augmentation. But there are more
advanced techniques like Cutout and SamplePairing. In this work we present two
improvements of the state-of-the-art Cutout and SamplePairing techniques. Our
new method called Copyout takes a square patch of another random training image
and copies it onto a random location of each image used for training. The
second technique we discovered is called CopyPairing. It combines Copyout and
SamplePairing for further augmentation and even better performance. We apply
different experiments with these augmentation techniques on the CIFAR-10
dataset to evaluate and compare them under different configurations. In our
experiments we show that Copyout reduces the test error rate by 8.18% compared
with Cutout and 4.27% compared with SamplePairing. CopyPairing reduces the test
error rate by 11.97% compared with Cutout and 8.21% compared with
SamplePairing. Copyout and CopyPairing implementations are available at
https://github.com/t-systems-on-site-services-gmbh/coocop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00395</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00395</id><created>2019-09-01</created><authors><author><keyname>Genders</keyname><forenames>Wade</forenames></author><author><keyname>Razavi</keyname><forenames>Saiedeh</forenames></author></authors><title>An Open-Source Framework for Adaptive Traffic Signal Control</title><categories>eess.SY cs.AI cs.LG cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sub-optimal control policies in transportation systems negatively impact
mobility, the environment and human health. Developing optimal transportation
control systems at the appropriate scale can be difficult as cities'
transportation systems can be large, complex and stochastic. Intersection
traffic signal controllers are an important element of modern transportation
infrastructure where sub-optimal control policies can incur high costs to many
users. Many adaptive traffic signal controllers have been proposed by the
community but research is lacking regarding their relative performance
difference - which adaptive traffic signal controller is best remains an open
question. This research contributes a framework for developing and evaluating
different adaptive traffic signal controller models in simulation - both
learning and non-learning - and demonstrates its capabilities. The framework is
used to first, investigate the performance variance of the modelled adaptive
traffic signal controllers with respect to their hyperparameters and second,
analyze the performance differences between controllers with optimal
hyperparameters. The proposed framework contains implementations of some of the
most popular adaptive traffic signal controllers from the literature;
Webster's, Max-pressure and Self-Organizing Traffic Lights, along with deep
Q-network and deep deterministic policy gradient reinforcement learning
controllers. This framework will aid researchers by accelerating their work
from a common starting point, allowing them to generate results faster with
less effort. All framework source code is available at
https://github.com/docwza/sumolights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00419</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00419</id><created>2019-09-01</created><authors><author><keyname>Rakia</keyname><forenames>Tamer</forenames></author><author><keyname>Gebali</keyname><forenames>Fayez</forenames></author><author><keyname>Yang</keyname><forenames>Hong-Chuan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Performance Analysis of Multiuser FSO/RF Network Under Non-Equal
  Priority with $P$-Persistence Protocol</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents and analyzes a novel multiuser network based on hybrid
free-space optical (FSO)/radio-frequency (RF) transmission system, where every
user is serviced by a primary FSO link. When more than one FSO link fail, the
central node services these corresponding users by using a common backup RF
link according to a non-equal priority with $p$ persistence servicing protocol.
A novel discrete-time Markov chain model is developed for the proposed network,
where different transmission rates over both RF and FSO links are assumed. We
investigate the throughput from central node to the user, the average size of
the transmit buffer allocated for every user, the frame queuing delay in the
transmit buffer, the efficiency of the queuing system, the frame loss
probability, and the RF link utilization. The network's users are arranged in
an ascending order. As the order of the failed user increases, the
corresponding performance criteria gets worse due to the non-equal priority
servicing protocol. Numerical examples show that transmitting a data frame with
probability $p$ when using the common backup RF link, achieves considerable
performance improvement that approaches the performance of the multiuser FSO/RF
network when using equal priority protocol to serve all the remote users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00454</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00454</id><created>2019-09-01</created><authors><author><keyname>Bhat</keyname><forenames>Alka</forenames></author><author><keyname>Lu</keyname><forenames>Linjie</forenames></author><author><keyname>Wang</keyname><forenames>Chen-Ho</forenames></author><author><keyname>Vecchio</keyname><forenames>Simon Lo</forenames></author><author><keyname>Maraspini</keyname><forenames>Riccardo</forenames></author><author><keyname>Honigmann</keyname><forenames>Alf</forenames></author><author><keyname>Riveline</keyname><forenames>Daniel</forenames></author></authors><title>How to orient cells in micro-cavities for high resolution imaging of
  cytokinesis and lumen formation</title><categories>q-bio.QM eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Imaging dynamics of cellular morphogenesis with high spatial-temporal
resolution in 3D is challenging, due to the low spatial resolution along the
optical axis and photo-toxicity. However, some cellular structures are planar
and hence 2D imaging should be sufficient, provided that the structure of
interest can be oriented with respect to the optical axis of the microscope.
Here, we report a 3D microfabrication method which positions and orients cell
divisions very close to the microscope coverglass. We use this approach to
study cytokinesis in fission yeasts and polarization to lumen formation in
mammalian epithelial cells. We show that this method improves spatial
resolution on range of common microscopies, including super-resolution STED.
Altogether, this method could shed new lights on self-organization phenomena in
single cells and 3D cell culture systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00478</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00478</id><created>2019-09-01</created><authors><author><keyname>Chen</keyname><forenames>Xihan</forenames></author><author><keyname>Cai</keyname><forenames>Yunlong</forenames></author><author><keyname>Shi</keyname><forenames>Qingjiang</forenames></author><author><keyname>Zhao</keyname><forenames>Min-Jian</forenames></author><author><keyname>Champage</keyname><forenames>Benoit</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Efficient Resource Allocation for Relay-Assisted Computation Offloading
  in Mobile Edge Computing</title><categories>cs.IT eess.SP math.IT</categories><comments>14 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we consider the problem of relay assisted computation
offloading (RACO), in which user A aims to share the results of computational
tasks with another user B through wireless exchange over a relay platform
equipped with mobile edge computing capabilities, referred to as a mobile edge
relay server (MERS). To support the computation offloading, we propose a hybrid
relaying (HR) approach employing two orthogonal frequency bands, where the
amplify-and-forward scheme is used in one band to exchange computational
results, while the decode-and-forward scheme is used in the other band to
transfer the unprocessed tasks. The motivation behind the proposed HR scheme
for RACO is to adapt the allocation of computing and communication resources
both to dynamic user requirements and to diverse computational tasks. Within
this framework, we seek to minimize the weighted sum of the execution delay and
the energy consumption in the RACO system by jointly optimizing the computation
offloading ratio, the bandwidth allocation, the processor speeds, as well as
the transmit power levels of both user $A$ and the MERS, under practical
constraints on the available computing and communication resources. The
resultant problem is formulated as a non-differentiable and nonconvex
optimization program with highly coupled constraints. By adopting a series of
transformations and introducing auxiliary variables, we first convert this
problem into a more tractable yet equivalent form. We then develop an efficient
iterative algorithm for its solution based on the concave-convex procedure. By
exploiting the special structure of this problem, we also propose a simplified
algorithm based on the inexact block coordinate descent method, with reduced
computational complexity. Finally, we present numerical results that illustrate
the advantages of the proposed algorithms over state-of-the-art benchmark
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00482</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00482</id><created>2019-09-01</created><authors><author><keyname>Amrehn</keyname><forenames>Mario</forenames></author><author><keyname>Steidl</keyname><forenames>Stefan</forenames></author><author><keyname>Kortekaas</keyname><forenames>Reinier</forenames></author><author><keyname>Strumia</keyname><forenames>Maddalena</forenames></author><author><keyname>Weingarten</keyname><forenames>Markus</forenames></author><author><keyname>Kowarschik</keyname><forenames>Markus</forenames></author><author><keyname>Maier</keyname><forenames>Andreas</forenames></author></authors><title>A Semi-Automated Usability Evaluation Framework for Interactive Image
  Segmentation Systems</title><categories>cs.HC cs.CV cs.LG eess.IV</categories><comments>Accepted as research article at the International Journal of
  Biomedical Imaging, Hindawi</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For complex segmentation tasks, the achievable accuracy of fully automated
systems is inherently limited. Specifically, when a precise segmentation result
is desired for a small amount of given data sets, semi-automatic methods
exhibit a clear benefit for the user. The optimization of human computer
interaction (HCI) is an essential part of interactive image segmentation.
Nevertheless, publications introducing novel interactive segmentation systems
(ISS) often lack an objective comparison of HCI aspects. It is demonstrated,
that even when the underlying segmentation algorithm is the same throughout
interactive prototypes, their user experience may vary substantially. As a
result, users prefer simple interfaces as well as a considerable degree of
freedom to control each iterative step of the segmentation. In this article, an
objective method for the comparison of ISS is proposed, based on extensive user
studies. A summative qualitative content analysis is conducted via abstraction
of visual and verbal feedback given by the participants. A direct assessment of
the segmentation system is executed by the users via the system usability scale
(SUS) and AttrakDiff-2 questionnaires. Furthermore, an approximation of the
findings regarding usability aspects in those studies is introduced, conducted
solely from the system-measurable user actions during their usage of
interactive segmentation prototypes. The prediction of all questionnaire
results has an average relative error of 8.9%, which is close to the expected
precision of the questionnaire results themselves. This automated evaluation
scheme may significantly reduce the resources necessary to investigate each
variation of a prototype's user interface (UI) features and segmentation
methodologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00508</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00508</id><created>2019-09-01</created><authors><author><keyname>Dahlin</keyname><forenames>Nathan</forenames></author><author><keyname>Jain</keyname><forenames>Rahul</forenames></author></authors><title>A Two-Stage Market Mechanism for Electricity with Renewable Generation</title><categories>cs.GT cs.SY econ.GN eess.SY q-fin.EC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a two stage market mechanism for trading electricity including
renewable generation as an alternative to the widely used multi-settlement
market structure. The two stage market structure allows for recourse decisions
by the market operator, which is not possible in today's markets. We allow for
different generation cost curves in the forward and the real-time stage. We
have considered costs of demand response programs, and black outs but have
ignored network structure for the sake of simplicity. Our first result is to
show existence (by construction) of a sequential competitive equilibrium (SCEq)
in such a two-stage market. We then argue social welfare properties of such an
SCEq. We then design a market mechanism that achieves social welfare
maximization when the market participants are non-strategic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00521</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00521</id><created>2019-09-01</created><updated>2019-10-22</updated><authors><author><keyname>Yu</keyname><forenames>Yue</forenames></author><author><keyname>Peng</keyname><forenames>Siyao</forenames></author><author><keyname>Yang</keyname><forenames>Grace Hui</forenames></author></authors><title>Modeling Long-Range Context for Concurrent Dialogue Acts Recognition</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>Accepted to CIKM '19</comments><doi>10.1145/3357384.3358145</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In dialogues, an utterance is a chain of consecutive sentences produced by
one speaker which ranges from a short sentence to a thousand-word post. When
studying dialogues at the utterance level, it is not uncommon that an utterance
would serve multiple functions. For instance, &quot;Thank you. It works great.&quot;
expresses both gratitude and positive feedback in the same utterance. Multiple
dialogue acts (DA) for one utterance breeds complex dependencies across
dialogue turns. Therefore, DA recognition challenges a model's predictive power
over long utterances and complex DA context. We term this problem Concurrent
Dialogue Acts (CDA) recognition. Previous work on DA recognition either assumes
one DA per utterance or fails to realize the sequential nature of dialogues. In
this paper, we present an adapted Convolutional Recurrent Neural Network (CRNN)
which models the interactions between utterances of long-range context. Our
model significantly outperforms existing work on CDA recognition on a tech
forum dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00524</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00524</id><created>2019-09-01</created><authors><author><keyname>Cheng</keyname><forenames>Junqiang</forenames></author><author><keyname>Gao</keyname><forenames>Hui</forenames></author><author><keyname>Xu</keyname><forenames>Wenjun</forenames></author><author><keyname>Bie</keyname><forenames>Zhisong</forenames></author><author><keyname>Lu</keyname><forenames>Yueming</forenames></author></authors><title>Low-Complexity Linear Equalizers for OTFS Exploiting Two-Dimensional
  Fast Fourier Transform</title><categories>cs.IT eess.SP math.IT</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal time frequency space (OTFS) modulation can effectively convert a
doubly dispersive channel into an almost non-fading channel in the
delay-Doppler domain. However, one critical issue for OTFS is the very high
complexity of equalizers. In this letter, we first reveal the doubly block
circulant feature of OTFS channel represented in the delay-Doppler domain. By
exploiting this unique feature, we further propose zero-forcing (ZF) and
minimum mean squared error (MMSE) equalizers that can be efficiently
implemented with the two-dimensional fast Fourier transform. The complexity of
our proposed equalizers is gracefully reduced from
$\mathcal{O}\left(\left(NM\right)^{3}\right)$ to
$\mathcal{O}\left(NM\mathrm{log_{2}}\left(NM\right)\right)$, where $N$ and $M$
are the number of OTFS symbols and subcarriers, respectively. Analysis and
simulation results show that compared with other existing linear equalizers for
OTFS, our proposed linear equalizers enjoy a much lower computational
complexity without any performance loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00525</identifier>
 <datestamp>2019-09-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00525</id><created>2019-09-01</created><authors><author><keyname>Jia</keyname><forenames>Yiling</forenames></author><author><keyname>Batra</keyname><forenames>Nipun</forenames></author><author><keyname>Wang</keyname><forenames>Hongning</forenames></author><author><keyname>Whitehouse</keyname><forenames>Kamin</forenames></author></authors><title>Active Collaborative Sensing for Energy Breakdown</title><categories>cs.LG eess.SP stat.ML</categories><comments>12 pages, CIKM 2019</comments><doi>10.1145/3357384.3357929</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Residential homes constitute roughly one-fourth of the total energy usage
worldwide. Providing appliance-level energy breakdown has been shown to induce
positive behavioral changes that can reduce energy consumption by 15%. Existing
approaches for energy breakdown either require hardware installation in every
target home or demand a large set of energy sensor data available for model
training. However, very few homes in the world have installed sub-meters
(sensors measuring individual appliance energy); and the cost of retrofitting a
home with extensive sub-metering eats into the funds available for energy
saving retrofits. As a result, strategically deploying sensing hardware to
maximize the reconstruction accuracy of sub-metered readings in
non-instrumented homes while minimizing deployment costs becomes necessary and
promising. In this work, we develop an active learning solution based on
low-rank tensor completion for energy breakdown. We propose to actively deploy
energy sensors to appliances from selected homes, with a goal to improve the
prediction accuracy of the completed tensor with minimum sensor deployment
cost. We empirically evaluate our approach on the largest public energy dataset
collected in Austin, Texas, USA, from 2013 to 2017. The results show that our
approach gives better performance with a fixed number of sensors installed when
compared to the state-of-the-art, which is also proven by our theoretical
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00532</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00532</id><created>2019-09-02</created><authors><author><keyname>Xu</keyname><forenames>Yuanyou</forenames></author><author><keyname>Wang</keyname><forenames>Kaiwei</forenames></author><author><keyname>Yang</keyname><forenames>Kailun</forenames></author><author><keyname>Sun</keyname><forenames>Dongming</forenames></author><author><keyname>Fu</keyname><forenames>Jia</forenames></author></authors><title>Semantic Segmentation of Panoramic Images Using a Synthetic Dataset</title><categories>cs.CV eess.IV</categories><comments>15 pages, 12 figures, SPIE Security + Defence International Symposium</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Panoramic images have advantages in information capacity and scene stability
due to their large field of view (FoV). In this paper, we propose a method to
synthesize a new dataset of panoramic image. We managed to stitch the images
taken from different directions into panoramic images, together with their
labeled images, to yield the panoramic semantic segmentation dataset
denominated as SYNTHIA-PANO. For the purpose of finding out the effect of using
panoramic images as training dataset, we designed and performed a comprehensive
set of experiments. Experimental results show that using panoramic images as
training data is beneficial to the segmentation result. In addition, it has
been shown that by using panoramic images with a 180 degree FoV as training
data the model has better performance. Furthermore, the model trained with
panoramic images also has a better capacity to resist the image distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00539</identifier>
 <datestamp>2020-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00539</id><created>2019-09-02</created><updated>2020-02-10</updated><authors><author><keyname>Behvandi</keyname><forenames>Milad</forenames></author><author><keyname>Havakhah</keyname><forenames>Seyed Jalil</forenames></author><author><keyname>Parvar</keyname><forenames>Mohsen Laleh</forenames></author><author><keyname>Haseli</keyname><forenames>Massih</forenames></author><author><keyname>Suratgar</keyname><forenames>Amirabolfazl</forenames></author></authors><title>Design, fabrication and 3-DOF control of legless capsule robot</title><categories>eess.SY cs.RO cs.SY</categories><comments>currently we are not sure about the performance of controller, we
  will submitted the paper after several tests when the effect of controller
  will be guaranteed</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, a legless capsule robot (capsubot) comprised of a sealed
external body, an internal body, and a rotational actuator is proposed. The aim
of this robot is to move in a two-dimensional viscous environment. After the
robot is designed and modeled, a four-stage angular velocity profile is
proposed to move the robot in one direction. In addition, a camera is used to
obtain the position of the robot in the environment while the orientation and
the velocity of the robot is estimated with Kalman filter by fusing the IMU,
gyro, and the magnetometer sensors. Furthermore, to control the robot a state
feedback control is implemented. Finally, experimental results are provided to
demonstrate the performance of the robots and the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00548</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00548</id><created>2019-09-02</created><authors><author><keyname>Bae</keyname><forenames>Woong</forenames></author><author><keyname>Lee</keyname><forenames>Seungho</forenames></author><author><keyname>Lee</keyname><forenames>Yeha</forenames></author><author><keyname>Park</keyname><forenames>Beomhee</forenames></author><author><keyname>Chung</keyname><forenames>Minki</forenames></author><author><keyname>Jung</keyname><forenames>Kyu-Hwan</forenames></author></authors><title>Resource Optimized Neural Architecture Search for 3D Medical Image
  Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><comments>MICCAI(International Conference on Medical Image Computing and
  Computer Assisted Intervention) 2019 accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural Architecture Search (NAS), a framework which automates the task of
designing neural networks, has recently been actively studied in the field of
deep learning. However, there are only a few NAS methods suitable for 3D
medical image segmentation. Medical 3D images are generally very large; thus it
is difficult to apply previous NAS methods due to their GPU computational
burden and long training time. We propose the resource-optimized neural
architecture search method which can be applied to 3D medical segmentation
tasks in a short training time (1.39 days for 1GB dataset) using a small amount
of computation power (one RTX 2080Ti, 10.8GB GPU memory). Excellent performance
can also be achieved without retraining(fine-tuning) which is essential in most
NAS methods. These advantages can be achieved by using a reinforcement
learning-based controller with parameter sharing and focusing on the optimal
search space configuration of macro search rather than micro search. Our
experiments demonstrate that the proposed NAS method outperforms manually
designed networks with state-of-the-art performance in 3D medical image
segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00553</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00553</id><created>2019-09-02</created><authors><author><keyname>Hong</keyname><forenames>Seokin</forenames></author><author><keyname>Abali</keyname><forenames>Bulent</forenames></author><author><keyname>Buyuktosunoglu</keyname><forenames>Alper</forenames></author><author><keyname>Healy</keyname><forenames>Michael B.</forenames></author><author><keyname>Nair</keyname><forenames>Prashant J.</forenames></author></authors><title>Touch\'e: Towards Ideal and Efficient Cache Compression By Mitigating
  Tag Area Overheads</title><categories>cs.AR cs.DC cs.PF cs.SY eess.SY</categories><comments>Keywords: Compression, Caches, Tag Array, Data Array, Hashing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compression is seen as a simple technique to increase the effective cache
capacity. Unfortunately, compression techniques either incur tag area overheads
or restrict data placement to only include neighboring compressed cache blocks
to mitigate tag area overheads. Ideally, we should be able to place arbitrary
compressed cache blocks without any placement restrictions and tag area
overheads.
  This paper proposes Touch\'e, a framework that enables storing multiple
arbitrary compressed cache blocks within a physical cacheline without any tag
area overheads. The Touch\'e framework consists of three components. The first
component, called the ``Signature'' (SIGN) engine, creates shortened signatures
from the tag addresses of compressed blocks. Due to this, the SIGN engine can
store multiple signatures in each tag entry. On a cache access, the physical
cacheline is accessed only if there is a signature match (which has a
negligible probability of false positive). The second component, called the
``Tag Appended Data'' (TADA) mechanism, stores the full tag addresses with
data. TADA enables Touch\'e to detect false positive signature matches by
ensuring that the actual tag address is available for comparison. The third
component, called the ``Superblock Marker'' (SMARK) mechanism, uses a unique
marker in the tag entry to indicate the occurrence of compressed cache blocks
from neighboring physical addresses in the same cacheline. Touch\'e is
completely hardware-based and achieves an average speedup of 12\% (ideal 13\%)
when compared to an uncompressed baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00582</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00582</id><created>2019-09-02</created><authors><author><keyname>Li</keyname><forenames>Yuzhe</forenames></author><author><keyname>Shi</keyname><forenames>Dawei</forenames></author><author><keyname>Chen</keyname><forenames>Tongwen</forenames></author></authors><title>Secure Analysis of Dynamic Networks under Pinning Attacks against
  Synchronization</title><categories>eess.SY cs.SI cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first consider a pinning node selection and control gain
co-design problem for complex networks. A necessary and sufficient condition
for the synchronization of the pinning controlled networks at a homogeneous
state is provided. A quantitative model is built to describe the pinning costs
and to formulate the pinning node selection and control gain design problem for
different scenarios into the corresponding optimization problems. Algorithms to
solve these problems efficiently are presented. Based on the developed results,
we take the existence of a malicious attacker into consideration and a resource
allocation model for the defender and the malicious attacker is described. We
set up a leader-follower Stackelberg game framework to study the behaviour of
both sides and the equilibrium of this security game is investigated. Numerical
examples and simulations are presented to demonstrate the main results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00612</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00612</id><created>2019-09-02</created><authors><author><keyname>de Almeida</keyname><forenames>Ivo Bizon Franco</forenames></author><author><keyname>Aquino</keyname><forenames>Guilherme Pedro</forenames></author><author><keyname>Mendes</keyname><forenames>Luciano Leonel</forenames></author></authors><title>Iterative Receiver for Non-Orthogonal Waveforms Based on the Sum-Product
  Algorithm</title><categories>eess.SP</categories><comments>Presented at the International Symposium on Wireless Communication
  Systems (ISWCS19) - Workshop: 5G for Remote Areas including the Arctic
  (5G-RAA)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the application of the Sum-Product algorithm (SPA) over factor
graphs, this paper presents a graphical representation of generalized frequency
division multiplexing (GFDM) and filter bank multicarrier with offset QAM
(FBMC-OQAM). FBMC-OQAM was chosen because it has the advantage of reducing the
algorithm's complexity, since it is directly related to the number of possible
values assumed by the transmitted data symbols. The receiver algorithm
performance is evaluated by the bit error ratio (BER) estimation considering
two channel models, additive white Gaussian noise (AWGN) and flat-fading
time-variant (Rayleigh). Likewise, a computational complexity analysis is
presented. Numerical results show that the BER curves of the proposed scheme
present a good match compared with theoretical bit error probability curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00617</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00617</id><created>2019-09-02</created><authors><author><keyname>Al</keyname><forenames>Walid Abdullah</forenames></author><author><keyname>Yun</keyname><forenames>Il Dong</forenames></author><author><keyname>Lee</keyname><forenames>Kyong Joon</forenames></author></authors><title>Reinforcement Learning-based Automatic Diagnosis of Acute Appendicitis
  in Abdominal CT</title><categories>eess.IV cs.CV cs.LG</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acute appendicitis characterized by a painful inflammation of the vermiform
appendix is one of the most common surgical emergencies. Localizing the
appendix is challenging due to its unclear anatomy amidst the complex
colon-structure as observed in the conventional CT views, resulting in a
time-consuming diagnosis. End-to-end learning of a convolutional neural network
(CNN) is also not likely to be useful because of the negligible size of the
appendix compared with the abdominal CT volume. With no prior computational
approaches to the best of our knowledge, we propose the first computerized
automation for acute appendicitis diagnosis. In our approach, we utilize a
reinforcement learning agent deployed in the lower abdominal region to obtain
the appendix location first to reduce the search space for diagnosis. Then, we
obtain the classification scores (i.e., the likelihood of acute appendicitis)
for the local neighborhood around the localized position, using a CNN trained
only on a small appendix patch per volume. From the spatial representation of
the resultant scores, we finally define a region of low-entropy (RLE) to choose
the optimal diagnosis score, which helps improve the classification accuracy
showing robustness even under high appendix localization error cases. In our
experiment with 319 abdominal CT volumes, the proposed RLE-based decision with
prior localization showed significant improvement over the standard CNN-based
diagnosis approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00626</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00626</id><created>2019-09-02</created><authors><author><keyname>Ravanbakhsh</keyname><forenames>Mahdyar</forenames></author><author><keyname>Klein</keyname><forenames>Tassilo</forenames></author><author><keyname>Batmanghelich</keyname><forenames>Kayhan</forenames></author><author><keyname>Nabi</keyname><forenames>Moin</forenames></author></authors><title>Uncertainty-Driven Semantic Segmentation through Human-Machine
  Collaborative Learning</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/rkgnwY04cV</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Deep learning-based approaches achieve state-of-the-art performance in the
majority of image segmentation benchmarks. However, training of such models
requires a sizable amount of manual annotations. In order to reduce this
effort, we propose a method based on conditional Generative Adversarial Network
(cGAN), which addresses segmentation in a semi-supervised setup and in a
human-in-the-loop fashion. More specifically, we use the discriminator to
identify unreliable slices for which expert annotation is required and use the
generator in the GAN to synthesize segmentations on unlabeled data for which
the model is confident. The quantitative results on a conventional standard
benchmark show that our method is comparable with the state-of-the-art fully
supervised methods in slice-level evaluation requiring far less annotated data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00631</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00631</id><created>2019-09-02</created><authors><author><keyname>Idrees</keyname><forenames>Sahar</forenames></author><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>Durrani</keyname><forenames>Salman</forenames></author><author><keyname>Niyato</keyname><forenames>Dusit</forenames></author></authors><title>Design of Ambient Backscatter Training for Retrodirective Wireless Power
  Transfer</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted for possible journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless power transfer (WPT) using energy beamforming is a promising
solution for low power devices in the future Internet of Things (IoT). In this
work, we propose a WPT scenario with a retrodirective antenna at the energy
transmitter (ET) and ambient backscatter at the energy receiver (ER). The
retrodirective WPT at the ET eliminates the requirement of knowing the channel
from the ET to ER, and the use of ambient backscattering (as opposed to active
transmission) minimizes the energy consumption at the ER. We propose a training
sequence design, i.e., the pattern of varying the reflection coefficient at the
ER, to eliminate the direct-link interference from the ambient source. We show
that when the ambient symbol duration is known, the ambient interference is
fully cancelled by using the proposed design. We analytically model the system
and derive a closed-form expression for the average harvested power at the ER,
assuming that the retrodirective array size is large. Our results show that
with practical parameter values, the proposed solution is robust to a small
timing offset mismatch at the correlator and allows the ER to successfully
harvest tens of $\mu$W of power, which is an important improvement for
low-power IoT devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00657</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00657</id><created>2019-09-02</created><authors><author><keyname>Foles</keyname><forenames>Ana</forenames></author><author><keyname>Fialho</keyname><forenames>Luis</forenames></author><author><keyname>Pereira</keyname><forenames>Manuel Collares</forenames></author></authors><title>Economic Evaluation of the Portuguese PV and Energy Storage Residential
  Applications</title><categories>eess.SY cs.SY</categories><comments>39 pages (including list of figures, tables and appendices), 18
  figures, Research paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the residential sector, energy micro-generation and its intelligent
management have been creating novel energy market models, considering new
concepts of energy use and distribution, in which the prosumer has an active
role in the energy generation and its self-consumption. The configuration of
the solar photovoltaic system with a battery energy storage in Portugal is
unclear in the technical, energetic and mostly in the economical point of view.
The energy generation and consumption management, jointly with the battery
operation, have a great influence in the profitability value of the
configuration. The present work evaluates different photovoltaic configurations
with and without energy storage for the normal low voltage C consumer profile,
for a contracted power of 3.45 kVA, to evaluate the cost-effectiveness of the
systems, framed in the regulation in force in Portugal, the decree-law
153/2014, which promotes the micro-generation and self-consumption. The
analysis consists of three different geographical locations in the country,
considering distinct electric tariffs. These are relevant parameters in the
choice of the configuration, concluding that although the solar photovoltaic
system by itself is already economical presently, its integration with battery
energy storage is not in most of the configurations, however it is already
possible to find profitable PV and battery configurations, considering all the
most relevant criteria, and supported by good energy management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00700</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00700</id><created>2019-09-02</created><updated>2019-11-24</updated><authors><author><keyname>Liu</keyname><forenames>Zili</forenames></author><author><keyname>Zheng</keyname><forenames>Tu</forenames></author><author><keyname>Xu</keyname><forenames>Guodong</forenames></author><author><keyname>Yang</keyname><forenames>Zheng</forenames></author><author><keyname>Liu</keyname><forenames>Haifeng</forenames></author><author><keyname>Cai</keyname><forenames>Deng</forenames></author></authors><title>Training-Time-Friendly Network for Real-Time Object Detection</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted to AAAI2020 (8 pages, 3 figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern object detectors can rarely achieve short training time, fast
inference speed, and high accuracy at the same time. To strike a balance among
them, we propose the Training-Time-Friendly Network (TTFNet). In this work, we
start with light-head, single-stage, and anchor-free designs, which enable fast
inference speed. Then, we focus on shortening training time. We notice that
encoding more training samples from annotated boxes plays a similar role as
increasing batch size, which helps enlarge the learning rate and accelerate the
training process. To this end, we introduce a novel approach using Gaussian
kernels to encode training samples. Besides, we design the initiative sample
weights for better information utilization. Experiments on MS COCO show that
our TTFNet has great advantages in balancing training time, inference speed,
and accuracy. It has reduced training time by more than seven times compared to
previous real-time detectors while maintaining state-of-the-art performances.
In addition, our super-fast version of TTFNet-18 and TTFNet-53 can outperform
SSD300 and YOLOv3 by less than one-tenth of their training time, respectively.
The code has been made available at
\url{https://github.com/ZJULearning/ttfnet}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00703</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00703</id><created>2019-09-02</created><authors><author><keyname>Rozumnyi</keyname><forenames>Denys</forenames></author><author><keyname>Cherabier</keyname><forenames>Ian</forenames></author><author><keyname>Pollefeys</keyname><forenames>Marc</forenames></author><author><keyname>Oswald</keyname><forenames>Martin R.</forenames></author></authors><title>Learned Semantic Multi-Sensor Depth Map Fusion</title><categories>cs.CV cs.LG eess.IV</categories><comments>11 pages, 7 figures, 2 tables, accepted for the 2nd Workshop on 3D
  Reconstruction in the Wild (3DRW2019) in conjunction with ICCV2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Volumetric depth map fusion based on truncated signed distance functions has
become a standard method and is used in many 3D reconstruction pipelines. In
this paper, we are generalizing this classic method in multiple ways: 1)
Semantics: Semantic information enriches the scene representation and is
incorporated into the fusion process. 2) Multi-Sensor: Depth information can
originate from different sensors or algorithms with very different noise and
outlier statistics which are considered during data fusion. 3) Scene denoising
and completion: Sensors can fail to recover depth for certain materials and
light conditions, or data is missing due to occlusions. Our method denoises the
geometry, closes holes and computes a watertight surface for every semantic
class. 4) Learning: We propose a neural network reconstruction method that
unifies all these properties within a single powerful framework. Our method
learns sensor or algorithm properties jointly with semantic depth fusion and
scene completion and can also be used as an expert system, e.g. to unify the
strengths of various photometric stereo algorithms. Our approach is the first
to unify all these properties. Experimental evaluations on both synthetic and
real data sets demonstrate clear improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00723</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00723</id><created>2019-09-02</created><authors><author><keyname>Pons-Abenza</keyname><forenames>Alejandro</forenames></author><author><keyname>Garcia-Barcelo</keyname><forenames>Jose-Maria</forenames></author><author><keyname>Romera-Perez</keyname><forenames>Antonio</forenames></author><author><keyname>Alvarez-Melcon</keyname><forenames>Alejandro</forenames></author><author><keyname>Quesada-Pereira</keyname><forenames>Fernando</forenames></author><author><keyname>Hinojosa-Jimenez</keyname><forenames>Juan</forenames></author><author><keyname>Guglielmi</keyname><forenames>Marco</forenames></author><author><keyname>Boria</keyname><forenames>Vicente</forenames></author><author><keyname>Arche-Andradas</keyname><forenames>Lara</forenames></author></authors><title>Design and Implementation of Evanescent Mode Waveguide Filters Using
  Dielectrics and Additive Manufacturing Techniques</title><categories>eess.SP</categories><comments>9 pages, 15 figures</comments><journal-ref>International Journal of Electronics and Communications (AEU),
  Vol. 116, No. 153065, March 2020</journal-ref><doi>10.1016/j.aeue.2020.153065</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution, we describe the design of bandpass filters using
evanescent mode waveguides and dielectric resonators implemented with additive
manufacturing techniques. Two C-band Chebyshev evanescent mode waveguide
filters of order five have been designed using a low cost commercial dielectric
material (ABSplus), widely used by Fused Deposition Modeling (FDM) 3D printers.
The housings of the filters have been manufactured using traditional computer
numerical control (CNC) machining techniques. Practical manufacturing
considerations are also discussed, including the integration of dielectric and
metallic parts. We first discuss two breadboards using two different resonator
geometries. We then demonstrate how different transfer functions can be easily
implemented by changing the 3D printed parts in the same metallic housing.
Breadboards show fractional bandwidths between 3% and 4.6% with return losses
better than RL=18dB, and spurious free ranges of SFR=1GHz. Insertion losses are
better than IL=4.3dB. Even though dielectric losses from the plastic material
are shown to be high, the measured results are quite satisfactory, thereby
clearly showing that this strategy maybe useful for the fast production of low
cost microwave filters implementing complex geometries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00733</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00733</id><created>2019-09-02</created><authors><author><keyname>Naujoks</keyname><forenames>Benjamin</forenames></author><author><keyname>Burger</keyname><forenames>Patrick</forenames></author><author><keyname>Wuensche</keyname><forenames>Hans-Joachim</forenames></author></authors><title>Combining Deep Learning and Model-Based Methods for Robust Real-Time
  Semantic Landmark Detection</title><categories>cs.CV eess.IV</categories><comments>In 22nd International Conference on Information Fusion (FUSION), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compared to abstract features, significant objects, so-called landmarks, are
a more natural means for vehicle localization and navigation, especially in
challenging unstructured environments. The major challenge is to recognize
landmarks in various lighting conditions and changing environment (growing
vegetation) while only having few training samples available. We propose a new
method which leverages Deep Learning as well as model-based methods to overcome
the need of a large data set. Using RGB images and light detection and ranging
(LiDAR) point clouds, our approach combines state-of-the-art classification
results of Convolutional Neural Networks (CNN), with robust model-based methods
by taking prior knowledge of previous time steps into account. Evaluations on a
challenging real-wold scenario, with trees and bushes as landmarks, show
promising results over pure learning-based state-of-the-art 3D detectors, while
being significant faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00735</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00735</id><created>2019-09-02</created><authors><author><keyname>Santini</keyname><forenames>Gianmarco</forenames></author><author><keyname>Moreau</keyname><forenames>No&#xe9;mi</forenames></author><author><keyname>Rubeaux</keyname><forenames>Mathieu</forenames></author></authors><title>Kidney tumor segmentation using an ensembling multi-stage deep learning
  approach. A contribution to the KiTS19 challenge</title><categories>eess.IV cs.CV</categories><comments>11 pages, 4 figures, submitted to MICCAI 2019 - KiTS Challenge</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Precise characterization of the kidney and kidney tumor characteristics is of
outmost importance in the context of kidney cancer treatment, especially for
nephron sparing surgery which requires a precise localization of the tissues to
be removed. The need for accurate and automatic delineation tools is at the
origin of the KiTS19 challenge. It aims at accelerating the research and
development in this field to aid prognosis and treatment planning by providing
a characterized dataset of 300 CT scans to be segmented. To address the
challenge, we proposed an automatic, multi-stage, 2.5D deep learning-based
segmentation approach based on Residual UNet framework. An ensembling operation
is added at the end to combine prediction results from previous stages reducing
the variance between single models. Our neural network segmentation algorithm
reaches a mean Dice score of 0.96 and 0.74 for kidney and kidney tumors,
respectively on 90 unseen test cases. The results obtained are promising and
could be improved by incorporating prior knowledge about the benign cysts that
regularly lower the tumor segmentation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00767</identifier>
 <datestamp>2020-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00767</id><created>2019-09-02</created><updated>2020-02-04</updated><authors><author><keyname>Naujoks</keyname><forenames>Benjamin</forenames></author><author><keyname>Burger</keyname><forenames>Patrick</forenames></author><author><keyname>Wuensche</keyname><forenames>Hans-Joachim</forenames></author></authors><title>Fast 3D Extended Target Tracking using NURBS Surfaces</title><categories>eess.SP</categories><comments>In Proceedings of IEEE Intelligent Transportation Systems Conference
  (ITSC), 2019</comments><doi>10.1109/ITSC.2019.8917384</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes fast and novel methods to jointly estimate the target's
unknown 3D shape and dynamics. Measurements are noisy and sparsely distributed
3D points from a light detection and ranging (LiDAR) sensor. The methods
utilize non-uniform rational B-splines (NURBS) surfaces to approximate the
target's shape. One method estimates Cartesian scaling parameters of a NURBS
surface, whereas the second method estimates the corresponding NURBS weights,
too. Major advantages are the capability of estimating a fully 3D shape as well
as the fast processing time. Real-world evaluations with a static and dynamic
vehicle show promising results compared to state-of-the-art 3D extended target
tracking algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00781</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00781</id><created>2019-09-02</created><authors><author><keyname>Michieli</keyname><forenames>Umberto</forenames></author><author><keyname>Biasetton</keyname><forenames>Matteo</forenames></author><author><keyname>Agresti</keyname><forenames>Gianluca</forenames></author><author><keyname>Zanuttigh</keyname><forenames>Pietro</forenames></author></authors><title>Adversarial Learning and Self-Teaching Techniques for Domain Adaptation
  in Semantic Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><comments>10 pages, 2 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning techniques have been widely used in autonomous driving systems
for the semantic understanding of urban scenes, however they need a huge amount
of labeled data for training, which is difficult and expensive to acquire. A
recently proposed workaround is to train deep networks using synthetic data,
however the domain shift between real world and synthetic representations
limits the performance. In this work a novel unsupervised domain adaptation
strategy is introduced to solve this issue. The proposed learning strategy is
driven by three components: a standard supervised learning loss on labeled
synthetic data, an adversarial learning module that exploits both labeled
synthetic data and unlabeled real data and finally a self-teaching strategy
exploiting unlabeled data. The last component exploits a region growing
framework guided by the segmentation confidence. Furthermore, we weighted this
component on the basis of the class frequencies to enhance the performance on
less common classes. Experimental results prove the effectiveness of the
proposed strategy in adapting a segmentation network trained on synthetic
datasets, like GTA5 and SYNTHIA, to real world datasets like Cityscapes and
Mapillary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00795</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00795</id><created>2019-09-02</created><authors><author><keyname>Nonhoff</keyname><forenames>Marko</forenames></author><author><keyname>K&#xf6;hler</keyname><forenames>Philipp N.</forenames></author><author><keyname>Kohl</keyname><forenames>Anna M.</forenames></author><author><keyname>Pettersen</keyname><forenames>Kristin Y.</forenames></author><author><keyname>Allg&#xf6;wer</keyname><forenames>Frank</forenames></author></authors><title>Economic model predictive control for snake robot locomotion</title><categories>eess.SY cs.SY</categories><comments>Extended version, accepted for IEEE Conference on Decision and
  Control (CDC) 2019. 8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, the control of snake robot locomotion via economic model
predictive control (MPC) is studied. Only very few examples of applications of
MPC to snake robots exist and rigorous proofs for recursive feasibility and
convergence are missing. We propose an economic MPC algorithm that maximizes
the robot's forward velocity and integrates the choice of the gait pattern into
the closed loop. We show recursive feasibility of the MPC optimization problem,
where some of the developed techniques are also applicable for the analysis of
a more general class of system. Besides, we provide performance results and
illustrate the achieved performance by numerical simulations. We thereby show
that the economic MPC algorithm outperforms a standard lateral undulation
controller and achieves constraint satisfaction. Surprisingly, a gait pattern
different to lateral undulation results from the optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00825</identifier>
 <datestamp>2019-11-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00825</id><created>2019-09-02</created><updated>2019-11-02</updated><authors><author><keyname>Zhou</keyname><forenames>Yuhao</forenames></author><author><keyname>Zhao</keyname><forenames>Long</forenames></author><author><keyname>Lee</keyname><forenames>Wei-Jen</forenames></author><author><keyname>Zhang</keyname><forenames>Zhenyuan</forenames></author><author><keyname>Wang</keyname><forenames>Peng</forenames></author></authors><title>Optimal Power Flow in Hybrid AC and Multi-terminal HVDC Networks with
  Offshore Wind Farm Integration Based on Semidefinite Programming</title><categories>eess.SY cs.SY</categories><comments>Accepted in IEEE/PES ISGT Asia 2019 conference (May, 2019), Chengdu,
  China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-terminal high voltage direct current (MTHVDC) technology is a promising
technology for the offshore wind farm integration, which requires the new
control and operation scheme. Therefore, the optimal power flow problem for
this system is important to achieve the optimal economic operation. In this
paper, convex relaxation model based on semidefinite programming for the
MT-HVDC system considering DC/DC converters is proposed to solve the optimal
power flow problem. A hybrid AC and MT-HVDC system for offshore wind farm
integration is used for the test. The simulation results validate the
effectiveness of the proposed model and guarantee that the global optimum
solution is achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00858</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00858</id><created>2019-09-02</created><authors><author><keyname>Haimovich</keyname><forenames>Hernan</forenames></author><author><keyname>Mancilla-Aguilar</keyname><forenames>Jos&#xe9; L.</forenames></author></authors><title>Strong ISS implies strong iISS for time-varying impulsive systems</title><categories>eess.SY cs.SY math.OC</categories><comments>Submitted to Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For time-invariant (nonimpulsive) systems, it is already well-known that the
input-to-state stability (ISS) property is strictly stronger than integral
input-to-state stability (iISS). Very recently, we have shown that under
suitable uniform boundedness and continuity assumptions on the function
defining system dynamics, ISS implies iISS also for time-varying systems. In
this paper, we show that this implication remains true for impulsive systems,
provided that asymptotic stability is understood in a sense stronger than usual
for impulsive systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00864</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00864</id><created>2019-09-02</created><authors><author><keyname>Yuan</keyname><forenames>Jingyi</forenames></author><author><keyname>Weng</keyname><forenames>Yang</forenames></author><author><keyname>Tan</keyname><forenames>Chin-Woo</forenames></author></authors><title>Quantifying Hosting Capacity for Rooftop PV System in LV Distribution
  Grids</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power systems face increasing challenges on reliable operations due to the
widespread distributed generators (DGs), e.g., rooftop PV system in the low
voltage (LV) distribution grids. Characterizing the hosting capacity (HC) is
vital for assessing the total amount of distributed generations that a grid can
hold before upgrading. For analyzing HC, some methods conduct extensive
simulations, lacking theoretical guarantees and can time-consuming. Therefore,
there are also methods employing optimization over all necessary operation
constraints. But, the complexity and inherent non-convexity lead to non-optimal
solutions. To solve these problems, this paper provides a constructive model
for HC determination. Based on geometrically obtained globally optimal HC, we
construct HC solutions sequentially according to realistic constraints, so that
we can obtain optimal solution even with non-convex model. For practical
adaption, we also consider three-phase unbalance condition and parallel
computation to speed-up. We validated our method by extensive numerical results
on IEEE standard systems, such as 8-bus and 123-bus radial distribution grids,
where the global optimums are obtained and performance illustrations are
demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00885</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00885</id><created>2019-09-02</created><updated>2019-09-22</updated><authors><author><keyname>Elimelech</keyname><forenames>Khen</forenames></author><author><keyname>Indelman</keyname><forenames>Vadim</forenames></author></authors><title>Efficient Decision Making and Belief Space Planning using Sparse
  Approximations</title><categories>cs.AI cs.CC cs.IT cs.RO cs.SY eess.SY math.IT</categories><comments>Submitted for peer review in December 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we introduce a new approach for the efficient solution of
autonomous decision and planning problems, with a special focus on decision
making under uncertainty and belief space planning (BSP) in high-dimensional
state spaces. Usually, to solve the decision problem, we identify the optimal
action, according to some objective function. Instead, we claim that we can
sometimes generate and solve an analogous yet simplified decision problem,
which can be solved more efficiently. Furthermore, a wise simplification method
can lead to the same action selection, or one for which the maximal loss can be
guaranteed. This simplification is separated from the state inference, and does
not compromise its accuracy, as the selected action would finally be applied on
the original state. At first, we develop the concept for general decision
problems, and provide a theoretical framework of definitions to allow a
coherent discussion. We then practically apply these ideas to BSP problems, in
which the problem is simplified by considering a sparse approximation of the
initial belief. The scalable sparsification algorithm we provide is able to
yield solutions which are guaranteed to be consistent with the original
problem. We demonstrate the benefits of the approach in the solution of a
highly realistic active-SLAM problem, and manage to significantly reduce
computation time, with practically no loss in the quality of solution. This
rigorous and fundamental work is conceptually novel, and holds numerous
possible extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00906</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00906</id><created>2019-09-02</created><authors><author><keyname>Zhou</keyname><forenames>Yuyin</forenames></author><author><keyname>Li</keyname><forenames>Yingwei</forenames></author><author><keyname>Zhang</keyname><forenames>Zhishuai</forenames></author><author><keyname>Wang</keyname><forenames>Yan</forenames></author><author><keyname>Wang</keyname><forenames>Angtian</forenames></author><author><keyname>Fishman</keyname><forenames>Elliot</forenames></author><author><keyname>Yuille</keyname><forenames>Alan</forenames></author><author><keyname>Park</keyname><forenames>Seyoun</forenames></author></authors><title>Hyper-Pairing Network for Multi-Phase Pancreatic Ductal Adenocarcinoma
  Segmentation</title><categories>eess.IV cs.CV</categories><comments>To appear in MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pancreatic ductal adenocarcinoma (PDAC) is one of the most lethal cancers
with an overall five-year survival rate of 8%. Due to subtle texture changes of
PDAC, pancreatic dual-phase imaging is recommended for better diagnosis of
pancreatic disease. In this study, we aim at enhancing PDAC automatic
segmentation by integrating multi-phase information (i.e., arterial phase and
venous phase). To this end, we present Hyper-Pairing Network (HPN), a 3D fully
convolution neural network which effectively integrates information from
different phases. The proposed approach consists of a dual path network where
the two parallel streams are interconnected with hyper-connections for
intensive information exchange. Additionally, a pairing loss is added to
encourage the commonality between high-level feature representations of
different phases. Compared to prior arts which use single phase data, HPN
reports a significant improvement up to 7.73% (from 56.21% to 63.94%) in terms
of DSC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00907</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00907</id><created>2019-09-02</created><authors><author><keyname>Saputra</keyname><forenames>Yuris Mulya</forenames></author><author><keyname>Hoang</keyname><forenames>Dinh Thai</forenames></author><author><keyname>Nguyen</keyname><forenames>Diep N.</forenames></author><author><keyname>Dutkiewicz</keyname><forenames>Eryk</forenames></author><author><keyname>Mueck</keyname><forenames>Markus Dominik</forenames></author><author><keyname>Srikanteswara</keyname><forenames>Srikathyayani</forenames></author></authors><title>Energy Demand Prediction with Federated Learning for Electric Vehicle
  Networks</title><categories>eess.SP cs.LG</categories><comments>6 pages, 4 figures, the paper has been accepted on IEEE GLOBECOM
  Conference 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose novel approaches using state-of-the-art machine
learning techniques, aiming at predicting energy demand for electric vehicle
(EV) networks. These methods can learn and find the correlation of complex
hidden features to improve the prediction accuracy. First, we propose an energy
demand learning (EDL)-based prediction solution in which a charging station
provider (CSP) gathers information from all charging stations (CSs) and then
performs the EDL algorithm to predict the energy demand for the considered
area. However, this approach requires frequent data sharing between the CSs and
the CSP, thereby driving communication overhead and privacy issues for the EVs
and CSs. To address this problem, we propose a federated energy demand learning
(FEDL) approach which allows the CSs sharing their information without
revealing real datasets. Specifically, the CSs only need to send their trained
models to the CSP for processing. In this case, we can significantly reduce the
communication overhead and effectively protect data privacy for the EV users.
To further improve the effectiveness of the FEDL, we then introduce a novel
clustering-based EDL approach for EV networks by grouping the CSs into clusters
before applying the EDL algorithms. Through experimental results, we show that
our proposed approaches can improve the accuracy of energy demand prediction up
to 24.63% and decrease communication overhead by 83.4% compared with other
baseline machine learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00935</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00935</id><created>2019-09-02</created><authors><author><keyname>Baumann</keyname><forenames>Roland</forenames></author><author><keyname>Malik</keyname><forenames>Khalid Mahmood</forenames></author><author><keyname>Javed</keyname><forenames>Ali</forenames></author><author><keyname>Ball</keyname><forenames>Andersen</forenames></author><author><keyname>Kujawa</keyname><forenames>Brandon</forenames></author><author><keyname>Malik</keyname><forenames>Hafiz</forenames></author></authors><title>Voice Spoofing Detection Corpus for Single and Multi-order Audio Replays</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of modern voice controlled devices (VCDs) in recent years has
revolutionized the Internet of Things, and resulted in increased realization of
smart homes, personalization and home automation through voice commands. The
introduction of VCDs in IoT is expected to give emergence of new subfield of
IoT, called Multimedia of Thing (MoT). These VCDs can be exploited in IoT
driven environment to generate various spoofing attacks including the replays.
Replay attacks are generated through replaying the recorded audio of legitimate
human speaker with the intent of deceiving the VCDs having speaker verification
system. The connectivity among the VCDs can easily be exploited in IoT driven
environment to generate a chain of replay attacks (multi-order replay attacks).
Existing spoofing detection datasets like ASVspoof and ReMASC contain only the
first-order replay recordings against the bonafide audio samples. These
datasets can not offer evaluation of the anti-spoofing algorithms capable of
detecting the multi-order replay attacks. Additionally, these datasets do not
capture the characteristics of microphone arrays, which is an important
characteristic of modern VCDs. We need a diverse replay spoofing detection
corpus that consists of multi-order replay recordings against the bonafide
voice samples. This paper presents a novel voice spoofing detection corpus
(VSDC) to evaluate the performance of multi-order replay anti-spoofing methods.
The proposed VSDC consists of first and second-order-replay samples against the
bonafide audio recordings. Additionally, the proposed VSDC can also be used to
evaluate the performance of speaker verification systems as our corpus includes
the audio samples of fifteen different speakers. To the best of our knowledge,
this is the first publicly available replay spoofing detection corpus
comprising of first-order and second-order-replay samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00936</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00936</id><created>2019-09-02</created><authors><author><keyname>Qing</keyname><forenames>Chaojin</forenames></author><author><keyname>Yang</keyname><forenames>Qingyao</forenames></author><author><keyname>Cai</keyname><forenames>Bin</forenames></author><author><keyname>Pan</keyname><forenames>Borui</forenames></author><author><keyname>Wang</keyname><forenames>Jiafan</forenames></author></authors><title>Superimposed Coding Based CSI Feedback Using 1-Bit Compressed Sensing</title><categories>eess.SP</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a frequency division duplex (FDD) massive multiple input multiple output
(MIMO) system, the channel state information (CSI) feedback causes a
significant bandwidth resource occupation. In order to save the uplink
bandwidth resources, a 1-bit compressed sensing (CS)-based CSI feedback method
assisted by superimposed coding (SC) is proposed. Using 1-bit CS and SC
techniques, the compressed support-set information and downlink CSI (DL-CSI)
are superimposed on the uplink user data sequence (UL-US) and fed back to base
station (BS). Compared with the SC-based feedback, the analysis and simulation
results show that the UL-US's bit error ratio (BER) and the DL-CSI's accuracy
can be improved in the proposed method, without using the exclusive uplink
bandwidth resources to feed DL-CSI back to BS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00941</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00941</id><created>2019-09-02</created><authors><author><keyname>Wollenstein-Betech</keyname><forenames>Salom&#xf3;n</forenames></author><author><keyname>Sun</keyname><forenames>Chuangchuang</forenames></author><author><keyname>Zhang</keyname><forenames>Jing</forenames></author><author><keyname>Paschalidis</keyname><forenames>Ioannis Ch.</forenames></author></authors><title>Joint Estimation of OD Demands and Cost Functions in Transportation
  Networks from Data</title><categories>math.OC cs.SY eess.SY</categories><comments>To appear at the Proceedings of the 58th IEEE Conference on Decision
  and Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing work has tackled the problem of estimating Origin-Destination (OD)
demands and recovering travel latency functions in transportation networks
under the Wardropian assumption. The ultimate objective is to derive an
accurate predictive model of the network to enable optimization and control.
However, these two problems are typically treated separately and estimation is
based on parametric models. In this paper, we propose a method to jointly
recover nonparametric travel latency cost functions and estimate OD demands
using traffic flow data. We formulate the problem as a bilevel optimization
problem and develop an iterative first-order optimization algorithm to solve
it. A numerical example using the Braess Network is presented to demonstrate
the effectiveness of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00952</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00952</id><created>2019-09-03</created><authors><author><keyname>Egilmez</keyname><forenames>Hilmi E.</forenames></author><author><keyname>Chao</keyname><forenames>Yung-Hsuan</forenames></author><author><keyname>Ortega</keyname><forenames>Antonio</forenames></author></authors><title>Graph-based Transforms for Video Coding</title><categories>eess.IV cs.LG cs.MM cs.SY eess.SY stat.AP stat.ML</categories><comments>Submitted to IEEE Trans. on Image Processing (12 pages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many state-of-the-art compression systems, signal transformation is an
integral part of the encoding and decoding process, where transforms provide
compact representations for the signals of interest. This paper introduces a
class of transforms called graph-based transforms (GBTs) for video compression,
and proposes two different techniques to design GBTs. In the first technique,
we formulate an optimization problem to learn graphs from data and provide
solutions for optimal separable and nonseparable GBT designs, called GL-GBTs.
The optimality of the proposed GL-GBTs is also theoretically analyzed based on
Gaussian-Markov random field (GMRF) models for intra and inter predicted block
signals. The second technique develops edge-adaptive GBTs (EA-GBTs) in order to
flexibly adapt transforms to block signals with image edges (discontinuities).
The advantages of EA-GBTs are both theoretically and empirically demonstrated.
Our experimental results demonstrate that the proposed transforms can
significantly outperform the traditional Karhunen-Loeve transform (KLT).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00957</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00957</id><created>2019-09-03</created><authors><author><keyname>Azuatalam</keyname><forenames>Donald</forenames></author><author><keyname>Chapman</keyname><forenames>Archie C.</forenames></author><author><keyname>Verbi&#x10d;</keyname><forenames>Gregor</forenames></author></authors><title>A Turvey-Shapley Value Method for Distribution Network Cost Allocation</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel cost-reflective and computationally efficient
method for allocating distribution network costs to residential customers.
First, the method estimates the growth in peak demand with a 50% probability of
exceedance (50POE) and the associated network augmentation costs using a
probabilistic long-run marginal cost computation based on the Turvey
perturbation method. Second, it allocates these costs to customers on a
cost-causal basis using the Shapley value solution concept. To overcome the
intractability of the exact Shapley value computation for real-world
applications, we implement a fast, scalable and efficient clustering technique
based on customers' peak demand contribution, which drastically reduces the
Shapley value computation time. Using customer load traces from an Australian
smart grid trial (Solar Home Electricity Data), we demonstrate the efficacy of
our method by comparing it with established energy- and peak demand-based cost
allocation approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00971</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00971</id><created>2019-09-03</created><authors><author><keyname>Liu</keyname><forenames>Zeyu</forenames></author><author><keyname>Xie</keyname><forenames>Yaxin</forenames></author><author><keyname>Feng</keyname><forenames>Donghan</forenames></author><author><keyname>Zhou</keyname><forenames>Yun</forenames></author><author><keyname>Shi</keyname><forenames>Shanshan</forenames></author><author><keyname>Fang</keyname><forenames>Chen</forenames></author></authors><title>Load Forecasting Model and Day-ahead Operation Strategy for City-located
  EV Quick Charge Stations</title><categories>eess.SY cs.SY math.OC</categories><comments>This article has been accepted in the 2019 International Conference
  on Renewable Power Generation (RPG 2019), Shanghai, China, October 24-25,
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Charging demands of electric vehicles (EVs) are sharply increasing due to the
rapid development of EVs. Hence, reliable and convenient quick charge stations
are required to respond to the needs of EV drivers. Due to the uncertainty of
EV charging loads, load forecasting becomes vital for the operation of quick
charge stations to formulate the day-ahead plan. In this paper, based on trip
chain theory and EV user behaviour, an EV charging load forecasting model is
established for quick charge station operators. This model is capable of
forecasting the charging demand of a city-located quick charge station during
the next day, where the Monte-Carlo simulation method is applied. Furthermore,
based on the forecasting model, a day-ahead profit-oriented operation strategy
for such stations is derived. The simulation results support the effectiveness
of this forecasting model and the operation strategy. The conclusions of this
paper are as follows: 1) The charging load forecasting model ensures operators
to grasp the feature of the charging load of the next day. 2) The revenue of
the quick charge station can be dramatically increased by applying the proposed
day-head operation strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00972</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.00972</id><created>2019-09-03</created><authors><author><keyname>Zhao</keyname><forenames>Wenxiao</forenames></author><author><keyname>Yin</keyname><forenames>George G.</forenames></author><author><keyname>Bai</keyname><forenames>Er-Wei</forenames></author></authors><title>Sparse System Identification for Stochastic Feedback Control Systems</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Focusing on identification, this paper develops techniques to reconstruct
zero and nonzero elements of a sparse parameter vector of a stochastic dynamic
system under feedback control, for which the current input may depend on the
past inputs and outputs, system noises as well as exogenous dithers. First, a
sparse parameter identification algorithm is introduced based on L2 norm with
L1 regularization, where the adaptive weights are adopted in the optimization
variables of L1 term. Second, estimates generated by the algorithm are shown to
have both set and parameter convergence. That is, sets of the zero and nonzero
elements in the parameter can be correctly identified with probability one
using a finite number of observations, and estimates of the nonzero elements
converge to the true values almost surely. Third, it is shown that the results
are applicable to a large number of applications, including variable selection,
open-loop identification, and closed-loop control of stochastic systems.
Finally, numerical examples are given to support the theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01008</identifier>
 <datestamp>2020-02-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01008</id><created>2019-09-03</created><updated>2020-01-31</updated><authors><author><keyname>Evers</keyname><forenames>Christine</forenames></author><author><keyname>Loellmann</keyname><forenames>Heinrich</forenames></author><author><keyname>Mellmann</keyname><forenames>Heinrich</forenames></author><author><keyname>Schmidt</keyname><forenames>Alexander</forenames></author><author><keyname>Barfuss</keyname><forenames>Hendrik</forenames></author><author><keyname>Naylor</keyname><forenames>Patrick</forenames></author><author><keyname>Kellermann</keyname><forenames>Walter</forenames></author></authors><title>The LOCATA Challenge: Acoustic Source Localization and Tracking</title><categories>eess.AS cs.SD eess.SP</categories><comments>Submitted for review to IEEE/ACM Transactions on Audio, Speech, and
  Language Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to localize and track acoustic events is a fundamental
prerequisite for equipping machines with the ability to be aware of and engage
with humans in their surrounding environment. However, in realistic scenarios,
audio signals are adversely affected by reverberation, noise, interference, and
periods of speech inactivity. In dynamic scenarios, where the sources and
microphone platforms may be moving, the signals are additionally affected by
variations in the source-sensor geometries. In practice, approaches to sound
source localization and tracking are often impeded by missing estimates of
active sources, estimation errors, as well as false estimates. The aim of the
LOCAlization and TrAcking (LOCATA) Challenge is an open-access framework for
the objective evaluation and benchmarking of broad classes of algorithms for
sound source localization and tracking. This paper provides a review of
relevant localization and tracking algorithms and, within the context of the
existing literature, a detailed evaluation and dissemination of the LOCATA
submissions. The evaluation highlights achievements in the field, open
challenges, and identifies potential future directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01015</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01015</id><created>2019-09-03</created><authors><author><keyname>Liu</keyname><forenames>Rang</forenames></author><author><keyname>Li</keyname><forenames>Hongyu</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author><author><keyname>Liu</keyname><forenames>Qian</forenames></author></authors><title>Symbol-Level Precoding Design for Intelligent Reflecting Surface
  Assisted Multi-user MIMO Systems</title><categories>eess.SP</categories><comments>6 pages, 6 figures, WCSP 2019 (Accepted)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surface (IRS) has emerged as a promising solution to
enhance wireless information transmissions by adaptively controlling
prorogation environment. Recently, the brand-new concept of utilizing IRS to
implement a passive transmitter attracts researchers' attention since it
potentially realizes low-complexity and hardware-efficient transmitters of
multiple-input single/multiple-output (MISO/MIMO) systems. In this paper we
investigate the problem of precoder design for a low-resolution IRS-based
transmitter to implement multi-user MISO/MIMO wireless communications.
Particularly, the IRS modulates information symbols by varying the phases of
its reflecting elements and transmits them to K single-antenna or multi-antenna
users. We first aim to design the symbol-level precoder for IRS to realize the
modulation and minimize the maximum symbol-error-rate (SER) of single-antenna
receivers. In order to tackle this NP-hard problem, we first relax the
low-resolution phase-shift constraint and solve this problem by Riemannian
conjugate gradient (RCG) algorithm. Then, the low-resolution symbol-level
precoding vector is obtained by direct quantization. Considering the large
quantization error for 1-bit resolution case, the branch-and-bound method is
utilized to solve the 1-bit resolution symbol-level precoding vector. For
multi-antenna receivers, we propose to iteratively design the symbol-level
precoder and combiner by decomposing the original large-scale optimization
problem into several sub-problems. Simulation results validate the
effectiveness of our proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01019</identifier>
 <datestamp>2020-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01019</id><created>2019-09-03</created><updated>2020-01-30</updated><authors><author><keyname>Kolb&#xe6;k</keyname><forenames>Morten</forenames></author><author><keyname>Tan</keyname><forenames>Zheng-Hua</forenames></author><author><keyname>Jensen</keyname><forenames>S&#xf8;ren Holdt</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author></authors><title>On Loss Functions for Supervised Monaural Time-Domain Speech Enhancement</title><categories>cs.SD cs.LG eess.AS</categories><comments>Published in the IEEE Transactions on Audio, Speech and Language
  Processing</comments><doi>10.1109/TASLP.2020.2968738</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many deep learning-based speech enhancement algorithms are designed to
minimize the mean-square error (MSE) in some transform domain between a
predicted and a target speech signal. However, optimizing for MSE does not
necessarily guarantee high speech quality or intelligibility, which is the
ultimate goal of many speech enhancement algorithms. Additionally, only little
is known about the impact of the loss function on the emerging class of
time-domain deep learning-based speech enhancement systems. We study how
popular loss functions influence the performance of deep learning-based speech
enhancement systems. First, we demonstrate that perceptually inspired loss
functions might be advantageous if the receiver is the human auditory system.
Furthermore, we show that the learning rate is a crucial design parameter even
for adaptive gradient-based optimizers, which has been generally overlooked in
the literature. Also, we found that waveform matching performance metrics must
be used with caution as they in certain situations can fail completely.
Finally, we show that a loss function based on scale-invariant
signal-to-distortion ratio (SI-SDR) achieves good general performance across a
range of popular speech enhancement evaluation metrics, which suggests that
SI-SDR is a good candidate as a general-purpose loss function for speech
enhancement systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01034</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01034</id><created>2019-09-03</created><updated>2019-09-04</updated><authors><author><keyname>Interdonato</keyname><forenames>Giovanni</forenames></author><author><keyname>Karlsson</keyname><forenames>Marcus</forenames></author><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Local Partial Zero-Forcing Precoding for Cell-Free Massive MIMO</title><categories>cs.IT eess.SP math.IT</categories><comments>This paper was submitted for publication in IEEE Transactions on
  Wireless Communications on August 15, 2019. {\copyright} 2019 IEEE. Personal
  use of this material is permitted. Permission from IEEE must be obtained for
  all other uses</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cell-free Massive MIMO (multiple-input multiple-output) is a promising
distributed network architecture for 5G-and-beyond systems. It guarantees
ubiquitous coverage at high spectral efficiency (SE) by leveraging signal
co-processing at multiple access points (APs), aggressive spatial user
multiplexing and extraordinary macro-diversity gain.
  In this study, we propose two distributed precoding schemes, referred to as
\textit{local partial zero-forcing} (PZF) and \textit{local protective partial
zero-forcing} (PPZF), that further improve the spectral efficiency by providing
an adaptable trade-off between interference cancelation and boosting of the
desired signal, with no additional front-hauling overhead, and implementable by
APs with very few antennas.
  We derive closed-form expressions for the achievable SE under the assumption
of independent Rayleigh fading channel, channel estimation error and pilot
contamination. PZF and PPZF can substantially outperform maximum ratio
transmission and zero-forcing, and their performance is comparable to that
achieved by regularized zero-forcing (RZF), which is a benchmark in the
downlink. Importantly, these closed-form expressions can be employed to devise
optimal (long-term) power control strategies that are also suitable for RZF,
whose closed-form expression for the SE is not available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01040</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01040</id><created>2019-09-03</created><authors><author><keyname>Ghosal</keyname><forenames>Koustav</forenames></author><author><keyname>Prasad</keyname><forenames>Mukta</forenames></author><author><keyname>Smolic</keyname><forenames>Aljosa</forenames></author></authors><title>A Geometry-Sensitive Approach for Photographic Style Classification</title><categories>cs.CV cs.LG eess.IV</categories><comments>Irish Machine Vision and Image Processing Conference, Belfast, 2018</comments><journal-ref>Irish Pattern Recognition and Classication Society (iprcs.org)
  2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photographs are characterized by different compositional attributes like the
Rule of Thirds, depth of field, vanishing-lines etc. The presence or absence of
one or more of these attributes contributes to the overall artistic value of an
image. In this work, we analyze the ability of deep learning based methods to
learn such photographic style attributes. We observe that although a standard
CNN learns the texture and appearance based features reasonably well, its
understanding of global and geometric features is limited by two factors.
First, the data-augmentation strategies (cropping, warping, etc.) distort the
composition of a photograph and affect the performance. Secondly, the CNN
features, in principle, are translation-invariant and appearance-dependent. But
some geometric properties important for aesthetics, e.g. the Rule of Thirds
(RoT), are position-dependent and appearance-invariant. Therefore, we propose a
novel input representation which is geometry-sensitive, position-cognizant and
appearance-invariant. We further introduce a two-column CNN architecture that
performs better than the state-of-the-art (SoA) in photographic style
classification. From our results, we observe that the proposed network learns
both the geometric and appearance-based attributes better than the SoA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01067</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01067</id><created>2019-09-03</created><updated>2020-02-24</updated><authors><author><keyname>Naderi</keyname><forenames>Habibeh</forenames></author><author><keyname>Soleimani</keyname><forenames>Behrouz Haji</forenames></author><author><keyname>Matwin</keyname><forenames>Stan</forenames></author></authors><title>Multimodal Deep Learning for Mental Disorders Prediction from Audio
  Speech Samples</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:1811.09362 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Key features of mental illnesses are reflected in speech. Our research
focuses on designing a multimodal deep learning structure that automatically
extracts salient features from recorded speech samples for predicting various
mental disorders including depression, bipolar, and schizophrenia. We adopt a
variety of pre-trained models to extract embeddings from both audio and text
segments. We use several state-of-the-art embedding techniques including BERT,
FastText, and Doc2VecC for the text representation learning and WaveNet and
VGG-ish models for audio encoding. We also leverage huge auxiliary
emotion-labeled text and audio corpora to train emotion-specific embeddings and
use transfer learning in order to address the problem of insufficient annotated
multimodal data available. All these embeddings are then combined into a joint
representation in a multimodal fusion layer and finally a recurrent neural
network is used to predict the mental disorder. Our results show that mental
disorders can be predicted with acceptable accuracy through multimodal analysis
of clinical interviews.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01068</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01068</id><created>2019-09-03</created><authors><author><keyname>Zhou</keyname><forenames>Yanning</forenames></author><author><keyname>Graham</keyname><forenames>Simon</forenames></author><author><keyname>Koohbanani</keyname><forenames>Navid Alemi</forenames></author><author><keyname>Shaban</keyname><forenames>Muhammad</forenames></author><author><keyname>Heng</keyname><forenames>Pheng-Ann</forenames></author><author><keyname>Rajpoot</keyname><forenames>Nasir</forenames></author></authors><title>CGC-Net: Cell Graph Convolutional Network for Grading of Colorectal
  Cancer Histology Images</title><categories>eess.IV cs.CV</categories><comments>Accepted in ICCVW 2019 (Visual Recognition for Medical Images)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colorectal cancer (CRC) grading is typically carried out by assessing the
degree of gland formation within histology images. To do this, it is important
to consider the overall tissue micro-environment by assessing the cell-level
information along with the morphology of the gland. However, current automated
methods for CRC grading typically utilise small image patches and therefore
fail to incorporate the entire tissue micro-architecture for grading purposes.
To overcome the challenges of CRC grading, we present a novel cell-graph
convolutional neural network (CGC-Net) that converts each large histology image
into a graph, where each node is represented by a nucleus within the original
image and cellular interactions are denoted as edges between these nodes
according to node similarity. The CGC-Net utilises nuclear appearance features
in addition to the spatial location of nodes to further boost the performance
of the algorithm. To enable nodes to fuse multi-scale information, we introduce
Adaptive GraphSage, which is a graph convolution technique that combines
multi-level features in a data-driven way. Furthermore, to deal with redundancy
in the graph, we propose a sampling technique that removes nodes in areas of
dense nuclear activity. We show that modeling the image as a graph enables us
to effectively consider a much larger image (around 16$\times$ larger) than
traditional patch-based approaches and model the complex structure of the
tissue micro-environment. We construct cell graphs with an average of over
3,000 nodes on a large CRC histology image dataset and report state-of-the-art
results as compared to recent patch-based as well as contextual patch-based
techniques, demonstrating the effectiveness of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01098</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01098</id><created>2019-09-03</created><authors><author><keyname>Ostertag</keyname><forenames>Cecilia</forenames></author><author><keyname>Beurton-Aimar</keyname><forenames>Marie</forenames></author><author><keyname>Urruty</keyname><forenames>Thierry</forenames></author></authors><title>3DSiameseNet to Analyze Brain MRI</title><categories>eess.IV cs.CV cs.LG</categories><comments>published in ICPRS 2019 conference</comments><msc-class>68</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prediction of the cognitive evolution of a person susceptible to develop a
neurodegenerative disorder is crucial to provide an appropriate treatment as
soon as possible. In this paper we propose a 3D siamese network designed to
extract features from whole-brain 3D MRI images. We show that it is possible to
extract meaningful features using convolution layers, reducing the need of
classical image processing operations such as segmentation or pre-computing
features such as cortical thickness. To lead this study we used the Alzheimer's
Disease Neuroimaging Initiative (ADNI), a public data base of 3D MRI brain
images. A set of 247 subjects has been extracted, all of the subjects having 2
images in a range of 12 months. In order to measure the evolution of the
patients states we have compared these 2 images. Our work has been inspired at
the beginning by an article of Bhagwat et al. in 2018, who have proposed a
siamese network to predict the status of patients but without any convolutional
layers and reducing the MRI images to a vector of features extracted from
predefined ROIs. We show that our network achieves an accuracy of 90\% in the
classification of cognitively declining VS stable patients. This result has
been obtained without the help of a cognitive score and with a small number of
patients comparing to the current datasets size claimed in deep learning
domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01100</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01100</id><created>2019-09-03</created><authors><author><keyname>Wang</keyname><forenames>Jianfeng</forenames></author><author><keyname>Zhou</keyname><forenames>Zhiyong</forenames></author><author><keyname>Yu</keyname><forenames>Jun</forenames></author></authors><title>Statistical inference for block sparsity of complex signals</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Block sparsity is an important parameter in many algorithms to successfully
recover block sparse signals under the framework of compressive sensing.
However, it is often unknown and needs to be estimated. Recently there emerges
a few research work about how to estimate block sparsity of real-valued
signals, while there is, to the best of our knowledge, no investigation that
has been conducted for complex-valued signals. In this paper, we propose a new
method to estimate the block sparsity of complex-valued signal. Its statistical
properties are obtained and verified by simulations. In addition, we
demonstrate the importance of accurately estimating the block sparsity in
signal recovery through a sensitivity analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01106</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01106</id><created>2019-09-03</created><authors><author><keyname>Wang</keyname><forenames>Yida</forenames></author><author><keyname>Tan</keyname><forenames>David Joseph</forenames></author><author><keyname>Navab</keyname><forenames>Nassir</forenames></author><author><keyname>Tombari</keyname><forenames>Federico</forenames></author></authors><title>ForkNet: Multi-branch Volumetric Semantic Completion from a Single Depth
  Image</title><categories>cs.CV cs.CG cs.LG eess.IV</categories><comments>Accepted in International Conference on Computer Vision 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel model for 3D semantic completion from a single depth
image, based on a single encoder and three separate generators used to
reconstruct different geometric and semantic representations of the original
and completed scene, all sharing the same latent space. To transfer information
between the geometric and semantic branches of the network, we introduce paths
between them concatenating features at corresponding network layers. Motivated
by the limited amount of training samples from real scenes, an interesting
attribute of our architecture is the capacity to supplement the existing
dataset by generating a new training dataset with high quality, realistic
scenes that even includes occlusion and real noise. We build the new dataset by
sampling the features directly from latent space which generates a pair of
partial volumetric surface and completed volumetric semantic surface. Moreover,
we utilize multiple discriminators to increase the accuracy and realism of the
reconstructions. We demonstrate the benefits of our approach on standard
benchmarks for the two most common completion tasks: semantic 3D scene
completion and 3D object completion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01108</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01108</id><created>2019-09-03</created><updated>2019-09-03</updated><authors><author><keyname>Wang</keyname><forenames>Siyuan</forenames></author><author><keyname>Lv</keyname><forenames>Junjie</forenames></author><author><keyname>Hu</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Liang</keyname><forenames>Dong</forenames></author><author><keyname>Zhang</keyname><forenames>Minghui</forenames></author><author><keyname>Liu</keyname><forenames>Qiegen</forenames></author></authors><title>Denoising Auto-encoding Priors in Undecimated Wavelet Domain for MR
  Image Reconstruction</title><categories>eess.IV cs.LG stat.ML</categories><comments>10 pages, 11 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing is an impressive approach for fast MRI. It aims at
reconstructing MR image using only a few under-sampled data in k-space,
enhancing the efficiency of the data acquisition. In this study, we propose to
learn priors based on undecimated wavelet transform and an iterative image
reconstruction algorithm. At the stage of prior learning, transformed feature
images obtained by undecimated wavelet transform are stacked as an input of
denoising autoencoder network (DAE). The highly redundant and multi-scale input
enables the correlation of feature images at different channels, which allows a
robust network-driven prior. At the iterative reconstruction, the transformed
DAE prior is incorporated into the classical iterative procedure by the means
of proximal gradient algorithm. Experimental comparisons on different sampling
trajectories and ratios validated the great potential of the presented
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01124</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01124</id><created>2019-09-03</created><authors><author><keyname>Xu</keyname><forenames>Jun</forenames></author><author><keyname>Zhu</keyname><forenames>Pengcheng</forenames></author><author><keyname>Li</keyname><forenames>Jiamin</forenames></author><author><keyname>You</keyname><forenames>Xiaohu</forenames></author></authors><title>Power Minimization for Wireless Backhaul Based Ultra-Dense Cache-enabled
  C-RAN</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This correspondence paper investigates joint design of small base station
(SBS) clustering, multicast beamforming for access and backhaul links, as well
as frequency allocation in backhaul transmission to minimize the total power
consumption for wireless backhaul based ultra-dense cache-enabled cloud radio
access network (C-RAN). To solve this nontrivial problem, we develop a
low-complexity algorithm, which is a combination of smoothed ${\ell
_0}{\text{-norm}}$ approximation and convex-concave procedure. Simulation
results show that the proposed algorithm converges fast and greatly reduces the
backhaul traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01127</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01127</id><created>2019-09-03</created><authors><author><keyname>Luo</keyname><forenames>GuanXiong</forenames></author><author><keyname>Zhao</keyname><forenames>Na</forenames></author><author><keyname>Jiang</keyname><forenames>Wenhao</forenames></author><author><keyname>Cao</keyname><forenames>Peng</forenames></author></authors><title>MRI Reconstruction Using Deep Bayesian Inference</title><categories>cs.CV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To develop a deep learning-based Bayesian inference for MRI
reconstruction. Methods: We modeled the MRI reconstruction problem with Bayes's
theorem, following the recently proposed PixelCNN++ method. The image
reconstruction from incomplete k-space measurement was obtained by maximizing
the posterior possibility. A generative network was utilized as the image
prior, which was computationally tractable, and the k-space data fidelity was
enforced by using an equality constraint. The stochastic backpropagation was
utilized to calculate the descent gradient in the process of maximum a
posterior, and a projected subgradient method was used to impose the equality
constraint. In contrast to the other deep learning reconstruction methods, the
proposed one used the likelihood of prior as the training loss and the
objective function in reconstruction to improve the image quality. Results: The
proposed method showed an improved performance in preserving image details and
reducing aliasing artifacts, compared with GRAPPA, $\ell_1$-ESPRiT, and MODL, a
state-of-the-art deep learning reconstruction method. The proposed method
generally achieved more than 5 dB peak signal-to-noise ratio improvement for
compressed sensing and parallel imaging reconstructions compared with the other
methods. Conclusion: The Bayesian inference significantly improved the
reconstruction performance, compared with the conventional $\ell_1$-sparsity
prior in compressed sensing reconstruction tasks. More importantly, the
proposed reconstruction framework can be generalized for most MRI
reconstruction scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01140</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01140</id><created>2019-09-03</created><authors><author><keyname>Brudfors</keyname><forenames>Mikael</forenames></author><author><keyname>Balbastre</keyname><forenames>Yael</forenames></author><author><keyname>Nachev</keyname><forenames>Parashkev</forenames></author><author><keyname>Ashburner</keyname><forenames>John</forenames></author></authors><title>A Tool for Super-Resolving Multimodal Clinical MRI</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a tool for resolution recovery in multimodal clinical magnetic
resonance imaging (MRI). Such images exhibit great variability, both biological
and instrumental. This variability makes automated processing with neuroimaging
analysis software very challenging. This leaves intelligence extractable only
from large-scale analyses of clinical data untapped, and impedes the
introduction of automated predictive systems in clinical care. The tool
presented in this paper enables such processing, via inference in a generative
model of thick-sliced, multi-contrast MR scans. All model parameters are
estimated from the observed data, without the need for manual tuning. The
model-driven nature of the approach means that no type of training is needed
for applicability to the diversity of MR contrasts present in a clinical
context. We show on simulated data that the proposed approach outperforms
conventional model-based techniques, and on a large hospital dataset of
multimodal MRIs that the tool can successfully super-resolve very thick-sliced
images. The implementation is available from
https://github.com/brudfors/spm_superres.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01145</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01145</id><created>2019-08-30</created><updated>2019-11-18</updated><authors><author><keyname>Liu</keyname><forenames>Peng</forenames></author><author><keyname>Wu</keyname><forenames>Xixin</forenames></author><author><keyname>Kang</keyname><forenames>Shiyin</forenames></author><author><keyname>Li</keyname><forenames>Guangzhi</forenames></author><author><keyname>Su</keyname><forenames>Dan</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>Maximizing Mutual Information for Tacotron</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end speech synthesis methods already achieve close-to-human quality
performance. However compared to HMM-based and NN-based frame-to-frame
regression methods, they are prone to some synthesis errors, such as missing or
repeating words and incomplete synthesis. We attribute the comparatively high
utterance error rate to the local information preference of conditional
autoregressive models, and the ill-posed training objective of the model, which
describes mostly the training status of the autoregressive module, but rarely
that of the condition module. Inspired by InfoGAN, we propose to maximize the
mutual information between the text condition and the predicted acoustic
features to strengthen the dependency between them for CAR speech synthesis
model, which would alleviate the local information preference issue and reduce
the utterance error rate. The training objective of maximizing mutual
information can be considered as a metric of the dependency between the
autoregressive module and the condition module. Experiment results show that
our method can reduce the utterance error rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01148</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01148</id><created>2019-08-29</created><authors><author><keyname>Torres</keyname><forenames>Felipe de Jes&#xfa;s</forenames></author><author><keyname>Arredondo</keyname><forenames>Monserrat Sugey</forenames></author><author><keyname>Martinez</keyname><forenames>Jos&#xe9; Manuel</forenames></author><author><keyname>Ocampo</keyname><forenames>V&#xed;ctor Manuel</forenames></author></authors><title>GNU-Octave Como Alternativa de Simulaci\'on de Sistemas Din\'amicos No
  Lineales en la Ense\~nanza de la Ingenier\'ia</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a proposed alternative to simulate non-linear dynamical
systems. This has an application in bachelor programs like: Electrical and
mechanical engineering, Networks and Telecommunications engineering, Mechanical
engineering and more, than they are taught in several public universities in
Guerrero state. Commonly, the computer devices used for simulations require of
high hardware capacity to support the simulation software. Moreover, the
simulation software in the majority of the cases is under license permission.
For these reasons, implementing a simulation lab in a public university is very
high cost. Thus, we show an alternative by using a commercial development board
Raspberry Pi supporting the GNU-Octave software, which is a free software, to
simulate non-linear dynamical systems like a 4 grades of freedom SCARA robot
and a rotational inverted pendulum. The comparision of the simulated dynamical
models in both the specialized software and the proposed free software, exhibit
the viability of the proposed alternative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01153</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01153</id><created>2019-08-30</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Li</keyname><forenames>Zhi</forenames></author><author><keyname>Chen</keyname><forenames>Liang</forenames></author></authors><title>Dynamic State Estimation of Generators Under Cyber Attacks</title><categories>eess.SY cs.SY eess.SP</categories><comments>Accepted by IEEE Access</comments><journal-ref>IEEE Access 7 (2019) 125253-125267</journal-ref><doi>10.1109/ACCESS.2019.2939055</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate and reliable estimation of generator's dynamic state vectors in real
time are critical to the monitoring and control of power systems. A robust
Cubature Kalman Filter (RCKF) based approach is proposed for dynamic state
estimation (DSE) of generators under cyber attacks in this paper. First, two
types of cyber attacks, namely false data injection and denial of service
attacks, are modelled and thereby introduced into DSE of a generator by mixing
the attack vectors with the measurement data; Second, under cyber attacks with
different degrees of sophistication, the RCKF algorithm and the Cubature Kalman
Filter (CKF) algorithm are adopted to the DSE, and then the two algorithms are
compared and discussed. The novelty of this study lies primarily in our attempt
to introduce cyber attacks into DSE of generators. The simulation results on
the IEEE 9-bus system and the New England 16-machine 68-bus system verify the
effectiveness and superiority of the RCKF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01167</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01167</id><created>2019-09-03</created><authors><author><keyname>Glasser</keyname><forenames>Abraham</forenames></author><author><keyname>Kushalnagar</keyname><forenames>Kesavan</forenames></author><author><keyname>Kushalnagar</keyname><forenames>Raja</forenames></author></authors><title>Feasibility of Using Automatic Speech Recognition with Voices of Deaf
  and Hard-of-Hearing Individuals</title><categories>cs.HC cs.SD eess.AS</categories><comments>2 pages, 3 figures</comments><doi>10.1145/3132525.3134819</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many personal devices have transitioned from visual-controlled interfaces to
speech-controlled interfaces to reduce device costs and interactive friction.
This transition has been hastened by the increasing capabilities of
speech-controlled interfaces, e.g., Amazon Echo or Apple's Siri. A consequence
is that people who are deaf or hard of hearing (DHH) may be unable to use these
speech-controlled devices. We show that deaf speech has a high error rate
compared to hearing speech, in commercial speech-controlled interfaces. Deaf
speech had approximately a 78% word error rate (WER) compared to a hearing
speech 18% WER. Our findings show that current speech-controlled interfaces are
not usable by deaf and hard of hearing people. Therefore, it might be wise to
pursue other methods for deaf persons to deliver natural commands to computers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01170</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01170</id><created>2019-09-03</created><authors><author><keyname>Xing</keyname><forenames>Jiarui</forenames></author><author><keyname>Kamilov</keyname><forenames>Ulugbek</forenames></author><author><keyname>Wu</keyname><forenames>Wenjie</forenames></author><author><keyname>Wang</keyname><forenames>Yong</forenames></author><author><keyname>Zhang</keyname><forenames>Miaomiao</forenames></author></authors><title>Plug-and-Play Priors for Reconstruction-based Placental Image
  Registration</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel deformable registration framework, leveraging an
image prior specified through a denoising function, for severely
noise-corrupted placental images. Recent work on plug-and-play (PnP) priors has
shown the state-of-the-art performance of reconstruction algorithms under such
priors in a range of imaging applications. Integration of powerful image
denoisers into advanced registration methods provides our model with a
flexibility to accommodate datasets that have low signal-to-noise ratios
(SNRs). We demonstrate the performance of our method under a wide variety of
denoising models in the context of diffeomorphic image registration.
Experimental results show that our model substantially improves the accuracy of
spatial alignment in applications of 3D in-utero diffusion-weighted MR images
(DW-MRI) that suffer from low SNR and large spatial transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01173</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01173</id><created>2019-09-03</created><authors><author><keyname>Dardikman</keyname><forenames>Gili</forenames></author><author><keyname>Singh</keyname><forenames>Gyanendra</forenames></author><author><keyname>Shaked</keyname><forenames>Natan T.</forenames></author></authors><title>Four dimensional phase unwrapping of dynamic objects in digital
  holography</title><categories>physics.optics eess.IV</categories><journal-ref>Opt. Express 26, 3772-3778 (2018)</journal-ref><doi>10.1364/OE.26.003772</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new four-dimensional phase unwrapping approach for time-lapse
quantitative phase microscopy, which allows reconstruction of optically thick
objects that are optically thin in a certain temporal point and angular view.
We thus use all four dimensions of the dynamic quantitative phase profile
acquired, including the angular dimension and the temporal dimension, in
addition to the x-y dimensions. We first demonstrate the capabilities of this
algorithm on simulative data, enabling the quantification of the reconstruction
quality relative to both the ground truth and existing unwrapping approaches.
Then, we demonstrate the applicability of the proposed four-dimensional phase
unwrapping algorithm by experimentally capturing a dual-angular dynamic
off-axis hologram with simultaneous recording of two angular views, using
multiplexing of two off-axis holograms into a single multiplexed hologram.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01174</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01174</id><created>2019-09-03</created><authors><author><keyname>D&#xe9;fossez</keyname><forenames>Alexandre</forenames><affiliation>SIERRA, PSL, FAIR</affiliation></author><author><keyname>Usunier</keyname><forenames>Nicolas</forenames><affiliation>FAIR</affiliation></author><author><keyname>Bottou</keyname><forenames>L&#xe9;on</forenames><affiliation>FAIR</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>PSL, DI-ENS, SIERRA</affiliation></author></authors><title>Demucs: Deep Extractor for Music Sources with extra unlabeled data
  remixed</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of source separation for music using deep learning with
four known sources: drums, bass, vocals and other accompaniments.
State-of-the-art approaches predict soft masks over mixture spectrograms while
methods working on the waveform are lagging behind as measured on the standard
MusDB benchmark. Our contribution is two fold. (i) We introduce a simple
convolutional and recurrent model that outperforms the state-of-the-art model
on waveforms, that is, Wave-U-Net, by 1.6 points of SDR (signal to distortion
ratio). (ii) We propose a new scheme to leverage unlabeled music. We train a
first model to extract parts with at least one source silent in unlabeled
tracks, for instance without bass. We remix this extract with a bass line taken
from the supervised dataset to form a new weakly supervised training example.
Combining our architecture and scheme, we show that waveform methods can play
in the same ballpark as spectrogram ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01178</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01178</id><created>2019-09-03</created><authors><author><keyname>Wetteland</keyname><forenames>Rune</forenames></author><author><keyname>Engan</keyname><forenames>Kjersti</forenames></author><author><keyname>Eftest&#xf8;l</keyname><forenames>Trygve</forenames></author><author><keyname>Kvikstad</keyname><forenames>Vebj&#xf8;rn</forenames></author><author><keyname>Janssen</keyname><forenames>Emilius A. M.</forenames></author></authors><title>Multiscale Deep Neural Networks for Multiclass Tissue Classification of
  Histological Whole-Slide Images</title><categories>eess.IV</categories><comments>International Conference on Medical Imaging with Deep Learning
  (MIDL), 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/SyebijnnYN</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Correct treatment of urothelial carcinoma patients is dependent on accurate
grading and staging of the cancer tumour. This is determined manually by a
pathologist by examining the histological whole-slide images (WSI). The large
size of these images makes this a time-consuming and challenging task. The WSI
contain a variety of tissue types, and a method for defining diagnostic
relevant regions would have several advantages for visualization as well as
further input to automated diagnosis systems. We propose an automatic
multiscale method for classification of tiles from WSI of urothelial carcinoma
patients into six classes. Three architectures based on convolutional neural
network (CNN) were tested: MONO-CNN (400x), DI-CNN (100x/400x) and TRI-CNN
(25x/100x/400x). The preliminary results show that the two multiscale models
performed significantly better than the mono-scale model, achieving an F1-score
of 0.986, substantiating that utilising multiple scales in the model aids the
classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01182</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01182</id><created>2019-09-03</created><updated>2020-01-13</updated><authors><author><keyname>Campello</keyname><forenames>V&#xed;ctor M.</forenames></author><author><keyname>Mart&#xed;n-Isla</keyname><forenames>Carlos</forenames></author><author><keyname>Izquierdo</keyname><forenames>Cristian</forenames></author><author><keyname>Petersen</keyname><forenames>Steffen E.</forenames></author><author><keyname>Ballester</keyname><forenames>Miguel A. Gonz&#xe1;lez</forenames></author><author><keyname>Lekadir</keyname><forenames>Karim</forenames></author></authors><title>Combining Multi-Sequence and Synthetic Images for Improved Segmentation
  of Late Gadolinium Enhancement Cardiac MRI</title><categories>eess.IV cs.CV</categories><comments>10 pages, Accepted to MS-CMRSeg Challenge (STACOM 2019), reference
  added and affiliations updated</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate segmentation of the cardiac boundaries in late gadolinium
enhancement magnetic resonance images (LGE-MRI) is a fundamental step for
accurate quantification of scar tissue. However, while there are many solutions
for automatic cardiac segmentation of cine images, the presence of scar tissue
can make the correct delineation of the myocardium in LGE-MRI challenging even
for human experts. As part of the Multi-Sequence Cardiac MR Segmentation
Challenge, we propose a solution for LGE-MRI segmentation based on two
components. First, a generative adversarial network is trained for the task of
modality-to-modality translation between cine and LGE-MRI sequences to obtain
extra synthetic images for both modalities. Second, a deep learning model is
trained for segmentation with different combinations of original, augmented and
synthetic sequences. Our results based on three magnetic resonance sequences
(LGE, bSSFP and T2) from 45 different patients show that the multi-sequence
model training integrating synthetic images and data augmentation improves in
the segmentation over conventional training with real datasets. In conclusion,
the accuracy of the segmentation of LGE-MRI images can be improved by using
complementary information provided by non-contrast MRI sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01206</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01206</id><created>2019-09-03</created><authors><author><keyname>Gudi</keyname><forenames>Amogh</forenames></author><author><keyname>Bittner</keyname><forenames>Marian</forenames></author><author><keyname>Lochmans</keyname><forenames>Roelof</forenames></author><author><keyname>van Gemert</keyname><forenames>Jan</forenames></author></authors><title>Efficient Real-Time Camera Based Estimation of Heart Rate and Its
  Variability</title><categories>cs.CV cs.HC eess.IV</categories><comments>International Conference on Computer Vision (ICCV) Workshop on
  Computer Vision for Physiological Measurement (CVPM) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Remote photo-plethysmography (rPPG) uses a remotely placed camera to
estimating a person's heart rate (HR). Similar to how heart rate can provide
useful information about a person's vital signs, insights about the underlying
physio/psychological conditions can be obtained from heart rate variability
(HRV). HRV is a measure of the fine fluctuations in the intervals between heart
beats. However, this measure requires temporally locating heart beats with a
high degree of precision. We introduce a refined and efficient real-time rPPG
pipeline with novel filtering and motion suppression that not only estimates
heart rate more accurately, but also extracts the pulse waveform to time heart
beats and measure heart rate variability. This method requires no rPPG specific
training and is able to operate in real-time. We validate our method on a
self-recorded dataset under an idealized lab setting, and show state-of-the-art
results on two public dataset with realistic conditions (VicarPPG and PURE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01215</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01215</id><created>2019-09-03</created><authors><author><keyname>Chin</keyname><forenames>Jun-Xing</forenames></author><author><keyname>Bernstein</keyname><forenames>Andrey</forenames></author><author><keyname>Hug</keyname><forenames>Gabriela</forenames></author></authors><title>Aggregating Privacy-Conscious Distributed Energy Resources for Grid
  Service Provision</title><categories>eess.SY cs.SY math.OC</categories><comments>This paper has been submitted for review. The online appendix for
  this paper can be found at https://zenodo.org/record/3384772</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing adoption of advanced metering infrastructure, there are
growing concerns with regards to privacy risks stemming from the high
resolution measurements. This has given rise to consumer privacy protection
techniques that physically alter the consumer's energy load profile in order to
mask private information using localised devices such as batteries or flexible
loads. Meanwhile, there has also been increasing interest in aggregating the
distributed energy resources (DERs) of residential consumers in order to
provide services to the grid. In this paper, we propose a distributed algorithm
to aggregate the DERs of privacy-conscious consumers to provide services to the
grid, whilst preserving the consumers' privacy. Results show that the
optimisation solution from the distributed method converges to one close to the
optimum computed using an ideal centralised solution method, balancing between
grid service provision, consumer preferences and privacy protection. While the
overall performance of the distributed method lags that of a centralised
solution, it preserves the privacy of consumers, and does not require
high-bandwidth two-way communications infrastructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01218</identifier>
 <datestamp>2019-09-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01218</id><created>2019-09-03</created><authors><author><keyname>M&#xfc;ller-Eberstein</keyname><forenames>Maximilian</forenames></author><author><keyname>van Noord</keyname><forenames>Nanne</forenames></author></authors><title>Translating Visual Art into Music</title><categories>cs.CV cs.HC cs.LG cs.SD eess.AS</categories><comments>Accepted for ICCV 2019 Workshop on Fashion, Art and Design</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Synesthetic Variational Autoencoder (SynVAE) introduced in this research
is able to learn a consistent mapping between visual and auditive sensory
modalities in the absence of paired datasets. A quantitative evaluation on
MNIST as well as the Behance Artistic Media dataset (BAM) shows that SynVAE is
capable of retaining sufficient information content during the translation
while maintaining cross-modal latent space consistency. In a qualitative
evaluation trial, human evaluators were furthermore able to match musical
samples with the images which generated them with accuracies of up to 73%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01220</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01220</id><created>2019-08-23</created><authors><author><keyname>Cabacungan</keyname><forenames>Paul M.</forenames></author><author><keyname>Oppus</keyname><forenames>Carlos M.</forenames></author><author><keyname>De Guzman</keyname><forenames>Dr. Jeremie E.</forenames></author><author><keyname>Tangonan</keyname><forenames>Dr. Gregory L.</forenames></author><author><keyname>Culaba</keyname><forenames>Ivan B.</forenames></author><author><keyname>Cabacungan</keyname><forenames>Nerissa G.</forenames></author></authors><title>Intelligent Sensors and Monitoring System for Low-cost Phototherapy
  Light for Jaundice Treatment</title><categories>physics.med-ph eess.SP</categories><comments>6 pages, 4 figures, 1 table, 2019 International Symposium on
  Multimedia and IEEECommunication Technology (ISMAC, Seda Vertis North,
  Diliman, Quezon City, Philippines</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A prototype of a low-cost phototherapy light system (LPLS) was deployed by
the Ateneo Innovation Center (AIC) at a public hospital in Metro Manila,
Philippines. It underwent clinical investigation for two years under the
supervision of licensed physicians in a public tertiary hospital. This paper
presents the process of upgrading the LPLS in order to enhance capabilities and
improve efficiency yet remain affordable. The following features were added:
(1) a visual and auditory monitoring system in order to remotely oversee the
infant from the nurse station; (2) an automation system that stores data about
the device's light intensity and bulb temperature and records ambient humidity;
(3) an alarm system that activates the warning lights if sensor readings are in
critical level and if the bulbs need to be replaced; and (4) a time setting to
manually set the time of operation and automatically turn-off the device as
programmed. The upgrades increased the system's cost but it remained cheaper
than the ones commercially available. For deployment in remote or off-grid
hospitals, the system was equipped with a solar-powering provision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01228</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01228</id><created>2019-09-03</created><authors><author><keyname>Islam</keyname><forenames>Md Nafee Al</forenames></author><author><keyname>Hassan</keyname><forenames>Tanzil Bin</forenames></author><author><keyname>Khan</keyname><forenames>Siamul Karim</forenames></author></authors><title>A CNN-based approach to classify cricket bowlers based on their bowling
  actions</title><categories>cs.CV cs.LG eess.IV</categories><comments>5 pages, 7 figures, The paper is under review in &quot;IEEE International
  Conference on Robotics, Automation, Artificial-Intelligence and
  Internet-of-Things, 2019&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advances in hardware technologies and deep learning techniques, it
has become feasible to apply these techniques in diverse fields. Convolutional
Neural Network (CNN), an architecture from the field of deep learning, has
revolutionized Computer Vision. Sports is one of the avenues in which the use
of computer vision is thriving. Cricket is a complex game consisting of
different types of shots, bowling actions and many other activities. Every
bowler, in a game of cricket, bowls with a different bowling action. We
leverage this point to identify different bowlers. In this paper, we have
proposed a CNN model to identify eighteen different cricket bowlers based on
their bowling actions using transfer learning. Additionally, we have created a
completely new dataset containing 8100 images of these eighteen bowlers to
train the proposed framework and evaluate its performance. We have used the
VGG16 model pre-trained with the ImageNet dataset and added a few layers on top
of it to build our model. After trying out different strategies, we found that
freezing the weights for the first 14 layers of the network and training the
rest of the layers works best. Our approach achieves an overall average
accuracy of 93.3% on the test set and converges to a very low cross-entropy
loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01238</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01238</id><created>2019-09-03</created><authors><author><keyname>Wills</keyname><forenames>Adrian</forenames></author><author><keyname>Sch&#xf6;n</keyname><forenames>Thomas</forenames></author></authors><title>Stochastic quasi-Newton with line-search regularization</title><categories>eess.SY cs.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a novel quasi-Newton algorithm for use in stochastic
optimisation. Quasi-Newton methods have had an enormous impact on deterministic
optimisation problems because they afford rapid convergence and computationally
attractive algorithms. In essence, this is achieved by learning the
second-order (Hessian) information based on observing first-order gradients. We
extend these ideas to the stochastic setting by employing a highly flexible
model for the Hessian and infer its value based on observing noisy gradients.
In addition, we propose a stochastic counterpart to standard line-search
procedures and demonstrate the utility of this combination on maximum
likelihood identification for general nonlinear state space models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01258</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01258</id><created>2019-09-03</created><authors><author><keyname>Bastani</keyname><forenames>Vahid</forenames></author><author><keyname>Campo</keyname><forenames>Damian</forenames></author><author><keyname>Marcenaro</keyname><forenames>Lucio</forenames></author><author><keyname>Regazzoni</keyname><forenames>Carlo S.</forenames></author></authors><title>Online Pedestrian Group Walking Event Detection Using Spectral Analysis
  of Motion Similarity Graph</title><categories>cs.CV eess.IV</categories><comments>Published in: 2015 12th IEEE International Conference on Advanced
  Video and Signal Based Surveillance (AVSS)</comments><doi>10.1109/AVSS.2015.7301744</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for online identification of group of moving objects in the video is
proposed in this paper. This method at each frame identifies group of tracked
objects with similar local instantaneous motion pattern using spectral
clustering on motion similarity graph. Then, the output of the algorithm is
used to detect the event of more than two object moving together as required by
PETS2015 challenge. The performance of the algorithm is evaluated on the
PETS2015 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01265</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01265</id><created>2019-09-03</created><authors><author><keyname>Campo</keyname><forenames>Damian</forenames></author><author><keyname>Bastidas</keyname><forenames>Manuela</forenames></author><author><keyname>Quintero</keyname><forenames>Olga Luc&#xed;a</forenames></author></authors><title>Multiresolution analysis (discrete wavelet transform) through Daubechies
  family for emotion recognition in speech</title><categories>cs.SD eess.AS stat.AP</categories><comments>Published in: Conference, XX Congreso Argentino de Bioingenier\'ia,
  SABI 2015, Octubre 28-30, 2015</comments><doi>10.13140/RG.2.1.5089.1608</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a study of the mathematical properties of voice as an audio
signal. This work includes signals in which the channel conditions are not
ideal for emotion recognition. Multiresolution analysis discrete wavelet
transform was performed through the use of Daubechies Wavelet Family (Db1-Haar,
Db 6, Db8, Db10) allowing the decomposition of the initial audio signal into
sets of coefficients on which a set of features was extracted and analyzed
statistically in order to differentiate emotional states. ANNs proved to be a
system that allows an appropriate classification of such states. This study
shows that the extracted features using wavelet decomposition are enough to
analyze and extract emotional content in audio signals presenting a high
accuracy rate in classification of emotional states without the need to use
other kinds of classical frequency-time features. Accordingly, this paper seeks
to characterize mathematically the six basic emotions in humans: boredom,
disgust, happiness, anxiety, anger and sadness, also included the neutrality,
for a total of seven states to identify.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01283</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01283</id><created>2019-09-03</created><updated>2020-02-22</updated><authors><author><keyname>Mukherjee</keyname><forenames>Moloy</forenames></author><author><keyname>Chaudhuri</keyname><forenames>Dipta</forenames></author><author><keyname>Khondekar</keyname><forenames>Mofazzal H.</forenames></author><author><keyname>Ghosh</keyname><forenames>Koushik</forenames></author></authors><title>Reevaluating the performance of the Double Exponential Smoothing filter
  and its Control Parameters</title><categories>eess.SP</categories><comments>Lots of error are there in the manuscript</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Double Exponential Smoothing (DES) has broad application in various fields
primarily as a forecasting tool. The values of the two smoothing parameters and
, involved in DES, are traditionally chosen by the users which yield minimum
MSE. In this work the authors endeavor to assess the performance of the DES as
a filter and tried to suggest the suitable values of the and for which DES
perform best as a filter. In this regard along with the conventional MSE
method, the dependency of the stability and other aspects associated with the
frequency response of the filter like transfer function, cutoff frequency,
bandwidth and center frequency on the smoothing parameters are also studied.
The values of the parameters close to 0.5 are found to be most appropriate when
DES acts as a filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01288</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01288</id><created>2019-09-03</created><authors><author><keyname>Jiang</keyname><forenames>Junjie</forenames></author><author><keyname>Lai</keyname><forenames>Ying-Cheng</forenames></author></authors><title>Irrelevance of linear controllability to nonlinear dynamical networks</title><categories>math.DS cs.SY eess.SY physics.data-an q-bio.PE</categories><comments>26 pages, 8 figures</comments><doi>10.1038/s41467-019-11822-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been tremendous development of linear controllability of complex
networks. Real-world systems are fundamentally nonlinear. Is linear
controllability relevant to nonlinear dynamical networks? We identify a common
trait underlying both types of control: the nodal &quot;importance.&quot; For nonlinear
and linear control, the importance is determined, respectively, by
physical/biological considerations and the probability for a node to be in the
minimum driver set. We study empirical mutualistic networks and a gene
regulatory network, for which the nonlinear nodal importance can be quantified
by the ability of individual nodes to restore the system from the aftermath of
a tipping-point transition. We find that the nodal importance ranking for
nonlinear and linear control exhibits opposite trends: for the former
large-degree nodes are more important but for the latter, the importance scale
is tilted towards the small-degree nodes, suggesting strongly irrelevance of
linear controllability to these systems. The recent claim of successful
application of linear controllability to C. elegans connectome is examined and
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01289</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01289</id><created>2019-09-03</created><authors><author><keyname>Riaza</keyname><forenames>Ricardo</forenames></author></authors><title>Homogeneous Models of Nonlinear Circuits</title><categories>eess.SY cs.ET cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a general approach to nonlinear circuit modelling aimed
at preserving the intrinsic symmetry of electrical circuits when formulating
reduced models. The goal is to provide a framework accommodating such
reductions in a global manner and without any loss of generality in the working
assumptions; that is, we avoid global hypotheses imposing the existence of a
classical circuit variable controlling each device. Classical (voltage/current
but also flux/charge) models are easily obtained as particular cases of our
general homogeneous model. Our approach extends the results introduced for
linear circuits in a previous paper, by means of a systematic use of global
parametrizations of smooth planar curves. This makes it possible to formulate
reduced models in terms of homogeneous variables also in the nonlinear context:
contrary to voltages and currents (and also to fluxes and charges), homogeneous
variables qualify as state variables in reduced models of uncoupled circuits
without any restriction in the characteristics of devices. The inherent
symmetry of this formalism makes it possible to address in broad generality
certain analytical problems in nonlinear circuit theory, such as the
state-space problem and related issues involving impasse phenomena, as well as
index analyses of differential-algebraic models. Our framework applies also to
circuits with memristors. Several examples illustrate the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01300</identifier>
 <datestamp>2020-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01300</id><created>2019-09-03</created><updated>2020-02-26</updated><authors><author><keyname>Barnes</keyname><forenames>Dan</forenames></author><author><keyname>Gadd</keyname><forenames>Matthew</forenames></author><author><keyname>Murcutt</keyname><forenames>Paul</forenames></author><author><keyname>Newman</keyname><forenames>Paul</forenames></author><author><keyname>Posner</keyname><forenames>Ingmar</forenames></author></authors><title>The Oxford Radar RobotCar Dataset: A Radar Extension to the Oxford
  RobotCar Dataset</title><categories>cs.RO eess.SP</categories><comments>The Oxford Radar RobotCar Dataset Website:
  http://ori.ox.ac.uk/datasets/radar-robotcar-dataset</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present The Oxford Radar RobotCar Dataset, a new dataset for
researching scene understanding using Millimetre-Wave FMCW scanning radar data.
The target application is autonomous vehicles where this modality is robust to
environmental conditions such as fog, rain, snow, or lens flare, which
typically challenge other sensor modalities such as vision and LIDAR.
  The data were gathered in January 2019 over thirty-two traversals of a
central Oxford route spanning a total of 280km of urban driving. It encompasses
a variety of weather, traffic, and lighting conditions. This 4.7TB dataset
consists of over 240,000 scans from a Navtech CTS350-X radar and 2.4 million
scans from two Velodyne HDL-32E 3D LIDARs; along with six cameras, two 2D
LIDARs, and a GPS/INS receiver. In addition we release ground truth optimised
radar odometry to provide an additional impetus to research in this domain. The
full dataset is available for download at:
ori.ox.ac.uk/datasets/radar-robotcar-dataset
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01302</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01302</id><created>2019-09-03</created><updated>2019-09-04</updated><authors><author><keyname>Pan</keyname><forenames>Zihan</forenames></author><author><keyname>Chua</keyname><forenames>Yansong</forenames></author><author><keyname>Wu</keyname><forenames>Jibin</forenames></author><author><keyname>Zhang</keyname><forenames>Malu</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author><author><keyname>Ambikairajah</keyname><forenames>Eliathamby</forenames></author></authors><title>An efficient and perceptually motivated auditory neural encoding and
  decoding algorithm for spiking neural networks</title><categories>cs.SD cs.NE eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Auditory front-end is an integral part of a spiking neural network (SNN) when
performing auditory cognitive tasks. It encodes the temporal dynamic stimulus,
such as speech and audio, into an efficient, effective and reconstructable
spike pattern to facilitate the subsequent processing. However, most of the
auditory front-ends in current studies have not made use of recent findings in
psychoacoustics and physiology concerning human listening. In this paper, we
propose a neural encoding and decoding scheme that is optimized for speech
processing. The neural encoding scheme, that we call Biologically plausible
Auditory Encoding (BAE), emulates the functions of the perceptual components of
the human auditory system, that include the cochlear filter bank, the inner
hair cells, auditory masking effects from psychoacoustic models, and the spike
neural encoding by the auditory nerve. We evaluate the perceptual quality of
the BAE scheme using PESQ; the performance of the BAE based on speech
recognition experiments. Finally, we also built and published two spike-version
of speech datasets: the Spike-TIDIGITS and the Spike-TIMIT, for researchers to
use and benchmarking of future SNN research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01341</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01341</id><created>2019-08-31</created><authors><author><keyname>Jin</keyname><forenames>Jing</forenames></author><author><keyname>Hou</keyname><forenames>Junhui</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Zeng</keyname><forenames>Huanqiang</forenames></author><author><keyname>Kwong</keyname><forenames>Sam</forenames></author><author><keyname>Yu</keyname><forenames>Jingyi</forenames></author></authors><title>Flexible, Fast and Accurate Densely-Sampled Light Field Reconstruction
  Network</title><categories>eess.IV cs.CV</categories><comments>16 pages, 10 figures, 7 tables, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The densely-sampled light field (LF) is highly desirable in various
applications, such as 3-D reconstruction, post-capture refocusing and virtual
reality. However, it is costly to acquire such data. Although many
computational methods have been proposed to reconstruct a densely-sampled LF
from a sparsely-sampled one, they still suffer from either low reconstruction
quality, low computational efficiency, or the restriction on the regularity of
the sampling pattern. To this end, we propose a novel learning-based method,
which accepts sparsely-sampled LFs with irregular structures, and produces
densely-sampled LFs with arbitrary angular resolution accurately and
efficiently. Our proposed method, an end-to-end trainable network, reconstructs
a densely-sampled LF in a coarse-to-fine manner. Specifically, the coarse
sub-aperture image (SAI) synthesis module first explores the scene geometry
from an unstructured sparsely-sampled LF and leverages it to independently
synthesize novel SAIs, giving an intermediate densely-sampled LF. Then, the
efficient LF refinement module learns the angular relations within the
intermediate result to recover the LF parallax structure. Comprehensive
experimental evaluations demonstrate the superiority of our method on both
real-world and synthetic LF images when compared with state-of-the-art methods.
In addition, we illustrate the benefits and advantages of the proposed approach
when applied in various LF-based applications, including image-based rendering,
depth estimation enhancement, and LF compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01359</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01359</id><created>2019-09-03</created><updated>2019-11-29</updated><authors><author><keyname>Carrazza</keyname><forenames>Stefano</forenames></author><author><keyname>Dreyer</keyname><forenames>Fr&#xe9;d&#xe9;ric A.</forenames></author></authors><title>Lund jet images from generative and cycle-consistent adversarial
  networks</title><categories>hep-ph cs.LG eess.IV hep-ex stat.ML</categories><comments>11 pages, 15 figures, code available at
  https://github.com/JetsGame/gLund and https://github.com/JetsGame/CycleJet,
  updated to match published version</comments><report-no>OUTP-19-09P, TIF-UNIMI-2019-14</report-no><doi>10.1140/epjc/s10052-019-7501-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a generative model to simulate radiation patterns within a jet
using the Lund jet plane. We show that using an appropriate neural network
architecture with a stochastic generation of images, it is possible to
construct a generative model which retrieves the underlying two-dimensional
distribution to within a few percent. We compare our model with several
alternative state-of-the-art generative techniques. Finally, we show how a
mapping can be created between different categories of jets, and use this
method to retroactively change simulation settings or the underlying process on
an existing sample. These results provide a framework for significantly
reducing simulation times through fast inference of the neural network as well
as for data augmentation of physical measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01394</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01394</id><created>2019-09-03</created><authors><author><keyname>Shi</keyname><forenames>Luyao</forenames></author><author><keyname>Onofrey</keyname><forenames>John A.</forenames></author><author><keyname>Revilla</keyname><forenames>Enette Mae</forenames></author><author><keyname>Toyonaga</keyname><forenames>Takuya</forenames></author><author><keyname>Menard</keyname><forenames>David</forenames></author><author><keyname>Ankrah</keyname><forenames>Jo-seph</forenames></author><author><keyname>Carson</keyname><forenames>Richard E.</forenames></author><author><keyname>Liu</keyname><forenames>Chi</forenames></author><author><keyname>Lu</keyname><forenames>Yihuan</forenames></author></authors><title>A Novel Loss Function Incorporating Imaging Acquisition Physics for PET
  Attenuation Map Generation using Deep Learning</title><categories>eess.IV cs.CV cs.LG physics.med-ph</categories><comments>Accepted at MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In PET/CT imaging, CT is used for PET attenuation correction (AC). Mismatch
between CT and PET due to patient body motion results in AC artifacts. In
addition, artifact caused by metal, beam-hardening and count-starving in CT
itself also introduces inaccurate AC for PET. Maximum likelihood reconstruction
of activity and attenuation (MLAA) was proposed to solve those issues by
simultaneously reconstructing tracer activity ($\lambda$-MLAA) and attenuation
map ($\mu$-MLAA) based on the PET raw data only. However, $\mu$-MLAA suffers
from high noise and $\lambda$-MLAA suffers from large bias as compared to the
reconstruction using the CT-based attenuation map ($\mu$-CT). Recently, a
convolutional neural network (CNN) was applied to predict the CT attenuation
map ($\mu$-CNN) from $\lambda$-MLAA and $\mu$-MLAA, in which an image-domain
loss (IM-loss) function between the $\mu$-CNN and the ground truth $\mu$-CT was
used. However, IM-loss does not directly measure the AC errors according to the
PET attenuation physics, where the line-integral projection of the attenuation
map ($\mu$) along the path of the two annihilation events, instead of the $\mu$
itself, is used for AC. Therefore, a network trained with the IM-loss may yield
suboptimal performance in the $\mu$ generation. Here, we propose a novel
line-integral projection loss (LIP-loss) function that incorporates the PET
attenuation physics for $\mu$ generation. Eighty training and twenty testing
datasets of whole-body 18F-FDG PET and paired ground truth $\mu$-CT were used.
Quantitative evaluations showed that the model trained with the additional
LIP-loss was able to significantly outperform the model trained solely based on
the IM-loss function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01415</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01415</id><created>2019-09-03</created><authors><author><keyname>Besser</keyname><forenames>Karl-Ludwig</forenames></author><author><keyname>Jorswieck</keyname><forenames>Eduard A.</forenames></author></authors><title>Reliable Communications Over Dependent Fading Wireless Channels</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unreliable fading wireless channels are the main challenge for strict
performance guarantees in mobile communications. Diversity schemes including
massive number of antennas, huge spectrum bands and multi-connectivity links
are applied to improve the outage performance. The success of these approaches
relies heavily on the joint distribution of the underlying fading channels. In
this work, we consider the $\varepsilon$-outage capacity of slowly fading
wireless diversity channels and provide lower and upper bounds for fixed
marginal distributions of the individual channels. This answers the question
about the best and worst case outage probability achievable over $n$ fading
channels with a given distribution, e.g., Rayleigh fading, but not necessarily
statistically independent. Interestingly, the best-case joint distribution
enables achieving a zero-outage capacity greater than zero without channel
state information at the transmitter for $n \geq 2$. Furthermore, the results
are applied to characterize the worst- and best-case joint distribution for
zero-outage capacity with perfect channel state information everywhere. All
results are specialized to Rayleigh fading and compared to the standard
assumption of independent and identically distributed fading component
channels. The results show a significant impact of the joint distribution and
the gap between worst- and best-case can be arbitrarily large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01417</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01417</id><created>2019-09-03</created><authors><author><keyname>Ray</keyname><forenames>Anupama</forenames></author><author><keyname>Kumar</keyname><forenames>Siddharth</forenames></author><author><keyname>Reddy</keyname><forenames>Rutvik</forenames></author><author><keyname>Mukherjee</keyname><forenames>Prerana</forenames></author><author><keyname>Garg</keyname><forenames>Ritu</forenames></author></authors><title>Multi-level Attention network using text, audio and video for Depression
  Prediction</title><categories>cs.CV eess.AS</categories><comments>in Proceedings of the 9th International Workshop on Audio/Visual
  Emotion Challenge, AVEC 2019, ACM Multimedia Workshop, Nice, France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Depression has been the leading cause of mental-health illness worldwide.
Major depressive disorder (MDD), is a common mental health disorder that
affects both psychologically as well as physically which could lead to loss of
lives. Due to the lack of diagnostic tests and subjectivity involved in
detecting depression, there is a growing interest in using behavioural cues to
automate depression diagnosis and stage prediction. The absence of labelled
behavioural datasets for such problems and the huge amount of variations
possible in behaviour makes the problem more challenging. This paper presents a
novel multi-level attention based network for multi-modal depression prediction
that fuses features from audio, video and text modalities while learning the
intra and inter modality relevance. The multi-level attention reinforces
overall learning by selecting the most influential features within each
modality for the decision making. We perform exhaustive experimentation to
create different regression models for audio, video and text modalities.
Several fusions models with different configurations are constructed to
understand the impact of each feature and modality. We outperform the current
baseline by 17.52% in terms of root mean squared error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01419</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01419</id><created>2019-09-03</created><updated>2020-02-21</updated><authors><author><keyname>Haseli</keyname><forenames>Masih</forenames></author><author><keyname>Cort&#xe9;s</keyname><forenames>Jorge</forenames></author></authors><title>Learning Koopman Eigenfunctions and Invariant Subspaces from Data:
  Symmetric Subspace Decomposition</title><categories>eess.SY cs.SY math.DS</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops data-driven methods to identify eigenfunctions of the
Koopman operator associated to a dynamical system and subspaces that are
invariant under the operator. We build on Extended Dynamic Mode Decomposition
(EDMD), a data-driven method that finds a finite-dimensional approximation of
the Koopman operator on the span of a predefined dictionary of functions. We
propose a necessary and sufficient condition to identify Koopman eigenfunctions
based on the application of EDMD forward and backward in time. Checking this
condition requires the comparison of the eigendecomposition of matrices whose
size grows with the size of the dictionary. To address this, we propose the
Symmetric Subspace Decomposition (SSD) algorithm which provably identifies the
maximal Koopman-invariant subspace and the Koopman eigenfunctions in the span
of the dictionary. We also introduce the Streaming Symmetric Subspace
Decomposition (SSSD) algorithm, an online method that only requires a small,
fixed memory and updates its estimate of the invariant subspace as new data is
received. We prove that, given a data set, SSSD and SSD find the same solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01445</identifier>
 <datestamp>2019-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01445</id><created>2019-09-03</created><updated>2019-12-24</updated><authors><author><keyname>Kartik</keyname><forenames>Dhruva</forenames></author><author><keyname>Nayyar</keyname><forenames>Ashutosh</forenames></author></authors><title>Zero-sum Stochastic Games with Asymmetric Information</title><categories>eess.SY cs.GT cs.SY</categories><comments>Accepted for presentation at the 58th Conference on Decision and
  Control (CDC), 2019 Submitted to Dynamic Games and Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general model for zero-sum stochastic games with asymmetric information is
considered. In this model, each player's information at each time can be
divided into a common information part and a private information part. Under
certain conditions on the evolution of the common and private information, a
dynamic programming characterization of the value of the game (if it exists) is
presented. If the value of the zero-sum game does not exist, then the dynamic
program provides bounds on the upper and lower values of the game. This dynamic
program is then used for a class of zero-sum stochastic games with complete
information on one side and partial information on the other, that is, games
where one player has complete information about state, actions and observation
history while the other player may only have partial information about the
state and action history. For such games, it is shown that the value exists and
can be characterized using the dynamic program. It is further shown that for
this class of games, the dynamic program can be used to compute an equilibrium
strategy for the more informed player in which the player selects its action
using its private information and the common information belief.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01469</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01469</id><created>2019-09-03</created><authors><author><keyname>Hashemi</keyname><forenames>Navid</forenames></author><author><keyname>Ruths</keyname><forenames>Justin</forenames></author></authors><title>Generalized chi-squared detector for LTI systems with non-Gaussian noise</title><categories>eess.SY cs.SY</categories><journal-ref>2019 Annual American Control Conference (ACC)</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Previously, we derived exact relationships between the properties of a linear
time-invariant control system and properties of an anomaly detector that
quantified the impact an attacker can have on the system if that attacker aims
to remain stealthy to the detector. A necessary first step in this process is
to be able to precisely tune the detector to a desired level of performance
(false alarm rate) under normal operation, typically through the selection of a
threshold parameter. To-date efforts have only considered Gaussian noises. Here
we generalize the approach to tune a chi-squared anomaly detector for noises
with non-Gaussian distributions. Our method leverages a Gaussian Mixture Model
to represent the arbitrary noise distributions, which preserves analytic
tractability and provides an informative interpretation in terms of a
collection of chi-squared detectors and multiple Gaussian disturbances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01477</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01477</id><created>2019-09-03</created><authors><author><keyname>Hashemi</keyname><forenames>Navid</forenames></author><author><keyname>German</keyname><forenames>Eduardo Verdugo</forenames></author><author><keyname>Ramirez</keyname><forenames>Jonatan Pena</forenames></author><author><keyname>Ruths</keyname><forenames>Justin</forenames></author></authors><title>Filtering Approaches for Dealing with Noise in Anomaly Detection</title><categories>eess.SY cs.SY</categories><journal-ref>2019 IEEE Conference on Decision and Control (CDC)</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The leading workhorse of anomaly (and attack) detection in the literature has
been residual-based detectors, where the residual is the discrepancy between
the observed output provided by the sensors (inclusive of any tampering along
the way) and the estimated output provided by an observer. These techniques
calculate some statistic of the residual and apply a threshold to determine
whether or not to raise an alarm. To date, these methods have not leveraged the
frequency content of the residual signal in making the detection problem
easier, specifically dealing with the case of (e.g., measurement) noise. Here
we demonstrate some opportunities to combine filtering to enhance the
performance of residual-based detectors. We also demonstrate how filtering can
provide a compelling alternative to residual-based methods when paired with a
robust observer. In this process, we consider the class of attacks that are
stealthy, or undetectable, by such filtered detection methods and the impact
they can have on the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01498</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01498</id><created>2019-09-03</created><updated>2020-01-24</updated><authors><author><keyname>Natekar</keyname><forenames>Parth</forenames></author><author><keyname>Kori</keyname><forenames>Avinash</forenames></author><author><keyname>Krishnamurthi</keyname><forenames>Ganapathy</forenames></author></authors><title>Demystifying Brain Tumour Segmentation Networks: Interpretability and
  Uncertainty Analysis</title><categories>eess.IV cs.CV cs.LG q-bio.QM stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The accurate automatic segmentation of gliomas and its intra-tumoral
structures is important not only for treatment planning but also for follow-up
evaluations. Several methods based on 2D and 3D Deep Neural Networks (DNN) have
been developed to segment brain tumors and to classify different categories of
tumors from different MRI modalities. However, these networks are often
black-box models and do not provide any evidence regarding the process they
take to perform this task. Increasing transparency and interpretability of such
deep learning techniques are necessary for the complete integration of such
methods into medical practice. In this paper, we explore various techniques to
explain the functional organization of brain tumor segmentation models and to
extract visualizations of internal concepts to understand how these networks
achieve highly accurate tumor segmentations. We use the BraTS 2018 dataset to
train three different networks with standard architectures and outline
similarities and differences in the process that these networks take to segment
brain tumors. We show that brain tumor segmentation networks learn certain
human-understandable disentangled concepts on a filter level. We also show that
they take a top-down or hierarchical approach to localizing the different parts
of the tumor. We then extract visualizations of some internal feature maps and
also provide a measure of uncertainty with regards to the outputs of the models
to give additional qualitative evidence about the predictions of these
networks. We believe that the emergence of such human-understandable
organization and concepts might aid in the acceptance and integration of such
methods in medical diagnosis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01505</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01505</id><created>2019-09-03</created><authors><author><keyname>Mitra</keyname><forenames>Aritra</forenames></author><author><keyname>Richards</keyname><forenames>John A.</forenames></author><author><keyname>Sundaram</keyname><forenames>Shreyas</forenames></author></authors><title>A Communication-Efficient Algorithm for Exponentially Fast Non-Bayesian
  Learning in Networks</title><categories>eess.SY cs.IT cs.LG cs.SY math.IT</categories><comments>To appear in the Proceedings of the Decision and Control Conference
  (CDC), 2019, to be held in Nice, France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a simple time-triggered protocol to achieve
communication-efficient non-Bayesian learning over a network. Specifically, we
consider a scenario where a group of agents interact over a graph with the aim
of discerning the true state of the world that generates their joint
observation profiles. To address this problem, we propose a novel distributed
learning rule wherein agents aggregate neighboring beliefs based on a
min-protocol, and the inter-communication intervals grow geometrically at a
rate $a \geq 1$. Despite such sparse communication, we show that each agent is
still able to rule out every false hypothesis exponentially fast with
probability $1$, as long as $a$ is finite. For the special case when
communication occurs at every time-step, i.e., when $a=1$, we prove that the
asymptotic learning rates resulting from our algorithm are network-structure
independent, and a strict improvement upon those existing in the literature. In
contrast, when $a&gt;1$, our analysis reveals that the asymptotic learning rates
vary across agents, and exhibit a non-trivial dependence on the network
topology coupled with the relative entropies of the agents' likelihood models.
This motivates us to consider the problem of allocating signal structures to
agents to maximize appropriate performance metrics. In certain special cases,
we show that the eccentricity centrality and the decay centrality of the
underlying graph help identify optimal allocations; for more general scenarios,
we bound the deviation from the optimal allocation as a function of the
parameter $a$, and the diameter of the communication graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01521</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01521</id><created>2019-09-03</created><authors><author><keyname>Xu</keyname><forenames>Dongyang</forenames></author><author><keyname>Ren</keyname><forenames>Pinyi</forenames></author><author><keyname>Wang</keyname><forenames>Yichen</forenames></author><author><keyname>Ritcey</keyname><forenames>James A.</forenames></author></authors><title>Fundamental Tradeoffs in Uplink Grant-Free Multiple Access with
  Protected CSI</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted in The 11th International Conference on. Wireless
  Communications and Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the envisioned 5G, uplink grant-free multiple access will become the
enabler of ultra-reliable low-latency communications (URLLC) services. By
removing the forward scheduling request (SR) and backward scheduling grant
(SG), pilot-based channel estimation and data transmission are launched in
one-shot communications with the aim of maintaining the reliability of
$99.999\% $ or more and latency of 1ms or less under 5G new radio (NR)
numerologies. The problem is that channel estimation can easily suffer from
pilot aware attack which significantly reduces the system reliability. To solve
this, we proposed to apply the hierarchical 2-D feature coding (H2DF) coding on
time-frequency-code domain to safeguard channel state information (CSI), which
informs a fundamental rethinking of reliability, latency and accessibility.
Considering uplink large-scale single-input multiple-output (SIMO) reception of
short packets, we characterize the analytical closed-form expression of
reliability and define the accessibility of system. We find two fundamental
tradeoffs: reliability-latency and reliability-accessibility. With the the help
of the two fundamental trade-offs, we demonstrate how CSI protection could be
integrated into uplink grant-free multiple access to strengthen URLLC services
comprehensively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01524</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01524</id><created>2019-09-03</created><updated>2019-09-05</updated><authors><author><keyname>Jin</keyname><forenames>Dakai</forenames></author><author><keyname>Guo</keyname><forenames>Dazhou</forenames></author><author><keyname>Ho</keyname><forenames>Tsung-Ying</forenames></author><author><keyname>Harrison</keyname><forenames>Adam P.</forenames></author><author><keyname>Xiao</keyname><forenames>Jing</forenames></author><author><keyname>Tseng</keyname><forenames>Chen-kan</forenames></author><author><keyname>Lu</keyname><forenames>Le</forenames></author></authors><title>Accurate Esophageal Gross Tumor Volume Segmentation in PET/CT using
  Two-Stream Chained 3D Deep Network Fusion</title><categories>eess.IV cs.CV</categories><comments>MICCAI 2019 (early accept and oral presentation)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gross tumor volume (GTV) segmentation is a critical step in esophageal cancer
radiotherapy treatment planning. Inconsistencies across oncologists and
prohibitive labor costs motivate automated approaches for this task. However,
leading approaches are only applied to radiotherapy computed tomography (RTCT)
images taken prior to treatment. This limits the performance as RTCT suffers
from low contrast between the esophagus, tumor, and surrounding tissues. In
this paper, we aim to exploit both RTCT and positron emission tomography (PET)
imaging modalities to facilitate more accurate GTV segmentation. By utilizing
PET, we emulate medical professionals who frequently delineate GTV boundaries
through observation of the RTCT images obtained after prescribing radiotherapy
and PET/CT images acquired earlier for cancer staging. To take advantage of
both modalities, we present a two-stream chained segmentation approach that
effectively fuses the CT and PET modalities via early and late 3D
deep-network-based fusion. Furthermore, to effect the fusion and segmentation
we propose a simple yet effective progressive semantically nested network
(PSNN) model that outperforms more complicated models. Extensive 5-fold
cross-validation on 110 esophageal cancer patients, the largest analysis to
date, demonstrates that both the proposed two-stream chained segmentation
pipeline and the PSNN model can significantly improve the quantitative
performance over the previous state-of-the-art work by 11% in absolute Dice
score (DSC) (from 0.654 to 0.764) and, at the same time, reducing the Hausdorff
distance from 129 mm to 47 mm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01526</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01526</id><created>2019-09-03</created><updated>2019-09-05</updated><authors><author><keyname>Jin</keyname><forenames>Dakai</forenames></author><author><keyname>Guo</keyname><forenames>Dazhou</forenames></author><author><keyname>Ho</keyname><forenames>Tsung-Ying</forenames></author><author><keyname>Harrison</keyname><forenames>Adam P.</forenames></author><author><keyname>Xiao</keyname><forenames>Jing</forenames></author><author><keyname>Tseng</keyname><forenames>Chen-kan</forenames></author><author><keyname>Lu</keyname><forenames>Le</forenames></author></authors><title>Deep Esophageal Clinical Target Volume Delineation using Encoded 3D
  Spatial Context of Tumors, Lymph Nodes, and Organs At Risk</title><categories>eess.IV cs.CV</categories><comments>MICCAI 2019 (early accept)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clinical target volume (CTV) delineation from radiotherapy computed
tomography (RTCT) images is used to define the treatment areas containing the
gross tumor volume (GTV) and/or sub-clinical malignant disease for radiotherapy
(RT). High intra- and inter-user variability makes this a particularly
difficult task for esophageal cancer. This motivates automated solutions, which
is the aim of our work. Because CTV delineation is highly context-dependent--it
must encompass the GTV and regional lymph nodes (LNs) while also avoiding
excessive exposure to the organs at risk (OARs)--we formulate it as a deep
contextual appearance-based problem using encoded spatial contexts of these
anatomical structures. This allows the deep network to better learn from and
emulate the margin- and appearance-based delineation performed by human
physicians. Additionally, we develop domain-specific data augmentation to
inject robustness to our system. Finally, we show that a simple 3D progressive
holistically nested network (PHNN), which avoids computationally heavy decoding
paths while still aggregating features at different levels of context, can
outperform more complicated networks. Cross-validated experiments on a dataset
of 135 esophageal cancer patients demonstrate that our encoded spatial context
approach can produce concrete performance improvements, with an average Dice
score of 83.9% and an average surface distance of 4.2 mm, representing
improvements of 3.8% and 2.4 mm, respectively, over the state-of-the-art
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01532</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01532</id><created>2019-09-03</created><authors><author><keyname>Shen</keyname><forenames>Yucong</forenames></author><author><keyname>Zhong</keyname><forenames>Xin</forenames></author><author><keyname>Shih</keyname><forenames>Frank Y.</forenames></author></authors><title>Deep Morphological Neural Networks</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematical morphology is a theory and technique to collect features like
geometric and topological structures in digital images. Given a target image,
determining suitable morphological operations and structuring elements is a
cumbersome and time-consuming task. In this paper, a morphological neural
network is proposed to address this problem. Serving as a nonlinear feature
extracting layer in deep learning frameworks, the efficiency of the proposed
morphological layer is confirmed analytically and empirically. With a known
target, a single-filter morphological layer learns the structuring element
correctly, and an adaptive layer can automatically select appropriate
morphological operations. For practical applications, the proposed
morphological neural networks are tested on several classification datasets
related to shape or geometric image features, and the experimental results have
confirmed the high computational efficiency and high accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01539</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01539</id><created>2019-09-03</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Strohmer</keyname><forenames>Thomas</forenames></author></authors><title>What Happens on the Edge, Stays on the Edge: Toward Compressive Deep
  Learning</title><categories>cs.LG eess.IV stat.ML</categories><comments>14 pages, 4 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning at the edge offers great benefits such as increased privacy
and security, low latency, and more autonomy. However, a major challenge is
that many devices, in particular edge devices, have very limited memory, weak
processors, and scarce energy supply. We propose a hybrid hardware-software
framework that has the potential to significantly reduce the computational
complexity and memory requirements of on-device machine learning. In the first
step, inspired by compressive sensing, data is collected in compressed form
simultaneously with the sensing process. Thus this compression happens already
at the hardware level during data acquisition. But unlike in compressive
sensing, this compression is achieved via a projection operator that is
specifically tailored to the desired machine learning task. The second step
consists of a specially designed and trained deep network. As concrete example
we consider the task of image classification, although the proposed framework
is more widely applicable. An additional benefit of our approach is that it can
be easily combined with existing on-device techniques. Numerical simulations
illustrate the viability of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01557</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01557</id><created>2019-09-04</created><authors><author><keyname>Tavakoli</keyname><forenames>Meysam</forenames></author><author><keyname>Shahri</keyname><forenames>Reza Pourreza</forenames></author><author><keyname>Pourreza</keyname><forenames>Hamidreza</forenames></author><author><keyname>Mehdizadeh</keyname><forenames>Alireza</forenames></author><author><keyname>Banaee</keyname><forenames>Touka</forenames></author><author><keyname>Toosi</keyname><forenames>Mohammad Hosein Bahreini</forenames></author></authors><title>A complementary method for automated detection of microaneurysms in
  fluorescein angiography fundus images to assess diabetic retinopathy</title><categories>physics.med-ph eess.IV</categories><comments>2740-2753</comments><journal-ref>Pattern Recognition, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early detection of microaneurysms (MAs), the first sign of Diabetic
Retinopathy (DR), is an essential first step in automated detection of DR to
prevent vision loss and blindness. This study presents a novel and different
algorithm for automatic detection of MAs in fluorescein angiography (FA) fundus
images, based on Radon transform (RT) and multi-overlapping windows. This
project addresses a novel method, in detection of retinal land marks and
lesions to diagnose the DR. At the first step, optic nerve head (ONH) was
detected and masked. In preprocessing stage, top-hat transformation and
averaging filter were applied to remove the background. In main processing
section, firstly, we divided the whole preprocessed image into sub-images and
then segmented and masked the vascular tree by applying RT in each sub-image.
After detecting and masking retinal vessels and ONH, MAs were detected and
numbered by using RT and appropriated thresholding. The results of the proposed
method were evaluated reported on three different retinal images databases, the
Mashhad Database with 120 FA fundus images, Second Local Database from Tehran
with 50 FA retinal images and a part of Retinopathy Online Challenge (ROC)
database with 22 images. Automated DR detection demonstrated a sensitivity and
specificity of 94% and 75% for Mashhad database and 100% and 70% for the Second
Local Database respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01558</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01558</id><created>2019-09-04</created><updated>2019-10-01</updated><authors><author><keyname>Pourreza-Shahri</keyname><forenames>Reza</forenames></author><author><keyname>Tavakoli</keyname><forenames>Meysam</forenames></author><author><keyname>Kehtarnavaz</keyname><forenames>Nasser</forenames></author></authors><title>Computationally Efficient Optic Nerve Head Detection in Retinal Fundus
  Images</title><categories>physics.med-ph eess.IV</categories><comments>63-73</comments><journal-ref>Biomedical Signal Processing and Control Volume 11, May 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a computationally efficient method for the detection of
optic nerve head in both color fundus and fluorescein angiography images. It
involves a combination of Radon transformation and multi-overlapping windows
within an optimization framework in order to achieve a robust detection in the
presence of various structural, color, and intensity variations in such images.
Three databases have been examined and it is shown that the introduced method
provides high detection rates while achieving faster proceeding rates than the
existing algorithms that possess comparable detection rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01585</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01585</id><created>2019-09-04</created><authors><author><keyname>Noyel</keyname><forenames>Guillaume</forenames><affiliation>IPRI, SIGPH@iPRI</affiliation></author><author><keyname>Jourlin</keyname><forenames>Michel</forenames><affiliation>UJM</affiliation></author></authors><title>Functional Asplund's metrics for pattern matching robust to variable
  lighting conditions</title><categories>cs.CV cs.NA eess.SP math.FA math.NA</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a complete framework to process images captured
under uncontrolled lighting and especially under low lighting. By taking
advantage of the Logarithmic Image Processing (LIP) context, we study two novel
functional metrics: i) the LIP-multiplicative Asplund's metric which is robust
to object absorption variations and ii) the LIP-additive Asplund's metric which
is robust to variations of source intensity and exposure-time. We introduce
robust to noise versions of these metrics. We demonstrate that the maps of
their corresponding distances between an image and a reference template are
linked to Mathematical Morphology. This facilitates their implementation. We
assess them in various situations with different lightings and movements.
Results show that those maps of distances are robust to lighting variations.
Importantly, they are efficient to detect patterns in low-contrast images with
a template acquired under a different lighting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01603</identifier>
 <datestamp>2020-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01603</id><created>2019-09-04</created><updated>2019-10-10</updated><authors><author><keyname>Coelho</keyname><forenames>Andre</forenames></author><author><keyname>Ott</keyname><forenames>Christian</forenames></author><author><keyname>Singh</keyname><forenames>Harsimran</forenames></author><author><keyname>Lizarralde</keyname><forenames>Fernando</forenames></author><author><keyname>Kondak</keyname><forenames>Konstantin</forenames></author></authors><title>Multi-DoF Time Domain Passivity Approach Based Drift Compensation for
  Telemanipulation</title><categories>cs.RO cs.SY eess.SY</categories><comments>2019 19th International Conference on Advanced Robotics (ICAR)</comments><journal-ref>2019 19th International Conference on Advanced Robotics (ICAR)
  695-701</journal-ref><doi>10.1109/ICAR46387.2019.8981661</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When, in addition to stability, position synchronization is also desired in
bilateral teleoperation, Time Domain Passivity Approach (TDPA) alone might not
be able to fulfill the desired objective. This is due to an undesired effect
caused by admittance type passivity controllers, namely position drift.
Previous works focused on developing TDPA-based drift compensation methods to
solve this issue. It was shown that, in addition to reducing drift, one of the
proposed methods was able to keep the force signals within their normal range,
guaranteeing the safety of the task. However, no multi-DoF treatment of those
approaches has been addressed. In that scope, this paper focuses on providing
an extension of previous TDPA-based approaches to multi-DoF Cartesian-space
teleoperation. An analysis of the convergence properties of the presented
method is also provided. In addition, its applicability to multi-DoF devices is
shown through hardware experiments and numerical simulation with round-trip
time delays up to 700 ms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01622</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01622</id><created>2019-09-04</created><authors><author><keyname>Kelz</keyname><forenames>Rainer</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Towards Interpretable Polyphonic Transcription with Invertible Neural
  Networks</title><categories>cs.SD eess.AS</categories><comments>Published at the 20th International Society for Music Information
  Retrieval Conference, Delft, The Netherlands, 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We explore a novel way of conceptualising the task of polyphonic music
transcription, using so-called invertible neural networks. Invertible models
unify both discriminative and generative aspects in one function, sharing one
set of parameters. Introducing invertibility enables the practitioner to
directly inspect what the discriminative model has learned, and exactly
determine which inputs lead to which outputs. For the task of transcribing
polyphonic audio into symbolic form, these models may be especially useful as
they allow us to observe, for instance, to what extent the concept of single
notes could be learned from a corpus of polyphonic music alone (which has been
identified as a serious problem in recent research). This is an entirely new
approach to audio transcription, which first of all necessitates some
groundwork. In this paper, we begin by looking at the simplest possible
invertible transcription model, and then thoroughly investigate its properties.
Finally, we will take first steps towards a more sophisticated and capable
version. We use the task of piano transcription, and specifically the MAPS
dataset, as a basis for these investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01647</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01647</id><created>2019-09-04</created><authors><author><keyname>Hussain</keyname><forenames>Raabid</forenames><affiliation>ImVia</affiliation></author><author><keyname>Lalande</keyname><forenames>Alain</forenames><affiliation>Le2i</affiliation></author><author><keyname>Girum</keyname><forenames>Kibrom Berihu</forenames><affiliation>Le2i</affiliation></author><author><keyname>Guigou</keyname><forenames>Caroline</forenames><affiliation>Le2i</affiliation></author><author><keyname>Grayeli</keyname><forenames>Alexis Bozorg</forenames><affiliation>Le2i</affiliation></author></authors><title>3D landmark detection for augmented reality based otologic procedures</title><categories>eess.IV cs.CV</categories><proxy>ccsd</proxy><journal-ref>Surgetica, Jun 2019, Rennes, France</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ear consists of the smallest bones in the human body and does not contain
significant amount of distinct landmark points that may be used to register a
preoperative CT-scan with the surgical video in an augmented reality framework.
Learning based algorithms may be used to help the surgeons to identify landmark
points. This paper presents a convolutional neural network approach to landmark
detection in preoperative ear CT images and then discusses an augmented reality
system that can be used to visualize the cochlear axis on an otologic surgical
video.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01671</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01671</id><created>2019-09-04</created><authors><author><keyname>Audebert</keyname><forenames>Nicolas</forenames><affiliation>OBELIX</affiliation></author><author><keyname>Boulch</keyname><forenames>Alexandre</forenames><affiliation>OBELIX</affiliation></author><author><keyname>Saux</keyname><forenames>Bertrand Le</forenames><affiliation>OBELIX</affiliation></author><author><keyname>Lef&#xe8;vre</keyname><forenames>S&#xe9;bastien</forenames><affiliation>OBELIX</affiliation></author></authors><title>Distance transform regression for spatially-aware deep semantic
  segmentation</title><categories>cs.NE cs.CV eess.IV</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding visual scenes relies more and more on dense pixel-wise
classification obtained via deep fully convolutional neural networks. However,
due to the nature of the networks, predictions often suffer from blurry
boundaries and ill-segmented shapes, fueling the need for post-processing. This
work introduces a new semantic segmentation regularization based on the
regression of a distance transform. After computing the distance transform on
the label masks, we train a FCN in a multi-task setting in both discrete and
continuous spaces by learning jointly classification and distance regression.
This requires almost no modification of the network structure and adds a very
low overhead to the training process. Learning to approximate the distance
transform back-propagates spatial cues that implicitly regularizes the
segmentation. We validate this technique with several architectures on various
datasets, and we show significant improvements compared to competitive
baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01672</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01672</id><created>2019-09-04</created><authors><author><keyname>Schoormans</keyname><forenames>Jasper</forenames></author><author><keyname>Strijkers</keyname><forenames>Gustav J.</forenames></author><author><keyname>Hansen</keyname><forenames>Anders C.</forenames></author><author><keyname>Nederveen</keyname><forenames>Aart J.</forenames></author><author><keyname>Coolen</keyname><forenames>Bram F.</forenames></author></authors><title>Compressed Sensing MRI With Variable Density Averaging (CS-VDA)
  Outperforms Full Sampling At Low SNR</title><categories>physics.med-ph eess.IV</categories><comments>11 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigated whether a combination of k-space undersampling and variable
density averaging enhances image quality for low-SNR MRI acquisitions. We
implemented 3D Cartesian k-space prospective undersampling with a variable
number of averages for each k-line. The performance of this compressed sensing
with variable-density averaging (CS-VDA) method was evaluated in retrospective
analysis of fully sampled phantom MRI measurements, as well as for
prospectively accelerated in vivo 3D brain and knee MRI scans. Both phantom and
in vivo results showed that acquisitions using the CS-VDA approach resulted in
better image quality as compared to full sampling of k-space in the same scan
time. Specifically, CS-VDA with a higher number of averages in the center of
k-space resulted in the best image quality, apparent from increased anatomical
detail with preserved soft-tissue contrast. This novel approach will facilitate
improved image quality of inherently low SNR data, such as those with
high-resolution or specific contrast-weightings with low SNR efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01700</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01700</id><created>2019-09-04</created><updated>2019-09-05</updated><authors><author><keyname>Yu</keyname><forenames>Chengzhu</forenames></author><author><keyname>Lu</keyname><forenames>Heng</forenames></author><author><keyname>Hu</keyname><forenames>Na</forenames></author><author><keyname>Yu</keyname><forenames>Meng</forenames></author><author><keyname>Weng</keyname><forenames>Chao</forenames></author><author><keyname>Xu</keyname><forenames>Kun</forenames></author><author><keyname>Liu</keyname><forenames>Peng</forenames></author><author><keyname>Tuo</keyname><forenames>Deyi</forenames></author><author><keyname>Kang</keyname><forenames>Shiyin</forenames></author><author><keyname>Lei</keyname><forenames>Guangzhi</forenames></author><author><keyname>Su</keyname><forenames>Dan</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>DurIAN: Duration Informed Attention Network For Multimodal Synthesis</title><categories>cs.CL cs.CV cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a generic and robust multimodal synthesis system
that produces highly natural speech and facial expression simultaneously. The
key component of this system is the Duration Informed Attention Network
(DurIAN), an autoregressive model in which the alignments between the input
text and the output acoustic features are inferred from a duration model. This
is different from the end-to-end attention mechanism used, and accounts for
various unavoidable artifacts, in existing end-to-end speech synthesis systems
such as Tacotron. Furthermore, DurIAN can be used to generate high quality
facial expression which can be synchronized with generated speech with/without
parallel speech and face data. To improve the efficiency of speech generation,
we also propose a multi-band parallel generation strategy on top of the WaveRNN
model. The proposed Multi-band WaveRNN effectively reduces the total
computational complexity from 9.8 to 5.5 GFLOPS, and is able to generate audio
that is 6 times faster than real time on a single CPU core. We show that DurIAN
could generate highly natural speech that is on par with current state of the
art end-to-end systems, while at the same time avoid word skipping/repeating
errors in those systems. Finally, a simple yet effective approach for
fine-grained control of expressiveness of speech and facial expression is
introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01730</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01730</id><created>2019-09-04</created><updated>2019-11-19</updated><authors><author><keyname>Andersson</keyname><forenames>Carl</forenames></author><author><keyname>Ribeiro</keyname><forenames>Ant&#xf4;nio H.</forenames></author><author><keyname>Tiels</keyname><forenames>Koen</forenames></author><author><keyname>Wahlstr&#xf6;m</keyname><forenames>Niklas</forenames></author><author><keyname>Sch&#xf6;n</keyname><forenames>Thomas B.</forenames></author></authors><title>Deep Convolutional Networks in System Identification</title><categories>eess.SY cs.LG cs.NE cs.SY stat.ML</categories><comments>Accepted to Conference on Decision and Control, The first two authors
  contributed equally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent developments within deep learning are relevant for nonlinear system
identification problems. In this paper, we establish connections between the
deep learning and the system identification communities. It has recently been
shown that convolutional architectures are at least as capable as recurrent
architectures when it comes to sequence modeling tasks. Inspired by these
results we explore the explicit relationships between the recently proposed
temporal convolutional network (TCN) and two classic system identification
model structures; Volterra series and block-oriented models. We end the paper
with an experimental study where we provide results on two real-world problems,
the well-known Silverbox dataset and a newer dataset originating from ground
vibration experiments on an F-16 fighter aircraft.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01738</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01738</id><created>2019-09-04</created><authors><author><keyname>Xu</keyname><forenames>Jiahua</forenames></author><author><keyname>Zhou</keyname><forenames>Wei</forenames></author><author><keyname>Chen</keyname><forenames>Zhibo</forenames></author><author><keyname>Ling</keyname><forenames>Suiyi</forenames></author><author><keyname>Callet</keyname><forenames>Patrick Le</forenames></author></authors><title>Predictive Auto-Encoding Network for Blind Stereoscopic Image Quality
  Assessment</title><categories>cs.MM eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stereoscopic image quality assessment (SIQA) has encountered non-trivial
challenges due to the fast proliferation of 3D contents. In the past years,
deep learning oriented SIQA methods have emerged and achieved spectacular
performance compared to conventional algorithms which are only relied on
extracting hand-crafted features. However, most existing deep SIQA evaluators
are not specifically built for stereoscopic content and consider little prior
domain knowledge of the 3D human visual system (HVS) in network design. In this
paper, to better simulate the binocular rivalry phenomenon, we propose a
Predictive Auto-encoDing Network (PAD-Net) for blind/No-Reference stereoscopic
image quality assessment (NR-SIQA). The proposed encoder-decoder architecture
is inspired by the predictive coding theory that the cognition system tries to
match bottom-up visual signal with top-down predictions. Besides, we design the
Siamese framework to mimic the binocular rivalry in the 3D HVS based on the
likelihood and prior maps generated from the predictive coding process.
Extensive experimental results on three publicly available stereoscopic image
quality databases demonstrate that the devised approach outperforms
state-of-the-art algorithms for predicting the perceptual quality of both
symmetrically and asymmetrically distorted stereoscopic images with various
distortion types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01758</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01758</id><created>2019-09-04</created><updated>2019-12-14</updated><authors><author><keyname>Anahtarci</keyname><forenames>Berkay</forenames></author><author><keyname>Kariksiz</keyname><forenames>Can Deha</forenames></author><author><keyname>Saldi</keyname><forenames>Naci</forenames></author></authors><title>Value Iteration Algorithm for Mean-field Games</title><categories>eess.SY cs.SY math.OC</categories><comments>19 pages, Corrected version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the literature, existence of mean-field equilibria has been established
for discrete-time mean field games under both the discounted cost and the
average cost optimality criteria. However, there is no algorithm with
convergence guarantee for computing mean-field equilibria for a general class
of models. In this paper, we provide a value iteration algorithm to compute
mean-field equilibrium for both the discounted cost and the average cost
criteria. We establish that the value iteration algorithm converges to the
fixed point of a mean-field equilibrium operator. Then, using this fixed point,
we construct a mean-field equilibrium. In our value iteration algorithm, we use
$Q$-functions instead of value functions for possible extension of this work to
the model-free setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01767</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01767</id><created>2019-08-30</created><updated>2019-10-16</updated><authors><author><keyname>Wolf</keyname><forenames>Armin</forenames></author></authors><title>Modular Modeling and Optimized Scheduling of Building Energy Systems
  Based on Mixed Integer Programming</title><categories>eess.SY cs.SY</categories><comments>Part of DECLARE 19 proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Almost climate neutral buildings are one of the core goals in terms of
sustainability. Beside the support of the necessary design decisions for an
integrated, interoperable, ecological and economical operation of building
energy systems, innovative management solutions for scheduling the operation of
decentralized energy systems are of great importance. The challenge is optimal
interaction between energy system components in terms of own consumption,
energy efficiency and resource consumption as well as greenhouse gas emissions.
To achieve these goals a modular optimization approach based on Mixed Integer
Programming is proposed. In detail, and to our knowledge the first time, a MIP
model for the dynamic behavior of fuel cell Combined Heat and Power plants is
presented. Our approach is evaluated for the operation of heat pumps showing
that their energy efficiency can be increased significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01813</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01813</id><created>2019-09-04</created><updated>2019-10-09</updated><authors><author><keyname>K&#xf6;hler</keyname><forenames>Johannes</forenames></author><author><keyname>Andina</keyname><forenames>Elisa</forenames></author><author><keyname>Soloperto</keyname><forenames>Raffaele</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Matthias A.</forenames></author><author><keyname>Allg&#xf6;wer</keyname><forenames>Frank</forenames></author></authors><title>Linear robust adaptive model predictive control: Computational
  complexity and conservatism</title><categories>eess.SY cs.SY</categories><comments>Extended version of a corresponding confernce paper at the conference
  on decision and control (CDC), including a detailed proof</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a robust adaptive model predictive control (MPC)
scheme for linear systems subject to parametric uncertainty and additive
disturbances. The proposed approach provides a computationally efficient
formulation with theoretical guarantees (constraint satisfaction and
stability), while allowing for reduced conservatism and improved performance
due to online parameter adaptation. A moving window parameter set
identification is used to compute a fixed complexity parameter set based on
past data. Robust constraint satisfaction is achieved by using a
computationally efficient tube based robust MPC method. The predicted cost
function is based on a least mean squares point estimate, which ensures
finite-gain $\mathcal{L}_2$ stability of the closed loop. The overall algorithm
has a fixed (user specified) computational complexity. We illustrate the
applicability of the approach and the trade-off between conservatism and
computational complexity using a numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01831</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01831</id><created>2019-09-04</created><authors><author><keyname>Chicco</keyname><forenames>Gianfranco</forenames></author><author><keyname>Mazza</keyname><forenames>Andrea</forenames></author></authors><title>New insights for setting up contractual options for demand side
  flexibility</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper exploits the Duration-of-Use of the demand patterns as a key
concept for dealing with demand side flexibility. Starting from the
consideration that fine-grained energy metering is not used at the point of
supply of the electricity consumers, i.e., the granularity of the energy
measured (at time steps of 15 minutes, 30 minutes or one hour), the event-based
energy metering (EDM) is indicated as a viable option to provides a very
detailed reconstruction of the demand patterns. The use of EDM enables
high-quality tracking of the demand peaks with a reduced number of data with
respect to the ones needed to measure energy at regular time steps for reaching
a similar peak tracking capability. From the EDM outcomes, a new class of
options for setting up tariffs or contracts for flexibility, based on the
demand duration curve, is envisioned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01855</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01855</id><created>2019-09-04</created><authors><author><keyname>Bajaj</keyname><forenames>Shivam</forenames></author><author><keyname>Bopardikar</keyname><forenames>Shaunak D.</forenames></author></authors><title>Dynamic Boundary Guarding Against Radially Incoming Targets</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a dynamic vehicle routing problem in which a single vehicle
seeks to guard a circular perimeter against radially inward moving targets.
Targets are generated uniformly as per a Poisson process in time with a fixed
arrival rate on the boundary of a circle with a larger radius and concentric
with the perimeter. Upon generation, each target moves radially inward toward
the perimeter with a fixed speed. The aim of the vehicle is to maximize the
capture fraction, i.e., the fraction of targets intercepted before they enter
the perimeter. We first obtain a fundamental upper bound on the capture
fraction which is independent of any policy followed by the vehicle. We analyze
several policies in the low and high arrival rates of target generation. For
low arrival, we propose and analyze a First-Come-First-Served and a Look-Ahead
policy based on repeated computation of the path that passes through maximum
number of unintercepted targets. For high arrival, we design and analyze a
policy based on repeated computation of Euclidean Minimum Hamiltonian path
through a fraction of existing targets and show that it is within a constant
factor of the optimal. Finally, we provide a numerical study of the performance
of the policies in parameter regimes beyond the scope of the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01865</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01865</id><created>2019-09-04</created><updated>2019-11-13</updated><authors><author><keyname>Eisen</keyname><forenames>Mark</forenames></author><author><keyname>Ribeiro</keyname><forenames>Alejandro</forenames></author></authors><title>Optimal Wireless Resource Allocation with Random Edge Graph Neural
  Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of optimally allocating resources across a set of
transmitters and receivers in a wireless network. The resulting optimization
problem takes the form of constrained statistical learning, in which solutions
can be found in a model-free manner by parameterizing the resource allocation
policy. Convolutional neural networks architectures are an attractive option
for parameterization, as their dimensionality is small and does not scale with
network size. We introduce the random edge graph neural network (REGNN), which
performs convolutions over random graphs formed by the fading interference
patterns in the wireless network. The REGNN-based allocation policies are shown
to retain an important permutation equivariance property that makes them
amenable to transference to different networks. We further present an
unsupervised model-free primal-dual learning algorithm to train the weights of
the REGNN. Through numerical simulations, we demonstrate the strong performance
REGNNs obtain relative to heuristic benchmarks and their transference
capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01868</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01868</id><created>2019-09-04</created><updated>2019-09-05</updated><authors><author><keyname>Tiwari</keyname><forenames>Ashutosh</forenames></author><author><keyname>Narayan</keyname><forenames>Avadh Bihari</forenames></author><author><keyname>Dikshit</keyname><forenames>Onkar</forenames></author></authors><title>Deep learning networks for selection of persistent scatterer pixels in
  multi-temporal SAR interferometric processing</title><categories>eess.IV cs.LG stat.ML</categories><comments>8728 words, 8 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multi-temporal SAR interferometry (MT-InSAR), persistent scatterer (PS)
pixels are used to estimate geophysical parameters, essentially deformation.
Conventionally, PS pixels are selected on the basis of the estimated noise
present in the spatially uncorrelated phase component along with look-angle
error in a temporal interferometric stack. In this study, two deep learning
architectures, namely convolutional neural network for interferometric semantic
segmentation (CNN-ISS) and convolutional long short term memory network for
interferometric semantic segmentation (CLSTM-ISS), based on learning spatial
and spatio-temporal behaviour respectively, were proposed for selection of PS
pixels. These networks were trained to relate the interferometric phase history
to its classification into phase stable (PS) and phase unstable (non-PS)
measurement pixels using ~10,000 real world interferometric images of different
study sites containing man-made objects, forests, vegetation, uncropped land,
water bodies, and areas affected by lengthening, foreshortening, layover and
shadowing. The networks were trained using training labels obtained from the
Stanford method for Persistent Scatterer Interferometry (StaMPS) algorithm.
However, pixel selection results, when compared to a combination of R-index and
a classified image of the test dataset, reveal that CLSTM-ISS estimates
improved the classification of PS and non-PS pixels compared to those of StaMPS
and CNN-ISS. The predicted results show that CLSTM-ISS reached an accuracy of
93.50%, higher than that of CNN-ISS (89.21%). CLSTM-ISS also improved the
density of reliable PS pixels compared to StaMPS and CNN-ISS and outperformed
StaMPS and other conventional MT-InSAR methods in terms of computational
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01874</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01874</id><created>2019-09-02</created><authors><author><keyname>Nguyen</keyname><forenames>Quan</forenames></author><author><keyname>Santoso</keyname><forenames>Surya</forenames></author></authors><title>Optimal Planning and Operation of Multi-Frequency HVac Transmission
  Systems</title><categories>eess.SY cs.SY</categories><comments>arXiv admin note: text overlap with arXiv:1908.02832</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-frequency high-voltage alternating-current (LF-HVac) transmission scheme
has been recently proposed as an alternative solution to conventional 50/60-Hz
HVac and high-voltage direct-current (HVdc) schemes for bulk power transfer.
This paper proposes an optimal planning and operation for loss minimization in
a multi-frequency HVac transmission system. In such a system, conventional HVac
and LF-HVac grids are interconnected using back-to-back (BTB) converters. The
dependence of system MW losses on converter dispatch as well as the operating
voltage and frequency in the LF-HVac is discussed and compared with that of
HVdc transmission. Based on the results of the loss analysis, multi-objective
optimization formulations for both planning and operation stages are proposed.
The planning phase decides a suitable voltage level for the LF-HVac grid, while
the operation phase determines the optimal operating frequency and power
dispatch of BTB converters, generators, and shunt capacitors. A solution
approach that effectively handles the variations of transmission line
parameters with the rated voltage and operating frequency in the LF-HVac grid
is proposed. The proposed solutions of the planning and operation stages are
evaluated using a multi-frequency HVac system. The results show a significant
loss reduction and improved voltage regulation during a 24-hour simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01887</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01887</id><created>2019-09-04</created><authors><author><keyname>Barbieri</keyname><forenames>Davide</forenames></author><author><keyname>Cabrelli</keyname><forenames>Carlos</forenames></author><author><keyname>Hern&#xe1;ndez</keyname><forenames>Eugenio</forenames></author><author><keyname>Molter</keyname><forenames>Ursula</forenames></author></authors><title>Optimal translational-rotational invariant dictionaries for images</title><categories>eess.IV cs.CV cs.NA math.FA math.NA stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide the construction of a set of square matrices whose translates and
rotates provide a Parseval frame that is optimal for approximating a given
dataset of images. Our approach is based on abstract harmonic analysis
techniques. Optimality is considered with respect to the quadratic error of
approximation of the images in the dataset with their projection onto a linear
subspace that is invariant under translations and rotations. In addition, we
provide an elementary and fully self-contained proof of optimality, and the
numerical results from datasets of natural images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01904</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01904</id><created>2019-09-04</created><authors><author><keyname>Nagaraja</keyname><forenames>Shishir</forenames></author><author><keyname>Shah</keyname><forenames>Ryan</forenames></author></authors><title>VoipLoc: Establishing VoIP call provenance using acoustic side-channels</title><categories>cs.CR cs.SD eess.AS</categories><comments>19 pages, 6 figures, 1 table</comments><msc-class>68M99</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We develop a novel technique to determine call provenance in anonymous VoIP
communications using acoustic side-channels. The technique exploits
location-attributable information embedded within audio speech data. The
victim's speech is exploited as an excitation signal, which is modulated (acted
upon) by the acoustic reflection characteristics of the victim's location. We
show that leading VoIP communication channels faithfully transfer this
information between sender-receiver pairs, enabling passive receivers to
extract a location fingerprint, to establish call provenance. To establish
provenance, a fingerprint is compared against a database of labelled
fingerprints to identify a match. The technique is fully passive and does not
depend on any characteristic background sounds, is speaker independent, and is
robust to lossy network conditions. Evaluation using a corpus of recordings of
VoIP conversations, over the Tor network, confirms that recording locations can
be fingerprinted and detected remotely with low false-positive rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01910</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01910</id><created>2019-09-04</created><authors><author><keyname>Giuliano</keyname><forenames>Vincenzo</forenames></author><author><keyname>Formicola</keyname><forenames>Valerio</forenames></author></authors><title>ICSrange: A Simulation-based Cyber Range Platform for Industrial Control
  Systems</title><categories>cs.CR cs.SY eess.SY</categories><comments>Student Forum paper of the 15th European Dependable Computing
  Conference (EDCC 2019)</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Maintenance staff of Industrial Control Systems (ICS) is generally not aware
about information technologies, and even less about cyber security problems.
The scary impact of cyber attacks in the industrial world calls for tools to
train defensive skills and test effective security measures. Cyber range offers
this opportunity, but current research is lacking cost-effective solutions
verticalized for the industrial domain. This work proposes ICSrange, a
simulation-based cyber range platform for Industrial Control Systems. ICSrange
adopts Commercial-Off-The-Shelf (COTS) technologies to virtualize an enterprise
network connected to Industrial Control Systems. ICSrange is the outcome of a
preliminary study intended to investigate challenges and opportunities to build
a configurable and extensible cyber range with simulated industrial processes.
Literature shows that testbeds based on realistic mock-ups are effectively
employed to develop complex exploits like Advanced Persistent Threats (APTs),
hence motivating their usage to train and test security in ICS. We prove the
effectiveness of ICSrange through the execution of a multi-staged attack that
breaches an enterprise network and progressively intrudes a simulated ICS with
water tanks. The attack mimics lateral movements as observed in APTs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01940</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01940</id><created>2019-09-03</created><authors><author><keyname>Pooch</keyname><forenames>Eduardo H. P.</forenames></author><author><keyname>Ballester</keyname><forenames>Pedro L.</forenames></author><author><keyname>Barros</keyname><forenames>Rodrigo C.</forenames></author></authors><title>Can we trust deep learning models diagnosis? The impact of domain shift
  in chest radiograph classification</title><categories>eess.IV cs.AI cs.CV cs.LG stat.ML</categories><comments>4 pages, 2 figures, to be submitted to ISBI 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While deep learning models become more widespread, their ability to handle
unseen data and generalize for any scenario is yet to be challenged. In medical
imaging, there is a high heterogeneity of distributions among images based on
the equipment that generate them and their parametrization. This heterogeneity
triggers a common issue in machine learning called domain shift, which
represents the difference between the training data distribution and the
distribution of where a model is employed. A high domain shift tends to
implicate in a poor performance from models. In this work, we evaluate the
extent of domain shift on three of the largest datasets of chest radiographs.
We show how training and testing with different datasets (e.g. training in
ChestX-ray14 and testing in CheXpert) drastically affects model performance,
posing a big question over the reliability of deep learning models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01959</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01959</id><created>2019-09-04</created><authors><author><keyname>Tabuada</keyname><forenames>Paulo</forenames></author><author><keyname>Fraile</keyname><forenames>Lucas</forenames></author></authors><title>A Note on Data-Driven Control for SISO Feedback Linearizable Systems
  Without Persistency of Excitation</title><categories>eess.SY cs.SY math.OC</categories><comments>Extension to the results in conference paper [TF19]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper [TF19] proposes a data-driven control technique for single-input
single-output feedback linearizable systems with unknown control gain by
relying on a persistency of excitation assumption. This note extends those
results by showing that persistency of excitation is not necessary. We refer
the readers to the papers [TMGA17, TF19] for more background and motivation for
the technical results in this note. Conceptually, the results in this note were
greatly inspired by the work of Fliess and Join on intelligent PID controllers,
e.g., [FJ09]. Technically, we were inspired by the work of Nesic and co-workers
on observer and controller design based on approximate models [AN04, NT04] and
by the work of Astolfi and Ortega on Immersion and Invariance [AO03].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01963</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01963</id><created>2019-09-04</created><updated>2020-01-10</updated><authors><author><keyname>Shrivastava</keyname><forenames>Aman</forenames></author><author><keyname>Adorno</keyname><forenames>Will</forenames></author><author><keyname>Ehsan</keyname><forenames>Lubaina</forenames></author><author><keyname>Ali</keyname><forenames>S. Asad</forenames></author><author><keyname>Moore</keyname><forenames>Sean R.</forenames></author><author><keyname>Amadi</keyname><forenames>Beatrice C.</forenames></author><author><keyname>Kelly</keyname><forenames>Paul</forenames></author><author><keyname>Syed</keyname><forenames>Sana</forenames></author><author><keyname>Brown</keyname><forenames>Donald E.</forenames></author></authors><title>Self-Attentive Adversarial Stain Normalization</title><categories>eess.IV cs.CV q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hematoxylin and Eosin (H&amp;E) stained Whole Slide Images (WSIs) are utilized
for biopsy visualization-based diagnostic and prognostic assessment of
diseases. Variation in the H&amp;E staining process across different lab sites can
lead to significant variations in biopsy image appearance. These variations
introduce an undesirable bias when the slides are examined by pathologists or
used for training deep learning models. To reduce this bias, slides need to be
translated to a common domain of stain appearance before analysis. We propose a
Self-Attentive Adversarial Stain Normalization (SAASN) approach for the
normalization of multiple stain appearances to a common domain. This
unsupervised generative adversarial approach includes self-attention mechanism
for synthesizing images with finer detail while preserving the structural
consistency of the biopsy features during translation. SAASN demonstrates
consistent and superior performance compared to other popular stain
normalization techniques on H&amp;E stained duodenal biopsy image data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01968</identifier>
 <datestamp>2019-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01968</id><created>2019-09-04</created><authors><author><keyname>Fraternali</keyname><forenames>Francesco</forenames></author><author><keyname>Balaji</keyname><forenames>Bharathan</forenames></author><author><keyname>Agarwal</keyname><forenames>Yuvraj</forenames></author><author><keyname>Gupta</keyname><forenames>Rajesh K.</forenames></author></authors><title>ACES -- Automatic Configuration of Energy Harvesting Sensors with
  Reinforcement Learning</title><categories>eess.SY cs.LG cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet of Things forms the backbone of modern building applications.
Wireless sensors are being increasingly adopted for their flexibility and
reduced cost of deployment. However, most wireless sensors are powered by
batteries today and large deployments are inhibited by manual battery
replacement. Energy harvesting sensors provide an attractive alternative, but
they need to provide adequate quality of service to applications given
uncertain energy availability. We propose using reinforcement learning to
optimize the operation of energy harvesting sensors to maximize sensing quality
with available energy. We present our system ACES that uses reinforcement
learning for periodic and event-driven sensing indoors with ambient light
energy harvesting. Our custom-built board uses a supercapacitor to store energy
temporarily, senses light, motion events and relays them using Bluetooth Low
Energy. Using simulations and real deployments, we show that our sensor nodes
adapt to their lighting conditions and continuously sends measurements and
events across nights and weekends. We use deployment data to continually adapt
sensing to changing environmental patterns and transfer learning to reduce the
training time in real deployments. In our 60 node deployment lasting two weeks,
we observe a dead time of 0.1%. The periodic sensors that measure luminosity
have a mean sampling period of 90 seconds and the event sensors that detect
motion with PIR captured 86% of the events on average compared to a
battery-powered node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01989</identifier>
 <datestamp>2019-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01989</id><created>2019-09-04</created><updated>2019-11-26</updated><authors><author><keyname>Belmekki</keyname><forenames>Baha Eddine Youcef</forenames></author><author><keyname>Hamza</keyname><forenames>Abdelkrim</forenames></author><author><keyname>Escrig</keyname><forenames>Beno&#xee;t</forenames></author></authors><title>Outage Analysis of Cooperative NOMA Using Maximum Ratio Combining at
  Intersections</title><categories>cs.IT eess.SP math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1904.11022</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The paper investigates the improvement of using maximum ratio combining (MRC)
in cooperative vehicular communications (VCs) transmission schemes considering
non-orthogonal multiple access scheme (NOMA) at intersections. The transmission
occurs between a source and two destination nodes with a help of a relay. The
transmission is subject to interference originated from vehicles that are
located on the roads. Closed form outage probability expressions are obtained.
We compare the performance of MRC cooperative NOMA with a classical cooperative
NOMA, and show that implementing MRC in cooperative NOMA transmission offers a
significant improvement over the classical cooperative NOMA in terms of outage
probability. We also compare the performance of MRC cooperative NOMA with MRC
cooperative orthogonal multiple access (OMA), and we show that NOMA has a
better performance than OMA. Finally, we show that the outage probability
increases when the nodes come closer to the intersection, and that using MRC
considering NOMA improves the performance in this context. The analysis is
verified with Monte Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.01999</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.01999</id><created>2019-09-04</created><authors><author><keyname>Fang</keyname><forenames>Song</forenames></author><author><keyname>Johansson</keyname><forenames>Karl Henrik</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author><author><keyname>Sandberg</keyname><forenames>Henrik</forenames></author><author><keyname>Ishii</keyname><forenames>Hideaki</forenames></author></authors><title>Two-Way Coding and Attack Decoupling in Control Systems Under Injection
  Attacks</title><categories>eess.SY cs.IT cs.RO cs.SY math.IT math.OC</categories><comments>arXiv admin note: text overlap with arXiv:1901.05420</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce the concept of two-way coding, which originates
in communication theory characterizing coding schemes for two-way channels,
into control theory, particularly to facilitate the analysis and design of
feedback control systems under injection attacks. Moreover, we propose the
notion of attack decoupling, and show how the controller and the two-way coding
can be co-designed to nullify the transfer function from attack to plant,
rendering the attack effect zero both in transient phase and in steady state.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02040</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02040</id><created>2019-09-04</created><authors><author><keyname>Wu</keyname><forenames>Zihui</forenames></author><author><keyname>Sun</keyname><forenames>Yu</forenames></author><author><keyname>Liu</keyname><forenames>Jiaming</forenames></author><author><keyname>Kamilov</keyname><forenames>Ulugbek S.</forenames></author></authors><title>Online Regularization by Denoising with Applications to Phase Retrieval</title><categories>eess.IV cs.CV</categories><comments>Accepted ICCVW 2019 (LCI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regularization by denoising (RED) is a powerful framework for solving imaging
inverse problems. Most RED algorithms are iterative batch procedures, which
limits their applicability to very large datasets. In this paper, we address
this limitation by introducing a novel online RED (On-RED) algorithm, which
processes a small subset of the data at a time. We establish the theoretical
convergence of On-RED in convex settings and empirically discuss its
effectiveness in non-convex ones by illustrating its applicability to phase
retrieval. Our results suggest that On-RED is an effective alternative to the
traditional RED algorithms when dealing with large datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02062</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02062</id><created>2019-09-04</created><authors><author><keyname>Alyafi</keyname><forenames>Basel</forenames></author><author><keyname>Diaz</keyname><forenames>Oliver</forenames></author><author><keyname>Marti</keyname><forenames>Robert</forenames></author></authors><title>DCGANs for Realistic Breast Mass Augmentation in X-ray Mammography</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>4 pages, 4 figures, SPIE Medical Imaging 2020 Conference</comments><msc-class>68U10 (Primary) 68U20 (Secondary)</msc-class><acm-class>I.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early detection of breast cancer has a major contribution to curability, and
using mammographic images, this can be achieved non-invasively. Supervised deep
learning, the dominant CADe tool currently, has played a great role in object
detection in computer vision, but it suffers from a limiting property: the need
of a large amount of labelled data. This becomes stricter when it comes to
medical datasets which require high-cost and time-consuming annotations.
Furthermore, medical datasets are usually imbalanced, a condition that often
hinders classifiers performance. The aim of this paper is to learn the
distribution of the minority class to synthesise new samples in order to
improve lesion detection in mammography. Deep Convolutional Generative
Adversarial Networks (DCGANs) can efficiently generate breast masses. They are
trained on increasing-size subsets of one mammographic dataset and used to
generate diverse and realistic breast masses. The effect of including the
generated images and/or applying horizontal and vertical flipping is tested in
an environment where a 1:10 imbalanced dataset of masses and normal tissue
patches is classified by a fully-convolutional network. A maximum of ~ 0:09
improvement of F1 score is reported by using DCGANs along with flipping
augmentation over using the original images. We show that DCGANs can be used
for synthesising photo-realistic breast mass patches with considerable
diversity. It is demonstrated that appending synthetic images in this
environment, along with flipping, outperforms the traditional augmentation
method of flipping solely, offering faster improvements as a function of the
training set size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02068</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02068</id><created>2019-08-28</created><updated>2019-11-24</updated><authors><author><keyname>Xu</keyname><forenames>Ran</forenames></author><author><keyname>Koo</keyname><forenames>Jinkyu</forenames></author><author><keyname>Kumar</keyname><forenames>Rakesh</forenames></author><author><keyname>Bai</keyname><forenames>Peter</forenames></author><author><keyname>Mitra</keyname><forenames>Subrata</forenames></author><author><keyname>Meghanath</keyname><forenames>Ganga</forenames></author><author><keyname>Bagchi</keyname><forenames>Saurabh</forenames></author></authors><title>ApproxNet: Content and Contention Aware Video Analytics System for the
  Edge</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Videos take lot of time to transport over the network, hence running
analytics on live video at the edge devices, right where it was captured has
become an important system driver. However these edge devices, e.g., IoT
devices, surveillance cameras, AR/VR gadgets are resource constrained. This
makes it impossible to run state-of-the-art heavy Deep Neural Networks (DNNs)
on them and yet provide low and stable latency under various circumstances,
such as, changes in the resource availability on the device, the content
characteristics, or requirements from the user. In this paper we introduce
ApproxNet, a video analytics system for the edge. It enables novel dynamic
approximation techniques to achieve desired inference latency and accuracy
trade-off under different system conditions and resource contentions,
variations in the complexity of the video contents and user requirements. It
achieves this by enabling two approximation knobs within a single DNN model,
rather than creating and maintaining an ensemble of models (such as in MCDNN
[Mobisys-16]). Ensemble models run into memory issues on the lightweight
devices and incur large switching penalties among the models in response to
runtime changes. We show that ApproxNet can adapt seamlessly at runtime to
video content changes and changes in system dynamics to provide low and stable
latency for object detection on a video stream. We compare the accuracy and the
latency to ResNet [2015], MCDNN, and MobileNets [Google-2017].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02070</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02070</id><created>2019-09-04</created><authors><author><keyname>Minghui</keyname><forenames>Sun</forenames></author><author><keyname>Bakirtzis</keyname><forenames>Georgios</forenames></author><author><keyname>Jafarzadeh</keyname><forenames>Hassan</forenames></author><author><keyname>Fleming</keyname><forenames>Cody</forenames></author></authors><title>Correct-by-construction: a contract-based semi-automated requirement
  decomposition process</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Requirement decomposition is a widely accepted Systems Engineering practice
for Requirements Engineering. Getting the requirements correct at the very
beginning of the lifecycle is crucial for the success of engineering a correct
system. This is especially the case for safety-critical complex systems, where
incorrect or clashing requirements can lead to accidents. While there is a
large volume of work on the formal verification for the bottom-up composition
of requirements, there are very few works on how these requirements are
rigorously decomposed top-down in the first place. This paper tackles this
problem. Inspired by Contract-Based Design, we develop a formalism for
requirement decomposition, which can mathematically guarantee a satisfactory
system implementation if certain conditions are respected. A systematic
methodology is then designed to semi-automatically search for the optimal
sub-requirements and guarantee their correctness upon definition. The proposed
approach is supported by existing formal methods (i.e., Reachability Analysis
and Constraint Programming) that have been applied to other areas. Finally, we
support our findings through a case study on a cruise control system to
illustrate the usability of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02087</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02087</id><created>2019-09-04</created><authors><author><keyname>Chen</keyname><forenames>Li</forenames></author><author><keyname>Sun</keyname><forenames>Jie</forenames></author><author><keyname>Canton</keyname><forenames>Gador</forenames></author><author><keyname>Balu</keyname><forenames>Niranjan</forenames></author><author><keyname>Zhao</keyname><forenames>Xihai</forenames></author><author><keyname>Li</keyname><forenames>Rui</forenames></author><author><keyname>Hatsukami</keyname><forenames>Thomas S.</forenames></author><author><keyname>Hwang</keyname><forenames>Jenq-Neng</forenames></author><author><keyname>Yuan</keyname><forenames>Chun</forenames></author></authors><title>Automated Artery Localization and Vessel Wall Segmentation of Magnetic
  Resonance Vessel Wall Images using Tracklet Refinement and Polar Conversion</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative analysis of vessel wall structures by automated vessel wall
segmentation provides useful imaging biomarkers in evaluating atherosclerotic
lesions and plaque progression time-efficiently. To quantify vessel wall
features, drawing lumen and outer wall contours of the artery of interest is
required. To alleviate manual labor in contour drawing, some computer-assisted
tools exist, but manual preprocessing steps, such as region of interest
identification and boundary initialization are needed. In addition, the prior
knowledge of the ring shape of vessel wall is not taken into consideration in
designing the segmentation method. In this work, trained on manual vessel wall
contours, a fully automated artery localization and vessel wall segmentation
system is proposed. A tracklet refinement algorithm is used to robustly
identify the centerlines of arteries of interest from a neural network
localization architecture. Image patches are extracted from the centerlines and
segmented in a polar coordinate system to use 3D information and to overcome
problems such as contour discontinuity and interference from neighboring
vessels. From a carotid artery dataset with 116 subjects (3406 slices) and a
popliteal artery dataset with 5 subjects (289 slices), the proposed system is
shown to robustly identify the artery of interest and segment the vessel wall.
The proposed system demonstrates better performance on the carotid dataset with
a Dice similarity coefficient of 0.824, compared with traditional vessel wall
segmentation methods, Dice of 0.576, and traditional convolutional neural
network approaches, Dice of 0.747. This vessel wall segmentation system will
facilitate research on atherosclerosis and assist radiologists in image review.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02150</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02150</id><created>2019-09-04</created><authors><author><keyname>Gholami</keyname><forenames>Anousheh</forenames></author><author><keyname>Fiaz</keyname><forenames>Usman A.</forenames></author><author><keyname>Baras</keyname><forenames>John S.</forenames></author></authors><title>Drone-Assisted Communications for Remote Areas and Disaster Relief</title><categories>eess.SP cs.RO cs.SY eess.SY</categories><comments>Accepted at DGRS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore an end-to-end (including access and backhaul links) UAV-assisted
wireless communication system, considering both uplink and downlink traffics,
with the goal of supporting demand of the Ground Users (GUs) using the minimum
number of UAVs. Moreover, in order to extend the operational (flight) time of
UAVs, we exploit an energy-aware routing scheme. Our intention is to design and
analyze the access and backhaul connectivity of a drone-assisted communication
network for remote and crowded areas and disaster relief, while minimizing the
resources required i.e., the number of UAVs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02157</identifier>
 <datestamp>2019-09-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02157</id><created>2019-09-04</created><authors><author><keyname>Storey</keyname><forenames>Gary</forenames></author><author><keyname>Bouridane</keyname><forenames>Ahmed</forenames></author><author><keyname>Jiang</keyname><forenames>Richard</forenames></author><author><keyname>Li</keyname><forenames>Chang-tsun</forenames></author></authors><title>Atypical Facial Landmark Localisation with Stacked Hourglass Networks: A
  Study on 3D Facial Modelling for Medical Diagnosis</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>In press, 2019</comments><journal-ref>Deep Biometrics, Springer Book, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While facial biometrics has been widely used for identification purpose, it
has recently been researched as medical biometrics for a range of diseases. In
this chapter, we investigate the facial landmark detection for atypical 3D
facial modelling in facial palsy cases, while potentially such modelling can
assist the medical diagnosis using atypical facial features. In our work, a
study of landmarks localisation methods such as stacked hourglass networks is
conducted and evaluated to ascertain their accuracy when presented with unseen
atypical faces. The evaluation highlights that the state-of-the-art stacked
hourglass architecture outperforms other traditional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02165</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02165</id><created>2019-09-04</created><authors><author><keyname>Pandey</keyname><forenames>Nilesh</forenames></author><author><keyname>Savakis</keyname><forenames>Andreas</forenames></author></authors><title>Poly-GAN: Multi-Conditioned GAN for Fashion Synthesis</title><categories>cs.CV cs.GR eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present Poly-GAN, a novel conditional GAN architecture that is motivated
by Fashion Synthesis, an application where garments are automatically placed on
images of human models at an arbitrary pose. Poly-GAN allows conditioning on
multiple inputs and is suitable for many tasks, including image alignment,
image stitching, and inpainting. Existing methods have a similar pipeline where
three different networks are used to first align garments with the human pose,
then perform stitching of the aligned garment and finally refine the results.
Poly-GAN is the first instance where a common architecture is used to perform
all three tasks. Our novel architecture enforces the conditions at all layers
of the encoder and utilizes skip connections from the coarse layers of the
encoder to the respective layers of the decoder. Poly-GAN is able to perform a
spatial transformation of the garment based on the RGB skeleton of the model at
an arbitrary pose. Additionally, Poly-GAN can perform image stitching,
regardless of the garment orientation, and inpainting on the garment mask when
it contains irregular holes. Our system achieves state-of-the-art quantitative
results on Structural Similarity Index metric and Inception Score metric using
the DeepFashion dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02190</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02190</id><created>2019-09-04</created><updated>2019-09-30</updated><authors><author><keyname>Gu</keyname><forenames>Jiazhen</forenames></author><author><keyname>Xu</keyname><forenames>Huanlin</forenames></author><author><keyname>Zhou</keyname><forenames>Yangfan</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Xu</keyname><forenames>Hui</forenames></author><author><keyname>Lyu</keyname><forenames>Michael</forenames></author></authors><title>Detecting Deep Neural Network Defects with Data Flow Analysis</title><categories>cs.LG eess.SP stat.ML</categories><comments>2 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks (DNNs) are shown to be promising solutions in many
challenging artificial intelligence tasks. However, it is very hard to figure
out whether the low precision of a DNN model is an inevitable result, or caused
by defects. This paper aims at addressing this challenging problem. We find
that the internal data flow footprints of a DNN model can provide insights to
locate the root cause effectively. We develop DeepMorph (DNN Tomography) to
analyze the root cause, which can guide a DNN developer to improve the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02192</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02192</id><created>2019-09-04</created><authors><author><keyname>Lee</keyname><forenames>Bruce</forenames></author><author><keyname>Lamperski</keyname><forenames>Andrew</forenames></author></authors><title>Non-asymptotic Closed-Loop System Identification using Autoregressive
  Processes and Hankel Model Reduction</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the primary challenges of system identification is determining how
much data is necessary to adequately fit a model. Non-asymptotic
characterizations of the performance of system identification methods provide
this knowledge. Such characterizations are available for several algorithms
performing open-loop identification. Often times, however, data is collected in
closed-loop. Application of open-loop identification methods to closed-loop
data can result in biased estimates. One method used by subspace identification
techniques to eliminate these biases involves first fitting a long-horizon
autoregressive model, then performing model reduction. The asymptotic behavior
of such algorithms is well characterized, but the non-asymptotic behavior is
not. This work provides a non-asymptotic characterization of one particular
variant of these algorithms. More specifically, we provide non-asymptotic upper
bounds on the generalization error of the produced model, as well as high
probability bounds on the difference between the produced model and the finite
horizon Kalman Filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02194</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02194</id><created>2019-09-04</created><authors><author><keyname>Ernest</keyname><forenames>Tan Zheng Hui</forenames></author><author><keyname>Madhukumar</keyname><forenames>A S</forenames></author><author><keyname>Sirigina</keyname><forenames>Rajendra Prasad</forenames></author><author><keyname>Krishna</keyname><forenames>Anoop Kumar</forenames></author></authors><title>An Outage Probability Analysis of Full-Duplex NOMA in UAV Communications</title><categories>cs.IT eess.SP math.IT</categories><comments>To appear in Proc. IEEE Wireless Commun. Netw. Conf. (WCNC),
  Marrakech, Morocco, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As unmanned aerial vehicles (UAVs) are expected to play a significant role in
fifth generation (5G) networks, addressing spectrum scarcity in UAV
communications remains a pressing issue. In this regard, the feasibility of
full-duplex non-orthogonal multiple access (FD-NOMA) UAV communications to
improve spectrum utilization is investigated in this paper. Specifically,
closed-form outage probability expressions are presented for FD-NOMA,
half-duplex non-orthogonal multiple access (HD-NOMA), and half-duplex
orthogonal multiple access (HD-OMA) schemes over Rician shadowed fading
channels. Extensive analysis revealed that the bottleneck of performance in
FD-NOMA is at the downlink UAVs. Also, FD-NOMA exhibits lower outage
probability at the ground station (GS) and downlink UAVs than HD-NOMA and
HD-OMA under low transmit power regimes. At high transmit power regimes,
FD-NOMA is limited by residual SI and inter-UAV interference at the downlink
UAVs and FD-GS, respectively. The impact of shadowing is also shown to affect
the reliability of FD-NOMA and HD-OMA at the downlink UAVs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02221</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02221</id><created>2019-09-05</created><authors><author><keyname>Shoeiby</keyname><forenames>Mehrdad</forenames></author><author><keyname>Petersson</keyname><forenames>Lars</forenames></author><author><keyname>Armin</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Aliakbarian</keyname><forenames>Sadegh</forenames></author><author><keyname>Robles-Kelly</keyname><forenames>Antonio</forenames></author></authors><title>Super-resolved Chromatic Mapping of Snapshot Mosaic Image Sensors via a
  Texture Sensitive Residual Network</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel method to simultaneously super-resolve and
colour-predict images acquired by snapshot mosaic sensors. These sensors allow
for spectral images to be acquired using low-power, small form factor,
solid-state CMOS sensors that can operate at video frame rates without the need
for complex optical setups. Despite their desirable traits, their main drawback
stems from the fact that the spatial resolution of the imagery acquired by
these sensors is low. Moreover, chromatic mapping in snapshot mosaic sensors is
not straightforward since the bands delivered by the sensor tend to be narrow
and unevenly distributed across the range in which they operate. We tackle this
drawback as applied to chromatic mapping by using a residual channel attention
network equipped with a texture sensitive block. Our method significantly
outperforms the traditional approach of interpolating the image and,
afterwards, applying a colour matching function. This work establishes
state-of-the-art in this domain while also making available to the research
community a dataset containing 296 registered stereo multi-spectral/RGB images
pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02227</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02227</id><created>2019-09-05</created><authors><author><keyname>Iskakov</keyname><forenames>Alexey B.</forenames></author><author><keyname>Yadykin</keyname><forenames>Igor B.</forenames></author></authors><title>Lyapunov modal analysis and participation factors with applications to
  small-signal stability of power systems</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When random disturbances are regularly introduced into a dynamical system
over time, its small-signal stability is determined by the energy of
perturbations accumulated in the system. To analyze this perturbation energy,
this paper proposes a novel physically motivated Lyapunov modal analysis (LMA)
framework, which combines selective modal analysis with the spectral
decompositions of specially chosen Lyapunov functions. This approach allows the
modal interactions in dynamical systems to be characterized and estimated in
connection with specific state variables. Conventional participation factors
characterize the relative contribution of the system modes and state variables
to the evolution of states and modes, respectively. In contrast, the proposed
Lyapunov participation factors characterize similar contributions to
corresponding Lyapunov functions, which determine the integral energy
associated with the states and modes on an infinite or finite time interval.
This allows the estimation of modal interactions in terms of total energy
produced by their mutual actions over time. Using a two-area four-machines
power system, we demonstrate that LMA reliably identifies resonant modal
interactions, merging of modes, and loss of stability, even for a linear model,
and associates them with certain state variables. The Lyapunov participation
factors corresponding to the selected part of the system spectrum can be
calculated independently and serve as a basis for rapid real-time calculations
of critical mode behaviors in large-scale dynamical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02231</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02231</id><created>2019-09-05</created><authors><author><keyname>Vuillemin</keyname><forenames>Pierre</forenames></author><author><keyname>Kergus</keyname><forenames>Pauline</forenames></author><author><keyname>Poussot-Vassal</keyname><forenames>Charles</forenames></author></authors><title>Technical note: Hybrid Loewner Data Driven Control</title><categories>eess.SY cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note describes how the Loewner framework can be exploited to create a
discrete-time control-law from frequency-data of a continuous-time plant so
that their hybrid interconnection matches a given continuous-time reference
model up to the Nyquist frequency. The resulting Hybrid Loewner Data Driven
Control scheme is illustrated on two numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02249</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02249</id><created>2019-09-05</created><authors><author><keyname>Lohani</keyname><forenames>Sanjaya</forenames></author><author><keyname>Glasser</keyname><forenames>Ryan T.</forenames></author></authors><title>Generative Machine Learning for Robust Free-Space Communication</title><categories>eess.SP cs.LG physics.optics quant-ph</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Realistic free-space optical communications systems suffer from turbulent
propagation of light through the atmosphere and detector noise at the receiver,
which can significantly degrade the optical mode quality of the received state,
increase cross-talk between modes, and correspondingly increase the symbol
error ratio (SER) of the system. In order to overcome these obstacles, we
develop a state-of-the-art generative machine learning (GML) and convolutional
neural network (CNN) system in combination, and demonstrate its efficacy in a
free-space optical (FSO) communications setting. The system corrects for the
distortion effects due to turbulence and reduces detector noise, resulting in
significantly lowered SERs and cross-talk at the output of the receiver, while
requiring no feedback. This scheme is straightforward to scale, and may provide
a concrete and cost effective technique to establishing long range classical
and quantum communication links in the near future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02256</identifier>
 <datestamp>2020-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02256</id><created>2019-09-05</created><updated>2020-01-13</updated><authors><author><keyname>Tang</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Meng</forenames></author></authors><title>Scalable Double Regularization for 3D Nano-CT Reconstruction</title><categories>eess.IV stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nano-CT (computerized tomography) has emerged as a non-destructive
high-resolution cross-sectional imaging technique to effectively study the
sub-$\mu$m pore structure of shale, which is of fundamental importance to the
evaluation and development of shale oil and gas. Nano-CT poses unique
challenges to the inverse problem of reconstructing the 3D structure due to the
lower signal-to-noise ratio (than Micro-CT) at the nano-scale, increased
sensitivity to the misaligned geometry caused by the movement of object
manipulator, limited sample size, and a larger volume of data at higher
resolution. In this paper, we propose a scalable double regularization (SDR)
method to utilize the entire dataset for simultaneous 3D structural
reconstruction across slices through total variation regularization within
slices and $L_1$ regularization between adjacent slices. SDR allows information
borrowing both within and between slices, contrasting with the traditional
methods that usually build on slice by slice reconstruction. We develop a
scalable and memory-efficient algorithm by exploiting the systematic sparsity
and consistent geometry induced by such Nano-CT data. We illustrate the
proposed method using synthetic data and two Nano-CT imaging datasets of
Jiulaodong (JLD) shale and Longmaxi (LMX) shale acquired in the Sichuan Basin.
These numerical experiments show that the proposed method substantially
outperforms selected alternatives both visually and quantitatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02268</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02268</id><created>2019-09-05</created><authors><author><keyname>Deng</keyname><forenames>Zhenzhou</forenames></author></authors><title>A novel TOF PET reconstruction method from limited-view data based on
  TV-minimization</title><categories>physics.med-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PET detectors provide the information of the position, the energy and the
timing about the decay events on the LOR. Traditional PET image reconstruction
has not taken the timing information into account, only used the timing
information for coincidence judgments. The high timing resolution PET detectors
provide very precise TOF information, then TOF image reconstruction method
which utilizes the timing information of PET detectors is so crucial for the
TOF PET system. We take advantage of timing information provided by a pair of
TOF PET detectors, and then reconstruct the activity distribution from the
limited-view projection data. Since the image reconstruction from the
limited-view data is an under-determined problem mathematically, conventional
algorithms cannot achieve the exact reconstruction of the limited-view problem.
In this work, we propose a half-analytic and half-iterative method named DF/LBM
(Direct Fourier and Logarithmic Barrier Method) to solve the limited-view
problem with the TOF information. The least square solution is obtained via DFM
(Direct Fourier Method), and then a convex optimization method named
logarithmic barrier method is employed to correct the least square solution.
The substance of the convex optimization is defining the components in the
null-space to satisfy some prior information (TV minimization), while the least
square solution has no components in the null-space. Applying this method to
Zubal phantom, the artifact generated by the least square solution is
eliminated, and PSNR is 30.6112, 34.8751 and 38.8998 when the timing resolution
is unused, 200ps and 100ps respectively and 16 views from $-45$ to $45$ are
adopted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02321</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02321</id><created>2019-09-05</created><authors><author><keyname>Anantrasirichai</keyname><forenames>N.</forenames></author><author><keyname>Biggs</keyname><forenames>J.</forenames></author><author><keyname>Albino</keyname><forenames>F.</forenames></author><author><keyname>Bull</keyname><forenames>D.</forenames></author></authors><title>The application of Convolutional Neural Networks to Detect Slow,
  Sustained Deformation in InSAR Timeseries</title><categories>eess.IV cs.CV</categories><doi>10.1029/2019GL084993</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated systems for detecting deformation in satellite InSAR imagery could
be used to develop a global monitoring system for volcanic and urban
environments. Here we explore the limits of a CNN for detecting slow, sustained
deformations in wrapped interferograms. Using synthetic data, we estimate a
detection threshold of 3.9cm for deformation signals alone, and 6.3cm when
atmospheric artefacts are considered. Over-wrapping reduces this to 1.8cm and
5.0cm respectively as more fringes are generated without altering SNR. We test
the approach on timeseries of cumulative deformation from Campi Flegrei and
Dallol, where over-wrapping improves classication performance by up to 15%. We
propose a mean-filtering method for combining results of different wrap
parameters to flag deformation. At Campi Flegrei, deformation of 8.5cm/yr was
detected after 60days and at Dallol, deformation of 3.5cm/yr was detected after
310 days. This corresponds to cumulative displacements of 3 cm and 4 cm
consistent with estimates based on synthetic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02344</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02344</id><created>2019-09-05</created><authors><author><keyname>Shi</keyname><forenames>Xueying</forenames></author><author><keyname>Dou</keyname><forenames>Qi</forenames></author><author><keyname>Xue</keyname><forenames>Cheng</forenames></author><author><keyname>Qin</keyname><forenames>Jing</forenames></author><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Heng</keyname><forenames>Pheng-Ann</forenames></author></authors><title>An Active Learning Approach for Reducing Annotation Cost in Skin Lesion
  Analysis</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>Accepted by MIML2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated skin lesion analysis is very crucial in clinical practice, as skin
cancer is among the most common human malignancy. Existing approaches with deep
learning have achieved remarkable performance on this challenging task,
however, heavily relying on large-scale labelled datasets. In this paper, we
present a novel active learning framework for cost-effective skin lesion
analysis. The goal is to effectively select and utilize much fewer labelled
samples, while the network can still achieve state-of-the-art performance. Our
sample selection criteria complementarily consider both informativeness and
representativeness, derived from decoupled aspects of measuring model certainty
and covering sample diversity. To make wise use of the selected samples, we
further design a simple yet effective strategy to aggregate intra-class images
in pixel space, as a new form of data augmentation. We validate our proposed
method on data of ISIC 2017 Skin Lesion Classification Challenge for two tasks.
Using only up to 50% of samples, our approach can achieve state-of-the-art
performances on both tasks, which are comparable or exceeding the accuracies
with full-data training, and outperform other well-known active learning
methods by a large margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02358</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02358</id><created>2019-09-05</created><authors><author><keyname>Zhou</keyname><forenames>Wei</forenames></author><author><keyname>Shi</keyname><forenames>Likun</forenames></author><author><keyname>Chen</keyname><forenames>Zhibo</forenames></author></authors><title>Tensor Oriented No-Reference Light Field Image Quality Assessment</title><categories>eess.IV cs.CV cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Light field image (LFI) quality assessment is becoming more and more
important, which helps to better guide the acquisition, processing and
application of immersive media. However, due to the inherent high dimensional
characteristics of LFI, the LFI quality assessment turns into a
multi-dimensional problem that requires consideration of the quality
degradation in both spatial and angular dimensions. Therefore, we propose a
novel Tensor oriented No-reference Light Field image Quality evaluator
(Tensor-NLFQ) based on tensor theory. Specifically, since the LFI is regarded
as a low-rank 4D tensor, the principle components of four oriented sub-aperture
view stacks are obtained via Tucker decomposition. Then, the Principal
Component Spatial Characteristic (PCSC) is designed to measure the
spatial-dimensional quality of LFI considering its global naturalness and local
frequency properties. Finally, the Tensor Angular Variation Index (TAVI) is
proposed to measure angular consistency quality by analyzing the structural
similarity distribution between the first principal component and each view in
the view stack. Extensive experimental results on four publicly available LFI
quality databases demonstrate that the proposed Tensor-NLFQ model outperforms
state-of-the-art 2D, 3D, multi-view, and LFI quality assessment algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02362</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02362</id><created>2019-09-05</created><authors><author><keyname>Abad</keyname><forenames>Mehdi Salehi Heydar</forenames></author><author><keyname>Ozfatura</keyname><forenames>Emre</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Ercetin</keyname><forenames>Ozgur</forenames></author></authors><title>Hierarchical Federated Learning Across Heterogeneous Cellular Networks</title><categories>cs.LG cs.DC cs.IT eess.SP math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study collaborative machine learning (ML) across wireless devices, each
with its own local dataset. Offloading these datasets to a cloud or an edge
server to implement powerful ML solutions is often not feasible due to latency,
bandwidth and privacy constraints. Instead, we consider federated edge learning
(FEEL), where the devices share local updates on the model parameters rather
than their datasets. We consider a heterogeneous cellular network (HCN), where
small cell base stations (SBSs) orchestrate FL among the mobile users (MUs)
within their cells, and periodically exchange model updates with the macro base
station (MBS) for global consensus. We employ gradient sparsification and
periodic averaging to increase the communication efficiency of this
hierarchical federated learning (FL) framework. We then show using CIFAR-10
dataset that the proposed hierarchical learning solution can significantly
reduce the communication latency without sacrificing the model accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02391</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02391</id><created>2019-09-02</created><authors><author><keyname>Choi</keyname><forenames>Hee-Sun</forenames></author><author><keyname>An</keyname><forenames>Junmo</forenames></author><author><keyname>Kim</keyname><forenames>Jin-Gyun</forenames></author><author><keyname>Jung</keyname><forenames>Jae-Yoon</forenames></author><author><keyname>Choi</keyname><forenames>Juhwan</forenames></author><author><keyname>Orzechowski</keyname><forenames>Grzegorz</forenames></author><author><keyname>Mikkola</keyname><forenames>Aki</forenames></author><author><keyname>Choi</keyname><forenames>Jin Hwan</forenames></author></authors><title>Data-driven simulation for general purpose multibody dynamics using deep
  neural networks</title><categories>cs.LG eess.SP stat.ML</categories><comments>32 pages, 17 figures, 11 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a machine learning-based simulation framework of
general-purpose multibody dynamics is introduced. The aim of the framework is
to generate a well-trained meta-model of multibody dynamics (MBD) systems. To
this end, deep neural network (DNN) is employed to the framework so as to
construct data-based meta-model representing multibody systems. Constructing
well-defined training data set with time variable is essential to get accurate
and reliable motion data such as displacement, velocity, acceleration, and
forces. As a result of the introduced approach, the meta-model provides motion
estimation of system dynamics without solving the analytical equations of
motion. The performance of the proposed DNN meta-modeling was evaluated to
represent several MBD systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02393</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02393</id><created>2019-08-30</created><authors><author><keyname>Syring</keyname><forenames>Anja F.</forenames></author><author><keyname>Tax</keyname><forenames>Niek</forenames></author><author><keyname>van der Aalst</keyname><forenames>Wil M. P.</forenames></author></authors><title>Evaluating Conformance Measures in Process Mining using Conformance
  Propositions (Extended version)</title><categories>cs.AI cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Process mining sheds new light on the relationship between process models and
real-life processes. Process discovery can be used to learn process models from
event logs. Conformance checking is concerned with quantifying the quality of a
business process model in relation to event data that was logged during the
execution of the business process. There exist different categories of
conformance measures. Recall, also called fitness, is concerned with
quantifying how much of the behavior that was observed in the event log fits
the process model. Precision is concerned with quantifying how much behavior a
process model allows for that was never observed in the event log.
Generalization is concerned with quantifying how well a process model
generalizes to behavior that is possible in the business process but was never
observed in the event log. Many recall, precision, and generalization measures
have been developed throughout the years, but they are often defined in an
ad-hoc manner without formally defining the desired properties up front. To
address these problems, we formulate 21 conformance propositions and we use
these propositions to evaluate current and existing conformance measures. The
goal is to trigger a discussion by clearly formulating the challenges and
requirements (rather than proposing new measures). Additionally, this paper
serves as an overview of the conformance checking measures that are available
in the process mining area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02411</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02411</id><created>2019-09-05</created><authors><author><keyname>G&#xf6;kceli</keyname><forenames>Selahattin</forenames></author><author><keyname>Levanen</keyname><forenames>Toni</forenames></author><author><keyname>Yli-Kaakinen</keyname><forenames>Juha</forenames></author><author><keyname>Riihonen</keyname><forenames>Taneli</forenames></author><author><keyname>Renfors</keyname><forenames>Markku</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>PAPR Reduction with Mixed-Numerology OFDM</title><categories>eess.SP</categories><comments>Accepted for publication as a Letter in the IEEE Wireless
  Communications Letters in September 2019. This is the revised version of
  original manuscript, and it is in press at the moment</comments><doi>10.1109/LWC.2019.2939521</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High peak-to-average power ratio (PAPR) is a critical problem in orthogonal
frequency-division multiplexing (OFDM). The fifth-generation New Radio (5G NR)
facilitates the utilization of multiple heterogeneous bandwidth parts (BWPs),
which complicates the PAPR problem even further and introduces inter-numerology
interference (INI) between the BWPs. This paper proposes two novel schemes to
reduce the PAPR of mixed-numerology OFDM signals. The first scheme is an
original enhanced iterative clipping-and-error-filtering (ICEF) approach that
cancels efficiently the INI along with PAPR reduction. This allows to achieve
efficient PAPR reduction while being compatible with well-known windowed
overlap-and-add (WOLA) processing. The second scheme is based on
fast-convolution (FC) processing, where PAPR reduction is embedded in the FC
filtering carried out using overlapping processing blocks. This allows one to
use any existing block-wise PAPR reduction method to reduce the composite
signals' PAPR with arbitrary BWP waveforms, and it is thus especially well
suited for processing mixed-numerology composite waveforms carrying multiple
BWPs with different OFDM numerologies. The performance of the proposed
algorithms is evaluated in the 5G NR context, and the essential performance
advantages are demonstrated and quantified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02445</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02445</id><created>2019-09-04</created><authors><author><keyname>Wu</keyname><forenames>Hao</forenames></author><author><keyname>Lyu</keyname><forenames>Xinchen</forenames></author><author><keyname>Tian</keyname><forenames>Hui</forenames></author></authors><title>Online Optimization of Wireless Powered Mobile-Edge Computing for
  Heterogeneous Industrial Internet of Things</title><categories>eess.SP cs.SY eess.SY</categories><comments>13 pages, 8 figures, journal</comments><doi>10.1109/JIOT.2019.2932995</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A spurt of progress in wireless power transfer (WPT) and mobile edge
computing (MEC) provides a promising approach for Industrial Internet of Things
(IIoT) to enhance the quality and productivity of manufacturing. Scheduling in
such a scenario is challenging due to congested wireless channels,
time-dependent energy constraints, complicated device heterogeneity, and
prohibitive signaling overheads. In this paper, we first propose an online
algorithm, called energy-aware resource scheduling (ERS), to maximize the
system utility comprising throughput and fairness, with consideration on both
system sustainability and stability. Based on Lyapunov optimization and convex
optimization techniques, the proposed algorithm achieves asymptotic optimality
for heterogeneous IIoT systems without prior knowledge of network state
information (NSI). Subsequently, we extend the ERS algorithm to a more
realistic scenario where the overhead and delay of NSI feedbacks are
nonnegligible. The optimal scheduling decisions of the scenario are provided,
and the optimality loss on system utility under outdated NSI is analyzed.
Simulations verify our theoretical claims and demonstrate the gains of our
proposed ERS algorithm over alternative benchmark schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02447</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02447</id><created>2019-08-29</created><authors><author><keyname>Paraschiv</keyname><forenames>Nicolae</forenames></author><author><keyname>Pricop</keyname><forenames>Emil</forenames></author><author><keyname>Fattahi</keyname><forenames>Jaouhar</forenames></author><author><keyname>Zamfir</keyname><forenames>Florin</forenames></author></authors><title>Towards a reliable approach on scaling in data acquisition</title><categories>eess.SP</categories><comments>Paper accepted for ICSTCC 2019 - 23rd International Conference on
  System Theory, Control and Computing, October 9-11, 2019, Sinaia, Romania</comments><doi>10.1109/ICSTCC.2019.8886145</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data acquisition is an important process in the functioning of any control
system. Usually, the acquired signal is analogic, representing a continuous
physical measure, and it should be processed in a digital system based on an
analog to digital converter (ADC) and a microcontroller. The ADC provides the
converted value in ADC units, but the system and its operator need the value
expressed in physical units. In this paper we propose a novel design solution
for the scaling module, which is a key component of a digital measurement
system. The scaling module refers to fitting the sensor result of a variable
number of bits depending on the ADC resolution into physical units. A general
method for scaling is proposed and a SageMath script is presented for obtaining
easily the scaling function. In the last part of the paper, the proposed method
is validated in a case study, by calculus, and it is implemented on a low-cost
development system in order to create a wireless sensor node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02448</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02448</id><created>2019-08-30</created><authors><author><keyname>Wang</keyname><forenames>Weizhong</forenames></author><author><keyname>Brady</keyname><forenames>Nicholas W.</forenames></author><author><keyname>Liao</keyname><forenames>Chenyao</forenames></author><author><keyname>Fahmy</keyname><forenames>Youssef A.</forenames></author><author><keyname>Chemali</keyname><forenames>Ephrem</forenames></author><author><keyname>West</keyname><forenames>Alan C.</forenames></author><author><keyname>Preindl</keyname><forenames>Matthias</forenames></author></authors><title>High-Fidelity State-of-Charge Estimation of Li-Ion Batteries Using
  Machine Learning</title><categories>eess.SP cs.LG cs.SY eess.SY</categories><comments>8 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a way to augment the existing machine learning algorithm
applied to state-of-charge estimation by introducing a form of pulse injection
to the running battery cells. It is believed that the information contained in
the pulse responses can be interpreted by a machine learning algorithm whereas
other techniques are difficult to decode due to the nonlinearity. The
sensitivity analysis of the amplitude of the current pulse is given through
simulation, allowing the researchers to select the appropriate current level
with respect to the desired accuracy improvement. A multi-layer feedforward
neural networks is trained to acquire the nonlinear relationship between the
pulse train and the ground-truth SoC. The experimental data is trained and the
results are shown to be promising with less than 2\% SoC estimation error using
layer sizes in the range of 10 - 10,000 trained in 0 - 1 million epochs. The
testing procedure specifically designed for the proposed technique is explained
and provided. The implementation of the proposed strategy is also discussed.
The detailed system layout to perform the augmented SoC estimation integrated
in the existing active balancing hardware has also been given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02449</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02449</id><created>2019-09-04</created><authors><author><keyname>Haldimann</keyname><forenames>David</forenames></author><author><keyname>Guerriero</keyname><forenames>Marco</forenames></author><author><keyname>Maret</keyname><forenames>Yannick</forenames></author><author><keyname>Bonavita</keyname><forenames>Nunzio</forenames></author><author><keyname>Ciarlo</keyname><forenames>Gregorio</forenames></author><author><keyname>Sabbadin</keyname><forenames>Marta</forenames></author></authors><title>A scalable algorithm for identifying multiple sensor faults using
  disentangled RNNs</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of detecting and identifying sensor faults is critical for
efficient, safe, regulatory-compliant and sustainable operations of modern
systems. Their increasing complexity brings new challenges for the Sensor Fault
Detection and Isolation (SFD-SFI) tasks. One of the key enablers for any
SFD-SFI methods employed in modern complex sensor systems, is the so-called
analytical redundancy, which is nothing but building an analytical model of the
sensors observations (either derived from first principles or identified from
historical data in a data-driven fashion). In a nutshell, SFD amounts to
generate and to monitor residuals by comparing the sensor measurements with the
model predictions with the idea that the faulty sensors will result in large
residuals (i.e. the defective sensors generate measurement that are
inconsistent with their expected behavior represented by the model). In this
paper we introduce a disentangled Recurrent Neural Network (RNN) with the
objective to cope with the \textit{smearing-out} effect, i.e. the propagation
of a sensor fault to the non-faulty sensors resulting in large misleading
residuals. Moreover, the introduction of a probabilistic model for the residual
generation allows us to develop a novel procedure for the identification of the
faulty sensors. The computational complexity of the proposed algorithm is
linear in the number of sensors as opposed to the combinatorial nature of the
SFI problem. Finally, we empirically verify the performances of the proposed
SFD-SFI architecture using a real data set collected at a petrochemical plant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02450</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02450</id><created>2019-08-31</created><authors><author><keyname>Wu</keyname><forenames>Dan</forenames></author><author><keyname>Wang</keyname><forenames>Bin</forenames></author><author><keyname>Sun</keyname><forenames>Kai</forenames></author><author><keyname>Xie</keyname><forenames>Le</forenames></author></authors><title>On Distribution Patterns of Power Flow Solutions</title><categories>eess.SP cs.SY eess.SY</categories><comments>All solution sets investigated in this letter paper are available on
  IEEEDataPort:
  https://ieee-dataport.org/open-access/power-flow-solution-sets-standard-ieee-test-systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental challenge in computer analysis of power flow is the rigorous
understanding of the impact of different loading levels on the solutions of the
power flow equation. This letter presents a comprehensive study of possible
numerical solutions that may arise as the loading level varies. In particular,
a type of &quot;false&quot; load flow solutions is reported for the first time as a
legitimate numerical solutions but with no engineering justification. The
existence and the mechanism of why this category of solutions exist are
rigorously analyzed. The probability mass function of voltage solution is shown
to be less dependent on loading levels. Furthermore, numbers of all actual
solutions and those solutions within engineering limits are summarized. This
letter presents a first attempt to compute such huge numbers of solutions to
the tested systems, and analyze their distribution patterns. All solution sets
investigated in this letter are posted online associated with this letter to
support any further research purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02451</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02451</id><created>2019-08-31</created><authors><author><keyname>Deng</keyname><forenames>Xianda</forenames></author><author><keyname>Thomas</keyname><forenames>Kyle</forenames></author><author><keyname>Huang</keyname><forenames>Huiying</forenames></author><author><keyname>Adams</keyname><forenames>Scott P</forenames></author><author><keyname>Liu</keyname><forenames>Hesen</forenames></author></authors><title>Online Dissolved Gas Analysis (DGA) Monitoring System</title><categories>eess.SP cs.SY eess.SY</categories><comments>9 pages</comments><journal-ref>CIGRE 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transformers are critical assets in power systems and transformer failures
can cause asset damage, customer outages, and safety concerns. Dominion Energy
has a sophisticated monitoring process for the transformers. One of the most
cost-efficient, convenient and practical transformer monitoring methods in
industry is Dissolved Gas Analysis(DGA). Leveraging new technology, on-line
transformer monitoring equipment is able to measure samples automatically. The
challenges of unstable sampling measurements and contradicted analysis results
for DGA are discussed in this paper. To provide further insight of transformer
health and support a new transformer monitoring process in Dominion Energy, a
DGA monitoring system is proposed. The DGA analysis methods used in the
monitoring system are selected based on laboratory verification results from
Dominion Energy. After derive the thresholds from IEEE standard, the solution
of the proposed monitoring system and test results are presented. In the end, a
historical transformer failure case in Dominion was analyzed and the results
indicate the monitoring system can provide prescient information and sufficient
supplemental report for making operational decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02477</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02477</id><created>2019-09-05</created><updated>2019-09-26</updated><authors><author><keyname>Wang</keyname><forenames>Dechun</forenames></author><author><keyname>Zhang</keyname><forenames>Ning</forenames></author><author><keyname>Sun</keyname><forenames>Xinzi</forenames></author><author><keyname>Zhang</keyname><forenames>Pengfei</forenames></author><author><keyname>Zhang</keyname><forenames>Chenxi</forenames></author><author><keyname>Cao</keyname><forenames>Yu</forenames></author><author><keyname>Liu</keyname><forenames>Benyuan</forenames></author></authors><title>AFP-Net: Realtime Anchor-Free Polyp Detection in Colonoscopy</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colorectal cancer (CRC) is a common and lethal disease. Globally, CRC is the
third most commonly diagnosed cancer in males and the second in females. For
colorectal cancer, the best screening test available is the colonoscopy. During
a colonoscopic procedure, a tiny camera at the tip of the endoscope generates a
video of the internal mucosa of the colon. The video data are displayed on a
monitor for the physician to examine the lining of the entire colon and check
for colorectal polyps. Detection and removal of colorectal polyps are
associated with a reduction in mortality from colorectal cancer. However, the
miss rate of polyp detection during colonoscopy procedure is often high even
for very experienced physicians. The reason lies in the high variation of polyp
in terms of shape, size, textural, color and illumination. Though challenging,
with the great advances in object detection techniques, automated polyp
detection still demonstrates a great potential in reducing the false negative
rate while maintaining a high precision. In this paper, we propose a novel
anchor free polyp detector that can localize polyps without using predefined
anchor boxes. To further strengthen the model, we leverage a Context
Enhancement Module and Cosine Ground truth Projection. Our approach can respond
in real time while achieving state-of-the-art performance with 99.36% precision
and 96.44% recall.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02483</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02483</id><created>2019-09-05</created><authors><author><keyname>Varnai</keyname><forenames>Peter</forenames></author><author><keyname>Dimarogonas</keyname><forenames>Dimos V.</forenames></author></authors><title>Gradient-Based STL Control with Application to Nonholonomic Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the control of dynamical systems under temporal logic
task specifications using gradient-based methods relying on quantitative
measures that express the extent to which the tasks are satisfied. A class of
controllers capable of providing satisfaction guarantees for simple systems and
specifications is introduced and then extended for the case of unicycle-like
dynamics. The possibility of combining such controllers in order to tackle more
complex task specifications while retaining their computational efficiency is
examined, and the practicalities related to an effective combination are
demonstrated through a simulation study. The introduced framework for
controller design lays ground for future work in the direction of effectively
combining such elementary controllers for the purpose of aiding exploration in
learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02485</identifier>
 <datestamp>2020-01-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02485</id><created>2019-09-05</created><updated>2020-01-10</updated><authors><author><keyname>D'Andrea</keyname><forenames>Carmen</forenames></author><author><keyname>Garcia-Rodriguez</keyname><forenames>Adrian</forenames></author><author><keyname>Geraci</keyname><forenames>Giovanni</forenames></author><author><keyname>Giordano</keyname><forenames>Lorenzo Galati</forenames></author><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author></authors><title>Analysis of UAV Communications in Cell-Free Massive MIMO systems</title><categories>cs.IT eess.SP math.IT</categories><comments>double-column, 14 pages, 8 figure, journal paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study support for unmanned aerial vehicle (UAV) communications through a
cell-free massive MIMO architecture, wherein a large number of access points
(APs) is deployed in place of large co-located massive MIMO arrays. We consider
also a variation of the pure cell-free architecture by applying a user-centric
association approach, where each user is served only from a subset of APs in
the network. Under the general assumption that the propagation channel between
the mobile stations, either UAVs or ground users (GUEs), and the APs follows a
Ricean distribution, we derive closed-form spectral efficiency lower bounds for
uplink and downlink with linear minimum mean square error channel estimation.
We consider several power allocation and user scheduling strategies for such a
system, and, among these, also minimum-rate maximizing power allocation
strategies to improve the system fairness. Our numerical results reveal that
cell-free massive MIMO architecture and its low-complexity user-centric
alternative may provide better performance than a traditional multi-cell
massive MIMO network deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02501</identifier>
 <datestamp>2019-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02501</id><created>2019-09-05</created><updated>2019-11-26</updated><authors><author><keyname>Bouchet</keyname><forenames>Dorian</forenames></author><author><keyname>Carminati</keyname><forenames>R&#xe9;mi</forenames></author><author><keyname>Mosk</keyname><forenames>Allard P.</forenames></author></authors><title>Influence of the local density of states on the localization precision
  of single particles in scattering environments</title><categories>physics.optics eess.SP</categories><comments>6 pages, 5 figures, + SI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the fundamental limit on the localization precision for a
subwavelength scatterer embedded in a strongly scattering environment, using
the external degrees of freedom provided by wavefront shaping. For a weakly
scattering target, the localization precision improves with the local density
of states at the target position. For a strongly scattering target, the
localization precision depends on the dressed polarizability that includes the
back action of the environment. This numerical study provides new insights for
the control of the information content of scattered light by wavefront shaping,
with potential applications in sensing, imaging, and nanoscale engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02511</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02511</id><created>2019-09-05</created><updated>2019-09-27</updated><authors><author><keyname>Zhou</keyname><forenames>Bo</forenames></author><author><keyname>Harrison</keyname><forenames>Adam P.</forenames></author><author><keyname>Yao</keyname><forenames>Jiawen</forenames></author><author><keyname>Cheng</keyname><forenames>Chi-Tung</forenames></author><author><keyname>Xiao</keyname><forenames>Jing</forenames></author><author><keyname>Liao</keyname><forenames>Chien-Hung</forenames></author><author><keyname>Lu</keyname><forenames>Le</forenames></author></authors><title>CT Data Curation for Liver Patients: Phase Recognition in Dynamic
  Contrast-Enhanced CT</title><categories>eess.IV cs.CV</categories><comments>11 pages, accepted by 2019 MICCAI - Medical Image Learning with Less
  Labels and Imperfect Data Workshop</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As the demand for more descriptive machine learning models grows within
medical imaging, bottlenecks due to data paucity will exacerbate. Thus,
collecting enough large-scale data will require automated tools to harvest
data/label pairs from messy and real-world datasets, such as hospital PACS.
This is the focus of our work, where we present a principled data curation tool
to extract multi-phase CT liver studies and identify each scan's phase from a
real-world and heterogenous hospital PACS dataset. Emulating a typical
deployment scenario, we first obtain a set of noisy labels from our
institutional partners that are text mined using simple rules from DICOM tags.
We train a deep learning system, using a customized and streamlined 3D SE
architecture, to identify non-contrast, arterial, venous, and delay phase
dynamic CT liver scans, filtering out anything else, including other types of
liver contrast studies. To exploit as much training data as possible, we also
introduce an aggregated cross entropy loss that can learn from scans only
identified as &quot;contrast&quot;. Extensive experiments on a dataset of 43K scans of
7680 patient imaging studies demonstrate that our 3DSE architecture, armed with
our aggregated loss, can achieve a mean F1 of 0.977 and can correctly harvest
up to 92.7% of studies, which significantly outperforms the text-mined and
standard-loss approach, and also outperforms other, and more complex, model
architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02515</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02515</id><created>2019-09-05</created><authors><author><keyname>Deakin</keyname><forenames>Callum</forenames></author><author><keyname>Liu</keyname><forenames>Zhixin</forenames></author></authors><title>Dual Frequency Comb Assisted Analog-to-Digital Conversion of Subcarrier
  Modulated Signals</title><categories>eess.SP physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photonic analog to digital conversion offers promise to overcome the
signal-to-noise ratio (SNR) and sample rate trade-off in conventional analog to
digital converters (ADCs), critical for modern digital communications and
signal analysis. We propose using phase-stable dual frequency combs with a
fixed frequency spacing offset to downconvert spectral slices of a broadband
signal and enable high resolution parallel digitization. To prove the concept
of our proposed method, we demonstrate the detection of a 10-GHz subcarrier
modulated (SCM) signal using 500-MHz bandwidth ADCs by optically converting the
SCM signal to ten 1-GHz bandwidth signals that can be processed in parallel for
full signal detection and reconstruction. Using sinusoidal wave based standard
ADC testing, we demonstrate a spurious-free dynamic range (SFDR) of &gt;45dB and
signal-to-noise-and-distortion (SINAD) of &gt;20dB, only limited by the receiver
front-end design. Our experimental investigation reveals that this SINAD
limitation can be overcome by improved receiver design, promising high
resolution ADC for broadband signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02526</identifier>
 <datestamp>2019-12-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02526</id><created>2019-09-05</created><authors><author><keyname>Lohani</keyname><forenames>Sanjaya</forenames></author><author><keyname>Knutson</keyname><forenames>Erin M.</forenames></author><author><keyname>Zhang</keyname><forenames>Wenlei</forenames></author><author><keyname>Glasser</keyname><forenames>Ryan T.</forenames></author></authors><title>Dispersion Characterization and Pulse Prediction with Machine Learning</title><categories>physics.optics cs.LG eess.SP quant-ph</categories><comments>7 pages, 5 figures</comments><journal-ref>OSA Continuum 2, 3438-3445 (2019)</journal-ref><doi>10.1364/OSAC.2.003438</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we demonstrate the efficacy of neural networks in the
characterization of dispersive media. We also develop a neural network to make
predictions for input probe pulses which propagate through a nonlinear
dispersive medium, which may be applied to predicting optimal pulse shapes for
a desired output. The setup requires only a single pulse for the probe,
providing considerable simplification of the current method of dispersion
characterization that requires frequency scanning across the entirety of the
gain and absorption features. We show that the trained networks are able to
predict pulse profiles as well as dispersive features that are nearly identical
to their experimental counterparts. We anticipate that the use of machine
learning in conjunction with optical communication and sensing methods, both
classical and quantum, can provide signal enhancement and experimental
simplifications even in the face of highly complex, layered nonlinear
light-matter interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02586</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02586</id><created>2019-09-05</created><updated>2019-09-22</updated><authors><author><keyname>Sankar</keyname><forenames>Gokul S.</forenames></author><author><keyname>Han</keyname><forenames>Kyoungseok</forenames></author></authors><title>Adaptive Robust Game-Theoretic Decision Making for Autonomous Vehicles</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a typical traffic scenario, autonomous vehicles are required to share the
road with other road participants, e.g., human driven vehicles, pedestrians,
etc. To successfully navigate the traffic, a cognitive hierarchy theory such as
level-k framework, can be used by the autonomous agents to categorize the
agents based on their depth of strategic thought and act accordingly. However,
mismatch between the vehicle dynamics and its predictions, and improper
classification of the agents can lead to undesirable behavior or collision.
Robust approaches can handle the uncertainties, however, might result in a
conservative behavior of the autonomous vehicle. This paper proposes an
adaptive robust decision making strategy for autonomous vehicles to handle
model mismatches in the prediction model while utilizing the confidence of the
driver behavior to obtain less conservative actions. The effectiveness of the
proposed approach is validated for a lane change maneuver in a highway driving
scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02642</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02642</id><created>2019-09-05</created><authors><author><keyname>Hesse</keyname><forenames>Linde S.</forenames></author><author><keyname>Kuling</keyname><forenames>Grey</forenames></author><author><keyname>Veta</keyname><forenames>Mitko</forenames></author><author><keyname>Martel</keyname><forenames>Anne L.</forenames></author></authors><title>Intensity augmentation for domain transfer of whole breast segmentation
  in MRI</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The segmentation of the breast from the chest wall is an important first step
in the analysis of breast magnetic resonance images. 3D U-nets have been shown
to obtain high segmentation accuracy and appear to generalize well when trained
on one scanner type and tested on another scanner, provided that a very similar
T1-weighted MR protocol is used. There has, however, been little work
addressing the problem of domain adaptation when image intensities or patient
orientation differ markedly between the training set and an unseen test set. To
overcome the domain shift we propose to apply extensive intensity augmentation
in addition to geometric augmentation during training. We explored both style
transfer and a novel intensity remapping approach as intensity augmentation
strategies. For our experiments, we trained a 3D U-net on T1-weighted scans and
tested on T2-weighted scans. By applying intensity augmentation we increased
segmentation performance from a DSC of 0.71 to 0.90. This performance is very
close to the baseline performance of training and testing on T2-weighted scans
(0.92). Furthermore, we applied our network to an independent test set made up
of publicly available scans acquired using a T1-weighted TWIST sequence and a
different coil configuration. On this dataset we obtained a performance of
0.89, close to the inter-observer variability of the ground truth segmentations
(0.92). Our results show that using intensity augmentation in addition to
geometric augmentation is a suitable method to overcome the intensity domain
shift and we expect it to be useful for a wide range of segmentation tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02647</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02647</id><created>2019-09-05</created><updated>2019-09-26</updated><authors><author><keyname>Abhishek</keyname><forenames>Vishal</forenames></author><author><keyname>Srivastava</keyname><forenames>Vaibhav</forenames></author></authors><title>On Epidemic Spreading under Mobility on Networks</title><categories>eess.SY cs.SI cs.SY math.DS math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a coupled epidemic-mobility model in which, at each time,
individuals move in a network of spatially-distributed regions
(sub-populations) according to a Continuous Time Markov Chain (CTMC) and
subsequently interact with the local sub-population according to an SIS model.
We derive a deterministic continuum limit model describing these interactions.
We prove the existence of a disease-free equilibrium and an endemic equilibrium
under different parameter regimes and establish their (almost) global
asymptotic stability using Lyapunov techniques. For the stability of
disease-free equilibrium, we also deduce some simple sufficient conditions
which highlight the influence of mobility on the behavior of the SIS dynamics.
Finally, we numerically illustrate that the derived model provides a good
approximation to the stochastic model with a finite population and also
demonstrate the influence of the graph structure on the transient performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02667</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02667</id><created>2019-09-05</created><authors><author><keyname>Mantena</keyname><forenames>Gautam</forenames></author><author><keyname>Kalinli</keyname><forenames>Ozlem</forenames></author><author><keyname>Abdel-Hamid</keyname><forenames>Ossama</forenames></author><author><keyname>McAllaster</keyname><forenames>Don</forenames></author></authors><title>Bandwidth Embeddings for Mixed-bandwidth Speech Recognition</title><categories>eess.AS cs.CL cs.LG</categories><comments>A part of this work is accepted in Interspeech 2019
  https://interspeech2019.org</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we tackle the problem of handling narrowband and wideband
speech by building a single acoustic model (AM), also called mixed bandwidth
AM. In the proposed approach, an auxiliary input feature is used to provide the
bandwidth information to the model, and bandwidth embeddings are jointly
learned as part of acoustic model training. Experimental evaluations show that
using bandwidth embeddings helps the model to handle the variability of the
narrow and wideband speech, and makes it possible to train a mixed-bandwidth
AM. Furthermore, we propose to use parallel convolutional layers to handle the
mismatch between the narrow and wideband speech better, where separate
convolution layers are used for each type of input speech signal. Our best
system achieves 13% relative improvement on narrowband speech, while not
degrading on wideband speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02671</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02671</id><created>2019-09-05</created><updated>2019-09-12</updated><authors><author><keyname>Canty</keyname><forenames>Brian</forenames></author><author><keyname>Paarporn</keyname><forenames>Keith</forenames></author><author><keyname>Brown</keyname><forenames>Philip N.</forenames></author><author><keyname>Alizadeh</keyname><forenames>Mahnoosh</forenames></author><author><keyname>Marden</keyname><forenames>Jason R.</forenames></author></authors><title>The Impact of Complex and Informed Adversarial Behavior in Graphical
  Coordination Games</title><categories>eess.SY cs.GT cs.SY math.OC</categories><comments>16 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How does system-level information impact the ability of an adversary to
degrade performance in a networked control system? How does the complexity of
an adversary's strategy affect its ability to degrade performance? This paper
focuses on these questions in the context of graphical coordination games where
an adversary can influence a given fraction of the agents in the system.
Focusing on the class of ring graphs, we explicitly highlight how both (i) the
complexity of the attack strategies and (ii) the knowledge of the graph
structure and agent identities can be leveraged by an adversary to degrade
system performance. We study four types of adversarial influence with varying
degrees of knowledge and complexity. We find these models can be ranked:
complex and informed adversaries can inflict more harm to the system whereas
simple and uninformed adversaries have the least ability to inflict damage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02692</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02692</id><created>2019-09-05</created><updated>2019-11-19</updated><authors><author><keyname>Yu</keyname><forenames>Junhao</forenames></author><author><keyname>Xie</keyname><forenames>Xuan</forenames></author><author><keyname>Feng</keyname><forenames>Hui</forenames></author><author><keyname>Hu</keyname><forenames>Bo</forenames></author></authors><title>On Critical Sampling of Time-Vertex Graph Signals</title><categories>eess.SP</categories><comments>GlobalSIP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Joint time-vertex graph signals are pervasive in real-world. This paper
focuses on the fundamental problem of sampling and reconstruction of joint
time-vertex graph signals. We prove the existence and the necessary condition
of a critical sampling set using minimum number of samples in time and graph
domain respectively. The theory proposed in this paper suggests to assign
heterogeneous sampling pattern for each node in a network under the constraint
of minimum resources. An efficient algorithm is also provided to construct a
critical sampling set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02702</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02702</id><created>2019-09-05</created><authors><author><keyname>Massaroli</keyname><forenames>Stefano</forenames></author><author><keyname>Poli</keyname><forenames>Michael</forenames></author><author><keyname>Califano</keyname><forenames>Federico</forenames></author><author><keyname>Faragasso</keyname><forenames>Angela</forenames></author><author><keyname>Park</keyname><forenames>Jinkyoo</forenames></author><author><keyname>Yamashita</keyname><forenames>Atsushi</forenames></author><author><keyname>Asama</keyname><forenames>Hajime</forenames></author></authors><title>Port-Hamiltonian Approach to Neural Network Training</title><categories>cs.NE cs.LG cs.SY eess.SY stat.ML</categories><comments>To appear in the Proceedings of the 58th IEEE Conference on Decision
  and Control (CDC 2019). The first two authors contributed equally to the work</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural networks are discrete entities: subdivided into discrete layers and
parametrized by weights which are iteratively optimized via difference
equations. Recent work proposes networks with layer outputs which are no longer
quantized but are solutions of an ordinary differential equation (ODE);
however, these networks are still optimized via discrete methods (e.g. gradient
descent). In this paper, we explore a different direction: namely, we propose a
novel framework for learning in which the parameters themselves are solutions
of ODEs. By viewing the optimization process as the evolution of a
port-Hamiltonian system, we can ensure convergence to a minimum of the
objective function. Numerical experiments have been performed to show the
validity and effectiveness of the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02710</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02710</id><created>2019-09-06</created><authors><author><keyname>Konovalov</keyname><forenames>Dmitry A.</forenames></author><author><keyname>Saleh</keyname><forenames>Alzayat</forenames></author><author><keyname>Efremova</keyname><forenames>Dina B.</forenames></author><author><keyname>Domingos</keyname><forenames>Jose A.</forenames></author><author><keyname>Jerry</keyname><forenames>Dean R.</forenames></author></authors><title>Automatic Weight Estimation of Harvested Fish from Images</title><categories>cs.CV eess.IV</categories><comments>Accepted for IEEE Digital Image Computing: Techniques and
  Applications, 2019 (DICTA 2019), 2-4 December 2019 in Perth, Australia,
  http://dicta2019.dictaconference.org/index.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximately 2,500 weights and corresponding images of harvested Lates
calcarifer (Asian seabass or barramundi) were collected at three different
locations in Queensland, Australia. Two instances of the LinkNet-34
segmentation Convolutional Neural Network (CNN) were trained. The first one was
trained on 200 manually segmented fish masks with excluded fins and tails. The
second was trained on 100 whole-fish masks. The two CNNs were applied to the
rest of the images and yielded automatically segmented masks. The one-factor
and two-factor simple mathematical weight-from-area models were fitted on 1072
area-weight pairs from the first two locations, where area values were
extracted from the automatically segmented masks. When applied to 1,400 test
images (from the third location), the one-factor whole-fish mask model achieved
the best mean absolute percentage error (MAPE), MAPE=4.36%. Direct
weight-from-image regression CNNs were also trained, where the no-fins based
CNN performed best on the test images with MAPE=4.28%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02712</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02712</id><created>2019-09-06</created><updated>2019-10-26</updated><authors><author><keyname>Zhang</keyname><forenames>Jiaqi</forenames></author><author><keyname>You</keyname><forenames>Keyou</forenames></author></authors><title>Decentralized Stochastic Gradient Tracking for Non-convex Empirical Risk
  Minimization</title><categories>cs.LG cs.DC cs.MA cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a decentralized stochastic gradient tracking (DSGT)
algorithm for a non-convex empirical risk minimization problem over a
peer-to-peer network, which is in sharp contrast to the existing DSGT works
only for the convex problem. To handle the variance among decentralized
datasets, the mini-batch in each node of the network is designed to be
proportional to the size of its local dataset. We explicitly evaluate the
convergence rate of DSGT in terms of algebraic connectivity of the network,
mini-batch size, and learning rate. Importantly, our theoretical rate has an
optimal dependence on the algebraic connectivity and can exactly recover the
rate of the centralized stochastic gradient method. Moreover, we demonstrate
that DSGT could achieve a linear speedup while a sublinear speedup is also
possible, depending on the problem at hand. Numerical experiments for neural
networks and logistic regression problems on CIFAR-10 finally illustrate the
advantages of DSGT for decentralized training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02730</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02730</id><created>2019-09-06</created><authors><author><keyname>Gao</keyname><forenames>Jiabao</forenames></author><author><keyname>Yi</keyname><forenames>Xuemei</forenames></author><author><keyname>Zhong</keyname><forenames>Caijun</forenames></author><author><keyname>Chen</keyname><forenames>Xiaoming</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author></authors><title>Deep Learning for Spectrum Sensing</title><categories>cs.IT eess.SP math.IT</categories><comments>4 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cognitive radio systems, the ability to accurately detect primary user's
signal is essential to secondary user in order to utilize idle licensed
spectrum. Conventional energy detector is a good choice for blind signal
detection, while it suffers from the well-known SNR-wall due to noise
uncertainty. In this letter, we firstly propose a deep learning based signal
detector which exploits the underlying structural information of the modulated
signals, and is shown to achieve the state of the art detection performance,
requiring no prior knowledge about channel state information or background
noise. In addition, the impacts of modulation scheme and sample length on
performance are investigated. Finally, a deep learning based cooperative
detection system is proposed, which is shown to provide substantial performance
gain over conventional cooperative sensing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02740</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02740</id><created>2019-09-06</created><authors><author><keyname>Celebi</keyname><forenames>Hasan Basri</forenames></author><author><keyname>Pitarokoilis</keyname><forenames>Antonios</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>Low-Latency Communication with Computational Complexity Constraints</title><categories>eess.SP cs.IT math.IT</categories><comments>Best student paper award at ISWCS 2019: International Symposium on
  Wireless Communication Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-latency communication is one of the most important application scenarios
in next-generation wireless networks. Often in communication-theoretic studies
latency is defined as the time required for the transmission of a packet over a
channel. However, with very stringent latency requirements and complexity
constrained receivers, the time required for the decoding of the packet cannot
be ignored and must be included in the total latency analysis through accurate
modeling. In this paper, we first present a way to calculate decoding time
using \textit{per bit} complexity metric and introduce an empirical model that
accurately describes the trade-off between the decoding complexity versus the
performance of state-of-the-art codes. By considering various communication
parameters, we show that including the decoding time in latency analyses has a
significant effect on the optimum selection of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02747</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02747</id><created>2019-09-06</created><authors><author><keyname>Yamakita</keyname><forenames>Takehisa</forenames></author></authors><title>Eelgrass beds and oyster farming at a lagoon before and after the Great
  East Japan Earthquake 2011: potential to apply deep learning at a coastal
  area</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a small number of case studies of automatic land cover
classification on the coastal area. Here, I test extraction of seagrass beds,
sandy area, oyster farming rafts at Mangoku-ura Lagoon, Miyagi, Japan by
comparing manual tracing, simple image segmentation, and image transformation
using deep learning. The result was used to extract the changes before and
after the earthquake and tsunami. The output resolution was best in the image
transformation method, which showed more than 69% accuracy for vegetation
classification by an assessment using random points on independent test data.
The distribution of oyster farming rafts was detected by the segmentation
model. Assessment of the change before and after the earthquake by the manual
tracing and image transformation result revealed increase of sand area and
decrease of the vegetation. By the segmentation model only the decrease of the
oyster farming was detected. These results demonstrate the potential to extract
the spatial pattern of these elements after an earthquake and tsunami. Index
Terms: Great East Japan Earthquake of 2011, Land use land cover (LULC),
Zosteracea seagrass, cultured oyster, deep learning, Mangoku Bay
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02753</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02753</id><created>2019-09-06</created><updated>2019-10-14</updated><authors><author><keyname>Picallo</keyname><forenames>Miguel</forenames></author><author><keyname>Bolognani</keyname><forenames>Saverio</forenames></author><author><keyname>D&#xf6;rfler</keyname><forenames>Florian</forenames></author></authors><title>Closing the Loop: Dynamic State Estimation and Feedback Optimization of
  Power Grids</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of online feedback optimization to solve the
AC Optimal Power Flow in real-time in power grids. This consists in
continuously driving the controllable power injections and loads towards the
optimal set-points in time-varying conditions based on real-time measurements
performed on the grid. However, instead of assuming noise-free full state
measurement like recent feedback optimization approaches, we connect a dynamic
State Estimation using available measurements, and study its dynamic
interaction with the optimization scheme. We certify stability of this
interconnection and the convergence in expectation of the state estimate and
the control inputs towards the true state values and optimal set-points
respectively. Additionally, we bound the resulting stochastic error. Finally,
we show the effectiveness of the approach on a test case using high resolution
consumption data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02759</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02759</id><created>2019-09-06</created><authors><author><keyname>Werner</keyname><forenames>Sebastian</forenames></author><author><keyname>Sch&#xe4;fer</keyname><forenames>Henrik</forenames></author><author><keyname>Hullin</keyname><forenames>Matthias</forenames></author></authors><title>A new operation mode for depth-focused high-sensitivity ToF range
  finding</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce pulsed correlation time-of-flight (PC-ToF) sensing, a new
operation mode for correlation time-of-flight range sensors that combines a
sub-nanosecond laser pulse source with a rectangular demodulation at the sensor
side. In contrast to previous work, our proposed measurement scheme attempts
not to optimize depth accuracy over the full measurement: With PC-ToF we trade
the global sensitivity of a standard C-ToF setup for measurements with strongly
localized high sensitivity -- we greatly enhance the depth resolution for the
acquisition of scene features around a desired depth of interest. Using
real-world experiments, we show that our technique is capable of achieving
depth resolutions down to 2mm using a modulation frequency as low as 10MHz and
an optical power as low as 1mW. This makes PC-ToF especially viable for
low-power applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02764</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02764</id><created>2019-09-06</created><updated>2019-09-09</updated><authors><author><keyname>Cevher</keyname><forenames>Deniz</forenames></author><author><keyname>Zepf</keyname><forenames>Sebastian</forenames></author><author><keyname>Klinger</keyname><forenames>Roman</forenames></author></authors><title>Towards Multimodal Emotion Recognition in German Speech Events in Cars
  using Transfer Learning</title><categories>cs.CL cs.HC eess.AS</categories><comments>12 pages, 2 figures, accepted at KONVENS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recognition of emotions by humans is a complex process which considers
multiple interacting signals such as facial expressions and both prosody and
semantic content of utterances. Commonly, research on automatic recognition of
emotions is, with few exceptions, limited to one modality. We describe an
in-car experiment for emotion recognition from speech interactions for three
modalities: the audio signal of a spoken interaction, the visual signal of the
driver's face, and the manually transcribed content of utterances of the
driver. We use off-the-shelf tools for emotion detection in audio and face and
compare that to a neural transfer learning approach for emotion recognition
from text which utilizes existing resources from other domains. We see that
transfer learning enables models based on out-of-domain corpora to perform
well. This method contributes up to 10 percentage points in F1, with up to 76
micro-average F1 across the emotions joy, annoyance and insecurity. Our
findings also indicate that off-the-shelf-tools analyzing face and audio are
not ready yet for emotion detection in in-car speech interactions without
further adjustments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02799</identifier>
 <datestamp>2019-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02799</id><created>2019-09-06</created><updated>2019-12-18</updated><authors><author><keyname>Shirokikh</keyname><forenames>Boris</forenames></author><author><keyname>Dalechina</keyname><forenames>Alexandra</forenames></author><author><keyname>Shevtsov</keyname><forenames>Alexey</forenames></author><author><keyname>Krivov</keyname><forenames>Egor</forenames></author><author><keyname>Kostjuchenko</keyname><forenames>Valery</forenames></author><author><keyname>Durgaryan</keyname><forenames>Amayak</forenames></author><author><keyname>Galkin</keyname><forenames>Mikhail</forenames></author><author><keyname>Osinov</keyname><forenames>Ivan</forenames></author><author><keyname>Golanov</keyname><forenames>Andrey</forenames></author><author><keyname>Belyaev</keyname><forenames>Mikhail</forenames></author></authors><title>Deep Learning for Brain Tumor Segmentation in Radiosurgery: Prospective
  Clinical Evaluation</title><categories>eess.IV cs.CV physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stereotactic radiosurgery is a minimally-invasive treatment option for a
large number of patients with intracranial tumors. As part of the therapy
treatment, accurate delineation of brain tumors is of great importance.
However, slice-by-slice manual segmentation on T1c MRI could be time-consuming
(especially for multiple metastases) and subjective. In our work, we compared
several deep convolutional networks architectures and training procedures and
evaluated the best model in a radiation therapy department for three types of
brain tumors: meningiomas, schwannomas and multiple brain metastases. The
developed semiautomatic segmentation system accelerates the contouring process
by 2.2 times on average and increases inter-rater agreement from 92.0% to
96.5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02825</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02825</id><created>2019-09-06</created><authors><author><keyname>Thanthrige</keyname><forenames>Udaya Sampath K. P. Miriya</forenames></author><author><keyname>Ahmed</keyname><forenames>Aya Mostafa</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>Supervised Learning Based Super Resolution DOA Estimation Utilizing
  Antenna Array Subsets</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a novel algorithm that can dramatically reduce
the number of antenna elements needed to accurately predict the direction of
arrival (DOA) for multiple input multiple output (MIMO) radar. The new proposed
algorithm predicts the received signal of a large antenna setup using reduced
number of antenna by using coupled dictionary learning. Hence, this enables the
MIMO radar to resolve more paths, which could not be resolved by the fewer
antennas. Specifically, we overcome the problem of inaccurate DOA estimation
due to a small virtual array setup. For example, we can use dictionary learning
to predict 100 virtual array elements using only 25. To evaluate our algorithm,
we used multiple signal classification (MUSIC) as a DOA estimation technique to
estimate the DOA for non coherent multiple targets. The results show that using
the predicted received signal, the proposed algorithm could resolve all the
targets in the scene, which could not been resolved using only the received
signal from the reduced antenna setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02829</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02829</id><created>2019-09-06</created><authors><author><keyname>Pattanaik</keyname><forenames>Priyadarshini Adyasha</forenames><affiliation>INTERMEDIA</affiliation></author><author><keyname>Wang</keyname><forenames>Zelong</forenames><affiliation>TSP</affiliation></author><author><keyname>Horain</keyname><forenames>Patrick</forenames><affiliation>INTERMEDIA</affiliation></author></authors><title>Deep CNN frameworks comparison for malaria diagnosis</title><categories>eess.IV cs.CV cs.LG</categories><proxy>ccsd</proxy><journal-ref>IMVIP 2019 Irish Machine Vision and Image Processing Conference,
  Sep 2019, Dublin, Ireland</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compare Deep Convolutional Neural Networks (DCNN) frameworks, namely
AlexNet and VGGNet, for the classification of healthy and malaria-infected
cells in large, grayscale, low quality and low resolution microscopic images,
in the case only a small training set is available. Experimental results
deliver promising results on the path to quick, automatic and precise
classification in unstained images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02838</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02838</id><created>2019-09-04</created><authors><author><keyname>Dutra</keyname><forenames>Dimas Abreu Archanjo</forenames></author></authors><title>Collocation-Based Output-Error Method for Aircraft System Identification</title><categories>stat.CO cs.SY eess.SY</categories><comments>2019 AIAA Aviation Forum 17-21 June 2019 Dallas, Texas</comments><doi>10.2514/6.2019-3087</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The output-error method is a mainstay of aircraft system identification from
flight-test data. It is the method of choice for a wide range of applications,
from the estimation of stability and control derivatives for aerodynamic
database generation to sensor bias estimation in flight-path reconstruction.
However, notable limitations of the output-error method are that it requires ad
hoc modifications for applications to unstable systems and it is an iterative
method which is particularly sensitive to the initial guess. In this paper, we
show how to reformulate the estimation as a collocation problem, an approach
common in other disciplines but seldomly used in flight vehicle system
identification. Both formulations are equivalent in terms of having the same
solution, but the collocation-based can be applied without modifications or
loss of efficiency to unstable systems. Examples with simulated and real-world
flight-test data also show that convergence to the optimum is obtained even
with poor initial guesses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02846</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02846</id><created>2019-09-04</created><authors><author><keyname>Zhang</keyname><forenames>Xinlin</forenames></author><author><keyname>Guo</keyname><forenames>Di</forenames></author><author><keyname>Huang</keyname><forenames>Yiman</forenames></author><author><keyname>Chen</keyname><forenames>Ying</forenames></author><author><keyname>Wang</keyname><forenames>Liansheng</forenames></author><author><keyname>Huang</keyname><forenames>Feng</forenames></author><author><keyname>Qu</keyname><forenames>Xiaobo</forenames></author></authors><title>Image Reconstruction with Low-rankness and Self-consistency of k-space
  Data in Parallel MRI</title><categories>physics.med-ph eess.IV</categories><comments>12 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel magnetic resonance imaging has served as an effective and widely
adopted technique for accelerating scans. The advent of sparse sampling offers
aggressive acceleration, allowing flexible sampling and better reconstruction.
Nevertheless, faithfully reconstructing the image from limited data still poses
a challenging task. Recent low-rank reconstruction methods exhibit superiority
in providing a high-quality image. However, none of them employ the routinely
acquired calibration data for improving image quality in parallel magnetic
resonance imaging. In this work, an image reconstruction approach named
STDLR-SPIRiT was proposed to explore the simultaneous two-directional
low-rankness (STDLR) in the k-space data and to mine the data correlation from
multiple receiver coils with the iterative self-consistent parallel imaging
reconstruction (SPIRiT). The reconstruction problem was then solved with a
singular value decomposition-free numerical algorithm. Experimental results of
phantom and brain imaging data show that the proposed method outperforms the
state-of-the-art methods in terms of suppressing artifacts and achieving the
lowest error. Moreover, the proposed method exhibits robust reconstruction even
when the auto-calibration signals are limited in parallel imaging. Overall the
proposed method can be exploited to achieve better image quality for
accelerated parallel magnetic resonance imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02848</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02848</id><created>2019-09-06</created><authors><author><keyname>Pfeifer</keyname><forenames>Martin</forenames></author><author><keyname>Caspart</keyname><forenames>Sven</forenames></author><author><keyname>Pfeiffer</keyname><forenames>Silja</forenames></author><author><keyname>Muller</keyname><forenames>Charles</forenames></author><author><keyname>Krebs</keyname><forenames>Stefan</forenames></author><author><keyname>Hohmann</keyname><forenames>Soeren</forenames></author></authors><title>Automated Generation of Explicit Port-Hamiltonian Models from Multi-Bond
  Graphs</title><categories>eess.SY cs.SY</categories><comments>15 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Port-Hamiltonian system theory is a well-known framework for the control of
complex physical systems. The majority of port-Hamiltonian control design
methods base on an explicit input-state-output port-Hamiltonian model for the
system under consideration. However in the literature, little effort has been
made towards a systematic, automatable derivation of such explicit models. In
this paper, we present a constructive, formally rigorous method for an explicit
port-Hamiltonian formulation of multi-bond graphs. Two conditions, one
necessary and one sufficient, for the existence of an explicit port-Hamiltonian
formulation of a multi-bond graph are given. We summarise our approach in a
fully automated algorithm of which we provide an exemplary implementation along
with this publication. The theoretical and practical results are illustrated
through an academic example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02850</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02850</id><created>2019-09-05</created><authors><author><keyname>Lee-Leon</keyname><forenames>Abigail</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Herremans</keyname><forenames>Dorien</forenames></author></authors><title>Doppler Invariant Demodulation for Shallow Water Acoustic Communications
  Using Deep Belief Networks</title><categories>eess.SP cs.LG cs.SD stat.ML</categories><journal-ref>Proceedings of 16th IEEE Asia Pacific Wireless Communications
  Symposium (APWCS). 2019. Singapore</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shallow water environments create a challenging channel for communications.
In this paper, we focus on the challenges posed by the frequency-selective
signal distortion called the Doppler effect. We explore the design and
performance of machine learning (ML) based demodulation methods --- (1) Deep
Belief Network-feed forward Neural Network (DBN-NN) and (2) Deep Belief
Network-Convolutional Neural Network (DBN-CNN) in the physical layer of Shallow
Water Acoustic Communication (SWAC). The proposed method comprises of a ML
based feature extraction method and classification technique. First, the
feature extraction converts the received signals to feature images. Next, the
classification model correlates the images to a corresponding binary
representative. An analysis of the ML based proposed demodulation shows that
despite the presence of instantaneous frequencies, the performance of the
algorithm shows an invariance with a small 2dB error margin in terms of bit
error rate (BER).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02851</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02851</id><created>2019-09-02</created><authors><author><keyname>Mizgajski</keyname><forenames>Jan</forenames></author><author><keyname>Szymczak</keyname><forenames>Adrian</forenames></author><author><keyname>G&#x142;owski</keyname><forenames>Robert</forenames></author><author><keyname>Szyma&#x144;ski</keyname><forenames>Piotr</forenames></author><author><keyname>&#x17b;elasko</keyname><forenames>Piotr</forenames></author><author><keyname>Augustyniak</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Morzy</keyname><forenames>Miko&#x142;aj</forenames></author><author><keyname>Carmiel</keyname><forenames>Yishay</forenames></author><author><keyname>Hodson</keyname><forenames>Jeff</forenames></author><author><keyname>W&#xf3;jciak</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Smoczyk</keyname><forenames>Daniel</forenames></author><author><keyname>Wr&#xf3;bel</keyname><forenames>Adam</forenames></author><author><keyname>Borowik</keyname><forenames>Bartosz</forenames></author><author><keyname>Artajew</keyname><forenames>Adam</forenames></author><author><keyname>Baran</keyname><forenames>Marcin</forenames></author><author><keyname>Kwiatkowski</keyname><forenames>Cezary</forenames></author><author><keyname>&#x17b;y&#x142;a-Hoppe</keyname><forenames>Marzena</forenames></author></authors><title>Avaya Conversational Intelligence: A Real-Time System for Spoken
  Language Understanding in Human-Human Call Center Conversations</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>Accepted for Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Avaya Conversational Intelligence(ACI) is an end-to-end, cloud-based solution
for real-time Spoken Language Understanding for call centers. It combines large
vocabulary, real-time speech recognition, transcript refinement, and entity and
intent recognition in order to convert live audio into a rich, actionable
stream of structured events. These events can be further leveraged with a
business rules engine, thus serving as a foundation for real-time supervision
and assistance applications. After the ingestion, calls are enriched with
unsupervised keyword extraction, abstractive summarization, and
business-defined attributes, enabling offline use cases, such as business
intelligence, topic mining, full-text search, quality assurance, and agent
training. ACI comes with a pretrained, configurable library of hundreds of
intents and a robust intent training environment that allows for efficient,
cost-effective creation and customization of customer-specific intents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02853</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02853</id><created>2019-09-03</created><authors><author><keyname>Glasser</keyname><forenames>Abraham</forenames></author></authors><title>Automatic Speech Recognition Services: Deaf and Hard-of-Hearing
  Usability</title><categories>cs.HC cs.SD eess.AS</categories><comments>6 pages, 4 figures</comments><doi>10.1145/3290607.3308461</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, speech is becoming a more common, if not standard, interface to
technology. This can be seen in the trend of technology changes over the years.
Increasingly, voice is used to control programs, appliances and personal
devices within homes, cars, workplaces, and public spaces through smartphones
and home assistant devices using Amazon's Alexa, Google's Assistant and Apple's
Siri, and other proliferating technologies. However, most speech interfaces are
not accessible for Deaf and Hard-of-Hearing (DHH) people. In this paper,
performances of current Automatic Speech Recognition (ASR) with voices of DHH
speakers are evaluated. ASR has improved over the years, and is able to reach
Word Error Rates (WER) as low as 5-6% [1][2][3], with the help of
cloud-computing and machine learning algorithms that take in custom vocabulary
models. In this paper, a custom vocabulary model is used, and the significance
of the improvement is evaluated when using DHH speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02859</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02859</id><created>2019-09-05</created><authors><author><keyname>Koutini</keyname><forenames>Khaled</forenames></author><author><keyname>Eghbal-zadeh</keyname><forenames>Hamid</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Receptive-field-regularized CNN variants for acoustic scene
  classification</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Accepted at Detection and Classification of Acoustic Scenes and
  Events 2019 (DCASE Workshop 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic scene classification and related tasks have been dominated by
Convolutional Neural Networks (CNNs). Top-performing CNNs use mainly audio
spectograms as input and borrow their architectural design primarily from
computer vision. A recent study has shown that restricting the receptive field
(RF) of CNNs in appropriate ways is crucial for their performance, robustness
and generalization in audio tasks. One side effect of restricting the RF of
CNNs is that more frequency information is lost. In this paper, we perform a
systematic investigation of different RF configuration for various CNN
architectures on the DCASE 2019 Task 1.A dataset. Second, we introduce
Frequency Aware CNNs to compensate for the lack of frequency information caused
by the restricted RF, and experimentally determine if and in what RF ranges
they yield additional improvement. The result of these investigations are
several well-performing submissions to different tasks in the DCASE 2019
Challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02869</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02869</id><created>2019-09-04</created><authors><author><keyname>Primus</keyname><forenames>Paul</forenames></author><author><keyname>Eghbal-zadeh</keyname><forenames>Hamid</forenames></author><author><keyname>Eitelsebner</keyname><forenames>David</forenames></author><author><keyname>Koutini</keyname><forenames>Khaled</forenames></author><author><keyname>Arzt</keyname><forenames>Andreas</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Exploiting Parallel Audio Recordings to Enforce Device Invariance in
  CNN-based Acoustic Scene Classification</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Published at the Workshop on Detection and Classification of Acoustic
  Scenes and Events, 25-26 October 2019, New York, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distribution mismatches between the data seen at training and at application
time remain a major challenge in all application areas of machine learning. We
study this problem in the context of machine listening (Task 1b of the DCASE
2019 Challenge). We propose a novel approach to learn domain-invariant
classifiers in an end-to-end fashion by enforcing equal hidden layer
representations for domain-parallel samples, i.e. time-aligned recordings from
different recording devices. No classification labels are needed for our domain
adaptation (DA) method, which makes the data collection process cheaper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02875</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02875</id><created>2019-09-06</created><authors><author><keyname>Ziaei</keyname><forenames>Nima</forenames></author></authors><title>Geolocation of an aircraft using image registration coupling modes for
  autonomous navigation</title><categories>eess.IV cs.CV</categories><comments>14 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes to study an alternative technology to the GPS system on
fixed wing aircraft using the aerial shots of landscapes from a ventral
monocular camera integrated into the aircraft and based on the technology of
image registration for aircraft geolocation purpose. Different types of use of
the image registration technology exist: the relative registration and the
absolute registration. The relative one is able to readjust position of the
aircraft from two successive aerial shots by knowing the aircraft s position of
image 1 and the overlap between the two images. The absolute registration
compare a real time aerial shot with pre-referenced images stored in a database
and permit the geolocation of the aircraft in comparing aerial shot with images
of the database. Each kind of image registration technology has its own flaw
preventing it to be used alone for aircraft geolocation. This study proposes to
evaluate, according to different physical parameters ( aircraft speed, flight
altitude, density of image points of interest), the coupling of these different
types of image registration. Finally, this study also aims to quantify some
image registration performances, particularly its execution time or its drift.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02896</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02896</id><created>2019-09-06</created><authors><author><keyname>Park</keyname><forenames>Jungwon</forenames></author><author><keyname>Kim</keyname><forenames>H. Jin</forenames></author></authors><title>Fast Trajectory Planning for Multiple Quadrotors using Relative Safe
  Flight Corridor</title><categories>eess.SY cs.RO cs.SY</categories><comments>8 pages, IROS2019 accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new trajectory planning method for multiple quadrotors
in obstacle-dense environments. We suggest a relative safe flight corridor
(RSFC) to model safe region between a pair of agents, and it is used to
generate linear constraints for inter-collision avoidance by utilizing the
convex hull property of relative Bernstein polynomial. Our approach employs a
graph-based multi-agent pathfinding algorithm to generate an initial
trajectory, which is used to construct a safe flight corridor (SFC) and RSFC.
We express the trajectory as a piecewise Bernstein polynomial and formulate the
trajectory planning problem into one quadratic programming problem using linear
constraints from SFC and RSFC. The proposed method can compute collision-free
trajectory for 16 agents within a second and for 64 agents less than a minute,
and it is validated both through simulation and indoor flight test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02909</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02909</id><created>2019-09-06</created><authors><author><keyname>Li</keyname><forenames>Zishuo</forenames></author><author><keyname>Mo</keyname><forenames>Yilin</forenames></author><author><keyname>Hao</keyname><forenames>Fei</forenames></author></authors><title>Game Theoretical Approach to Sequential Hypothesis Test with Byzantine
  Sensors</title><categories>eess.SY cs.GT cs.SY eess.SP</categories><comments>conference paper for CDC2019, 9 pages with appendix, 1 figure</comments><msc-class>60G40</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we consider the problem of sequential binary hypothesis test
in adversary environment based on observations from s sensors, with the caveat
that a subset of c sensors is compromised by an adversary, whose observations
can be manipulated arbitrarily. We choose the asymptotic Average Sample Number
(ASN) required to reach a certain level of error probability as the performance
metric of the system. The problem is cast as a game between the detector and
the adversary, where the detector aims to optimize the system performance while
the adversary tries to deteriorate it. We propose a pair of flip attack
strategy and voting hypothesis testing rule and prove that they form an
equilibrium strategy pair for the game. We further investigate the performance
of our proposed detection scheme with unknown number of compromised sensors and
corroborate our result with simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02923</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02923</id><created>2019-09-06</created><authors><author><keyname>Bakirtzis</keyname><forenames>Georgios</forenames></author><author><keyname>Simon</keyname><forenames>Brandon J.</forenames></author><author><keyname>Collins</keyname><forenames>Aidan G.</forenames></author><author><keyname>Fleming</keyname><forenames>Cody H.</forenames></author><author><keyname>Elks</keyname><forenames>Carl R.</forenames></author></authors><title>Data Driven Vulnerability Exploration for Design Phase System Analysis</title><categories>eess.SY cs.CR cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applying security as a lifecycle practice is becoming increasingly important
to combat targeted attacks in safety-critical systems. Among others there are
two significant challenges in this area: (1) the need for models that can
characterize a realistic system in the absence of an implementation and (2) an
automated way to associate attack vector information; that is, historical data,
to such system models. We propose the cybersecurity body of knowledge (CYBOK),
which takes in sufficiently characteristic models of systems and acts as a
search engine for potential attack vectors. CYBOK is fundamentally an
algorithmic approach to vulnerability exploration, which is a significant
extension to the body of knowledge it builds upon. By using CYBOK, security
analysts and system designers can work together to assess the overall security
posture of systems early in their lifecycle, during major design decisions and
before final product designs. Consequently, assisting in applying security
earlier and throughout the systems lifecycle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02924</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02924</id><created>2019-09-06</created><authors><author><keyname>Yvanoff-Frenchin</keyname><forenames>C.</forenames></author><author><keyname>Ramos</keyname><forenames>V.</forenames></author><author><keyname>Belabed</keyname><forenames>T.</forenames></author><author><keyname>Valderrama</keyname><forenames>C.</forenames></author></authors><title>An Edge Computing Robot Experience for Automatic Elderly Mental Health
  Care Based on Voice</title><categories>cs.HC eess.AS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We need open platforms driven by specialists, in which queries can be created
and collected for long periods and the diagnosis made, based on a rigorous
clinical follow-up. In this work, we developed a multi-language robot interface
helping to evaluate the mental health of seniors by interacting through
questions. The specialist can propose questions, as well as to receive users'
answers, in text form. The robot can automatically interact with the user using
the appropriate language. It can process the answers and under the guidance of
a specialist, questions and answers can be oriented towards the desired therapy
direction. The prototype, was implemented on an embedded device meant for edge
computing, thus it is able to filter environmental noise and can be placed
anywhere at home. The experience is now available for specialists to create
queries and answers through a Web-based interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02953</identifier>
 <datestamp>2020-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02953</id><created>2019-09-06</created><authors><author><keyname>Chen</keyname><forenames>Jianan</forenames></author><author><keyname>Milot</keyname><forenames>Laurent</forenames></author><author><keyname>Cheung</keyname><forenames>Helen M. C.</forenames></author><author><keyname>Martel</keyname><forenames>Anne L.</forenames></author></authors><title>Unsupervised Clustering of Quantitative Imaging Phenotypes using
  Autoencoder and Gaussian Mixture Model</title><categories>eess.IV cs.CV q-bio.QM</categories><comments>Accepted at MICCAI 2019</comments><doi>10.1007/978-3-030-32251-9_63</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative medical image computing (radiomics) has been widely applied to
build prediction models from medical images. However, overfitting is a
significant issue in conventional radiomics, where a large number of radiomic
features are directly used to train and test models that predict genotypes or
clinical outcomes. In order to tackle this problem, we propose an unsupervised
learning pipeline composed of an autoencoder for representation learning of
radiomic features and a Gaussian mixture model based on minimum message length
criterion for clustering. By incorporating probabilistic modeling, disease
heterogeneity has been taken into account. The performance of the proposed
pipeline was evaluated on an institutional MRI cohort of 108 patients with
colorectal cancer liver metastases. Our approach is capable of automatically
selecting the optimal number of clusters and assigns patients into clusters
(imaging subtypes) with significantly different survival rates. Our method
outperforms other unsupervised clustering methods that have been used for
radiomics analysis and has comparable performance to a state-of-the-art imaging
biomarker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02966</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02966</id><created>2019-09-06</created><authors><author><keyname>Emam</keyname><forenames>Yousef</forenames></author><author><keyname>Glotfelter</keyname><forenames>Paul</forenames></author><author><keyname>Egerstedt</keyname><forenames>Magnus</forenames></author></authors><title>Robust Barrier Functions for a Fully Autonomous, Remotely Accessible
  Swarm-Robotics Testbed</title><categories>cs.RO cs.MA cs.SY eess.SY</categories><comments>Submitted and accepted for the 58th IEEE Conference on Decision and
  Control (CDC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Robotarium, a remotely accessible swarm-robotics testbed, has provided
free, open access to robotics and controls research for hundreds of users in
thousands of experiments. This high level of usage requires autonomy in the
system, which mainly corresponds to constraint satisfaction in the context of
users' submissions. In other words, in case that the users' inputs to the
robots may lead to collisions, these inputs must be altered to avoid these
collisions automatically. However, these alterations must be minimal so as to
preserve the users' objective in the experiment. Toward this end, the system
has utilized barrier functions, which admit a minimally invasive
controller-synthesis procedure. However, barrier functions are yet to be
robustified with respect to unmodeled disturbances (e.g., wheel slip or packet
loss) in a manner conducive to real-time synthesis. As such, this paper
formulates robust barrier functions for a general class of disturbed
control-affine systems that, in turn, is key for the Robotarium to operate
fully autonomously (i.e., without human supervision). Experimental results
showcase the effectiveness of this robust formulation in a long-term experiment
in the Robotarium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02971</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.02971</id><created>2019-09-06</created><authors><author><keyname>Rad</keyname><forenames>Ali Bahrami</forenames></author><author><keyname>Zabihi</keyname><forenames>Morteza</forenames></author><author><keyname>Zhao</keyname><forenames>Zheng</forenames></author><author><keyname>Gabbouj</keyname><forenames>Moncef</forenames></author><author><keyname>Katsaggelos</keyname><forenames>Aggelos K.</forenames></author><author><keyname>S&#xe4;rkk&#xe4;</keyname><forenames>Simo</forenames></author></authors><title>Automated Polysomnography Analysis for Detection of Non-Apneic and
  Non-Hypopneic Arousals using Feature Engineering and a Bidirectional LSTM
  Network</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: The aim of this study is to develop an automated classification
algorithm for polysomnography (PSG) recordings to detect non-apneic and
non-hypopneic arousals. Our particular focus is on detecting the respiratory
effort-related arousals (RERAs) which are very subtle respiratory events that
do not meet the criteria for apnea or hypopnea, and are more challenging to
detect. Methods: The proposed algorithm is based on a bidirectional long
short-term memory (BiLSTM) classifier and 465 multi-domain features, extracted
from multimodal clinical time series. The features consist of a set of
physiology-inspired features (n = 75), obtained by multiple steps of feature
selection and expert analysis, and a set of physiology-agnostic features (n =
390), derived from scattering transform. Results: The proposed algorithm is
validated on the 2018 PhysioNet challenge dataset. The overall performance in
terms of the area under the precision-recall curve (AUPRC) is 0.50 on the
hidden test dataset. This result is tied for the second-best score during the
follow-up and official phases of the 2018 PhysioNet challenge. Conclusions: The
results demonstrate that it is possible to automatically detect subtle
non-apneic/non-hypopneic arousal events from PSG recordings. Significance:
Automatic detection of subtle respiratory events such as RERAs together with
other non-apneic/non-hypopneic arousals will allow detailed annotations of
large PSG databases. This contributes to a better retrospective analysis of
sleep data, which may also improve the quality of treatment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03019</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03019</id><created>2019-08-22</created><authors><author><keyname>Zhao</keyname><forenames>Xingyu</forenames></author><author><keyname>Osborne</keyname><forenames>Matt</forenames></author><author><keyname>Lantair</keyname><forenames>Jenny</forenames></author><author><keyname>Robu</keyname><forenames>Valentin</forenames></author><author><keyname>Flynn</keyname><forenames>David</forenames></author><author><keyname>Huang</keyname><forenames>Xiaowei</forenames></author><author><keyname>Fisher</keyname><forenames>Michael</forenames></author><author><keyname>Papacchini</keyname><forenames>Fabio</forenames></author><author><keyname>Ferrando</keyname><forenames>Angelo</forenames></author></authors><title>Towards Integrating Formal Verification of Autonomous Robots with
  Battery Prognostics and Health Management</title><categories>cs.AI cs.RO cs.SY eess.SP eess.SY</categories><journal-ref>Proceedings of 17th International Conference on Software
  Engineering and Formal Methods (SEFM 2019), Oslo, Norway (September 2019)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The battery is a key component of autonomous robots. Its performance limits
the robot's safety and reliability. Unlike liquid-fuel, a battery, as a
chemical device, exhibits complicated features, including (i) capacity fade
over successive recharges and (ii) increasing discharge rate as the state of
charge (SOC) goes down for a given power demand. Existing formal verification
studies of autonomous robots, when considering energy constraints, formalise
the energy component in a generic manner such that the battery features are
overlooked. In this paper, we model an unmanned aerial vehicle (UAV) inspection
mission on a wind farm and via probabilistic model checking in PRISM show (i)
how the battery features may affect the verification results significantly in
practical cases; and (ii) how the battery features, together with dynamic
environments and battery safety strategies, jointly affect the verification
results. Potential solutions to explicitly integrate battery prognostics and
health management (PHM) with formal verification of autonomous robots are also
discussed to motivate future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03026</identifier>
 <datestamp>2019-12-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03026</id><created>2019-09-06</created><updated>2019-12-06</updated><authors><author><keyname>Traub</keyname><forenames>Jonas</forenames><affiliation>Technische Universit&#xe4;t Berlin, German Research Center for Artificial Intelligence</affiliation></author><author><keyname>Quian&#xe9;-Ruiz</keyname><forenames>Jorge-Arnulfo</forenames><affiliation>Technische Universit&#xe4;t Berlin, German Research Center for Artificial Intelligence</affiliation></author><author><keyname>Kaoudi</keyname><forenames>Zoi</forenames><affiliation>Technische Universit&#xe4;t Berlin, German Research Center for Artificial Intelligence</affiliation></author><author><keyname>Markl</keyname><forenames>Volker</forenames><affiliation>Technische Universit&#xe4;t Berlin, German Research Center for Artificial Intelligence</affiliation></author></authors><title>Agora: Towards An Open Ecosystem for Democratizing Data Science &amp;
  Artificial Intelligence</title><categories>cs.DB cs.AI cs.DC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data science and artificial intelligence are driven by a plethora of diverse
data-related assets including datasets, data streams, algorithms, processing
software, compute resources, and domain knowledge. As providing all these
assets requires a huge investment, data sciences and artificial intelligence
are currently dominated by a small number of providers who can afford these
investments. In this paper, we present a vision of a data ecosystem to
democratize data science and artificial intelligence. In particular, we
envision a data infrastructure for fine-grained asset exchange in combination
with scalable systems operation. This will overcome lock-in effects and remove
entry barriers for new asset providers. Our goal is to enable companies,
research organizations, and individuals to have equal access to data, data
science, and artificial intelligence. Such an open ecosystem has recently been
put on the agenda of several governments and industrial associations. We point
out the requirements and the research challenges as well as outline an initial
data infrastructure architecture for building such a data ecosystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03030</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03030</id><created>2019-09-06</created><authors><author><keyname>Wei</keyname><forenames>Xizi</forenames></author><author><keyname>Hunt</keyname><forenames>Melvyn</forenames></author><author><keyname>Skilling</keyname><forenames>Adrian</forenames></author></authors><title>Neural Network-Based Modeling of Phonetic Durations</title><categories>cs.SD cs.LG eess.AS</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A deep neural network (DNN)-based model has been developed to predict
non-parametric distributions of durations of phonemes in specified phonetic
contexts and used to explore which factors influence durations most. Major
factors in US English are pre-pausal lengthening, lexical stress, and speaking
rate. The model can be used to check that text-to-speech (TTS) training speech
follows the script and words are pronounced as expected. Duration prediction is
poorer with training speech for automatic speech recognition (ASR) because the
training corpus typically consists of single utterances from many speakers and
is often noisy or casually spoken. Low probability durations in ASR training
material nevertheless mostly correspond to non-standard speech, with some
having disfluencies. Children's speech is disproportionately present in these
utterances, since children show much more variation in timing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03037</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03037</id><created>2019-09-06</created><authors><author><keyname>Ghojogh</keyname><forenames>Benyamin</forenames></author><author><keyname>Pasand</keyname><forenames>Ali Saheb</forenames></author><author><keyname>Karray</keyname><forenames>Fakhri</forenames></author><author><keyname>Crowley</keyname><forenames>Mark</forenames></author></authors><title>Quantized Fisher Discriminant Analysis</title><categories>stat.ML cs.IT cs.LG eess.IV math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new subspace learning method, named Quantized Fisher
Discriminant Analysis (QFDA), which makes use of both machine learning and
information theory. There is a lack of literature for combination of machine
learning and information theory and this paper tries to tackle this gap. QFDA
finds a subspace which discriminates the uniformly quantized images in the
Discrete Cosine Transform (DCT) domain at least as well as discrimination of
non-quantized images by Fisher Discriminant Analysis (FDA) while the images
have been compressed. This helps the user to throw away the original images and
keep the compressed images instead without noticeable loss of classification
accuracy. We propose a cost function whose minimization can be interpreted as
rate-distortion optimization in information theory. We also propose quantized
Fisherfaces for facial analysis in QFDA. Our experiments on AT&amp;T face dataset
and Fashion MNIST dataset show the effectiveness of this subspace learning
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03050</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03050</id><created>2019-09-09</created><authors><author><keyname>Liao</keyname><forenames>kaisheng</forenames></author><author><keyname>Tao</keyname><forenames>Guanhong</forenames></author><author><keyname>Zhong</keyname><forenames>Yi</forenames></author><author><keyname>Zhang</keyname><forenames>Yaping</forenames></author><author><keyname>Zhang</keyname><forenames>Zhenghong</forenames></author></authors><title>Sequential Convolutional Recurrent Neural Networks for Fast Automatic
  Modulation Classification</title><categories>eess.SP cs.LG</categories><comments>5 pages, 6 fgures, IEEE Journal</comments><doi>10.3847/1538-4357/ab1b2a</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel and efficient end-to-end learning model for automatic modulation
classification (AMC) is proposed for wireless spectrum monitoring applications,
which automatically learns from the time domain in-phase and quadrature (IQ)
data without requiring the design of hand-crafted expert features. With the
intuition of convolutional layers with pooling serving as front-end feature
distillation and dimensionality reduction, sequential convolutional recurrent
neural networks (SCRNNs) are developed to take complementary advantage of
parallel computing capability of convolutional neural networks (CNNs) and
temporal sensitivity of recurrent neural networks (RNNs). Experimental results
demonstrate that the proposed architecture delivers overall superior
performance in signal to noise ratio (SNR) range above -10 dB, and achieves
significantly improved classification accuracy from 80% to 92.1% at high SNRs,
while drastically reduces the training and prediction time by approximately 74%
and 67%, respectively. Furthermore, a comparative study is performed to
investigate the impacts of various SCRNN structure settings on classification
performance. A representative SCRNN architecture with the two-layer CNN and
subsequent two-layer long short-term memory (LSTM) is developed to suggest the
option for fast AMC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03082</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03082</id><created>2019-09-06</created><authors><author><keyname>Roy</keyname><forenames>Dhrubojyoti</forenames></author><author><keyname>Srivastava</keyname><forenames>Sangeeta</forenames></author><author><keyname>Kusupati</keyname><forenames>Aditya</forenames></author><author><keyname>Jain</keyname><forenames>Pranshu</forenames></author><author><keyname>Varma</keyname><forenames>Manik</forenames></author><author><keyname>Arora</keyname><forenames>Anish</forenames></author></authors><title>One Size Does Not Fit All: Multi-Scale, Cascaded RNNs for Radar
  Classification</title><categories>eess.SP cs.LG</categories><comments>Conditionally accepted to ACM BuildSys 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Edge sensing with micro-power pulse-Doppler radars is an emergent domain in
monitoring and surveillance with several smart city applications. Existing
solutions for the clutter versus multi-source radar classification task are
limited in terms of either accuracy or efficiency, and in some cases, struggle
with a trade-off between false alarms and recall of sources. We find that this
problem can be resolved by learning the classifier across multiple time-scales.
We propose a multi-scale, cascaded recurrent neural network architecture,
MSC-RNN, comprised of an efficient multi-instance learning (MIL) Recurrent
Neural Network (RNN) for clutter discrimination at a lower tier, and a more
complex RNN classifier for source classification at the upper tier. By
controlling the invocation of the upper RNN with the help of the lower tier
conditionally, MSC-RNN achieves an overall accuracy of 0.972. Our approach
holistically improves the accuracy and per-class recalls over ML models
suitable for radar inferencing. Notably, we outperform cross-domain handcrafted
feature engineering with time-domain deep feature learning, while also being up
to $\sim$3$\times$ more efficient than a competitive solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03108</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03108</id><created>2019-09-06</created><updated>2019-09-12</updated><authors><author><keyname>Hou</keyname><forenames>Le</forenames></author><author><keyname>Cheng</keyname><forenames>Youlong</forenames></author><author><keyname>Shazeer</keyname><forenames>Noam</forenames></author><author><keyname>Parmar</keyname><forenames>Niki</forenames></author><author><keyname>Li</keyname><forenames>Yeqing</forenames></author><author><keyname>Korfiatis</keyname><forenames>Panagiotis</forenames></author><author><keyname>Drucker</keyname><forenames>Travis M.</forenames></author><author><keyname>Blezek</keyname><forenames>Daniel J.</forenames></author><author><keyname>Song</keyname><forenames>Xiaodan</forenames></author></authors><title>High Resolution Medical Image Analysis with Spatial Partitioning</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical images such as 3D computerized tomography (CT) scans and pathology
images, have hundreds of millions or billions of voxels/pixels. It is
infeasible to train CNN models directly on such high resolution images, because
neural activations of a single image do not fit in the memory of a single
GPU/TPU, and naive data and model parallelism approaches do not work. Existing
image analysis approaches alleviate this problem by cropping or down-sampling
input images, which leads to complicated implementation and sub-optimal
performance due to information loss. In this paper, we implement spatial
partitioning, which internally distributes the input and output of
convolutional layers across GPUs/TPUs. Our implementation is based on the
Mesh-TensorFlow framework and the computation distribution is transparent to
end users. With this technique, we train a 3D Unet on up to 512 by 512 by 512
resolution data. To the best of our knowledge, this is the first work for
handling such high resolution images end-to-end.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03115</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03115</id><created>2019-09-06</created><authors><author><keyname>Radenkovi&#x107;</keyname><forenames>Milena &#x10c;uki&#x107;</forenames></author><author><keyname>Lopez</keyname><forenames>Victoria Lopez</forenames></author></authors><title>Machine Learning Approaches for Detecting the Depression from
  Resting-State Electroencephalogram (EEG): A Review Study</title><categories>eess.SP cs.LG nlin.CD stat.ML</categories><comments>30 pages, 1 table. arXiv admin note: substantial text overlap with
  arXiv1903.11454</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we aimed at reviewing present literature on employing
nonlinear analysis in combination with machine learning methods, in depression
detection or prediction task. We are focusing on an affordable data-driven
approach, applicable for everyday clinical practice, and in particular, those
based on electroencephalographic (EEG) recordings. Among those studies
utilizing EEG, we are discussing a group of applications used for detecting the
depression based on the resting state EEG (detection studies) and
interventional studies (using stimulus in their protocols or aiming to predict
the outcome of therapy). We conclude with a discussion and review of guidelines
to improve the reliability of developed models that could serve the improvement
of diagnostic and more accurate treatment of depression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03120</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03120</id><created>2019-09-06</created><authors><author><keyname>Sun</keyname><forenames>Xinyao</forenames></author><author><keyname>Zimmer</keyname><forenames>Aaron</forenames></author><author><keyname>Mukherjee</keyname><forenames>Subhayan</forenames></author><author><keyname>Kottayil</keyname><forenames>Navaneeth Kamballur</forenames></author><author><keyname>Ghuman</keyname><forenames>Parwant</forenames></author><author><keyname>Cheng</keyname><forenames>Irene</forenames></author></authors><title>DeepInSAR: A Deep Learning Framework for SAR Interferometric Phase
  Restoration and Coherence Estimation</title><categories>eess.IV cs.CV</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past decade, Interferometric Synthetic Aperture Radar (InSAR) has
become a successful remote sensing technique. However, during the acquisition
step, microwave reflections received at satellite are usually disturbed by
strong noise, leading to a noisy single-look complex (SLC) SAR image. The
quality of their interferometric phase is even worse. InSAR phase filtering is
an ill-posed problem and plays a key role in subsequent processing. However,
most of existing methods usually require expert supervision or heavy runtime,
which limits the usability and scalability for practical usages such as
wide-area monitoring and forecasting. In this work, we propose a deep
convolutional neural network (CNN) based model DeepInSAR to intelligently solve
both the phase filtering and coherence estimation problems. We demonstrate our
DeepInSAR using both simulated and real data. A teacher-student framework is
proposed to deal with the issue that there is no ground truth sample for
real-world InSAR data. Quantitative and qualitative comparisons show that
DeepInSAR achieves comparable or even better results than its stacked-based
teacher method on new test datasets but requiring fewer pairs of SLCs as well
as outperforms three other established non-stack based methods with less
running time and no human supervision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03143</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03143</id><created>2019-09-06</created><authors><author><keyname>Vieira</keyname><forenames>Henrique S.</forenames></author><author><keyname>de Paiva</keyname><forenames>Ely C.</forenames></author><author><keyname>Moriguchi</keyname><forenames>Sergio K.</forenames></author><author><keyname>Carvalho</keyname><forenames>Jose R. H.</forenames></author></authors><title>Unified Backstepping Sliding Mode Framework for Airship Control Design</title><categories>eess.SY cs.SY</categories><comments>12 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new kind of vectorial backstepping sliding mode control
(BSMC) for the positioning and trajectory tracking of an autonomous robotic
airship. Also, a unified framework basis for the design/analysis of vectorial
BSMC, as well as sliding mode control (SMC) and backstepping control (BS) for a
system in lower triangular block form is derived. The design framework makes it
easier the theoretical-based comparative analysis of performances/robustness
between the three nonlinear control approaches. Simulation results for the
positioning and tracking of the autonomous airship illustrate the proposal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03181</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03181</id><created>2019-09-06</created><updated>2019-12-28</updated><authors><author><keyname>Wang</keyname><forenames>Shen</forenames></author><author><keyname>Taha</keyname><forenames>Ahmad F.</forenames></author><author><keyname>Gatsis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Giacomoni</keyname><forenames>Marcio</forenames></author></authors><title>Receding Horizon Control for Drinking Water Networks: The Case for
  Geometric Programming</title><categories>eess.SY cs.SY math.OC</categories><comments>IEEE Transactions on Control of Network Systems, In Press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal, network-driven control of Water Distribution Networks (WDN) is very
difficult: valve and pump models form non-trivial, combinatorial logic;
hydraulic models are nonconvex; water demand patterns are uncertain; and WDN
are naturally large-scale. Prior research on control of WDN addressed major
research challenges, yet either (i) adopted simplified hydraulic models, WDN
topologies, and rudimentary valve/pump modeling or (ii) used mixed-integer,
nonconvex optimization to solve WDN control problems.
  The objective of this paper is to develop tractable computational algorithms
to manage WDN operation, while considering arbitrary topology, flow direction,
an abundance of valve types, control objectives, hydraulic models, and
operational constraints---all while only using convex, continuous optimization.
Specifically, we propose new Geometric Programming (GP)-based Model Predictive
Control (MPC) algorithms, designed to solve the water flow equations and obtain
WDN controls, i.e., pump/valve schedules alongside heads and flows. The
proposed approach amounts to solving a series of convex optimization problems
that graciously scale to large networks. The proposed approach is tested using
a 126-node network with many valves and pumps and shown to outperform
traditional, rule-based control. The developed GP-based MPC algorithms, as well
as the numerical test results are all included on Github.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03182</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03182</id><created>2019-09-06</created><updated>2019-09-10</updated><authors><author><keyname>Wang</keyname><forenames>Shen</forenames></author><author><keyname>Taha</keyname><forenames>Ahmad F.</forenames></author><author><keyname>Sela</keyname><forenames>Lina</forenames></author><author><keyname>Gatsis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Giacomoni</keyname><forenames>Marcio H.</forenames></author></authors><title>State Estimation in Water Distribution Networks through a New Successive
  Linear Approximation</title><categories>eess.SY cs.SY math.OC</categories><comments>To Appear in the 58th Conference on Decision and Control, Nice,
  France, December 11--13, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State estimation (SE) of water distribution networks (WDNs) is difficult to
solve due to nonlinearity/nonconvexity of water flow models, uncertainties from
parameters and demands, lack of redundancy of measurements, and inaccurate flow
and pressure measurements. This paper proposes a new, scalable successive
linear approximation to solve the SE problem in WDNs. The approach amounts to
solving either a sequence of linear or quadratic programs---depending on the
operators' objectives. The proposed successive linear approximation offers a
seamless way of dealing with valve/pump model nonconvexities, is different than
a first order Taylor series linearization, and can incorporate with robust
uncertainty modeling. Two simple testcases are adopted to illustrate the
effectiveness of proposed approach using head measurements at select nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03187</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03187</id><created>2019-09-07</created><authors><author><keyname>Xu</keyname><forenames>Ti</forenames></author><author><keyname>Li</keyname><forenames>Hanyue</forenames></author><author><keyname>Birchfield</keyname><forenames>Adam B.</forenames></author><author><keyname>Overbye</keyname><forenames>Thomas J.</forenames></author></authors><title>Synthesize Phasor Measurement Unit Data Using Large-Scale Electric
  Network Models</title><categories>eess.SY cs.SY</categories><comments>Submitted and Accepted by North American Power Symposium</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Big data analytic applications using phasor measurements help improve the
situation awareness of grid operators to better operate and control the system.
Phasor measurement unit (PMU) data from actual grids is viewed as highly
confidential and is not publicly available to researchers and educators. This
paper develops a methodology to synthesize PMU data that can be accessed and
shared freely, with a focus on input data preparation. Time series of demand-
and generation-side input data are generated using public data from different
utilities and statistical analysis methods. Detailed load dynamics modeling is
also performed in this paper to extend the synthetic electric network models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03192</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03192</id><created>2019-09-07</created><authors><author><keyname>Romano</keyname><forenames>Marcello</forenames></author><author><keyname>Curti</keyname><forenames>Fabio</forenames></author></authors><title>Analytic Solution of the Time-Optimal Control of a Double Integrator
  from an Arbitrary State to the State-space Origin</title><categories>math.OC cs.SY eess.SY math.DS</categories><comments>5 pages, 1 figure, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This brief note presents known results about the minimum-time control of a
double integrator system from an arbitrary initial state to the state-space
origin (minimum-time regulation problem, or special problem). The main purpose
of this note is didactical. Results are presented in all details and following
a step by step procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03197</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03197</id><created>2019-09-07</created><authors><author><keyname>Wang</keyname><forenames>Jialiang</forenames></author><author><keyname>Yue</keyname><forenames>Chaolei</forenames></author><author><keyname>Xi</keyname><forenames>Yueli</forenames></author><author><keyname>Sun</keyname><forenames>Yanguang</forenames></author><author><keyname>Cheng</keyname><forenames>Nan</forenames></author><author><keyname>Yang</keyname><forenames>Fei</forenames></author><author><keyname>Jiang</keyname><forenames>Mingyu</forenames></author><author><keyname>Sun</keyname><forenames>Jianfeng</forenames></author><author><keyname>Gui</keyname><forenames>Youzhen</forenames></author><author><keyname>Cai</keyname><forenames>Haiwen</forenames></author></authors><title>Fiber-optic joint time and frequency transfer with the same wavelength</title><categories>eess.SP</categories><doi>10.1364/OL.45.000208</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optical fiber links have demonstrated their ability to transfer the
ultra-stable clock signals. In this paper we propose and demonstrate a new
scheme to transfer both time and radio frequency with the same wavelength based
on coherent demodulation technique. Time signal is encoded as a binary
phase-shift keying (BPSK) to the optical carrier using electro optic modulator
(EOM) by phase modulation and makes sure the frequency signal free from
interference with single pulse. The phase changes caused by the fluctuations of
the transfer links are actively cancelled at local site by optical delay lines.
Radio frequency with 1GHz and time signal with one pulse per second (1PPS)
transmitted over a 110km fiber spools are obtained. The experimental results
demonstrate that frequency instabilities of 1.7E-14 at 1s and 5.9E-17 at 104s.
Moreover, time interval transfer of 1PPS signal reaches sub-ps stability after
1000s. This scheme offers advantages with respect to reduce the channel in
fiber network, and can keep time and frequency signal independent of each
other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03214</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03214</id><created>2019-09-07</created><authors><author><keyname>Xie</keyname><forenames>Xuan</forenames></author><author><keyname>Yu</keyname><forenames>Junhao</forenames></author><author><keyname>Feng</keyname><forenames>Hui</forenames></author><author><keyname>Hu</keyname><forenames>Bo</forenames></author></authors><title>Bayesian Design of Sampling Set for Bandlimited Graph Signals</title><categories>eess.SP math.ST stat.TH</categories><comments>Accepted by GloalSIP2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of sampling set (DoS) for bandlimited graph signals (GS) has been
extensively studied in recent years, but few of them exploit the benefits of
the stochastic prior of GS. In this work, we introduce the optimization
framework for Bayesian DoS of bandlimited GS. We also illustrate how the choice
of different sampling sets affects the estimation error and how the prior
knowledge influences the result of DoS compared with the non-Bayesian DoS by
the aid of analyzing Gershgorin discs of error metric matrix. Finally, based on
our analysis, we propose a heuristic algorithm for DoS to avoid solving the
optimization problem directly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03253</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03253</id><created>2019-09-07</created><authors><author><keyname>Jahanifar</keyname><forenames>Mostafa</forenames></author><author><keyname>Koohbanani</keyname><forenames>Navid Alemi</forenames></author><author><keyname>Rajpoot</keyname><forenames>Nasir</forenames></author></authors><title>NuClick: From Clicks in the Nuclei to Nuclear Boundaries</title><categories>q-bio.QM cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Best performing nuclear segmentation methods are based on deep learning
algorithms that require a large amount of annotated data. However, collecting
annotations for nuclear segmentation is a very labor-intensive and
time-consuming task. Thereby, providing a tool that can facilitate and speed up
this procedure is very demanding. Here we propose a simple yet efficient
framework based on convolutional neural networks, named NuClick, which can
precisely segment nuclei boundaries by accepting a single point position (or
click) inside each nucleus. Based on the clicked positions, inclusion and
exclusion maps are generated which comprise 2D Gaussian distributions centered
on those positions. These maps serve as guiding signals for the network as they
are concatenated to the input image. The inclusion map focuses on the desired
nucleus while the exclusion map indicates neighboring nuclei and improve the
results of segmentation in scenes with nuclei clutter. The NuClick not only
facilitates collecting more annotation from unseen data but also leads to
superior segmentation output for deep models. It is also worth mentioning that
an instance segmentation model trained on NuClick generated labels was able to
rank first in LYON19 challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03265</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03265</id><created>2019-09-07</created><authors><author><keyname>Joshi</keyname><forenames>Anant A.</forenames></author><author><keyname>Subbarao</keyname><forenames>Kamesh</forenames></author></authors><title>Uncertainty Quantification And Analysis Of Dynamical Systems With
  Invariants</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers uncertainty quantification in systems perturbed by
stochastic disturbances, in particular, Gaussian white noise. The main focus of
this work is on describing the time evolution of statistical moments of certain
invariants (for instance total energy and magnitude of angular momentum) for
such systems. A first case study for the attitude dynamics of a rigid body is
presented where it is shown that these techniques offer a closed form
representation of the evolution of the first and second moments of the kinetic
energy of the resulting stochastic dynamical system. A second case study of a
two body problem is presented in which bounds on the first and second moments
of the angular momentum are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03272</identifier>
 <datestamp>2020-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03272</id><created>2019-09-07</created><updated>2020-01-29</updated><authors><author><keyname>Zheng</keyname><forenames>Beixiong</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Intelligent Reflecting Surface-Enhanced OFDM: Channel Estimation and
  Reflection Optimization</title><categories>cs.IT eess.SP math.IT</categories><comments>Early Access in IEEE Wireless Communications Letters. Please refer to
  &quot;https://ieeexplore.ieee.org/document/8937491/&quot;. In this work, we propose
  practical a practical transmission protocol to execute optimal channel
  estimation and reflection optimization successively for an IRS-enhanced OFDM
  system, which is also applicable to the narrow-band IRS system</comments><journal-ref>IEEE Wireless Communications Letters, 2019</journal-ref><doi>10.1109/LWC.2019.2961357</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the intelligent reflecting surface (IRS)-enhanced wireless communication
system, channel state information (CSI) is of paramount importance for
achieving the passive beamforming gain of IRS, which, however, is a practically
challenging task due to its massive number of passive elements without
transmitting/receiving capabilities. In this letter, we propose a practical
transmission protocol to execute channel estimation and reflection optimization
successively for an IRS-enhanced orthogonal frequency division multiplexing
(OFDM) system. Under the unit-modulus constraint, a novel reflection pattern at
the IRS is designed to aid the channel estimation at the access point (AP)
based on the received pilot signals from the user, for which the channel
estimation error is derived in closed-form. With the estimated CSI, the
reflection coefficients are then optimized by a low-complexity algorithm based
on the resolved strongest signal path in the time domain. Simulation results
corroborate the effectiveness of the proposed channel estimation and reflection
optimization methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03313</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03313</id><created>2019-09-07</created><authors><author><keyname>Wu</keyname><forenames>Wen</forenames><affiliation>Sherman</affiliation></author><author><keyname>Cheng</keyname><forenames>Nan</forenames><affiliation>Sherman</affiliation></author><author><keyname>Zhang</keyname><forenames>Ning</forenames><affiliation>Sherman</affiliation></author><author><keyname>Yang</keyname><forenames>Peng</forenames><affiliation>Sherman</affiliation></author><author><keyname>Zhuang</keyname><forenames>Weihua</forenames><affiliation>Sherman</affiliation></author><author><keyname>Xuemin</keyname><affiliation>Sherman</affiliation></author><author><keyname>Shen</keyname></author></authors><title>Fast mmwave Beam Alignment via Correlated Bandit Learning</title><categories>eess.SP cs.AI</categories><comments>Accepted by IEEE Transactions on Wireless Communications. In this
  article, we propose a learning-based fast beam alignment algorithm to reduce
  beam alignment latency</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beam alignment (BA) is to ensure the transmitter and receiver beams are
accurately aligned to establish a reliable communication link in
millimeter-wave (mmwave) systems. Existing BA methods search the entire beam
space to identify the optimal transmit-receive beam pair, which incurs
significant BA latency on the order of seconds in the worst case. In this
paper, we develop a learning algorithm to reduce BA latency, namely
Hierarchical Beam Alignment (HBA) algorithm. We first formulate the BA problem
as a stochastic multi-armed bandit problem with the objective to maximize the
cumulative received signal strength within a certain period. The proposed
algorithm takes advantage of the correlation structure among beams such that
the information from nearby beams is extracted to identify the optimal beam,
instead of searching the entire beam space. Furthermore, the prior knowledge on
the channel fluctuation is incorporated in the proposed algorithm to further
accelerate the BA process. Theoretical analysis indicates that the proposed
algorithm is asymptotically optimal. Extensive simulation results demonstrate
that the proposed algorithm can identify the optimal beam with a high
probability and reduce the BA latency from hundreds of milliseconds to a few
milliseconds in the multipath channel, as compared to the existing BA method in
IEEE 802.11ad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03316</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03316</id><created>2019-09-07</created><updated>2019-11-18</updated><authors><author><keyname>Meerdink</keyname><forenames>Susan</forenames></author><author><keyname>Bocinsky</keyname><forenames>James</forenames></author><author><keyname>Zare</keyname><forenames>Alina</forenames></author><author><keyname>Kroeger</keyname><forenames>Nicholas</forenames></author><author><keyname>McCurley</keyname><forenames>Connor</forenames></author><author><keyname>Shats</keyname><forenames>Daniel</forenames></author><author><keyname>Gader</keyname><forenames>Paul</forenames></author></authors><title>Multi-Target Multiple Instance Learning for Hyperspectral Target
  Detection</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In remote sensing, it is often challenging to acquire or collect a large
dataset that is accurately labeled. This difficulty is usually due to several
issues, including but not limited to the study site's spatial area and
accessibility, errors in the global positioning system (GPS), and mixed pixels
caused by an image's spatial resolution. We propose an approach, with two
variations, that estimates multiple target signatures from training samples
with imprecise labels: Multi-Target Multiple Instance Adaptive Cosine Estimator
(Multi-Target MI-ACE) and Multi-Target Multiple Instance Spectral Match Filter
(Multi-Target MI-SMF). The proposed methods address the problems above by
directly considering the multiple-instance, imprecisely labeled dataset. They
learn a dictionary of target signatures that optimizes detection against a
background using the Adaptive Cosine Estimator (ACE) and Spectral Match Filter
(SMF). Experiments were conducted to test the proposed algorithms using a
simulated hyperspectral dataset, the MUUFL Gulfport hyperspectral dataset
collected over the University of Southern Mississippi-Gulfpark Campus, and the
AVIRIS hyperspectral dataset collected over Santa Barbara County, California.
Both simulated and real hyperspectral target detection experiments show the
proposed algorithms are effective at learning target signatures and performing
target detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03331</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03331</id><created>2019-09-07</created><updated>2020-02-17</updated><authors><author><keyname>Papagiannis</keyname><forenames>Georgios</forenames></author><author><keyname>Moschoyiannis</keyname><forenames>Sotiris</forenames></author></authors><title>Deep Reinforcement Learning for Control of Probabilistic Boolean
  Networks</title><categories>cs.LG cs.AI cs.SY eess.SY</categories><comments>Extended version. Preprint. Latest Version: Fixed typo</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic Boolean Networks (PBNs) were introduced as a computational
model for studying gene interactions in Gene Regulatory Networks (GRNs).
Controllability of PBNs, and hence GRNs, is the process of making strategic
interventions to a network in order to drive it from a particular state towards
some other potentially more desirable state. This is of significant importance
to systems biology as successful control could be used to obtain potential gene
treatments by making therapeutic interventions. Recent advancements in Deep
Reinforcement Learning have enabled systems to develop policies merely by
interacting with the environment, without complete knowledge of the underlying
Markov Decision Process (MDP). In this paper we propose the use of a Deep Q
Network with Double Q Learning, that directly interacts with the environment -
that is, a Probabilistic Boolean Network. The proposed approach is trained by
sampling experiences obtained from the environment using Prioritised Experience
Replay and successfully determines a control policy that directs a PBN from any
state to the desired state (attractor). We demonstrate successful results on
significantly larger PBNs compared to previous approaches under our control
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03352</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03352</id><created>2019-09-07</created><authors><author><keyname>Hoang</keyname><forenames>V. T.</forenames></author><author><keyname>Phung</keyname><forenames>M. D.</forenames></author><author><keyname>Dinh</keyname><forenames>T. H.</forenames></author><author><keyname>Zhu</keyname><forenames>Q.</forenames></author><author><keyname>Ha</keyname><forenames>Q. P.</forenames></author></authors><title>Reconfigurable Multi-UAV Formation Using Angle-Encoded PSO</title><categories>eess.SY cs.RO cs.SY</categories><comments>Pages 1670 - 1675</comments><journal-ref>2019 IEEE 15th International Conference on Automation Science and
  Engineering (CASE)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an algorithm for the formation of multiple UAVs
used in vision-based inspection of infrastructure. A path planning algorithm is
first developed by using a variant of the particle swarm optimisation, named
theta-PSO, to generate a feasible path for the overall formation configuration
taken into account the constraints for visual inspection. Here, we introduced a
cost function that includes various constraints on flight safety and visual
inspection. A reconfigurable topology is then added based on the use of
intermediate waypoints to allow the formation to avoid collision with obstacles
during operation. The planned path and formation are then combined to derive
the trajectory and velocity profiles for each UAV. Experiments have been
conducted for the task of inspecting a light rail bridge. The results confirmed
the validity and effectiveness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03353</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03353</id><created>2019-09-07</created><authors><author><keyname>Xu</keyname><forenames>Xingyuan</forenames></author><author><keyname>Tan</keyname><forenames>Mengxi</forenames></author><author><keyname>Wu</keyname><forenames>Jiayang</forenames></author><author><keyname>Morandotti</keyname><forenames>Roberto</forenames></author><author><keyname>Mitchell</keyname><forenames>Arnan</forenames></author><author><keyname>Moss</keyname><forenames>David J.</forenames></author></authors><title>Microwave and RF signal processing based on integrated soliton crystal
  optical microcombs</title><categories>eess.SP physics.app-ph physics.optics</categories><comments>7 pages, 7 figures, 39 references</comments><journal-ref>IEEE Photonics Technology Letters Volume 31 (2019)</journal-ref><doi>10.1109/LPT.2019.2940497</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microcombs are powerful tools as sources of multiple wavelength channels for
photonic RF signal processing. They offer a compact device footprint, large
numbers of wavelengths, and wide Nyquist bands. Here, we review recent progress
on microcomb-based photonic RF signal processors, including true time delays,
reconfigurable filters, Hilbert transformers, differentiators, and
channelizers. The strong potential of optical micro-combs for RF photonics
applications in terms of functions and integrability is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03354</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03354</id><created>2019-09-07</created><updated>2019-09-26</updated><authors><author><keyname>Rony</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Belharbi</keyname><forenames>Soufiane</forenames></author><author><keyname>Dolz</keyname><forenames>Jose</forenames></author><author><keyname>Ayed</keyname><forenames>Ismail Ben</forenames></author><author><keyname>McCaffrey</keyname><forenames>Luke</forenames></author><author><keyname>Granger</keyname><forenames>Eric</forenames></author></authors><title>Deep weakly-supervised learning methods for classification and
  localization in histology images: a survey</title><categories>cs.CV cs.LG eess.IV</categories><comments>37 pages, 21 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using state-of-the-art deep learning models for the computer-assisted
diagnosis of diseases like cancer raises several challenges related to the
nature and availability of labeled histology images. In particular, cancer
grading and localization in these images normally relies on both image- and
pixel-level labels, the latter requiring a costly annotation process. In this
survey, deep weakly-supervised learning (WSL) architectures are investigated to
identify and locate diseases in histology image, without the need for
pixel-level annotations. Given a training dataset with globally-annotated
images, these models allow to simultaneously classify histology images, while
localizing the corresponding regions of interest. These models are organized
into two main approaches -- (1) bottom-up approaches (based on forward-pass
information through a network, either by spatial pooling of
representations/scores, or by detecting class regions), and (2) top-down
approaches (based on backward-pass information within a network, inspired by
human visual attention). Since relevant WSL models have mainly been developed
in the computer vision community, and validated on natural scene images, we
assess the extent to which they apply to histology images which have
challenging properties, e.g., large size, non-salient and highly unstructured
regions, stain heterogeneity, and coarse/ambiguous labels. The most relevant
deep WSL models (e.g., CAM, WILDCAT and Deep MIL) are compared experimentally
in terms of accuracy (classification and pixel-level localization) on several
public benchmark histology datasets for breast and colon cancer (BACH ICIAR
2018, BreakHis, CAMELYON16, and GlaS). Results indicate that several deep
learning models, and in particular WILDCAT and deep MIL can provide a high
level of classification accuracy, although pixel-wise localization of cancer
regions remains an issue for such images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03377</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03377</id><created>2019-09-07</created><updated>2019-09-26</updated><authors><author><keyname>Xiao</keyname><forenames>Tong</forenames></author><author><keyname>Qiu</keyname><forenames>Xiaojun</forenames></author><author><keyname>Halkon</keyname><forenames>Ben</forenames></author></authors><title>Ultra-broadband active noise cancellation at the ears via optical
  microphones</title><categories>eess.SY cs.SD cs.SY eess.AS eess.SP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  High frequency noise has generally been difficult to be cancelled actively at
a person's ears, particularly for active headrest systems aiming to free the
listener from noise cancellation headphones. One of the main challenges is to
measure the noise precisely at the ears. Here we demonstrate a new error
sensing methodology with an optical microphone arrangement for active noise
cancellation (ANC). It can measure the noise accurately for ANC without any
obstructions at the listener's ears. The demonstrated system, or virtual ANC
headphone as we call it, is shown to provide more than 10 dB attenuation for
ultra-broadband noise - up to 6000 Hz - inside the ears in a complex sound
field. The bandwidth of the controllable noise significantly exceeds the
results from the state-of-the-art system, which is below 1000 Hz. The proposed
method leads to the next generation of personal hearing protection system and
can open up a whole new area of sound control research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03382</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03382</id><created>2019-09-08</created><updated>2019-09-13</updated><authors><author><keyname>Paarporn</keyname><forenames>Keith</forenames></author><author><keyname>Chandan</keyname><forenames>Rahul</forenames></author><author><keyname>Alizadeh</keyname><forenames>Mahnoosh</forenames></author><author><keyname>Marden</keyname><forenames>Jason R.</forenames></author></authors><title>Characterizing the interplay between information and strength in Blotto
  games</title><categories>cs.GT cs.SY eess.SY math.OC</categories><comments>8 pages, 2 figures. Accepted for presentation at 58th Conference on
  Decision and Control (CDC), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate informational asymmetries in the Colonel Blotto
game, a game-theoretic model of competitive resource allocation between two
players over a set of battlefields. The battlefield valuations are subject to
randomness. One of the two players knows the valuations with certainty. The
other knows only a distribution on the battlefield realizations. However, the
informed player has fewer resources to allocate. We characterize unique
equilibrium payoffs in a two battlefield setup of the Colonel Blotto game. We
then focus on a three battlefield setup in the General Lotto game, a popular
variant of the Colonel Blotto game. We characterize the unique equilibrium
payoffs and mixed equilibrium strategies. We quantify the value of information
- the difference in equilibrium payoff between the asymmetric information game
and complete information game. We find information strictly improves the
informed player's performance guarantee. However, the magnitude of improvement
varies with the informed player's strength as well as the game parameters. Our
analysis highlights the interplay between strength and information in
adversarial environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03385</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03385</id><created>2019-09-08</created><authors><author><keyname>Tann</keyname><forenames>Hokchhay</forenames></author><author><keyname>Zhao</keyname><forenames>Heng</forenames></author><author><keyname>Reda</keyname><forenames>Sherief</forenames></author></authors><title>A Resource-Efficient Embedded Iris Recognition System Using Fully
  Convolutional Networks</title><categories>cs.NE cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applications of Fully Convolutional Networks (FCN) in iris segmentation have
shown promising advances. For mobile and embedded systems, a significant
challenge is that the proposed FCN architectures are extremely computationally
demanding. In this article, we propose a resource-efficient, end-to-end iris
recognition flow, which consists of FCN-based segmentation, contour fitting,
followed by Daugman normalization and encoding. To attain accurate and
efficient FCN models, we propose a three-step SW/HW co-design methodology
consisting of FCN architectural exploration, precision quantization, and
hardware acceleration. In our exploration, we propose multiple FCN models, and
in comparison to previous works, our best-performing model requires 50X less
FLOPs per inference while achieving a new state-of-the-art segmentation
accuracy. Next, we select the most efficient set of models and further reduce
their computational complexity through weights and activations quantization
using 8-bit dynamic fixed-point (DFP) format. Each model is then incorporated
into an end-to-end flow for true recognition performance evaluation. A few of
our end-to-end pipelines outperform the previous state-of-the-art on two
datasets evaluated. Finally, we propose a novel DFP accelerator and fully
demonstrate the SW/HW co-design realization of our flow on an embedded FPGA
platform. In comparison with the embedded CPU, our hardware acceleration
achieves up to 8.3X speedup for the overall pipeline while using less than 15%
of the available FPGA resources. We also provide comparisons between the FPGA
system and an embedded GPU showing different benefits and drawbacks for the two
platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03428</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03428</id><created>2019-09-08</created><authors><author><keyname>Masiala</keyname><forenames>Spyroula</forenames></author><author><keyname>Huijbers</keyname><forenames>Willem</forenames></author><author><keyname>Atzmueller</keyname><forenames>Martin</forenames></author></authors><title>Feature-Set-Engineering for Detecting Freezing of Gait in Parkinson's
  Disease using Deep Recurrent Neural Networks</title><categories>eess.SP cs.AI cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Freezing of gait (FoG) is a common gait disability in Parkinson's disease,
that usually appears in its advanced stage. Freeze episodes are associated with
falls, injuries, and psychological consequences, negatively affecting the
patients' quality of life. For detecting FoG episodes automatically, a highly
accurate detection method is necessary. This paper presents an approach for
detecting FoG episodes utilizing a deep recurrent neural network (RNN) on
3D-accelerometer measurements. We investigate suitable features and feature
combinations extracted from the sensors' time series data. Specifically, for
detecting FoG episodes, we apply a deep RNN with Long Short-Term Memory cells.
In our experiments, we perform both user dependent and user independent
experiments, to detect freeze episodes. Our experimental results show that the
frequency domain features extracted from the trunk sensor are the most
informative feature group in the subject independent method, achieving an
average AUC score of 93%, Specificity of 90% and Sensitivity of 81%. Moreover,
frequency and statistical features of all the sensors are identified as the
best single input for the subject dependent method, achieving an average AUC
score of 97%, Specificity of 96% and Sensitivity of 87%. Overall, in a
comparison to state-of-the-art approaches from literature as baseline methods,
our proposed approach outperforms these significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03434</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03434</id><created>2019-09-08</created><authors><author><keyname>Tsai</keyname><forenames>Che-Ping</forenames></author><author><keyname>Lee</keyname><forenames>Hung-Yi</forenames></author></authors><title>Order-free Learning Alleviating Exposure Bias in Multi-label
  Classification</title><categories>cs.LG cs.CL cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-label classification (MLC) assigns multiple labels to each sample.
Prior studies show that MLC can be transformed to a sequence prediction problem
with a recurrent neural network (RNN) decoder to model the label dependency.
However, training a RNN decoder requires a predefined order of labels, which is
not directly available in the MLC specification. Besides, RNN thus trained
tends to overfit the label combinations in the training set and have difficulty
generating unseen label sequences. In this paper, we propose a new framework
for MLC which does not rely on a predefined label order and thus alleviates
exposure bias. The experimental results on three multi-label classification
benchmark datasets show that our method outperforms competitive baselines by a
large margin. We also find the proposed approach has a higher probability of
generating label combinations not seen during training than the baseline
models. The result shows that the proposed approach has better generalization
capability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03454</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03454</id><created>2019-09-08</created><authors><author><keyname>Devinder</keyname><forenames>Shital</forenames></author><author><keyname>Lal</keyname><forenames>Ashish</forenames></author><author><keyname>Dastidar</keyname><forenames>Tathagato Rai</forenames></author><author><keyname>Dubey</keyname><forenames>Satish Kumar</forenames></author></authors><title>Quantitative analysis of numerically focused red blood cells using
  subdivided two-beam interference (STBI) based lateral-shearing digital
  holographic microscope</title><categories>eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A lateral shear interferometer based digital holographic microscopy has been
realized to study the morphology dynamics of Human red blood cells
quantitatively. Here, a lateral shear interferometer is embedded with a
conventional microscope with a CMOS sensor to form a lateral-shearing digital
holographic microscope. It enables recording of image plane holograms of
objects that can be numerically reconstructed to estimate its3-D prole. This
yields the depth information of the sample in addition to its bright field
image. The problem of the duplicate image is addressed by filtering object
information from one of the beams, without losing the contrast in the fringes.
The contrast in the fringes is maintained by increased reflectivity of the back
surface of the shear plate. This improves the resolution in the proposed
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03467</identifier>
 <datestamp>2019-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03467</id><created>2019-09-08</created><updated>2019-12-04</updated><authors><author><keyname>Zhang</keyname><forenames>Qi</forenames></author><author><keyname>Du</keyname><forenames>Tao</forenames></author><author><keyname>Tian</keyname><forenames>Changzheng</forenames></author></authors><title>Self-driving scale car trained by Deep reinforcement learning</title><categories>cs.LG cs.AI cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The self-driving based on deep reinforcement learning, as the most important
application of artificial intelligence, has become a popular topic. Most of the
current self-driving methods focus on how to directly learn end-to-end
self-driving control strategy from the raw sensory data. Essentially, this
control strategy can be considered as a mapping between images and driving
behavior, which usually faces a problem of low generalization ability. To
improve the generalization ability for the driving behavior, the reinforcement
learning method requires extrinsic reward from the real environment, which may
damage the car. In order to obtain a good generalization ability in safety, a
virtual simulation environment that can be constructed different driving scene
is designed by Unity. A theoretical model is established and analyzed in the
virtual simulation environment, and it is trained by double Deep Q-network.
Then, the trained model is migrated to a scale car in real world. This process
is also called a sim2real method. The sim2real training method efficiently
handle the these two problems. The simulations and experiments are carried out
to evaluate the performance and effectiveness of the proposed algorithm.
Finally, it is demonstrated that the scale car in real world obtain the
capability for autonomous driving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03472</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03472</id><created>2019-09-08</created><authors><author><keyname>Mange</keyname><forenames>Vivek</forenames></author><author><keyname>Shah</keyname><forenames>Priyam</forenames></author><author><keyname>Kothari</keyname><forenames>Vishal</forenames></author></authors><title>Autonomous Underwater Vehicle: Electronics and Software Implementation
  of the Proton AUV</title><categories>cs.RO cs.CV eess.IV</categories><comments>6 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper deals with the software and the electronics unit for an autonomous
underwater vehicle. The implementation in the electronics unit is the
connection and communication between SBC, pixhawk controller and other sensory
hardware and actuators. The major implementation of the software unit is the
algorithm for object detection based on Convolutional Neural Network (CNN) and
its models. The Hyperparameters were tuned according to Odroid Xu4 for various
models. The maneuvering algorithm uses the MAVLink protocol of the ArduSub
project for movement and its simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03483</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03483</id><created>2019-09-08</created><authors><author><keyname>Jiao</keyname><forenames>Jianbo</forenames></author><author><keyname>Namburete</keyname><forenames>Ana I. L.</forenames></author><author><keyname>Papageorghiou</keyname><forenames>Aris T.</forenames></author><author><keyname>Noble</keyname><forenames>J. Alison</forenames></author></authors><title>Anatomy-Aware Self-supervised Fetal MRI Synthesis from Unpaired
  Ultrasound Images</title><categories>cs.CV cs.LG eess.IV</categories><comments>MICCAI-MLMI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fetal brain magnetic resonance imaging (MRI) offers exquisite images of the
developing brain but is not suitable for anomaly screening. For this ultrasound
(US) is employed. While expert sonographers are adept at reading US images, MR
images are much easier for non-experts to interpret. Hence in this paper we
seek to produce images with MRI-like appearance directly from clinical US
images. Our own clinical motivation is to seek a way to communicate US findings
to patients or clinical professionals unfamiliar with US, but in medical image
analysis such a capability is potentially useful, for instance, for US-MRI
registration or fusion. Our model is self-supervised and end-to-end trainable.
Specifically, based on an assumption that the US and MRI data share a similar
anatomical latent space, we first utilise an extractor to determine shared
latent features, which are then used for data synthesis. Since paired data was
unavailable for our study (and rare in practice), we propose to enforce the
distributions to be similar instead of employing pixel-wise constraints, by
adversarial learning in both the image domain and latent space. Furthermore, we
propose an adversarial structural constraint to regularise the anatomical
structures between the two modalities during the synthesis. A cross-modal
attention scheme is proposed to leverage non-local spatial correlations. The
feasibility of the approach to produce realistic looking MR images is
demonstrated quantitatively and with a qualitative evaluation compared to real
fetal MR images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03503</identifier>
 <datestamp>2019-11-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03503</id><created>2019-09-08</created><authors><author><keyname>Chen</keyname><forenames>Mingliang</forenames></author><author><keyname>Zhu</keyname><forenames>Qiang</forenames></author><author><keyname>Zhang</keyname><forenames>Harrison</forenames></author><author><keyname>Wu</keyname><forenames>Min</forenames></author><author><keyname>Wang</keyname><forenames>Quanzeng</forenames></author></authors><title>Respiratory Rate Estimation from Face Videos</title><categories>eess.IV</categories><journal-ref>2019 IEEE EMBS International Conference on Biomedical &amp; Health
  Informatics (BHI)</journal-ref><doi>10.1109/BHI.2019.8834499</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vital signs, such as heart rate (HR), heart rate variability (HRV),
respiratory rate (RR), are important indicators for a person's health. Vital
signs are traditionally measured with contact sensors, and may be inconvenient
and cause discomfort during continuous monitoring. Commercial cameras are
promising contact-free sensors, and remote photoplethysmography (rPPG) have
been studied to remotely monitor heart rate from face videos. For remote RR
measurement, most prior art was based on small periodical motions of chest
regions caused by breathing cycles, which are vulnerable to subjects' voluntary
movements. This paper explores remote RR measurement based on rPPG obtained
from face videos. The paper employs motion compensation, two-phase temporal
filtering, and signal pruning to capture signals with high quality. The
experimental results demonstrate that the proposed framework can obtain
accurate RR results and can provide HR, HRV and RR measurement synergistically
in one framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03516</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03516</id><created>2019-09-08</created><authors><author><keyname>Deshpande</keyname><forenames>Vedang M.</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Raktim</forenames></author></authors><title>On Improved Statistical Accuracy of Low-Order Polynomial Chaos
  Approximations</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polynomial chaos expansion is a popular way to develop surrogate models for
stochastic systems with arbitrary random variables. Standard techniques such as
Galerkin projection, stochastic collocation, and least squares approximation,
are applied to determine polynomial chaos coefficients, which define the
surrogate model. Since the surrogate models are developed from a function
approximation perspective, there is no reason to expect accuracy of statistics
from these models. The statistical moments estimated from the surrogate model
may significantly differ from the true moments, especially for lower order
approximations. Often arbitrary high orders are required to recover, for
example, the second moment. In this paper, we present modifications of standard
techniques and determine polynomial chaos coefficients by solving a constrained
optimization problem. We present this new approach for algebraic functions and
differential equations with random parameters, and demonstrate that the
surrogate models from the new approach are able to recover the first two
moments exactly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03522</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03522</id><created>2019-09-08</created><authors><author><keyname>Liang</keyname><forenames>Xia</forenames></author><author><keyname>Wu</keyname><forenames>Junmin</forenames></author><author><keyname>Cao</keyname><forenames>Jing</forenames></author></authors><title>MIDI-Sandwich2: RNN-based Hierarchical Multi-modal Fusion Generation VAE
  networks for multi-track symbolic music generation</title><categories>cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently, almost all the multi-track music generation models use the
Convolutional Neural Network (CNN) to build the generative model, while the
Recurrent Neural Network (RNN) based models can not be applied in this task. In
view of the above problem, this paper proposes a RNN-based Hierarchical
Multi-modal Fusion Generation Variational Autoencoder (VAE) network,
MIDI-Sandwich2, for multi-track symbolic music generation. Inspired by VQ-VAE2,
MIDI-Sandwich2 expands the dimension of the original hierarchical model by
using multiple independent Binary Variational Autoencoder (BVAE) models without
sharing weights to process the information of each track. Then, with
multi-modal fusion technology, the upper layer named Multi-modal Fusion
Generation VAE (MFG-VAE) combines the latent space vectors generated by the
respective tracks, and uses the decoder to perform the ascending dimension
reconstruction to simulate the inverse operation of multi-modal fusion,
multi-modal generation, so as to realize the RNN-based multi-track symbolic
music generation. For the multi-track format pianoroll, we also improve the
output binarization method of MuseGAN, which solves the problem that the
refinement step of the original scheme is difficult to differentiate and the
gradient is hard to descent, making the generated song more expressive. The
model is validated on the Lakh Pianoroll Dataset (LPD) multi-track dataset.
Compared to the MuseGAN, MIDI-Sandwich2 can not only generate harmonious
multi-track music, the generation quality is also close to the state of the art
level. At the same time, by using the VAE to restore songs, the semi-generated
songs reproduced by the MIDI-Sandwich2 are more beautiful than the pure
autogeneration music generated by MuseGAN. Both the code and the audition audio
samples are open source on https://github.com/LiangHsia/MIDI-S2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03551</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03551</id><created>2019-09-08</created><authors><author><keyname>Ibrahim</keyname><forenames>Osama T.</forenames></author><author><keyname>Gomaa</keyname><forenames>Walid</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>Zero-Calibration Device-free Localization for the IoT based on
  Participatory Sensing</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Device-free localization (DFL) is an emerging technology for estimating the
position of a human or object that is not equipped with any electronic tag, nor
participate actively in the localization process. Similar to device-based
localization, the initial phase in DFL is to build the fingerprint database
which is usually done manually using site surveying. This process is tedious,
time-consuming, and vulnerable to environmental dynamics. Motivated by the
recent advances in the Internet of Things (IoT), this paper introduces
RadioGrapher; a system that automates the process of device-free fingerprint
calibration in IoT environments. RadioGrapher leverages the device-based
locations of entities in the area of interest in a crowd-sensing manner, aided
with Fresnel zones of the wirelessly connected IoT devices to automatically
construct a device-free fingerprint. Experimental evaluation of RadioGrapher in
an IoT testbed using multiple entities shows that it can construct DFL
fingerprints with high accuracy. Moreover, its median localization accuracy is
comparable to that of manual fingerprinting. This comes with no calibration
overhead, highlighting the promise of RadioGrapher as a crowdsourcing
device-free fingerprint constructor in IoT environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03565</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03565</id><created>2019-09-08</created><authors><author><keyname>Shabbir</keyname><forenames>Mudassir</forenames></author><author><keyname>Abbas</keyname><forenames>Waseem</forenames></author><author><keyname>Yazicioglu</keyname><forenames>A. Yasin</forenames></author></authors><title>On Computation of the Distance-based Bound on Strong Structural
  Controllability in Networks</title><categories>eess.SY cs.SY math.DS</categories><comments>IEEE Conference on Decision and Control (CDC) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A network of agents with linear dynamics is strong structurally controllable
if agents can be maneuvered from any initial state to any final state
independently of the coupling strengths between agents. If a network is not
strong structurally controllable with a given set of input nodes (leaders),
then the dimension of strong structurally controllable subspace quantifies the
extent to which a network can be controlled by the same inputs. Computing this
dimension exactly is computationally challenging. In this paper, we study the
problem of computing a sharp lower bound on the dimension of strong
structurally controllable subspace in networks with Laplacian dynamics. The
bound is based on a sequence of vectors containing distances between leaders
and the remaining nodes in the underlying network graph. Such vectors are
referred to as the distance-to-leader vectors. We provide a polynomial time
algorithm to compute a particular sequence of distance-to-leader vectors with a
fixed set of leaders, which directly provides a lower bound on the dimension of
strong structurally controllable subspace. We also present a linearithmic
approximation algorithm to compute such a sequence, which provides near optimal
solutions in practice. Using these results, we also explore connections between
graph-theoretic properties and length of longest such sequences in path and
cycle graphs. Finally, we numerically evaluate and compare our bound with other
bounds in the literature on various networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03573</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03573</id><created>2019-09-08</created><authors><author><keyname>Yang</keyname><forenames>Wenming</forenames></author><author><keyname>Zhang</keyname><forenames>Xuechen</forenames></author><author><keyname>Tian</keyname><forenames>Yapeng</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Xue</keyname><forenames>Jing-Hao</forenames></author><author><keyname>Liao</keyname><forenames>Qingmin</forenames></author></authors><title>LCSCNet: Linear Compressing Based Skip-Connecting Network for Image
  Super-Resolution</title><categories>eess.IV cs.CV</categories><comments>Accepted by IEEE Transactions on Image Processing (IEEE-TIP)</comments><doi>10.1109/TIP.2019.2940679</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a concise but efficient network architecture called
linear compressing based skip-connecting network (LCSCNet) for image
super-resolution. Compared with two representative network architectures with
skip connections, ResNet and DenseNet, a linear compressing layer is designed
in LCSCNet for skip connection, which connects former feature maps and
distinguishes them from newly-explored feature maps. In this way, the proposed
LCSCNet enjoys the merits of the distinguish feature treatment of DenseNet and
the parameter-economic form of ResNet. Moreover, to better exploit hierarchical
information from both low and high levels of various receptive fields in deep
models, inspired by gate units in LSTM, we also propose an adaptive
element-wise fusion strategy with multi-supervised training. Experimental
results in comparison with state-of-the-art algorithms validate the
effectiveness of LCSCNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03587</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03587</id><created>2019-09-08</created><authors><author><keyname>Taherkhani</keyname><forenames>Nima</forenames></author><author><keyname>Kiasaleh</keyname><forenames>Kamran</forenames></author></authors><title>Statistical Modelling of the Clipping Noise in OFDM-based Visible Light
  Communication System</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyses the statistics of the clipping noise in orthogonal
frequency-division-multiplex (OFDM) based visible light Communication systems.
The clipped signal is generally modelled as the summation of the scaled
original signal and clipping noise, which is treated by the linear equalizer in
the receiver. Generally, it is assumed that the clipped and original signal
share the same statistics. Although valid in some cases, we show that such
assumption is invalid when the transmitter is tightly constrained. We derive
closed-form probability distribution function (pdf) for the clipping noise and
use the pdf for statistical hypothesis testing in an optimum receiver
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03594</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03594</id><created>2019-09-08</created><updated>2019-09-17</updated><authors><author><keyname>Zhang</keyname><forenames>Guofeng</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>Structural Decomposition for Quantum Two-level Systems</title><categories>quant-ph cs.SY eess.SY</categories><comments>12 pages, submitted for publication. Comments are welcome!</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An input-output model of a two-level quantum system in the Heisenberg picture
is of bilinear form with constant system matrices, which allows the
introduction of the concepts of controllability and observability in analogy
with those of quantum linear systems. By means of the notions of
controllability and observability, coordinate transformations, which are
rotation matrices, can be constructed explicitly that transform an input-output
model to a new one. The new input-output model enables us to investigate many
interesting properties of the two-level quantum system, such as steady-state
solutions to the Lindblad master equation, quantum decoherence-free (DF)
subspaces, quantum non-demolition (QND) variables, and the realization of
quantum back-action evading (BAE) measurements. The physical system in (Wang,
J. \&amp; Wiseman, H. M. (2001), Feedback-stabilization of an arbitrary pure state
of a two-level atom, Physical Review A 64(6), 063810) is re-studied to
illustrate the results presented in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03611</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03611</id><created>2019-09-08</created><authors><author><keyname>Liu</keyname><forenames>Jinlin</forenames></author><author><keyname>Yao</keyname><forenames>Yuan</forenames></author><author><keyname>Ren</keyname><forenames>Jianqiang</forenames></author></authors><title>An Acceleration Framework for High Resolution Image Synthesis</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synthesis of high resolution images using Generative Adversarial Networks
(GANs) is challenging, which usually requires numbers of high-end graphic cards
with large memory and long time of training. In this paper, we propose a
two-stage framework to accelerate the training process of synthesizing high
resolution images. High resolution images are first transformed to small codes
via the trained encoder and decoder networks. The code in latent space is times
smaller than the original high resolution images. Then, we train a code
generation network to learn the distribution of the latent codes. In this way,
the generator only learns to generate small latent codes instead of large
images. Finally, we decode the generated latent codes to image space via the
decoder networks so as to output the synthesized high resolution images.
Experimental results show that the proposed method accelerates the training
process significantly and increases the quality of the generated samples. The
proposed acceleration framework makes it possible to generate high resolution
images using less training time with limited hardware resource. After using the
proposed acceleration method, it takes only 3 days to train a 1024 *1024 image
generator on Celeba-HQ dataset using just one NVIDIA P100 graphic card.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03626</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03626</id><created>2019-09-09</created><authors><author><keyname>Vasudeva</keyname><forenames>Karthik</forenames></author><author><keyname>Ozdemir</keyname><forenames>Ozgur</forenames></author><author><keyname>Chandar</keyname><forenames>Sugan R. S.</forenames></author><author><keyname>Erden</keyname><forenames>Fatih</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Vehicular LTE Connectivity Analysis in Urban and Rural Environments
  using USRP Measurements</title><categories>eess.SP</categories><comments>11 pages, 28 figures, journal</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The intelligent transportation system (ITS) offers a wide range of
applications related to traffic management, which often require high data rate
and low latency. The ubiquitous coverage and advancements of the Long Term
Evolution (LTE) technology have made it possible to achieve these requirements
and to enable broadband applications for vehicular users. In this paper, we
perform field trial measurements in various different commercial LTE networks
using software defined radios (SDRs) and report our findings. First, we provide
a detailed tutorial overview on how to post-process SDR measurements for
decoding broadcast channels and reference signal measurements from LTE
networks. We subsequently describe the details of our measurement campaigns in
urban, sub-urban, and rural environments. Based on these measurements, we
report joint distributions of base station density, cellular coverage, link
strength, disconnected vehicle duration, and vehicle velocity in these
environments, and compare the LTE coverage in different settings. Our
experimental results quantify the stronger coverage, shorter link distances,
and shorter duration of disconnectivity in urban environments when compared to
sub-urban and rural settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03629</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03629</id><created>2019-09-09</created><updated>2020-02-01</updated><authors><author><keyname>Takeuchi</keyname><forenames>Shungo</forenames></author><author><keyname>Hasegawa</keyname><forenames>Mikio</forenames></author><author><keyname>Kanno</keyname><forenames>Kazutaka</forenames></author><author><keyname>Uchida</keyname><forenames>Atsushi</forenames></author><author><keyname>Chauvet</keyname><forenames>Nicolas</forenames></author><author><keyname>Naruse</keyname><forenames>Makoto</forenames></author></authors><title>Dynamic channel selection in wireless communications via a multi-armed
  bandit algorithm using laser chaos time series</title><categories>eess.SP cs.SI nlin.CD</categories><journal-ref>Sci Rep 10, 1574 (2020)</journal-ref><doi>10.1038/s41598-020-58541-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic channel selection is among the most important wireless communication
elements in dynamically changing electromagnetic environments wherein a user
can experience improved communication quality by choosing a better channel.
Multi-armed bandit (MAB) algorithms are a promising approach by which the
difficult tradeoff between exploration to search for better a channel and
exploitation to experience enhanced communication quality is resolved.
Ultrafast solution of MAB problems has been demonstrated by utilizing
chaotically oscillating time series generated by semiconductor lasers. In this
study, we experimentally demonstrate a MAB algorithm incorporating laser chaos
time series in a wireless local area network (WLAN). Autonomous and adaptive
dynamic channel selection is successfully demonstrated in an IEEE802.11a-based,
four-channel WLAN. Although the laser chaos time series is arranged prior to
the WLAN experiments, the results confirm the usefulness of ultrafast chaotic
sequences for real wireless applications. In addition, we numerically examine
the underlining adaptation mechanism of the significantly simplified MAB
algorithm implemented in the present study compared with the previously
reported chaos-based decision makers. This study provides a first step toward
the application of ultrafast chaotic lasers for future high-performance
wireless communication networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03642</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03642</id><created>2019-09-09</created><updated>2019-10-21</updated><authors><author><keyname>Bryan</keyname><forenames>Nicholas J.</forenames></author></authors><title>Impulse Response Data Augmentation and Deep Neural Networks for Blind
  Room Acoustic Parameter Estimation</title><categories>cs.SD eess.AS</categories><comments>Under Review</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The reverberation time (T60) and the direct-to-reverberant ratio (DRR) are
commonly used to characterize room acoustic environments. Both parameters can
be measured from an acoustic impulse response (AIR) or using blind estimation
methods that perform estimation directly from speech. When neural networks are
used for blind estimation, however, a large realistic dataset is needed, which
is expensive and time consuming to collect. To address this, we propose an AIR
augmentation method that can parametrically control the T60 and DRR, allowing
us to expand a small dataset of real AIRs into a balanced dataset orders of
magnitude larger. Using this method, we train a previously proposed
convolutional neural network (CNN) and show we can outperform past
single-channel state-of-the-art methods. We then propose a more efficient,
straightforward baseline CNN that is 4-5x faster, which provides an additional
improvement and is better or comparable to all previously reported single- and
multi-channel state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03644</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03644</id><created>2019-09-09</created><authors><author><keyname>Lin</keyname><forenames>Jingran</forenames></author><author><keyname>Ma</keyname><forenames>Mengyuan</forenames></author><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author></authors><title>Joint Long-Term Admission Control and Beamforming in Green Downlink
  Networks: Offline and Online Approaches</title><categories>cs.IT eess.SP math.IT</categories><comments>12 pages, 13 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Admission control is an effective solution to managing a wireless network
with a large user set. It dynamically rejects users in bad conditions, and
thereby guarantees high quality-of-service (QoS) for the others. Unfortunately,
a frequently-varying admissible user set requests remarkable power to
continually re-establish the transmission link. Hence, we explore the stability
of admissible user set, and formulate a joint long-term admission control and
beamforming problem for a network with one multi-antenna base station (BS) and
multiple single-antenna users. We consider the downlink transmission in a time
period containing multiple time slices. By jointly optimizing the admissible
users and the BS transmit beamformers in different time slices, we aim to
minimize the total power cost, including not only the power for QoS guarantee,
but also the power for user status switching. Due to the NP-hardness of the
problem, we develop two (offline and online) algorithms to find some efficient
suboptimal solutions. The offline algorithm requires all channel state
information (CSI), and solves the admissible users and beamformers in different
time slices in one shot, based on successive upper-bound minimization (SUM). To
support real-time data transmission, we further design an alternating direction
method of multipliers (ADMM)-based online algorithm, which outputs the
admissible users and beamformers in different time slices successively,
utilizing the previous admissible user set, the actual value of current CSI,
and the distribution of future CSI. Simulations validate the performance of the
two algorithms, and show that the online algorithm is an efficient practical
alternative to the offline algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03647</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03647</id><created>2019-09-09</created><authors><author><keyname>Liu</keyname><forenames>Jiaying</forenames></author><author><keyname>Liu</keyname><forenames>Dong</forenames></author><author><keyname>Yang</keyname><forenames>Wenhan</forenames></author><author><keyname>Xia</keyname><forenames>Sifeng</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaoshuai</forenames></author><author><keyname>Dai</keyname><forenames>Yuanying</forenames></author></authors><title>A Comprehensive Benchmark for Single Image Compression Artifacts
  Reduction</title><categories>eess.IV cs.CV</categories><comments>https://flyywh.github.io/LIU4K_Website/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a comprehensive study and evaluation of existing single image
compression artifacts removal algorithms, using a new 4K resolution benchmark
including diversified foreground objects and background scenes with rich
structures, called Large-scale Ideal Ultra high definition 4K (LIU4K)
benchmark. Compression artifacts removal, as a common post-processing
technique, aims at alleviating undesirable artifacts such as blockiness,
ringing, and banding caused by quantization and approximation in the
compression process. In this work, a systematic listing of the reviewed methods
is presented based on their basic models (handcrafted models and deep
networks). The main contributions and novelties of these methods are
highlighted, and the main development directions, including architectures,
multi-domain sources, signal structures, and new targeted units, are
summarized. Furthermore, based on a unified deep learning configuration (i.e.
same training data, loss function, optimization algorithm, etc.), we evaluate
recent deep learning-based methods based on diversified evaluation measures.
The experimental results show the state-of-the-art performance comparison of
existing methods based on both full-reference, non-reference and task-driven
metrics. Our survey would give a comprehensive reference source for future
research on single image compression artifacts removal and inspire new
directions of the related fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03650</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03650</id><created>2019-09-09</created><authors><author><keyname>Kawahara</keyname><forenames>Hideki</forenames></author><author><keyname>Sakakibara</keyname><forenames>Ken-Ichi</forenames></author><author><keyname>Haneishi</keyname><forenames>Eri</forenames></author><author><keyname>Hagiwara</keyname><forenames>Kaori</forenames></author></authors><title>Real-time and interactive tools for vocal training based on an analytic
  signal with a cosine series envelope</title><categories>cs.SD cs.HC eess.AS eess.SP</categories><comments>4 pages, 6 figures, APSIPA ASC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce real-time and interactive tools for assisting vocal training. In
this presentation, we demonstrate mainly a tool based on real-time visualizer
of fundamental frequency candidates to provide information-rich feedback to
learners. The visualizer uses an efficient algorithm using analytic signals for
deriving phase-based attributes. We start using these tools in vocal training
for assisting learners to acquire the awareness of appropriate vocalization.
The first author made the MATLAB implementation of the tools open-source. The
code and associated video materials are accessible in the first author's GitHub
repository.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03661</identifier>
 <datestamp>2019-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03661</id><created>2019-09-09</created><authors><author><keyname>Kraljic</keyname><forenames>David</forenames></author><author><keyname>Troha</keyname><forenames>Miha</forenames></author><author><keyname>Sobocan</keyname><forenames>Blaz</forenames></author></authors><title>Extracting physical power plant parameters from historical behaviour</title><categories>eess.SY cs.SY</categories><comments>5 pages, Accepted contribution for The European Energy Market 2019
  conference</comments><doi>10.1109/EEM.2019.8916516</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The information needed for fundamental modelling of the power markets -- the
efficiency, start-up, fixed, and variable operating costs of each power plant
-- is not publicly available. These parameters are usually estimated by
considering the type of technology and the age of a power plant. We present a
method to extract these parameters for thermal power plants on the British
electricity market using only the publicly available data. For each power
plant, we solve a bilevel optimisation problem, where the inner level solves
the Unit Commitment (UC) problem and outputs the optimal schedule given the
prices of fuel, emissions, electricity, and the unknown plant parameters. The
outer level then optimises over the plant parameters matching the historical
production of each plant as closely as possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03664</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03664</id><created>2019-09-09</created><authors><author><keyname>Lazar</keyname><forenames>Daniel A.</forenames></author><author><keyname>B&#x131;y&#x131;k</keyname><forenames>Erdem</forenames></author><author><keyname>Sadigh</keyname><forenames>Dorsa</forenames></author><author><keyname>Pedarsani</keyname><forenames>Ramtin</forenames></author></authors><title>Learning How to Dynamically Route Autonomous Vehicles on Shared Roads</title><categories>math.OC cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Road congestion induces significant costs across the world, and road network
disturbances, such as traffic accidents, can cause highly congested traffic
patterns. If a planner had control over the routing of all vehicles in the
network, they could easily reverse this effect. In a more realistic scenario,
we consider a planner that controls autonomous cars, which are a fraction of
all present cars. We study a dynamic routing game, in which the route choices
of autonomous cars can be controlled and the human drivers react selfishly and
dynamically to autonomous cars' actions. As the problem is prohibitively large,
we use deep reinforcement learning to learn a policy for controlling the
autonomous vehicles. This policy influences human drivers to route themselves
in such a way that minimizes congestion on the network. To gauge the
effectiveness of our learned policies, we establish theoretical results
characterizing equilibria on a network of parallel roads and empirically
compare the learned policy results with best possible equilibria. Moreover, we
show that in the absence of these policies, high demands and network
perturbations would result in large congestion, whereas using the policy
greatly decreases the travel times by minimizing the congestion. To the best of
our knowledge, this is the first work that employs deep reinforcement learning
to reduce congestion by influencing humans' routing decisions in mixed-autonomy
traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03676</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03676</id><created>2019-09-09</created><updated>2019-10-11</updated><authors><author><keyname>Pakravan</keyname><forenames>Mansooreh</forenames></author><author><keyname>Shamsollahi</keyname><forenames>Mohammad Bagher</forenames></author></authors><title>Joint, Partially-joint, and Individual Independent Component Analysis in
  Multi-Subject fMRI Data</title><categories>stat.ML cs.LG eess.SP</categories><doi>10.1109/TBME.2019.2953274</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Objective: Joint analysis of multi-subject brain imaging datasets has wide
applications in biomedical engineering. In these datasets, some sources belong
to all subjects (joint), a subset of subjects (partially-joint), or a single
subject (individual). In this paper, this source model is referred to as
joint/partially-joint/individual multiple datasets multidimensional (JpJI-MDM),
and accordingly, a source extraction method is developed. Method: We present a
deflation-based algorithm utilizing higher order cumulants to analyze the
JpJI-MDM source model. The algorithm maximizes a cost function which leads to
an eigenvalue problem solved with thin-SVD (singular value decomposition)
factorization. Furthermore, we introduce the JpJI-feature which indicates the
spatial shape of each source and the amount of its jointness with other
subjects. We use this feature to determine the type of sources. Results: We
evaluate our algorithm by analyzing simulated data and two real functional
magnetic resonance imaging (fMRI) datasets. In our simulation study, we will
show that the proposed algorithm determines the type of sources with the
accuracy of 95% and 100% for 2-class and 3-class clustering scenarios,
respectively. Furthermore, our algorithm extracts meaningful joint and
partially-joint sources from the two real datasets, which are consistent with
the existing neuroscience studies. Conclusion: Our results in analyzing the
real datasets reveal that both datasets follow the JpJI-MDM source model. This
source model improves the accuracy of source extraction methods developed for
multi-subject datasets. Significance: The proposed joint blind source
separation algorithm is robust and avoids parameters which are difficult to
fine-tune.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03739</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03739</id><created>2019-09-09</created><updated>2019-11-24</updated><authors><author><keyname>Tennenholtz</keyname><forenames>Guy</forenames></author><author><keyname>Mannor</keyname><forenames>Shie</forenames></author><author><keyname>Shalit</keyname><forenames>Uri</forenames></author></authors><title>Off-Policy Evaluation in Partially Observable Environments</title><categories>cs.LG cs.AI cs.SY eess.SY stat.ML</categories><comments>Accepted to AAAI-2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the problem of batch off-policy evaluation for
Reinforcement Learning in partially observable environments. Off-policy
evaluation under partial observability is inherently prone to bias, with risk
of arbitrarily large errors. We define the problem of off-policy evaluation for
Partially Observable Markov Decision Processes (POMDPs) and establish what we
believe is the first off-policy evaluation result for POMDPs. In addition, we
formulate a model in which observed and unobserved variables are decoupled into
two dynamic processes, called a Decoupled POMDP. We show how off-policy
evaluation can be performed under this new model, mitigating estimation errors
inherent to general POMDPs. We demonstrate the pitfalls of off-policy
evaluation in POMDPs using a well-known off-policy method, Importance Sampling,
and compare it with our result on synthetic medical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03748</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03748</id><created>2019-09-09</created><authors><author><keyname>Umer</keyname><forenames>Rao Muhammad</forenames></author><author><keyname>Foresti</keyname><forenames>Gian Luca</forenames></author><author><keyname>Micheloni</keyname><forenames>Christian</forenames></author></authors><title>Deep Super-Resolution Network for Single Image Super-Resolution with
  Realistic Degradations</title><categories>eess.IV cs.CV</categories><comments>7 pages</comments><journal-ref>13th International Conference on Distributed Smart Cameras (ICDSC
  2019)</journal-ref><doi>10.1145/3349801.3349823</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single Image Super-Resolution (SISR) aims to generate a high-resolution (HR)
image of a given low-resolution (LR) image. The most of existing convolutional
neural network (CNN) based SISR methods usually take an assumption that a LR
image is only bicubicly down-sampled version of an HR image. However, the true
degradation (i.e. the LR image is a bicubicly downsampled, blurred and noisy
version of an HR image) of a LR image goes beyond the widely used bicubic
assumption, which makes the SISR problem highly ill-posed nature of inverse
problems. To address this issue, we propose a deep SISR network that works for
blur kernels of different sizes, and different noise levels in an unified
residual CNN-based denoiser network, which significantly improves a practical
CNN-based super-resolver for real applications. Extensive experimental results
on synthetic LR datasets and real images demonstrate that our proposed method
not only can produce better results on more realistic degradation but also
computational efficient to practical SISR applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03749</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03749</id><created>2019-09-09</created><updated>2019-10-23</updated><authors><author><keyname>Ferreira</keyname><forenames>Fabio</forenames></author><author><keyname>Shao</keyname><forenames>Lin</forenames></author><author><keyname>Asfour</keyname><forenames>Tamim</forenames></author><author><keyname>Bohg</keyname><forenames>Jeannette</forenames></author></authors><title>Learning Visual Dynamics Models of Rigid Objects using Relational
  Inductive Biases</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>short paper (4 pages, two figures), accepted to NeurIPS 2019 Graph
  Representation Learning workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Endowing robots with human-like physical reasoning abilities remains
challenging. We argue that existing methods often disregard spatio-temporal
relations and by using Graph Neural Networks (GNNs) that incorporate a
relational inductive bias, we can shift the learning process towards exploiting
relations. In this work, we learn action-conditional forward dynamics models of
a simulated manipulation task from visual observations involving cluttered and
irregularly shaped objects. We investigate two GNN approaches and empirically
assess their capability to generalize to scenarios with novel and an increasing
number of objects. The first, Graph Networks (GN) based approach, considers
explicitly defined edge attributes and not only does it consistently
underperform an auto-encoder baseline that we modified to predict future
states, our results indicate how different edge attributes can significantly
influence the predictions. Consequently, we develop the Auto-Predictor that
does not rely on explicitly defined edge attributes. It outperforms the
baseline and the GN-based models. Overall, our results show the sensitivity of
GNN-based approaches to the task representation, the efficacy of relational
inductive biases and advocate choosing lightweight approaches that implicitly
reason about relations over ones that leave these decisions to human designers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03783</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03783</id><created>2019-09-09</created><authors><author><keyname>Cherukuri</keyname><forenames>Ashish</forenames></author></authors><title>Sample average approximation of CVaR-based Wardrop equilibrium in
  routing under uncertain costs</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the class of routing games that have uncertain costs.
Assuming that agents are risk-averse and select paths with minimum conditional
value-at-risk (CVaR) associated to them, we define the notion of CVaR-based
Wardrop equilibrium (CWE). We focus on computing this equilibrium under the
condition that the distribution of the uncertainty is unknown and a set of
independent and identically distributed samples is available. To this end, we
define the sample average approximation scheme where CWE is estimated with
solutions of a variational inequality problem involving sample average
approximations of the CVaR. We establish two properties for this scheme. First,
under continuity of costs and boundedness of uncertainty, we prove asymptotic
consistency, establishing almost sure convergence of approximate equilibria to
CWE as the sample size grows. Second, under the additional assumption of
Lipschitz cost, we prove exponential convergence where the probability of the
distance between an approximate solution and the CWE being smaller than any
constant approaches unity exponentially fast. Simulation example validates our
theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03824</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03824</id><created>2019-09-06</created><authors><author><keyname>Tian</keyname><forenames>Yongqiang</forenames></author><author><keyname>Ma</keyname><forenames>Shiqing</forenames></author><author><keyname>Wen</keyname><forenames>Ming</forenames></author><author><keyname>Liu</keyname><forenames>Yepang</forenames></author><author><keyname>Cheung</keyname><forenames>Shing-Chi</forenames></author><author><keyname>Zhang</keyname><forenames>Xiangyu</forenames></author></authors><title>Testing Deep Learning Models for Image Analysis Using Object-Relevant
  Metamorphic Relations</title><categories>cs.LG cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning models are widely used for image analysis. While they offer
high performance in terms of accuracy, people are concerned about if these
models inappropriately make inferences using irrelevant features that are not
encoded from the target object in a given image. To address the concern, we
propose a metamorphic testing approach that assesses if a given inference is
made based on irrelevant features. Specifically, we propose two novel
metamorphic relations to detect such inappropriate inferences. We applied our
approach to 10 image classification models and 10 object detection models, with
three large datasets, i.e., ImageNet, COCO, and Pascal VOC. Over 5.3% of the
top-5 correct predictions made by the image classification models are subject
to inappropriate inferences using irrelevant features. The corresponding rate
for the object detection models is over 8.5%. Based on the findings, we further
designed a new image generation strategy that can effectively attack existing
models. Comparing with a baseline approach, our strategy can double the success
rate of attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03836</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03836</id><created>2019-09-06</created><authors><author><keyname>Chandler</keyname><forenames>M.</forenames></author><author><keyname>Jenkins</keyname><forenames>C.</forenames></author><author><keyname>Shermer</keyname><forenames>S. M.</forenames></author><author><keyname>Langbein</keyname><forenames>F. C.</forenames></author></authors><title>MRSNet: Metabolite Quantification from Edited Magnetic Resonance Spectra
  With Convolutional Neural Networks</title><categories>eess.IV eess.SP physics.med-ph</categories><comments>12 pages, 5 figures, 10 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantification of metabolites from magnetic resonance spectra (MRS) has many
applications in medicine and psychology, but remains a challenging task despite
considerable research efforts. For example, the neurotransmitter
$\gamma$-aminobutyric acid (GABA), present in very low concentration in vivo,
regulates inhibitory neurotransmission in the brain and is involved in several
processes outside the brain. Reliable quantification is required to determine
its role in various physiological and pathological conditions. We present a
novel approach to quantification of metabolites from MRS with convolutional
neural networks --- MRSNet. MRSNet is trained to perform the multi-class
regression problem of identifying relative metabolite concentrations from given
input spectra, focusing specifically on the quantification of GABA, which is
particularly difficult to resolve. Typically it can only be detected at all
using special editing acquisition sequences such as MEGA-PRESS. A large range
of network structures, data representations and automatic processing methods
are investigated. Results are benchmarked using experimental datasets from test
objects of known composition and compared to state-of-the-art quantification
methods: LCModel, jMRUI (AQUES, QUEST), TARQUIN, VeSPA and Gannet. The results
show that the overall accuracy and precision of metabolite quantification is
improved using convolutional neural networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03868</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03868</id><created>2019-09-09</created><updated>2019-09-10</updated><authors><author><keyname>K&#xf6;pf</keyname><forenames>Florian</forenames></author><author><keyname>Nitsch</keyname><forenames>Alexander</forenames></author><author><keyname>Flad</keyname><forenames>Michael</forenames></author><author><keyname>Hohmann</keyname><forenames>S&#xf6;ren</forenames></author></authors><title>Partner Approximating Learners (PAL): Simulation-Accelerated Learning
  with Explicit Partner Modeling in Multi-Agent Domains</title><categories>eess.SY cs.AI cs.LG cs.MA cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mixed cooperative-competitive control scenarios such as human-machine
interaction with individual goals of the interacting partners are very
challenging for reinforcement learning agents. In order to contribute towards
intuitive human-machine collaboration, we focus on problems in the continuous
state and control domain where no explicit communication is considered and the
agents do not know the others' goals or control laws but only sense their
control inputs retrospectively. Our proposed framework combines a learned
partner model based on online data with a reinforcement learning agent that is
trained in a simulated environment including the partner model. Thus, we
overcome drawbacks of independent learners and, in addition, benefit from a
reduced amount of real world data required for reinforcement learning which is
vital in the human-machine context. We finally analyze an example that
demonstrates the merits of our proposed framework which learns fast due to the
simulated environment and adapts to the continuously changing partner due to
the partner approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03873</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03873</id><created>2019-09-09</created><authors><author><keyname>Su</keyname><forenames>Nanchi</forenames></author><author><keyname>Liu</keyname><forenames>Fan</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author></authors><title>Secure Radar-Communication Systems with Malicious Targets: Integrating
  Radar, Communications and Jamming Functionalities</title><categories>eess.SP</categories><comments>12 pages, 8 figures, submitted to transactions on wireless
  communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the physical layer security in a
multiple-input-multiple-output (MIMO) dual-functional radar-communication
(DFRC) system, which communicates with downlink cellular users and tracks radar
targets simultaneously. Here, the radar targets are considered as potential
eavesdroppers which might eavesdrop the information from the communication
transmitter to legitimate users. To ensure the transmission secrecy, we employ
artificial noise (AN) at the transmitter and formulate optimization problems by
minimizing the signal-to-interference-plus-noise ratio (SINR) received at radar
targets, while guaranteeing the SINR requirement at legitimate users. We first
consider the ideal case where both the target angle and the channel state
information (CSI) are precisely known. The scenario is further extended to more
general cases with target location uncertainty and CSI errors, where we propose
robust optimization approaches to guarantee the worst-case performances.
Accordingly, the computational complexity is analyzed for each proposed method.
Our numerical results show the feasibility of the algorithms with the existence
of instantaneous and statistical CSI error. In addition, the secrecy rate of
secure DFRC system grows with the increasing angular interval of location
uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03891</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03891</id><created>2019-09-05</created><authors><author><keyname>Yazdanpanah</keyname><forenames>Hamed</forenames></author></authors><title>On Data-Selective Learning</title><categories>eess.SP cs.LG stat.ML</categories><comments>Ph.D. Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive filters are applied in several electronic and communication devices
like smartphones, advanced headphones, DSP chips, smart antenna, and
teleconference systems. Also, they have application in many areas such as
system identification, channel equalization, noise reduction, echo
cancellation, interference cancellation, signal prediction, and stock market.
Therefore, reducing the energy consumption of the adaptive filtering algorithms
has great importance, particularly in green technologies and in devices using
battery.
  In this thesis, data-selective adaptive filters, in particular the
set-membership (SM) adaptive filters, are the tools to reach the goal. There
are well known SM adaptive filters in literature. This work introduces new
algorithms based on the classical ones in order to improve their performances
and reduce the number of required arithmetic operations at the same time.
Therefore, firstly, we analyze the robustness of the classical SM adaptive
filtering algorithms. Secondly, we extend the SM technique to trinion and
quaternion systems. Thirdly, by combining SM filtering and partial-updating, we
introduce a new improved set-membership affine projection algorithm with
constrained step size to improve its stability behavior. Fourthly, we propose
some new least-mean-square (LMS) based and recursive least-squares based
adaptive filtering algorithms with low computational complexity for sparse
systems. Finally, we derive some feature LMS algorithms to exploit the hidden
sparsity in the parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03892</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03892</id><created>2019-09-05</created><authors><author><keyname>Lee</keyname><forenames>Donghoon</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>A Variational Bayes Approach to Adaptive Radio Tomography</title><categories>eess.SP cs.LG stat.ML</categories><comments>submitted to IEEE Transactions on Signal Processing. arXiv admin
  note: substantial text overlap with arXiv:1804.02084</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio tomographic imaging (RTI) is an emerging technology for localization of
physical objects in a geographical area covered by wireless networks. With
attenuation measurements collected at spatially distributed sensors, RTI
capitalizes on spatial loss fields (SLFs) measuring the absorption of radio
frequency waves at spatial locations along the propagation path. These SLFs can
be utilized for interference management in wireless communication networks,
environmental monitoring, and survivor localization after natural disasters
such as earthquakes. Key to the success of RTI is to accurately model shadowing
as the weighted line integral of the SLF. To learn the SLF exhibiting
statistical heterogeneity induced by spatially diverse environments, the
present work develops a Bayesian framework entailing a piecewise homogeneous
SLF with an underlying hidden Markov random field model. Utilizing variational
Bayes techniques, the novel approach yields efficient field estimators at
affordable complexity. A data-adaptive sensor selection strategy is also
introduced to collect informative measurements for effective reconstruction of
the SLF. Numerical tests using synthetic and real datasets demonstrate the
capabilities of the proposed approach to radio tomography and channel-gain
estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03900</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03900</id><created>2019-09-09</created><authors><author><keyname>Xu</keyname><forenames>Weitao</forenames></author><author><keyname>Kim</keyname><forenames>Jun Young</forenames></author><author><keyname>Huang</keyname><forenames>Walter</forenames></author><author><keyname>Kanhere</keyname><forenames>Salil</forenames></author><author><keyname>Jha</keyname><forenames>Sanjay</forenames></author><author><keyname>Hu</keyname><forenames>Wen</forenames></author></authors><title>Measurement, Characterization and Modeling of LoRa Technology in
  Multi-floor Buildings</title><categories>cs.NI eess.SP</categories><comments>10 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, we have witnessed the rapid development of LoRa technology,
together with extensive studies trying to understand its performance in various
application settings. In contrast to measurements performed in large outdoor
areas, limited number of attempts have been made to understand the
characterization and performance of LoRa technology in indoor environments. In
this paper, we present a comprehensive study of LoRa technology in multi-floor
buildings. Specifically, we investigate the large-scale fading characteristic,
temporal fading characteristic, coverage and energy consumption of LoRa
technology in four different types of buildings. Moreover, we find that the
energy consumption using different parameter settings can vary up to 145 times.
These results indicate the importance of parameter selection and enabling LoRa
adaptive data rate feature in energy-limited applications. We hope the results
in this paper can help both academia and industry understand the performance of
LoRa technology in multi-floor buildings to facilitate developing practical
indoor applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03902</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03902</id><created>2019-09-09</created><authors><author><keyname>Joshi</keyname><forenames>Kishor Chandra</forenames></author><author><keyname>Niknam</keyname><forenames>Solmaz</forenames></author><author><keyname>Prasad</keyname><forenames>R. Venkatesha</forenames></author><author><keyname>Natarajan</keyname><forenames>Balasubramaniam</forenames></author></authors><title>Analyzing the Trade-offs in Using Millimeter Wave Directional Links for
  High Data Rate Tactile Internet Applications</title><categories>cs.NI eess.SP</categories><comments>IEEE Transactions on Industrial Informatics, 2019</comments><doi>10.1109/TII.2019.2931703</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultra-low latency and high reliability communications are the two defining
characteristics of Tactile Internet (TI). Nevertheless, some TI applications
would also require high data-rate transfer of audio-visual information to
complement the haptic data. Using Millimeter wave (mmWave) communications is an
attractive choice for high datarate TI applications due to the availability of
large bandwidth in the mmWave bands. Moreover, mmWave radio access is also
advantageous to attain the airinterface-diversity required for high reliability
in TI systems as mmWave signal propagation significantly differs to sub-6GHz
propagation. However, the use of narrow beamwidth in mmWave systems makes them
susceptible to link misalignment-induced unreliability and high access latency.
In this paper, we analyze the trade-offs between high gain of narrow beamwidth
antennas and corresponding susceptibility to misalignment in mmWave links. To
alleviate the effects of random antenna misalignment, we propose a
beamwidth-adaptation scheme that significantly stabilize the link throughput
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03919</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03919</id><created>2019-09-09</created><authors><author><keyname>Zang</keyname><forenames>Junwei</forenames></author><author><keyname>Towhidlou</keyname><forenames>Vahid</forenames></author><author><keyname>Shikh-Bahaei</keyname><forenames>Mohammad</forenames></author></authors><title>Collision Avoidance in V2X Communication Networks</title><categories>cs.NI eess.SP</categories><comments>This paper is accepted on WCNC 2019, Workshop on Smart Spectrum
  Marrakech, Morocco, Apr. 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate collision detection and avoidance in a vehicular
network of full duplex (FD) operating nodes. Each vehicle in this network
senses the energy level of the channel before and during its transmission. The
measured energy is compared against a dynamic threshold which is preset based
on the target detection probability, transmitter's power, sensing time and
self-interference cancellation (SIC) capability of the vehicles' on board units
(OBU). Probabilities of detection and false alarm, detection threshold before
and during transmission, and effect of residual self interference (SI) on these
metrics have been formulated. It is shown that the proposed scheme would
experience a shorter collision duration. Meanwhile, it also requires a minimum
SIC capability for acceptable operation, below which, system throughput would
be poor due to high false alarm probability. Numerical simulations verify the
accuracy of our analysis. They also illustrate that the proposed model perform
better than the fixed threshold strategy. A trade-off between half duplex (HD)
and FD has been found and the scheme would be applicable even if SIC capability
of OBUs is relatively poor, with no need for complicated and expensive devices
for future vehicular communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03932</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03932</id><created>2019-09-09</created><authors><author><keyname>Zhao</keyname><forenames>Di</forenames></author><author><keyname>Rantzer</keyname><forenames>Anders</forenames></author><author><keyname>Qiu</keyname><forenames>Li</forenames></author></authors><title>A Convex Approach to Frisch-Kalman Problem</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a convex approach to the Frisch-Kalman problem that
identifies the linear relations among variables from noisy observations. The
problem was proposed by Ragnar Frisch in 1930s, and was promoted and further
developed by Rudolf Kalman later in 1980s. It is essentially a rank
minimization problem with convex constraints. Regarding this problem,
analytical results and heuristic methods have been pursued over a half century.
The proposed convex method in this paper is shown to be accurate and
demonstrated to outperform several commonly adopted heuristics when the noise
components are relatively small compared with the underlying data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03953</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03953</id><created>2019-09-09</created><authors><author><keyname>Gahr</keyname><forenames>Bernhard</forenames></author><author><keyname>Liu</keyname><forenames>Shu</forenames></author><author><keyname>Koch</keyname><forenames>Kevin</forenames></author><author><keyname>Barata</keyname><forenames>Filipe</forenames></author><author><keyname>Dahlinger</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Ryder</keyname><forenames>Benjamin</forenames></author><author><keyname>Fleisch</keyname><forenames>Elgar</forenames></author><author><keyname>Wortmann</keyname><forenames>Felix</forenames></author></authors><title>Driver Identification via the Steering Wheel</title><categories>stat.ML cs.LG eess.SP</categories><comments>10 pages, 16 figures, 6 equations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Driver identification has emerged as a vital research field, where both
practitioners and researchers investigate the potential of driver
identification to enable a personalized driving experience. Within recent
years, a selection of studies have reported that individuals could be perfectly
identified based on their driving behavior under controlled conditions.
However, research investigating the potential of driver identification under
naturalistic conditions claim accuracies only marginally higher than random
guess. The paper at hand provides a comprehensive summary of the recent work,
highlighting the main discrepancies in the design of the machine learning
approaches, primarily the window length parameter that was considered. Key
findings further indicate that the longitudinal vehicle control information is
particularly useful for driver identification, leaving the research gap on the
extent to which the lateral vehicle control can be used for reliable
identification. Building upon existing work, we provide a novel approach for
the design of the window length parameter that provides evidence that reliable
driver identification can be achieved with data limited to the steering wheel
only. The results and insights in this paper are based on data collected from
the largest naturalistic driving study conducted in this field. Overall, a
neural network based on GRUs was found to provide better identification
performance than traditional methods, increasing the prediction accuracy from
under 15\% to over 65\% for 15 drivers. When leveraging the full field study
dataset, comprising 72 drivers, the accuracy of identification prediction of
the approach improved a random guess approach by a factor of 25.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03957</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03957</id><created>2019-09-01</created><authors><author><keyname>Onyedinma</keyname><forenames>E</forenames></author><author><keyname>Onyenwe</keyname><forenames>I</forenames></author><author><keyname>Inyiama</keyname><forenames>H</forenames></author></authors><title>Performance Evaluation of Histogram Equalization and Fuzzy image
  Enhancement Techniques on Low Contrast Images</title><categories>cs.CV eess.IV</categories><journal-ref>International Journal of Computer Science and Software Engineering
  (IJCSSE), Volume 8, Issue 7, Page: 144-150, July2019. ISSN (Online):
  2409-4285w w w.IJCSSE.org</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image enhancement aims at improving the information content of original image
for a specific purpose. This purpose could be for visual interpretation or for
effective extraction of required details. Nevertheless, some acquired images
are often associated with pixels of low dynamic range and as such result in low
contrast images. Enhancing the contrast therefore tends to increase the dynamic
range of the gray levels in the acquired image so as to span the full intensity
range. Techniques such as Histogram Equalization (HE) and fuzzy technique can
be adopted for contrast enhancement. HE adjusts the contrast of an input image
by modifying the intensity distribution of its histogram. It is characterized
by providing a global approach to image enhancement, computationally fast and
easy to implement approach but can introduce unnatural artifacts and other
undesirable elements to the resulting image. Fuzzy technique on its part
enhances image by mapping the image gray level intensities into a fuzzy plane
using membership functions; modifying the membership functions as desired and
mapping back into the gray level plane. Thus, details at desired areas can be
enhanced at the expense of increase in computational cost. This paper explores
the effect of the use of HE and fuzzy technique to enhance low contrast images.
Their performances are evaluated using the Mean squared error (MSE), Peak to
signal noise ratio (PSNR), entropy and Absolute mean brightness error (AMBE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03965</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03965</id><created>2019-09-09</created><authors><author><keyname>Clark</keyname><forenames>Rob</forenames></author><author><keyname>Silen</keyname><forenames>Hanna</forenames></author><author><keyname>Kenter</keyname><forenames>Tom</forenames></author><author><keyname>Leith</keyname><forenames>Ralph</forenames></author></authors><title>Evaluating Long-form Text-to-Speech: Comparing the Ratings of Sentences
  and Paragraphs</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>Accepted for The 10th ISCA Speech Synthesis Workshop (SSW10), 6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text-to-speech systems are typically evaluated on single sentences. When
long-form content, such as data consisting of full paragraphs or dialogues is
considered, evaluating sentences in isolation is not always appropriate as the
context in which the sentences are synthesized is missing. In this paper, we
investigate three different ways of evaluating the naturalness of long-form
text-to-speech synthesis. We compare the results obtained from evaluating
sentences in isolation, evaluating whole paragraphs of speech, and presenting a
selection of speech or text as context and evaluating the subsequent speech. We
find that, even though these three evaluations are based upon the same
material, the outcomes differ per setting, and moreover that these outcomes do
not necessarily correlate with each other. We show that our findings are
consistent between a single speaker setting of read paragraphs and a
two-speaker dialogue scenario. We conclude that to evaluate the quality of
long-form speech, the traditional way of evaluating sentences in isolation does
not suffice, and that multiple evaluations are required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03974</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03974</id><created>2019-09-09</created><updated>2019-09-10</updated><authors><author><keyname>Reddy</keyname><forenames>M Kiran</forenames></author><author><keyname>Rao</keyname><forenames>K Sreenivasa</forenames></author></authors><title>DNN-based cross-lingual voice conversion using Bottleneck Features</title><categories>eess.AS cs.LG cs.SD</categories><doi>10.1007/s11063-019-10149-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cross-lingual voice conversion (CLVC) is a quite challenging task since the
source and target speakers speak different languages. This paper proposes a
CLVC framework based on bottleneck features and deep neural network (DNN). In
the proposed method, the bottleneck features extracted from a deep auto-encoder
(DAE) are used to represent speaker-independent features of speech signals from
different languages. A DNN model is trained to learn the mapping between
bottleneck features and the corresponding spectral features of the target
speaker. The proposed method can capture speaker-specific characteristics of a
target speaker, and hence requires no speech data from source speaker during
training. The performance of the proposed method is evaluated using data from
three Indian languages: Telugu, Tamil and Malayalam. The experimental results
show that the proposed method outperforms the baseline Gaussian mixture model
(GMM)-based CLVC approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03986</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03986</id><created>2019-09-09</created><authors><author><keyname>Wada</keyname><forenames>Akihiko</forenames></author><author><keyname>Saito</keyname><forenames>Yuya</forenames></author><author><keyname>Irie</keyname><forenames>Ryusuke</forenames></author><author><keyname>Kamagata</keyname><forenames>Koji</forenames></author><author><keyname>Maekawa</keyname><forenames>Tomoko</forenames></author><author><keyname>Fujita</keyname><forenames>Shohei</forenames></author><author><keyname>Hagiwara</keyname><forenames>Akifumi</forenames></author><author><keyname>Kumamaru</keyname><forenames>Kanako</forenames></author><author><keyname>Suzuki</keyname><forenames>Michimasa</forenames></author><author><keyname>Nakanishi</keyname><forenames>Atsushi</forenames></author><author><keyname>Hori</keyname><forenames>Masaaki</forenames></author><author><keyname>Shimizu</keyname><forenames>Toshiaki</forenames></author><author><keyname>Aoki</keyname><forenames>Shigeki</forenames></author></authors><title>Convolutional Neural Networks for Estimation of Myelin Maturation in
  Infant Brain</title><categories>q-bio.QM eess.IV</categories><comments>7 pages, 4 figures, 1 table</comments><msc-class>62P10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Myelination plays an important role in the neurological development of infant
brain and MRI can visualize the myelination extension as T1 high and T2 low
signal intensity at white matter. We tried to construct a convolutional neural
network machine learning model to estimate the myelination. Eight layers CNN
architecture was constructed to estimate the subjects age with T1 and T2
weighted image at 5 levels associated with myelin maturation in 119 subjects up
to 24 months. CNN model learned with all age dataset revealed a strong
correlation between the estimated age and the corrected age and the coefficient
of correlation, root mean square error and mean absolute error was 0. 81, 3. 40
and 2. 28. Moreover, the adaptation of ensemble learning models with two
datasets 0 to 16 months and 8 to 24 months improved that to 0. 93, 2. 12 and 1.
34. Deep learning can be adaptable to myelination estimation in infant brain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.03989</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.03989</id><created>2019-09-09</created><updated>2019-11-12</updated><authors><author><keyname>Shishika</keyname><forenames>Daigo</forenames></author><author><keyname>Kumar</keyname><forenames>Vijay</forenames></author></authors><title>Perimeter-defense Game on Arbitrary Convex Shapes</title><categories>eess.SY cs.SY math.OC</categories><comments>Fixed typos. Link to supplemental video added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a variant of multi-player reach-avoid game played between
intruders and defenders. The intruder team tries to score by sending as many
intruders as possible to the target area, while the defender team tries to
minimize this score by intercepting them. Specifically, we consider the case
where the defenders are constrained to move on the perimeter of the target
area. Finding the optimal strategies of the game is challenging due to the high
dimensionality of the joint state space. As a tractable approximation, existing
methods reduce the design of the defense strategy to an assignment problem by
decomposing the game into a combination of one vs. one games. To solve the one
vs. one game, those works either rely on numerical approaches or makes
simplifying assumptions (e.g., circular perimeter, or equal speed). This paper
provides an analytical solution to the case where the target area takes any
arbitrary convex shape. We also provide a detailed discussion on the optimality
of the derived strategies. In addition, we solve the two vs. one game to
introduce a cooperative pincer maneuver, where a pair of defenders team up to
capture an intruder that cannot be captured by either one of the defender
individually. The existing assignment-based defense strategy is extended to
incorporate such cooperative behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04012</identifier>
 <datestamp>2020-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04012</id><created>2019-09-09</created><authors><author><keyname>Fu</keyname><forenames>Jie</forenames></author><author><keyname>Zhong</keyname><forenames>Xinran</forenames></author><author><keyname>Li</keyname><forenames>Ning</forenames></author><author><keyname>Van Dams</keyname><forenames>Ritchell</forenames></author><author><keyname>Lewis</keyname><forenames>John</forenames></author><author><keyname>Sung</keyname><forenames>Kyunghyun</forenames></author><author><keyname>Raldow</keyname><forenames>Ann C.</forenames></author><author><keyname>Jin</keyname><forenames>Jing</forenames></author><author><keyname>Qi</keyname><forenames>X. Sharon</forenames></author></authors><title>Deep Learning-based Radiomic Features for Improving Neoadjuvant
  Chemoradiation Response Prediction in Locally Advanced Rectal Cancer</title><categories>physics.med-ph cs.CV eess.IV</categories><comments>Review in progress</comments><journal-ref>2020 Phys. Med. Biol</journal-ref><doi>10.1088/1361-6560/ab7970</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radiomic features achieve promising results in cancer diagnosis, treatment
response prediction, and survival prediction. Our goal is to compare the
handcrafted (explicitly designed) and deep learning (DL)-based radiomic
features extracted from pre-treatment diffusion-weighted magnetic resonance
images (DWIs) for predicting neoadjuvant chemoradiation treatment (nCRT)
response in patients with locally advanced rectal cancer (LARC). 43 patients
receiving nCRT were included. All patients underwent DWIs before nCRT and total
mesorectal excision surgery 6-12 weeks after completion of nCRT. Gross tumor
volume (GTV) contours were drawn by an experienced radiation oncologist on
DWIs. The patient-cohort was split into the responder group (n=22) and the
non-responder group (n=21) based on the post-nCRT response assessed by
postoperative pathology, MRI or colonoscopy. Handcrafted and DL-based features
were extracted from the apparent diffusion coefficient (ADC) map of the DWI
using conventional computer-aided diagnosis methods and a pre-trained
convolution neural network, respectively. Least absolute shrinkage and
selection operator (LASSO)-logistic regression models were constructed using
extracted features for predicting treatment response. The model performance was
evaluated with repeated 20 times stratified 4-fold cross-validation using
receiver operating characteristic (ROC) curves and compared using the corrected
resampled t-test. The model built with handcrafted features achieved the mean
area under the ROC curve (AUC) of 0.64, while the one built with DL-based
features yielded the mean AUC of 0.73. The corrected resampled t-test on AUC
showed P-value &lt; 0.05. DL-based features extracted from pre-treatment DWIs
achieved significantly better classification performance compared with
handcrafted features for predicting nCRT response in patients with LARC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04018</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04018</id><created>2019-09-09</created><authors><author><keyname>Gao</keyname><forenames>Jie</forenames><affiliation>Sherman</affiliation></author><author><keyname>Li</keyname><forenames>Mushu</forenames><affiliation>Sherman</affiliation></author><author><keyname>Zhao</keyname><forenames>Lian</forenames><affiliation>Sherman</affiliation></author><author><keyname>Xuemin</keyname><affiliation>Sherman</affiliation></author><author><keyname>Shen</keyname></author></authors><title>Contention Intensity based Distributed Coordination for V2V Safety
  Message Broadcast</title><categories>eess.SY cs.SY</categories><comments>25 Pages, 8 Figures</comments><journal-ref>IEEE Transactions on Vehicular Technology, Volume: 67, Issue: 12,
  Dec.2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a contention intensity based distributed
coordination (CIDC) scheme for safety message broadcast. By exploiting the
high-frequency and periodical features of the safety message broadcast, the
application-layer design of the CIDC enables each vehicle to estimate the
instantaneous channel contention intensity in a fully distributed manner. With
the contention intensity information, the MAC layer design of CIDC allows
vehicles to adopt a better channel access strategy compared to the 802.11p.
This is because CIDC selects the initial back-off counter for each new packet
deterministically, i.e., based on the contention intensity, instead of
randomly. The proposed CIDC is modeled, and key performance indicators in terms
of the packet collision probability and average contention delay, are derived.
It is shown that the proposed change in the initial counter selection leads to
a system model completely different from the classic Markov chain based model.
Moreover, the proposed CIDC, fully distributed and compatible with the 802.11p,
can achieve both a much lower collision probability and a smaller contention
delay compared with 802.11p at the cost of a small communication and
computation overhead. Extensive simulation results demonstrate the
effectiveness of the CIDC in both of the accurate and the erroneous contention
intensity estimation scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04087</identifier>
 <datestamp>2020-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04087</id><created>2019-09-09</created><updated>2020-01-29</updated><authors><author><keyname>Kim</keyname><forenames>Bach Ngoc</forenames></author><author><keyname>Dolz</keyname><forenames>Jose</forenames></author><author><keyname>Jodoin</keyname><forenames>Pierre-Marc</forenames></author><author><keyname>Desrosiers</keyname><forenames>Christian</forenames></author></authors><title>Privacy-Net: An Adversarial Approach for Identity-Obfuscated
  Segmentation of Medical Images</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a client/server privacy-preserving network in the context
of multicentric medical image analysis. Our approach is based on adversarial
learning which encodes images to obfuscate the patient identity while
preserving enough information for a target task. Our novel architecture is
composed of three components: 1) an encoder network which removes
identity-specific features from input medical images, 2) a discriminator
network that attempts to identify the subject from the encoded images, 3) a
medical image analysis network which analyzes the content of the encoded images
(segmentation in our case). By simultaneously fooling the discriminator and
optimizing the medical analysis network, the encoder learns to remove
privacy-specific features while keeping those essentials for the target task.
Our approach is illustrated on the problem of segmenting brain MRI from the
large-scale Parkinson Progression Marker Initiative (PPMI) dataset. Using
longitudinal data from PPMI, we show that the discriminator learns to heavily
distort input images while allowing for highly accurate segmentation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04095</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04095</id><created>2019-09-09</created><authors><author><keyname>Ajala</keyname><forenames>Olaoluwapo</forenames></author><author><keyname>Dominguez-Garcia</keyname><forenames>Alejandro</forenames></author><author><keyname>Liberzon</keyname><forenames>Daniel</forenames></author></authors><title>Robust synchronization of electric power generators</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of synchronizing two electric power generators, one
of which (the leader) is serving a time-varying electrical load, so that they
can ultimately be connected to form a single power system. Each generator is
described by a second-order reduced state-space model. We assume that the
generator not serving an external load initially (the follower) has access to
measurements of the leader's phase angle, corrupted by some additive
disturbances. By using these measurements, and leveraging results on
reduced-order observers with ISS-type robustness, we propose a procedure that
drives (i) the angular velocity of the follower close enough to that of the
leader, and (ii) the phase angle of the follower close enough to that of the
point at which both systems will be electrically connected. An explicit bound
on the synchronization error in terms of the measurement disturbance and the
variations in the electrical load served by the leader is computed. We
illustrate the procedure via numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04104</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04104</id><created>2019-09-09</created><updated>2019-09-16</updated><authors><author><keyname>Shen</keyname><forenames>Zengming</forenames></author><author><keyname>Chen</keyname><forenames>Yifan</forenames></author><author><keyname>Zhou</keyname><forenames>S. Kevin</forenames></author><author><keyname>Georgescu</keyname><forenames>Bogdan</forenames></author><author><keyname>Liu</keyname><forenames>Xuqi</forenames></author><author><keyname>Huang</keyname><forenames>Thomas S.</forenames></author></authors><title>Towards Learning a Self-inverse Network for Bidirectional Image-to-image
  Translation</title><categories>cs.CV cs.AI cs.LG eess.IV</categories><comments>10 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The one-to-one mapping is necessary for many bidirectional image-to-image
translation applications, such as MRI image synthesis as MRI images are unique
to the patient. State-of-the-art approaches for image synthesis from domain X
to domain Y learn a convolutional neural network that meticulously maps between
the domains. A different network is typically implemented to map along the
opposite direction, from Y to X. In this paper, we explore the possibility of
only wielding one network for bi-directional image synthesis. In other words,
such an autonomous learning network implements a self-inverse function. A
self-inverse network shares several distinct advantages: only one network
instead of two, better generalization and more restricted parameter space. Most
importantly, a self-inverse function guarantees a one-to-one mapping, a
property that cannot be guaranteed by earlier approaches that are not
self-inverse. The experiments on three datasets show that, compared with the
baseline approaches that use two separate models for the image synthesis along
two directions, our self-inverse network achieves better synthesis results in
terms of standard metrics. Finally, our sensitivity analysis confirms the
feasibility of learning a self-inverse function for the bidirectional image
translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04105</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04105</id><created>2019-09-09</created><authors><author><keyname>Song</keyname><forenames>Junnan</forenames></author><author><keyname>Mittal</keyname><forenames>Khushboo</forenames></author><author><keyname>Gupta</keyname><forenames>Shalabh</forenames></author><author><keyname>Wettergren</keyname><forenames>Thomas A.</forenames></author></authors><title>Rapid Motion-Planning for Dubins Vehicles under Environmental Drifts</title><categories>cs.RO cs.SY eess.SY</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a rapid (i.e., (near) real time) solution to the
minimum-time motion planning problem for Dubins vehicles under environmental
drifts (e.g., wind or ocean currents). Real-time solutions are essential in
time-critical situations (e.g., replanning under dynamically changing
environments or tracking fast moving targets). Typically, Dubins problem
requires to solve for six path types; however, due to the presence of drifts,
four of these path types require to solve the root-finding problem involving
transcendental functions. Thus, the existing solution methods result in high
computation times and their applicability for real-time applications is
limited. In this regard, in order to obtain a (near) real-time solution, this
paper proposes a novel approach where only a subset of two Dubins path types
(i.e., LSL and RSR) are used which have direct analytical solutions in the
presence of drifts. We show that by extending the feasible range of circular
arcs in these path types: 1) full reachability of any goal pose is guaranteed,
and 2) even better paths can be produced with lower time costs. Theoretical
findings are comparatively evaluated by extensive Monte-Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04111</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04111</id><created>2019-09-09</created><authors><author><keyname>Zhang</keyname><forenames>Daniel</forenames></author><author><keyname>Zhang</keyname><forenames>Yang</forenames></author><author><keyname>Wang</keyname><forenames>Dong</forenames></author></authors><title>Poster Abstract: A Dynamic Data-Driven Prediction Model for Sparse
  Collaborative Sensing Applications</title><categories>eess.SP</categories><comments>Accepted to INFOCOM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in collaborative sensing lies in providing an accurate
prediction of critical events (e.g., hazardous environmental condition, urban
abnormalities, economic trends). However, due to the resource constraints,
collaborative sensing applications normally only collect measurements from a
subset of physical locations and predict the measurements for the rest of
locations. This problem is referred to as sparse collaborative sensing
prediction. In this poster, we present a novel closed-loop prediction model by
leveraging topic modeling and online learning techniques. We evaluate our
scheme using a real-world collaborative sensing dataset. The initial results
show that our proposed scheme outperforms the state-of-the-art baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04139</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04139</id><created>2019-09-09</created><authors><author><keyname>Barkakati</keyname><forenames>Meghna</forenames></author><author><keyname>Biswas</keyname><forenames>Reetam Sen</forenames></author><author><keyname>Pal</keyname><forenames>Anamitra</forenames></author></authors><title>A PMU Based Islanding Detection Scheme Immune to Additive
  Instrumentation Channel Errors</title><categories>eess.SY cs.SY</categories><comments>Accepted in the proceedings of the 51st North American Power
  Symposium (NAPS), Wichita, USA, Oct. 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Traditional synchrophasor measurement-based islanding detection techniques
have primarily relied on voltage angle measurements and/or their derivatives
for successfully detecting islands. However, relatively high instrumentation
channel errors associated with phasor measurement unit (PMU) data, can
significantly degrade islanding detection accuracies. In this paper, a new
islanding detection scheme employing cumulative sum of change in voltage phase
angle difference (CUSPAD) is proposed, which is immune to additive
instrumentation channel errors in the PMU measurements. The robustness of the
proposed islanding detection algorithm is established through application to an
18-bus test system and the IEEE 118-bus system having different wind energy
penetration levels. Comparative analysis of the accuracies of the proposed
approach (CUSPAD) and the conventional angle difference (AD) approach prove the
former's superior performance when additive instrumentation channel errors are
present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04141</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04141</id><created>2019-09-09</created><authors><author><keyname>Xu</keyname><forenames>Lin</forenames></author><author><keyname>Xu</keyname><forenames>Cheng</forenames></author><author><keyname>Tong</keyname><forenames>Yi</forenames></author><author><keyname>Su</keyname><forenames>Yu Chun</forenames></author></authors><title>Detection and Classification of Breast Cancer Metastates Based on U-Net</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents U-net based breast cancer metastases detection and
classification in lymph nodes, as well as patient-level classification based on
metastases detection. The whole pipeline can be divided into five steps:
preprocessing and data argumentation, patch-based segmentation, post
processing, slide-level classification, and patient-level classification. In
order to reduce overfitting and speedup convergence, we applied batch
normalization and dropout into U-Net. The final Kappa score reaches 0.902 on
training data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04142</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04142</id><created>2019-09-09</created><authors><author><keyname>Quan</keyname><forenames>Justin</forenames></author><author><keyname>Xu</keyname><forenames>Lin</forenames></author><author><keyname>Xu</keyname><forenames>Rene</forenames></author><author><keyname>Tong</keyname><forenames>Tyrael</forenames></author><author><keyname>Su</keyname><forenames>Jean</forenames></author></authors><title>DaTscan SPECT Image Classification for Parkinson's Disease</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parkinson's Disease (PD) is a neurodegenerative disease that currently does
not have a cure. In order to facilitate disease management and reduce the speed
of symptom progression, early diagnosis is essential. The current clinical,
diagnostic approach is to have radiologists perform human visual analysis of
the degeneration of dopaminergic neurons in the substantia nigra region of the
brain. Clinically, dopamine levels are monitored through observing dopamine
transporter (DaT) activity. One method of DaT activity analysis is performed
with the injection of an Iodine-123 fluoropropyl (123I-FP-CIT) tracer combined
with single photon emission computerized tomography (SPECT) imaging. The tracer
illustrates the region of interest in the resulting DaTscan SPECT images. Human
visual analysis is slow and vulnerable to subjectivity between radiologists, so
the goal was to develop an introductory implementation of a deep convolutional
neural network that can objectively and accurately classify DaTscan SPECT
images as Parkinson's Disease or normal. This study illustrates the approach of
using a deep convolutional neural network and evaluates its performance on
DaTscan SPECT image classification. The data used in this study was obtained
through a database provided by the Parkinson's Progression Markers Initiative
(PPMI). The deep neural network in this study utilizes the InceptionV3
architecture, 1st runner up in the 2015 ImageNet Large Scale Visual Recognition
Competition (ILSVRC), as a base model. A custom, binary classifier block was
added on top of this base. In order to account for the small dataset size, a
ten fold cross validation was implemented to evaluate the model's performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04143</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04143</id><created>2019-09-09</created><updated>2019-09-11</updated><authors><author><keyname>Hosseini</keyname><forenames>Nozhan</forenames></author><author><keyname>Matolak</keyname><forenames>David W.</forenames></author></authors><title>Chirp Spread Spectrum Signaling for Future Air-Ground Communications</title><categories>eess.SP</categories><comments>This paper has been accepted for publication in IEEE milcom
  conference November 2019. N. Hosseini and D. W. Matolak, &quot; Chirp Spread
  Spectrum Signaling for Future Air-Ground Communications,&quot; MILCOM 2019 - 2019
  IEEE Military Communications Conference (MILCOM), Norfolk, VA, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the use of chirp spread spectrum signaling over
air-ground channels. This includes evaluation of not only the traditional
linear chirp, but also of a new chirp signal format we have devised for
multiple access applications. This new format is more practical than prior
multi-user chirp systems in the literature, because we allow for imperfect
synchronism. Specifically we evaluate multi-user chirp signaling over
air-ground channels in a quasi-synchronous condition. The air-ground channels
we employ are models based upon an extensive NASA measurement campaign. We show
that our new signaling scheme outperforms the classic linear chirp in these
air-ground settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04145</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04145</id><created>2019-09-09</created><authors><author><keyname>Nath</keyname><forenames>Anubhav</forenames></author><author><keyname>Biswas</keyname><forenames>Reetam Sen</forenames></author><author><keyname>Pal</keyname><forenames>Anamitra</forenames></author></authors><title>Application of Machine Learning for Online Dynamic Security Assessment
  in Presence of System Variability and Additive Instrumentation Errors</title><categories>eess.SY cs.SY</categories><comments>Accepted in the proceedings of the 51st North American Power
  Symposium (NAPS), Wichita, USA, Oct. 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Large-scale blackouts that have occurred in the past few decades have
necessitated the need to do extensive research in the field of grid security
assessment. With the aid of synchrophasor technology, which uses phasor
measurement unit (PMU) data, dynamic security assessment (DSA) can be performed
online. However, existing applications of DSA are challenged by variability in
system conditions and unaccounted for measurement errors. To overcome these
challenges, this research develops a DSA scheme to provide security prediction
in real-time for load profiles of different seasons in presence of realistic
errors in the PMU measurements. The major contributions of this paper are: (1)
develop a DSA scheme based on PMU data, (2) consider seasonal load profiles,
(3) account for varying penetrations of renewable generation, and (4) compare
the accuracy of different machine learning (ML) algorithms for DSA with and
without erroneous measurements. The performance of this approach is tested on
the IEEE-118 bus system. Comparative analysis of the accuracies of the ML
algorithms under different operating scenarios highlights the importance of
considering realistic errors and variability in system conditions while
creating a DSA scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04147</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04147</id><created>2019-08-25</created><authors><author><keyname>Moan</keyname><forenames>Steven Le</forenames></author><author><keyname>Pedersen</keyname><forenames>Marius</forenames></author></authors><title>A Three-Feature Model to Predict Colour Change Blindness</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Change blindness is a striking shortcoming of our visual system which is
exploited in the popular &quot;Spot the difference&quot; game. It makes us unable to
notice large visual changes happening right before our eyes and illustrates the
fact that we see much less than we think we do. We introduce a fully automated
model to predict colour change blindness in cartoon images based on two
low-level image features and observer experience. Using linear regression with
only three parameters, the predictions of the proposed model correlate
significantly with measured detection times. We also demonstrate the efficacy
of the model to classify stimuli in terms of difficulty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04157</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04157</id><created>2019-09-09</created><authors><author><keyname>Lu</keyname><forenames>Liang</forenames></author><author><keyname>Sun</keyname><forenames>Eric</forenames></author><author><keyname>Gong</keyname><forenames>Yifan</forenames></author></authors><title>Self-Teaching Networks</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>5 pages, Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose self-teaching networks to improve the generalization capacity of
deep neural networks. The idea is to generate soft supervision labels using the
output layer for training the lower layers of the network. During the network
training, we seek an auxiliary loss that drives the lower layer to mimic the
behavior of the output layer. The connection between the two network layers
through the auxiliary loss can help the gradient flow, which works similar to
the residual networks. Furthermore, the auxiliary loss also works as a
regularizer, which improves the generalization capacity of the network. We
evaluated the self-teaching network with deep recurrent neural networks on
speech recognition tasks, where we trained the acoustic model using 30 thousand
hours of data. We tested the acoustic model using data collected from 4
scenarios. We show that the self-teaching network can achieve consistent
improvements and outperform existing methods such as label smoothing and
confidence penalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04172</identifier>
 <datestamp>2020-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04172</id><created>2019-09-09</created><updated>2020-01-04</updated><authors><author><keyname>Safi</keyname><forenames>Mostafa</forenames></author><author><keyname>Dibaji</keyname><forenames>Seyed Mehran</forenames></author></authors><title>A Filtering Approach for Resiliency of Distributed Observers against
  Smart Spoofers</title><categories>cs.CR cs.SY eess.SY</categories><comments>A revision is needed which can take a long time</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a Linear Time-Invariant (LTI) system, a network of observers is
considered where through asynchronous (with bounded delay) communications, they
all obtain the state variables of the LTI system. In such setting, a new type
of adversarial nodes might affect the observation process by impersonating the
identity of the regular nodes, which is a violation against communication
authenticity. These adversaries also inherit the capabilities of Byzantine
nodes making them more powerful threats called smart spoofers. We show how
asynchronous networks are vulnerable to smart spoofing attack. In the
estimation scheme considered in this paper, the estimated state variables are
flowed from the sets of source nodes, which can detect a portion of the state
variables each, to the other follower nodes. The regular nodes, to avoid
getting misguided by the impersonation threats, distributively filter the
extreme values received from the nodes in their neighborhood. A topological
condition based on graph strong robustness is obtained to guarantee the
convergence. Two simulation scenarios are provided to verify the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04178</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04178</id><created>2019-09-09</created><updated>2020-01-20</updated><authors><author><keyname>Jalili</keyname><forenames>Amin</forenames></author><author><keyname>Sahami</keyname><forenames>Sadid</forenames></author><author><keyname>Chi</keyname><forenames>Chong-Yung</forenames></author></authors><title>Translation Operator in Graph Signal Processing: A Generalized Approach</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of translation (shift) is straightforward in classical signal
processing, however, it is challenging on an irregular graph structure. In this
work, we present an approach to characterize the translation operator in
various signal domains. By a natural generalization from classical domains, one
can characterize an abstract representation for the graph translation operator.
Then we propose an isometric translation operator in joint time-vertex domain
consistent with the abstract form of translation operators in other domains. We
also demonstrate the connection between this notion and the Schr\&quot;{o}dinger
equation on a dynamic system which intriguingly describes the idea behind
translation on graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04188</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04188</id><created>2019-09-09</created><authors><author><keyname>Zhu</keyname><forenames>Zheyuan</forenames></author><author><keyname>Sun</keyname><forenames>Yangyang</forenames></author><author><keyname>White</keyname><forenames>Johnathon</forenames></author><author><keyname>Chang</keyname><forenames>Zenghu</forenames></author><author><keyname>Pang</keyname><forenames>Shuo</forenames></author></authors><title>Signal retrieval with measurement system knowledge using variational
  generative model</title><categories>eess.IV cs.LG eess.SP physics.comp-ph stat.ML</categories><comments>8 pages, 5 figures. Initial submission to IEEE Transactions on
  Computational Imaging</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signal retrieval from a series of indirect measurements is a common task in
many imaging, metrology and characterization platforms in science and
engineering. Because most of the indirect measurement processes are
well-described by physical models, signal retrieval can be solved with an
iterative optimization that enforces measurement consistency and prior
knowledge on the signal. These iterative processes are time-consuming and only
accommodate a linear measurement process and convex signal constraints.
Recently, neural networks have been widely adopted to supersede iterative
signal retrieval methods by approximating the inverse mapping of the
measurement model. However, networks with deterministic processes have failed
to distinguish signal ambiguities in an ill-posed measurement system, and
retrieved signals often lack consistency with the measurement. In this work we
introduce a variational generative model to capture the distribution of all
possible signals, given a particular measurement. By exploiting the known
measurement model in the variational generative framework, our signal retrieval
process resolves the ambiguity in the forward process, and learns to retrieve
signals that satisfy the measurement with high fidelity in a variety of linear
and nonlinear ill-posed systems, including ultrafast pulse retrieval, coded
aperture compressive video sensing and image retrieval from Fresnel hologram.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04198</identifier>
 <datestamp>2020-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04198</id><created>2019-09-09</created><updated>2020-02-18</updated><authors><author><keyname>Ahmed</keyname><forenames>Shimaa</forenames></author><author><keyname>Chowdhury</keyname><forenames>Amrita Roy</forenames></author><author><keyname>Fawaz</keyname><forenames>Kassem</forenames></author><author><keyname>Ramanathan</keyname><forenames>Parmesh</forenames></author></authors><title>Preech: A System for Privacy-Preserving Speech Transcription</title><categories>cs.CR cs.SD eess.AS</categories><comments>21 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New Advances in machine learning have made Automated Speech Recognition (ASR)
systems practical. ASR systems can transcribe speech data at scale.
Unfortunately, these systems pose serious privacy threats as speech is a rich
source of sensitive acoustic and textual information. Although offline ASR
eliminates the privacy risks, its transcription performance is inferior to that
of cloud-based ASR systems, especially for real-world use cases. In this paper,
we propose Pr$\epsilon\epsilon$ch, an end-to-end speech transcription system
which lies at an intermediate point in the privacy-utility spectrum of speech
transcription. It protects the acoustic features of the speakers' voices and
protects the privacy of the textual content at an improved performance relative
to offline ASR. Additionally, Pr$\epsilon\epsilon$ch provides several control
knobs to allow customizable utility-usability-privacy trade-off. It relies on
cloud-based services to transcribe a speech file after applying a series of
privacy-preserving operations on the user's side. We perform a comprehensive
evaluation of Pr$\epsilon\epsilon$ch, using diverse real-world datasets, that
demonstrates its effectiveness. Pr$\epsilon\epsilon$ch provides transcriptions
at a 2% to 32.25% (mean 17.34%) relative improvement in word error rate over
Deep Speech, while fully obfuscating the speakers' voice biometrics and
allowing only a differentially private view of the textual content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04202</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04202</id><created>2019-09-09</created><authors><author><keyname>Jin</keyname><forenames>Baihong</forenames></author><author><keyname>Tan</keyname><forenames>Yingshui</forenames></author><author><keyname>Chen</keyname><forenames>Yuxin</forenames></author><author><keyname>Sangiovanni-Vincentelli</keyname><forenames>Alberto</forenames></author></authors><title>Augmenting Monte Carlo Dropout Classification Models with Unsupervised
  Learning Tasks for Detecting and Diagnosing Out-of-Distribution Faults</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Monte Carlo dropout method has proved to be a scalable and easy-to-use
approach for estimating the uncertainty of deep neural network predictions.
This approach was recently applied to Fault Detection and Di-agnosis (FDD)
applications to improve the classification performance on incipient faults. In
this paper, we propose a novel approach of augmenting the classification model
with an additional unsupervised learning task. We justify our choice of
algorithm design via an information-theoretical analysis. Our experimental
results on three datasets from diverse application domains show that the
proposed method leads to improved fault detection and diagnosis performance,
especially on out-of-distribution examples including both incipient and unknown
faults.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04207</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04207</id><created>2019-09-09</created><authors><author><keyname>Yasarla</keyname><forenames>Rajeev</forenames></author><author><keyname>Patel</keyname><forenames>Vishal M.</forenames></author></authors><title>Confidence Measure Guided Single Image De-raining</title><categories>eess.IV cs.CV</categories><comments>TIP2019 submission. arXiv admin note: substantial text overlap with
  arXiv:1906.11129</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single image de-raining is an extremely challenging problem since the rainy
images contain rain streaks which often vary in size, direction and density.
This varying characteristic of rain streaks affect different parts of the image
differently. Previous approaches have attempted to address this problem by
leveraging some prior information to remove rain streaks from a single image.
One of the major limitations of these approaches is that they do not consider
the location information of rain drops in the image. The proposed Image
Quality-based single image Deraining using Confidence measure (QuDeC), network
addresses this issue by learning the quality or distortion level of each patch
in the rainy image, and further processes this information to learn the rain
content at different scales. In addition, we introduce a technique which guides
the network to learn the network weights based on the confidence measure about
the estimate of both quality at each location and residual rain streak
information (residual map). Extensive experiments on synthetic and real
datasets demonstrate that the proposed method achieves significant improvements
over the recent state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04223</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04223</id><created>2019-09-09</created><authors><author><keyname>Huang</keyname><forenames>Tianyao</forenames></author><author><keyname>Shlezinger</keyname><forenames>Nir</forenames></author><author><keyname>Xu</keyname><forenames>Xingyu</forenames></author><author><keyname>Liu</keyname><forenames>Yimin</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>MAJoRCom: A Dual-Function Radar Communication System Using Index
  Modulation</title><categories>eess.SP cs.IT math.IT</categories><comments>A novel dual-function radar communication (DFRC) system based on the
  carrier agile phased array radar (CAESAR) without affecting the radar
  performance. 13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dual-function radar communication (DFRC) systems implement both sensing and
communication using the same hardware. Such schemes are often more efficient in
terms of size, power, and cost, over using distinct radar and communication
systems. Since these functionalities share resources such as spectrum, power,
and antennas, DFRC methods typically entail some degradation in both radar and
communication performance. In this work we propose a DFRC scheme based on the
carrier agile phased array radar (CAESAR), which combines frequency and spatial
agility. The proposed DFRC system, referred to as multi-carrier agile joint
radar communication (MAJoRCom), exploits the inherent spatial and spectral
randomness of CAESAR to convey digital messages in the form of index
modulation. The resulting communication scheme naturally coexists with the
radar functionality, and thus does not come at the cost of reduced radar
performance. We analyze the performance of MAJoRCom, quantifying its achievable
bit rate. In addition, we develop a low complexity decoder and a codebook
design approach, which simplify the recovery of the communicated bits. Our
numerical results demonstrate that MAJoRCom is capable of achieving a bit rate
which is comparable to utilizing independent communication modules without
affecting the radar performance, and that our proposed low-complexity decoder
allows the receiver to reliably recover the transmitted symbols with an
affordable computational burden.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04259</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04259</id><created>2019-09-09</created><authors><author><keyname>Ratnam</keyname><forenames>Vishnu V.</forenames></author></authors><title>Optimal Reference Signal Design for Phase Noise Compensation in
  Multi-carrier Massive MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to IEEE Journal on Selected Topics in Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter-wave and Terahertz frequencies, while promising high throughput
and abundant spectrum, are highly susceptible to hardware non-idealities like
phase-noise, which degrade the system performance and make transceiver
implementation difficult. In this paper, a novel reference-signal (RS) aided
low-complexity and low-latency technique is proposed to mitigate phase-noise in
high-frequency multi-carrier massive multiple-input-multiple-output systems.
Unlike in existing methods, the proposed RS is transmitted in each symbol and
occupies adjacent sub-carriers separated from the data by null sub-carriers.
The receiver uses the received RS to estimate and compensate for the dominant
spectral components of the phase-noise at each symbol. While the null
sub-carriers reduce the interference between the RS and data, the frequency
compactness of the RS decouples phase-noise estimation from channel
equalization, reducing error propagation. A detailed theoretical analysis of
the technique is presented and correspondingly, throughput-optimal designs for
the RS sequence, RS bandwidth, power allocation and the number of nulled
sub-carriers and estimated spectral components, are derived. A hitherto
unexplored interplay between oscillator phase-locked loop design and the
performance of phase-noise compensation is also studied. Simulations, performed
under 3GPP compliant settings, suggest that the proposed scheme, while
achieving better performance than several existing solutions, also effectively
compensates for oscillator frequency offsets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04261</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04261</id><created>2019-09-09</created><authors><author><keyname>Xie</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Bo</forenames></author><author><keyname>Li</keyname><forenames>Cheng</forenames></author><author><keyname>Auclair</keyname><forenames>Jared</forenames></author><author><keyname>Baker</keyname><forenames>Peter</forenames></author></authors><title>Bayesian Network Based Risk and Sensitivity Analysis for Production
  Process Stability Control</title><categories>stat.ML cs.LG cs.SY eess.SY</categories><comments>42 pages, 4 figures, under review, submitted to European Journal of
  Operational Research (EJOR)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The biomanufacturing industry is growing rapidly and becoming one of the key
drivers of personalized medicine and life science. However, biopharmaceutical
production faces critical challenges, including complexity, high variability,
long lead time and rapid changes in technologies, processes, and regulatory
environment. Driven by these challenges, we explore the bio-technology domain
knowledge and propose a rigorous risk and sensitivity analysis framework for
biomanufacturing innovation. Built on the causal relationships of raw material
quality attributes, production process, and bio-drug properties in safety and
efficacy, we develop a Bayesian Network (BN) to model the complex probabilistic
interdependence between process parameters and quality attributes of raw
materials/in-process materials/drug substance. It integrates various sources of
data and leads to an interpretable probabilistic knowledge graph of the
end-to-end production process. Then, we introduce a systematic risk analysis to
assess the criticality of process parameters and quality attributes. The
complex production processes often involve many process parameters and quality
attributes impacting the product quality variability. However, the real-world
(batch) data are often limited, especially for customized and personalized
bio-drugs. We propose uncertainty quantification and sensitivity analysis to
analyze the impact of model risk. Given very limited process data, the
empirical results show that we can provide reliable and interpretable risk and
sensitivity analysis. Thus, the proposed framework can provide the science- and
risk-based guidance on the process monitoring, data collection, and process
parameters specifications to facilitate the production process learning and
stability control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04299</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04299</id><created>2019-09-10</created><updated>2019-10-27</updated><authors><author><keyname>Wang</keyname><forenames>Gang</forenames></author><author><keyname>Li</keyname><forenames>Bingcong</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>A Multistep Lyapunov Approach for Finite-Time Analysis of Biased
  Stochastic Approximation</title><categories>stat.ML cs.LG cs.SY eess.SY math.OC</categories><comments>28 Pages; fixed errors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the widespread use of temporal-difference (TD-) and Q-learning
algorithms in reinforcement learning, this paper studies a class of biased
stochastic approximation (SA) procedures under a mild &quot;ergodic-like&quot; assumption
on the underlying stochastic noise sequence. Building upon a carefully designed
multistep Lyapunov function that looks ahead to several future updates to
accommodate the stochastic perturbations (for control of the gradient bias), we
prove a general result on the convergence of the iterates, and use it to derive
non-asymptotic bounds on the mean-square error in the case of constant
stepsizes. This novel looking-ahead viewpoint renders finite-time analysis of
biased SA algorithms under a large family of stochastic perturbations possible.
For direct comparison with existing contributions, we also demonstrate these
bounds by applying them to TD- and Q-learning with linear function
approximation, under the practical Markov chain observation model. The
resultant finite-time error bound for both the TD- as well as the Q-learning
algorithms is the first of its kind, in the sense that it holds i) for the
unmodified versions (i.e., without making any modifications to the parameter
updates) using even nonlinear function approximators; as well as for Markov
chains ii) under general mixing conditions and iii) starting from any initial
distribution, at least one of which has to be violated for existing results to
be applicable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04301</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04301</id><created>2019-09-10</created><authors><author><keyname>Kawahara</keyname><forenames>Hideki</forenames></author><author><keyname>Sakakibara</keyname><forenames>Ken-Ichi</forenames></author><author><keyname>Mizumachi</keyname><forenames>Mitsunori</forenames></author><author><keyname>Banno</keyname><forenames>Hideki</forenames></author><author><keyname>Morise</keyname><forenames>Masanori</forenames></author><author><keyname>Irino</keyname><forenames>Toshio</forenames></author></authors><title>Frequency domain variant of Velvet noise and its application to acoustic
  measurements</title><categories>eess.AS cs.SD eess.SP</categories><comments>10 pages, 14 figures, APSIPA ASC 2019. arXiv admin note: text overlap
  with arXiv:1806.06812</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new family of test signals for acoustic measurements such as
impulse response, nonlinearity, and the effects of background noise. The
proposed family complements difficulties in existing families, the Swept-Sine
(SS), pseudo-random noise such as the maximum length sequence (MLS). The
proposed family uses the frequency domain variant of the Velvet noise (FVN) as
its building block. An FVN is an impulse response of an all-pass filter and
yields the unit impulse when convolved with the time-reversed version of
itself. In this respect, FVN is a member of the time-stretched pulse (TSP) in
the broadest sense. The high degree of freedom in designing an FVN opens a vast
range of applications in acoustic measurement. We introduce the following
applications and their specific procedures, among other possibilities. They are
as follows. a) Spectrum shaping adaptive to background noise. b) Simultaneous
measurement of impulse responses of multiple acoustic paths. d) Simultaneous
measurement of linear and nonlinear components of an acoustic path. e)
Automatic procedure for time axis alignment of the source and the receiver when
they are using independent clocks in acoustic impulse response measurement. We
implemented a reference measurement tool equipped with all these procedures.
The MATLAB source code and related materials are open-sourced and placed in a
GitHub repository.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04314</identifier>
 <datestamp>2020-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04314</id><created>2019-09-10</created><updated>2020-02-27</updated><authors><author><keyname>Berberich</keyname><forenames>Julian</forenames></author><author><keyname>Romer</keyname><forenames>Anne</forenames></author><author><keyname>Scherer</keyname><forenames>Carsten W.</forenames></author><author><keyname>Allg&#xf6;wer</keyname><forenames>Frank</forenames></author></authors><title>Robust data-driven state-feedback design</title><categories>eess.SY cs.SY</categories><comments>Final version, accepted for publication in Proc. American Control
  Conference (ACC), 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of designing robust state-feedback controllers for
discrete-time linear time-invariant systems, based directly on measured data.
The proposed design procedures require no model knowledge, but only a single
open-loop data trajectory, which may be affected by noise. First, a data-driven
characterization of the uncertain class of closed-loop matrices under
state-feedback is derived. By considering this parametrization in the robust
control framework, we design data-driven state-feedback gains with guarantees
on stability and performance, containing, e.g., the
$\mathcal{H}_\infty$-control problem as a special case. Further, we show how
the proposed framework can be extended to take partial model knowledge into
account. The validity of the proposed approach is illustrated via a numerical
example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04320</identifier>
 <datestamp>2020-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04320</id><created>2019-09-10</created><updated>2020-02-20</updated><authors><author><keyname>Hafiz</keyname><forenames>Faizal</forenames></author><author><keyname>Swain</keyname><forenames>Akshya</forenames></author><author><keyname>Mendes</keyname><forenames>Eduardo M. A. M.</forenames></author><author><keyname>Aguirre</keyname><forenames>Luis</forenames></author></authors><title>Multi-objective Evolutionary Approach to Grey-Box Identification of Buck
  Converter</title><categories>eess.SY cs.NE cs.SY</categories><doi>10.1109/TCSI.2020.2970759</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present study proposes a simple grey-box identification approach to model
a real DC-DC buck converter operating in continuous conduction mode. The
problem associated with the information void in the observed dynamical data,
which is often obtained over a relatively narrow input range, is alleviated by
exploiting the known static behavior of buck converter as a priori knowledge. A
simple method is developed based on the concept of term clusters to determine
the static response of the candidate models. The error in the static behavior
is then directly embedded into the multi-objective framework for structure
selection. In essence, the proposed approach casts grey-box identification
problem into a multi-objective framework to balance bias-variance dilemma of
model building while explicitly integrating a priori knowledge into the
structure selection process. The results of the investigation, considering the
case of practical buck converter, demonstrate that it is possible to identify
parsimonious models which can capture both the dynamic and static behavior of
the system over a wide input range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04324</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04324</id><created>2019-09-10</created><authors><author><keyname>Xing</keyname><forenames>Xianglei</forenames></author><author><keyname>Wu</keyname><forenames>Tianfu</forenames></author><author><keyname>Zhu</keyname><forenames>Song-Chun</forenames></author><author><keyname>Wu</keyname><forenames>Ying Nian</forenames></author></authors><title>Towards Interpretable Image Synthesis by Learning Sparsely Connected
  AND-OR Networks</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes interpretable image synthesis by learning hierarchical
AND-OR networks of sparsely connected semantically meaningful nodes. The
proposed method is based on the compositionality and interpretability of
scene-objects-parts-subparts-primitives hierarchy in image representation. A
scene has different types (i.e., OR) each of which consists of a number of
objects (i.e., AND). This can be recursively formulated across the
scene-objects-parts-subparts hierarchy and is terminated at the primitive level
(e.g., Gabor wavelets-like basis). To realize this interpretable AND-OR
hierarchy in image synthesis, the proposed method consists of two components:
(i) Each layer of the hierarchy is represented by an over-completed set of
basis functions. The basis functions are instantiated using convolution to be
translation covariant. Off-the-shelf convolutional neural architectures are
then exploited to implement the hierarchy. (ii) Sparsity-inducing constraints
are introduced in end-to-end training, which facilitate a sparsely connected
AND-OR network to emerge from initially densely connected convolutional neural
networks. A straightforward sparsity-inducing constraint is utilized, that is
to only allow the top-$k$ basis functions to be active at each layer (where $k$
is a hyperparameter). The learned basis functions are also capable of image
reconstruction to explain away input images. In experiments, the proposed
method is tested on five benchmark datasets. The results show that meaningful
and interpretable hierarchical representations are learned with better
qualities of image synthesis and reconstruction obtained than state-of-the-art
baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04335</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04335</id><created>2019-09-10</created><authors><author><keyname>Liu</keyname><forenames>Chen-Feng</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author></authors><title>Taming the Tail of Maximal Information Age in Wireless Industrial
  Networks</title><categories>cs.NI eess.SP</categories><comments>Accepted in the IEEE Communications Letters with 6 pages and 5
  figures</comments><doi>10.1109/LCOMM.2019.2940965</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless industrial networks, the information of time-sensitive control
systems needs to be transmitted in an ultra-reliable and low-latency manner.
This letter studies the resource allocation problem in finite blocklength
transmission, in which the information freshness is measured as the age of
information (AoI) whose maximal AoI is characterized using extreme value theory
(EVT). The considered system design is to minimize the sensors' transmit power
and transmission blocklength subject to constraints on the maximal AoI's tail
behavior. The studied problem is solved using Lyapunov stochastic optimization,
and a dynamic reliability and age-aware policy for resource allocation and
status updates is proposed. Simulation results validate the effectiveness of
using EVT to characterize the maximal AoI. It is shown that sensors need to
send larger-size data with longer transmission blocklength at lower transmit
power. Moreover, the maximal AoI's tail decays faster at the expense of higher
average information age.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04336</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04336</id><created>2019-09-10</created><authors><author><keyname>Lou</keyname><forenames>Hanqiong</forenames></author><author><keyname>Ge</keyname><forenames>Xiaohu</forenames></author><author><keyname>Li</keyname><forenames>Qiang</forenames></author></authors><title>The New Purity and Capacity Models for the OAM-mmWave Communication
  Systems under Atmospheric Turbulence</title><categories>eess.SP cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The orbital angular momentum (OAM) wireless communication technology is
widely studied in recent literatures. But the atmospheric turbulence is rarely
considered in analyzing the capacity of OAM-based millimeter wave (OAM-mmWave)
communication systems. The OAM-mmWave propagated in the atmosphere environments
is usually interfered by the atmospheric turbulence, resulting in the crosstalk
among OAM channels,capacity degradation, etc. By taking into account the
atmospheric turbulence effect, this paper proposes a new purity model and a new
capacity model for the OAM-mmWave communication systems. Simulation results
indicate that the OAM-mmWave propagation in the atmosphere environments is
evidently interfered by atmospheric turbulence, where the capacity of the
OAMmmWave communication systems decreases with the increase of the transmission
frequency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04350</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04350</id><created>2019-09-10</created><authors><author><keyname>Ndjiongue</keyname><forenames>Alain R.</forenames></author><author><keyname>Ngatched</keyname><forenames>Telex M. N.</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Armada</keyname><forenames>Ana G.</forenames></author></authors><title>VLC-Based Networking: Feasibility and Challenges</title><categories>eess.SP cs.NI</categories><comments>12 pages, 4 figures, 2 tables, IEEE Networking Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible-light communication (VLC) has emerged as a prominent technology to
address the radio spectrum shortage. It is characterized by the unlicensed and
unexploited high bandwidth, and provides the system with cost-effective
advantages because of the dual-use of light bulbs for illumination and
communication and the low complexity design. It is considered to be utilized in
various telecommunication systems, including 5G, and represents the key
technology for light-fidelity. To this end, VLC has to be integrated into the
existing telecommunication networks. Therefore, its analysis as a network
technology is momentous. In this article, we consider the feasibility of using
VLC as a network technology and discuss the challenges related to the
implementation of a VLC-based network, as well as the integration of VLC into
existing conventional networks and its inclusion in standards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04355</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04355</id><created>2019-09-10</created><authors><author><keyname>Wang</keyname><forenames>Zijian</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author><author><keyname>Ashraf</keyname><forenames>Mateen</forenames></author><author><keyname>Mou</keyname><forenames>Yuting</forenames></author><author><keyname>Janatian</keyname><forenames>Nafiseh</forenames></author></authors><title>Minimization of Sum Inverse Energy Efficiency for Multiple Base Station
  Systems</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sum inverse energy efficiency (SIEE) minimization problem is solved.
Compared with conventional sum energy efficiency (EE) maximization problems,
minimizing SIEE achieves a better fairness. The paper begins by proposing a
framework for solving sum-fraction minimization (SFMin) problems, then uses a
novel transform to solve the SIEE minimization problem in a multiple base
station (BS) system. After the reformulation into a multi-convex problem, the
alternating direction method of multipliers (ADMM) is used to further simplify
the problem. Numerical results confirm the efficiency of the transform and the
fairness improvement of the SIEE minimization. Simulation results show that the
algorithm convergences fast and the ADMM method is efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04357</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04357</id><created>2019-09-10</created><authors><author><keyname>Liu</keyname><forenames>Zhedong</forenames></author><author><keyname>Kammoun</keyname><forenames>Abla</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed Slim</forenames></author></authors><title>On Robust Spectrum Sensing Using M-estimators of Covariance Matrix</title><categories>eess.SP math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the spectrum sensing in cognitive radio networks
when the impulsive noise appears. We propose a class of blind and robust
detectors using M-estimators in eigenvalue based spectrum sensing method. The
conventional eigenvalue based method uses statistics derived from the
eigenvalues of sample covariance matrix(SCM) as testing statistics, which are
inefficient and unstable in the impulsive noise environment. Instead of SCM, we
can use M-estimators, which have good performance under both impulsive and
non-impulsive noise. Among those M-estimators, We recommend the Tyler's
M-estimator instead, which requires no knowledge of noise distribution and have
the same probability of false alarm under different complex elliptically
symmetric distributions. In addition, it performs better than the detector
using sample covariance matrix when the noise is highly impulsive. It should be
emphasized that this detector does not require knowledge of noise power which
is required by the energy detection based methods. Simulations show that it
performs better than conventional detector using sample covariance matrix in a
highly impulsive noise environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04390</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04390</id><created>2019-09-10</created><authors><author><keyname>Frid</keyname><forenames>Alex</forenames></author><author><keyname>Manevitz</keyname><forenames>Larry M.</forenames></author><author><keyname>Nawa</keyname><forenames>Norberto Eiji</forenames></author></authors><title>Classifying the Valence of Autobiographical Memories from fMRI Data</title><categories>cs.LG eess.IV q-bio.NC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that fMRI analysis using machine learning tools are sufficient to
distinguish valence (i.e., positive or negative) of freely retrieved
autobiographical memories in a cross-participant setting. Our methodology uses
feature selection (ReliefF) in combination with boosting methods, both applied
directly to data represented in voxel space. In previous work using the same
data set, Nawa and Ando showed that whole-brain based classification could
achieve above-chance classification accuracy only when both training and
testing data came from the same individual. In a cross-participant setting,
classification results were not statistically significant. Additionally, on
average the classification accuracy obtained when using ReliefF is
substantially higher than previous results - 81% for the within-participant
classification, and 62% for the cross-participant classification. Furthermore,
since features are defined in voxel space, it is possible to show brain maps
indicating the regions of that are most relevant in determining the results of
the classification. Interestingly, the voxels that were selected using the
proposed computational pipeline seem to be consistent with current
neurophysiological theories regarding the brain regions actively involved in
autobiographical memory processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04391</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04391</id><created>2019-09-10</created><updated>2019-12-16</updated><authors><author><keyname>Kim</keyname><forenames>Soo Ye</forenames></author><author><keyname>Oh</keyname><forenames>Jihyong</forenames></author><author><keyname>Kim</keyname><forenames>Munchurl</forenames></author></authors><title>JSI-GAN: GAN-Based Joint Super-Resolution and Inverse Tone-Mapping with
  Pixel-Wise Task-Specific Filters for UHD HDR Video</title><categories>eess.IV cs.CV</categories><comments>The first two authors contributed equally to this work. Accepted at
  AAAI 2020. (Camera-ready version)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Joint learning of super-resolution (SR) and inverse tone-mapping (ITM) has
been explored recently, to convert legacy low resolution (LR) standard dynamic
range (SDR) videos to high resolution (HR) high dynamic range (HDR) videos for
the growing need of UHD HDR TV/broadcasting applications. However, previous
CNN-based methods directly reconstruct the HR HDR frames from LR SDR frames,
and are only trained with a simple L2 loss. In this paper, we take a
divide-and-conquer approach in designing a novel GAN-based joint SR-ITM
network, called JSI-GAN, which is composed of three task-specific subnets: an
image reconstruction subnet, a detail restoration (DR) subnet and a local
contrast enhancement (LCE) subnet. We delicately design these subnets so that
they are appropriately trained for the intended purpose, learning a pair of
pixel-wise 1D separable filters via the DR subnet for detail restoration and a
pixel-wise 2D local filter by the LCE subnet for contrast enhancement.
Moreover, to train the JSI-GAN effectively, we propose a novel detail GAN loss
alongside the conventional GAN loss, which helps enhancing both local details
and contrasts to reconstruct high quality HR HDR results. When all subnets are
jointly trained well, the predicted HR HDR results of higher quality are
obtained with at least 0.41 dB gain in PSNR over those generated by the
previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04406</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04406</id><created>2019-09-10</created><authors><author><keyname>Menon</keyname><forenames>Vishnu</forenames></author><author><keyname>M</keyname><forenames>Gokularam</forenames></author><author><keyname>Kalyani</keyname><forenames>Sheetal</forenames></author></authors><title>Subspace clustering without knowing the number of clusters: A parameter
  free approach</title><categories>stat.ML cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Subspace clustering, the task of clustering high dimensional data when the
data points come from a union of subspaces is one of the fundamental tasks in
unsupervised machine learning. Most of the existing algorithms for this task
involves supplying prior information in form of a parameter, like the number of
clusters, to the algorithm. In this work, a parameter free method for subspace
clustering is proposed, where the data points are clustered on the basis of the
difference in statistical distribution of the angles made by the data points
within a subspace and those by points belonging to different subspaces. Given
an initial coarse clustering, the proposed algorithm merges the clusters until
a true clustering is obtained. This, unlike many existing methods, does not
involve the use of an unknown parameter or tuning for one through cross
validation. Also, a parameter free method for producing a coarse initial
clustering is discussed, which makes the whole process of subspace clustering
parameter free. The comparison of algorithm performance with the existing state
of the art in synthetic and real data sets, shows the significance of the
proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04410</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04410</id><created>2019-09-10</created><authors><author><keyname>Wu</keyname><forenames>Chunxue</forenames></author><author><keyname>Ju</keyname><forenames>Bobo</forenames></author><author><keyname>Xiong</keyname><forenames>Naixue</forenames></author><author><keyname>Yang</keyname><forenames>Guisong</forenames></author><author><keyname>Wu</keyname><forenames>Yan</forenames></author><author><keyname>Yang</keyname><forenames>Hongming</forenames></author><author><keyname>Huang</keyname><forenames>Jiaying</forenames></author><author><keyname>Xu</keyname><forenames>Zhiyong</forenames></author></authors><title>U-net super-neural segmentation and similarity calculation to realize
  vegetation change assessment in satellite imagery</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vegetation is the natural linkage connecting soil, atmosphere and water. It
can represent the change of land cover to a certain extent and serve as an
indicator for global change research. Methods for measuring coverage can be
divided into two types: surface measurement and remote sensing. Because
vegetation cover has significant spatial and temporal differentiation
characteristics, remote sensing has become an important technical means to
estimate vegetation coverage. This paper firstly uses U-net to perform remote
sensing image semantic segmentation training, then uses the result of semantic
segmentation, and then uses the integral progressive method to calculate the
forestland change rate, and finally realizes automated valuation of woodland
change rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04425</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04425</id><created>2019-09-10</created><authors><author><keyname>Serra</keyname><forenames>O. M.</forenames></author><author><keyname>Martins</keyname><forenames>F. P. R.</forenames></author><author><keyname>Padovese</keyname><forenames>L. R.</forenames></author></authors><title>Automatic detection of estuarine dolphin whistles in spectrogram images</title><categories>cs.SD cs.LG eess.AS</categories><comments>10 pages; 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm for detecting tonal vocalizations from estuarine dolphin
(Sotalia guianensis) specimens without interference of a human operator is
developed. The raw audio data collected from a passive monitoring sensor in the
Canan\'eia underwater soundscape is converted to spectrogram images, containing
the desired acoustic event (whistle) as a linear pattern in the images.
Detection is a four-step method: first, ridge maps are obtained from the
spectrogram images; second, a probabilistic Hough transform algorithm is
applied to detect roughly linear ridges, which are adjusted to the true
corresponding shape of the whistles via an active contour algorithm; third,
feature vectors are built from the geometry of each detected curve; and fourth,
the detections are fed to a random forest classifier to parse out false
positives. We develop a system capable of reliably classifying roughly 97% of
the characteristic patterns detected as Sotalia guianensis whistles or random
empty detections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04438</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04438</id><created>2019-09-10</created><authors><author><keyname>Soriano--Rangel</keyname><forenames>Carlos A.</forenames></author><author><keyname>He</keyname><forenames>Wei</forenames></author><author><keyname>Mancilla--David</keyname><forenames>Fernando</forenames></author><author><keyname>Ortega</keyname><forenames>Romeo</forenames></author></authors><title>Voltage regulation in buck--boost coniverters feeding an unknown
  constant power load: an adaptive passivity-based control</title><categories>eess.SY cs.SY</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Rapid developments in power distribution systems and renewable energy have
widened the applications of dc--dc buck--boost converters in dc voltage
regulation. Applications include vehicular power systems, renewable energy
sources that generate power at a low voltage, and dc microgrids. It is noted
that the cascade--connection of converters in these applications may cause
instability due to the fact that converters acting as loads have a constant
power load (CPL) behavior. In this paper, the output voltage regulation problem
of a buck--boost converter feeding a CPL is addressed. The construction of the
feedback controller is based on the interconnection and damping assignment
control technique. Additionally, an immersion and invariance parameter
estimator is proposed to compute online the extracted load power, which is
difficult to measure in practical applications. It is ensured through the
design that the desired operating point is (locally) asymptotically stable with
a guaranteed domain of attraction. The approach is validated via computer
simulations and experimental prototyping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04442</identifier>
 <datestamp>2019-12-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04442</id><created>2019-09-10</created><updated>2019-09-26</updated><authors><author><keyname>Dar&#xe7;ot</keyname><forenames>Emeline</forenames></author><author><keyname>Yerly</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Hilbert</keyname><forenames>Tom</forenames></author><author><keyname>Colotti</keyname><forenames>Roberto</forenames></author><author><keyname>Najdenovska</keyname><forenames>Elena</forenames></author><author><keyname>Pellegrin</keyname><forenames>Maxime</forenames></author><author><keyname>Kober</keyname><forenames>Tobias</forenames></author><author><keyname>Stuber</keyname><forenames>Matthias</forenames></author><author><keyname>van Heeswijk</keyname><forenames>Ruud B.</forenames></author></authors><title>Compressed Sensing with Signal Averaging for Improved Sensitivity and
  Motion Artifact Reduction in Fluorine-19 MRI</title><categories>physics.med-ph eess.IV</categories><journal-ref>Under revision at NMR in Biomedicine 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluorine-19 (19F) MRI of injected perfluorocarbon emulsions (PFCs) allows for
the non-invasive quantification of inflammation and cell tracking, but suffers
from a low signal-to-noise ratio and extended scan time. To address this
limitation, we tested the hypothesis that a 19F MRI pulse sequence that
combines a specific undersampling regime with signal averaging has increased
sensitivity and robustness against motion artifacts compared to a non-averaged
fully-sampled dataset, when both are reconstructed with compressed sensing. To
this end, numerical simulations and phantom experiments were performed to
characterize the point spread function (PSF) of undersampling patterns and the
vulnerability to noise of acquisition-reconstruction strategies with paired
numbers of x signal averages and acceleration factor x (NAx-AFx). At all
investigated noise levels, the DSC of the acquisition-reconstruction strategies
strongly depended on the regularization parameters and acceleration factor. In
phantoms, motion robustness of an NA8-AF8 undersampling pattern versus NA1-AF1
was evaluated with simulated and real motions. Differences were assessed with
Dice similarity coefficients (DSC), and were consistently higher for NA8-AF8
compared to NA1-AF1 strategy, for both simulated and real cyclic motions
(P&lt;0.001). Both acquisition-reconstruction strategies were validated in vivo in
mice (n=2) injected with perfluoropolyether. These images displayed a sharper
delineation of the liver with the NA8-AF8 strategy than with the NA1-AF1
strategy. In conclusion, we validated the hypothesis that in 19F MRI, the
combination of undersampling and averaging improves both the sensitivity and
the robustness against motion artifacts compared to a non-averaged
fully-sampled dataset, when both are reconstructed with compressed sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04494</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04494</id><created>2019-09-06</created><authors><author><keyname>Zabetian</keyname><forenames>Negar</forenames></author><author><keyname>Mohammadi</keyname><forenames>Abbas</forenames></author><author><keyname>Masoudi</keyname><forenames>Meysam</forenames></author></authors><title>Energy Efficient Power Allocation for Device-to-Device Communications
  Underlaid Cellular Networks Using Stochastic Geometry</title><categories>eess.SP cs.IT math.IT</categories><comments>20 pages, 7 figures, Journal paper, accepted by ETT</comments><journal-ref>Transactions on Emerging Telecommunications Technologies, 3
  September 2019</journal-ref><doi>10.1002/ett.3768</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we study an energy efficiency maximization problem in uplink
for D2D communications underlaid with cellular networks on multiple bands.
Utilizing stochastic geometry, we derive closed-form expressions for the
average sum rate, successful transmission probability, and energy efficiency of
cellular and D2D users. Then, we formulate an optimization problem to jointly
maximize the energy efficiency of D2D and cellular users and obtain optimum
transmission power of both D2D and cellular users. In the optimization problem,
we guarantee the QoS of users by taking into account the success transmission
probability on each link. To solve the problem, first we convert the problem
into canonical convex form. Afterwards, we solve the problem in two phases,
energy efficiency maximization of devices and energy efficiency maximization of
cellular users. In the first phase, we maximize the energy efficiency of D2D
users and feed the solution to the second phase where we maximize the energy
efficiency of cellular users. Simulation results reveal that significant energy
efficiency can be attained e.g., 10% energy efficiency improvement compared to
fix transmission power in high density scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04509</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04509</id><created>2019-09-09</created><authors><author><keyname>Tridgell</keyname><forenames>Stephen</forenames></author><author><keyname>Kumm</keyname><forenames>Martin</forenames></author><author><keyname>Hardieck</keyname><forenames>Martin</forenames></author><author><keyname>Boland</keyname><forenames>David</forenames></author><author><keyname>Moss</keyname><forenames>Duncan</forenames></author><author><keyname>Zipf</keyname><forenames>Peter</forenames></author><author><keyname>Leong</keyname><forenames>Philip H. W.</forenames></author></authors><title>Unrolling Ternary Neural Networks</title><categories>eess.SP cs.LG cs.NE eess.IV</categories><comments>Accepted in TRETS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The computational complexity of neural networks for large scale or real-time
applications necessitates hardware acceleration. Most approaches assume that
the network architecture and parameters are unknown at design time, permitting
usage in a large number of applications. This paper demonstrates, for the case
where the neural network architecture and ternary weight values are known a
priori, that extremely high throughput implementations of neural network
inference can be made by customising the datapath and routing to remove
unnecessary computations and data movement. This approach is ideally suited to
FPGA implementations as a specialized implementation of a trained network
improves efficiency while still retaining generality with the reconfigurability
of an FPGA. A VGG style network with ternary weights and fixed point
activations is implemented for the CIFAR10 dataset on Amazon's AWS F1 instance.
This paper demonstrates how to remove 90% of the operations in convolutional
layers by exploiting sparsity and compile-time optimizations. The
implementation in hardware achieves 90.9 +/- 0.1% accuracy and 122 k frames per
second, with a latency of only 29 us, which is the fastest CNN inference
implementation reported so far on an FPGA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04518</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04518</id><created>2019-09-10</created><authors><author><keyname>Nguyen</keyname><forenames>Thanh</forenames></author><author><keyname>Bui</keyname><forenames>Vy</forenames></author><author><keyname>Thai</keyname><forenames>Anh</forenames></author><author><keyname>Lam</keyname><forenames>Van</forenames></author><author><keyname>Raub</keyname><forenames>Christopher B.</forenames></author><author><keyname>Chang</keyname><forenames>Lin-Ching</forenames></author><author><keyname>Nehmetallah</keyname><forenames>George</forenames></author></authors><title>Virtual organelle self-coding for fluorescence imaging via adversarial
  learning</title><categories>eess.IV cs.CV q-bio.QM</categories><comments>20 pages, 9 figures</comments><msc-class>92B20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluorescence microscopy plays a vital role in understanding the subcellular
structures of living cells. However, it requires considerable effort in sample
preparation related to chemical fixation, staining, cost, and time. To reduce
those factors, we present a virtual fluorescence staining method based on deep
neural networks (VirFluoNet) to transform fluorescence images of molecular
labels into other molecular fluorescence labels in the same field-of-view. To
achieve this goal, we develop and train a conditional generative adversarial
network (cGAN) to perform digital fluorescence imaging demonstrated on human
osteosarcoma U2OS cell fluorescence images captured under Cell Painting
staining protocol. A detailed comparative analysis is also conducted on the
performance of the cGAN network between predicting fluorescence channels based
on phase contrast or based on another fluorescence channel using human breast
cancer MDA-MB-231 cell line as a test case. In addition, we implement a deep
learning model to perform autofocusing on another human U2OS fluorescence
dataset as a preprocessing step to defocus an out-focus channel in U2OS
dataset. A quantitative index of image prediction error is introduced based on
signal pixel-wise spatial and intensity differences with ground truth to
evaluate the performance of prediction to high-complex and throughput
fluorescence. This index provides a rational way to perform image segmentation
on error signals and to understand the likelihood of mis-interpreting biology
from the predicted image. In total, these findings contribute to the utility of
deep learning image regression for fluorescence microscopy datasets of
biological cells, balanced against savings of cost, time, and experimental
effort. Furthermore, the approach introduced here holds promise for modeling
the internal relationships between organelles and biomolecules within living
cells.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04520</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04520</id><created>2019-09-09</created><authors><author><keyname>Duarte</keyname><forenames>J.</forenames></author><author><keyname>Cassin</keyname><forenames>R.</forenames></author><author><keyname>Huijts</keyname><forenames>J.</forenames></author><author><keyname>Kholodtsova</keyname><forenames>M.</forenames></author><author><keyname>Iwan</keyname><forenames>B.</forenames></author><author><keyname>Kovacev</keyname><forenames>M.</forenames></author><author><keyname>Fajardo</keyname><forenames>M.</forenames></author><author><keyname>Fortuna</keyname><forenames>F.</forenames></author><author><keyname>Delbecq</keyname><forenames>L.</forenames></author><author><keyname>Boutu</keyname><forenames>W.</forenames></author><author><keyname>Merdji</keyname><forenames>H.</forenames></author></authors><title>Computed stereo lensless X-ray imaging</title><categories>eess.IV physics.optics</categories><journal-ref>Nature Photonics 2019</journal-ref><doi>10.1038/s41566-019-0419-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to gain insights into the 3D properties of artificial or
biological systems is often critical. However, 3D structures are difficult to
retrieve at low dose and with extremely fast processing, as most techniques are
based on acquiring and computing hundreds of 2D angular projections. This is
even more challenging with ultrashort X-rays which allow realizing nanometre
scale studies and ultrafast time resolved 2D movies. Here we show that computer
stereo vision concepts can be transposed to X-rays. We demonstrate nanoscale
three-dimensional reconstruction from a single ultrafast acquisition. Two
diffraction patterns are recorded simultaneously on a single CCD camera and
after phase retrieval two stereo images are reconstructed. A 3D representation
of the sample is then computed from quantitative disparity maps with about
130x130x380nm3 voxel resolution in a snapshot of 20 femtoseconds. We extend our
demonstration to phase contrast X-ray stereo imaging and reveal hidden 3D
features of a sample. Computed phase stereo imaging will find scientific
applications at X-ray free electron lasers, synchrotrons and laser-based
sources, but also in fast industrial and medical 3D diagnostics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04542</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04542</id><created>2019-09-10</created><authors><author><keyname>Jiang</keyname><forenames>Jue</forenames></author><author><keyname>Hu</keyname><forenames>Jason</forenames></author><author><keyname>Tyagi</keyname><forenames>Neelam</forenames></author><author><keyname>Rimner</keyname><forenames>Andreas</forenames></author><author><keyname>Berry</keyname><forenames>Sean L.</forenames></author><author><keyname>Deasy</keyname><forenames>Joseph O.</forenames></author><author><keyname>Veeraraghavan</keyname><forenames>Harini</forenames></author></authors><title>Integrating cross-modality hallucinated MRI with CT to aid mediastinal
  lung tumor segmentation</title><categories>eess.IV cs.CV</categories><comments>This paper has been accepted by MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lung tumors, especially those located close to or surrounded by soft tissues
like the mediastinum, are difficult to segment due to the low soft tissue
contrast on computed tomography images. Magnetic resonance images contain
superior soft-tissue contrast information that can be leveraged if both
modalities were available for training. Therefore, we developed a
cross-modality educed learning approach where MR information that is educed
from CT is used to hallucinate MRI and improve CT segmentation. Our approach,
called cross-modality educed deep learning segmentation (CMEDL) combines CT and
pseudo MR produced from CT by aligning their features to obtain segmentation on
CT. Features computed in the last two layers of parallelly trained CT and MR
segmentation networks are aligned. We implemented this approach on U-net and
dense fully convolutional networks (dense-FCN). Our networks were trained on
unrelated cohorts from open-source the Cancer Imaging Archive CT images
(N=377), an internal archive T2-weighted MR (N=81), and evaluated using
separate validation (N=304) and testing (N=333) CT-delineated tumors. Our
approach using both networks were significantly more accurate (U-net $P
&lt;0.001$; denseFCN $P &lt;0.001$) than CT-only networks and achieved an accuracy
(Dice similarity coefficient) of 0.71$\pm$0.15 (U-net), 0.74$\pm$0.12
(denseFCN) on validation and 0.72$\pm$0.14 (U-net), 0.73$\pm$0.12 (denseFCN) on
the testing sets. Our novel approach demonstrated that educing cross-modality
information through learned priors enhances CT segmentation performance
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04551</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04551</id><created>2019-09-08</created><authors><author><keyname>Park</keyname><forenames>Hyunbin</forenames></author><author><keyname>Kim</keyname><forenames>Dohyun</forenames></author><author><keyname>Kim</keyname><forenames>Shiho</forenames></author></authors><title>TMA: Tera-MACs/W Neural Hardware Inference Accelerator with a
  Multiplier-less Massive Parallel Processor</title><categories>cs.DC cs.AR eess.SP</categories><comments>8 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computationally intensive Inference tasks of Deep neural networks have
enforced revolution of new accelerator architecture to reduce power consumption
as well as latency. The key figure of merit in hardware inference accelerators
is the number of multiply-and-accumulation operations per watt (MACs/W), where,
the state-of-the-arts MACs/W remains several hundreds Giga-MACs/W. We propose a
Tera-MACS/W neural hardware inference Accelerator (TMA) with 8-bit activations
and scalable integer weights less than 1-byte. The architectures main feature
is configurable neural processing element for matrix-vector operations. The
proposed neural processing element has Multiplier-less Massive Parallel
Processor to work without any multiplications, which makes it attractive for
energy efficient high-performance neural network applications. We benchmark our
systems latency, power, and performance using Alexnet trained on ImageNet.
Finally, we compared our accelerators throughput and power consumption to the
prior works. The proposed accelerator outperforms the state of the art in terms
of energy and area achieving 2.3 TMACS/W@1.0 V, 65 nm CMOS technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04572</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04572</id><created>2019-09-10</created><authors><author><keyname>Cherukuri</keyname><forenames>Venkateswararao</forenames></author><author><keyname>Guo</keyname><forenames>Tiantong</forenames></author><author><keyname>Schiff</keyname><forenames>Steve. J.</forenames></author><author><keyname>Monga</keyname><forenames>Vishal</forenames></author></authors><title>Deep MR Brain Image Super-Resolution Using Spatio-Structural Priors</title><categories>eess.IV cs.AI</categories><comments>Accepted to IEEE transactions on Image Processing</comments><doi>10.1109/TIP.2019.2942510</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High resolution Magnetic Resonance (MR) images are desired for accurate
diagnostics. In practice, image resolution is restricted by factors like
hardware and processing constraints. Recently, deep learning methods have been
shown to produce compelling state-of-the-art results for image
enhancement/super-resolution. Paying particular attention to desired
hi-resolution MR image structure, we propose a new regularized network that
exploits image priors, namely a low-rank structure and a sharpness prior to
enhance deep MR image super-resolution (SR). Our contributions are then
incorporating these priors in an analytically tractable fashion \color{black}
as well as towards a novel prior guided network architecture that accomplishes
the super-resolution task. This is particularly challenging for the low rank
prior since the rank is not a differentiable function of the image matrix(and
hence the network parameters), an issue we address by pursuing differentiable
approximations of the rank. Sharpness is emphasized by the variance of the
Laplacian which we show can be implemented by a fixed feedback layer at the
output of the network. As a key extension, we modify the fixed feedback
(Laplacian) layer by learning a new set of training data driven filters that
are optimized for enhanced sharpness. Experiments performed on publicly
available MR brain image databases and comparisons against existing
state-of-the-art methods show that the proposed prior guided network offers
significant practical gains in terms of improved SNR/image quality measures.
Because our priors are on output images, the proposed method is versatile and
can be combined with a wide variety of existing network architectures to
further enhance their performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04573</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04573</id><created>2019-09-10</created><authors><author><keyname>Taspinar</keyname><forenames>Samet</forenames></author><author><keyname>Mohanty</keyname><forenames>Manoranjan</forenames></author><author><keyname>Memon</keyname><forenames>Nasir</forenames></author></authors><title>Camera Fingerprint Extraction via Spatial Domain Averaged Frames</title><categories>cs.MM eess.IV</categories><comments>11 pages, 9 figures, submitted to IEEE Transactions on Information
  Forensics and Security journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photo Response Non-Uniformity (PRNU) based camera attribution is an effective
method to determine the source camera of visual media (an image or a video). To
apply this method, images or videos need to be obtained from a camera to create
a &quot;camera fingerprint&quot; which then can be compared against the PRNU of the query
media whose origin is under question. The fingerprint extraction process can be
time-consuming when a large number of video frames or images have to be
denoised. This may need to be done when the individual images have been
subjected to high compression or other geometric processing such as video
stabilization. This paper investigates a simple, yet effective and efficient
technique to create a camera fingerprint when so many still images need to be
denoised. The technique utilizes Spatial Domain Averaged (SDA) frames. An
SDA-frame is the arithmetic mean of multiple still images. When it is used for
fingerprint extraction, the number of denoising operations can be significantly
decreased with little or no performance loss. Experimental results show that
the proposed method can work more than 50 times faster than conventional
methods while providing similar matching results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04580</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04580</id><created>2019-09-10</created><updated>2019-10-08</updated><authors><author><keyname>Natnithikarat</keyname><forenames>Sanurak</forenames></author><author><keyname>Lamyai</keyname><forenames>Sirakorn</forenames></author><author><keyname>Leelaarporn</keyname><forenames>Pitshaporn</forenames></author><author><keyname>Kunaseth</keyname><forenames>Narin</forenames></author><author><keyname>Autthasan</keyname><forenames>Phairot</forenames></author><author><keyname>Wisutthisen</keyname><forenames>Thayakorn</forenames></author><author><keyname>Wilaiprasitporn</keyname><forenames>Theerawit</forenames></author></authors><title>Drowsiness Detection for Office-based Workload with Mouse and Keyboard
  Data</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-invasive devices involved in the detection of drowsiness generally
include infrared camera and Electroencephalography (EEG), of which sometimes
are constrained in an actual real-life scenario deployments and implementations
such as in the working office environment. This study proposes a combination
using the biometric features of keyboard and mouse movements and eye tracking
during an office-based tasks to detect and evaluate drowsiness according to the
self-report Karolinska sleepiness scale (KSS) questionnaire. Using machine
learning models, the results demonstrate a correlation between the predicted
KSS from the biometrics and the actual KSS from the user input, indicating the
feasibility of evaluating the office workers' drowsiness level of the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04588</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04588</id><created>2019-09-07</created><authors><author><keyname>Liu</keyname><forenames>Qinghui</forenames></author><author><keyname>Kampffmeyer</keyname><forenames>Michael</forenames></author><author><keyname>Jenssen</keyname><forenames>Robert</forenames></author><author><keyname>Salberg</keyname><forenames>Arnt-B&#xf8;rre</forenames></author></authors><title>Road Mapping In LiDAR Images Using A Joint-Task Dense Dilated
  Convolutions Merging Network</title><categories>cs.CV cs.LG eess.IV</categories><comments>IGARSS 2019. arXiv admin note: text overlap with arXiv:1908.11799</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  It is important, but challenging, for the forest industry to accurately map
roads which are used for timber transport by trucks. In this work, we propose a
Dense Dilated Convolutions Merging Network (DDCM-Net) to detect these roads in
lidar images. The DDCM-Net can effectively recognize multi-scale and complex
shaped roads with similar texture and colors, and also is shown to have
superior performance over existing methods. To further improve its ability to
accurately infer categories of roads, we propose the use of a joint-task
learning strategy that utilizes two auxiliary output branches, i.e, multi-class
classification and binary segmentation, joined with the main output of
full-class segmentation. This pushes the network towards learning more robust
representations that are expected to boost the ultimate performance of the main
task. In addition, we introduce an iterative-random-weighting method to
automatically weigh the joint losses for auxiliary tasks. This can avoid the
difficult and expensive process of tuning the weights of each task's loss by
hand. The experiments demonstrate that our proposed joint-task DDCM-Net can
achieve better performance with fewer parameters and higher computational
efficiency than previous state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04596</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04596</id><created>2019-09-10</created><authors><author><keyname>Agravat</keyname><forenames>Rupal</forenames></author><author><keyname>Raval</keyname><forenames>Mehul S</forenames></author></authors><title>Prediction of Overall Survival of Brain Tumor Patients</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>5 pages, IEEE TENCON 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated brain tumor segmentation plays an important role in the diagnosis
and prognosis of the patient. In addition, features from the tumorous brain
help in predicting patients overall survival. The main focus of this paper is
to segment tumor from BRATS 2018 benchmark dataset and use age, shape and
volumetric features to predict overall survival of patients. The random forest
classifier achieves overall survival accuracy of 59% on the test dataset and
67% on the dataset with resection status as gross total resection. The proposed
approach uses fewer features but achieves better accuracy than state of the art
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04606</identifier>
 <datestamp>2020-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04606</id><created>2019-09-10</created><updated>2020-02-12</updated><authors><author><keyname>Zhou</keyname><forenames>Gui</forenames></author><author><keyname>Pan</keyname><forenames>Cunhua</forenames></author><author><keyname>Ren</keyname><forenames>Hong</forenames></author><author><keyname>Wang</keyname><forenames>Kezhi</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author></authors><title>Intelligent Reflecting Surface Aided Multigroup Multicast MISO
  Communication Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>Under revision in IEEE Transactions on Signal Processing</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Intelligent reflecting surface (IRS) has recently been envisioned to offer
unprecedented massive multiple-input multiple-output (MIMO)-like gains by
deploying large-scale and low-cost passive reflection elements. By adjusting
the reflection coefficients, the IRS can change the phase shifts on the
impinging electromagnetic waves so that it can smartly reconfigure the signal
propagation environment and enhance the power of the desired received signal or
suppress the interference signal. In this paper, we consider downlink
multigroup multicast communication systems assisted by an IRS. We aim for
maximizing the sum rate of all the multicasting groups by the joint
optimization of the precoding matrix at the base station (BS) and the
reflection coefficients at the IRS under both the power and unit-modulus
constraint. To tackle this non-convex problem, we propose two efficient
algorithms under the majorization--minimization (MM) algorithm framework.
Specifically, a concave lower bound surrogate objective function of each user's
rate has been derived firstly, based on which two sets of variables can be
updated alternately by solving two corresponding second-order cone programming
(SOCP) problems. Then, in order to reduce the computational complexity, we
derive another concave lower bound function of each group's rate for each set
of variables at every iteration, and obtain the closed-form solutions under
these loose surrogate objective functions. Finally, the simulation results
demonstrate the benefits in terms of the spectral and energy efficiency of the
introduced IRS and the effectiveness in terms of the convergence and complexity
of our proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04614</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04614</id><created>2019-09-10</created><authors><author><keyname>Song</keyname><forenames>Weiwei</forenames></author><author><keyname>Li</keyname><forenames>Shutao</forenames></author><author><keyname>Benediktsson</keyname><forenames>Jon Atli</forenames></author></authors><title>Deep Hashing Learning for Visual and Semantic Retrieval of Remote
  Sensing Images</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Driven by the urgent demand for managing remote sensing big data, large-scale
remote sensing image retrieval (RSIR) attracts increasing attention in the
remote sensing field. In general, existing retrieval methods can be regarded as
visual-based retrieval approaches which search and return a set of similar
images from a database to a given query image. Although retrieval methods have
achieved great success, there is still a question that needs to be responded
to: Can we obtain the accurate semantic labels of the returned similar images
to further help analyzing and processing imagery? Inspired by the above
question, in this paper, we redefine the image retrieval problem as visual and
semantic retrieval of images. Specifically, we propose a novel deep hashing
convolutional neural network (DHCNN) to simultaneously retrieve the similar
images and classify their semantic labels in a unified framework. In more
detail, a convolutional neural network (CNN) is used to extract
high-dimensional deep features. Then, a hash layer is perfectly inserted into
the network to transfer the deep features into compact hash codes. In addition,
a fully connected layer with a softmax function is performed on hash layer to
generate class distribution. Finally, a loss function is elaborately designed
to simultaneously consider the label loss of each image and similarity loss of
pairs of images. Experimental results on two remote sensing datasets
demonstrate that the proposed method achieves the state-of-art retrieval and
classification performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04617</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04617</id><created>2019-09-10</created><authors><author><keyname>Sarkar</keyname><forenames>Tuhin</forenames></author><author><keyname>Rakhlin</keyname><forenames>Alexander</forenames></author><author><keyname>Dahleh</keyname><forenames>Munther A.</forenames></author></authors><title>Nonparametric System identification of Stochastic Switched Linear
  Systems</title><categories>eess.SY cs.SY</categories><comments>9 pages. Accepted to CDC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of learning the parameters of a mean square stable
switched linear systems(SLS) with unknown latent space dimension, or
\textit{order}, from its noisy input--output data. In particular, we focus on
learning a good lower order approximation of the underlying model allowed by
finite data. This is achieved by constructing Hankel-like matrices from data
and obtaining suitable approximations via SVD truncation where the threshold
for SVD truncation is purely data dependent. By exploiting tools from theory of
model reduction for SLS, we find that the system parameter estimates are close
to a balanced truncated realization of the underlying system with high
probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04694</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04694</id><created>2019-09-10</created><updated>2019-12-14</updated><authors><author><keyname>Fridovich-Keil</keyname><forenames>David</forenames></author><author><keyname>Ratner</keyname><forenames>Ellis</forenames></author><author><keyname>Peters</keyname><forenames>Lasse</forenames></author><author><keyname>Dragan</keyname><forenames>Anca D.</forenames></author><author><keyname>Tomlin</keyname><forenames>Claire J.</forenames></author></authors><title>Efficient Iterative Linear-Quadratic Approximations for Nonlinear
  Multi-Player General-Sum Differential Games</title><categories>eess.SY cs.RO cs.SY</categories><comments>8 pages, 4 figures, under review at Robotics and Automation Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many problems in robotics involve multiple decision making agents. To operate
efficiently in such settings, a robot must reason about the impact of its
decisions on the behavior of other agents. Differential games offer an
expressive theoretical framework for formulating these types of multi-agent
problems. Unfortunately, most numerical solution techniques scale poorly with
state dimension and are rarely used in real-time applications. For this reason,
it is common to predict the future decisions of other agents and solve the
resulting decoupled, i.e., single-agent, optimal control problem. This
decoupling neglects the underlying interactive nature of the problem; however,
efficient solution techniques do exist for broad classes of optimal control
problems. We take inspiration from one such technique, the iterative
linear-quadratic regulator (ILQR), which solves repeated approximations with
linear dynamics and quadratic costs. Similarly, our proposed algorithm solves
repeated linear-quadratic games. We experimentally benchmark our algorithm in
several examples with a variety of initial conditions and show that the
resulting strategies exhibit complex interactive behavior. Our results indicate
that our algorithm converges reliably and runs in real-time. In a three-player,
14-state simulated intersection problem, our algorithm initially converges in
&lt;0.25s. Receding horizon invocations converge in &lt;50 ms in a hardware
collision-avoidance test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04737</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04737</id><created>2019-09-10</created><authors><author><keyname>Pereira</keyname><forenames>F. Estev&#xe3;o S.</forenames></author><author><keyname>Nossek</keyname><forenames>Josef A.</forenames></author><author><keyname>Cavalcanti</keyname><forenames>F. Rodrigo P.</forenames></author></authors><title>Decoupling and Matching Strategies for Compact Antenna Arrays</title><categories>eess.SP</categories><comments>Submitted for publication in an IEEE Acess</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Antenna arrays have been used in various applications and have become an
important tool to achieve high spectral efficiency in wireless communications.
Its use brings to the communications system an increase in performance in terms
of capacity and reliability. Recently one of the main communications
architectures that makes use of antenna arrays is the Multiple-Input
Multiple-Output (MIMO) technology. MIMO technology has been applied in antenna
arrays composed of elements in the order of tens to hundreds. In this way, it
is necessary to use the structure of compact antennas that offer all the
necessary robustness to the applied project. In this context, it is important
to revisit the concepts of mutual coupling and impedance matching among antenna
elements in an array. This paper proposes and evaluates three strategies of
joint decoupling and impedance matching networks(DMN) for antenna arrays. The
first method called DMN with Lumped Elements (DMN-LE) performs the decoupling
and impedance matching steps with capacitors and inductors. The second method
is called the Ring Hybrid (DMN-RH). It is utilizes a microstrip line in the
ring form. With this approach is achieved first the decoupling followed by
impedance matching steps. The third method is called Networkless Decoupling and
Matching (NDM). It brings a concept of decoupling without the presence of a
network itself. A comparison of the methods is performed both analytically and
via computer simulations. We conclude that the third method, networkless one,
is an interesting new alternative approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04755</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04755</id><created>2019-09-09</created><authors><author><keyname>Pinel</keyname><forenames>Dimitri</forenames></author><author><keyname>Bjarghov</keyname><forenames>Sigurd</forenames></author><author><keyname>Korp&#xe5;s</keyname><forenames>Magnus</forenames></author></authors><title>Impact of Grid Tariffs Design on the Zero Emission Neighborhoods Energy
  System Investments</title><categories>eess.SP cs.SY eess.SY math.OC</categories><comments>Presented at IEEE Powertech 2019 in Milano, 6 pages</comments><journal-ref>2019 IEEE Milan PowerTech, Milan, Italy, 2019, pp. 1-6</journal-ref><doi>10.1109/PTC.2019.8810942</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the relationship between grid tariffs and investment
in Zero Emission Neighborhoods (ZEN) energy system, and how the grid exchanges
are affected. Different grid tariffs (energy based, time of use (ToU),
subscribed capacity and dynamic) are implemented in an optimization model that
minimizes the cost of investing and operating a ZEN during its lifetime. The
analysis is conducted in two cases: non-constrained exports and exports limited
to 100kWh/h. The results suggest that in the case with no limit on export, the
grid tariff has little influence, but ToU is economically advantageous for both
the ZEN and the DSO. When exports are limited, the subscribed capacity scheme
allows to maintain DSO revenue, while the others cut them by half. This tariff
also offers the lowest maximum peak and a good duration curve. The dynamic
tariff creates new potentially problematic peak imports despite its benefits in
other peak hours.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04760</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04760</id><created>2019-09-10</created><authors><author><keyname>Pandey</keyname><forenames>Venktesh</forenames></author><author><keyname>Wang</keyname><forenames>Evana</forenames></author><author><keyname>Boyles</keyname><forenames>Stephen D.</forenames></author></authors><title>Deep Reinforcement Learning Algorithm for Dynamic Pricing of Express
  Lanes with Multiple Access Locations</title><categories>eess.SY cs.AI cs.LG cs.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article develops a deep reinforcement learning (Deep-RL) framework for
dynamic pricing on managed lanes with multiple access locations and
heterogeneity in travelers' value of time, origin, and destination. This
framework relaxes assumptions in the literature by considering multiple origins
and destinations, multiple access locations to the managed lane, en route
diversion of travelers, partial observability of the sensor readings, and
stochastic demand and observations. The problem is formulated as a partially
observable Markov decision process (POMDP) and policy gradient methods are used
to determine tolls as a function of real-time observations. Tolls are modeled
as continuous and stochastic variables, and are determined using a feedforward
neural network. The method is compared against a feedback control method used
for dynamic pricing. We show that Deep-RL is effective in learning toll
policies for maximizing revenue, minimizing total system travel time, and other
joint weighted objectives, when tested on real-world transportation networks.
The Deep-RL toll policies outperform the feedback control heuristic for the
revenue maximization objective by generating revenues up to 9.5% higher than
the heuristic and for the objective minimizing total system travel time (TSTT)
by generating TSTT up to 10.4% lower than the heuristic. We also propose reward
shaping methods for the POMDP to overcome the undesired behavior of toll
policies, like the jam-and-harvest behavior of revenue-maximizing policies.
Additionally, we test transferability of the algorithm trained on one set of
inputs for new input distributions and offer recommendations on real-time
implementations of Deep-RL algorithms. The source code for our experiments is
available online at https://github.com/venktesh22/ExpressLanes_Deep-RL
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04763</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04763</id><created>2019-09-10</created><authors><author><keyname>Azim</keyname><forenames>M Imran</forenames></author><author><keyname>Pourmousavi</keyname><forenames>S. A.</forenames></author><author><keyname>Tushar</keyname><forenames>Wayes</forenames></author><author><keyname>Saha</keyname><forenames>Tapan K.</forenames></author></authors><title>Feasibility Study of Financial P2P Energy Trading in a Grid-tied Power
  Network</title><categories>eess.SY cs.SY</categories><comments>Conference, 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the applicability of peer-to-peer (P2P) energy trading in
a grid-tied network. The main objectives are to understand the impact of the
financial P2P energy trading on the network operation, and thus demonstrate the
importance of taking various issues related to power network into account while
designing a practical P2P trading scheme. To do so, a simple mechanism is
developed for energy trading among prosumers without considering any network
constraints, as done by many existing studies. Once the trading parameters,
such as the energy traded by each prosumer in the P2P market and the price per
unit of energy are determined, the developed scheme is tested on a low-voltage
(LV) network model to check its feasibility of deployment in a real P2P
network. It is shown that although the considered trading scheme is
economically beneficial to the participating prosumers compared to the existing
incentive mechanisms (such as feed-in-tariff), it could be unfit for real
deployment due to violating bus voltage limits during multiple P2P trading
executed simultaneously. Further, the grid operator may experience financial
losses for compensating the losses during P2P transactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04776</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04776</id><created>2019-09-10</created><authors><author><keyname>Chinen</keyname><forenames>Michael</forenames></author><author><keyname>Kleijn</keyname><forenames>W. Bastiaan</forenames></author><author><keyname>Lim</keyname><forenames>Felicia S. C.</forenames></author><author><keyname>Skoglund</keyname><forenames>Jan</forenames></author></authors><title>Generative Speech Enhancement Based on Cloned Networks</title><categories>eess.AS cs.SD</categories><comments>Accepted WASPAA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose to implement speech enhancement by the regeneration of clean
speech from a salient representation extracted from the noisy signal. The
network that extracts salient features is trained using a set of weight-sharing
clones of the extractor network. The clones receive mel-frequency spectra of
different noisy versions of the same speech signal as input. By encouraging the
outputs of the clones to be similar for these different input signals, we train
a feature extractor network that is robust to noise. At inference, the salient
features form the input to a WaveNet network that generates a natural and clean
speech signal with the same attributes as the ground-truth clean signal. As the
signal becomes noisier, our system produces natural sounding errors that stay
on the speech manifold, in place of traditional artifacts found in other
systems. Our experiments confirm that our generative enhancement system
provides state-of-the-art enhancement performance within the generative class
of enhancers according to a MUSHRA-like test. The clones based system matches
or outperforms the other systems at each input signal-to-noise (SNR) range with
statistical significance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04779</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04779</id><created>2019-09-10</created><authors><author><keyname>Rothberg</keyname><forenames>Eitan</forenames></author><author><keyname>Chen</keyname><forenames>Tingting</forenames></author><author><keyname>Jie</keyname><forenames>Luo</forenames></author><author><keyname>Ji</keyname><forenames>Hao</forenames></author></authors><title>Localized Adversarial Training for Increased Accuracy and Robustness in
  Image Classification</title><categories>cs.LG cs.CR cs.CV eess.IV stat.ML</categories><comments>4 pages (excluding references). Presented at AdvML: 1st Workshop on
  Adversarial Learning Methods for Machine Learning and Data Mining at KDD '19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's state-of-the-art image classifiers fail to correctly classify
carefully manipulated adversarial images. In this work, we develop a new,
localized adversarial attack that generates adversarial examples by
imperceptibly altering the backgrounds of normal images. We first use this
attack to highlight the unnecessary sensitivity of neural networks to changes
in the background of an image, then use it as part of a new training technique:
localized adversarial training. By including locally adversarial images in the
training set, we are able to create a classifier that suffers less loss than a
non-adversarially trained counterpart model on both natural and adversarial
inputs. The evaluation of our localized adversarial training algorithm on MNIST
and CIFAR-10 datasets shows decreased accuracy loss on natural images, and
increased robustness against adversarial inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04797</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04797</id><created>2019-09-10</created><updated>2019-10-08</updated><authors><author><keyname>Dey</keyname><forenames>Raunak</forenames></author><author><keyname>Hong</keyname><forenames>Yi</forenames></author></authors><title>Hybrid Cascaded Neural Network for Liver Lesion Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic liver lesion segmentation is a challenging task while having a
significant impact on assisting medical professionals in the designing of
effective treatment and planning proper care. In this paper we propose a
cascaded system that combines both 2D and 3D convolutional neural networks to
effectively segment hepatic lesions. Our 2D network operates on a slice by
slice basis to segment the liver and larger tumors, while we use a 3D network
to detect small lesions that are often missed in a 2D segmentation design. We
employ this algorithm on the LiTS challenge obtaining a Dice score per case of
68.1%, which performs the best among all non pre-trained models and the second
best among published methods. We also perform two-fold cross-validation to
reveal the over- and under-segmentation issues in the LiTS annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04802</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04802</id><created>2019-09-10</created><authors><author><keyname>Choi</keyname><forenames>Yoojin</forenames></author><author><keyname>El-Khamy</keyname><forenames>Mostafa</forenames></author><author><keyname>Lee</keyname><forenames>Jungwon</forenames></author></authors><title>Variable Rate Deep Image Compression With a Conditional Autoencoder</title><categories>eess.IV cs.CV</categories><comments>ICCV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel variable-rate learned image compression
framework with a conditional autoencoder. Previous learning-based image
compression methods mostly require training separate networks for different
compression rates so they can yield compressed images of varying quality. In
contrast, we train and deploy only one variable-rate image compression network
implemented with a conditional autoencoder. We provide two rate control
parameters, i.e., the Lagrange multiplier and the quantization bin size, which
are given as conditioning variables to the network. Coarse rate adaptation to a
target is performed by changing the Lagrange multiplier, while the rate can be
further fine-tuned by adjusting the bin size used in quantizing the encoded
representation. Our experimental results show that the proposed scheme provides
a better rate-distortion trade-off than the traditional variable-rate image
compression codecs such as JPEG2000 and BPG. Our model also shows comparable
and sometimes better performance than the state-of-the-art learned image
compression models that deploy multiple networks trained for varying rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04824</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04824</id><created>2019-09-10</created><authors><author><keyname>Ahrens</keyname><forenames>Julian</forenames></author><author><keyname>Ahrens</keyname><forenames>Lia</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>A Machine Learning Method for Prediction of Multipath Channels</title><categories>eess.SP cs.LG</categories><comments>10 pages, 1 table, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a machine learning method for predicting the evolution of a
mobile communication channel based on a specific type of convolutional neural
network is developed and evaluated in a simulated multipath transmission
scenario. The simulation and channel estimation are designed to replicate
real-world scenarios and common measurements supported by reference signals in
modern cellular networks. The capability of the predictor meets the
requirements that a deployment of the developed method in a radio resource
scheduler of a base station poses. Possible applications of the method are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04834</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04834</id><created>2019-09-10</created><authors><author><keyname>Heydaribeni</keyname><forenames>Nasimeh</forenames></author><author><keyname>Anastasopoulos</keyname><forenames>Achilleas</forenames></author></authors><title>Linear Equilibria for Dynamic LQG Games with Asymmetric Information and
  Dependent Types</title><categories>econ.GN cs.SY eess.SY q-fin.EC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a non-zero-sum linear quadratic Gaussian (LQG) dynamic game with
asymmetric information. Each player observes privately a noisy version of a
(hidden) state of the world $V$, resulting in dependent private observations.
We study perfect Bayesian equilibria (PBE) for this game with equilibrium
strategies that are linear in players' private estimates of $V$. The main
difficulty arises from the fact that players need to construct estimates on
other players' estimate on $V$, which in turn would imply that an infinite
hierarchy of estimates on estimates needs to be constructed, rendering the
problem unsolvable. We show that this is not the case: each player's estimate
on other players' estimates on $V$ can be summarized into her own estimate on
$V$ and some appropriately defined public information. Based on this finding we
characterize the PBE through a backward/forward algorithm akin to dynamic
programming for the standard LQG control problem. Unlike the standard LQG
problem, however, Kalman filter covariance matrices, as well as some other
required quantities, are observation-dependent and thus cannot be evaluated
off-line through a forward recursion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04850</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04850</id><created>2019-09-11</created><updated>2019-09-12</updated><authors><author><keyname>Phan-Minh</keyname><forenames>Tung</forenames></author><author><keyname>Cai</keyname><forenames>Karena X.</forenames></author><author><keyname>Murray</keyname><forenames>Richard M.</forenames></author></authors><title>Towards Assume-Guarantee Profiles for Autonomous Vehicles</title><categories>eess.SY cs.LO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rules or specifications for autonomous vehicles are currently formulated on a
case-by-case basis, and put together in a rather ad-hoc fashion. As a step
towards eliminating this practice, we propose a systematic procedure for
generating a set of supervisory specifications for self-driving cars that are
1) associated with a distributed assume-guarantee structure and 2)
characterizable by the notion of consistency and completeness. Besides helping
autonomous vehicles make better decisions on the road, the assume-guarantee
contract structure also helps address the notion of blame when undesirable
events occur. We give several game-theoretic examples to demonstrate
applicability of our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04851</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04851</id><created>2019-09-11</created><authors><author><keyname>Cheng</keyname><forenames>Samuel</forenames></author></authors><title>Implementing distributed graph filters by elementary matrix
  decomposition</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider the implementation problem of distributed graph
filters, where each node only has access to the signals of the current and its
neighboring nodes. By using Gaussian elimination, we show that as long as the
graph is connected, we can implement any graph filter by decomposing the filter
into a product of directly implementable filters, filters that only use the
signals at the current and neighboring nodes as inputs. We have also included a
concrete example as an illustration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04856</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04856</id><created>2019-09-11</created><authors><author><keyname>Donaire</keyname><forenames>Alejandro</forenames></author><author><keyname>Romero</keyname><forenames>Jose Guadalupe</forenames></author><author><keyname>Ortega</keyname><forenames>Romeo</forenames></author></authors><title>Correction to the paper &quot;A robust IDA-PBC approach for handling
  uncertainties in underactuated mechanical systems&quot;</title><categories>math.DS cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, it is shown that the results claimed in the paper [1]---as well
as the examples presented there---are, unfortunately, incorrect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04886</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04886</id><created>2019-09-11</created><authors><author><keyname>Gu</keyname><forenames>Xiaozhe</forenames></author><author><keyname>Easwaran</keyname><forenames>Arvind</forenames></author></authors><title>Towards Safe Machine Learning for CPS: Infer Uncertainty from Training
  Data</title><categories>eess.SY cs.LG cs.SY stat.ML</categories><comments>Publication rights licensed to ACM</comments><journal-ref>In Proceedings of the 10th ACM/IEEE International Conference on
  Cyber-Physical Systems (ICCPS), 2019. ACM, New York, NY, USA, pages 249-258</journal-ref><doi>10.1145/3302509.3311038</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning (ML) techniques are increasingly applied to decision-making
and control problems in Cyber-Physical Systems among which many are
safety-critical, e.g., chemical plants, robotics, autonomous vehicles. Despite
the significant benefits brought by ML techniques, they also raise additional
safety issues because 1) most expressive and powerful ML models are not
transparent and behave as a black box and 2) the training data which plays a
crucial role in ML safety is usually incomplete. An important technique to
achieve safety for ML models is &quot;Safe Fail&quot;, i.e., a model selects a reject
option and applies the backup solution, a traditional controller or a human
operator for example, when it has low confidence in a prediction.
  Data-driven models produced by ML algorithms learn from training data, and
hence they are only as good as the examples they have learnt. As pointed in
[17], ML models work well in the &quot;training space&quot; (i.e., feature space with
sufficient training data), but they could not extrapolate beyond the training
space. As observed in many previous studies, a feature space that lacks
training data generally has a much higher error rate than the one that contains
sufficient training samples [31]. Therefore, it is essential to identify the
training space and avoid extrapolating beyond the training space. In this
paper, we propose an efficient Feature Space Partitioning Tree (FSPT) to
address this problem. Using experiments, we also show that, a strong
relationship exists between model performance and FSPT score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04888</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04888</id><created>2019-09-11</created><authors><author><keyname>Deka</keyname><forenames>Bhabesh</forenames></author></authors><title>Overcomplete Wavelets for Compressed Sensing</title><categories>eess.IV</categories><comments>9 pages Submitted to Springer LNCS proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing (CS) using overcomplete wavelet dictionaries has been a
well-investigated topic in the recent times for image and vision applications.
In this paper, different overcomplete wavelet transforms have been studied to
estimate the best transform. Performance evaluations are carried out for
different overcomplete wavelet transforms from highly undersampled and
inaccurate measurements for the recovery of images in frequency as well as
physical domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04922</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04922</id><created>2019-09-11</created><authors><author><keyname>Edalat-Javid</keyname><forenames>Mohammad</forenames></author><author><keyname>Shiri</keyname><forenames>Isaac</forenames></author><author><keyname>Hajianfar</keyname><forenames>Ghasem</forenames></author><author><keyname>Abdollahi</keyname><forenames>Hamid</forenames></author><author><keyname>Oveisi</keyname><forenames>Niki</forenames></author><author><keyname>Javadian</keyname><forenames>Mohammad</forenames></author><author><keyname>Zafarghandi</keyname><forenames>Mojtaba Shamsaei</forenames></author><author><keyname>Malek</keyname><forenames>Hadi</forenames></author><author><keyname>Bitarafan-Rajabi</keyname><forenames>Ahmad</forenames></author><author><keyname>Oveisi</keyname><forenames>Mehrdad</forenames></author></authors><title>Cardiac SPECT Radiomics Features Repeatability and Reproducibility: A
  Multi Scanner Phantom Study</title><categories>physics.med-ph eess.IV</categories><comments>32 Pages, 2 Figures, 3 Tables, 9 Supplemental Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: The aim of this study was to assess the robustness of cardiac
SPECT radiomics features against changes in imaging settings including
acquisition and reconstruction settings.
  Methods: Four scanners were used to acquire SPECT scans of a cardiac phantom
with 5mCi of 99mTc. The effects of different image acquisition and
reconstruction settings including the Number of View, View Matrix Size,
attenuation correction, image reconstruction algorithm, number of iterations,
number of subsets, type of filter, full width at half maximum (FWHM) of
Gaussian filter, Butterworth filter order, and Butterworth filter cut-off were
studied. In total 5263 different images were reconstructed. Eighty-seven
radiomic features including first, second, and high order textures were
extracted from images. To assess reproducibility and repeatability the
coefficient of variation (COV) was used for each image feature over the
different imaging settings.
  Result: IDMN and IDN features from GLCM, RP from GLRLM, ZE from GLSZM, and DE
from GLDM feature sets were the only features that were the most reproducible
(COV &lt; 5) against changes in all imaging settings. In addition, the IDMN
feature from GLCM, LALGLE, SALGLE and LGLZE from GLSZM, and SDLGLE from GLDM
feature sets were the features that were less reproducible (COV&gt;20 ) against
changes in all imaging settings. Matrix size has the greatest impact on feature
variability as most of features are not repeatable and 82.76 of them had
(COV&gt;20 ).
  Conclusion: Repeatability and reproducibility of SPECT radiomics texture
features in different imaging settings is feature-dependent, and different
image acquisitions and reconstructions have different effects on radiomics
texture features. Low COV radiomics features could be consider for further
clinical studies.
  Keywords: SPECT, Radiomics, Cardiac, Repeatability, Reproducibility
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04973</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.04973</id><created>2019-09-11</created><authors><author><keyname>Woznicki</keyname><forenames>Piotr</forenames></author><author><keyname>Przybyszewski</keyname><forenames>Przemyslaw</forenames></author><author><keyname>Kapinski</keyname><forenames>Norbert</forenames></author><author><keyname>Zielinski</keyname><forenames>Jakub</forenames></author><author><keyname>Ciszkowska-Lyson</keyname><forenames>Beata</forenames></author><author><keyname>Borucki</keyname><forenames>Bartosz A.</forenames></author><author><keyname>Trzcinski</keyname><forenames>Tomasz</forenames></author><author><keyname>Nowinski</keyname><forenames>Krzysztof S.</forenames></author></authors><title>Monitoring Achilles tendon healing progress in ultrasound imaging with
  convolutional neural networks</title><categories>eess.IV cs.CV q-bio.QM</categories><comments>Paper accepted to MICCAI'19 SUSI workshop</comments><doi>10.1007/978-3-030-32875-7_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Achilles tendon rupture is a debilitating injury, which is typically treated
with surgical repair and long-term rehabilitation. The recovery, however, is
protracted and often incomplete. Diagnosis, as well as healing progress
assessment, are largely based on ultrasound and magnetic resonance imaging. In
this paper, we propose an automatic method based on deep learning for analysis
of Achilles tendon condition and estimation of its healing progress on
ultrasound images. We develop custom convolutional neural networks for
classification and regression on healing score and feature extraction. Our
models are trained and validated on an acquired dataset of over 250.000
sagittal and over 450.000 axial ultrasound slices. The obtained estimates show
a high correlation with the assessment of expert radiologists, with respect to
all key parameters describing healing progress. We also observe that parameters
associated with i.a. intratendinous healing processes are better modeled with
sagittal slices. We prove that ultrasound imaging is quantitatively useful for
clinical assessment of Achilles tendon healing process and should be viewed as
complementary to magnetic resonance imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05007</identifier>
 <datestamp>2019-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05007</id><created>2019-09-10</created><updated>2019-10-31</updated><authors><author><keyname>Anderson</keyname><forenames>Daron</forenames></author><author><keyname>Leith</keyname><forenames>Douglas</forenames></author></authors><title>Optimality of the Subgradient Algorithm in the Stochastic Setting</title><categories>math.ST cs.DS cs.LG cs.SY eess.SY math.OC math.PR stat.ML stat.TH</categories><comments>6 figures, Corrected off-by-one errors coming from proof in Appendix
  A</comments><msc-class>68W27</msc-class><acm-class>F.2.2; G.1.6; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently Jaouad Mourtada and St\' ephane Ga\&quot;iffas showed the anytime hedge
algorithm has pseudo-regret $O(\log (d) / \Delta)$ if the cost vectors are
generated by an i.i.d sequence in the cube $[0,1]^d$. Here $d$ is the dimension
and $\Delta$ the suboptimality gap. This is remarkable because the Hedge
algorithm was designed for the antagonistic setting. We prove a similar result
for the anytime subgradient algorithm on the simplex. Given i.i.d cost vectors
in the unit ball our pseudo-regret bound is $O(1/\Delta)$ and does not depend
on the dimension of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05030</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05030</id><created>2019-09-10</created><authors><author><keyname>Koneputugodage</keyname><forenames>Chamin Hewa</forenames></author><author><keyname>Healy</keyname><forenames>Rhys</forenames></author><author><keyname>Lamont</keyname><forenames>Sean</forenames></author><author><keyname>Mallett</keyname><forenames>Ian</forenames></author><author><keyname>Brown</keyname><forenames>Matt</forenames></author><author><keyname>Walters</keyname><forenames>Matt</forenames></author><author><keyname>Attanayake</keyname><forenames>Ushini</forenames></author><author><keyname>Zhang</keyname><forenames>Libo</forenames></author><author><keyname>Dean</keyname><forenames>Roger T.</forenames></author><author><keyname>Hunter</keyname><forenames>Alexander</forenames></author><author><keyname>Gretton</keyname><forenames>Charles</forenames></author><author><keyname>Walder</keyname><forenames>Christian</forenames></author></authors><title>Computer Assisted Composition in Continuous Time</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We address the problem of combining sequence models of symbolic music with
user defined constraints. For typical models this is non-trivial as only the
conditional distribution of each symbol given the earlier symbols is available,
while the constraints correspond to arbitrary times. Previously this has been
addressed by assuming a discrete time model of fixed rhythm. We generalise to
continuous time and arbitrary rhythm by introducing a simple, novel, and
efficient particle filter scheme, applicable to general continuous time point
processes. Extensive experimental evaluations demonstrate that in comparison
with a more traditional beam search baseline, the particle filter exhibits
superior statistical properties and yields more agreeable results in an
extensive human listening test experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05085</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05085</id><created>2019-09-11</created><updated>2019-09-26</updated><authors><author><keyname>Bontempi</keyname><forenames>Dennis</forenames></author><author><keyname>Benini</keyname><forenames>Sergio</forenames></author><author><keyname>Signoroni</keyname><forenames>Alberto</forenames></author><author><keyname>Svanera</keyname><forenames>Michele</forenames></author><author><keyname>Muckli</keyname><forenames>Lars</forenames></author></authors><title>CEREBRUM: a fast and fully-volumetric Convolutional Encoder-decodeR for
  weakly-supervised sEgmentation of BRain strUctures from out-of-the-scanner
  MRI</title><categories>eess.IV cs.CV</categories><comments>15 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many functional and structural neuroimaging studies call for accurate
morphometric segmentation of different brain structures starting from image
intensity values of MRI scans. Current automatic (multi-) atlas-based
segmentation strategies often lack accuracy on difficult-to-segment brain
structures and, since these methods rely on atlas-to-scan alignment, they may
take long processing times. Recently, methods deploying solutions based on
Convolutional Neural Networks (CNNs) are making the direct analysis of
out-of-the-scanner data feasible. However, current CNN-based solutions
partition the test volume into 2D or 3D patches, which are processed
independently. This entails a loss of global contextual information thereby
negatively impacting the segmentation accuracy. In this work, we design and
test an optimised end-to-end CNN architecture that makes the exploitation of
global spatial information computationally tractable, allowing to process a
whole MRI volume at once. We adopt a weakly supervised learning strategy by
exploiting a large dataset composed by 947 out-of-the-scanner (3 Tesla
T1-weighted 1mm isotropic MP-RAGE 3D sequences) MR Images. The resulting model
is able to produce accurate multi-structure segmentation results in only few
seconds. Different quantitative measures demonstrate an improved accuracy of
our solution when compared to state-of-the-art techniques. Moreover, through a
randomised survey involving expert neuroscientists, we show that subjective
judgements clearly prefer our solution with respect to the widely adopted
atlas-based FreeSurfer software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05090</identifier>
 <datestamp>2019-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05090</id><created>2019-09-11</created><updated>2019-11-26</updated><authors><author><keyname>Zhang</keyname><forenames>Kun</forenames></author><author><keyname>He</keyname><forenames>Peng</forenames></author><author><keyname>Yao</keyname><forenames>Ping</forenames></author><author><keyname>Chen</keyname><forenames>Ge</forenames></author><author><keyname>Yang</keyname><forenames>Chuanguang</forenames></author><author><keyname>Li</keyname><forenames>Huimin</forenames></author><author><keyname>Fu</keyname><forenames>Li</forenames></author><author><keyname>Zheng</keyname><forenames>Tianyao</forenames></author></authors><title>DNANet: De-Normalized Attention Based Multi-Resolution Network for Human
  Pose Estimation</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, multi-resolution networks (such as Hourglass, CPN, HRNet, etc.)
have achieved significant performance on the task of human pose estimation by
combining features from various resolutions. In this paper, we propose a novel
type of attention module, namely De-Normalized Attention (DNA) to deal with the
feature attenuations of conventional attention modules. Our method extends the
original HRNet with spatial, channel-wise and resolution-wise DNAs, which aims
at evaluating the importance of features from different locations, channels and
resolutions to enhance the network capability for feature representation. We
also propose to add fine-to-coarse connections across high-to-low resolutions
in-side each layer of HRNet to increase the maximum depth of network topology.
In addition, we propose to modify the keypoint regressor at the end of HRNet
for accurate keypoint heatmap prediction. The effectiveness of our proposed
network is demonstrated on COCO keypoint detection dataset, achieving
state-of-the-art performance at 77.9 AP score on COCO val2017 dataset and 77.0
on test-dev 2017 dataset without using extra keypoint training data. Our paper
will be accompanied with publicly available codes at GitHub.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05106</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05106</id><created>2019-09-11</created><updated>2019-10-28</updated><authors><author><keyname>Alt</keyname><forenames>Bastian</forenames></author><author><keyname>&#x160;o&#x161;i&#x107;</keyname><forenames>Adrian</forenames></author><author><keyname>Koeppl</keyname><forenames>Heinz</forenames></author></authors><title>Correlation Priors for Reinforcement Learning</title><categories>cs.LG cs.AI cs.SY eess.SY stat.ML</categories><comments>15 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many decision-making problems naturally exhibit pronounced structures
inherited from the characteristics of the underlying environment. In a Markov
decision process model, for example, two distinct states can have inherently
related semantics or encode resembling physical state configurations. This
often implies locally correlated transition dynamics among the states. In order
to complete a certain task in such environments, the operating agent usually
needs to execute a series of temporally and spatially correlated actions.
Though there exists a variety of approaches to capture these correlations in
continuous state-action domains, a principled solution for discrete
environments is missing. In this work, we present a Bayesian learning framework
based on P\'olya-Gamma augmentation that enables an analogous reasoning in such
cases. We demonstrate the framework on a number of common decision-making
related problems, such as imitation learning, subgoal extraction, system
identification and Bayesian reinforcement learning. By explicitly modeling the
underlying correlation structures of these problems, the proposed approach
yields superior predictive performance compared to correlation-agnostic models,
even when trained on data sets that are an order of magnitude smaller in size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05109</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05109</id><created>2019-09-09</created><authors><author><keyname>Santoyo</keyname><forenames>Cesar</forenames></author><author><keyname>Dutreix</keyname><forenames>Maxence</forenames></author><author><keyname>Coogan</keyname><forenames>Samuel</forenames></author></authors><title>A Barrier Function Approach to Finite-Time Stochastic System
  Verification and Control</title><categories>eess.SY cs.SY</categories><comments>arXiv admin note: substantial text overlap with arXiv:1905.12077</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of enforcing safety of a stochastic dynamical
system over a finite-time horizon. We use stochastic control barrier functions
as a means to quantify the probability that a system exits a given safe region
of the state space in finite time. A barrier certificate condition that bounds
the expected value of the barrier function over the time horizon is recast as a
sum-of-squares optimization problem for efficient numerical computation. Unlike
prior works, the proposed certificate condition includes a state-dependent
upper bound on the evolution of the expectation. We present formulations for
both continuous-time and discrete-time systems. Moreover, for systems for which
the drift dynamics are affine-in-control, we propose a method for synthesizing
polynomial state feedback controllers that achieve a specified probability of
safety. Several case studies are presented which benchmark and illustrate the
performance of our verification and control method in the continuous-time and
discrete-time domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05122</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05122</id><created>2019-09-11</created><authors><author><keyname>Va&#x161;kevi&#x10d;ius</keyname><forenames>Tomas</forenames></author><author><keyname>Kanade</keyname><forenames>Varun</forenames></author><author><keyname>Rebeschini</keyname><forenames>Patrick</forenames></author></authors><title>Implicit Regularization for Optimal Sparse Recovery</title><categories>stat.ML cs.LG eess.SP</categories><comments>To appear in NeurIPS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate implicit regularization schemes for gradient descent methods
applied to unpenalized least squares regression to solve the problem of
reconstructing a sparse signal from an underdetermined system of linear
measurements under the restricted isometry assumption. For a given
parametrization yielding a non-convex optimization problem, we show that
prescribed choices of initialization, step size and stopping time yield a
statistically and computationally optimal algorithm that achieves the minimax
rate with the same cost required to read the data up to poly-logarithmic
factors. Beyond minimax optimality, we show that our algorithm adapts to
instance difficulty and yields a dimension-independent rate when the
signal-to-noise ratio is high enough. Key to the computational efficiency of
our method is an increasing step size scheme that adapts to refined estimates
of the true solution. We validate our findings with numerical experiments and
compare our algorithm against explicit $\ell_{1}$ penalization. Going from hard
instances to easy ones, our algorithm is seen to undergo a phase transition,
eventually matching least squares with an oracle knowledge of the true support.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05128</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05128</id><created>2019-09-11</created><authors><author><keyname>Burrus</keyname><forenames>C. Sidney</forenames></author></authors><title>Vector Space and Matrix Methods in Signal and System Theory</title><categories>eess.SP</categories><comments>Presents basic linear algebra and matrix theory for the analysis and
  syntheses of signals and systems</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The tools, ideas, and insights from linear algebra, abstract algebra, and
functional analysis can be extremely useful to signal processing and system
theory in various areas of engineering, science, and social science including
approximation, optimization, parameter identification, big data, etc. Indeed,
many important ideas can be developed from the simple operator equation
  A x = b
  by considering it in a variety of ways. If x and if b are vectors from the
same or, perhaps, different vector spaces and A is an operator, there are three
interesting questions that can be asked which provide a setting for a broad
study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05130</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05130</id><created>2019-09-11</created><authors><author><keyname>Braun</keyname><forenames>Christophe</forenames></author><author><keyname>Voicu</keyname><forenames>Andra M.</forenames></author><author><keyname>Simi&#x107;</keyname><forenames>Ljiljana</forenames></author><author><keyname>M&#xe4;h&#xf6;nen</keyname><forenames>Petri</forenames></author></authors><title>Should We Worry About Interference in Emerging Dense NGSO Satellite
  Constellations?</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many satellite operators are planning to deploy NGSO systems for broadband
communication services in the Ku-, Ka-, and V-band, where some of them have
already launched. Consequently, new challenges are expected for inter-system
satellite coexistence due to the increased interference level and the
complexity of the interactions resulting from the heterogeneity of the
constellations. This is especially relevant for the Ku-band, where the NGSO
systems are most diverse and existing GSO systems, which often support critical
services, must be protected from interference. It is thus imperative to
evaluate the impact of mutual inter-system interference, the efficiency of the
basic interference mitigation techniques, and whether regulatory intervention
is needed for the new systems. We conduct an extensive study of inter-satellite
coexistence in the Ku-band, where we consider all recently proposed NGSO and
some selected GSO systems. Our throughput degradation results suggest that
existing spectrum regulation may be insufficient to ensure GSO protection from
NGSO interference, especially due to the high transmit power of the LEO Kepler
satellites. This also results in strong interference towards other NGSO
systems, where traditional interference mitigation techniques like look-aside
may perform poorly. Specifically, look-aside can be beneficial for large
constellations, but detrimental for small constellations. Furthermore, we
confirm that band-splitting among satellite operators significantly degrades
throughput, also for the Ku-band. Our results overall show that the complexity
of the inter-satellite interactions for new NGSO systems is too high to be
managed via simple interference mitigation techniques. This means that more
sophisticated engineering solutions, and potentially even more strict
regulatory requirements, will be needed to ensure coexistence in emerging,
dense NGSO deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05138</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05138</id><created>2019-09-09</created><authors><author><keyname>Lan</keyname><forenames>Hao</forenames></author><author><keyname>Tong</keyname><forenames>Yin</forenames></author><author><keyname>Guo</keyname><forenames>Jin</forenames></author><author><keyname>Seatzu</keyname><forenames>Carla</forenames></author></authors><title>Verification of infinite-step and K-step opacity Using Petri Nets</title><categories>eess.SY cs.SY</categories><comments>8 pages, 5 figures. arXiv admin note: text overlap with
  arXiv:1908.09604, arXiv:1903.07827, arXiv:1903.09298</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of infinite-step opacity and K-step opacity
of discrete event systems modeled with Petri nets. A Petri net system is said
to be infinite-step/K-step opaque if all its secret states remains opaque to an
intruder for any instant within infinite/K steps. In other words, the intruder
is never able to ascertain that the system used to be in a secrete state within
infinite/K steps based on its observation of the systems evolution. Based on
the notion of basis reachability and the twoway observer, an efficient approach
to verify infinite-step opacity and K-step opacity is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05147</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05147</id><created>2019-08-25</created><authors><author><keyname>Amirabadi</keyname><forenames>M. A.</forenames></author></authors><title>On the performance of some new Multiuser FSO-MIMO Communication Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The practical implementation of maximum likelihood detection is limited by
its high complexity as well as requiring perfect channel state information.
Although conventional blind detection techniques reduce complexity, they
degrade performance and require blind channel state information. In this paper
(for the first time), a deep learning based blind detection and a joint blind
detection-constellation shaping structure are presented (to solve this
problem). This paper (deeply) goes through the problem and discusses several
(practical) scenarios, including single user, multiuser with resource (channel)
allocation, and multiuser without resource allocation (multiuser interference).
In order to show the universality of the proposed systems, wide atmospheric
turbulence regimes, from weak to strong are considered, and single input single
output, as well as multi-input multi-output structures are considered. Results
indicate that without channel estimation, a deep learning based (blind)
detector (despite its very few complexity, and despite conventional systems
require it), could have a very favorable performance at all around. So, it is
expected that practical implementations of the proposed structures greatly
reduce cost, and processing latency, while maintaining performance close enough
to the outstanding conventional systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05148</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05148</id><created>2019-08-21</created><authors><author><keyname>Amirabadi</keyname><forenames>M. A.</forenames></author></authors><title>A Survey on Machine Learning for Optical Communication [Machine Learning
  View]</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine Learning (ML) for Optical Communication (OC) is certainly a hot topic
emerged recently and will continue to raise interest at least for the next few
years. The rate of research development in this area is growing very rapidly.
Novelty of this research direction resides mainly in the peculiarity of the
application field, rather than in the methodological approaches, which are (at
least up to now) state-of-the-art ML algorithms. Reviewing the literature shows
that many of the ML algorithms have not yet been used in this area, and many of
the OC applications are not considered yet, which reflects the fact that the
research topic is pristine. Accordingly, tutorial investigations are quiet
necessary in this filed to help researchers be aware about the last
progressions and cavities of this field. Although several tutorials have been
released recently, they considered this topic from OC view, and neglected ML
view. However, it is required to have an investigations about the ML algorithms
used in this subject. Accordingly, for the first time, this paper reviews ML
for OC literature from ML viewpoint. This view could be really helpful because
only OC experts work on ML for OC, and they are not ML experts, so it could
really help them to have a comprehensive view on the ML subjects implantable in
OC. It has worth to mention that compared with other works, this survey reviews
much more investigations; therefore, it has more generality, and gives the
reader to have a comprehensive overview on this topic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05152</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05152</id><created>2019-08-30</created><authors><author><keyname>Rahimpour</keyname><forenames>Alireza</forenames></author><author><keyname>Martin</keyname><forenames>Sujitha</forenames></author><author><keyname>Tawari</keyname><forenames>Ashish</forenames></author><author><keyname>Qi</keyname><forenames>Hairong</forenames></author></authors><title>Context Aware Road-user Importance Estimation (iCARE)</title><categories>cs.CV cs.HC cs.LG eess.IV</categories><comments>Published in: IEEE Intelligent Vehicles (IV), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Road-users are a critical part of decision-making for both self-driving cars
and driver assistance systems. Some road-users, however, are more important for
decision-making than others because of their respective intentions, ego
vehicle's intention and their effects on each other. In this paper, we propose
a novel architecture for road-user importance estimation which takes advantage
of the local and global context of the scene. For local context, the model
exploits the appearance of the road users (which captures orientation,
intention, etc.) and their location relative to ego-vehicle. The global context
in our model is defined based on the feature map of the convolutional layer of
the module which predicts the future path of the ego-vehicle and contains rich
global information of the scene (e.g., infrastructure, road lanes, etc.), as
well as the ego vehicle's intention information. Moreover, this paper
introduces a new data set of real-world driving, concentrated around
inter-sections and includes annotations of important road users. Systematic
evaluations of our proposed method against several baselines show promising
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05165</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05165</id><created>2019-09-11</created><authors><author><keyname>K&#xf6;p&#xfc;kl&#xfc;</keyname><forenames>Okan</forenames></author><author><keyname>Herzog</keyname><forenames>Fabian</forenames></author><author><keyname>Rigoll</keyname><forenames>Gerhard</forenames></author></authors><title>Comparative Analysis of CNN-based Spatiotemporal Reasoning in Videos</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding actions and gestures in video streams requires temporal
reasoning of the spatial content from different time instants, i.e.,
spatiotemporal (ST) modeling. In this paper, we have made a comparative
analysis of different ST modeling techniques. Since convolutional neural
networks (CNNs) are proved to be an effective tool as a feature extractor for
static images, we apply ST modeling techniques on the features of static images
from different time instants extracted by CNNs. All techniques are trained
end-to-end together with a CNN feature extraction part and evaluated on two
publicly available benchmarks: The Jester and the Something-Something dataset.
The Jester dataset contains various dynamic and static hand gestures, whereas
the Something-Something dataset contains actions of human-object interactions.
The common characteristic of these two benchmarks is that the designed
architectures need to capture the full temporal content of the actions/gestures
in the correct order. Contrary to expectations, experimental results show that
recurrent neural network (RNN) based ST modeling techniques yield inferior
results compared to other techniques such as fully convolutional architectures.
Codes and pretrained models of this work are publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05169</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05169</id><created>2019-09-11</created><authors><author><keyname>Guthrie</keyname><forenames>James</forenames></author><author><keyname>Mallada</keyname><forenames>Enrique</forenames></author></authors><title>Adversarial Model Predictive Control via Second-Order Cone Programming</title><categories>math.OC cs.SY eess.SY</categories><comments>accepted to 2019 IEEE 58th Conference on Decision and Control (CDC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of designing attacks to safety-critical systems in which
the adversary seeks to maximize the overall system cost within a model
predictive control framework. Although in general this problem is NP-hard, we
characterize a family of problems that can be solved in polynomial time via a
second-order cone programming relaxation. In particular, we show that positive
systems fall under this family. We provide examples demonstrating the design of
optimal attacks on an autonomous vehicle and a microgrid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05184</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05184</id><created>2019-09-11</created><authors><author><keyname>Chen</keyname><forenames>Xihao</forenames></author><author><keyname>Yu</keyname><forenames>Jingya</forenames></author><author><keyname>Chen</keyname><forenames>Li</forenames></author><author><keyname>Zeng</keyname><forenames>Shaoqun</forenames></author><author><keyname>Liu</keyname><forenames>Xiuli</forenames></author><author><keyname>Cheng</keyname><forenames>Shenghua</forenames></author></authors><title>Multi-stage domain adversarial style reconstruction for cytopathological
  image stain normalization</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The different stain styles of cytopathological images have a negative effect
on the generalization ability of automated image analysis algorithms. This
article proposes a new framework that normalizes the stain style for
cytopathological images through a stain removal module and a multi-stage domain
adversarial style reconstruction module. We convert colorful images into
grayscale images with a color-encoding mask. Using the mask, reconstructed
images retain their basic color without red and blue mixing, which is important
for cytopathological image interpretation. The style reconstruction module
consists of per-pixel regression with intradomain adversarial learning,
inter-domain adversarial learning, and optional task-based refining. Per-pixel
regression with intradomain adversarial learning establishes the generative
network from the decolorized input to the reconstructed output. The interdomain
adversarial learning further reduces the difference in stain style. The
generation network can be optimized by combining it with the task network.
Experimental results show that the proposed techniques help to optimize the
generation network. The average accuracy increases from 75.41% to 84.79% after
the intra-domain adversarial learning, and to 87.00% after interdomain
adversarial learning. Under the guidance of the task network, the average
accuracy rate reaches 89.58%. The proposed method achieves unsupervised stain
normalization of cytopathological images, while preserving the cell structure,
texture structure, and cell color properties of the image. This method
overcomes the problem of generalizing the task models between different stain
styles of cytopathological images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05202</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05202</id><created>2019-08-27</created><authors><author><keyname>Li</keyname><forenames>Rui</forenames></author><author><keyname>Pan</keyname><forenames>Zhibin</forenames></author><author><keyname>Wang</keyname><forenames>Yang</forenames></author></authors><title>Correlation-based Initialization Algorithm for Tensor-based HSI
  Compression Methods</title><categories>eess.IV cs.MM eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tensor decomposition (TD) is widely used in hyperspectral image (HSI)
compression. The initialization of factor matrix in tensor decomposition can
determine the HSI compression performance. It is worth noting that HSI is
highly correlated in bands. However, this phenomenon is ignored by the previous
TD method. Aiming at improving the HSI compression performance, we propose a
method called correlation-based TD initialization algorithm. As HSI is well
approximated by means of a reference band. In accordance with the SVD result of
the reference band, the initialized factor matrices of TD are produced. We
compare our methods with random and SVD-based initialization methods. The
experimental results reveal that our correlation-based TD initialization method
is capable of significantly reducing the computational cost of TD while keeping
the initialization quality and compression performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05215</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05215</id><created>2019-09-11</created><updated>2020-02-14</updated><authors><author><keyname>Zhong</keyname><forenames>Ellen D.</forenames></author><author><keyname>Bepler</keyname><forenames>Tristan</forenames></author><author><keyname>Davis</keyname><forenames>Joseph H.</forenames></author><author><keyname>Berger</keyname><forenames>Bonnie</forenames></author></authors><title>Reconstructing continuous distributions of 3D protein structure from
  cryo-EM images</title><categories>q-bio.QM cs.CV cs.LG eess.IV stat.ML</categories><journal-ref>International Conference on Learning Representations (ICLR), 2020</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryo-electron microscopy (cryo-EM) is a powerful technique for determining
the structure of proteins and other macromolecular complexes at near-atomic
resolution. In single particle cryo-EM, the central problem is to reconstruct
the three-dimensional structure of a macromolecule from $10^{4-7}$ noisy and
randomly oriented two-dimensional projections. However, the imaged protein
complexes may exhibit structural variability, which complicates reconstruction
and is typically addressed using discrete clustering approaches that fail to
capture the full range of protein dynamics. Here, we introduce a novel method
for cryo-EM reconstruction that extends naturally to modeling continuous
generative factors of structural heterogeneity. This method encodes structures
in Fourier space using coordinate-based deep neural networks, and trains these
networks from unlabeled 2D cryo-EM images by combining exact inference over
image orientation with variational inference for structural heterogeneity. We
demonstrate that the proposed method, termed cryoDRGN, can perform ab initio
reconstruction of 3D protein complexes from simulated and real 2D cryo-EM image
data. To our knowledge, cryoDRGN is the first neural network-based approach for
cryo-EM reconstruction and the first end-to-end method for directly
reconstructing continuous ensembles of protein structures from cryo-EM images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05227</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05227</id><created>2019-09-11</created><authors><author><keyname>Anderson</keyname><forenames>Cyrus</forenames></author><author><keyname>Vasudevan</keyname><forenames>Ram</forenames></author><author><keyname>Johnson-Roberson</keyname><forenames>Matthew</forenames></author></authors><title>On-Demand Trajectory Predictions for Interaction Aware Highway Driving</title><categories>cs.RO eess.SP</categories><comments>8 pages, 6 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Highway driving places significant demands on human drivers and autonomous
vehicles (AVs) alike due to high speeds and the complex interactions in dense
traffic. Merging onto the highway poses additional challenges by limiting the
amount of time available for decision-making. Predicting others' trajectories
accurately and quickly is crucial to safely executing these maneuvers. Many
existing prediction methods based on neural networks have focused on modeling
interactions to achieve better accuracy while assuming the existence of
observation windows over 3s long. This paper proposes a novel probabilistic
model for trajectory prediction that performs competitively with as little as
400ms of observations. The proposed method fits a low-dimensional car-following
model to observed behavior and introduces nonconvex regularization terms that
enforce realistic driving behaviors in the predictions. The resulting inference
procedure allows for realtime forecasts up to 10s into the future while
accounting for interactions between vehicles. Experiments on dense traffic in
the NGSIM dataset demonstrate that the proposed method achieves
state-of-the-art performance with both highly constrained and more traditional
observation windows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05237</identifier>
 <datestamp>2020-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05237</id><created>2019-09-11</created><updated>2020-02-26</updated><authors><author><keyname>Beretta</keyname><forenames>Davide</forenames></author><author><keyname>Grillo</keyname><forenames>Samuele</forenames></author><author><keyname>Pigoli</keyname><forenames>Davide</forenames></author><author><keyname>Bionda</keyname><forenames>Enea</forenames></author><author><keyname>Bossi</keyname><forenames>Claudio</forenames></author><author><keyname>Tornelli</keyname><forenames>Carlo</forenames></author></authors><title>Functional Principal Component Analysis as a Versatile Technique to
  Understand and Predict the Electric Consumption Patterns</title><categories>eess.SY cs.SY stat.AP</categories><comments>Accepted for publication on Sustainable Energy, Grids and Networks
  (Elsevier)</comments><doi>10.1016/j.segan.2020.100308</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding and predicting the electric consumption patterns in the short-,
mid- and long-term, at the distribution and transmission level, is a
fundamental asset for smart grids infrastructure planning, dynamic network
reconfiguration, dynamic energy pricing and savings, and thus energy
efficiency. This work introduces the Functional Principal Component Analysis
(FPCA) as a versatile method to both investigate and predict, at different
level of spatial aggregation, the consumption patterns. The method was applied
to a unique and sensitive dataset that includes electric consumption and
contractual information of Milan metropolitan area. The decomposition of the
load patterns into principal functions was found to be a powerful method to
identify the physical and behavioral causes underlying the daily consumptions,
given knowledge of exogenous variables such as calendar and meteorological
data. The effectiveness of long-term predictions based on principal functions
was proved on Milan's metropolitan area data and assessed on a
publicly-available dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05249</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05249</id><created>2019-09-11</created><authors><author><keyname>Guan</keyname><forenames>Hao</forenames></author><author><keyname>Liu</keyname><forenames>Liu</forenames></author><author><keyname>Moran</keyname><forenames>Sean</forenames></author><author><keyname>Song</keyname><forenames>Fenglong</forenames></author><author><keyname>Slabaugh</keyname><forenames>Gregory</forenames></author></authors><title>NODE: Extreme Low Light Raw Image Denoising using a Noise Decomposition
  Network</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Denoising extreme low light images is a challenging task due to the high
noise level. When the illumination is low, digital cameras increase the ISO
(electronic gain) to amplify the brightness of captured data. However, this in
turn amplifies the noise, arising from read, shot, and defective pixel sources.
In the raw domain, read and shot noise are effectively modelled using Gaussian
and Poisson distributions respectively, whereas defective pixels can be modeled
with impulsive noise. In extreme low light imaging, noise removal becomes a
critical challenge to produce a high quality, detailed image with low noise. In
this paper, we propose a multi-task deep neural network called Noise
Decomposition (NODE) that explicitly and separately estimates defective pixel
noise, in conjunction with Gaussian and Poisson noise, to denoise an extreme
low light image. Our network is purposely designed to work with raw data, for
which the noise is more easily modeled before going through non-linear
transformations in the image signal processing (ISP) pipeline. Quantitative and
qualitative evaluation show the proposed method to be more effective at
denoising real raw images than state-of-the-art techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05298</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05298</id><created>2019-09-11</created><authors><author><keyname>Burrus</keyname><forenames>C. Sidney</forenames></author></authors><title>Prony, Pad\'e, and Linear Prediction for Interpolation and Approximation
  in the Time and Frequency Domain Design of IIR Digital Filters and in
  Parameter Identification</title><categories>eess.SP</categories><comments>18 pages, 78 references</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Model based signal processing or signal analysis or signal representation has
a rather different point of view from the more traditional filtering and
algorithm based approaches. However, in all of these, the names of Prony,
Pad\'e, and linear prediction come up. This note examines these ideas with the
goal of showing they are all based on the same principles and all can be
extended and generalized. A particular application is the frequency sampling
design of IIR digital filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05300</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05300</id><created>2019-09-11</created><authors><author><keyname>Li</keyname><forenames>Boyang</forenames></author><author><keyname>Wu</keyname><forenames>Jie</forenames></author><author><keyname>Shi</keyname><forenames>Yiyu</forenames></author></authors><title>Privacy-Aware Cost-Effective Scheduling Considering Non-Schedulable
  Appliances in Smart Home</title><categories>cs.CR cs.SY eess.SY</categories><comments>8 pages, 9 fgiures. The 15th IEEE International Conference on
  Embedded Software and Systems (2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Smart Home provides integrating and electronic information services to help
residential users manage their energy usage and bill cost but also exposes
users to significant privacy risks due to fine-grained information collected by
smart meters. Taking account of users' privacy concerns, this paper focuses on
cost-effective runtime scheduling designed for schedulable and non-schedulable
appliances. To alleviate the influence of operation uncertainties introduced by
non-schedulable appliances, we formulate the problem by minimizing the expected
sum of electricity cost under the worst privacy situation. Inventing the
iterative alternative algorithm, we effectively schedule the appliances and
rechargeable battery in a cost-effective way while satisfying users' privacy
requirement. Experimental evaluation based on real-world data demonstrates the
effectiveness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05304</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05304</id><created>2019-09-11</created><authors><author><keyname>Hasanbeig</keyname><forenames>Mohammadhosein</forenames></author><author><keyname>Kantaros</keyname><forenames>Yiannis</forenames></author><author><keyname>Abate</keyname><forenames>Alessandro</forenames></author><author><keyname>Kroening</keyname><forenames>Daniel</forenames></author><author><keyname>Pappas</keyname><forenames>George J.</forenames></author><author><keyname>Lee</keyname><forenames>Insup</forenames></author></authors><title>Reinforcement Learning for Temporal Logic Control Synthesis with
  Probabilistic Satisfaction Guarantees</title><categories>cs.LO cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reinforcement Learning (RL) has emerged as an efficient method of choice for
solving complex sequential decision making problems in automatic control,
computer science, economics, and biology. In this paper we present a model-free
RL algorithm to synthesize control policies that maximize the probability of
satisfying high-level control objectives given as Linear Temporal Logic (LTL)
formulas. Uncertainty is considered in the workspace properties, the structure
of the workspace, and the agent actions, giving rise to a
Probabilistically-Labeled Markov Decision Process (PL-MDP) with unknown graph
structure and stochastic behaviour, which is even more general case than a
fully unknown MDP. We first translate the LTL specification into a Limit
Deterministic Buchi Automaton (LDBA), which is then used in an on-the-fly
product with the PL-MDP. Thereafter, we define a synchronous reward function
based on the acceptance condition of the LDBA. Finally, we show that the RL
algorithm delivers a policy that maximizes the satisfaction probability
asymptotically. We provide experimental results that showcase the efficiency of
the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05305</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05305</id><created>2019-09-11</created><authors><author><keyname>Nazeri</keyname><forenames>Kamyar</forenames></author><author><keyname>Thasarathan</keyname><forenames>Harrish</forenames></author><author><keyname>Ebrahimi</keyname><forenames>Mehran</forenames></author></authors><title>Edge-Informed Single Image Super-Resolution</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The recent increase in the extensive use of digital imaging technologies has
brought with it a simultaneous demand for higher-resolution images. We develop
a novel edge-informed approach to single image super-resolution (SISR). The
SISR problem is reformulated as an image inpainting task. We use a two-stage
inpainting model as a baseline for super-resolution and show its effectiveness
for different scale factors (x2, x4, x8) compared to basic interpolation
schemes. This model is trained using a joint optimization of image contents
(texture and color) and structures (edges). Quantitative and qualitative
comparisons are included and the proposed model is compared with current
state-of-the-art techniques. We show that our method of decoupling structure
and texture reconstruction improves the quality of the final reconstructed
high-resolution image. Code and models available at:
https://github.com/knazeri/edge-informed-sisr
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05321</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05321</id><created>2019-09-11</created><authors><author><keyname>Gao</keyname><forenames>Riqiang</forenames></author><author><keyname>Huo</keyname><forenames>Yuankai</forenames></author><author><keyname>Bao</keyname><forenames>Shunxing</forenames></author><author><keyname>Tang</keyname><forenames>Yucheng</forenames></author><author><keyname>Antic</keyname><forenames>Sanja L.</forenames></author><author><keyname>Epstein</keyname><forenames>Emily S.</forenames></author><author><keyname>Balar</keyname><forenames>Aneri B.</forenames></author><author><keyname>Deppen</keyname><forenames>Steve</forenames></author><author><keyname>Paulson</keyname><forenames>Alexis B.</forenames></author><author><keyname>Sandler</keyname><forenames>Kim L.</forenames></author><author><keyname>Massion</keyname><forenames>Pierre P.</forenames></author><author><keyname>Landman</keyname><forenames>Bennett A.</forenames></author></authors><title>Distanced LSTM: Time-Distanced Gates in Long Short-Term Memory Models
  for Lung Cancer Detection</title><categories>eess.IV cs.CV</categories><comments>This paper is accepted by MLMI (oral), MICCAI workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The field of lung nodule detection and cancer prediction has been rapidly
developing with the support of large public data archives. Previous studies
have largely focused on cross-sectional (single) CT data. Herein, we consider
longitudinal data. The Long Short-Term Memory (LSTM) model addresses learning
with regularly spaced time points (i.e., equal temporal intervals). However,
clinical imaging follows patient needs with often heterogeneous, irregular
acquisitions. To model both regular and irregular longitudinal samples, we
generalize the LSTM model with the Distanced LSTM (DLSTM) for temporally varied
acquisitions. The DLSTM includes a Temporal Emphasis Model (TEM) that enables
learning across regularly and irregularly sampled intervals. Briefly, (1) the
time intervals between longitudinal scans are modeled explicitly, (2)
temporally adjustable forget and input gates are introduced for irregular
temporal sampling; and (3) the latest longitudinal scan has an additional
emphasis term. We evaluate the DLSTM framework in three datasets including
simulated data, 1794 National Lung Screening Trial (NLST) scans, and 1420
clinically acquired data with heterogeneous and irregular temporal accession.
The experiments on the first two datasets demonstrate that our method achieves
competitive performance on both simulated and regularly sampled datasets (e.g.
improve LSTM from 0.6785 to 0.7085 on F1 score in NLST). In external validation
of clinically and irregularly acquired data, the benchmarks achieved 0.8350
(CNN feature) and 0.8380 (LSTM) on the area under the ROC curve (AUC) score,
while the proposed DLSTM achieves 0.8905.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05330</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05330</id><created>2019-09-11</created><authors><author><keyname>Kannan</keyname><forenames>Anjuli</forenames></author><author><keyname>Datta</keyname><forenames>Arindrima</forenames></author><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Weinstein</keyname><forenames>Eugene</forenames></author><author><keyname>Ramabhadran</keyname><forenames>Bhuvana</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Bapna</keyname><forenames>Ankur</forenames></author><author><keyname>Chen</keyname><forenames>Zhifeng</forenames></author><author><keyname>Lee</keyname><forenames>Seungji</forenames></author></authors><title>Large-Scale Multilingual Speech Recognition with a Streaming End-to-End
  Model</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Accepted in Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multilingual end-to-end (E2E) models have shown great promise in expansion of
automatic speech recognition (ASR) coverage of the world's languages. They have
shown improvement over monolingual systems, and have simplified training and
serving by eliminating language-specific acoustic, pronunciation, and language
models. This work presents an E2E multilingual system which is equipped to
operate in low-latency interactive applications, as well as handle a key
challenge of real world data: the imbalance in training data across languages.
Using nine Indic languages, we compare a variety of techniques, and find that a
combination of conditioning on a language vector and training language-specific
adapter layers produces the best model. The resulting E2E multilingual model
achieves a lower word error rate (WER) than both monolingual E2E models (eight
of nine languages) and monolingual conventional systems (all nine languages).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05331</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05331</id><created>2019-09-11</created><authors><author><keyname>Eini</keyname><forenames>Roja</forenames></author><author><keyname>Abdelwahed</keyname><forenames>Sherif</forenames></author></authors><title>Learning-based Model Predictive Control for Smart Building Thermal
  Management</title><categories>eess.SY cs.LG cs.NE cs.SY math.OC</categories><comments>5 pages, 9 figures, conference paper, accepted in the 16th
  International Conference on Smart Cities: Improving Quality of Life Using ICT
  &amp; IoT (HONET-ICT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a learning-based model predictive control (MPC) approach
for the thermal control of a four-zone smart building. The objectives are to
minimize energy consumption and maintain the residents' comfort. The proposed
control scheme incorporates learning with the model-based control. The
occupancy profile in the building zones are estimated in a long-term horizon
through the artificial neural network (ANN), and this data is fed into the
model-based predictor to get the indoor temperature predictions. The Energy
Plus software is utilized as the actual dataset provider (weather data, indoor
temperature, energy consumption). The optimization problem, including the
actual and predicted data, is solved in each step of the simulation and the
input setpoint temperature for the heating/cooling system, is generated.
Comparing the results of the proposed approach with the conventional MPC
results proved the significantly better performance of the proposed method in
energy savings (40.56% less cooling power consumption and 16.73% less heating
power consumption), and residents' comfort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05354</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05354</id><created>2019-08-15</created><authors><author><keyname>Li</keyname><forenames>Peng</forenames></author><author><keyname>Maddali</keyname><forenames>Siddharth</forenames></author><author><keyname>Pateras</keyname><forenames>Anastasios</forenames></author><author><keyname>Calvo-Almazan</keyname><forenames>Irene</forenames></author><author><keyname>Hruszkewycz</keyname><forenames>Stephan O.</forenames></author><author><keyname>Chamard</keyname><forenames>Virginie</forenames></author><author><keyname>Allain</keyname><forenames>Marc</forenames></author></authors><title>General approaches for shear-correcting coordinate transformations in
  Bragg coherent diffraction imaging: Part 2</title><categories>physics.ins-det eess.SP</categories><comments>37 pages (double spaced), 4 figures, under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  X-ray Bragg coherent diffraction imaging has been demonstrated as a powerful
three-dimensional (3D) microscopy approach for the investigation of
sub-micrometer-scale crystalline particles. It is based on the measurement of a
series of coherent diffraction intensity patterns that are numerically inverted
to retrieve an image of the spatial distribution of relative phase and
amplitude of the Bragg structure factor of the scatterer. This 3D information,
which is collected through an angular rotation of the sample, is necessarily
obtained in a non-orthogonal frame in Fourier space that must be eventually
reconciled. To deal with this, the currently favored approach (detailed in Part
I) is to perform the entire inversion in conjugate non-orthogonal real and
Fourier space frames, and to transform the 3D sample image into an orthogonal
frame as a post-processing step for result analysis. In this article, a direct
follow-up of Part I, we demonstrate two different transformation strategies
that enable the entire inversion procedure of the measured data set to be
performed in an orthogonal frame. The new approaches described here build
mathematical and numerical frameworks that apply to the cases of evenly and
non-evenly sampled data along the direction of sample rotation (the rocking
curve). The value of these methods is that they rely on and incorporate
significantly more information about the experimental geometry into the design
of the phase retrieval Fourier transformation than the strategy presented in
Part I. Two important outcomes are 1) that the resulting sample image is
correctly interpreted in a shear-free frame, and 2) physically realistic
constraints of BCDI phase retrieval that are difficult to implement with
current methods are easily incorporated. Computing scripts are also given to
aid readers in the implementation of the proposed formalisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05377</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05377</id><created>2019-09-11</created><authors><author><keyname>Xu</keyname><forenames>Xiaotian</forenames></author><author><keyname>Diaz-Mercado</keyname><forenames>Yancy</forenames></author></authors><title>Multi-Agent Control Using Coverage Over Time-Varying Domains</title><categories>cs.MA cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-agent coverage control is used as a mechanism to influence the behavior
of a group of robots by introducing time-varying domain. The coverage
optimization problem is modified to adopt time-varying domains, and the
proposed control law possesses an exponential convergence characteristic.
Cumbrous control for many robots is simplified by deploying distribution and
behavior of the robot team as a whole. In the proposed approach, the inputs to
the multi-agent system, i.e., time-varying density and time-varying domain, are
agnostic to the size of the system. Analytic expressions of surface and line
integrals present in the control law are obtained under uniform density. The
scalability of the proposed control strategy is explained and verified via
numerical simulation. Experiments on real robots are used to test the proposed
control law.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05382</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05382</id><created>2019-09-11</created><authors><author><keyname>Liu</keyname><forenames>Yuan</forenames></author><author><keyname>Jain</keyname><forenames>Ayush</forenames></author><author><keyname>Eng</keyname><forenames>Clara</forenames></author><author><keyname>Way</keyname><forenames>David H.</forenames></author><author><keyname>Lee</keyname><forenames>Kang</forenames></author><author><keyname>Bui</keyname><forenames>Peggy</forenames></author><author><keyname>Kanada</keyname><forenames>Kimberly</forenames></author><author><keyname>Marinho</keyname><forenames>Guilherme de Oliveira</forenames></author><author><keyname>Gallegos</keyname><forenames>Jessica</forenames></author><author><keyname>Gabriele</keyname><forenames>Sara</forenames></author><author><keyname>Gupta</keyname><forenames>Vishakha</forenames></author><author><keyname>Singh</keyname><forenames>Nalini</forenames></author><author><keyname>Natarajan</keyname><forenames>Vivek</forenames></author><author><keyname>Hofmann-Wellenhof</keyname><forenames>Rainer</forenames></author><author><keyname>Corrado</keyname><forenames>Greg S.</forenames></author><author><keyname>Peng</keyname><forenames>Lily H.</forenames></author><author><keyname>Webster</keyname><forenames>Dale R.</forenames></author><author><keyname>Ai</keyname><forenames>Dennis</forenames></author><author><keyname>Huang</keyname><forenames>Susan</forenames></author><author><keyname>Liu</keyname><forenames>Yun</forenames></author><author><keyname>Dunn</keyname><forenames>R. Carter</forenames></author><author><keyname>Coz</keyname><forenames>David</forenames></author></authors><title>A deep learning system for differential diagnosis of skin diseases</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Skin conditions affect an estimated 1.9 billion people worldwide. A shortage
of dermatologists causes long wait times and leads patients to seek
dermatologic care from general practitioners. However, the diagnostic accuracy
of general practitioners has been reported to be only 0.24-0.70 (compared to
0.77-0.96 for dermatologists), resulting in referral errors, delays in care,
and errors in diagnosis and treatment. In this paper, we developed a deep
learning system (DLS) to provide a differential diagnosis of skin conditions
for clinical cases (skin photographs and associated medical histories). The DLS
distinguishes between 26 skin conditions that represent roughly 80% of the
volume of skin conditions seen in primary care. The DLS was developed and
validated using de-identified cases from a teledermatology practice serving 17
clinical sites via a temporal split: the first 14,021 cases for development and
the last 3,756 cases for validation. On the validation set, where a panel of
three board-certified dermatologists defined the reference standard for every
case, the DLS achieved 0.71 and 0.93 top-1 and top-3 accuracies respectively.
For a random subset of the validation set (n=963 cases), 18 clinicians reviewed
the cases for comparison. On this subset, the DLS achieved a 0.67 top-1
accuracy, non-inferior to board-certified dermatologists (0.63, p&lt;0.001), and
higher than primary care physicians (PCPs, 0.45) and nurse practitioners (NPs,
0.41). The top-3 accuracy showed a similar trend: 0.90 DLS, 0.75
dermatologists, 0.60 PCPs, and 0.55 NPs. These results highlight the potential
of the DLS to augment general practitioners to accurately diagnose skin
conditions by suggesting differential diagnoses that may not have been
considered. Future work will be needed to prospectively assess the clinical
impact of using this tool in actual clinical workflows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05393</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05393</id><created>2019-09-11</created><authors><author><keyname>Xia</keyname><forenames>Tiancheng</forenames></author><author><keyname>Jiang</keyname><forenames>Richard</forenames></author><author><keyname>Fu</keyname><forenames>YongQing</forenames></author><author><keyname>Jin</keyname><forenames>Nanlin</forenames></author></authors><title>Automated Blood Cell Detection and Counting via Deep Learning for
  Microfluidic Point-of-Care Medical Devices</title><categories>cs.CV cs.AI cs.ET cs.LG cs.SY eess.SY</categories><journal-ref>Proceeding of 2019 3rd International Conference on Artificial
  Intelligence Applications and Technologies (AIAAT 2019)</journal-ref><doi>10.1088/1757-899X/646/1/012048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated in-vitro cell detection and counting have been a key theme for
artificial and intelligent biological analysis such as biopsy, drug analysis
and decease diagnosis. Along with the rapid development of microfluidics and
lab-on-chip technologies, in-vitro live cell analysis has been one of the
critical tasks for both research and industry communities. However, it is a
great challenge to obtain and then predict the precise information of live
cells from numerous microscopic videos and images. In this paper, we
investigated in-vitro detection of white blood cells using deep neural
networks, and discussed how state-of-the-art machine learning techniques could
fulfil the needs of medical diagnosis. The approach we used in this study was
based on Faster Region-based Convolutional Neural Networks (Faster RCNNs), and
a transfer learning process was applied to apply this technique to the
microscopic detection of blood cells. Our experimental results demonstrated
that fast and efficient analysis of blood cells via automated microscopic
imaging can achieve much better accuracy and faster speed than the
conventionally applied methods, implying a promising future of this technology
to be applied to the microfluidic point-of-care medical devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05397</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05397</id><created>2019-09-11</created><authors><author><keyname>Le</keyname><forenames>Thi-Lam-Thuy</forenames></author><author><keyname>Thome</keyname><forenames>Nicolas</forenames></author><author><keyname>Bernard</keyname><forenames>Sylvain</forenames></author><author><keyname>Bismuth</keyname><forenames>Vincent</forenames></author><author><keyname>Patoureaux</keyname><forenames>Fanny</forenames></author></authors><title>Multitask Classification and Segmentation for Cancer Diagnosis in
  Mammography</title><categories>eess.IV</categories><comments>International Conference on Medical Imaging with Deep Learning 2019.
  MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/r1xDM5DGcV</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Annotation cost is a bottleneck for collecting massive data in mammography,
especially for training deep neural networks. In this paper, we study the use
of heterogeneous levels of annotation granularity to improve predictive
performances. More precisely, we introduce a multi-task learning scheme for
training convolutional neural network (ConvNets), which combines segmentation
and classification, using image-level and pixel-level annotations. In this way,
different objectives can be used to regularize training by sharing intermediate
deep representations. Successful experiments are carried out on the Digital
Database of Screening Mammography (DDSM) to validate the relevance of the
proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05402</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05402</id><created>2019-09-11</created><authors><author><keyname>Duan</keyname><forenames>Jingliang</forenames></author><author><keyname>Li</keyname><forenames>Shengbo Eben</forenames></author><author><keyname>Liu</keyname><forenames>Zhengyu</forenames></author><author><keyname>Bujarbaruah</keyname><forenames>Monimoy</forenames></author><author><keyname>Cheng</keyname><forenames>Bo</forenames></author></authors><title>Generalized Policy Iteration for Optimal Control in Continuous Time</title><categories>eess.SY cs.LG cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes the Deep Generalized Policy Iteration (DGPI) algorithm to
find the infinite horizon optimal control policy for general nonlinear
continuous-time systems with known dynamics. Unlike existing adaptive dynamic
programming algorithms for continuous time systems, DGPI does not require the
admissibility of initialized policy, and input-affine nature of controlled
systems for convergence. Our algorithm employs the actor-critic architecture to
approximate both policy and value functions with the purpose of iteratively
solving the Hamilton-Jacobi-Bellman equation. Both the policy and value
functions are approximated by deep neural networks. Given any arbitrary initial
policy, the proposed DGPI algorithm can eventually converge to an admissible,
and subsequently an optimal policy for an arbitrary nonlinear system. We also
relax the update termination conditions of both the policy evaluation and
improvement processes, which leads to a faster convergence speed than
conventional Policy Iteration (PI) methods, for the same architecture of
function approximators. We further prove the convergence and optimality of the
algorithm with thorough Lyapunov analysis, and demonstrate its generality and
efficacy using two detailed numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05405</identifier>
 <datestamp>2020-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05405</id><created>2019-09-11</created><updated>2020-02-14</updated><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Richter</keyname><forenames>Florian</forenames></author><author><keyname>Lu</keyname><forenames>Jingpei</forenames></author><author><keyname>Funk</keyname><forenames>Emily K.</forenames></author><author><keyname>Orosco</keyname><forenames>Ryan K.</forenames></author><author><keyname>Zhu</keyname><forenames>Jianke</forenames></author><author><keyname>Yip</keyname><forenames>Michael C.</forenames></author></authors><title>SuPer: A Surgical Perception Framework for Endoscopic Tissue
  Manipulation with Surgical Robotics</title><categories>cs.RO cs.CV eess.IV</categories><comments>The first two authors made equal contribution on this paper</comments><journal-ref>IEEE Robotics and Automation Letters (RA-L), vol. 5, no. 2, pp.
  2294-2301, April 2020</journal-ref><doi>10.1109/LRA.2020.2970659</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional control and task automation have been successfully demonstrated
in a variety of structured, controlled environments through the use of highly
specialized modeled robotic systems in conjunction with multiple sensors.
However, the application of autonomy in endoscopic surgery is very challenging,
particularly in soft tissue work, due to the lack of high-quality images and
the unpredictable, constantly deforming environment. In this work, we propose a
novel surgical perception framework, SuPer, for surgical robotic control. This
framework continuously collects 3D geometric information that allows for
mapping a deformable surgical field while tracking rigid instruments within the
field. To achieve this, a model-based tracker is employed to localize the
surgical tool with a kinematic prior in conjunction with a model-free tracker
to reconstruct the deformable environment and provide an estimated point cloud
as a mapping of the environment. The proposed framework was implemented on the
da Vinci Surgical System in real-time with an end-effector controller where the
target configurations are set and regulated through the framework. Our proposed
framework successfully completed soft tissue manipulation tasks with high
accuracy. The demonstration of this novel framework is promising for the future
of surgical autonomy. In addition, we provide our dataset for further surgical
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05411</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05411</id><created>2019-09-11</created><authors><author><keyname>Alghaythi</keyname><forenames>Mamdouh L.</forenames></author><author><keyname>Oconnell</keyname><forenames>Robert M.</forenames></author><author><keyname>Islam</keyname><forenames>Naz E.</forenames></author></authors><title>Design of a High Step-up DC-DC Power Converter with Voltage Multiplier
  Cells and Reduced Losses on Semiconductors for Photovoltaic Systems</title><categories>eess.SY cs.SY</categories><comments>5 pages, 14 figures, (2019 IEEE ELECTRIC SHIP TECHNOLOGIES
  SYMPOSIUM), Arlington, VA, August 14-16, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A high step up dc dc converter based on an isolated dc dc converter with
voltage multiplier cells for photovoltaic systems is essentially introduced in
this paper. The proposed converter can provide a high step up voltage gain. The
switch voltage stress and losses on semiconductors are significantly reduced
through this work. Furthermore, the proposed converter can reliably offer and
provide continuous input current which can be basically used for integrating
photovoltaic systems to convert 30 V to 480 V dc bus. The ripple on the input
current is minimized due to the isolated converter, and the proposed converter
is fed by a single input voltage. The operation modes and the characteristics
of the aforementioned converter are thoroughly analyzed. The components
selection, simulation results and experiment results are mainly verified by
using MATALB Simulink. Consequently, a 360 W hardware prototype is implemented
to validate the design and the theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05417</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05417</id><created>2019-09-03</created><authors><author><keyname>Song</keyname><forenames>Hyoung-Kyu</forenames></author><author><keyname>AlAlkeem</keyname><forenames>Ebrahim</forenames></author><author><keyname>Yun</keyname><forenames>Jaewoong</forenames></author><author><keyname>Kim</keyname><forenames>Tae-Ho</forenames></author><author><keyname>Kim</keyname><forenames>Tae-Ho</forenames></author><author><keyname>Yoo</keyname><forenames>Hyerin</forenames></author><author><keyname>Heo</keyname><forenames>Dasom</forenames></author><author><keyname>Yeun</keyname><forenames>Chan Yeob</forenames></author><author><keyname>Chae</keyname><forenames>Myungsu</forenames></author></authors><title>Deep User Identification Model with Multiple Biometrics</title><categories>cs.CV cs.LG eess.SP</categories><comments>Accepted, CIKM 2019 Workshop on DTMBio</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identification using biometrics is an important yet challenging task.
Abundant research has been conducted on identifying personal identity or gender
using given signals. Various types of biometrics such as electrocardiogram
(ECG), electroencephalogram (EEG), face, fingerprint, and voice have been used
for these tasks. Most research has only focused on single modality or a single
task, while the combination of input modality or tasks is yet to be
investigated. In this paper, we propose deep identification and gender
classification using multimodal biometrics. Our model uses ECG, fingerprint,
and facial data. It then performs two tasks: gender identification and
classification. By engaging multi-modality, a single model can handle various
input domains without training each modality independently, and the correlation
between domains can increase its generalization performance on the tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05429</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05429</id><created>2019-09-11</created><authors><author><keyname>Ezuma</keyname><forenames>Martins</forenames></author><author><keyname>Erden</keyname><forenames>Fatih</forenames></author><author><keyname>Anjinappa</keyname><forenames>Chethan Kumar</forenames></author><author><keyname>Ozdemir</keyname><forenames>Ozgur</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Detection and Classification of UAVs Using RF Fingerprints in the
  Presence of Interference</title><categories>eess.SP</categories><comments>13 pages. Journal paper. Interference, machine learning, Markov
  models, RF fingerprinting, unmanned aerial vehicles (UAVs), UAV detection and
  classification</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of detection and classification of
unmanned aerial vehicles (UAVs) in the presence of wireless interference
signals using a passive radio frequency (RF) surveillance system. The system
uses a multistage detector to distinguish signals transmitted by a UAV
controller from the background noise and interference signals. First, RF
signals from any source are detected using a Markov models-based na\&quot;ive Bayes
decision mechanism. When the receiver operates at a signal-to-noise ratio (SNR)
of 10 dB, and the threshold, which defines the states of the models, is set at
a level 3.5 times the standard deviation of the preprocessed noise data, a
detection accuracy of 99.8% with a false alarm rate of 2.8% is achieved.
Second, signals from Wi-Fi and Bluetooth emitters, if present, are detected
based on the bandwidth and modulation features of the detected RF signal. Once
the input signal is identified as a UAV controller signal, it is classified
using machine learning (ML) techniques. Fifteen statistical features extracted
from the energy transients of the UAV controller signals are fed to
neighborhood component analysis (NCA), and the three most significant features
are selected. The performance of the NCA and five different ML classifiers are
studied for 15 different types of UAV controllers. A classification accuracy of
98.13% is achieved by k-nearest neighbor classifier at 25 dB SNR.
Classification performance is also investigated at different SNR levels and for
a set of 17 UAV controllers which includes two pairs from the same UAV
controller models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05437</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05437</id><created>2019-09-11</created><authors><author><keyname>Pilanawithana</keyname><forenames>Bhathiya</forenames></author><author><keyname>Atapattu</keyname><forenames>Saman</forenames></author><author><keyname>Evans</keyname><forenames>Jamie</forenames></author></authors><title>Resource Allocation in Dynamic DF Relay for SWIPT Network with Circuit
  Power Consumption</title><categories>eess.SP cs.IT math.IT</categories><comments>2019 IEEE Global Communications Conference (GLOBECOM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers simultaneous wireless information and power transfer
(SWIPT) over a dual-hop dynamic decode-and-forward (DF) relay network with the
power-splitting (PS) energy harvesting protocol at the relay. The circuit power
consumption (CPC), which includes power requirements for both decoding and
encoding circuits, is considered at the relay. For a rate-dependent linear CPC
model, we formulate an optimization problem to decide the optimal throughput,
PS ratio, relay transmit power and time ratio for the source to relay
transmission. Although the resultant optimization problem is non-convex, we
derive an efficient optimization algorithm, requiring significantly less
floating point operations than an interior point method. Finally, we present
numerical results which lead to some interesting insights for system design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05442</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05442</id><created>2019-09-11</created><authors><author><keyname>Bedi</keyname><forenames>Amrit Singh</forenames></author><author><keyname>Koppel</keyname><forenames>Alec</forenames></author><author><keyname>Rajawat</keyname><forenames>Ketan</forenames></author><author><keyname>Sadler</keyname><forenames>Brian M.</forenames></author></authors><title>Nonstationary Nonparametric Online Learning: Balancing Dynamic Regret
  and Model Parsimony</title><categories>math.OC cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An open challenge in supervised learning is \emph{conceptual drift}: a data
point begins as classified according to one label, but over time the notion of
that label changes. Beyond linear autoregressive models, transfer and meta
learning address drift, but require data that is representative of disparate
domains at the outset of training. To relax this requirement, we propose a
memory-efficient \emph{online} universal function approximator based on
compressed kernel methods. Our approach hinges upon viewing non-stationary
learning as online convex optimization with dynamic comparators, for which
performance is quantified by dynamic regret.
  Prior works control dynamic regret growth only for linear models. In
contrast, we hypothesize actions belong to reproducing kernel Hilbert spaces
(RKHS). We propose a functional variant of online gradient descent (OGD)
operating in tandem with greedy subspace projections. Projections are necessary
to surmount the fact that RKHS functions have complexity proportional to time.
  For this scheme, we establish sublinear dynamic regret growth in terms of
both loss variation and functional path length, and that the memory of the
function sequence remains moderate. Experiments demonstrate the usefulness of
the proposed technique for online nonlinear regression and classification
problems with non-stationary data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05468</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05468</id><created>2019-09-12</created><authors><author><keyname>Chen</keyname><forenames>Yongxin</forenames></author><author><keyname>Georgiou</keyname><forenames>Tryphon T.</forenames></author><author><keyname>Pavon</keyname><forenames>Michele</forenames></author></authors><title>Covariance steering in zero-sum linear-quadratic two-player differential
  games</title><categories>eess.SY cs.SY math.DS</categories><comments>10 pages</comments><msc-class>93E20, 49N70, 91A10, 60G99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulate a new class of two-person zero-sum differential games, in a
stochastic setting, where a specification on a target terminal state
distribution is imposed on the players. We address such added specification by
introducing incentives to the game that guides the players to steer the join
distribution accordingly. In the present paper, we only address linear
quadratic games with Gaussian target distribution. The solution is
characterized by a coupled Riccati equations system, resembling that in the
standard linear quadratic differential games. Indeed, once the incentive
function is calculated, our problem reduces to a standard one. Tthe framework
developed in this paper extends previous results in covariance control, a fast
growing research area. On the numerical side, problems herein are reformulated
as convex-concave minimax problems for which efficient and reliable algorithms
are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05477</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05477</id><created>2019-09-12</created><authors><author><keyname>Scobee</keyname><forenames>Dexter R. R.</forenames></author><author><keyname>Sastry</keyname><forenames>S. Shankar</forenames></author></authors><title>Maximum Likelihood Constraint Inference for Inverse Reinforcement
  Learning</title><categories>cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While most approaches to the problem of Inverse Reinforcement Learning (IRL)
focus on estimating a reward function that best explains an expert agent's
policy or demonstrated behavior on a control task, it is often the case that
such behavior is more succinctly described by a simple reward combined with a
set of hard constraints. In this setting, the agent is attempting to maximize
cumulative rewards subject to these given constraints on their behavior. We
reformulate the problem of IRL on Markov Decision Processes (MDPs) such that,
given a nominal model of the environment and a nominal reward function, we seek
to estimate state, action, and feature constraints in the environment that
motivate an agent's behavior. Our approach is based on the Maximum Entropy IRL
framework, which allows us to reason about the likelihood of an expert agent's
demonstrations given our knowledge of an MDP. Using our method, we can infer
which constraints can be added to the MDP to most increase the likelihood of
observing these demonstrations. We present an algorithm which iteratively
infers the Maximum Likelihood Constraint to best explain observed behavior, and
we evaluate its efficacy using both simulated behavior and recorded data of
humans navigating around an obstacle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05484</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05484</id><created>2019-09-12</created><authors><author><keyname>Simk&#xf3;</keyname><forenames>A.</forenames></author><author><keyname>L&#xf6;fstedt</keyname><forenames>T.</forenames></author><author><keyname>Garpebring</keyname><forenames>A.</forenames></author><author><keyname>Nyholm</keyname><forenames>T.</forenames></author><author><keyname>Jonsson</keyname><forenames>J.</forenames></author></authors><title>A Generalized Network for MRI Intensity Normalization</title><categories>eess.IV</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/HyeL2iQRYE</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Image normalization, the correction for intra-volume inhomogeneities in
magnetic resonance imaging (MRI) data has little significance for visual
diagnosis, but is a crucial step before automated radiotherapy solutions. There
are several well-established normalization methods, however they are usually
time expensive and difficult to tune for a specific dataset. In this study, we
show how an artificial neural network (ANN) can be trained on non-medical
images --- making the model general --- for intensity normalization on medical
MRI images. Compared to one of the most well-known correction methods, N4ITK,
the trained network achieves a higher accuracy with a speedup-factor of almost
70.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05487</identifier>
 <datestamp>2020-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05487</id><created>2019-09-12</created><updated>2020-02-05</updated><authors><author><keyname>Li</keyname><forenames>Tongxin</forenames></author><author><keyname>Werner</keyname><forenames>Lucien</forenames></author><author><keyname>Low</keyname><forenames>Steven H.</forenames></author></authors><title>Learning Graphs from Linear Measurements: Fundamental Trade-offs and
  Applications</title><categories>cs.IT eess.SP math.IT</categories><comments>Part of the results are in a conference paper accepted by CDC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a specific graph learning task: reconstructing a symmetric matrix
that represents an underlying graph using linear measurements. We present a
sparsity characterization for distributions of random graphs (that are allowed
to contain high-degree nodes), based on which we study fundamental trade-offs
between the number of measurements, the complexity of the graph class, and the
probability of error. We first derive a necessary condition on the number of
measurements. Then, by considering a three-stage recovery scheme, we give a
sufficient condition for recovery. Furthermore, assuming the measurements are
Gaussian IID, we prove upper and lower bounds on the (worst-case) sample
complexity for both noisy and noiseless recovery. In the special cases of the
uniform distribution on trees with n nodes and the Erdos-Renyi (n,p) class, the
fundamental trade-offs are tight up to multiplicative factors with noiseless
measurements. In addition, for practical applications, we design and implement
a polynomial-time (in n) algorithm based on the three-stage recovery scheme.
Experiments show that the heuristic algorithm outperforms basis pursuit on star
graphs. We apply the heuristic algorithm to learn admittance matrices in
electric grids. Simulations for several canonical graph classes and IEEE power
system test cases demonstrate the effectiveness and robustness of the proposed
algorithm for parameter reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05488</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05488</id><created>2019-09-12</created><authors><author><keyname>Liu</keyname><forenames>Yashu</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Kuanquan</forenames></author><author><keyname>Ye</keyname><forenames>Chengqin</forenames></author><author><keyname>Luo</keyname><forenames>Gongning</forenames></author></authors><title>An Automatic Cardiac Segmentation Framework based on Multi-sequence MR
  Image</title><categories>eess.IV cs.CV</categories><comments>accepted by STACOM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LGE CMR is an efficient technology for detecting infarcted myocardium. An
efficient and objective ventricle segmentation method in LGE can benefit the
location of the infarcted myocardium. In this paper, we proposed an automatic
framework for LGE image segmentation. There are just 5 labeled LGE volumes with
about 15 slices of each volume. We adopted histogram match, an invariant of
rotation registration method, on the other labeled modalities to achieve
effective augmentation of the training data. A CNN segmentation model was
trained based on the augmented training data by leave-one-out strategy. The
predicted result of the model followed a connected component analysis for each
class to remain the largest connected component as the final segmentation
result. Our model was evaluated by the 2019 Multi-sequence Cardiac MR
Segmentation Challenge. The mean testing result of 40 testing volumes on Dice
score, Jaccard score, Surface distance, and Hausdorff distance is 0.8087,
0.6976, 2.8727mm, and 15.6387mm, respectively. The experiment result shows a
satisfying performance of the proposed framework. Code is available at
https://github.com/Suiiyu/MS-CMR2019.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05507</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05507</id><created>2019-09-12</created><authors><author><keyname>Masarczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>G&#x142;omb</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>Grabowski</keyname><forenames>Bartosz</forenames></author><author><keyname>Ostaszewski</keyname><forenames>Mateusz</forenames></author></authors><title>Effective transfer learning for hyperspectral image classification with
  deep convolutional neural networks</title><categories>cs.NE cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral imaging is a rich source of data, allowing for multitude of
effective applications. On the other hand such imaging remains challenging
because of large data dimension and, typically, small pool of available
training examples. While deep learning approaches have been shown to be
successful in providing effective classification solutions, especially for high
dimensional problems, unfortunately they work best with a lot of labelled
examples available. To alleviate the second requirement for a particular
dataset the transfer learning approach can be used: first the network is
pre-trained on some dataset with large amount of training labels available,
then the actual dataset is used to fine-tune the network. This strategy is not
straightforward to apply with hyperspectral images, as it is often the case
that only one particular image of some type or characteristic is available. In
this paper, we propose and investigate a simple and effective strategy of
transfer learning that uses unsupervised pre-training step without label
information. This approach can be applied to many of the hyperspectral
classification problems. Performed experiments show that it is very effective
in improving the classification accuracy without being restricted to a
particular image type or neural network architecture. An additional advantage
of the proposed approach is the unsupervised nature of the pre-training step,
which can be done immediately after image acquisition, without the need of the
potentially costly expert's time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05522</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05522</id><created>2019-09-12</created><authors><author><keyname>Tripathy</keyname><forenames>Niladri Sekhar</forenames></author><author><keyname>Chamanbaz</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Bouffanais</keyname><forenames>Roland</forenames></author></authors><title>Robust Stabilization of Resource Limited Networked Control Systems Under
  Denial-of-Service Attack</title><categories>eess.SY cs.SY</categories><comments>Accepted for IEEE CDC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a class of denial-of-service (DoS) attacks, which
aims at overloading the communication channel. On top of the security issue,
continuous or periodic transmission of information within feedback loop is
necessary for the effective control and stabilization of the system. In
addition, uncertainty---originating from variation of parameters or unmodeled
system dynamics---plays a key role in the system's stability. To address these
three critical factors, we solve the joint control and security problem for an
uncertain discrete-time Networked Control System (NCS) subject to limited
availability of the shared communication channel. An event-triggered-based
control and communication strategy is adopted to reduce bandwidth consumption.
To tackle the uncertainty in the system dynamics, a robust control law is
derived using an optimal control approach based on a virtual nominal dynamics
associated with a quadratic cost-functional. The conditions for closed-loop
stability and aperiodic transmission rule of feedback information are derived
using the discrete-time Input-to-State Stability theory. We show that the
proposed control approach withstands a general class of DoS attacks, and the
stability analysis rests upon the characteristics of the attack signal. The
results are illustrated and validated numerically with a classical NCS batch
reactor system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05523</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05523</id><created>2019-09-12</created><authors><author><keyname>Pardi</keyname><forenames>T.</forenames></author><author><keyname>Ortenzi</keyname><forenames>V.</forenames></author><author><keyname>Fairbairn</keyname><forenames>C.</forenames></author><author><keyname>Pipe</keyname><forenames>T.</forenames></author><author><keyname>E.</keyname><forenames>A. M. Ghalamzan</forenames></author><author><keyname>Stolkin</keyname><forenames>R.</forenames></author></authors><title>Maximally manipulable vision-based motion planning for robotic
  rough-cutting on arbitrarily shaped surfaces</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for constrained motion planning from vision,
which enables a robot to move its end-effector over an observed surface, given
start and destination points. The robot has no prior knowledge of the surface
shape, but observes it from a noisy point-cloud camera. We consider the
multi-objective optimisation problem of finding robot trajectories which
maximise the robot's manipulability throughout the motion, while also
minimising surface-distance travelled between the two points. This work has
application in industrial problems of \textit{rough} robotic cutting,
\textit{e.g.} demolition of legacy nuclear plant, where the cut path need not
be precise as long as it achieves dismantling. We show how detours in the cut
path can be leveraged, to increase the manipulability of the robot at all
points along the path. This helps avoid singularities, while maximising the
robot's capability to make small deviations during task execution,
\textit{e.g.} compliantly responding to cutting forces via impedance control.
We show how a sampling-based planner can be projected onto the Riemannian
manifold of a curved surface, and extended to include a term which maximises
manipulability. We present the results of empirical experiments, with both
simulated and real robots, which are tasked with moving over a variety of
different surface shapes. Our planner enables successful task completion, while
avoiding singularities and ensuring significantly greater manipulability when
compared against a conventional RRT* planner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05558</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05558</id><created>2019-09-12</created><authors><author><keyname>Mathews</keyname><forenames>Ian</forenames></author><author><keyname>Kantareddy</keyname><forenames>Sai Nithin Reddy</forenames></author><author><keyname>Sun</keyname><forenames>Shijing</forenames></author><author><keyname>Layurova</keyname><forenames>Mariya</forenames></author><author><keyname>Thapa</keyname><forenames>Janak</forenames></author><author><keyname>Correa-Baena</keyname><forenames>Juan-Pablo</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Rahul</forenames></author><author><keyname>Buonassisi</keyname><forenames>Tonio</forenames></author><author><keyname>Sarma</keyname><forenames>Sanjay</forenames></author><author><keyname>Peters</keyname><forenames>Ian Marius</forenames></author></authors><title>Self-powered sensors enabled by wide-bandgap perovskite indoor
  photovoltaic cells</title><categories>physics.app-ph eess.SP</categories><comments>16 pages, 3 figures</comments><journal-ref>Advanced Functional Materials, 2019, 1904072</journal-ref><doi>10.1002/adfm.201904072</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new approach to ubiquitous sensing for indoor applications,
using high-efficiency and low-cost indoor perovksite photovoltaic cells as
external power sources for backscatter sensors. We demonstrate wide-bandgap
perovskite photovoltaic cells for indoor light energy harvesting with the
1.63eV and 1.84 eV devices demonstrate efficiencies of 21% and 18.5%
respectively under indoor compact fluorescent lighting, with a champion
open-circuit voltage of 0.95 V in a 1.84 eV cell under a light intensity of
0.16 mW/cm2. Subsequently, we demonstrate a wireless temperature sensor
self-powered by a perovskite indoor light-harvesting module. We connect three
perovskite photovoltaic cells in series to create a module that produces 14.5
uW output power under 0.16 mW/cm2 of compact fluorescent illumination with an
efficiency of 13.2%. We use this module as an external power source for a
battery-assisted RFID temperature sensor and demonstrate a read range by of 5.1
meters while maintaining very high frequency measurements every 1.24 seconds.
Our combined indoor perovskite photovoltaic modules and backscatter
radio-frequency sensors are further discussed as a route to ubiquitous sensing
in buildings given their potential to be manufactured in an integrated manner
at very low-cost, their lack of a need for battery replacement and the high
frequency data collection possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05578</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05578</id><created>2019-09-12</created><updated>2019-09-18</updated><authors><author><keyname>Zhao</keyname><forenames>Tianyu</forenames></author><author><keyname>Yi</keyname><forenames>Hanling</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author><author><keyname>Wu</keyname><forenames>Chenye</forenames></author><author><keyname>Xu</keyname><forenames>Yunjian</forenames></author></authors><title>Efficient and Robust Equilibrium Strategies of Utilities in Day-ahead
  Market with Load Uncertainty</title><categories>eess.SY cs.SY</categories><comments>47 pages, 15 figures, to be submitted to IEEE Transactions on Power
  Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the scenario where $N$ utilities strategically bid for
electricity in the day-ahead market and balance the mismatch between the
committed supply and actual demand in the real-time market. Each utility aims
at minimizing its own cost of per-unit electricity by optimizing the bidding
strategy, with uncertainty in demand and local renewable generation taken into
account. The per-unit electricity cost of a utility is a function of both the
day-ahead clearing price and the real-time spot price affected by the
market-level supply-demand mismatch. We model the interactions among utilities
as a non-cooperative game and study the equilibrium strategies. We show that
all utilities bidding according to (net load) prediction is a unique pure
strategy Nash Equilibrium with two salient properties. First, it incurs no loss
of efficiency; hence, the competition among utilities does not increase the
social cost. Second, it is robust and (0, $N-1$)-immune. Irrational fault
behaviors of any subset of the utilities only help reduce the costs of other
rational utilities. We prove the results hold for correlated prediction errors
and a general class of real-time spot pricing models, which capture the
relationship between the spot price, the day-ahead clearing price, and the
market-level mismatch. Simulations based on real-world traces corroborate our
theoretical results. Our study highlights that the market operator can design
real-time pricing schemes according to the sufficient conditions derived in our
paper, such that the day-ahead market admits a unique and efficient pure
strategy Nash Equilibrium and it is robust to irrational fault behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05597</identifier>
 <datestamp>2020-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05597</id><created>2019-09-12</created><updated>2020-02-25</updated><authors><author><keyname>Ravent&#xf3;s</keyname><forenames>Oriol</forenames></author><author><keyname>Bartels</keyname><forenames>Julian</forenames></author></authors><title>Evaluation of Temporal Complexity Reduction Techniques Applied to
  Storage Expansion Planning in Power System Models</title><categories>eess.SY cs.SY math.OC</categories><comments>18 pages, 10 figures. Minor corrections. References added</comments><acm-class>I.6.3</acm-class><journal-ref>Energies 2020, 13, 988</journal-ref><doi>10.3390/en13040988</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growing share of renewable energy makes the optimization of power flows
in power system models computationally more complicated, due to the widely
distributed weather-dependent electricity generation. This article evaluates
two methods to reduce the temporal complexity of a power transmission grid
model with storage expansion planning. The goal of the reduction techniques is
to accelerate the computation of the linear optimal power flow of the grid
model. This is achieved by choosing a small number of representative time
periods to represent one whole year. To select representative time periods, a
hierarchical clustering is used to aggregate either adjacent hours
chronologically or independently distributed coupling days into clusters of
time series. The aggregation efficiency is evaluated by means of the error of
the objective value and the computational time reduction. Further, both the
influence of the network size and the efficiency of parallel computation in the
optimization process are analysed. As a test case, the transmission grid of the
northernmost German federal state of Schleswig-Holstein with a scenario
corresponding to the year 2035 is considered. The considered scenario is
characterized by a high share of installed renewables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05603</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05603</id><created>2019-09-12</created><authors><author><keyname>Chiariotti</keyname><forenames>Federico</forenames></author></authors><title>The Adaptive Tobit Kalman Filter: Tracking Position with Censored
  Measurements in the IoT</title><categories>eess.SP</categories><comments>This paper has been submitted to IEEE for publication. Copyright may
  be transferred without notice</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Internet of Things (IoT) paradigm, distributed sensors and actuators
can observe and act on their environment, communicating wirelessly. In this
context, filtering the observations and tracking the network and environment
state over time is extremely important, and the Kalman Filter (KF) is one of
the most common tools for this. Several of these applications deal with
censored data, either because of sensor saturation or limited detection
regions: when censoring happens, all measurements below a certain threshold are
clipped to the threshold value. The recently proposed Tobit Kalman Filter (TKF)
is an adjusted version of the KF that can deal with censored measurements.
However, like the traditional KF, it needs full knowledge of the process and
measurement noise covariances to work, which are not always available in
practice. In this work, we relax this assumption and propose the Adaptive Tobit
Kalman Filter (ATKF), which can dynamically estimate the process and
measurement noise along with the hidden state of the system from the censored
measurements. We apply our solution to navigation and positioning IoT
scenarios, obtaining a negligible performance loss with regard to the TKF, even
with no a priori knowledge of the noise statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05617</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05617</id><created>2019-06-28</created><authors><author><keyname>Indrusiak</keyname><forenames>Leandro Soares</forenames></author><author><keyname>Dziurzanski</keyname><forenames>Piotr</forenames></author><author><keyname>Zhao</keyname><forenames>Shuai</forenames></author></authors><title>Proceedings of the International Workshop on Reconfigurable and
  Communication-centric Cyber-Physical Systems (ReCoCyPS 2019)</title><categories>eess.SP cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume represents the proceedings of the International Workshop on
Reconfigurable and Communication-centric Cyber-Physical Systems (ReCoCyPS
2019), co-located with the 14th International Symposium on Reconfigurable
Communication-centric Systems-on-Chip (ReCoSoC 2019) on July 2-3 2019, York,
United Kingdom.
  The workshop is organised by the EU-funded SAFIRE project consortium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05620</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05620</id><created>2019-08-29</created><authors><author><keyname>Rathore</keyname><forenames>Govind</forenames></author><author><keyname>Lin</keyname><forenames>Wan-Yi</forenames></author><author><keyname>Kim</keyname><forenames>Ji Eun</forenames></author></authors><title>DeepBbox: Accelerating Precise Ground Truth Generation for Autonomous
  Driving Datasets</title><categories>cs.CV cs.AI eess.IV</categories><comments>accepted by ITSC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous driving requires various computer vision algorithms, such as
object detection and tracking.Precisely-labeled datasets (i.e., objects are
fully contained in bounding boxes with only a few extra pixels) are preferred
for training such algorithms, so that the algorithms can detect exact locations
of the objects. However, it is very time-consuming and hence expensive to
generate precise labels for image sequences at scale. In this paper, we propose
DeepBbox, an algorithm that corrects loose object labels into right bounding
boxes to reduce human annotation efforts. We use Cityscapes dataset to show
annotation efficiency and accuracy improvement using DeepBbox. Experimental
results show that, with DeepBbox,we can increase the number of object edges
that are labeled automatically (within 1\% error) by 50% to reduce manual
annotation time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05630</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05630</id><created>2019-09-02</created><updated>2019-10-07</updated><authors><author><keyname>Al</keyname><forenames>Walid Abdullah</forenames></author><author><keyname>Yun</keyname><forenames>Il Dong</forenames></author></authors><title>Reinforcing Medical Image Classifier to Improve Generalization on Small
  Datasets</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advents of deep learning, improved image classification with complex
discriminative models has been made possible. However, such deep models with
increased complexity require a huge set of labeled samples to generalize the
training. Such classification models can easily overfit when applied for
medical images because of limited training data, which is a common problem in
the field of medical image analysis. This paper proposes and investigates a
reinforced classifier for improving the generalization under a few available
training data. Partially following the idea of reinforcement learning, the
proposed classifier uses a generalization-feedback from a subset of the
training data to update its parameter instead of only using the conventional
cross-entropy loss about the training data. We evaluate the improvement of the
proposed classifier by applying it on three different classification problems
against the standard deep classifiers equipped with existing
overfitting-prevention techniques. Besides an overall improvement in
classification performance, the proposed classifier showed remarkable
characteristics of generalized learning, which can have great potential in
medical classification tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05638</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05638</id><created>2019-09-04</created><authors><author><keyname>Chamain</keyname><forenames>Lahiru D.</forenames></author><author><keyname>Ding</keyname><forenames>Zhi</forenames></author></authors><title>Faster and Accurate Classification for JPEG2000 Compressed Images in
  Networked Applications</title><categories>cs.CV cs.LG cs.MM eess.IV stat.ML</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  JPEG2000 (j2k) is a highly popular format for image and video
compression.With the rapidly growing applications of cloud based image
classification, most existing j2k-compatible schemes would stream compressed
color images from the source before reconstruction at the processing center as
inputs to deep CNNs. We propose to remove the computationally costly
reconstruction step by training a deep CNN image classifier using the CDF 9/7
Discrete Wavelet Transformed (DWT) coefficients directly extracted from
j2k-compressed images. We demonstrate additional computation savings by
utilizing shallower CNN to achieve classification of good accuracy in the DWT
domain. Furthermore, we show that traditional augmentation transforms such as
flipping/shifting are ineffective in the DWT domain and present different
augmentation transformations to achieve more accurate classification without
any additional cost. This way, faster and more accurate classification is
possible for j2k encoded images without image reconstruction. Through
experiments on CIFAR-10 and Tiny ImageNet data sets, we show that the
performance of the proposed solution is consistent for image transmission over
limited channel bandwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05639</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05639</id><created>2019-09-03</created><authors><author><keyname>Gibbon</keyname><forenames>Dafydd</forenames></author><author><keyname>Li</keyname><forenames>Peng</forenames></author></authors><title>Quantifying and Correlating Rhythm Formants in Speech</title><categories>eess.AS cs.CL cs.SD</categories><comments>6 pagers, 7 figures, 2 tables, accepted: LPSS (Linguistic Properties
  of Spontaneous Speech, Taipei 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of the present study is exploratory: to introduce and apply a
new theory of speech rhythm zones or rhythm formants (R-formants). R-formants
are zones of high magnitude frequencies in the low frequency (LF) long-term
spectrum (LTS), rather like formants in the short-term spectra of vowels and
consonants. After an illustration of the method, an R-formant analysis is made
of non-elicited extracts from public speeches. The LF-LTS of three domains, the
amplitude modulated (AM) absolute (rectified) signal, the amplitude envelope
modulation (AEM) and frequency modulation (FM, F0, 'pitch') of the signal are
compared. The first two correlate well, but the third does not correlate
consistently with the other two, presumably due to variability of tone, pitch
accent and intonation. Consequently, only the LF LTS of the absolute speech
signal is used in the empirical analysis. An informal discussion of the
relation between R-formant patterns and utterance structure and a selection of
pragmatic variables over the same utterances showed some trends for R-formant
functionality and thus useful directions for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05645</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05645</id><created>2019-09-05</created><authors><author><keyname>Xu</keyname><forenames>Haiyang</forenames></author><author><keyname>Zhang</keyname><forenames>Hui</forenames></author><author><keyname>Han</keyname><forenames>Kun</forenames></author><author><keyname>Wang</keyname><forenames>Yun</forenames></author><author><keyname>Peng</keyname><forenames>Yiping</forenames></author><author><keyname>Li</keyname><forenames>Xiangang</forenames></author></authors><title>Learning Alignment for Multimodal Emotion Recognition from Speech</title><categories>cs.CL cs.SD eess.AS</categories><comments>InterSpeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech emotion recognition is a challenging problem because human convey
emotions in subtle and complex ways. For emotion recognition on human speech,
one can either extract emotion related features from audio signals or employ
speech recognition techniques to generate text from speech and then apply
natural language processing to analyze the sentiment. Further, emotion
recognition will be beneficial from using audio-textual multimodal information,
it is not trivial to build a system to learn from multimodality. One can build
models for two input sources separately and combine them in a decision level,
but this method ignores the interaction between speech and text in the temporal
domain. In this paper, we propose to use an attention mechanism to learn the
alignment between speech frames and text words, aiming to produce more accurate
multimodal feature representations. The aligned multimodal features are fed
into a sequential model for emotion recognition. We evaluate the approach on
the IEMOCAP dataset and the experimental results show the proposed approach
achieves the state-of-the-art performance on the dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05660</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05660</id><created>2019-09-09</created><authors><author><keyname>Valverde</keyname><forenames>Juan Miguel</forenames></author><author><keyname>Imani</keyname><forenames>Vandad</forenames></author><author><keyname>Lewis</keyname><forenames>John D.</forenames></author><author><keyname>Tohka</keyname><forenames>Jussi</forenames></author></authors><title>Predicting intelligence based on cortical WM/GM contrast, cortical
  thickness and volumetry</title><categories>q-bio.NC cs.LG eess.IV stat.ML</categories><comments>Submission to the ABCD Neurocognitive Prediction Challenge at MICCAI
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a four-layer fully-connected neural network (FNN) for predicting
fluid intelligence scores from T1-weighted MR images for the ABCD-challenge. In
addition to the volumes of brain structures, the FNN uses cortical WM/GM
contrast and cortical thickness at 78 cortical regions. These last two
measurements were derived from the T1-weighted MR images using cortical
surfaces produced by the CIVET pipeline. The age and gender of the subjects and
the scanner manufacturer are also used as features for the learning algorithm.
This yielded 283 features provided to the FNN with two hidden layers of 20 and
15 nodes. The method was applied to the data from the ABCD study. Trained with
a training set of 3736 subjects, the proposed method achieved a MSE of 71.596
and a correlation of 0.151 in the validation set of 415 subjects. For the final
submission, the model was trained with 3568 subjects and it achieved a MSE of
94.0270 in the test set comprised of 4383 subjects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05667</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05667</id><created>2019-09-07</created><authors><author><keyname>Hiley</keyname><forenames>Liam</forenames></author><author><keyname>Preece</keyname><forenames>Alun</forenames></author><author><keyname>Hicks</keyname><forenames>Yulia</forenames></author></authors><title>Explainable Deep Learning for Video Recognition Tasks: A Framework &amp;
  Recommendations</title><categories>cs.LG cs.CV cs.HC eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The popularity of Deep Learning for real-world applications is ever-growing.
With the introduction of high performance hardware, applications are no longer
limited to image recognition. With the introduction of more complex problems
comes more and more complex solutions, and the increasing need for explainable
AI. Deep Neural Networks for Video tasks are amongst the most complex models,
with at least twice the parameters of their Image counterparts. However,
explanations for these models are often ill-adapted to the video domain. The
current work in explainability for video models is still overshadowed by Image
techniques, while Video Deep Learning itself is quickly gaining on methods for
still images. This paper seeks to highlight the need for explainability methods
designed with video deep learning models, and by association spatio-temporal
input in mind, by first illustrating the cutting edge for video deep learning,
and then noting the scarcity of research into explanations for these methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05669</identifier>
 <datestamp>2019-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05669</id><created>2019-09-06</created><updated>2019-11-27</updated><authors><author><keyname>Podilchuk</keyname><forenames>Christine</forenames></author><author><keyname>Pachhai</keyname><forenames>Siddhartha</forenames></author><author><keyname>Warfsman</keyname><forenames>Robert</forenames></author><author><keyname>Mammone</keyname><forenames>Richard</forenames></author></authors><title>On-demand teleradiology using smartphone photographs as proxies for
  DICOM images</title><categories>eess.IV cs.CV</categories><comments>4 pages, 9 figures , IEEE SPMB19 conference submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of photographs of the screen of displayed medical images is explored
to circumvent the challenges involved in transferring images between sites. The
photographs can be conveniently taken with a smartphone and analyzed remotely
by either human or AI experts. An autoencoder preprocessor is shown to improve
the performance for human experts. The AI performance provided by photographs
is shown to be statistically equivalent to using the original DICOM images. The
autoencoder preprocessor increases the PSNR by 15 dB or greater and provides an
AUC that is statistically equivalent to using the original DICOM images. The
photo approach is an alternative to IHE-based teleradiology applications while
avoiding the problems inherit in navigating the proprietary and security
barriers that limit DICOM communication between PACS in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05670</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05670</id><created>2019-09-12</created><authors><author><keyname>Ruderman</keyname><forenames>Michael</forenames></author></authors><title>Lead-Lag-Shaped Interactive Force Estimation by Equivalent Output
  Injection of Sliding-Mode</title><categories>eess.SY cs.SY</categories><comments>5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimation of interactive forces, which are mostly unavailable for direct
measurement on the interface between a system and its environment, is an
essential task in various motion control applications. This paper proposes an
interactive force estimation method, based on the well-known equivalent output
injection of the second-order sliding mode. The equivalent output injection is
used to obtain a frequency-unshaped quantity that appears as a matched external
disturbance and encompasses the interactive forces. Afterwards, a universal
lead-lag shaper, depending on dynamics of the motion control system coupled
with its environment, is used to extract an interactive force quantity. Once
identified, the lead-lag shaper can be applied to the given system structure.
An experimental case study, using a valvecontrolled hydraulic cylinder
counteracted by the dynamic load, is demonstrated with an accurate estimation
of the interactive force, that in comparison to the reference measurement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05679</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05679</id><created>2019-09-11</created><authors><author><keyname>Yousefvand</keyname><forenames>Mohammad</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan</forenames></author></authors><title>Learning End-User Behavior for Optimized Bidding in HetNets: Impact on
  User/Network Association</title><categories>eess.SY cs.NI cs.SY</categories><comments>Submitted to IEEE J-SAC Special issue on Smart Data Pricing. arXiv
  admin note: text overlap with arXiv:1806.03213</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the impact of end-user behavior on service provider (SP) bidding and
user/network association in a HetNet with multiple SPs while considering the
uncertainty in the service guarantees offered by the SPs. Using Prospect Theory
(PT) to model end-user decision making that deviates from expected utility
theory (EUT), we formulate user association with SPs as a multiple leader
Stackelberg game where each SP offers a bid to each user that includes a data
rate with a certain probabilistic service guarantee and at a given price, while
the user chooses the best offer among multiple such bids. We show that when
users underweight the advertised service guarantees of the SPs (a behavior
observed under uncertainty), the rejection rate of the bids increases
dramatically which in turn decreases the SPs utilities and service rates. To
overcome this, we propose a two-stage learning-based optimized bidding
framework for SPs. In the first stage, we use a support vector machine (SVM)
learning algorithm to predict users' binary decisions (accept/reject bids), and
then in the second stage we cast the utility-optimized bidding problem as a
Markov Decision Problem (MDP) and propose a reinforcement learning-based
dynamic programming algorithm to efficiently solve it. Simulation results and
computational complexity analysis validate the efficiency of our proposed
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05686</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05686</id><created>2019-09-11</created><authors><author><keyname>Gopal</keyname><forenames>Preeti</forenames></author><author><keyname>Chandran</keyname><forenames>Sharat</forenames></author><author><keyname>Svalbe</keyname><forenames>Imants</forenames></author><author><keyname>Rajwade</keyname><forenames>Ajit</forenames></author></authors><title>Tomographic reconstruction to detect evolving structures</title><categories>eess.IV cs.CV</categories><comments>33 pages, 18 figures. arXiv admin note: text overlap with
  arXiv:1812.10998</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need for tomographic reconstruction from sparse measurements arises when
the measurement process is potentially harmful, needs to be rapid, or is
uneconomical. In such cases, information from previous longitudinal scans of
the same object helps to reconstruct the current object while requiring
significantly fewer updating measurements. Our work is based on longitudinal
data acquisition scenarios where we wish to study new changes that evolve
within an object over time, such as in repeated scanning for disease
monitoring, or in tomography-guided surgical procedures. While this is easily
feasible when measurements are acquired from a large number of projection
views, it is challenging when the number of views is limited. If the goal is to
track the changes while simultaneously reducing sub-sampling artefacts, we
propose (1) acquiring measurements from a small number of views and using a
global unweighted prior-based reconstruction. If the goal is to observe details
of new changes, we propose (2) acquiring measurements from a moderate number of
views and using a more involved reconstruction routine. We show that in the
latter case, a weighted technique is necessary in order to prevent the prior
from adversely affecting the reconstruction of new structures that are absent
in any of the earlier scans. The reconstruction of new regions is safeguarded
from the bias of the prior by computing regional weights that moderate the
local influence of the priors. We are thus able to effectively reconstruct both
the old and the new structures in the test. In addition to testing on simulated
data, we have validated the efficacy of our method on real tomographic data.
The results demonstrate the use of both unweighted and weighted priors in
different scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05687</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05687</id><created>2019-09-11</created><authors><author><keyname>Kapinski</keyname><forenames>Norbert</forenames></author><author><keyname>Nowosielski</keyname><forenames>Jedrzej M.</forenames></author><author><keyname>Marchwiany</keyname><forenames>Maciej E.</forenames></author><author><keyname>Zielinski</keyname><forenames>Jakub</forenames></author><author><keyname>Ciszkowska-Lyson</keyname><forenames>Beata</forenames></author><author><keyname>Borucki</keyname><forenames>Bartosz A.</forenames></author><author><keyname>Trzcinski</keyname><forenames>Tomasz</forenames></author><author><keyname>Nowinski</keyname><forenames>Krzysztof S.</forenames></author></authors><title>Late fusion of deep learning and hand-crafted features for Achilles
  tendon healing monitoring</title><categories>eess.IV cs.CV</categories><comments>Paper accepted to MICCAI'19 MSKI workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Healing process assessment of the Achilles tendon is usually a complex
procedure that relies on a combination of biomechanical and medical imaging
tests. As a result, diagnostics remains a tedious and long-lasting task.
Recently, a novel method for the automatic assessment of tendon healing based
on Magnetic Resonance Imaging and deep learning was introduced. The method
assesses six parameters related to the treatment progress utilizing a modified
pre-trained network, PCA-reduced space, and linear regression. In this paper,
we propose to improve this approach by incorporating hand-crafted features. We
first perform a feature selection in order to obtain optimal sets of mixed
hand-crafted and deep learning predictors. With the use of approx. 20,000 MRI
slices, we then train a meta-regression algorithm that performs the tendon
healing assessment. Finally, we evaluate the method against scores given by an
experienced radiologist. In comparison with the previous baseline method, our
approach significantly improves correlation in all of the six parameters
assessed. Furthermore, our method uses only one MRI protocol and saves up to
60\% of the time needed for data acquisition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05699</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05699</id><created>2019-09-12</created><authors><author><keyname>Beckers</keyname><forenames>Thomas</forenames></author><author><keyname>Bansal</keyname><forenames>Somil</forenames></author><author><keyname>Tomlin</keyname><forenames>Claire J.</forenames></author><author><keyname>Hirche</keyname><forenames>Sandra</forenames></author></authors><title>Closed-loop Model Selection for Kernel-based Models using Bayesian
  Optimization</title><categories>eess.SY cs.LG cs.SY</categories><journal-ref>IEEE Conference on Decision and Control 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kernel-based nonparametric models have become very attractive for model-based
control approaches for nonlinear systems. However, the selection of the kernel
and its hyperparameters strongly influences the quality of the learned model.
Classically, these hyperparameters are optimized to minimize the prediction
error of the model but this process totally neglects its later usage in the
control loop. In this work, we present a framework to optimize the kernel and
hyperparameters of a kernel-based model directly with respect to the
closed-loop performance of the model. Our framework uses Bayesian optimization
to iteratively refine the kernel-based model using the observed performance on
the actual system until a desired performance is achieved. We demonstrate the
proposed approach in a simulation and on a 3-DoF robotic arm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05703</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05703</id><created>2019-09-12</created><authors><author><keyname>Lemic</keyname><forenames>Filip</forenames></author><author><keyname>Abadal</keyname><forenames>Sergi</forenames></author><author><keyname>Tavernier</keyname><forenames>Wouter</forenames></author><author><keyname>Stroobant</keyname><forenames>Pieter</forenames></author><author><keyname>Colle</keyname><forenames>Didier</forenames></author><author><keyname>Alarc&#xf3;n</keyname><forenames>Eduard</forenames></author><author><keyname>Marquez-Barja</keyname><forenames>Johann</forenames></author><author><keyname>Famaey</keyname><forenames>Jeroen</forenames></author></authors><title>Survey on Terahertz Nanocommunication and Networking: A Top-Down
  Perspective</title><categories>cs.NI cs.ET cs.SY eess.SY</categories><comments>30 pages, 9 figures, 7 tables</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recent developments in nanotechnology herald nanometer-sized devices expected
to bring light to a number of groundbreaking applications. Communication with
and among nanodevices will be needed for unlocking the full potential of such
applications. As the traditional communication approaches cannot be directly
applied in nanocommunication, several alternative paradigms have emerged. Among
them, electromagnetic nanocommunication in the terahertz (THz) frequency band
is particularly promising, mainly due to the breakthrough of novel materials
such as graphene. For this reason, numerous research efforts are nowadays
targeting THz band nanocommunication and consequently nanonetworking. As it is
expected that these trends will continue in the future, we see it beneficial to
summarize the current status in these research domains. In this survey, we
therefore aim to provide an overview of the current THz nanocommunication and
nanonetworking research. Specifically, we discuss the applications envisioned
to be supported by nanonetworks operating in the THz band, together with the
requirements such applications pose on the underlying nanonetworks.
Subsequently, we provide an overview of the current contributions on the
different layers of the protocol stack, as well as the available channel models
and experimentation tools. As the final contribution, we identify a number of
open research challenges and outline several potential future research
directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05731</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05731</id><created>2019-09-12</created><updated>2019-09-13</updated><authors><author><keyname>Pierpaoli</keyname><forenames>Pietro</forenames></author><author><keyname>Doan</keyname><forenames>Thinh T.</forenames></author><author><keyname>Romberg</keyname><forenames>Justin</forenames></author><author><keyname>Egerstedt</keyname><forenames>Magnus</forenames></author></authors><title>A Reinforcement Learning Framework for Sequencing Multi-Robot Behaviors</title><categories>cs.RO cs.SY eess.SY</categories><comments>6 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Given a list of behaviors and associated parameterized controllers for
solving different individual tasks, we study the problem of selecting an
optimal sequence of coordinated behaviors in multi-robot systems for completing
a given mission, which could not be handled by any single behavior. In
addition, we are interested in the case where partial information of the
underlying mission is unknown, therefore, the robots must cooperatively learn
this information through their course of actions. Such problem can be
formulated as an optimal decision problem in multi-robot systems, however, it
is in general intractable due to modeling imperfections and the curse of
dimensionality of the decision variables. To circumvent these issues, we first
consider an alternate formulation of the original problem through introducing a
sequence of behaviors' switching times. Our main contribution is then to
propose a novel reinforcement learning based method, that combines Q-learning
and online gradient descent, for solving this reformulated problem. In
particular, the optimal sequence of the robots' behaviors is found by using
Q-learning while the optimal parameters of the associated controllers are
obtained through an online gradient descent method. Finally, to illustrate the
effectiveness of our proposed method we implement it on a team of
differential-drive robots for solving two different missions, namely, convoy
protection and object manipulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05742</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05742</id><created>2019-09-12</created><authors><author><keyname>Simon</keyname><forenames>Dror</forenames></author><author><keyname>Elad</keyname><forenames>Michael</forenames></author></authors><title>Rethinking the CSC Model for Natural Images</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse representation with respect to an overcomplete dictionary is often
used when regularizing inverse problems in signal and image processing. In
recent years, the Convolutional Sparse Coding (CSC) model, in which the
dictionary consists of shift-invariant filters, has gained renewed interest.
While this model has been successfully used in some image processing problems,
it still falls behind traditional patch-based methods on simple tasks such as
denoising.
  In this work we provide new insights regarding the CSC model and its
capability to represent natural images, and suggest a Bayesian connection
between this model and its patch-based ancestor. Armed with these observations,
we suggest a novel feed-forward network that follows an MMSE approximation
process to the CSC model, using strided convolutions. The performance of this
supervised architecture is shown to be on par with state of the art methods
while using much fewer parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05746</identifier>
 <datestamp>2019-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05746</id><created>2019-09-12</created><updated>2019-10-24</updated><authors><author><keyname>Li</keyname><forenames>Tingle</forenames></author><author><keyname>Chen</keyname><forenames>Jiawei</forenames></author><author><keyname>Hou</keyname><forenames>Haowen</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>TF-Attention-Net: An End To End Neural Network For Singing Voice
  Separation</title><categories>eess.AS cs.IR cs.LG cs.SD</categories><comments>5 pages, 5 figures, submitted to ICASSP 2020 for review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In terms of source separation task, deep neural networks have two major
approaches: one approach is modeling in the spectrogram domain, and the other
approach is modeling in the waveform domain. Most of the previous papers use
CNNs or LSTMs. However, due to the high sampling rate of audio, whether it is
LSTMs with long-distance dependent or CNNs with sliding windows, it is still
difficult to extract long-term input context. In this case, we propose an
end-to-end network: Time-Frequency Attention Net (TF-Attention-Net), to study
the ability of the attention mechanism in the source separation task. First, we
introduce the Slice Attention, which can extract the acoustic features of
temporal and frequency scales under different channels. Besides, the attention
mechanism can be parallel calculated, while LSTMs cannot, because of its
time-dependent property. Meanwhile, the receptive field of the attention
mechanism is larger than the CNNs, which means that we can use shallower layers
to extract longer distance dependence. Experiments indicate that our proposed
TF-Attention-Net outperforms both the spectrogram-based U-Net and the
waveform-based Wave-U-Net baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05748</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05748</id><created>2019-09-12</created><authors><author><keyname>Hu</keyname><forenames>Ren</forenames></author><author><keyname>Li</keyname><forenames>Qifeng</forenames></author></authors><title>Ensemble Learning based Convexification of Power Flow with Application
  in OPF</title><categories>eess.SY cs.LG cs.SY stat.ME</categories><comments>8 pages, 16 figures, 4 tables</comments><msc-class>49-02</msc-class><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an ensemble learning based approach for convexifying AC
power flow equations, which differs from the existing relaxation-based
convexification techniques. The proposed approach is based on the quadratic
power flow equations in rectangular coordinates. To develop this data-driven
convex model of power flow, the polynomial regression (PR) is first deployed as
a basic learner to fit convex relationships between the independent and
dependent variables. Then, ensemble learning algorithms, i.e. gradient boosting
(GB) and bagging, are introduced to combine learners to boost model
performance. Based on the learned convex models of power flow, optimal power
flow (OPF) is formulated as a convex quadratic programming problem. The
simulation results on IEEE standard cases illustrate that, 1) GB outperforms PR
and bagging on the prediction accuracy, 2) in context of solving OPF, the
proposed data-driven convex model outperforms the conventional SDP relaxation
in both accuracy and computational efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05767</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05767</id><created>2019-09-12</created><updated>2019-09-17</updated><authors><author><keyname>Dees</keyname><forenames>Bruno Scalzo</forenames></author><author><keyname>Stankovic</keyname><forenames>Ljubisa</forenames></author><author><keyname>Dakovic</keyname><forenames>Milos</forenames></author><author><keyname>Constantinides</keyname><forenames>Anthony G.</forenames></author><author><keyname>Mandic</keyname><forenames>Danilo P.</forenames></author></authors><title>Unitary Shift Operators on a Graph</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A unitary shift operator (GSO) for signals on a graph is introduced, which
exhibits the desired property of energy preservation over both backward and
forward graph shifts. For rigour, the graph differential operator is also
derived in an analytical form. The commutativity relation of the shift operator
with the Fourier transform is next explored in conjunction with the proposed
GSO to introduce a graph discrete Fourier transform (GDFT) which, unlike
existing approaches, ensures the orthogonality of GDFT bases and admits a
natural frequency-domain interpretation. The proposed GDFT is shown to allow
for a coherent definition of the graph discrete Hilbert transform (GDHT) and
the graph analytic signal. The advantages of the proposed GSO are demonstrated
through illustrative examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05773</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05773</id><created>2019-09-12</created><updated>2020-01-20</updated><authors><author><keyname>Weiss</keyname><forenames>Tomer</forenames></author><author><keyname>Senouf</keyname><forenames>Ortal</forenames></author><author><keyname>Vedula</keyname><forenames>Sanketh</forenames></author><author><keyname>Michailovich</keyname><forenames>Oleg</forenames></author><author><keyname>Zibulevsky</keyname><forenames>Michael</forenames></author><author><keyname>Bronstein</keyname><forenames>Alex</forenames></author></authors><title>PILOT: Physics-Informed Learned Optimized Trajectories for Accelerated
  MRI</title><categories>eess.IV cs.CV physics.med-ph</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Magnetic Resonance Imaging (MRI) has long been considered to be among &quot;the
gold standards&quot; of diagnostic medical imaging. The long acquisition times,
however, render MRI prone to motion artifacts, let alone their adverse
contribution to the relative high costs of MRI examination. Over the last few
decades, multiple studies have focused on the development of both physical and
post-processing methods for accelerated acquisition of MRI scans. These two
approaches, however, have so far been addressed separately. On the other hand,
recent works in optical computational imaging have demonstrated growing success
of concurrent learning-based design of data acquisition and image
reconstruction schemes. In this work, we propose a novel approach to the
learning of optimal schemes for conjoint acquisition and reconstruction of MRI
scans, with the optimization carried out simultaneously with respect to the
time-efficiency of data acquisition and the quality of resulting
reconstructions. To be of a practical value, the schemes are encoded in the
form of general k-space trajectories, whose associated magnetic gradients are
constrained to obey a set of predefined hardware requirements (as defined in
terms of, e.g., peak currents and maximum slew rates of magnetic gradients).
With this proviso in mind, we propose a novel algorithm for the end-to-end
training of a combined acquisition-reconstruction pipeline using a deep neural
network with differentiable forward- and back-propagation operators. We also
demonstrate the effectiveness of the proposed solution in application to both
image reconstruction and image segmentation, reporting substantial improvements
in terms of acceleration factors as well as the quality of these end tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05774</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05774</id><created>2019-09-12</created><authors><author><keyname>Almalioglu</keyname><forenames>Yasin</forenames></author><author><keyname>Turan</keyname><forenames>Mehmet</forenames></author><author><keyname>Lu</keyname><forenames>Chris Xiaoxuan</forenames></author><author><keyname>Trigoni</keyname><forenames>Niki</forenames></author><author><keyname>Markham</keyname><forenames>Andrew</forenames></author></authors><title>Milli-RIO: Ego-Motion Estimation with Millimetre-Wave Radar and Inertial
  Measurement Unit Sensor</title><categories>eess.SP cs.RO</categories><comments>Submitted to RA-L + ICRA2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the fast-growing demand of location-based services in various indoor
environments, robust indoor ego-motion estimation has attracted significant
interest in the last decades. Single-chip millimeter-wave (MMWave) radar as an
emerging technology provides an alternative and complementary solution for
robust ego-motion estimation. This paper introduces Milli-RIO, a MMWave radar
based solution making use of a fixed beam antenna and inertial measurement unit
sensor to calculate 6 degree-of-freedom pose of a moving radar. Detailed
quantitative and qualitative evaluations prove that the proposed method
achieves precisions on the order of few centimetres for indoor localization
tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05783</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05783</id><created>2019-09-11</created><authors><author><keyname>Iftikhar</keyname><forenames>Faiza</forenames></author><author><keyname>Khan</keyname><forenames>Usman</forenames></author><author><keyname>Cheema</keyname><forenames>M. Imran</forenames></author></authors><title>Digital synthesis of multistage etalons for enhancing the FSR</title><categories>eess.SP physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fabry-Perot fiber etalons (FPE) built from three or more reflectors are
attractive for a variety of applications including communications and sensing.
For accelerating a research and development work, one often desires to use
off-the-shelf components to build an FPE with a required transmission profile
for a particular application. Usually, multistage FPEs are designed with equal
lengths of cavities followed by determination of the required reflectivities
for realizing a desired transmission profile. As seen in previous works,
fabricated reflectors are usually slightly different from the designed ones
leading to departure from the desired transmission profile of the FPE. Here, we
show a novel digital synthesis of multistage etalons with off-the-shelf
reflectors and unequal lengths of involved cavities. We find that, in contrast
to equal cavity lengths, unequal lengths of cavities provide more number of
poles in the $z$-domain to achieve a desired multicavity FPE transmission
response. For given reflectivities and by determining correct unequal lengths
of cavities with our synthesis technique, we demonstrate a design example of
increasing the FSR followed by its experimental validation. This work is
generalizable to ring resonators, mirrored, and fiber Bragg grating based
cavities; enabling the design and optimization of cavity systems for a wide
range of applications including lasers, sensors, and filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05784</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05784</id><created>2019-09-11</created><authors><author><keyname>Gao</keyname><forenames>Dashan</forenames></author><author><keyname>Ju</keyname><forenames>Ce</forenames></author><author><keyname>Wei</keyname><forenames>Xiguang</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Chen</keyname><forenames>Tianjian</forenames></author><author><keyname>Yang</keyname><forenames>Qiang</forenames></author></authors><title>HHHFL: Hierarchical Heterogeneous Horizontal Federated Learning for
  Electroencephalography</title><categories>eess.SP cs.AI</categories><comments>5 pages, 6 figures</comments><acm-class>I.2.6; I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electroencephalography (EEG) classification techniques have been widely
studied for human behavior and emotion recognition tasks. But it is still a
challenging issue since the data may vary from subject to subject, may change
over time for the same subject, and maybe heterogeneous. Recent years,
increasing privacy-preserving demands poses new challenges to this task. The
data heterogeneity, as well as the privacy constraint of the EEG data, is not
concerned in previous studies. To fill this gap, in this paper, we propose a
heterogeneous federated learning approach to train machine learning models over
heterogeneous EEG data, while preserving the data privacy of each party. To
verify the effectiveness of our approach, we conduct experiments on a
real-world EEG dataset, consisting of heterogeneous data collected from diverse
devices. Our approach achieves consistent performance improvement on every
task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05785</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05785</id><created>2019-09-10</created><authors><author><keyname>Fern&#xe1;ndez</keyname><forenames>Manuel P.</forenames></author><author><keyname>Bulus-Rossini</keyname><forenames>Laureano A.</forenames></author><author><keyname>Costanzo-Caso</keyname><forenames>Pablo A.</forenames></author></authors><title>PON Monitoring Technique Using Single-FBG Encoders and
  Wavelength-to-Time Mapping</title><categories>eess.SP</categories><doi>10.1109/LPT.2019.2944528</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel coding-based technique for remote monitoring of passive
optical networks which exploits the wavelength-to-time mapping effect of
broadband short pulses in a highly dispersive medium. In this scheme, each
encoder consists in a single FBG written at the same central wavelength but
each one having a unique spectral bandwidth. The ultra-compactness and low-cost
of the encoders allow them to be potentially integrated inside the customers'
terminal. We experimentally demonstrate the feasibility of the proposed method
for the supervision of current and future high-density networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05787</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05787</id><created>2019-09-05</created><authors><author><keyname>Hou</keyname><forenames>Zhanwei</forenames></author><author><keyname>She</keyname><forenames>Changyang</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Li</keyname><forenames>Zhuo</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Prediction and Communication Co-design for Ultra-Reliable and
  Low-Latency Communications</title><categories>eess.SP cs.IT cs.NI cs.SY eess.SY math.IT</categories><comments>This paper has been submitted to IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible. Part of this work was presented in IEEE ICC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultra-reliable and low-latency communications (URLLC) are considered as one
of three new application scenarios in the fifth generation cellular networks.
In this work, we aim to reduce the user experienced delay through prediction
and communication co-design, where each mobile device predicts its future
states and sends them to a data center in advance. Since predictions are not
error-free, we consider prediction errors and packet losses in communications
when evaluating the reliability of the system. Then, we formulate an
optimization problem that maximizes the number of URLLC services supported by
the system by optimizing time and frequency resources and the prediction
horizon. Simulation results verify the effectiveness of the proposed method,
and show that the tradeoff between user experienced delay and reliability can
be improved significantly via prediction and communication co-design.
Furthermore, we carried out an experiment on the remote control in a virtual
factory, and validated our concept on prediction and communication co-design
with the practical mobility data generated by a real tactile device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05789</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05789</id><created>2019-09-03</created><authors><author><keyname>Pu</keyname><forenames>Cunlai</forenames></author><author><keyname>Wu</keyname><forenames>Pang</forenames></author></authors><title>Vulnerability Assessment of Power Grids Based on Both Topological and
  Electrical Properties</title><categories>eess.SY cs.SY eess.SP</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In modern power grids, a local failure or attack can trigger catastrophic
cascading failures, which make it challenging to assess the attack
vulnerability of power grids. In this Brief, we define the $K$-link attack
problem and study the attack vulnerability of power grids under cascading
failures. Particularly, we propose a link centrality measure based on both
topological and electrical properties of power grids. According to this
centrality, we propose a greedy attack algorithm and an optimal attack
algorithm. Simulation results on standard IEEE bus test data show that the
optimal attack is better than the greedy attack and the traditional PSO-based
attack in fracturing power grids. Moreover, the greedy attack has smaller
computational complexity than the optimal attack and the PSO-based attack with
an adequate attack efficiency. Our work helps to understand the vulnerability
of power grids and provides some clues for securing power grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05818</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05818</id><created>2019-09-12</created><authors><author><keyname>Kantareddy</keyname><forenames>Sai Nithin R.</forenames></author><author><keyname>Mathews</keyname><forenames>Ian</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Rahul</forenames></author><author><keyname>Peters</keyname><forenames>Ian Marius</forenames></author><author><keyname>Buonassisi</keyname><forenames>Tonio</forenames></author><author><keyname>Sarma</keyname><forenames>Sanjay E.</forenames></author></authors><title>Long range battery-less PV-powered RFID tag sensors</title><categories>eess.SP cs.ET cs.NI</categories><journal-ref>IEEE Internet of Things, 2019</journal-ref><doi>10.1109/JIOT.2019.2913403</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication range in passive Radio-Frequency Identification (RFID)
front-end devices is a critical barrier in the real-world implementation of
this low-cost technology. Purely passive RFID tags power up by harvesting the
limited RF energy transmitted by the interrogator, and communicate by
backscattering the incident signal. This mode of communication keeps
manufacturing costs below a few cents per tag, but the limited power available
at the tag undermines long-range deployment. In this paper, we present an
approach to use Photovoltaics (PV) to augment the available energy at the tag
to improve read range and sensing capabilities. We provide this extra-energy to
the RFID integrated circuit (IC) using minimum additional electronics yet
enabling persistent sensor-data acquisition. Current and emerging thin-film PV
technologies have significant potential for being very low-cost, hence
eliminating the barrier for implementation and making of PV-RFID wireless
sensors. We reduce the long-range PV-RFID idea to practice by creating
functional prototypes of i) a wireless building environment sensor to monitor
temperature, and ii) an embedded tracker to find lost golf balls. The read
range of PV-RFID is enhanced 8 times compared to conventional passive devices.
In addition, the PV-RFID tags persistently transmit large volumes of sensor
data (&gt;0.14 million measurements per day) without using batteries. For
communication range and energy persistence, we observe good agreement between
calculated estimates and experimental results. We have also identified avenues
for future research to develop low-cost PV-RFID devices for wireless sensing in
the midst of the other competitive wireless technologies such as Bluetooth,
Zigbee, Long Range (LoRa) backscatter etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05827</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05827</id><created>2019-09-12</created><authors><author><keyname>Halder</keyname><forenames>Abhishek</forenames></author><author><keyname>Georgiou</keyname><forenames>Tryphon T.</forenames></author></authors><title>Proximal Recursion for the Wonham Filter</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper contributes to the emerging viewpoint that governing equations for
dynamic state estimation, conditioned on the history of noisy measurements, can
be viewed as gradient flow on the manifold of joint probability density
functions with respect to suitable metrics. Herein, we focus on the Wonham
filter where the prior dynamics is given by a continuous time Markov chain on a
finite state space; the measurement model includes noisy observation of the
(possibly nonlinear function of) state. We establish that the posterior flow
given by the Wonham filter can be viewed as the small time-step limit of
proximal recursions of certain functionals on the probability simplex. The
results of this paper extend our earlier work where similar proximal recursions
were derived for the Kalman-Bucy filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05831</identifier>
 <datestamp>2019-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05831</id><created>2019-09-12</created><updated>2019-11-14</updated><authors><author><keyname>Calvi</keyname><forenames>Giuseppe G.</forenames></author><author><keyname>Dees</keyname><forenames>Bruno Scalzo</forenames></author><author><keyname>Mandic</keyname><forenames>Danilo P.</forenames></author></authors><title>Tight Lower Bound on the Tensor Rank based on the Maximally Square
  Unfolding</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tensors decompositions are a class of tools for analysing datasets of high
dimensionality and variety in a natural manner, with the Canonical Polyadic
Decomposition (CPD) being a main pillar. While the notion of CPD is closely
intertwined with that of the tensor rank, $R$, unlike the matrix rank, the
computation of the tensor rank is an NP-hard problem, owing to the associated
computational burden of evaluating the CPD. To address this issue, we
investigate tight lower bounds on $R$ with the aim to provide a reduced search
space, and hence to lessen the computational costs of the CPD evaluation. This
is achieved by establishing a link between the maximum attainable lower bound
on $R$ and the dimensions of the matrix unfolding of the tensor with aspect
ratio closest to unity (maximally square). Moreover, we demonstrate that, for a
generic tensor, such lower bound can be attained under very mild conditions,
whereby the tensor rank becomes detectable. Numerical examples demonstrate the
benefits of this result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05882</identifier>
 <datestamp>2019-10-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05882</id><created>2019-09-12</created><updated>2019-10-25</updated><authors><author><keyname>Ca&#xf1;&#xf3;n</keyname><forenames>Juan Sebasti&#xe1;n G&#xf3;mez</forenames></author><author><keyname>Herrera</keyname><forenames>Perfecto</forenames></author><author><keyname>G&#xf3;mez</keyname><forenames>Emilia</forenames></author><author><keyname>Cano</keyname><forenames>Estefan&#xed;a</forenames></author></authors><title>The emotions that we perceive in music: the influence of language and
  lyrics comprehension on agreement</title><categories>cs.SD cs.CL eess.AS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the present study, we address the relationship between the emotions
perceived in pop and rock music (mainly in Euro-American styles with English
lyrics) and the language spoken by the listener. Our goal is to understand the
influence of lyrics comprehension on the perception of emotions and use this
information to improve Music Emotion Recognition (MER) models. Two main
research questions are addressed: 1. Are there differences and similarities
between the emotions perceived in pop/rock music by listeners raised with
different mother tongues? 2. Do personal characteristics have an influence on
the perceived emotions for listeners of a given language? Personal
characteristics include the listeners' general demographics, familiarity and
preference for the fragments, and music sophistication. Our hypothesis is that
inter-rater agreement (as defined by Krippendorff's alpha coefficient) from
subjects is directly influenced by the comprehension of lyrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05904</identifier>
 <datestamp>2020-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05904</id><created>2019-09-12</created><authors><author><keyname>Tuluptceva</keyname><forenames>Nina</forenames></author><author><keyname>Bakker</keyname><forenames>Bart</forenames></author><author><keyname>Fedulova</keyname><forenames>Irina</forenames></author><author><keyname>Konushin</keyname><forenames>Anton</forenames></author></authors><title>Perceptual Image Anomaly Detection</title><categories>eess.IV cs.CV</categories><journal-ref>In: Palaiahnakote S., Sanniti di Baja G., Wang L., Yan W. (eds)
  Pattern Recognition. ACPR 2019. Lecture Notes in Computer Science, vol 12046.
  Springer, Cham</journal-ref><doi>10.1007/978-3-030-41404-7_12</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We present a novel method for image anomaly detection, where algorithms that
use samples drawn from some distribution of &quot;normal&quot; data, aim to detect
out-of-distribution (abnormal) samples. Our approach includes a combination of
encoder and generator for mapping an image distribution to a predefined latent
distribution and vice versa. It leverages Generative Adversarial Networks to
learn these data distributions and uses perceptual loss for the detection of
image abnormality. To accomplish this goal, we introduce a new similarity
metric, which expresses the perceived similarity between images and is robust
to changes in image contrast. Secondly, we introduce a novel approach for the
selection of weights of a multi-objective loss function (image reconstruction
and distribution mapping) in the absence of a validation dataset for
hyperparameter tuning. After training, our model measures the abnormality of
the input image as the perceptual dissimilarity between it and the closest
generated image of the modeled data distribution. The proposed approach is
extensively evaluated on several publicly available image benchmarks and
achieves state-of-the-art performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05926</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05926</id><created>2019-09-12</created><updated>2019-11-16</updated><authors><author><keyname>LaLonde</keyname><forenames>Rodney</forenames></author><author><keyname>Torigian</keyname><forenames>Drew</forenames></author><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author></authors><title>Encoding Visual Attributes in Capsules for Explainable Medical Diagnoses</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Paper is currently under review at an unnamed conference. Please
  respect double blind submissions. This paper will be updated with public code
  and any feedback from the peer-review process</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In high-risk domains, understanding the reasons behind machine-generated
predictions is vital in assessing trust. In this study, we introduce a novel
design of multi-task capsule network to provide explainable medical image-based
diagnosis. Our proposed explainable capsule architecture, called X-Caps,
encodes high-level visual attributes within the vectors of its capsules, then
forms predictions based on these interpretable features. Since these attributes
are independent, we modify the dynamic routing algorithm to independently route
information from child capsules to parents. To increase the explainability of
our method further, we propose to train our network on a distribution of expert
labels directly, rather than the average of these labels as done in previous
studies. This provides a meaningful metric of model confidence, punishing
over/under confidence, directly supervised by human-experts' agreement. In our
example high-risk application of lung cancer diagnosis, we conduct experiments
on a large and diverse dataset of over 1000 CT scans, where our proposed
X-Caps, a relatively small 2D capsule network, significantly outperforms the
previous state-of-the-art deep dual-path dense 3D CNN in predicting visual
attribute scores while also improving diagnostic accuracy. To the best of our
knowledge, this is the first study to investigate capsule networks for making
predictions based on human-level interpretable visual attributes in general and
its applications to explainable medical image diagnosis in particular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05948</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05948</id><created>2019-09-07</created><authors><author><keyname>Luppino</keyname><forenames>Luigi T.</forenames></author><author><keyname>Bianchi</keyname><forenames>Filippo M.</forenames></author><author><keyname>Moser</keyname><forenames>Gabriele</forenames></author><author><keyname>Anfinsen</keyname><forenames>Stian N.</forenames></author></authors><title>Unsupervised Image Regression for Heterogeneous Change Detection</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:1807.11766</comments><doi>10.1109/TGRS.2019.2930348</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Change detection in heterogeneous multitemporal satellite images is an
emerging and challenging topic in remote sensing. In particular, one of the
main challenges is to tackle the problem in an unsupervised manner. In this
paper we propose an unsupervised framework for bitemporal heterogeneous change
detection based on the comparison of affinity matrices and image regression.
First, our method quantifies the similarity of affinity matrices computed from
co-located image patches in the two images. This is done to automatically
identify pixels that are likely to be unchanged. With the identified pixels as
pseudo-training data, we learn a transformation to map the first image to the
domain of the other image, and vice versa. Four regression methods are selected
to carry out the transformation: Gaussian process regression, support vector
regression, random forest regression, and a recently proposed kernel regression
method called homogeneous pixel transformation. To evaluate the potentials and
limitations of our framework, and also the benefits and disadvantages of each
regression method, we perform experiments on two real data sets. The results
indicate that the comparison of the affinity matrices can already be considered
a change detection method by itself. However, image regression is shown to
improve the results obtained by the previous step alone and produces accurate
change detection maps despite of the heterogeneity of the multitemporal input
data. Notably, the random forest regression approach excels by achieving
similar accuracy as the other methods, but with a significantly lower
computational cost and with fast and robust tuning of hyperparameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05952</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05952</id><created>2019-09-12</created><authors><author><keyname>Fujita</keyname><forenames>Yusuke</forenames></author><author><keyname>Kanda</keyname><forenames>Naoyuki</forenames></author><author><keyname>Horiguchi</keyname><forenames>Shota</forenames></author><author><keyname>Nagamatsu</keyname><forenames>Kenji</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author></authors><title>End-to-End Neural Speaker Diarization with Permutation-Free Objectives</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted to INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel end-to-end neural-network-based speaker
diarization method. Unlike most existing methods, our proposed method does not
have separate modules for extraction and clustering of speaker representations.
Instead, our model has a single neural network that directly outputs speaker
diarization results. To realize such a model, we formulate the speaker
diarization problem as a multi-label classification problem, and introduces a
permutation-free objective function to directly minimize diarization errors
without being suffered from the speaker-label permutation problem. Besides its
end-to-end simplicity, the proposed method also benefits from being able to
explicitly handle overlapping speech during training and inference. Because of
the benefit, our model can be easily trained/adapted with real-recorded
multi-speaker conversations just by feeding the corresponding multi-speaker
segment labels. We evaluated the proposed method on simulated speech mixtures.
The proposed method achieved diarization error rate of 12.28%, while a
conventional clustering-based system produced diarization error rate of 28.77%.
Furthermore, the domain adaptation with real-recorded speech provided 25.6%
relative improvement on the CALLHOME dataset. Our source code is available
online at https://github.com/hitachi-speech/EEND.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05962</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05962</id><created>2019-09-12</created><authors><author><keyname>Wong</keyname><forenames>Ken C. L.</forenames></author><author><keyname>Moradi</keyname><forenames>Mehdi</forenames></author></authors><title>SegNAS3D: Network Architecture Search with Derivative-Free Global
  Optimization for 3D Image Segmentation</title><categories>eess.IV cs.CV cs.NE</categories><comments>This paper was accepted by the International Conference on Medical
  Image Computing and Computer-Assisted Intervention - MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has largely reduced the need for manual feature selection in
image segmentation. Nevertheless, network architecture optimization and
hyperparameter tuning are mostly manual and time consuming. Although there are
increasing research efforts on network architecture search in computer vision,
most works concentrate on image classification but not segmentation, and there
are very limited efforts on medical image segmentation especially in 3D. To
remedy this, here we propose a framework, SegNAS3D, for network architecture
search of 3D image segmentation. In this framework, a network architecture
comprises interconnected building blocks that consist of operations such as
convolution and skip connection. By representing the block structure as a
learnable directed acyclic graph, hyperparameters such as the number of feature
channels and the option of using deep supervision can be learned together
through derivative-free global optimization. Experiments on 43 3D brain
magnetic resonance images with 19 structures achieved an average Dice
coefficient of 82%. Each architecture search required less than three days on
three GPUs and produced architectures that were much smaller than the
state-of-the-art manually created architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05990</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05990</id><created>2019-09-12</created><authors><author><keyname>Amini</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Kolmanovsky</keyname><forenames>Ilya</forenames></author><author><keyname>Sun</keyname><forenames>Jing</forenames></author></authors><title>Robust Hierarchical MPC for Handling Long Horizon Demand Forecast
  Uncertainty with Application to Automotive Thermal Management</title><categories>math.OC cs.SY eess.SY</categories><comments>7 pages, 5 figures, 58th Conference on Decision and Control (CDC),
  December 11--13, 2019, Nice, France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a robust hierarchical MPC (H-MPC) for dynamic systems
with slow states subject to demand forecast uncertainty. The H-MPC has two
layers: (i) the scheduling MPC at the upper layer with a relatively long
prediction/planning horizon and slow update rate, and (ii) the piloting MPC at
the lower layer over a shorter prediction horizon with a faster update rate.
The scheduling layer MPC calculates the optimal slow states, which will be
tracked by the piloting MPC, while enforcing the system constraints according
to a long-range and approximate prediction of the future demand/load, e.g.,
traction power demand for driving a vehicle. In this paper, to enhance the
H-MPC robustness against the long-term demand forecast uncertainty, we propose
to use the high-quality preview information enabled by the connectivity
technology over the short horizon to modify the planned trajectories via a
constraint tightening approach at the scheduling layer. Simulation results are
presented for a simplified vehicle model to confirm the effectiveness of the
proposed robust H-MPC framework in handling demand forecast uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.05992</identifier>
 <datestamp>2020-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.05992</id><created>2019-09-12</created><authors><author><keyname>Ho</keyname><forenames>David Joon</forenames></author><author><keyname>Han</keyname><forenames>Shuo</forenames></author><author><keyname>Fu</keyname><forenames>Chichen</forenames></author><author><keyname>Salama</keyname><forenames>Paul</forenames></author><author><keyname>Dunn</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Delp</keyname><forenames>Edward J.</forenames></author></authors><title>Center-Extraction-Based Three Dimensional Nuclei Instance Segmentation
  of Fluorescence Microscopy Images</title><categories>eess.IV cs.CV</categories><comments>Presented at the IEEE-EMBS International Conference on Biomedical and
  Health Informatics (BHI 2019)</comments><doi>10.1109/BHI.2019.8834516</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluorescence microscopy is an essential tool for the analysis of 3D
subcellular structures in tissue. An important step in the characterization of
tissue involves nuclei segmentation. In this paper, a two-stage method for
segmentation of nuclei using convolutional neural networks (CNNs) is described.
In particular, since creating labeled volumes manually for training purposes is
not practical due to the size and complexity of the 3D data sets, the paper
describes a method for generating synthetic microscopy volumes based on a
spatially constrained cycle-consistent adversarial network. The proposed method
is tested on multiple real microscopy data sets and outperforms other commonly
used segmentation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06001</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06001</id><created>2019-09-12</created><authors><author><keyname>Arabian</keyname><forenames>Farah</forenames></author><author><keyname>Rice</keyname><forenames>Michael</forenames></author></authors><title>Polarization diversity and equalization of frequency selective channels
  in telemetry environment for 16APSK</title><categories>eess.SP</categories><comments>International telemetry conference (ITC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing RHCP and LHCP outputs from the antennas vertical (V) and horizontal
(H) dipoles in the resonant cavity within the antenna feeds is the current
practice of ground-based station receivers in aeronautical telemetry. The
equalizers on the market, operate on either LHCP or RHCP alone, or a combined
signal created by co-phasing and adding the RHCP and LHCP outputs. In this
paper, we show how to optimally combine the V and H dipole outputs and
demonstrate that an equalizer operating on this optimally-combined signal
outperforms an equalizer operating on the RHCP, LHCP, or the combined signals.
Finally, we show how to optimally combine the RHCP and LHCP outputs for
equalization, where this optimal combination performs as good as the optimally
combined V and H signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06012</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06012</id><created>2019-09-04</created><authors><author><keyname>Huang</keyname><forenames>Chao</forenames></author><author><keyname>Han</keyname><forenames>Hu</forenames></author><author><keyname>Yao</keyname><forenames>Qingsong</forenames></author><author><keyname>Zhu</keyname><forenames>Shankuan</forenames></author><author><keyname>Zhou</keyname><forenames>S. Kevin</forenames></author></authors><title>3D U$^2$-Net: A 3D Universal U-Net for Multi-Domain Medical Image
  Segmentation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fully convolutional neural networks like U-Net have been the state-of-the-art
methods in medical image segmentation. Practically, a network is highly
specialized and trained separately for each segmentation task. Instead of a
collection of multiple models, it is highly desirable to learn a universal data
representation for different tasks, ideally a single model with the addition of
a minimal number of parameters steered to each task. Inspired by the recent
success of multi-domain learning in image classification, for the first time we
explore a promising universal architecture that handles multiple medical
segmentation tasks and is extendable for new tasks, regardless of different
organs and imaging modalities. Our 3D Universal U-Net (3D U$^2$-Net) is built
upon separable convolution, assuming that {\it images from different domains
have domain-specific spatial correlations which can be probed with channel-wise
convolution while also share cross-channel correlations which can be modeled
with pointwise convolution}. We evaluate the 3D U$^2$-Net on five organ
segmentation datasets. Experimental results show that this universal network is
capable of competing with traditional models in terms of segmentation accuracy,
while requiring only about $1\%$ of the parameters. Additionally, we observe
that the architecture can be easily and effectively adapted to a new domain
without sacrificing performance in the domains used to learn the shared
parameterization of the universal network. We put the code of 3D U$^2$-Net into
public domain. \url{https://github.com/huangmozhilv/u2net_torch/}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06016</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06016</id><created>2019-09-12</created><authors><author><keyname>Zhang</keyname><forenames>Yanyan</forenames></author><author><keyname>Lu</keyname><forenames>Ping</forenames></author><author><keyname>Yu</keyname><forenames>Hua</forenames></author><author><keyname>Morris</keyname><forenames>Stan</forenames></author></authors><title>Enhancement of seismic imaging: An innovative deep learning approach</title><categories>eess.IV cs.IT math.IT physics.geo-ph</categories><comments>10 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enhancing the frequency bandwidth of the seismic data is always the pursuance
at the geophysical community. High resolution of seismic data provides the key
resource to extract detailed stratigraphic knowledge. Here, a novel approach,
based on deep learning model, is introduced by extracting reflections from well
log data to broaden spectrum bandwidth of seismic data through boosting low and
high frequencies. The corresponding improvement is observed from the
enhancement of resolution of seismic data as well as elimination of sidelobe
artifacts from seismic wavelets. During the training stage of deep learning
model, geo-spatial information by taking consideration of multiple wells
simultaneously is fully guaranteed, which assures that laterally and vertically
geological information are constrained by and accurate away from the well
controls during the inversion procedure. Extensive experiments prove that the
enhanced seismic data is consistent with well log information, and honors rock
property relationships defined from the wells at given locations. Uncertainty
analysis could also be quantitatively assessed to determine the possibilities
of a range of seismic responses by leveraging the outputs from the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06020</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06020</id><created>2019-09-12</created><authors><author><keyname>Zheng</keyname><forenames>Shilian</forenames></author><author><keyname>Chen</keyname><forenames>Shichuan</forenames></author><author><keyname>Qi</keyname><forenames>Peihan</forenames></author><author><keyname>Zhou</keyname><forenames>Huaji</forenames></author><author><keyname>Yang</keyname><forenames>Xiaoniu</forenames></author></authors><title>Spectrum Sensing Based on Deep Learning Classification for Cognitive
  Radios</title><categories>eess.SP cs.LG</categories><comments>Submitted to China Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing is a key technology for cognitive radios. We present
spectrum sensing as a classification problem and propose a sensing method based
on deep learning classification. We normalize the received signal power to
overcome the effects of noise power uncertainty. We train the model with as
many types of signals as possible as well as noise data to enable the trained
network model to adapt to untrained new signals. We also use transfer learning
strategies to improve the performance for real-world signals. Extensive
experiments are conducted to evaluate the performance of this method. The
simulation results show that the proposed method performs better than two
traditional spectrum sensing methods, i.e., maximum-minimum eigenvalue
ratio-based method and frequency domain entropy-based method. In addition, the
experimental results of the new untrained signal types show that our method can
adapt to the detection of these new signals. Furthermore, the real-world signal
detection experiment results show that the detection performance can be further
improved by transfer learning. Finally, experiments under colored noise show
that our proposed method has superior detection performance under colored
noise, while the traditional methods have a significant performance
degradation, which further validate the superiority of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06031</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06031</id><created>2019-09-13</created><authors><author><keyname>Zheng</keyname><forenames>Shilian</forenames></author><author><keyname>Chen</keyname><forenames>Shichuan</forenames></author><author><keyname>Yang</keyname><forenames>Xiaoniu</forenames></author></authors><title>Deep Learning for Cooperative Radio Signal Classification</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio signal classification has a very wide range of applications in
cognitive radio networks and electromagnetic spectrum monitoring. In this
article, we consider scenarios where multiple nodes in the network participate
in cooperative classification. We propose cooperative radio signal
classification methods based on deep learning for decision fusion, signal
fusion and feature fusion, respectively. We analyze the performance of these
methods through simulation experiments. We conclude the article with a
discussion of research challenges and open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06034</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06034</id><created>2019-09-13</created><authors><author><keyname>Blum</keyname><forenames>Tamir</forenames></author><author><keyname>Jones</keyname><forenames>William</forenames></author><author><keyname>Yoshida</keyname><forenames>Kazuya</forenames></author></authors><title>Deep Learned Path Planning via Randomized Reward-Linked-Goals and
  Potential Space Applications</title><categories>cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML</categories><comments>8 pages, 3 tables, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space exploration missions have seen use of increasingly sophisticated
robotic systems with ever more autonomy. Deep learning promises to take this
even a step further, and has applications for high-level tasks, like path
planning, as well as low-level tasks, like motion control, which are critical
components for mission efficiency and success. Using deep reinforcement
end-to-end learning with randomized reward function parameters during training,
we teach a simulated 8 degree-of-freedom quadruped ant-like robot to travel
anywhere within a perimeter, conducting path plan and motion control on a
single neural network, without any system model or prior knowledge of the
terrain or environment. Our approach also allows for user specified waypoints,
which could translate well to either fully autonomous or
semi-autonomous/teleoperated space applications that encounter delay times. We
trained the agent using randomly generated waypoints linked to the reward
function and passed waypoint coordinates as inputs to the neural network. Such
applications show promise on a variety of space exploration robots, including
high speed rovers for fast locomotion and legged cave robots for rough terrain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06045</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06045</id><created>2019-09-13</created><updated>2019-09-19</updated><authors><author><keyname>Vyas</keyname><forenames>Ritesh</forenames></author><author><keyname>Kumar</keyname><forenames>Ajay</forenames></author></authors><title>A Collaborative Approach using Ridge-Valley Minutiae for More Accurate
  Contactless Fingerprint Identification</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contactless fingerprint identification has emerged as an reliable and user
friendly alternative for the personal identification in a range of e-business
and law-enforcement applications. It is however quite known from the literature
that the contactless fingerprint images deliver remarkably low matching
accuracies as compared with those obtained from the contact-based fingerprint
sensors. This paper develops a new approach to significantly improve
contactless fingerprint matching capabilities available today. We
systematically analyze the extent of complimentary ridge-valley information and
introduce new approaches to achieve significantly higher matching accuracy over
state-of-art fingerprint matchers commonly employed today. We also investigate
least explored options for the fingerprint color-space conversions, which can
play a key-role for more accurate contactless fingerprint matching. This paper
presents experimental results from different publicly available contactless
fingerprint databases using NBIS, MCC and COTS matchers. Our consistently
outperforming results validate the effectiveness of the proposed approach for
more accurate contactless fingerprint identification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06049</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06049</id><created>2019-09-13</created><authors><author><keyname>Monteiro</keyname><forenames>Rafael</forenames></author><author><keyname>Miyazato</keyname><forenames>Itsuki</forenames></author><author><keyname>Takahashi</keyname><forenames>Keisuke</forenames></author></authors><title>The Rising Sun Envelope Method: an automatic and accurate peak location
  technique for XANES measurements</title><categories>cond-mat.mtrl-sci eess.SP physics.chem-ph</categories><comments>10 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lack of theoretical understanding of X-Ray Absorption Near Edge Structure
(XANES) spectroscopy makes the development of analysis tools for its study a
necessity. Here, an algorithm for judicious choice of local minima and maxima
points of XANES spectrum (experimental or simulated) is proposed, without any
loss of information on peaks location nor on peak strength. We call it the
Rising Sun Envelope Method, since it is based on successive regularizations of
the spectral measurement that, according to parameter choices that are
intrinsic to the measurements, keep peaks location and strength as invariants.
This is the first method that finds peaks in XANES automatically, without
depending on first derivative information. Nevertheless, a direct computation
of Absorption-Edge is provided, where we avoid the issue inflection point
computations based on the XANES second derivative, dealing instead with simpler
computations of inflection points of higher quality cubic spline approximation.
Besides applications of the algorithm to XANES, we illustrate further
applications in Electron Energy Loss Spectroscopy (EELS) and Raman spectra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06057</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06057</id><created>2019-09-13</created><authors><author><keyname>Miehling</keyname><forenames>Erik</forenames></author><author><keyname>Dong</keyname><forenames>Roy</forenames></author><author><keyname>Langbort</keyname><forenames>C&#xe9;dric</forenames></author><author><keyname>Ba&#x15f;ar</keyname><forenames>Tamer</forenames></author></authors><title>Strategic Inference with a Single Private Sample</title><categories>cs.GT cs.SY eess.SY math.OC</categories><comments>Accepted to 58th Conference on Decision and Control (2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications in cyber security, we develop a simple game model
for describing how a learning agent's private information influences an
observing agent's inference process. The model describes a situation in which
one of the agents (attacker) is deciding which of two targets to attack, one
with a known reward and another with uncertain reward. The attacker receives a
single private sample from the uncertain target's distribution and updates its
belief of the target quality. The other agent (defender) knows the true
rewards, but does not see the sample that the attacker has received. This leads
to agents possessing asymmetric information: the attacker is uncertain over the
parameter of the distribution, whereas the defender is uncertain about the
observed sample. After the attacker updates its belief, both the attacker and
the defender play a simultaneous move game based on their respective beliefs.
We offer a characterization of the pure strategy equilibria of the game and
explain how the players' decisions are influenced by their prior knowledge and
the payoffs/costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06106</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06106</id><created>2019-09-13</created><authors><author><keyname>Zulfiqar</keyname><forenames>Umair</forenames></author><author><keyname>Sreeram</keyname><forenames>Victor</forenames></author><author><keyname>Du</keyname><forenames>Xin</forenames></author></authors><title>Controller Reduction via Weighted Interpolation</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The important analytical control designs which are based on the state-space
model of the linear time-invariant system yield a controller whose order is
almost the same as that of the plant model. If a plant is described by a
high-order model, the resulting controller cannot be implemented without
reducing its order to a practically acceptable value. This is achieved using
weighted model order reduction wherein the weights represent a specific
closed-loop performance criterion. In this paper, we present a weighted model
order reduction algorithm, which is computationally efficient and ensures less
weighted error. The algorithm tends to achieve the weighted-H2 error optimality
and guarantee the stability of the reduced-order model, unlike the existing
weighted interpolation algorithms. The proposed algorithm is an effective
design tool to obtain a lower order controller for large-scale plants in a
computationally efficient way. The application of the proposed technique in
achieving this objective is also demonstrated on benchmark problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06112</identifier>
 <datestamp>2020-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06112</id><created>2019-09-13</created><updated>2020-01-06</updated><authors><author><keyname>Salamati</keyname><forenames>Mahmoud</forenames></author><author><keyname>Soudjani</keyname><forenames>Sadegh</forenames></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author></authors><title>A Lyapunov Approach for Time Bounded Reachability of CTMCs and CTMDPs</title><categories>eess.SY cs.SY</categories><comments>To be published at in ACM Transactions on Modeling and Performance
  Evaluation of Computing Systems (TOMPECS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time bounded reachability is a fundamental problem in model checking
continuous-time Markov chains (CTMCs) and Markov decision processes (CTMDPs)
for specifications in continuous stochastic logics. It can be computed by
numerically solving a characteristic linear dynamical system but the procedure
is computationally expensive. We take a control-theoretic approach and propose
a reduction technique that finds another dynamical system of lower dimension
(number of variables), such that numerically solving the reduced dynamical
system provides an approximation to the solution of the original system with
guaranteed error bounds. Our technique generalises lumpability (or
probabilistic bisimulation) to a quantitative setting. Our main result is a
Lyapunov function characterisation of the difference in the trajectories of the
two dynamics that depends on the initial mismatch and exponentially decreases
over time. In particular, the Lyapunov function enables us to compute an error
bound between the two dynamics as well as a convergence rate. Finally, we show
that the search for the reduced dynamics can be computed in polynomial time
using a Schur decomposition of the transition matrix. This enables us to
efficiently solve the reduced dynamical system by computing the exponential of
an upper-triangular matrix characterising the reduced dynamics. For CTMDPs, we
generalise our approach using piecewise quadratic Lyapunov functions for
switched affine dynamical systems. We synthesise a policy for the CTMDP via its
reduced-order switched system that guarantees the time bounded reachability
probability lies above a threshold. We provide error bounds that depend on the
minimum dwell time of the policy. We demonstrate the technique on examples from
queueing networks, for which lumpability does not produce any state space
reduction but our technique synthesises policies using reduced version of the
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06139</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06139</id><created>2019-09-13</created><authors><author><keyname>Das</keyname><forenames>Soumya</forenames></author><author><keyname>Verma</keyname><forenames>Ashu</forenames></author><author><keyname>Bijwe</keyname><forenames>P. R.</forenames></author></authors><title>Efficient Multi-Year Security Constrained AC Transmission Network
  Expansion Planning</title><categories>eess.SY cs.SY math.OC</categories><comments>JOURNAL, 10 Pages, 8 Tables and 1 Figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solution of multi-year, dynamic AC Transmission network expansion planning
(TNEP) problem is gradually taking center stage of planning research owing to
its potential accuracy. However, computational burden for a security
constrained AC TNEP is huge compared to that with DC TNEP. For a dynamic,
security constrained AC TNEP problem, the computational burden becomes so very
excessive that solution for even moderately sized systems becomes almost
impossible. Hence, this paper presents an efficient, four-stage solution
methodology for multi-year, network N-1 contingency and voltage stability
constrained, dynamic ACTNEP problems. Several intelligent logical strategies
are developed and applied to reduce the computational burden of optimization
algorithms. The proposed methodology is applied to Garver 6, IEEE 24 and 118
bus systems to demonstrate its efficiency and ability to solve TNEP for varying
system sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06148</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06148</id><created>2019-09-13</created><authors><author><keyname>Li</keyname><forenames>Minghan</forenames></author><author><keyname>Cao</keyname><forenames>Xiangyong</forenames></author><author><keyname>Zhao</keyname><forenames>Qian</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Gao</keyname><forenames>Chenqiang</forenames></author><author><keyname>Meng</keyname><forenames>Deyu</forenames></author></authors><title>Video Rain/Snow Removal by Transformed Online Multiscale Convolutional
  Sparse Coding</title><categories>cs.CV eess.IV</categories><comments>14 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video rain/snow removal from surveillance videos is an important task in the
computer vision community since rain/snow existed in videos can severely
degenerate the performance of many surveillance system. Various methods have
been investigated extensively, but most only consider consistent rain/snow
under stable background scenes. Rain/snow captured from practical surveillance
camera, however, is always highly dynamic in time with the background scene
transformed occasionally. To this issue, this paper proposes a novel rain/snow
removal approach, which fully considers dynamic statistics of both rain/snow
and background scenes taken from a video sequence. Specifically, the rain/snow
is encoded as an online multi-scale convolutional sparse coding (OMS-CSC)
model, which not only finely delivers the sparse scattering and multi-scale
shapes of real rain/snow, but also well encodes their temporally dynamic
configurations by real-time ameliorated parameters in the model. Furthermore, a
transformation operator imposed on the background scenes is further embedded
into the proposed model, which finely conveys the dynamic background
transformations, such as rotations, scalings and distortions, inevitably
existed in a real video sequence. The approach so constructed can naturally
better adapt to the dynamic rain/snow as well as background changes, and also
suitable to deal with the streaming video attributed its online learning mode.
The proposed model is formulated in a concise maximum a posterior (MAP)
framework and is readily solved by the ADMM algorithm. Compared with the
state-of-the-art online and offline video rain/snow removal methods, the
proposed method achieves better performance on synthetic and real videos
datasets both visually and quantitatively. Specifically, our method can be
implemented in relatively high efficiency, showing its potential to real-time
video rain/snow removal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06154</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06154</id><created>2019-09-13</created><authors><author><keyname>Tonello</keyname><forenames>Andrea M.</forenames></author><author><keyname>Salamat</keyname><forenames>Babak</forenames></author></authors><title>A Swash Mass Unmanned Aerial Vehicle: Design, Modeling and Control</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new unmanned aerial vehicle (UAV) structure, referred to as
swash mass UAV, is presented. It consists of a double blade coaxial shaft rotor
and four swash masses that allow changing the orientation and maneuvering the
UAV. The dynamical system model is derived from the Newton\textquotesingle s
law framework. The rotational behavior of the UAV is discussed as a function of
the design parameters. Given the uniqueness and the form of the obtained
non-linear dynamical system model, a back-stepping control mechanism is
proposed. It is obtained following the Lyapunov's control approach in each
iteration step. Numerical results show that the swashed mass UAV can be
maneuvered with the proposed control algorithm so that linear and aggressive
trajectories can be accurately tracked.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06161</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06161</id><created>2019-09-13</created><updated>2019-10-28</updated><authors><author><keyname>Kubilius</keyname><forenames>Jonas</forenames></author><author><keyname>Schrimpf</keyname><forenames>Martin</forenames></author><author><keyname>Kar</keyname><forenames>Kohitij</forenames></author><author><keyname>Hong</keyname><forenames>Ha</forenames></author><author><keyname>Majaj</keyname><forenames>Najib J.</forenames></author><author><keyname>Rajalingham</keyname><forenames>Rishi</forenames></author><author><keyname>Issa</keyname><forenames>Elias B.</forenames></author><author><keyname>Bashivan</keyname><forenames>Pouya</forenames></author><author><keyname>Prescott-Roy</keyname><forenames>Jonathan</forenames></author><author><keyname>Schmidt</keyname><forenames>Kailyn</forenames></author><author><keyname>Nayebi</keyname><forenames>Aran</forenames></author><author><keyname>Bear</keyname><forenames>Daniel</forenames></author><author><keyname>Yamins</keyname><forenames>Daniel L. K.</forenames></author><author><keyname>DiCarlo</keyname><forenames>James J.</forenames></author></authors><title>Brain-Like Object Recognition with High-Performing Shallow Recurrent
  ANNs</title><categories>cs.CV cs.LG cs.NE eess.IV q-bio.NC</categories><comments>NeurIPS 2019 (Oral). Code available at
  https://github.com/dicarlolab/neurips2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep convolutional artificial neural networks (ANNs) are the leading class of
candidate models of the mechanisms of visual processing in the primate ventral
stream. While initially inspired by brain anatomy, over the past years, these
ANNs have evolved from a simple eight-layer architecture in AlexNet to
extremely deep and branching architectures, demonstrating increasingly better
object categorization performance, yet bringing into question how brain-like
they still are. In particular, typical deep models from the machine learning
community are often hard to map onto the brain's anatomy due to their vast
number of layers and missing biologically-important connections, such as
recurrence. Here we demonstrate that better anatomical alignment to the brain
and high performance on machine learning as well as neuroscience measures do
not have to be in contradiction. We developed CORnet-S, a shallow ANN with four
anatomically mapped areas and recurrent connectivity, guided by Brain-Score, a
new large-scale composite of neural and behavioral benchmarks for quantifying
the functional fidelity of models of the primate ventral visual stream. Despite
being significantly shallower than most models, CORnet-S is the top model on
Brain-Score and outperforms similarly compact models on ImageNet. Moreover, our
extensive analyses of CORnet-S circuitry variants reveal that recurrence is the
main predictive factor of both Brain-Score and ImageNet top-1 performance.
Finally, we report that the temporal evolution of the CORnet-S &quot;IT&quot; neural
population resembles the actual monkey IT population dynamics. Taken together,
these results establish CORnet-S, a compact, recurrent ANN, as the current best
model of the primate ventral visual stream.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06178</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06178</id><created>2019-09-10</created><authors><author><keyname>Lin</keyname><forenames>Liwei</forenames></author><author><keyname>Wang</keyname><forenames>Xiangdong</forenames></author><author><keyname>Liu</keyname><forenames>Hong</forenames></author><author><keyname>Qian</keyname><forenames>Yueliang</forenames></author></authors><title>Guided Learning Convolution System for DCASE 2019 Task 4</title><categories>eess.AS cs.LG cs.SD</categories><comments>Accept by DCASE2019 Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe in detail the system we submitted to DCASE2019
task 4: sound event detection (SED) in domestic environments. We employ a
convolutional neural network (CNN) with an embedding-level attention pooling
module to solve it. By considering the interference caused by the co-occurrence
of multiple events in the unbalanced dataset, we utilize the disentangled
feature to raise the performance of the model. To take advantage of the
unlabeled data, we adopt Guided Learning for semi-supervised learning. A group
of median filters with adaptive window sizes is utilized in the post-processing
of output probabilities of the model. We also analyze the effect of the
synthetic data on the performance of the model and finally achieve an
event-based F-measure of 45.43% on the validation set and an event-based
F-measure of 42.7% on the test set. The system we submitted to the challenge
achieves the best performance compared to those of other participates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06199</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06199</id><created>2019-09-13</created><authors><author><keyname>Nadeem</keyname><forenames>Uzair</forenames></author><author><keyname>Atif</keyname><forenames>Muhammad Shahzaib</forenames></author><author><keyname>Ahmed</keyname><forenames>Rizwan</forenames></author><author><keyname>Touqeer</keyname><forenames>Hassan</forenames></author><author><keyname>Khawaja</keyname><forenames>Hamood Ur Rahman</forenames></author></authors><title>FPGA based Implementation of Frequency and Phase Matching Technique for
  Grid Tied Applications</title><categories>eess.SY cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A grid tied inverter converts DC voltage into AC voltage, while synchronizing
it with the supply line phase and frequency. This paper presents an efficient,
robust, and easy-to-implement grid tie mechanism. First, the grid tie mechanism
was simulated in software using LabVIEW and Multisim. Then, the whole system
was practically implemented on hardware. A prototype hardware was developed to
produce AC voltage from solar panels. Phase and frequency of the generated
voltage were synchronized with those of a reference sinusoidal signal. The
synchronization mechanism was digitally implemented on an FPGA, which also
controlled the whole system. We achieved real time frequency matching with an
improved Zero Crossing Detection (ZCD) technique. Phase matching was also
achieved in real time using a modified Phase Locked Loop (PLL) algorithm, which
retains stability while being simpler than the general PLL algorithm.
Experiments demonstrated that the proposed grid tied system reliably
synchronized the phase and frequency of the voltage generated by the
implemented hardware with those of the reference grid voltage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06203</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06203</id><created>2019-09-12</created><authors><author><keyname>Pucci</keyname><forenames>Daniele</forenames></author></authors><title>On the Existence of Flight Equilibria in Longitudinal Dynamics</title><categories>eess.SY cs.SY</categories><comments>arXiv admin note: substantial text overlap with arXiv:1608.02505</comments><journal-ref>IEEE Conference on Decision and Control (CDC), 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Any control law for aircraft asymptotic stabilization requires the existence
of an equilibrium condition, also called trim flight condition. At a constant
velocity flight, for instance, there must exist an aircraft orientation such
that aerodynamic forces oppose the plane's thrust plus weight, and the torque
balance equals zero. A closer look at the equations characterizing the trim
conditions point out that the existence of aircraft equilibrium configurations
cannot be in general claimed beforehand. By considering aircraft longitudinal
linear dynamics, this paper shows that the existence of flight trim conditions
is a consequence of the vehicle shape or aerodynamics. These results are
obtained independently from the aircraft flight envelope, and do not require
any explicit expression of the aerodynamics acting on the vehicle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06218</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06218</id><created>2019-09-13</created><authors><author><keyname>Hao</keyname><forenames>Wanming</forenames></author><author><keyname>Zeng</keyname><forenames>Ming</forenames></author><author><keyname>Sun</keyname><forenames>Gangcan</forenames></author><author><keyname>Muta</keyname><forenames>Osamu</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Yang</keyname><forenames>Shouyi</forenames></author><author><keyname>Gacanin</keyname><forenames>Haris</forenames></author></authors><title>Codebook-Based Max-Min Energy-Efficient Resource Allocation for Uplink
  mmWave MIMO-NOMA Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>IEEE_T_COM, accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the energy-efficient resource allocation
problem in an uplink non-orthogonal multiple access (NOMA) millimeter wave
system, where the fully-connected-based sparse radio frequency chain antenna
structure is applied at the base station (BS). To relieve the pilot overhead
for channel estimation, we propose a codebook-based analog beam design scheme,
which only requires to obtain the equivalent channel gain. On this basis, users
belonging to the same analog beam are served via NOMA. Meanwhile, an advanced
NOMA decoding scheme is proposed by exploiting the global information available
at the BS. Under predefined minimum rate and maximum transmit power constraints
for each user, we formulate a max-min user energy efficiency (EE) optimization
problem by jointly optimizing the detection matrix at the BS and transmit power
at the users. We first transform the original fractional objective function
into a subtractive one. Then, we propose a two-loop iterative algorithm to
solve the reformulated problem. Specifically, the inner loop updates the
detection matrix and transmit power iteratively, while the outer loop adopts
the bisection method. Meanwhile, to decrease the complexity of the inner loop,
we propose a zero-forcing (ZF)-based iterative algorithm, where the detection
matrix is designed via the ZF technique. Finally, simulation results show that
the proposed schemes obtain a better performance in terms of spectral
efficiency and EE than the conventional schemes
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06247</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06247</id><created>2019-09-13</created><authors><author><keyname>Fujita</keyname><forenames>Yusuke</forenames></author><author><keyname>Kanda</keyname><forenames>Naoyuki</forenames></author><author><keyname>Horiguchi</keyname><forenames>Shota</forenames></author><author><keyname>Xue</keyname><forenames>Yawen</forenames></author><author><keyname>Nagamatsu</keyname><forenames>Kenji</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author></authors><title>End-to-End Neural Speaker Diarization with Self-attention</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted for ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker diarization has been mainly developed based on the clustering of
speaker embeddings. However, the clustering-based approach has two major
problems; i.e., (i) it is not optimized to minimize diarization errors
directly, and (ii) it cannot handle speaker overlaps correctly. To solve these
problems, the End-to-End Neural Diarization (EEND), in which a bidirectional
long short-term memory (BLSTM) network directly outputs speaker diarization
results given a multi-talker recording, was recently proposed. In this study,
we enhance EEND by introducing self-attention blocks instead of BLSTM blocks.
In contrast to BLSTM, which is conditioned only on its previous and next hidden
states, self-attention is directly conditioned on all the other frames, making
it much suitable for dealing with the speaker diarization problem. We evaluated
our proposed method on simulated mixtures, real telephone calls, and real
dialogue recordings. The experimental results revealed that the self-attention
was the key to achieving good performance and that our proposed method
performed significantly better than the conventional BLSTM-based method. Our
method was even better than that of the state-of-the-art x-vector
clustering-based method. Finally, by visualizing the latent representation, we
show that the self-attention can capture global speaker characteristics in
addition to local speech activity dynamics. Our source code is available online
at https://github.com/hitachi-speech/EEND.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06258</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06258</id><created>2019-09-13</created><authors><author><keyname>Linard</keyname><forenames>Alexis</forenames></author><author><keyname>Bucur</keyname><forenames>Doina</forenames></author><author><keyname>Stoelinga</keyname><forenames>Marielle</forenames></author></authors><title>Fault Trees from Data: Efficient Learning with an Evolutionary Algorithm</title><categories>cs.FL cs.SY eess.SY</categories><comments>This paper is an extended version of the SETTA 2019 paper,
  Springer-Verlag</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyber-physical systems come with increasingly complex architectures and
failure modes, which complicates the task of obtaining accurate system
reliability models. At the same time, with the emergence of the (industrial)
Internet-of-Things, systems are more and more often being monitored via
advanced sensor systems. These sensors produce large amounts of data about the
components' failure behaviour, and can, therefore, be fruitfully exploited to
learn reliability models automatically. This paper presents an effective
algorithm for learning a prominent class of reliability models, namely fault
trees, from observational data. Our algorithm is evolutionary in nature; i.e.,
is an iterative, population-based, randomized search method among fault-tree
structures that are increasingly more consistent with the observational data.
We have evaluated our method on a large number of case studies, both on
synthetic data, and industrial data. Our experiments show that our algorithm
outperforms other methods and provides near-optimal results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06264</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06264</id><created>2019-09-13</created><updated>2019-09-20</updated><authors><author><keyname>Blanco</keyname><forenames>Gustavo</forenames></author><author><keyname>Traina</keyname><forenames>Agma J. M.</forenames></author><author><keyname>Traina</keyname><forenames>Caetano</forenames><suffix>Jr.</suffix></author><author><keyname>Azevedo-Marques</keyname><forenames>Paulo M.</forenames></author><author><keyname>Jorge</keyname><forenames>Ana E. S.</forenames></author><author><keyname>de Oliveira</keyname><forenames>Daniel</forenames></author><author><keyname>Bedo</keyname><forenames>Marcos V. N.</forenames></author></authors><title>A superpixel-driven deep learning approach for the analysis of
  dermatological wounds</title><categories>eess.IV cs.CV cs.LG</categories><doi>10.1016/j.cmpb.2019.105079</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background. The image-based identification of distinct tissues within
dermatological wounds enhances patients' care since it requires no intrusive
evaluations. This manuscript presents an approach, we named QTDU, that combines
deep learning models with superpixel-driven segmentation methods for assessing
the quality of tissues from dermatological ulcers.
  Method. QTDU consists of a three-stage pipeline for the obtaining of ulcer
segmentation, tissues' labeling, and wounded area quantification. We set up our
approach by using a real and annotated set of dermatological ulcers for
training several deep learning models to the identification of ulcered
superpixels.
  Results. Empirical evaluations on 179,572 superpixels divided into four
classes showed QTDU accurately spot wounded tissues (AUC = 0.986, sensitivity =
0.97, and specificity = 0.974) and outperformed machine-learning approaches in
up to 8.2% regarding F1-Score through fine-tuning of a ResNet-based model.
Last, but not least, experimental evaluations also showed QTDU correctly
quantified wounded tissue areas within a 0.089 Mean Absolute Error ratio.
  Conclusions. Results indicate QTDU effectiveness for both tissue segmentation
and wounded area quantification tasks. When compared to existing
machine-learning approaches, the combination of superpixels and deep learning
models outperformed the competitors within strong significant levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06317</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06317</id><created>2019-09-13</created><updated>2019-09-28</updated><authors><author><keyname>Karita</keyname><forenames>Shigeki</forenames></author><author><keyname>Chen</keyname><forenames>Nanxin</forenames></author><author><keyname>Hayashi</keyname><forenames>Tomoki</forenames></author><author><keyname>Hori</keyname><forenames>Takaaki</forenames></author><author><keyname>Inaguma</keyname><forenames>Hirofumi</forenames></author><author><keyname>Jiang</keyname><forenames>Ziyan</forenames></author><author><keyname>Someki</keyname><forenames>Masao</forenames></author><author><keyname>Soplin</keyname><forenames>Nelson Enrique Yalta</forenames></author><author><keyname>Yamamoto</keyname><forenames>Ryuichi</forenames></author><author><keyname>Wang</keyname><forenames>Xiaofei</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author><author><keyname>Yoshimura</keyname><forenames>Takenori</forenames></author><author><keyname>Zhang</keyname><forenames>Wangyou</forenames></author></authors><title>A Comparative Study on Transformer vs RNN in Speech Applications</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted at ASRU 2019</comments><journal-ref>IEEE Automatic Speech Recognition and Understanding Workshop 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence-to-sequence models have been widely used in end-to-end speech
processing, for example, automatic speech recognition (ASR), speech translation
(ST), and text-to-speech (TTS). This paper focuses on an emergent
sequence-to-sequence model called Transformer, which achieves state-of-the-art
performance in neural machine translation and other natural language processing
applications. We undertook intensive studies in which we experimentally
compared and analyzed Transformer and conventional recurrent neural networks
(RNN) in a total of 15 ASR, one multilingual ASR, one ST, and two TTS
benchmarks. Our experiments revealed various training tips and significant
performance benefits obtained with Transformer for each task including the
surprising superiority of Transformer in 13/15 ASR benchmarks in comparison
with RNN. We are preparing to release Kaldi-style reproducible recipes using
open source and publicly available datasets for all the ASR, ST, and TTS tasks
for the community to succeed our exciting outcomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06326</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06326</id><created>2019-09-10</created><authors><author><keyname>Krogue</keyname><forenames>Justin D</forenames></author><author><keyname>Cheng</keyname><forenames>Kaiyang V</forenames></author><author><keyname>Hwang</keyname><forenames>Kevin M</forenames></author><author><keyname>Toogood</keyname><forenames>Paul</forenames></author><author><keyname>Meinberg</keyname><forenames>Eric G</forenames></author><author><keyname>Geiger</keyname><forenames>Erik J</forenames></author><author><keyname>Zaid</keyname><forenames>Musa</forenames></author><author><keyname>McGill</keyname><forenames>Kevin C</forenames></author><author><keyname>Patel</keyname><forenames>Rina</forenames></author><author><keyname>Sohn</keyname><forenames>Jae Ho</forenames></author><author><keyname>Wright</keyname><forenames>Alexandra</forenames></author><author><keyname>Darger</keyname><forenames>Bryan F</forenames></author><author><keyname>Padrez</keyname><forenames>Kevin A</forenames></author><author><keyname>Ozhinsky</keyname><forenames>Eugene</forenames></author><author><keyname>Majumdar</keyname><forenames>Sharmila</forenames></author><author><keyname>Pedoia</keyname><forenames>Valentina</forenames></author></authors><title>Automatic Hip Fracture Identification and Functional Subclassification
  with Deep Learning</title><categories>q-bio.QM cs.CV cs.LG eess.IV physics.med-ph</categories><comments>Presented at Orthopaedic Research Society, Austin, TX, Feb 2, 2019,
  currently in submission for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: Hip fractures are a common cause of morbidity and mortality.
Automatic identification and classification of hip fractures using deep
learning may improve outcomes by reducing diagnostic errors and decreasing time
to operation. Methods: Hip and pelvic radiographs from 1118 studies were
reviewed and 3034 hips were labeled via bounding boxes and classified as
normal, displaced femoral neck fracture, nondisplaced femoral neck fracture,
intertrochanteric fracture, previous ORIF, or previous arthroplasty. A deep
learning-based object detection model was trained to automate the placement of
the bounding boxes. A Densely Connected Convolutional Neural Network (DenseNet)
was trained on a subset of the bounding box images, and its performance
evaluated on a held out test set and by comparison on a 100-image subset to two
groups of human observers: fellowship-trained radiologists and orthopaedists,
and senior residents in emergency medicine, radiology, and orthopaedics.
Results: The binary accuracy for fracture of our model was 93.8% (95% CI,
91.3-95.8%), with sensitivity of 92.7% (95% CI, 88.7-95.6%), and specificity
95.0% (95% CI, 91.5-97.3%). Multiclass classification accuracy was 90.4% (95%
CI, 87.4-92.9%). When compared to human observers, our model achieved at least
expert-level classification under all conditions. Additionally, when the model
was used as an aid, human performance improved, with aided resident performance
approximating unaided fellowship-trained expert performance. Conclusions: Our
deep learning model identified and classified hip fractures with at least
expert-level accuracy, and when used as an aid improved human performance, with
aided resident performance approximating that of unaided fellowship-trained
attendings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06351</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06351</id><created>2019-09-13</created><updated>2019-09-30</updated><authors><author><keyname>Raj</keyname><forenames>Desh</forenames></author><author><keyname>Snyder</keyname><forenames>David</forenames></author><author><keyname>Povey</keyname><forenames>Daniel</forenames></author><author><keyname>Khudanpur</keyname><forenames>Sanjeev</forenames></author></authors><title>Probing the Information Encoded in X-vectors</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted at IEEE Workshop on Automatic Speech Recognition and
  Understanding (ASRU) 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep neural network based speaker embeddings, such as x-vectors, have been
shown to perform well in text-independent speaker recognition/verification
tasks. In this paper, we use simple classifiers to investigate the contents
encoded by x-vector embeddings. We probe these embeddings for information
related to the speaker, channel, transcription (sentence, words, phones), and
meta information about the utterance (duration and augmentation type), and
compare these with the information encoded by i-vectors across a varying number
of dimensions. We also study the effect of data augmentation during extractor
training on the information captured by x-vectors. Experiments on the RedDots
data set show that x-vectors capture spoken content and channel-related
information, while performing well on speaker verification tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06365</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06365</id><created>2019-09-13</created><authors><author><keyname>Weinand</keyname><forenames>Andreas</forenames></author><author><keyname>Sattiraju</keyname><forenames>Raja</forenames></author><author><keyname>Karrenbauer</keyname><forenames>Michael</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Supervised Learning for Physical Layer based Message Authentication in
  URLLC scenarios</title><categories>eess.SP cs.LG</categories><comments>arXiv admin note: text overlap with arXiv:1711.05088</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PHYSEC based message authentication can, as an alternative to conventional
security schemes, be applied within \gls{urllc} scenarios in order to meet the
requirement of secure user data transmissions in the sense of authenticity and
integrity. In this work, we investigate the performance of supervised learning
classifiers for discriminating legitimate transmitters from illegimate ones in
such scenarios. We further present our methodology of data collection using
\gls{sdr} platforms and the data processing pipeline including e.g. necessary
preprocessing steps. Finally, the performance of the considered supervised
learning schemes under different side conditions is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06395</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06395</id><created>2019-09-13</created><authors><author><keyname>Hoppe</keyname><forenames>Elisabeth</forenames></author><author><keyname>Thamm</keyname><forenames>Florian</forenames></author><author><keyname>K&#xf6;rzd&#xf6;rfer</keyname><forenames>Gregor</forenames></author><author><keyname>Syben</keyname><forenames>Christopher</forenames></author><author><keyname>Schirrmacher</keyname><forenames>Franziska</forenames></author><author><keyname>Nittka</keyname><forenames>Mathias</forenames></author><author><keyname>Pfeuffer</keyname><forenames>Josef</forenames></author><author><keyname>Meyer</keyname><forenames>Heiko</forenames></author><author><keyname>Maier</keyname><forenames>Andreas</forenames></author></authors><title>Magnetic Resonance Fingerprinting Reconstruction Using Recurrent Neural
  Networks</title><categories>eess.IV cs.CV</categories><comments>Accepted and presented at the German Medical Data Sciences (GMDS)
  conference 2019 (Dortmund, Germany)</comments><journal-ref>Studies in Health Technology and Informatics [01 Sep 2019,
  267:126-133]</journal-ref><doi>10.3233/SHTI190816</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic Resonance Fingerprinting (MRF) is an imaging technique acquiring
unique time signals for different tissues. Although the acquisition is highly
accelerated, the reconstruction time remains a problem, as the state-of-the-art
template matching compares every signal with a set of possible signals. To
overcome this limitation, deep learning based approaches, e.g. Convolutional
Neural Networks (CNNs) have been proposed. In this work, we investigate the
applicability of Recurrent Neural Networks (RNNs) for this reconstruction
problem, as the signals are correlated in time. Compared to previous methods
based on CNNs, RNN models yield significantly improved results using in-vivo
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06425</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06425</id><created>2019-09-13</created><updated>2019-09-17</updated><authors><author><keyname>Ghasemi</keyname><forenames>Kasra</forenames></author><author><keyname>Sadraddini</keyname><forenames>Sadra</forenames></author><author><keyname>Belta</keyname><forenames>Calin</forenames></author></authors><title>Compositional Synthesis of Decentralized Robust Set-Invariance
  Controllers for Large-scale Linear Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensuring constraint satisfaction in large-scale systems with hard constraints
is vital in many safety critical systems. The challenge is to design
controllers that are efficiently synthesized offline, easily implementable
online, and provide formal correctness guarantees. In this paper, we provide a
method to compute correct-by-construction controllers for a network of coupled
linear systems with additive bounded disturbances such that i) the design of
the controllers is fully compositional - we use an optimization-based approach
that iteratively computes subsystem-level assume-guarantee contracts in the
form of robust control invariant sets; and ii) the controllers are
decentralized hence online implementation requires only the local state
information. We present illustrative examples, including a case study on a
system with 1000 dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06436</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06436</id><created>2019-09-13</created><updated>2019-10-02</updated><authors><author><keyname>Reed</keyname><forenames>Albert</forenames></author><author><keyname>Gerg</keyname><forenames>Isaac</forenames></author><author><keyname>McKay</keyname><forenames>John</forenames></author><author><keyname>Brown</keyname><forenames>Daniel</forenames></author><author><keyname>Williams</keyname><forenames>David</forenames></author><author><keyname>Jayasuriya</keyname><forenames>Suren</forenames></author></authors><title>Coupling Rendering and Generative Adversarial Networks for Artificial
  SAS Image Generation</title><categories>eess.IV cs.CV</categories><comments>10 pages, 9 figures. Submitted to IEEE OCEANS 2019 (Seattle). Updated
  acknowledgements</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acquisition of Synthetic Aperture Sonar (SAS) datasets is bottlenecked by the
costly deployment of SAS imaging systems, and even when data acquisition is
possible,the data is often skewed towards containing barren seafloor rather
than objects of interest. We present a novel pipeline, called SAS GAN, which
couples an optical renderer with a generative adversarial network (GAN) to
synthesize realistic SAS images of targets on the seafloor. This coupling
enables high levels of SAS image realism while enabling control over image
geometry and parameters. We demonstrate qualitative results by presenting
examples of images created with our pipeline. We also present quantitative
results through the use of t-SNE and the Fr\'echet Inception Distance to argue
that our generated SAS imagery potentially augments SAS datasets more
effectively than an off-the-shelf GAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06451</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06451</id><created>2019-09-13</created><authors><author><keyname>Pang</keyname><forenames>Wubin</forenames></author><author><keyname>Brady</keyname><forenames>David J.</forenames></author></authors><title>Distributed Focus and Digital Zoom</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore integrated microcamera focus systems for array cameras. We propose
a new model for system camera integration relying on fast action focus
mechanisms with &gt;10mm aperture. Rather than reducing resolution or expanding
aperture size, such systems can be used in arrays to enable digital zoom. We
show that a common mechanism supports camera modules with focal lengths ranging
from 25 to 60 mm. Designs for each focal length include a fixed objective lens
group and an adjustable back focus group. Increasing the focal power of the
front focal group enables the travel range of available microcamera modules to
accommodate long focal length systems. We present design examples both discrete
and multiscale array camera systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06467</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06467</id><created>2019-09-13</created><authors><author><keyname>Aylor</keyname><forenames>K.</forenames></author><author><keyname>Haq</keyname><forenames>M.</forenames></author><author><keyname>Knox</keyname><forenames>L.</forenames></author><author><keyname>Hezaveh</keyname><forenames>Y.</forenames></author><author><keyname>Perreault-Levasseur</keyname><forenames>L.</forenames></author></authors><title>Cleaning our own Dust: Simulating and Separating Galactic Dust
  Foregrounds with Neural Networks</title><categories>astro-ph.IM eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Separating galactic foreground emission from maps of the cosmic microwave
background (CMB), and quantifying the uncertainty in the CMB maps due to errors
in foreground separation are important for avoiding biases in scientific
conclusions. Our ability to quantify such uncertainty is limited by our lack of
a model for the statistical distribution of the foreground emission. Here we
use a Deep Convolutional Generative Adversarial Network (DCGAN) to create an
effective non-Gaussian statistical model for intensity of emission by
interstellar dust. For training data we use a set of dust maps inferred from
observations by the Planck satellite. A DCGAN is uniquely suited for such
unsupervised learning tasks as it can learn to model a complex non-Gaussian
distribution directly from examples. We then use these simulations to train a
second neural network to estimate the underlying CMB signal from
dust-contaminated maps. We discuss other potential uses for the trained DCGAN,
and the generalization to polarized emission from both dust and synchrotron.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06470</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06470</id><created>2019-09-13</created><authors><author><keyname>Nikshi</keyname><forenames>Walelign</forenames></author><author><keyname>Hoover</keyname><forenames>Randy C.</forenames></author><author><keyname>Bedillion</keyname><forenames>Mark D.</forenames></author><author><keyname>Shahmiri</keyname><forenames>Saeed</forenames></author><author><keyname>Simmons</keyname><forenames>Jeremy</forenames></author></authors><title>Fuzzy Logic Control for Mixed conventional/braking Actuation Mobile
  Robots</title><categories>eess.SY cs.SY</categories><comments>29 pages 29 images, journal paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of conventional actuators in robotic systems (electric motors in
particular), while often offering advantages in terms of flexibility and
controllability, suffer from primary actuator failure,due to unexpected
complexities in their environment, which can lead to loss of controllability.
Conventional actuators can impose disadvantages on mechanical complexity,
weight, and cost. Here,the Mixed conventional/braking Actuation Mobile Robot
(MAMR), a new mobile robot platform,is proposed to tackle such drawbacks in
actuation and explore the use and control of braking actuation. This platform
substitutes the drive motors used in Ackermann steering with brakes that have
only two states, ON and OFF. Additionally, the conventional drive wheels are
replaced by a single,omni-directional wheel that only supports a driving force
in the robots longitudinal direction. The ability of braking actuators in
providing controllability under actuator failure is one of the primary
motivations of this work. To validate the reliability and accuracy of MAMR
approach, this paper studies the design of such robotic systems, the design and
synthesis of fuzzy logic controllers along with the experimental assessments of
these controllers in real-time. The experimental tests point out the controller
performance enhancement using fuzzy logic controllers and MAMR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06473</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06473</id><created>2019-09-13</created><updated>2019-12-01</updated><authors><author><keyname>Herrmann</keyname><forenames>Felix J.</forenames></author><author><keyname>Siahkoohi</keyname><forenames>Ali</forenames></author><author><keyname>Rizzuti</keyname><forenames>Gabrio</forenames></author></authors><title>Learned imaging with constraints and uncertainty quantification</title><categories>eess.IV cs.LG physics.geo-ph stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We outline new approaches to incorporate ideas from deep learning into
wave-based least-squares imaging. The aim, and main contribution of this work,
is the combination of handcrafted constraints with deep convolutional neural
networks, as a way to harness their remarkable ease of generating natural
images. The mathematical basis underlying our method is the
expectation-maximization framework, where data are divided in batches and
coupled to additional &quot;latent&quot; unknowns. These unknowns are pairs of elements
from the original unknown space (but now coupled to a specific data batch) and
network inputs. In this setting, the neural network controls the similarity
between these additional parameters, acting as a &quot;center&quot; variable. The
resulting problem amounts to a maximum-likelihood estimation of the network
parameters when the augmented data model is marginalized over the latent
variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06474</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06474</id><created>2019-09-13</created><updated>2019-09-30</updated><authors><author><keyname>Mei</keyname><forenames>Wenjun</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author><author><keyname>Chen</keyname><forenames>Ge</forenames></author><author><keyname>D&#xf6;rfler</keyname><forenames>Florian</forenames></author></authors><title>Occam's Razor in Opinion Dynamics: The Weighted-Median Influence Process</title><categories>cs.SI cs.SY eess.SY math.DS</categories><msc-class>91C99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays public opinion formation is deeply influenced by social networks and
faces unprecedented challenges such as opinion radicalization, echo chambers,
and ideologization of public debates. Mathematical modeling of opinion dynamics
plays a fundamental role in understanding the microscopic mechanisms of social
interactions behind these macroscopic phenomena. The weighted-averaging opinion
update is arguably the most widely adopted microscopic mechanism for opinion
dynamics. However, such models based on weighted averaging are restricted in
their predictive power and limited to stylized continuous opinion spectra. Here
we point out that these models' limitation in predictability is not due to the
lack of complexity, but because the weighted-averaging mechanism itself
features a non-negligible unrealistic implication. By resolving this
unrealistic feature in the framework of cognitive dissonance theory, we propose
a novel opinion dynamics model based on a weighted-median mechanism instead.
Surprisingly, such an inconspicuous change in microscopic mechanism leads to
dramatic macroscopic consequences. In the spirit of Occam's razor, our new
model, despite its simplicity in form, exhibits a sophisticated
consensus-disagreement phase transition depending on the influence network
structure. Our model gives perhaps the simplest answers to various open
problems in sociology and political science, such as the connection between
social marginalization and opinion radicalization, the mechanism for echo
chambers, and the formation of multipolar opinion distributions. Remarkably,
the weighted-median opinion dynamics are the first model applicable to ordered
multiple-choice issues, which are prevalent in modern-day public debates and
elections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06478</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06478</id><created>2019-09-13</created><authors><author><keyname>Nikshi</keyname><forenames>Walelign</forenames></author><author><keyname>Hoover</keyname><forenames>Randy C.</forenames></author><author><keyname>Bedillion</keyname><forenames>Mark D.</forenames></author><author><keyname>Shahmiri</keyname><forenames>Saeed</forenames></author><author><keyname>Simmons</keyname><forenames>Jeremy</forenames></author></authors><title>Sliding Mode Control for Mixed Conventional/Braking Actuation Mobile
  Robots</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Mixed convention/braking Actuation Mobile Robot (MAMR) was designed to
tackle some of the drawbacks of conventional mobile robots such as losing
controllability due to primary actuator failures, mechanical complexity,
weight, and cost. It replaces conventional steering wheels with braking
actuators and conventional drive wheels with a single omni-directional wheel.
This makes it fall under the category of under-actuated mobile robots. The
brakes have only two states, ON and OFF, resulting in discontinuous dynamics.
This inspires the use of a discontinuous control law to control the system.
This work presents a Sliding Mode Controller (SMC) design to park the MAMR
system from a given initial configuration to a desired final configuration.
Experimental results are presented to validate the parking control of the MAMR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06482</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06482</id><created>2019-09-13</created><authors><author><keyname>Yan</keyname><forenames>Hanfei</forenames></author></authors><title>Ptychographic phase-retrieval by proximal algorithms</title><categories>eess.IV physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a set of ptychography phase-retrieval iterative engines based on
proximal algorithms originally developed in convex optimization theory, and
discuss their connections with existing ones. The use of proximal operator
creates a simple frame work that allows us to incorporate the effect of noise
from a maximum-likelihood principle. We focus on three particular algorithms,
namely proximal minimization, alternating direction method of multiplier and
accelerated proximal gradient, and benckmark their performance with numerical
simulations and experimental x-ray data. Among them, accelerated proximal
gradient shows superior performance in terms of both accuracy and convergence
rate for a noisy dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06486</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06486</id><created>2019-09-13</created><updated>2019-09-28</updated><authors><author><keyname>Lu</keyname><forenames>Ping</forenames></author></authors><title>Deep Learning Realm for Geophysics: Seismic Acquisition, Processing,
  Interpretation, and Inversion</title><categories>physics.geo-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applying deep-learning models to geophysical applications has attracted
special attentions during the past a couple of years. There are several papers
published in this domain involving with different topics primarily focusing on
synthetic data. Based on the presented results, reaching the satisfaction from
geophysicists is largely far away the performance of the conventional
algorithms. Moreover, it is extremely hard to find documents with detailed
illustrations about what are the best practices that researchers should follow
regarding how to design appropriate deep-learning models to effectively and
precisely tackle problems relevant to the field data. This paper serves as a
summarization to demonstrate successful stories and share with extensive
experiences we have gained during past several years in the process of
designing and deploying of deep-learning models to the geophysical projects in
a large scale. Four different disciplines are discussed individually with
seismic acquisition, processing, interpretation, and inversion. Finally,
special attentions about designing an effective deep-neural-networks especially
for geophysics are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06492</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06492</id><created>2019-09-13</created><authors><author><keyname>Varasteh</keyname><forenames>Morteza</forenames></author><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Clerckx</keyname><forenames>Bruno</forenames></author></authors><title>Learning to Communicate and Energize: Modulation, Coding and Multiple
  Access Designs for Wireless Information-Power Transmission</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The explosion of the number of low-power devices in the next decades calls
for a re-thinking of wireless network design, namely, unifying wireless
transmission of information and power so as to make the best use of the RF
spectrum, radiation, and infrastructure for the dual purpose of communicating
and energizing. This paper provides a novel learning-based approach towards
such wireless network design. To that end, a parametric model of a practical
energy harvester, accounting for various sources of nonlinearities, is proposed
using a nonlinear regression algorithm applied over collected real data.
Relying on the proposed model, the learning problem of modulation design for
Simultaneous Wireless Information-Power Transmission (SWIPT) over a
point-to-point link is studied. Joint optimization of the transmitter and the
receiver is implemented using Neural Network (NN)-based autoencoders. The
results reveal that by increasing the receiver power demand, the baseband
transmit modulation constellation converges to an On-Off keying signalling.
Utilizing the observations obtained via learning, an algorithmic SWIPT
modulation design is proposed. It is observed via numerical results that the
performance loss of the proposed modulations are negligible compared to the
ones obtained from learning. Extension of the studied problem to learning
modulation design for multi-user SWIPT scenarios and coded modulation design
for point-to-point SWIPT are considered. The major conclusion of this work is
to utilize learning-based results to design non learning-based algorithms,
which perform as well. In particular, inspired by the results obtained via
learning, an algorithmic approach for coded modulation design is proposed,
which performs very close to its learning counterparts, and is significantly
superior due to its high real-time adaptability to new system design
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06493</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06493</id><created>2019-09-13</created><authors><author><keyname>Koch</keyname><forenames>William</forenames></author></authors><title>Flight Controller Synthesis Via Deep Reinforcement Learning</title><categories>cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML</categories><comments>206 pages, PhD Dissertation</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Traditional control methods are inadequate in many deployment settings
involving control of Cyber-Physical Systems (CPS). In such settings, CPS
controllers must operate and respond to unpredictable interactions, conditions,
or failure modes. Dealing with such unpredictability requires the use of
executive and cognitive control functions that allow for planning and
reasoning. Motivated by the sport of drone racing, this dissertation addresses
these concerns for state-of-the-art flight control by investigating the use of
deep neural networks to bring essential elements of higher-level cognition for
constructing low level flight controllers.
  This thesis reports on the development and release of an open source, full
solution stack for building neuro-flight controllers. This stack consists of
the methodology for constructing a multicopter digital twin for synthesize the
flight controller unique to a specific aircraft, a tuning framework for
implementing training environments (GymFC), and a firmware for the world's
first neural network supported flight controller (Neuroflight). GymFC's novel
approach fuses together the digital twinning paradigm for flight control
training to provide seamless transfer to hardware. Additionally, this thesis
examines alternative reward system functions as well as changes to the software
environment to bridge the gap between the simulation and real world deployment
environments.
  Work summarized in this thesis demonstrates that reinforcement learning is
able to be leveraged for training neural network controllers capable, not only
of maintaining stable flight, but also precision aerobatic maneuvers in real
world settings. As such, this work provides a foundation for developing the
next generation of flight control systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06506</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06506</id><created>2019-09-13</created><authors><author><keyname>Savla</keyname><forenames>Ketan</forenames></author><author><keyname>Shamma</keyname><forenames>Jeff S.</forenames></author><author><keyname>Dahleh</keyname><forenames>Munther A.</forenames></author></authors><title>Network Effects on Robustness of Dynamic Systems</title><categories>eess.SY cs.SY math.OC</categories><comments>To appear in Annual Review of Control, Robotics, and Autonomous
  Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review selected results related to robustness of networked systems in
finite and asymptotically large size regimes, under static and dynamical
settings. In the static setting, within the framework of flow over finite
networks, we discuss the effect of physical constraints on robustness to loss
in link capacities. In the dynamical setting, we review several settings in
which small gain type analysis provides tight robustness guarantees for linear
dynamics over finite networks towards worst-case and stochastic disturbances.
We also discuss network flow dynamic settings where nonlinear techniques
facilitate in understanding the effect on robustness of constraints on capacity
and information, substituting information with control action, and cascading
failure. We also contrast the latter with a representative contagion model. For
asymptotically large networks, we discuss the role of network properties in
connecting microscopic shocks to emergent macroscopic fluctuations under linear
dynamics as well as for economic networks at equilibrium. Through the review of
these results, the paper aims to achieve two objectives. First, to highlight
selected settings in which the role of interconnectivity structure of a network
on its robustness is well-understood. Second, to highlight a few additional
settings in which existing system theoretic tools give tight robustness
guarantees, and which are also appropriate avenues for future network-theoretic
investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06507</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06507</id><created>2019-09-13</created><authors><author><keyname>Paudel</keyname><forenames>Santosh</forenames></author><author><keyname>Shrestha</keyname><forenames>Ajay Kumar</forenames></author><author><keyname>Maharjan</keyname><forenames>Pradip Singh</forenames></author><author><keyname>Rijal</keyname><forenames>Rameshwar</forenames></author></authors><title>Performance Analysis of Spatial and Transform Filters for Efficient
  Image Noise Reduction</title><categories>eess.IV cs.LG</categories><comments>7 pages, 7 figures, 3 tables, conference &quot;for associated conference
  file, see
  http://https://www.researchgate.net/publication/291974499_Performance_Analysis_of_Spatial_and_Transform_Filters_for_Efficient_Image_Noise_Reduction&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the acquisition of an image from its source, noise always becomes an
integral part of it. Various algorithms have been used in past to denoise the
images. Image denoising still has scope for improvement. Visual information
transmitted in the form of digital images has become a considerable method of
communication in the modern age, but the image obtained after the transmission
is often corrupted due to noise. In this paper, we review the existing
denoising algorithms such as filtering approach and wavelets based approach and
then perform their comparative study with bilateral filters. We use different
noise models to describe additive and multiplicative noise in an image. Based
on the samples of degraded pixel neighbourhoods as inputs, the output of an
efficient filtering approach has shown a better image denoising performance.
This yields promising qualitative and quantitative results of the degraded
noisy images in terms of Peak Signal to Noise Ratio, Mean Square Error and
Universal Quality Identifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06515</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06515</id><created>2019-09-13</created><updated>2019-10-22</updated><authors><author><keyname>Pino</keyname><forenames>Juan</forenames></author><author><keyname>Puzon</keyname><forenames>Liezl</forenames></author><author><keyname>Gu</keyname><forenames>Jiatao</forenames></author><author><keyname>Ma</keyname><forenames>Xutai</forenames></author><author><keyname>McCarthy</keyname><forenames>Arya D.</forenames></author><author><keyname>Gopinath</keyname><forenames>Deepak</forenames></author></authors><title>Harnessing Indirect Training Data for End-to-End Automatic Speech
  Translation: Tricks of the Trade</title><categories>cs.CL cs.SD eess.AS</categories><comments>IWSLT 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For automatic speech translation (AST), end-to-end approaches are
outperformed by cascaded models that transcribe with automatic speech
recognition (ASR), then translate with machine translation (MT). A major cause
of the performance gap is that, while existing AST corpora are small, massive
datasets exist for both the ASR and MT subsystems. In this work, we evaluate
several data augmentation and pretraining approaches for AST, by comparing all
on the same datasets. Simple data augmentation by translating ASR transcripts
proves most effective on the English--French augmented LibriSpeech dataset,
closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong
cascade that could directly utilize copious ASR and MT data. The same
end-to-end approach plus fine-tuning closes the gap on the English--Romanian
MuST-C dataset from 6.7 to 3.7 BLEU. In addition to these results, we present
practical recommendations for augmentation and pretraining approaches. Finally,
we decrease the performance gap to 0.01 BLEU using a Transformer-based
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06522</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06522</id><created>2019-09-13</created><authors><author><keyname>Liu</keyname><forenames>Chunxi</forenames></author><author><keyname>Zhang</keyname><forenames>Qiaochu</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaohui</forenames></author><author><keyname>Singh</keyname><forenames>Kritika</forenames></author><author><keyname>Saraf</keyname><forenames>Yatharth</forenames></author><author><keyname>Zweig</keyname><forenames>Geoffrey</forenames></author></authors><title>Multilingual ASR with Massive Data Augmentation</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Towards developing high-performing ASR for low-resource languages, approaches
to address the lack of resources are to make use of data from multiple
languages, and to augment the training data by creating acoustic variations. In
this work we present a single grapheme-based ASR model learned on 7
geographically proximal languages, using standard hybrid BLSTM-HMM acoustic
models with lattice-free MMI objective. We build the single ASR grapheme set
via taking the union over each language-specific grapheme set, and we find such
multilingual ASR model can perform language-independent recognition on all 7
languages, and substantially outperform each monolingual ASR model. Secondly,
we evaluate the efficacy of multiple data augmentation alternatives within
language, as well as their complementarity with multilingual modeling. Overall,
we show that the proposed multilingual ASR with various data augmentation can
not only recognize any within training set languages, but also provide large
ASR performance improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06532</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06532</id><created>2019-09-14</created><authors><author><keyname>Luong</keyname><forenames>Hieu-Thi</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author></authors><title>Bootstrapping non-parallel voice conversion from speaker-adaptive
  text-to-speech</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>Accepted for IEEE ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice conversion (VC) and text-to-speech (TTS) are two tasks that share a
similar objective, generating speech with a target voice. However, they are
usually developed independently under vastly different frameworks. In this
paper, we propose a methodology to bootstrap a VC system from a pretrained
speaker-adaptive TTS model and unify the techniques as well as the
interpretations of these two tasks. Moreover by offloading the heavy data
demand to the training stage of the TTS model, our VC system can be built using
a small amount of target speaker speech data. It also opens up the possibility
of using speech in a foreign unseen language to build the system. Our
subjective evaluations show that the proposed framework is able to not only
achieve competitive performance in the standard intra-language scenario but
also adapt and convert using speech utterances in an unseen language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06536</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06536</id><created>2019-09-14</created><authors><author><keyname>Ghazijahani</keyname><forenames>Hamed Alizadeh</forenames></author><author><keyname>Seyedarabi</keyname><forenames>Hadi</forenames></author><author><keyname>Niya</keyname><forenames>Javad Musevi</forenames></author><author><keyname>Cheung</keyname><forenames>Ngai-Man</forenames></author></authors><title>Optimized Routing and Spectrum Assignment for Video Communication over
  an Elastic Optical Network</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Elastic optical network (EON) efficiently utilize spectral resources for
optical fiber communication by allocating the minimum necessary bandwidth to
client demands. On the other hand, network traffic has been continuously
increasing due to the wide penetration of video streaming services, so the
efficient and cost-effective use of available bandwidth plays an important role
in improving service provisioning. In this work, we formulate and solve an
optimization problem to perform routing and spectrum assignment (RSA) in EON
with focus on video streaming. In this formulation, EON and video constraints
such as spectrum fragmentation and received video quality are considered
jointly. In this way, we utilize a machine learning (ML) technique to estimate
the video quality versus channel state. The proposed algorithm is evaluated
over two benchmarks fiber-optic network, namely NSFNET and US-backbone using
numerical simulations based on random traffic models. The results reveal that
the mean optical signal-to-noise ratio (OSNR) for video content data in the
receiver is remarkably higher than in non-video data. This is while the
blocking ratio is the same for both data types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06539</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06539</id><created>2019-09-14</created><updated>2019-09-29</updated><authors><author><keyname>Bussola</keyname><forenames>Nicole</forenames></author><author><keyname>Marcolini</keyname><forenames>Alessia</forenames></author><author><keyname>Maggio</keyname><forenames>Valerio</forenames></author><author><keyname>Jurman</keyname><forenames>Giuseppe</forenames></author><author><keyname>Furlanello</keyname><forenames>Cesare</forenames></author></authors><title>Not again! Data Leakage in Digital Pathology</title><categories>q-bio.QM eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bioinformatics of high throughput omics data (e.g. microarrays and
proteomics) has been plagued by uncountable issues with reproducibility at the
start of the century. Concerns have motivated international initiatives such as
the FDA's led MAQC Consortium, addressing reproducibility of predictive
biomarkers by means of appropriate Data Analysis Plans (DAPs). For instance,
repreated cross-validation is a standard procedure meant at mitigating the risk
that information from held-out validation data may be used during model
selection. We prove here that, many years later, Data Leakage can still be a
non-negligible overfitting source in deep learning models for digital
pathology. In particular, we evaluate the impact of (i) the presence of
multiple images for each subject in histology collections; (ii) the systematic
adoption of training over collection of subregions (i.e. &quot;tiles&quot; or &quot;patches&quot;)
extracted for the same subject. We verify that accuracy scores may be inflated
up to 41%, even if a well-designed 10x5 iterated cross-validation DAP is
applied, unless all images from the same subject are kept together either in
the internal training or validation splits. Results are replicated for 4
classification tasks in digital pathology on 3 datasets, for a total of 373
subjects, and 543 total slides (around 27, 000 tiles). Impact of applying
transfer learning strategies with models pre-trained on general-purpose or
digital pathology datasets is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06567</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06567</id><created>2019-09-14</created><authors><author><keyname>Miao</keyname><forenames>Jifei</forenames></author><author><keyname>Kou</keyname><forenames>Kit Ian</forenames></author></authors><title>Color image recovery using low-rank quaternion matrix completion
  algorithm</title><categories>math.NA cs.NA eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a new color image representation tool, quaternion has achieved excellent
results in color image processing problems. In this paper, we propose a novel
low-rank quaternion matrix completion algorithm to recover missing data of
color image. Motivated by two kinds of low-rank approximation approaches
(low-rank decomposition and nuclear norm minimization) in traditional
matrix-based methods, we combine the two approaches in our quaternion
matrix-based model. Furthermore, the nuclear norm of the quaternion matrix is
replaced by the sum of Frobenius norm of its two low-rank factor quaternion
matrices. Based on the relationship between quaternion matrix and its
equivalent complex matrix, the problem eventually is converted from quaternion
number field to complex number field. An alternating minimization method is
applied to solve the model. Simulation results on real world color image
recovery show the superior performance and efficiency of the proposed algorithm
over some state-of-the-art tensor-based ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06591</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06591</id><created>2019-09-14</created><updated>2019-12-30</updated><authors><author><keyname>Sun</keyname><forenames>Yi</forenames></author><author><keyname>Han</keyname><forenames>Xushen</forenames></author><author><keyname>Sun</keyname><forenames>Kai</forenames></author><author><keyname>Li</keyname><forenames>Boren</forenames></author><author><keyname>Chen</keyname><forenames>Yongjiang</forenames></author><author><keyname>Li</keyname><forenames>Mingyang</forenames></author></authors><title>Sem-LSD: A Learning-based Semantic Line Segment Detector</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduces a new type of line-shaped image representation,
named semantic line segment (Sem-LS) and focus on solving its detection
problem. Sem-LS contains high-level semantics and is a compact scene
representation where only visually salient line segments with stable semantics
are preserved. Combined with high-level semantics, Sem-LS is more robust under
cluttered environment compared with existing line-shaped representations. The
compactness of Sem-LS facilitates its use in large-scale applications, such as
city-scale SLAM (simultaneously localization and mapping) and LCD (loop closure
detection). Sem-LS detection is a challenging task due to its significantly
different appearance from existing learning-based image representations such as
wireframes and objects. For further investigation, we first label Sem-LS on two
well-known datasets, KITTI and KAIST URBAN, as new benchmarks. Then, we propose
a learning-based Sem-LS detector (Sem-LSD) and devise new module as well as
metrics to address unique challenges in Sem-LS detection. Experimental results
have shown both the efficacy and efficiency of Sem-LSD. Finally, the
effectiveness of the proposed Sem-LS is supported by two experiments on
detector repeatability and a city-scale LCD problem. Labeled datasets and code
will be released shortly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06600</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06600</id><created>2019-09-14</created><authors><author><keyname>Nuradha</keyname><forenames>Theshani</forenames></author><author><keyname>Hemachandra</keyname><forenames>Kasun T.</forenames></author><author><keyname>Samarasinghe</keyname><forenames>Tharaka</forenames></author><author><keyname>Atapattu</keyname><forenames>Saman</forenames></author></authors><title>Physical-Layer Security for Untrusted UAV-Assisted Full-Duplex Wireless
  Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper considers physical layer security (PLS) of an untrusted unmanned
aerial vehicle (UAV) network, where a multitude of UAVs communicate in
full-duplex (FD) mode. A source-based jamming (SBJ) scheme is exploited for
secure communication without utilizing any external jammers. Firstly, the
optimal power allocation between the confidential signal and the jamming signal
is derived to maximize the secrecy rate of each link between the source and the
destination. Then, the best UAV selection scheme is proposed to maximize the
overall secrecy rate of the network. The corresponding secrecy outage
probability (SOP) and the average secrecy rate (ASR) of the network are
analyzed based on the proposed UAV selection and the optimal power allocation
schemes. Asymptotic results are also obtained to derive the achievable
diversity order. Results are validated through numerical evaluations while
providing useful network design insights such as locations and altitudes of the
UAVs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06604</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06604</id><created>2019-09-14</created><authors><author><keyname>Quan</keyname><forenames>Kin</forenames></author><author><keyname>Shipley</keyname><forenames>Rebecca J.</forenames></author><author><keyname>Tanno</keyname><forenames>Ryutaro</forenames></author><author><keyname>McPhillips</keyname><forenames>Graeme</forenames></author><author><keyname>Vavourakis</keyname><forenames>Vasileios</forenames></author><author><keyname>Edwards</keyname><forenames>David</forenames></author><author><keyname>Jacob</keyname><forenames>Joseph</forenames></author><author><keyname>Hurst</keyname><forenames>John R.</forenames></author><author><keyname>Hawkes</keyname><forenames>David J.</forenames></author></authors><title>Tapering Analysis of Airways with Bronchiectasis</title><categories>eess.IV cs.CV physics.med-ph q-bio.QM</categories><comments>12 pages, 7 figures. Previously submitted for SPIE Medical Imaging,
  2018, Houston, Texas, United States</comments><journal-ref>Proc. SPIE 10574, Medical Imaging 2018: Image Processing, 105742G
  (2 March 2018)</journal-ref><doi>10.1117/12.2292306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bronchiectasis is the permanent dilation of airways. Patients with the
disease can suffer recurrent exacerbations, reducing their quality of life. The
gold standard to diagnose and monitor bronchiectasis is accomplished by
inspection of chest computed tomography (CT) scans. A clinician examines the
broncho-arterial ratio to determine if an airway is brochiectatic. The visual
analysis assumes the blood vessel diameter remains constant, although this
assumption is disputed in the literature. We propose a simple measurement of
tapering along the airways to diagnose and monitor bronchiectasis. To this end,
we constructed a pipeline to measure the cross-sectional area along the airways
at contiguous intervals, starting from the carina to the most distal point
observable. Using a phantom with calibrated 3D printed structures, the
precision and accuracy of our algorithm extends to the sub voxel level. The
tapering measurement is robust to bifurcations along the airway and was applied
to chest CT images acquired in clinical practice. The result is a statistical
difference in tapering rate between airways with bronchiectasis and controls.
Our code is available at https://github.com/quan14/AirwayTaperingInCT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06614</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06614</id><created>2019-09-14</created><updated>2019-10-01</updated><authors><author><keyname>Li</keyname><forenames>Qiujia</forenames></author><author><keyname>Zhang</keyname><forenames>Chao</forenames></author><author><keyname>Woodland</keyname><forenames>Philip C.</forenames></author></authors><title>Integrating Source-channel and Attention-based Sequence-to-sequence
  Models for Speech Recognition</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>To appear in Proc. ASRU2019, December 14-18, 2019, Sentosa, Singapore</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel automatic speech recognition (ASR) framework
called Integrated Source-Channel and Attention (ISCA) that combines the
advantages of traditional systems based on the noisy source-channel model (SC)
and end-to-end style systems using attention-based sequence-to-sequence models.
The traditional SC system framework includes hidden Markov models and
connectionist temporal classification (CTC) based acoustic models, language
models (LMs), and a decoding procedure based on a lexicon, whereas the
end-to-end style attention-based system jointly models the whole process with a
single model. By rescoring the hypotheses produced by traditional systems using
end-to-end style systems based on an extended noisy source-channel model, ISCA
allows structured knowledge to be easily incorporated via the SC-based model
while exploiting the complementarity of the attention-based model. Experiments
on the AMI meeting corpus show that ISCA is able to give a relative word error
rate reduction up to 21% over an individual system, and by 13% over an
alternative method which also involves combining CTC and attention-based
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06629</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06629</id><created>2019-09-14</created><updated>2019-09-17</updated><authors><author><keyname>He</keyname><forenames>Zhou</forenames></author><author><keyname>Bao</keyname><forenames>Siqi</forenames></author><author><keyname>Chung</keyname><forenames>Albert</forenames></author></authors><title>3D Deep Affine-Invariant Shape Learning for Brain MR Image Segmentation</title><categories>eess.IV cs.CV</categories><comments>Accepted to 2018 MICCAI DLMIA, published at Deep Learning in Medical
  Image Analysis and Multimodal Learning for Clinical Decision Support</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advancements in medical image segmentation techniques have achieved
compelling results. However, most of the widely used approaches do not take
into account any prior knowledge about the shape of the biomedical structures
being segmented. More recently, some works have presented approaches to
incorporate shape information. However, many of them are indeed introducing
more parameters to the segmentation network to learn the general features,
which any segmentation network is able learn, instead of specifically shape
features. In this paper, we present a novel approach that seamlessly integrates
the shape information into the segmentation network. Experiments on human brain
MRI segmentation demonstrate that our approach can achieve a lower Hausdorff
distance and higher Dice coefficient than the state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06654</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06654</id><created>2019-09-14</created><authors><author><keyname>Pons</keyname><forenames>Jordi</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>musicnn: Pre-trained convolutional neural networks for music audio
  tagging</title><categories>cs.SD cs.CL eess.AS</categories><comments>Accepted to be presented at the Late-Breaking/Demo session of ISMIR
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pronounced as &quot;musician&quot;, the musicnn library contains a set of pre-trained
musically motivated convolutional neural networks for music audio tagging:
https://github.com/jordipons/musicnn. This repository also includes some
pre-trained vgg-like baselines. These models can be used as out-of-the-box
music audio taggers, as music feature extractors, or as pre-trained models for
transfer learning.
  We also provide the code to train the aforementioned models:
https://github.com/jordipons/musicnn-training. This framework also allows
implementing novel models. For example, a musically motivated convolutional
neural network with an attention-based output layer (instead of the temporal
pooling layer) can achieve state-of-the-art results for music audio tagging:
90.77 ROC-AUC / 38.61 PR-AUC on the MagnaTagATune dataset --- and 88.81 ROC-AUC
/ 31.51 PR-AUC on the Million Song Dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06655</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06655</id><created>2019-09-14</created><authors><author><keyname>Maeng</keyname><forenames>Sung Joon</forenames></author><author><keyname>Deshmukh</keyname><forenames>Mrugen</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Bhuyan</keyname><forenames>Arupjyoti</forenames></author></authors><title>Interference Mitigation Scheme in 3D Topology IoT Network with Antenna
  Radiation Pattern</title><categories>eess.SP</categories><doi>10.1109/VTCFall.2019.8891323</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet of things (IoT) is one of main paradigms for 5G wireless systems.
Due to high connection density, interference from other sources is a key
problem in IoT networks. Especially, it is more difficult to find a solution to
manage interference in uncoordinated networks than coordinated system. In this
work, we consider 3D topology of uncoordinated IoT network and propose
interference mitigation scheme with respect to 3D antenna radiation pattern. In
2D topology network, the radiation pattern of dipole antenna can be assumed as
onmi-directional. We show the variance of antenna gain on dipole antenna in 3D
topology, consider the simultaneous use of three orthogonal dipole antennas,
and compare the system performance depending on different antenna
configurations. Our simulation results show that proper altitude of IoT devices
can extensively improve the system performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06669</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06669</id><created>2019-09-14</created><updated>2019-12-27</updated><authors><author><keyname>Hashim</keyname><forenames>Hashim A.</forenames></author></authors><title>Special Orthogonal Group SO(3), Euler Angles, Angle-axis, Rodriguez
  Vector and Unit-Quaternion: Overview, Mapping and Challenges</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The attitude of a rigid-body in the three dimensional space has a unique and
global definition on the Special Orthogonal Group SO (3). This paper gives an
overview of the rotation matrix, attitude kinematics and parameterization. The
four most frequently used methods of attitude representations are discussed
with detailed derivations, namely Euler angles, angle-axis parameterization,
Rodriguez vector, and unit-quaternion. The mapping from one representation to
others including SO (3) is given. Also, important results which could be useful
for the process of filter and/or control design are given. The main weaknesses
of attitude parameterization using Euler angles, angle-axis parameterization,
Rodriguez vector, and unit-quaternion are illustrated. Keywords: Special
Orthogonal Group 3, Euler angles, Angle-axis, Rodriguez Vector,
Unit-quaternion, SO(3), Mapping, Parameterization, Attitude, Control, Filter,
Observer, Estimator, Rotation, Rotational matrix, Transformation matrix,
Orientation, Transformation, Roll, Pitch, Yaw, Quad-rotor, Unmanned aerial
vehicle, Robot, spacecraft, satellite, UAV, Underwater vehicle, autonomous,
system, Pose, literature review, survey, overview, comparison, comparative
study, body frame, identity, origin, dynamics, kinematics, Lie group, inertial
frame, zero, filter, control, estimate, observation, measurement, 3D, three
dimensional space, advantage, disadvantage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06678</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06678</id><created>2019-09-14</created><authors><author><keyname>Sim</keyname><forenames>Khe Chai</forenames></author><author><keyname>Zadrazil</keyname><forenames>Petr</forenames></author><author><keyname>Beaufays</keyname><forenames>Fran&#xe7;oise</forenames></author></authors><title>An Investigation Into On-device Personalization of End-to-end Automatic
  Speech Recognition Models</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker-independent speech recognition systems trained with data from many
users are generally robust against speaker variability and work well for a
large population of speakers. However, these systems do not always generalize
well for users with very different speech characteristics. This issue can be
addressed by building personalized systems that are designed to work well for
each specific user. In this paper, we investigate the idea of securely training
personalized end-to-end speech recognition models on mobile devices so that
user data and models never leave the device and are never stored on a server.
We study how the mobile training environment impacts performance by simulating
on-device data consumption. We conduct experiments using data collected from
speech impaired users for personalization. Our results show that
personalization achieved 63.7\% relative word error rate reduction when trained
in a server environment and 58.1% in a mobile environment. Moving to on-device
personalization resulted in 18.7% performance degradation, in exchange for
improved scalability and data privacy. To train the model on device, we split
the gradient computation into two and achieved 45% memory reduction at the
expense of 42% increase in training time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06684</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06684</id><created>2019-09-14</created><authors><author><keyname>Myronenko</keyname><forenames>Andriy</forenames></author><author><keyname>Hatamizadeh</keyname><forenames>Ali</forenames></author></authors><title>3D Kidneys and Kidney Tumor Semantic Segmentation using Boundary-Aware
  Networks</title><categories>eess.IV cs.CV cs.LG</categories><comments>Manuscript of MICCAI Kidney Tumor Segmentation Challenge 2019</comments><journal-ref>MICCAI Kidney Tumor Segmentation Challenge 2019</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Automated segmentation of kidneys and kidney tumors is an important step in
quantifying the tumor's morphometrical details to monitor the progression of
the disease and accurately compare decisions regarding the kidney tumor
treatment. Manual delineation techniques are often tedious, error-prone and
require expert knowledge for creating unambiguous representation of kidneys and
kidney tumors segmentation. In this work, we propose an end-to-end boundary
aware fully Convolutional Neural Networks (CNNs) for reliable kidney and kidney
tumor semantic segmentation from arterial phase abdominal 3D CT scans. We
propose a segmentation network consisting of an encoder-decoder architecture
that specifically accounts for organ and tumor edge information by devising a
dedicated boundary branch supervised by edge-aware loss terms. We have
evaluated our model on 2019 MICCAI KiTS Kidney Tumor Segmentation Challenge
dataset and our method has achieved dice scores of 0.9742 and 0.8103 for kidney
and tumor repetitively and an overall composite dice score of 0.8923.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06685</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06685</id><created>2019-09-14</created><authors><author><keyname>Gaasedelen</keyname><forenames>Erik</forenames></author><author><keyname>Deakyne</keyname><forenames>Alex</forenames></author><author><keyname>Iaizzo</keyname><forenames>Paul</forenames></author></authors><title>Automated Multiclass Cardiac Volume Segmentation and Model Generation</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Many strides have been made in semantic segmentation of multiple classes
within an image. This has been largely due to advancements in deep learning and
convolutional neural networks (CNNs). Features within a CNN are automatically
learned during training, which allows for the abstraction of semantic
information within the images. These deep learning models are powerful enough
to handle the segmentation of multiple classes without the need for multiple
networks. Despite these advancements, few attempts have been made to
automatically segment multiple anatomical features within medical imaging
datasets obtained from CT or MRI scans. This offers a unique challenge because
of the three dimensional nature of medical imaging data. In order to alleviate
the 3D modality problem, we propose a multi-axis ensemble method, applied to a
dataset of 4-cardiac-chamber segmented CT scans. Inspired by the typical
three-axis view used by humans, this technique aims to maximize the 3D spatial
information afforded to the model, while remaining efficient for consumer grade
inference hardware. Multi-axis ensembling along with pragmatic voxel
preprocessing have shown in our experiments to greatly increase the mean
intersection over union of our predictions over the complete DICOM dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06687</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06687</id><created>2019-09-14</created><authors><author><keyname>Thakallapelli</keyname><forenames>Abilash</forenames></author><author><keyname>Kamalasadan</keyname><forenames>Sukumar</forenames></author></authors><title>Measurement-Based Wide-Area Damping of Inter-Area Oscillations based on
  MIMO Identification</title><categories>eess.SY cs.SY</categories><comments>Wide Area Damping Control, IEEE 39 Bus</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interconnected power grid exhibits oscillatory response after a disturbance
in the system. One such type of oscillations, the inter-area oscillations has
the oscillation frequency in the range of 0.1 to 1 Hz. The damping of
inter-area oscillations is difficult with local controllers, but it can be
achieved using a Wide Area Damping Controller (WADC). For effective control,
the input to the WADC should be the most observable signal and the WADC output
should be sent to the most controllable generator. This paper presents a
measurement-based novel algorithm for multi-input-multi-output (MIMO) transfer
function identification of the power system based on optimization to estimate
such oscillation frequencies. Based on the MIMO transfer function the optimal
control loop for WADC is estimated. The WADC design is based on the discrete
linear quadratic regulator (DLQR) and Kalman filtering for damping of
inter-area oscillations. Since the MIMO identification is based on actual
measurements, the proposed method can accurately monitor changes in the power
grid whereas the conventional methods are based on small-signal analysis of a
linearized model which does not consider changing operating conditions. The
overall algorithm is implemented and validated on a RTDS/RSCAD and MATLAB
real-time co-simulation platform using two-area and IEEE 39 bus power system
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06691</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06691</id><created>2019-09-14</created><authors><author><keyname>Thakallapelli</keyname><forenames>Abilash</forenames></author><author><keyname>Ghosh</keyname><forenames>Sudipta</forenames></author><author><keyname>Kamalasadan</keyname><forenames>Sukumar</forenames></author></authors><title>Sensorless Real-Time Reduced Order Model Based Adaptive Maximum Power
  Tracking Pitch Controller for Grid Connected Wind Turbines</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a sensor-less maximum power tracking (MPT) pitch
controller for grid connected Wind Turbine (WT). The main advantage of the
proposed architecture is that the approach ensures smooth operation and thus
minimizes the mechanical stress and damage on the WT during high wind speed and
grid transient conditions. Simultaneously, it also: a) reduces transients in
Point of Common Coupling (PCC) bus voltage, b) reduces rotor speed
oscillations, and c) controls the output power of the wind turbine without
exceeding its thermal limits. The approach can work without wind speed
measurements. In order to consider the effect of grid variations at the PCC,
the affected area in the grid is modeled as a study area (area of interest),
and remaining area (external area) is modeled as frequency dependent reduced
order model (FDROM). The reduced order model (ROM) is then used to estimate the
reference speed. The proposed controller is designed using the error between
actual speed of the generator and the reference speed, to ensure smooth
operation and limit the speed and aerodynamic power at the rated values. The
architecture is evaluated using wind farm integrated Kundur's two-area and
IEEE-39 bus test systems using real-time digital simulator (RTDS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06700</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06700</id><created>2019-09-14</created><authors><author><keyname>Lin</keyname><forenames>Jiarong</forenames></author><author><keyname>Zhang</keyname><forenames>Fu</forenames></author></authors><title>Loam_livox: A fast, robust, high-precision LiDAR odometry and mapping
  package for LiDARs of small FoV</title><categories>cs.RO cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LiDAR odometry and mapping (LOAM) has been playing an important role in
autonomous vehicles, due to its ability to simultaneously localize the robot's
pose and build high-precision, high-resolution maps of the surrounding
environment. This enables autonomous navigation and safe path planning of
autonomous vehicles. In this paper, we present a robust, real-time LOAM
algorithm for LiDARs with small FoV and irregular samplings. By taking effort
on both front-end and back-end, we address several fundamental challenges
arising from such LiDARs, and achieve better performance in both precision and
efficiency compared to existing baselines. To share our findings and to make
contributions to the community, we open source our codes on Github
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06726</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06726</id><created>2019-09-14</created><authors><author><keyname>Wang</keyname><forenames>Tianchen</forenames></author><author><keyname>Xiong</keyname><forenames>Jinjun</forenames></author><author><keyname>Xu</keyname><forenames>Xiaowei</forenames></author><author><keyname>Jiang</keyname><forenames>Meng</forenames></author><author><keyname>Shi</keyname><forenames>Yiyu</forenames></author><author><keyname>Yuan</keyname><forenames>Haiyun</forenames></author><author><keyname>Huang</keyname><forenames>Meiping</forenames></author><author><keyname>Zhuang</keyname><forenames>Jian</forenames></author></authors><title>MSU-Net: Multiscale Statistical U-Net for Real-time 3D Cardiac MRI Video
  Segmentation</title><categories>eess.IV cs.CV</categories><comments>MICCAI19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cardiac magnetic resonance imaging (MRI) is an essential tool for MRI-guided
surgery and real-time intervention. The MRI videos are expected to be segmented
on-the-fly in real practice. However, existing segmentation methods would
suffer from drastic accuracy loss when modified for speedup. In this work, we
propose Multiscale Statistical U-Net (MSU-Net) for real-time 3D MRI video
segmentation in cardiac surgical guidance. Our idea is to model the input
samples as multiscale canonical form distributions for speedup, while the
spatio-temporal correlation is still fully utilized. A parallel statistical
U-Net is then designed to efficiently process these distributions. The fast
data sampling and efficient parallel structure of MSU-Net endorse the fast and
accurate inference. Compared with vanilla U-Net and a modified state-of-the-art
method GridNet, our method achieves up to 268% and 237% speedup with 1.6% and
3.6% increased Dice scores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06750</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06750</id><created>2019-09-15</created><authors><author><keyname>Lari</keyname><forenames>Mohammad</forenames></author><author><keyname>Asaeian</keyname><forenames>Sina</forenames></author></authors><title>Multi-objective Antenna Selection in a Full Duplex Base Station</title><categories>cs.IT eess.SP math.IT</categories><doi>10.1007/s11277-019-06754-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of full-duplex (FD) communication systems is a new way to increase
spectral efficiency. For this reason, it has received serious attention in the
new generation of wireless communication systems. The main challenge of FD
systems is self-interference that needs to be reduced appropriately. In this
paper, we have considered an FD multi-antenna base station in a cellular
network and we have used the antenna selection technique to resolve the
self-interference issue. We have also provided a new criterion to select an
appropriate antenna. In this new criterion, the antenna selection is modeled as
a multi-objective optimization problem. Here, the antennas which simultaneously
minimizes interference channel gain and maximizes uplink (UL) and downlink (DL)
channel gains are selected for transmission and reception. The base station has
to perform well in both the UL and DL and reduce the self-interference
simultaneously. Therefore, the multi-objective criterion has a better
performance than the single-objective criterion. Although, in conventional
antenna selection with the single-objective criterion, only the function of the
UL and DL channels or the interference channel is considered. Finally, the
simulations show that the new criterion has a higher throughput rate than the
other conventional single-objective antenna selection techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06760</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06760</id><created>2019-09-15</created><authors><author><keyname>Yang</keyname><forenames>Xi</forenames></author><author><keyname>Cao</keyname><forenames>Fan</forenames></author><author><keyname>Matthaiou</keyname><forenames>Michail</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author></authors><title>On the Uplink Transmission of Multi-user Extra-large Scale Massive MIMO
  Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>Copyright may be transferred without notice, after which this version
  may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the inherent benefits, such as, better cell coverage and higher area
throughput, extra-large scale massive MIMO has great potential to be one of the
key technologies for the next generation wireless communication systems.
However, in practice, when the antenna dimensions grow large, spatial
non-stationarities occur and users would only see a portion of the base station
antenna array, which we call visibility region (VR). To exploit the impact of
spatial non-stationarities, in this paper, we investigate the uplink
transmission of multi-user extra-large scale massive MIMO systems by
considering VRs. In particular, we first propose a subarray-based system
architecture for extra-large scale massive MIMO systems. Then, tight
closed-form uplink spectral efficiency (SE) approximations with linear
receivers are derived.These approximations reveal that users with their VRs
covering different subarrays or VRs with less overlap should be scheduled
simultaneously under maximum ratio combining receiver, while as many users as
possible should be selected under linear minimum mean squared error receiver.
With the objective of maximizing the system sum achievable SE, we also propose
schemes for the subarray phase coefficient design. In addition, two statistical
CSI-based greedy user scheduling algorithms are developed. Our results indicate
that statistical CSI-based scheduling algorithms achieve great performance for
extra-large scale massive MIMO systems, and it is not necessary to
simultaneously turn on all the subarrays and radio frequency chains to serve
the users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06763</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06763</id><created>2019-09-15</created><authors><author><keyname>Lin</keyname><forenames>Hongxiang</forenames></author><author><keyname>Figini</keyname><forenames>Matteo</forenames></author><author><keyname>Tanno</keyname><forenames>Ryutaro</forenames></author><author><keyname>Blumberg</keyname><forenames>Stefano B.</forenames></author><author><keyname>Kaden</keyname><forenames>Enrico</forenames></author><author><keyname>Ogbole</keyname><forenames>Godwin</forenames></author><author><keyname>Brown</keyname><forenames>Biobele J.</forenames></author><author><keyname>D'Arco</keyname><forenames>Felice</forenames></author><author><keyname>Carmichael</keyname><forenames>David W.</forenames></author><author><keyname>Lagunju</keyname><forenames>Ikeoluwa</forenames></author><author><keyname>Cross</keyname><forenames>Helen J.</forenames></author><author><keyname>Fernandez-Reyes</keyname><forenames>Delmiro</forenames></author><author><keyname>Alexander</keyname><forenames>Daniel C.</forenames></author></authors><title>Deep Learning for Low-Field to High-Field MR: Image Quality Transfer
  with Probabilistic Decimation Simulator</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  MR images scanned at low magnetic field ($&lt;1$T) have lower resolution in the
slice direction and lower contrast, due to a relatively small signal-to-noise
ratio (SNR) than those from high field (typically 1.5T and 3T). We adapt the
recent idea of Image Quality Transfer (IQT) to enhance very low-field
structural images aiming to estimate the resolution, spatial coverage, and
contrast of high-field images. Analogous to many learning-based image
enhancement techniques, IQT generates training data from high-field scans alone
by simulating low-field images through a pre-defined decimation model. However,
the ground truth decimation model is not well-known in practice, and lack of
its specification can bias the trained model, aggravating performance on the
real low-field scans. In this paper we propose a probabilistic decimation
simulator to improve robustness of model training. It is used to generate and
augment various low-field images whose parameters are random variables and
sampled from an empirical distribution related to tissue-specific SNR on a
0.36T scanner. The probabilistic decimation simulator is model-agnostic, that
is, it can be used with any super-resolution networks. Furthermore we propose a
variant of U-Net architecture to improve its learning performance. We show
promising qualitative results from clinical low-field images confirming the
strong efficacy of IQT in an important new application area: epilepsy diagnosis
in sub-Saharan Africa where only low-field scanners are normally available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06785</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06785</id><created>2019-09-15</created><authors><author><keyname>Sun</keyname><forenames>Xiaofang</forenames></author><author><keyname>Ng</keyname><forenames>Derrick Wing Kwan</forenames></author><author><keyname>Ding</keyname><forenames>Zhiguo</forenames></author><author><keyname>Xu</keyname><forenames>Yanqing</forenames></author><author><keyname>Zhong</keyname><forenames>Zhangdui</forenames></author></authors><title>Physical Layer Security in UAV Systems: Challenges and Opportunities</title><categories>cs.IT eess.SP math.IT</categories><comments>18 pages, 5 figures. This paper has been accepted by IEEE Wireless
  Communications. X. Sun, D.W.K. Ng, Z. Ding, Y. Xu, and Z. Zhong, &quot;Physical
  Layer Security in UAV Systems: Challenges and Opportunities,&quot; IEEE Wireless
  Commun., accepted to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicle (UAV) wireless communications have experienced an
upsurge of interest in both military and civilian applications, due to its high
mobility, low cost, on-demand deployment, and inherent line-of-sight (LoS)
air-to-ground channels. However, these benefits also make UAV wireless
communication systems vulnerable to malicious eavesdropping attacks. In this
article, we aim to examine the physical layer security issues in UAV systems.
In particular, passive and active eavesdroppings are two primary attacks in UAV
systems. We provide an overview on emerging techniques, such as trajectory
design, resource allocation, and cooperative UAVs, to fight against both types
of eavesdroppings in UAV wireless communication systems. Moreover, the
applications of non-orthogonal multiple access, multiple-input and
multiple-output, and millimeter wave in UAV systems are also proposed to
improve the system spectral efficiency and to guarantee security
simultaneously. Finally, we discuss some potential research directions and
challenges in terms of physical layer security in UAV systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06805</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06805</id><created>2019-09-15</created><updated>2020-02-02</updated><authors><author><keyname>Lee</keyname><forenames>Keonnyeong</forenames></author><author><keyname>Yoo</keyname><forenames>In-Chul</forenames></author><author><keyname>Yook</keyname><forenames>Dongsuk</forenames></author></authors><title>Many-to-Many Voice Conversion using Cycle-Consistent Variational
  Autoencoder with Multiple Decoders</title><categories>eess.AS cs.CL</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the obstacles in many-to-many voice conversion is the requirement of
the parallel training data, which contain pairs of utterances with the same
linguistic content spoken by different speakers. Since collecting such parallel
data is a highly expensive task, many works attempted to use non-parallel
training data for many-to-many voice conversion. One of such approaches is
using the variational autoencoder (VAE). Though it can handle many-to-many
voice conversion without the parallel training, the VAE based voice conversion
methods suffer from low sound qualities of the converted speech. One of the
major reasons is because the VAE learns only the self-reconstruction path. The
conversion path is not trained at all. In this paper, we propose a cycle
consistency loss for VAE to explicitly learn the conversion path. In addition,
we propose to use multiple decoders to further improve the sound qualities of
the conventional VAE based voice conversion methods. The effectiveness of the
proposed method is validated using objective and the subjective evaluations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06833</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06833</id><created>2019-09-15</created><authors><author><keyname>Kageyama</keyname><forenames>Tomoya</forenames></author><author><keyname>Muta</keyname><forenames>Osamu</forenames></author><author><keyname>Gacanin</keyname><forenames>Haris</forenames></author></authors><title>Performance Analysis of OFDM with Peak Cancellation Under EVM and ACLR
  Restrictions</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents performance analysis of an adaptive peak cancellation
method to reduce the high peak-toaverage power ratio (PAPR) for OFDM systems,
while keeping the out-of-band (OoB) power leakage as well as an in-band
distortion power below the pre-determined level. In this work, the increase of
adjacent leakage power ratio (ACLR) and error vector magnitude (EVM) are
estimated recursively using the detected peak amplitude. We present analytical
framework for OFDM-based systems with theoretical bit error rate (BER)
representations and detection of optimum peak threshold based on predefined EVM
and ACLR requirements. Moreover, the optimum peak detection threshold is
selected based on the oretical design to maintain the predefined distortion
level. Thus, their degradations are automatically restricted below the
pre-defined levels which correspond to target OoB radiation. We also discuss
the practical design of peak-cancellation (PC) signal with target OoB radiation
and in-band distortion through optimizing the windowing size of the PC signal.
Numerical results show the improvements with respect to both achievable bit
error rate (BER) and PAPR with the PC method in eigen-beam space division
multiplexing (E-SDM) systems under restriction of OoB power radiation. It can
also be seen that the theoretical BER shows good agreements with simulation
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06840</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06840</id><created>2019-09-15</created><updated>2019-11-22</updated><authors><author><keyname>Karimov</keyname><forenames>Alexander</forenames></author><author><keyname>Razumov</keyname><forenames>Artem</forenames></author><author><keyname>Manbatchurina</keyname><forenames>Ruslana</forenames></author><author><keyname>Simonova</keyname><forenames>Ksenia</forenames></author><author><keyname>Donets</keyname><forenames>Irina</forenames></author><author><keyname>Vlasova</keyname><forenames>Anastasia</forenames></author><author><keyname>Khramtsova</keyname><forenames>Yulia</forenames></author><author><keyname>Ushenin</keyname><forenames>Konstantin</forenames></author></authors><title>Comparison of UNet, ENet, and BoxENet for Segmentation of Mast Cells in
  Scans of Histological Slices</title><categories>eess.IV cs.CV cs.LG</categories><comments>4 pages, 5 figures, 1 table</comments><doi>10.1109/SIBIRCON48586.2019.8958121</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks show high accuracy in theproblem of semantic and
instance segmentation of biomedicaldata. However, this approach is
computationally expensive. Thecomputational cost may be reduced with network
simplificationafter training or choosing the proper architecture, which
providessegmentation with less accuracy but does it much faster. In thepresent
study, we analyzed the accuracy and performance ofUNet and ENet architectures
for the problem of semantic imagesegmentation. In addition, we investigated the
ENet architecture by replacing of some convolution layers with
box-convolutionlayers. The analysis performed on the original dataset consisted
of histology slices with mast cells. These cells provide a region
forsegmentation with different types of borders, which vary fromclearly visible
to ragged. ENet was less accurate than UNet byonly about 1-2%, but ENet
performance was 8-15 times faster than UNet one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06849</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06849</id><created>2019-09-15</created><authors><author><keyname>Rahati-Quchani</keyname><forenames>Mahla</forenames></author><author><keyname>Abrishami</keyname><forenames>Saeid</forenames></author><author><keyname>Feizi</keyname><forenames>Mehdi</forenames></author></authors><title>An Efficient Mechanism for Computation Offloading in Mobile-Edge
  Computing</title><categories>cs.DC cs.GT eess.SP</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile edge computing (MEC) is a promising technology that provides cloud and
IT services within the proximity of the mobile user. With the increasing number
of mobile applications, mobile devices (MD) encounter limitations of their
resources, such as battery life and computation capacity. The computation
offloading in MEC can help mobile users to reduce battery usage and speed up
task execution. Although there are many solutions for offloading in MEC, most
usually only employ one MEC server for improving mobile device energy
consumption and execution time. Instead of conventional centralized
optimization methods, the current paper considers a decentralized optimization
mechanism between MEC servers and users. In particular, an assignment mechanism
called school choice is employed to assist heterogeneous users to select
different MEC operators in a distributed environment. With this mechanism, each
user can benefit from minimizing the price and energy consumption of executing
tasks while also meeting the specified deadline. The present research has
designed an efficient mechanism for a computation offloading scheme that
achieves minimal price and energy consumption under latency constraints.
Numerical results demonstrate that the proposed algorithm can attain efficient
and successful computation offloading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06852</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06852</id><created>2019-09-15</created><authors><author><keyname>Li</keyname><forenames>Zhaoshuo</forenames></author><author><keyname>Shahbazi</keyname><forenames>Mahya</forenames></author><author><keyname>Patel</keyname><forenames>Niravkumar</forenames></author><author><keyname>Sullivan</keyname><forenames>Eimear O'</forenames></author><author><keyname>Zhang</keyname><forenames>Haojie</forenames></author><author><keyname>Vyas</keyname><forenames>Khushi</forenames></author><author><keyname>Chalasani</keyname><forenames>Preetham</forenames></author><author><keyname>Deguet</keyname><forenames>Anton</forenames></author><author><keyname>Gehlbach</keyname><forenames>Peter L.</forenames></author><author><keyname>Iordachita</keyname><forenames>Iulian</forenames></author><author><keyname>Yang</keyname><forenames>Guang-Zhong</forenames></author><author><keyname>Taylor</keyname><forenames>Russell H.</forenames></author></authors><title>Hybrid Robotic-assisted Frameworks for Endomicroscopy Scanning in
  Retinal Surgeries</title><categories>cs.RO eess.IV</categories><comments>12 pages, TMRB</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-resolution real-time imaging at cellular levelin retinal surgeries is
very challenging due to extremely confinedspace within the eyeball and lack of
appropriate modalities.Probe-based confocal laser endomicroscopy (pCLE)
system,which has a small footprint and provides highly-magnified im-ages, can
be a potential imaging modality for improved diagnosis.The ability to visualize
in cellular-level the retinal pigmentepithelium and the chorodial blood vessels
underneath canprovide useful information for surgical outcomes in
conditionssuch as retinal detachment. However, the adoption of pCLE islimited
due to narrow field of view and micron-level range offocus. The physiological
tremor of surgeons' hand also deterioratethe image quality considerably and
leads to poor imaging results. In this paper, a novel image-based hybrid motion
controlapproach is proposed to mitigate challenges of using pCLEin retinal
surgeries. The proposed framework enables sharedcontrol of the pCLE probe by a
surgeon to scan the tissueprecisely without hand tremors and an auto-focus
image-basedcontrol algorithm that optimizes quality of pCLE images. Thecontrol
strategy is deployed on two semi-autonomous frameworks: cooperative and
teleoperated. Both frameworks consist of theSteady-Hand Eye Robot (SHER), whose
end-effector holds thepCLE probe...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06862</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06862</id><created>2019-09-15</created><authors><author><keyname>Cousik</keyname><forenames>Tarun</forenames></author><author><keyname>Shafin</keyname><forenames>Rubayet</forenames></author><author><keyname>Zhou</keyname><forenames>Zhou</forenames></author><author><keyname>Kleine</keyname><forenames>Kaleb</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey</forenames></author><author><keyname>Liu</keyname><forenames>Lingjia</forenames></author></authors><title>CogRF: A New Frontier for Machine Learning and Artificial Intelligence
  for 6G RF Systems</title><categories>eess.SP cs.NI</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of CogRF, a novel tunable radio frequency (RF) frontend that uses
artificial intelligence (AI) to meet mission requirements for beyond 5G and 6G
systems, is introduced. CogRF utilizes AI as the core to control and operate RF
system components with the objective of optimizing the overall system
performance. An overview of the vital elements that make up CogRF as well as
the overall hierarchy of the envisioned CogRF system is provided, and potential
RF components and control parameters are discussed. AI-powered flexible RF
front ends, provide new opportunities to identify to enhance security, speed up
optimization of device configurations, further refine radio design, improve
existing spectrum sharing operations, and develop device health analytics. Top
research challenges for CogRF systems have also been described and potential
research directions are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06869</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06869</id><created>2019-09-15</created><authors><author><keyname>Mathias</keyname><forenames>Joel</forenames></author><author><keyname>Moye</keyname><forenames>Robert</forenames></author><author><keyname>Meyn</keyname><forenames>Sean</forenames></author><author><keyname>Warrington</keyname><forenames>Joseph</forenames></author></authors><title>State Space Collapse in Resource Allocation for Demand Dispatch</title><categories>eess.SY cs.SY math.OC</categories><comments>13 pages, 3 figures, 31 references, preprint version of conference
  paper to appear in IEEE Conference on Decision and Control, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Demand dispatch is the science of extracting virtual energy storage through
the automatic control of deferrable loads to provide balancing or regulation
services to the grid, while maintaining consumer-end quality of service (QoS).
  The control of a large collection of heterogeneous loads is in part a
resource allocation problem, since different classes of loads are valuable for
different services.
  The goal of this paper is to unveil the structure of the optimal solution to
the resource allocation problem and to investigate short term market
implications. It is found that the marginal cost for each load class evolves on
a two-dimensional subspace, spanned by an optimal costate process and its
derivative.
  The resource allocation problem is recast to construct a dynamic competitive
equilibrium model, in which the consumer utility is the negative of the cost of
deviation from ideal QoS. It is found that a competitive equilibrium exists,
with the equilibrium price equal to the negative of an optimal costate process.
Moreover, the equilibrium price is different from what would be obtained based
on the standard assumption that the consumer's utility is a function of power
consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06916</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06916</id><created>2019-09-15</created><authors><author><keyname>Eslamiat</keyname><forenames>Hossein</forenames></author><author><keyname>Wang</keyname><forenames>Ningshan</forenames></author><author><keyname>Sanyal</keyname><forenames>Amit K.</forenames></author></authors><title>Geometric PID-type attitude tracking control on SO(3)</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article develops and proposes a geometric nonlinear
proportional-integral-derivative (PID) type tracking control scheme on the Lie
group of rigid body rotations, SO(3). Like PD-type attitude tracking control
schemes that have been proposed in the past, this PID-type control scheme
exhibits almost global asymptotic stability in tracking a desired attitude
profile. The stability of this PID-type tracking control scheme is shown using
a Lyapunov analysis. A numerical simulation study demonstrates the stability of
this tracking control scheme, as well as its robustness to a disturbance
torque. In addition, a numerical comparison study shows the effectiveness of
the proposed integrator term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06936</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06936</id><created>2019-09-15</created><authors><author><keyname>Mao</keyname><forenames>Yanbing</forenames></author><author><keyname>Akyol</keyname><forenames>Emrah</forenames></author><author><keyname>Zhang</keyname><forenames>Ziang</forenames></author></authors><title>Novel Defense Strategy Against Zero-Dynamics Attack in Multi-Agent
  Systems</title><categories>eess.SY cs.SY</categories><comments>To appear in IEEE CDC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the defense strategy of strategic topology switching for
the second-order multi-agent system under zero-dynamics attack (ZDA) whose
attack-starting time is allowed to be not the initial time. We first study the
detectability of ZDA, which is a sufficient and necessary condition of
switching topologies in detecting the attack. Based on the detectability, a
Luenberger observer under switching topology is proposed to detect the stealthy
attack. The primary advantages of the attack-detection algorithm are twofold:
(i) in detecting ZDA, the algorithm allows the defender (system operator) to
have no knowledge of the attack-starting time and the misbehaving agents (i.e.,
agents under attack); (ii) in tracking system in the absence of attacks,
Luenberger observer has no constraint on the magnitudes of observer gains and
the number of observed outputs, i.e., only one agent's observed output is
sufficient. Simulations are provided to verify the effectiveness of the
strategic topology-switching algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06938</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06938</id><created>2019-09-15</created><authors><author><keyname>Mao</keyname><forenames>Yanbing</forenames></author><author><keyname>Jafarnejadsani</keyname><forenames>Hamidreza</forenames></author><author><keyname>Zhao</keyname><forenames>Pan</forenames></author><author><keyname>Akyol</keyname><forenames>Emrah</forenames></author><author><keyname>Hovakimyan</keyname><forenames>Naira</forenames></author></authors><title>Detectability of Intermittent Zero-Dynamics Attack in Networked Control
  Systems</title><categories>eess.SY cs.SY</categories><comments>To appear in IEEE CDC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes stealthy attacks, particularly the zero-dynamics attack
(ZDA) in networked control systems. ZDA hides the attack signal in the
null-space of the state-space representation of the control system and hence it
cannot be detected via conventional detection methods. A natural defense
strategy builds on changing the null-space via switching through a set of
topologies. In this paper, we propose a realistic ZDA variation where the
attacker is aware of this topology-switching strategy, and hence employs the
policy to avoid detection: &quot;pause (update and resume) attack&quot; before (after)
topology switching to evade detection. We first systematically study the
proposed ZDA variation, and then develop defense strategies under the realistic
assumptions. Particularly, we characterize conditions for detectability of the
proposed ZDA variation, in terms of the network topologies to be maintained,
the set of agents to be monitored, and the measurements of the monitored agents
that should be extracted. We provide numerical results that demonstrate our
theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06942</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06942</id><created>2019-09-15</created><authors><author><keyname>Zhang</keyname><forenames>Jian-Dong</forenames></author><author><keyname>Zhang</keyname><forenames>Zi-Jing</forenames></author><author><keyname>Cen</keyname><forenames>Long-Zhu</forenames></author><author><keyname>Luo</keyname><forenames>Bin</forenames></author><author><keyname>You</keyname><forenames>Chenglong</forenames></author><author><keyname>Maga&#xf1;a-Loaiza</keyname><forenames>Omar S.</forenames></author><author><keyname>Sun</keyname><forenames>Yi-Fei</forenames></author><author><keyname>Xu</keyname><forenames>Lu</forenames></author><author><keyname>Wu</keyname><forenames>Long</forenames></author><author><keyname>Zhao</keyname><forenames>Yuan</forenames></author></authors><title>Control of Structured Light Enables Nearly Perfect Noise-filtering</title><categories>physics.optics eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of laser-based active sensing has been severely limited by
two types of noise: electrical noise, stemming from elements; optical noise,
laser jamming from an eavesdropper and background from environment.
Conventional methods to filter optical noise take advantage of the differences
between signal and noise in time, wavelength, and polarization. However, they
may be limited when the noise and signal share the same information on these
degrees of freedoms (DoFs). In order to overcome this drawback, we
experimentally demonstrate a groundbreaking noise-filtering method by
controlling orbital angular momentum (OAM) to distinguish signal from noise. We
provide a proof-of-principle experiment and discuss the dependence of azimuthal
index of OAM and detection aperture on signal-to-noise ratio (SNR). Our results
suggest that using OAM against noise is an efficient method, offering a new
route to optical sensing immersed in high-level noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06943</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06943</id><created>2019-09-12</created><authors><author><keyname>Mohammad</keyname><forenames>Abdullahi</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Andreopoulos</keyname><forenames>Yiannis</forenames></author></authors><title>Complexity-Scalable Neural Network Based MIMO Detection With Learnable
  Weight Scaling</title><categories>eess.SP cs.LG</categories><comments>12 pages, 12 figures, journal</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces a framework for systematic complexity scaling of deep
neural network (DNN) based MIMO detectors. The model uses a fraction of the DNN
inputs by scaling their values through weights that follow monotonically
non-increasing functions. This allows for weight scaling across and within the
different DNN layers in order to achieve scalable complexity-accuracy results.
To reduce complexity further, we introduce a regularization constraint on the
layer weights such that, at inference, parts (or the entirety) of network
layers can be removed with minimal impact on the detection accuracy. We also
introduce trainable weight-scaling functions for increased robustness to
changes in the activation patterns and a further improvement in the detection
accuracy at the same inference complexity. Numerical results show that our
approach is 10 and 100-fold less complex than classical approaches based on
semi-definite relaxation and ML detection, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06952</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06952</id><created>2019-09-15</created><authors><author><keyname>Mao</keyname><forenames>Zeyu</forenames></author><author><keyname>Huang</keyname><forenames>Hao</forenames></author><author><keyname>Davis</keyname><forenames>Katherine</forenames></author></authors><title>W4IPS: A Web-based Interactive Power System Simulation Environment For
  Power System Security Analysis</title><categories>eess.SY cs.SY eess.SP</categories><comments>10 pages, HICSS, accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern power systems are increasingly evolving Cyber-Physical Systems (CPS)
that feature close interaction between Information and Communication Technology
(ICT), physical and electrical devices, and human factors. The interactivity
and security of CPS are the essential building blocks for the reliability,
stability and economic operation of power systems. This paper presents a
web-based interactive multi-user power system simulation environment and open
source toolset (W4IPS) whose main features are a publish/subscribe structure, a
real-time data sharing capability, role-based multi-user visualizations,
distributed multi-user interactive controls, an easy to use and deploy web
interface, and flexible and extensible support for communication protocols. The
paper demonstrates the use of W4IPS features as an ideal platform for
contingency response training and cyber security analysis, with an emphasis on
interactivity and expandability. In particular, we present the use cases and
the results of W4IPS in power system operation education and security analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06962</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06962</id><created>2019-09-15</created><authors><author><keyname>Turan</keyname><forenames>Berkay</forenames></author><author><keyname>Pedarsani</keyname><forenames>Ramtin</forenames></author><author><keyname>Alizadeh</keyname><forenames>Mahnoosh</forenames></author></authors><title>Dynamic Pricing and Management for Electric Autonomous Mobility on
  Demand Systems Using Reinforcement Learning</title><categories>eess.SY cs.SY</categories><comments>14 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proliferation of ride sharing systems is a major drive in the advancement
of autonomous and electric vehicle technologies. This paper considers the joint
routing, battery charging, and pricing problem faced by a profit-maximizing
transportation service provider that operates a fleet of autonomous electric
vehicles. We define the dynamic system model that captures the time dependent
and stochastic features of an electric autonomous-mobility-on-demand system. To
accommodate for the time-varying nature of trip demands, renewable energy
availability, and electricity prices and to further optimally manage the
autonomous fleet, a dynamic policy is required. In order to develop a dynamic
control policy, we first formulate the dynamic progression of the system as a
Markov decision process. We argue that it is intractable to exactly solve for
the optimal policy using exact dynamic programming methods and therefore apply
deep reinforcement learning to develop a near-optimal control policy.
Furthermore, we establish the static planning problem by considering
time-invariant system parameters. We define the capacity region and determine
the optimal static policy to serve as a baseline for comparison with our
dynamic policy. While the static policy provides important insights on optimal
pricing and fleet management, we show that in a real dynamic setting, it is
inefficient to utilize a static policy. The two case studies we conducted in
Manhattan and San Francisco demonstrate the efficacy of our dynamic policy in
terms of network stability and profits, while keeping the queue lengths up to
200 times less than the static policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06972</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06972</id><created>2019-09-15</created><authors><author><keyname>Li</keyname><forenames>Yiqing</forenames></author><author><keyname>Jiang</keyname><forenames>Miao</forenames></author><author><keyname>Zhang</keyname><forenames>Qi</forenames></author><author><keyname>Qin</keyname><forenames>Jiayin</forenames></author></authors><title>Joint Beamforming Design in Multi-Cluster MISO NOMA Intelligent
  Reflecting Surface-Aided Downlink Communication Networks</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering intelligent reflecting surface (IRS), we study a multi-cluster
multiple-input-single-output (MISO) non-orthogonal multiple access (NOMA)
downlink communication network. In the network, an IRS assists the
communication from the base station (BS) to all users by passive beamforming.
Our goal is to minimize the total transmit power by jointly optimizing the
transmit beamforming vectors at the BS and the reflection coefficient vector at
the IRS. Because of the restrictions on the IRS reflection amplitudes and phase
shifts, the formulated quadratically constrained quadratic problem is highly
non-convex. For the aforementioned problem, the conventional semidefinite
programming (SDP) based algorithm has prohibitively high computational
complexity and deteriorating performance. Here, we propose an effective
second-order cone programming (SOCP)-alternating direction method of
multipliers (ADMM) based algorithm to obtain the locally optimal solution. To
reduce the computational complexity, we also propose a low-complexity
zero-forcing (ZF) based suboptimal algorithm. It is shown through simulation
results that our proposed SOCP-ADMM based algorithm achieves significant
performance gain over the conventional SDP based algorithm. Furthermore, when
the number of passive reflection elements is relatively high, our proposed
ZF-based suboptimal algorithm also outperforms the SDP based algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06975</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06975</id><created>2019-09-15</created><authors><author><keyname>Shi</keyname><forenames>Minwei</forenames></author><author><keyname>Yang</keyname><forenames>Kai</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Niyato</keyname><forenames>Dusit</forenames></author></authors><title>Coverage Analysis of Integrated Sub-6GHz-mmWave Cellular Networks with
  Hotspots</title><categories>cs.IT eess.SP math.IT</categories><comments>28 pages, 16 figures, to appear in IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deploying Sub-6GHz networks together with millimeter wave (mmWave) is a
promising solution to achieve high data rates in traffic hotspots while
guaranteeing sufficient coverage, where mmWave small cells are densely deployed
to provide high quality of service. In this paper, we propose an analytical
framework to investigate the integrated Sub-6GHz-mmWave cellular networks, in
which the Sub-6GHz base stations (BSs) are modeled as a Poisson point process,
and the mmWave BSs are clustered following a Poisson cluster process in traffic
hotspots. We conduct stochastic geometry-based analysis and derive the
performance metrics including the association probability,
signal-to-interference-plus-noise ratio coverage probability and average
achievable rate, which are validated to be accurate by Monte Carlo simulations.
We analyze the impact of various deployment parameters on the network
performance to give insights on the network design. In particular, it is shown
that deploying mmWave small cells in traffic hotspots will outperform both
traditional Sub-6GHz heterogeneous network and isolated mmWave system in terms
of the coverage probability. It can also be shown that extremely high and
extremely small association weight for mmWave BSs will deteriorate the
performance for cell edge users and cell interior users, respectively.
Moreover, there exists an optimal pre-decided dispersion parameter of mmWave
BSs that contributes to the maximum coverage probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06977</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06977</id><created>2019-09-16</created><authors><author><keyname>He</keyname><forenames>Xing</forenames></author><author><keyname>Ai</keyname><forenames>Qian</forenames></author><author><keyname>Qiu</keyname><forenames>Robert C.</forenames></author><author><keyname>Zhang</keyname><forenames>Dongxia</forenames></author></authors><title>Preliminary Exploration on Digital Twin for Power Systems: Challenges,
  Framework, and Applications</title><categories>eess.SP stat.AP</categories><comments>8 pages. Submitted to IEEE Transactions on Industrial Informaticss</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital twin (DT) is one of the most promising enabling technologies for
realizing smart grids. Characterized by seamless and active---data-driven,
real-time, and closed-loop---integration between digital and physical spaces, a
DT is much more than a blueprint, simulation tool, or cyber-physical system
(CPS). Numerous state-of-the-art technologies such as internet of things (IoT),
5G, big data, and artificial intelligence (AI) serve as a basis for DT. DT for
power systems aims at situation awareness and virtual test to assist the
decision-making on power grid operation and management under normal or urgent
conditions. This paper, from both science paradigms and engineering practice,
outlines the backgrounds, challenges, framework, tools, and possible directions
of DT as a preliminary exploration. To our best knowledge, it is also the first
exploration on DT in the context of power systems. Starting from the
fundamental and most frequently used power flow (PF) analysis, some typical
application scenarios are presented. Our work is expected to contribute some
novel discoveries, as well as some high-dimensional analytics, to the
engineering community. Besides, the connection of DT with big data analytics
and AI may has deep impact on data science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06982</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06982</id><created>2019-09-16</created><updated>2020-01-25</updated><authors><author><keyname>Jiang</keyname><forenames>Tai-Xiang</forenames></author><author><keyname>Ng</keyname><forenames>Michael K.</forenames></author><author><keyname>Zhao</keyname><forenames>Xi-Le</forenames></author><author><keyname>Huang</keyname><forenames>Ting-Zhu</forenames></author></authors><title>Framelet Representation of Tensor Nuclear Norm for Third-Order Tensor
  Completion</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main aim of this paper is to develop a framelet representation of the
tensor nuclear norm for third-order tensor completion. In the literature, the
tensor nuclear norm can be computed by using tensor singular value
decomposition based on the discrete Fourier transform matrix, and tensor
completion can be performed by the minimization of the tensor nuclear norm
which is the relaxation of the sum of matrix ranks from all Fourier transformed
matrix frontal slices. These Fourier transformed matrix frontal slices are
obtained by applying the discrete Fourier transform on the tubes of the
original tensor. In this paper, we propose to employ the framelet
representation of each tube so that a framelet transformed tensor can be
constructed. Because of framelet basis redundancy, the representation of each
tube is sparsely represented. When the matrix slices of the original tensor are
highly correlated, we expect the corresponding sum of matrix ranks from all
framelet transformed matrix frontal slices would be small, and the resulting
tensor completion can be performed much better. The proposed minimization model
is convex and global minimizers can be obtained. Numerical results on several
types of multi-dimensional data (videos, multispectral images, and magnetic
resonance imaging data) have tested and shown that the proposed method
outperformed the other testing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06985</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06985</id><created>2019-09-16</created><authors><author><keyname>Khordad</keyname><forenames>Erfan</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author><author><keyname>Hanly</keyname><forenames>Stephen V.</forenames></author></authors><title>A Kronecker-Based Sparse Compressive Sensing Matrix for Millimeter Wave
  Beam Alignment</title><categories>eess.SP</categories><comments>Accepted to 13th International Conference on Signal Processing and
  Communication Systems (ICSPCS'2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave beam alignment (BA) is a challenging problem especially for
large number of antennas. Compressed sensing (CS) tools have been exploited due
to the sparse nature of such channels. This paper presents a novel
deterministic CS approach for BA. Our proposed sensing matrix which has a
Kronecker-based structure is sparse, which means it is computationally
efficient. We show that our proposed sensing matrix satisfies the restricted
isometry property (RIP) condition, which guarantees the reconstruction of the
sparse vector. Our approach outperforms existing random beamforming techniques
in practical low signal to noise ratio (SNR) scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06996</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.06996</id><created>2019-09-16</created><updated>2019-09-21</updated><authors><author><keyname>Dong</keyname><forenames>Ming</forenames></author></authors><title>A Data-driven Dynamic Rating Forecast Method and Application for Power
  Transformer Long-term Planning</title><categories>cs.CE cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a data-driven method for producing annual continuous
dynamic rating of power transformers to serve the long-term planning purpose.
Historically, research works on dynamic rating have been focused on
real-time/near-future system operations. There has been a lack of research for
long-term planning oriented applications. Currently, most utility companies
still rely on static rating numbers when planning power transformers for the
next few years. In response, this paper proposes a novel and comprehensive
method to analyze the past 5-year temperature, loading and load composition
data of existing power transformers in a planning region. Based on such data
and the forecasted area load composition, a future power transformer loading
profile can be constructed by using Gaussian Mixture Model. Then according to
IEEE std. C57.91-2011, a power transformer thermal aging model can be
established to incorporate future loading and temperature profiles. As a
result, annual continuous dynamic rating profiles under different temperature
scenarios can be determined. The profiles can reflect the long-term thermal
overloading risk in a much more realistic and granular way, which can
significantly improve the accuracy of power transformer planning. A real
utility application example in Canada has been presented to demonstrate the
practicality and usefulness of this method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07042</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07042</id><created>2019-09-16</created><authors><author><keyname>Fokina</keyname><forenames>Daria</forenames></author><author><keyname>Muravleva</keyname><forenames>Ekaterina</forenames></author><author><keyname>Ovchinnikov</keyname><forenames>George</forenames></author><author><keyname>Oseledets</keyname><forenames>Ivan</forenames></author></authors><title>Microstructure synthesis using style-based generative adversarial
  network</title><categories>eess.IV cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Work considers the usage of StyleGAN architecture for the task of
microstructure synthesis. The task is the following: given number of samples of
structure we try to generate similar samples at the same time preserving its
properties. Since the considered architecture is not able to produce samples of
sizes larger than the training images, we propose to use image quilting to
merge fixed-sized samples. One of the key features of the considered
architecture is that it uses multiple image resolutions. We also investigate
the necessity of such an approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07046</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07046</id><created>2019-09-16</created><authors><author><keyname>Chan</keyname><forenames>Justin</forenames></author><author><keyname>Raju</keyname><forenames>Sharat</forenames></author><author><keyname>Bly</keyname><forenames>Randall</forenames></author><author><keyname>Perkins</keyname><forenames>Jonathan A.</forenames></author><author><keyname>Gollakota</keyname><forenames>Shyamnath</forenames></author></authors><title>Identifying Pediatric Vascular Anomalies With Deep Learning</title><categories>eess.IV cs.CV q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vascular anomalies, more colloquially known as birthmarks, affect up to 1 in
10 infants. Though many of these lesions self-resolve, some types can result in
medical complications or disfigurement without proper diagnosis or management.
Accurately diagnosing vascular anomalies is challenging for pediatricians and
primary care physicians due to subtle visual differences and similarity to
other pediatric dermatologic conditions. This can result in delayed or
incorrect referrals for treatment. To address this problem, we developed a
convolutional neural network (CNN) to automatically classify images of vascular
anomalies and other pediatric skin conditions to aid physicians with diagnosis.
We constructed a dataset of 21,681 clinical images, including data collected
between 2002-2018 at Seattle Children's hospital as well as five
dermatologist-curated online repositories, and built a taxonomy over vascular
anomalies and other common pediatric skin lesions. The CNN achieved an average
AUC of 0.9731 when ten-fold cross-validation was performed across a taxonomy of
12 classes. The classifier's average AUC and weighted F1 score was 0.9889 and
0.9732 respectively when evaluated on a previously unseen test set of six of
these classes. Further, when used as an aid by pediatricians (n = 7), the
classifier increased their average visual diagnostic accuracy from 73.10% to
91.67%. The classifier runs in real-time on a smartphone and has the potential
to improve diagnosis of these conditions, particularly in resource-limited
areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07073</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07073</id><created>2019-09-16</created><authors><author><keyname>Moschella</keyname><forenames>Michela</forenames></author><author><keyname>Crisostomi</keyname><forenames>Emanuele</forenames></author><author><keyname>Shorten</keyname><forenames>Robert</forenames></author></authors><title>Stochastic Assignment of Electric Vehicles at Charging Stations Based on
  Personalized Utility Functions</title><categories>eess.SY cs.SY</categories><comments>7 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we propose a stochastic decentralized algorithm to recommend
the most convenient Charging Station (CS) to Plug-in Electric Vehicles (PEVs)
that need charging. In particular, we use different utility functions to
describe the possibly different priorities of PEV drivers, such as the
preference to minimize charging costs or to minimize charging times, or both of
them. For this purpose we generalize the notion of a simple CS to include the
possibility of supplying other loads in addition to PEVs, and exploit locally
generated energy from renewable sources. Extensive simulations based on the
mobility simulator SUMO in realistic city-wide networks have been provided to
illustrate how the proposed PEV assignment procedure works in practice and to
validate its performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07116</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07116</id><created>2019-09-16</created><authors><author><keyname>Rao</keyname><forenames>Dattaraj</forenames></author></authors><title>Leveraging human Domain Knowledge to model an empirical Reward function
  for a Reinforcement Learning problem</title><categories>cs.AI cs.LG cs.SY eess.SY</categories><comments>4 pages, 3 figures, code shared on Google colab</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional Reinforcement Learning (RL) problems depend on an exhaustive
simulation environment that models real-world physics of the problem and trains
the RL agent by observing this environment. In this paper, we present a novel
approach to creating an environment by modeling the reward function based on
empirical rules extracted from human domain knowledge of the system under
study. Using this empirical rewards function, we will build an environment and
train the agent. We will first create an environment that emulates the effect
of setting cabin temperature through thermostat. This is typically done in RL
problems by creating an exhaustive model of the system with detailed
thermodynamic study. Instead, we propose an empirical approach to model the
reward function based on human domain knowledge. We will document some rules of
thumb that we usually exercise as humans while setting thermostat temperature
and try and model these into our reward function. This modeling of empirical
human domain rules into a reward function for RL is the unique aspect of this
paper. This is a continuous action space problem and using deep deterministic
policy gradient (DDPG) method, we will solve for maximizing the reward
function. We will create a policy network that predicts optimal temperature
setpoint given external temperature and humidity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07147</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07147</id><created>2019-09-16</created><authors><author><keyname>Bear</keyname><forenames>Helen</forenames></author><author><keyname>Harvey</keyname><forenames>Richard</forenames></author></authors><title>Alternative Visual Units for an Optimized Phoneme-Based Lipreading
  System</title><categories>eess.IV eess.AS</categories><comments>Accepted and published in Applied Sciences, 22pgs plus appendices and
  references</comments><journal-ref>Applied. Sciences. 2019, 9(18), 3870</journal-ref><doi>10.3390/app9183870</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lipreading is understanding speech from observed lip movements. An observed
series of lip motions is an ordered sequence of visual lip gestures. These
gestures are commonly known, but as yet are not formally defined, as `visemes'.
In this article, we describe a structured approach which allows us to create
speaker-dependent visemes with a fixed number of visemes within each set. We
create sets of visemes for sizes two to 45. Each set of visemes is based upon
clustering phonemes, thus each set has a unique phoneme-to-viseme mapping. We
first present an experiment using these maps and the Resource Management
Audio-Visual (RMAV) dataset which shows the effect of changing the viseme map
size in speaker-dependent machine lipreading and demonstrate that word
recognition with phoneme classifiers is possible. Furthermore, we show that
there are intermediate units between visemes and phonemes which are better
still. Second, we present a novel two-pass training scheme for phoneme
classifiers. This approach uses our new intermediary visual units from our
first experiment in the first pass as classifiers; before using the
phoneme-to-viseme maps, we retrain these into phoneme classifiers. This method
significantly improves on previous lipreading results with RMAV speakers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07154</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07154</id><created>2019-09-16</created><authors><author><keyname>Koelewijn</keyname><forenames>P. J. W.</forenames></author><author><keyname>T&#xf3;th</keyname><forenames>R.</forenames></author><author><keyname>Nijmeijer</keyname><forenames>H.</forenames></author></authors><title>Linear Parameter-Varying Control of Nonlinear Systems based on
  Incremental Stability</title><categories>eess.SY cs.SY</categories><comments>Submitted to 3rd IFAC Workshop on Linear Parameter Varying Systems
  (LPVS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Linear Parameter-Varying (LPV) framework has long been used to guarantee
performance and stability requirements of nonlinear (NL) systems mainly through
the $\mathcal{L}_2$-gain concept. However, recent research has pointed out that
current $\mathcal{L}_2$-gain based LPV synthesis methods can fail to guarantee
these requirements if stabilization of a non-zero operating condition (e.g.
reference tracking, constant disturbance rejection, etc.) is required. In this
paper, an LPV based synthesis method is proposed which is able to guarantee
incremental performance and stability of an NL system even with reference and
disturbance rejection objectives. The developed approach and the current
$\mathcal{L}_2$ LPV synthesis method are compared in a simulation study of the
position control problem of a Duffing oscillator, showing performance
improvements of the proposed method compared to the current
$\mathcal{L}_2$-based approach for tracking and disturbance rejection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07172</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07172</id><created>2019-09-16</created><authors><author><keyname>Zou</keyname><forenames>Hang</forenames></author><author><keyname>Zhang</keyname><forenames>Chao</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author><author><keyname>Saludjian</keyname><forenames>Lucas</forenames></author><author><keyname>Panciatici</keyname><forenames>Patrick</forenames></author></authors><title>Decision Set Optimization and Energy-Efficient MIMO Communications</title><categories>cs.IT cs.NE eess.SP math.IT</categories><comments>7 pages, 5 figures</comments><journal-ref>30th IEEE International Symposium on Personal, Indoor and Mobile
  Radio Communications (PIMRC'19),8-11 September 2019, Istanbul, Turkey</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Assuming that the number of possible decisions for a transmitter (e.g., the
number of possible beamforming vectors) has to be finite and is given, this
paper investigates for the first time the problem of determining the best
decision set when energy-efficiency maximization is pursued. We propose a
framework to find a good (finite) decision set which induces a minimal
performance loss w.r.t. to the continuous case. We exploit this framework for a
scenario of energy-efficient MIMO communications in which transmit power and
beamforming vectors have to be adapted jointly to the channel given under
finite-rate feedback. To determine a good decision set we propose an algorithm
which combines the approach of Invasive Weed Optimization (IWO) and an
Evolutionary Algorithm (EA). We provide a numerical analysis which illustrates
the benefits of our point of view. In particular, given a performance loss
level, the feedback rate can by reduced by 2 when the transmit decision set has
been designed properly by using our algorithm. The impact on energy-efficiency
is also seen to be significant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07185</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07185</id><created>2019-09-16</created><authors><author><keyname>Di Claudio</keyname><forenames>Elio D.</forenames></author><author><keyname>Parisi</keyname><forenames>Raffaele</forenames></author><author><keyname>Jacovitti</keyname><forenames>Giovanni</forenames></author></authors><title>P-BOOST: Parallel Boosting of Optimal Narrow-Band Direction of Arrival
  Estimators</title><categories>eess.SP</categories><comments>13 pages, 6 figures, general proposal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal Maximum Likelihood (ML), narrow-band direction finding cannot be
easily initialized in coherent and low signal to noise ratio environments.
Sparse under-determined solvers are considered as viable solutions to this
problem, since they drastically reduce the dimensionality of the search space
by exploiting the array model sparseness. However, because of quantized
locations, conventional sparse solvers present some ambiguity problems. In this
work, we propose a novel boosting scheme for ML-type estimators, referred to as
Parallel BOOSTer (P-BOOST), where a set of generalized MUSIC solutions provides
pre-estimates of the directions and the number of coherent paths for arbitrary
sensor array geometry and noise covariance. P-BOOST delivers improved and
reliable coarse parameter estimates to a further ML or sparse optimization
stage even in coherent and/or high noise scenarios. Moreover, its dataflow is
highly parallel, which is essential in foreseen remote sensing and
telecommunication applications and fully justifies its acronym.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07193</identifier>
 <datestamp>2020-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07193</id><created>2019-09-16</created><updated>2020-02-05</updated><authors><author><keyname>Bjelonic</keyname><forenames>Marko</forenames></author><author><keyname>Sankar</keyname><forenames>Prajish K.</forenames></author><author><keyname>Bellicoso</keyname><forenames>C. Dario</forenames></author><author><keyname>Vallery</keyname><forenames>Heike</forenames></author><author><keyname>Hutter</keyname><forenames>Marco</forenames></author></authors><title>Rolling in the Deep -- Hybrid Locomotion for Wheeled-Legged Robots using
  Online Trajectory Optimization</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wheeled-legged robots have the potential for highly agile and versatile
locomotion. The combination of legs and wheels might be a solution for any
real-world application requiring rapid, and long-distance mobility skills on
challenging terrain. In this paper, we present an online trajectory
optimization framework for wheeled quadrupedal robots capable of executing
hybrid walking-driving locomotion strategies. By breaking down the optimization
problem into a wheel and base trajectory planning, locomotion planning for high
dimensional wheeled-legged robots becomes more tractable, can be solved in
real-time on-board in a model predictive control fashion, and becomes robust
against unpredicted disturbances. The reference motions are tracked by a
hierarchical whole-body controller that sends torque commands to the robot. Our
approach is verified on a quadrupedal robot with non-steerable wheels attached
to its legs. The robot performs hybrid locomotion with a great variety of gait
sequences on rough terrain. Besides, we validated the robotic platform at the
Defense Advanced Research Projects Agency (DARPA) Subterranean Challenge, where
the robot rapidly mapped, navigated and explored dynamic underground
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07205</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07205</id><created>2019-09-12</created><authors><author><keyname>Schrade</keyname><forenames>Stefan O.</forenames></author><author><keyname>Menner</keyname><forenames>Marcel</forenames></author><author><keyname>Shirota</keyname><forenames>Camila</forenames></author><author><keyname>Winiger</keyname><forenames>Peter</forenames></author><author><keyname>Stutz</keyname><forenames>Alex</forenames></author><author><keyname>Zeilinger</keyname><forenames>Melanie N.</forenames></author><author><keyname>Lambercy</keyname><forenames>Olivier</forenames></author><author><keyname>Gassert</keyname><forenames>Roger</forenames></author></authors><title>Knee Compliance Reduces Peak Swing Phase Collision Forces in a
  Lower-Limb Exoskeleton Leg: A Test Bench Evaluation</title><categories>physics.med-ph cs.SY eess.SY</categories><comments>9 pages, 7 figures, 3 tabels</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Powered lower limb exoskeletons are a viable solution for people with a
spinal cord injury to regain mobility for their daily activities. However, the
commonly employed rigid actuation and pre-programmed trajectories increase the
risk of falling in case of collisions with external objects. Compliant
actuation may reduce forces during collisions, thus protecting hardware and
user. However, experimental data of collisions specific to lower limb
exoskeletons are not available. In this work, we investigated how a variable
stiffness actuator at the knee joint influences collision forces transmitted to
the user via the exoskeleton. In a test bench experiment, we compared three
configurations of an exoskeleton leg with a variable stiffness knee actuator in
(i) compliant or (ii) stiff configurations, and with (iii) a rigid actuator.
The peak torque observed at the pelvis was reduced from 260.2 Nm to 116.2 Nm as
stiffness decreased. In addition, the mechanical impulse was reduced by a
factor of three. These results indicate that compliance in the knee joint of an
exoskeleton can be favorable in case of collision and should be considered when
designing powered lower limb exoskeletons. Overall, this could decrease the
effort necessary to maintain balance after a collision and improved collision
handling in exoskeletons could result in safer use and benefit their usefulness
in daily life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07208</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07208</id><created>2019-09-16</created><authors><author><keyname>Rejaibi</keyname><forenames>Emna</forenames></author><author><keyname>Komaty</keyname><forenames>Ali</forenames></author><author><keyname>Meriaudeau</keyname><forenames>Fabrice</forenames></author><author><keyname>Agrebi</keyname><forenames>Said</forenames></author><author><keyname>Othmani</keyname><forenames>Alice</forenames></author></authors><title>MFCC-based Recurrent Neural Network for Automatic Clinical Depression
  Recognition and Assessment from Speech</title><categories>cs.HC cs.AI cs.LG eess.AS</categories><comments>14 pages, 6 figures, 9 tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Major depression, also known as clinical depression, is a constant sense of
despair and hopelessness. It is a major mental disorder that can affect people
of any age including children and that affect negatively person's personal
life, work life, social life and health conditions. Globally, over 300 million
people of all ages are estimated to suffer from clinical depression. A deep
recurrent neural network-based framework is presented in this paper to detect
depression and to predict its severity level from speech. Low-level and
high-level audio features are extracted from audio recordings to predict the 24
scores of the Patient Health Questionnaire (a depression assessment test) and
the binary class of depression diagnosis. To overcome the problem of the small
size of Speech Depression Recognition (SDR) datasets, data augmentation
techniques are used to expand the labeled training set and also transfer
learning is performed where the proposed model is trained on a related task and
reused as starting point for the proposed model on SDR task. The proposed
framework is evaluated on the DAIC-WOZ corpus of the AVEC2017 challenge and
promising results are obtained. An overall accuracy of 76.27\% with a root mean
square error of 0.4 is achieved in assessing depression, while a root mean
square error of 0.168 is achieved in predicting the depression severity levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07210</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07210</id><created>2019-09-12</created><authors><author><keyname>Khairullah</keyname><forenames>Shawkat S.</forenames></author><author><keyname>Mostfa</keyname><forenames>Ahmed A.</forenames></author></authors><title>Reliability and Safety Modeling of a Digital Feed Water Control System</title><categories>eess.SY cs.SY eess.SP</categories><comments>12 pages, 7 figures, conference</comments><journal-ref>The international conference held by University of Al- Hamdania
  2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much digital instrumentation and control systems embedded in the critical
medical healthcare equipment aerospace devices and nuclear industry have
obvious consequence of different failure modes. These failures can affect the
behavior of the overall safety critical digital system and its ability to
deliver its dependability attributes if any defected area that could be a
hardware component or software code embedded inside the digital system is not
detected and repaired appropriately. The safety and reliability analysis of
safety critical systems can be accomplished with Markov modeling techniques
which could express the dynamic and regenerative behavior of the digital
control system. Certain states in the system represent system failure while
others represent fault free behavior or correct operation in the presence of
faults. This paper presents the development of a safety and reliability
modeling of a digital feedwater control system using Markov based chain models.
All the Markov states and the transitions between these states were assumed and
calculated from the control logic for the digital control system. Finally based
on the simulation results of modeling the digital feedwater control system the
system does meet its reliability requirement with the probability of being in
fully operational states is 0.99 over a 6 months time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07239</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07239</id><created>2019-09-16</created><updated>2020-02-17</updated><authors><author><keyname>K&#xf6;pf</keyname><forenames>Florian</forenames></author><author><keyname>Ramsteiner</keyname><forenames>Simon</forenames></author><author><keyname>Flad</keyname><forenames>Michael</forenames></author><author><keyname>Hohmann</keyname><forenames>S&#xf6;ren</forenames></author></authors><title>Adaptive Dynamic Programming for Model-free Tracking of Trajectories
  with Time-varying Parameters</title><categories>eess.SY cs.LG cs.RO cs.SY</categories><comments>This is a preprint submitted to the Int J Adapt Control Signal
  Process. The substantially revised version will be published in the Int J
  Adapt Control Signal Process (DOI: 10.1002/ACS.3106)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to autonomously learn to control unknown systems optimally w.r.t. an
objective function, Adaptive Dynamic Programming (ADP) is well-suited to adapt
controllers based on experience from interaction with the system. In recent
years, many researchers focused on the tracking case, where the aim is to
follow a desired trajectory. So far, ADP tracking controllers assume that the
reference trajectory follows time-invariant exo-system dynamics-an assumption
that does not hold for many applications. In order to overcome this limitation,
we propose a new Q-function which explicitly incorporates a parametrized
approximation of the reference trajectory. This allows to learn to track a
general class of trajectories by means of ADP. Once our Q-function has been
learned, the associated controller copes with time-varying reference
trajectories without need of further training and independent of exo-system
dynamics. After proposing our general model-free off-policy tracking method, we
provide analysis of the important special case of linear quadratic tracking. We
conclude our paper with an example which demonstrates that our new method
successfully learns the optimal tracking controller and outperforms existing
approaches in terms of tracking error and cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07247</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07247</id><created>2019-09-16</created><authors><author><keyname>Strai&#x17e;ys</keyname><forenames>Art&#x16b;ras</forenames></author><author><keyname>Burke</keyname><forenames>Michael</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Subramanian</forenames></author></authors><title>Surfing on an uncertain edge: Precision cutting of soft tissue using
  torque-based medium classification</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precision cutting of soft-tissue remains a challenging problem in robotics,
due to the complex and unpredictable mechanical behaviour of tissue under
manipulation. Here, we consider the challenge of cutting along the boundary
between two soft mediums, a problem that is made extremely difficult due to
visibility constraints, which means that the precise location of the cutting
trajectory is typically unknown. This paper introduces a novel strategy to
address this task, using a binary medium classifier trained using joint torque
measurements, and a closed loop control law that relies on an error signal
compactly encoded in the decision boundary of the classifier. We illustrate
this on a grapefruit cutting task, successfully modulating a nominal trajectory
fit using dynamic movement primitives to follow the boundary between grapefruit
pulp and peel using torque based medium classification. Results show that this
control strategy is successful in 72 % of attempts in contrast to control using
a nominal trajectory, which only succeeds in 50 % of attempts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07270</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07270</id><created>2019-09-16</created><authors><author><keyname>Daws</keyname><forenames>Joseph</forenames><suffix>Jr.</suffix></author><author><keyname>Petrosyan</keyname><forenames>Armenak</forenames></author><author><keyname>Tran</keyname><forenames>Hoang</forenames></author><author><keyname>Webster</keyname><forenames>Clayton G.</forenames></author></authors><title>A Weighted $\ell_1$-Minimization Approach For Wavelet Reconstruction of
  Signals and Images</title><categories>eess.IV cs.NA eess.SP math.NA</categories><comments>16 pages and 20 figures</comments><msc-class>65D99</msc-class><acm-class>I.4.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this effort, we propose a convex optimization approach based on weighted
$\ell_1$-regularization for reconstructing objects of interest, such as signals
or images, that are sparse or compressible in a wavelet basis. We recover the
wavelet coefficients associated to the functional representation of the object
of interest by solving our proposed optimization problem. We give a specific
choice of weights and show numerically that the chosen weights admit efficient
recovery of objects of interest from either a set of sub-samples or a noisy
version. Our method not only exploits sparsity but also helps promote a
particular kind of structured sparsity often exhibited by many signals and
images. Furthermore, we illustrate the effectiveness of the proposed convex
optimization problem by providing numerical examples using both orthonormal
wavelets and a frame of wavelets. We also provide an adaptive choice of weights
which is a modification of the iteratively reweighted $\ell_1$-minimization
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07273</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07273</id><created>2019-09-16</created><updated>2019-09-26</updated><authors><author><keyname>Chen</keyname><forenames>Kai-Xuan</forenames></author><author><keyname>Wu</keyname><forenames>Xiao-Jun</forenames></author><author><keyname>Ren</keyname><forenames>Jie-Yi</forenames></author><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Kittler</keyname><forenames>Josef</forenames></author></authors><title>More About Covariance Descriptors for Image Set Coding: Log-Euclidean
  Framework based Kernel Matrix Representation</title><categories>cs.CV eess.IV</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a family of structural descriptors for visual data, namely
covariance descriptors (CovDs) that lie on a non-linear symmetric positive
definite (SPD) manifold, a special type of Riemannian manifolds. We propose an
improved version of CovDs for image set coding by extending the traditional
CovDs from Euclidean space to the SPD manifold. Specifically, the manifold of
SPD matrices is a complete inner product space with the operations of
logarithmic multiplication and scalar logarithmic multiplication defined in the
Log-Euclidean framework. In this framework, we characterise covariance
structure in terms of the arc-cosine kernel which satisfies Mercer's condition
and propose the operation of mean centralization on SPD matrices. Furthermore,
we combine arc-cosine kernels of different orders using mixing parameters
learnt by kernel alignment in a supervised manner. Our proposed framework
provides a lower-dimensional and more discriminative data representation for
the task of image set classification. The experimental results demonstrate its
superior performance, measured in terms of recognition accuracy, as compared
with the state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07352</identifier>
 <datestamp>2019-09-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07352</id><created>2019-09-16</created><updated>2019-09-19</updated><authors><author><keyname>Tan</keyname><forenames>Ke</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Zhang</keyname><forenames>Shi-Xiong</forenames></author><author><keyname>Yu</keyname><forenames>Meng</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>Audio-Visual Speech Separation and Dereverberation with a Two-Stage
  Multimodal Network</title><categories>eess.AS cs.SD eess.SP</categories><comments>11 pages, in submission to IEEE JSTSP Special Issue on Deep Learning
  for Multi-modal Intelligence across Speech, Language, Vision, and
  Heterogeneous Signals</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background noise, interfering speech and room reverberation frequently
distort target speech in real listening environments. In this study, we address
joint speech separation and dereverberation, which aims to separate target
speech from background noise, interfering speech and room reverberation. In
order to tackle this fundamentally difficult problem, we propose a novel
multimodal network that exploits both audio and visual signals. The proposed
network architecture adopts a two-stage strategy, where a separation module is
employed to attenuate background noise and interfering speech in the first
stage and a dereverberation module to suppress room reverberation in the second
stage. The two modules are first trained separately, and then integrated for
joint training, which is based on a new multi-objective loss function. Our
experimental results show that the proposed multimodal network yields
consistently better objective intelligibility and perceptual quality than
several one-stage and two-stage baselines. We find that our network achieves a
21.10% improvement in ESTOI and a 0.79 improvement in PESQ over the unprocessed
mixtures. Moreover, our network architecture does not require the knowledge of
the number of speakers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07377</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07377</id><created>2019-09-16</created><authors><author><keyname>Vladimirov</keyname><forenames>Igor G.</forenames></author><author><keyname>James</keyname><forenames>Matthew R.</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>A Karhunen-Loeve expansion for one-mode open quantum harmonic
  oscillators using the eigenbasis of the two-point commutator kernel</title><categories>quant-ph cs.SY eess.SY math-ph math.MP math.OC math.PR</categories><comments>9 pages, accepted to the 2019 Australian and New Zealand Control
  Conference (ANZCC 2019), Auckland University of Technology, Auckland, New
  Zealand, 27-29 November 2019</comments><msc-class>81S25, 81Q93, 81P16, 81S30, 81S05, 81S22, 81P40, 81Q10, 60G15,
  47G10, 34B09, 34L10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers one-mode open quantum harmonic oscillators with a pair
of conjugate position and momentum variables driven by vacuum bosonic fields
according to a linear quantum stochastic differential equation. Such systems
model cavity resonators in quantum optical experiments. Assuming that the
quadratic Hamiltonian of the oscillator is specified by a positive definite
energy matrix, we consider a modified version of the quantum Karhunen-Loeve
expansion of the system variables proposed recently. The expansion employs
eigenvalues and eigenfunctions of the two-point commutator kernel for linearly
transformed system variables. We take advantage of the specific structure of
this eigenbasis in the one-mode case (including its connection with the
classical Ornstein-Uhlenbeck process). These results are applied to computing
quadratic-exponential cost functionals which provide robust performance
criteria for risk-sensitive control of open quantum systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07445</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07445</id><created>2019-09-16</created><authors><author><keyname>S&#xe1;nchez</keyname><forenames>David Cerezo</forenames></author></authors><title>Truthful and Faithful Monetary Policy for a Stablecoin Conducted by a
  Decentralised, Encrypted Artificial Intelligence</title><categories>cs.CR cs.AI cs.GT cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Holy Grail of a decentralised stablecoin is achieved on rigorous
mathematical frameworks, obtaining multiple advantageous proofs: stability,
convergence, truthfulness, faithfulness, and malicious-security. These
properties could only be attained by the novel and interdisciplinary
combination of previously unrelated fields: model predictive control, deep
learning, alternating direction method of multipliers (consensus-ADMM),
mechanism design, secure multi-party computation, and zero-knowledge proofs.
For the first time, this paper proves:
  - the feasibility of decentralising the central bank while securely
preserving its independence in a decentralised computation setting
  - the benefits for price stability of combining mechanism design, provable
security, and control theory, unlike the heuristics of previous stablecoins
  - the implementation of complex monetary policies on a stablecoin, equivalent
to the ones used by central banks and beyond the current fixed rules of
cryptocurrencies that hinder their price stability
  - methods to circumvent the impossibilities of Guaranteed Output Delivery
(G.O.D.) and fairness: standing on truthfulness and faithfulness, we reach
G.O.D. and fairness under the assumption of rational parties
  As a corollary, a decentralised artificial intelligence is able to conduct
the monetary policy of a stablecoin, minimising human intervention.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07474</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07474</id><created>2019-09-16</created><authors><author><keyname>Lee</keyname><forenames>Hoileong</forenames></author><author><keyname>Matin</keyname><forenames>Tahreema</forenames></author><author><keyname>Gleeson</keyname><forenames>Fergus</forenames></author><author><keyname>Grau</keyname><forenames>Vicente</forenames></author></authors><title>Efficient 3D Fully Convolutional Networks for Pulmonary Lobe
  Segmentation in CT Images</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The human lung is a complex respiratory organ, consisting of five distinct
anatomic compartments called lobes. Accurate and automatic segmentation of
these pulmonary lobes from computed tomography (CT) images is of clinical
importance for lung disease assessment and treatment planning. However, this
task is challenging due to ambiguous lobar boundaries, anatomical variations
and pathological deformations. In this paper, we propose a high-resolution and
efficient 3D fully convolutional network to automatically segment the lobes. We
refer to the network as Pulmonary Lobe Segmentation Network (PLS-Net), which is
designed to efficiently exploit 3D spatial and contextual information from
high-resolution volumetric CT images for effective volume-to-volume learning
and inference. The PLS-Net is based on an asymmetric encoder-decoder
architecture with three novel components: (i) 3D depthwise separable
convolutions to improve the network efficiency by factorising each regular 3D
convolution into two simpler operations; (ii) dilated residual dense blocks to
efficiently expand the receptive field of the network and aggregate multi-scale
contextual information for segmentation; and (iii) input reinforcement at each
downsampled resolution to compensate for the loss of spatial information due to
convolutional and downsampling operations. We evaluated the proposed PLS-Net on
a multi-institutional dataset that consists of 210 CT images acquired from
patients with a wide range of lung abnormalities. Experimental results show
that our PLS-Net achieves state-of-the-art performance with better
computational efficiency. Further experiments confirm the effectiveness of each
novel component of the PLS-Net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07476</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07476</id><created>2019-09-16</created><authors><author><keyname>Mukherjee</keyname><forenames>Pratik</forenames></author><author><keyname>Santilli</keyname><forenames>Matteo</forenames></author><author><keyname>Gasparri</keyname><forenames>Andrea</forenames></author><author><keyname>Williams</keyname><forenames>Ryan K</forenames></author></authors><title>Experimental Validation of Stable Coordination for Multi-Robot Systems
  with Limited Fields of View using a PortableMulti-Robot Testbed</title><categories>eess.SY cs.RO cs.SY</categories><comments>Accepted as Extended Abstract at THE 2ND IEEE INTERNATIONAL SYMPOSIUM
  ON MULTI-ROBOT AND MULTI-AGENT SYSTEMS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of stable coordinated motion in
multi-robot systems with limited fields of view (FOVs). These problems arise
naturally for multi-robot systems that interact based on sensing, such as our
case study of multiple unmanned aerial vehicles (UAVs) each equipped with
several cameras that are used for detecting neighboring UAVs. In this context,
our contributions are: i) first, we derive a framework for studying stable
motion and distributed topology control for multi-robot systems with limited
FOVs; and ii) Then, we provide experimental results in indoor and challenging
outdoor environments (e.g., with wind speeds up to 10 mph) with a team of UAVs
to demonstrate the performance of the proposed control framework using a
portable multi-robot experimental set-up.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07480</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07480</id><created>2019-09-16</created><authors><author><keyname>Li</keyname><forenames>Peichao</forenames></author><author><keyname>Zhou</keyname><forenames>Xiao-Yun</forenames></author><author><keyname>Wang</keyname><forenames>Zhao-Yang</forenames></author><author><keyname>Yang</keyname><forenames>Guang-Zhong</forenames></author></authors><title>Z-Net: an Asymmetric 3D DCNN for Medical CT Volume Segmentation</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>8 pages, 9 figures, two tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate volume segmentation from the Computed Tomography (CT) scan is a
common prerequisite for pre-operative planning, intra-operative guidance and
quantitative assessment of therapeutic outcomes in robot-assisted Minimally
Invasive Surgery (MIS). The use of 3D Deep Convolutional Neural Network (DCNN)
is a viable solution for this task but is memory intensive. The use of patch
division can mitigate this issue in practice, but can cause discontinuities
between the adjacent patches and severe class-imbalances within individual
sub-volumes. This paper presents a new patch division approach - Patch-512 to
tackle the class-imbalance issue by preserving a full field-of-view of the
objects in the XY planes. To achieve better segmentation results based on these
asymmetric patches, a 3D DCNN architecture using asymmetrical separable
convolutions is proposed. The proposed network, called Z-Net, can be seamlessly
integrated into existing 3D DCNNs such as 3D U-Net and V-Net, for improved
volume segmentation. Detailed validation of the method is provided for CT
aortic, liver and lung segmentation, demonstrating the effectiveness and
practical value of the method for intra-operative 3D navigation in
robot-assisted MIS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07482</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07482</id><created>2019-09-10</created><authors><author><keyname>AlAshery</keyname><forenames>Mohamed Kareem</forenames></author><author><keyname>EI-Khattam</keyname><forenames>Walid</forenames></author><author><keyname>Badr</keyname><forenames>M. Abd El Rehim</forenames></author></authors><title>Coupling of Wind Farms with Nuclear Power Plants</title><categories>physics.soc-ph cs.SY eess.SY</categories><comments>in proceedings of GCC CIGRE Conference, Abu Dhabi, UAE, Nov 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the planning phase of siting both new Wind Farms (WFs) and Nuclear Power
Plants (NPPs), many benefits and challenges exist. An important aspect taken
into consideration during the NPP siting is the existence of ultimate heat sink
which is sea water in most cases. That is why most NPPs are sited on sea
coasts. On the other hand, during WF siting, the main influential aspect is the
existence of good wind resources. Many coastal areas around the world fulfill
this requirement for WF siting. Coupling both NPPs and WFs in one site or
nearby has many benefits and obstacles as well. In this paper, the
implementation aspects of NPP and WF coupling/adjacency will be discussed in
detail. Based on international experience and literature reviews, the benefits
and obstacles of this coupling/adjacency are studied and evaluated. Various
case studies are carried out to verify the coupling/adjacency concept. The
benefits of WF geographical distribution are examined on two candidate sites in
Egypt. The WF capacity credit is calculated by implementing the PJM method
using actual three-year hourly wind data. The obtained results are evaluated to
study their applicability in the Egyptian environment and their applicability
for countries in the Gulf region. Finally, both the coupling idea and the
capacity credit values can be used to help decision makers in the planning
phase as well as in the selection of WT characteristics as discussed in this
paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07492</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07492</id><created>2019-09-16</created><authors><author><keyname>Massicot</keyname><forenames>Olivier</forenames></author><author><keyname>Marecek</keyname><forenames>Jakub</forenames></author></authors><title>On-line Non-Convex Constrained Optimization</title><categories>math.OC cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time-varying non-convex continuous-valued non-linear constrained optimization
is a fundamental problem. We study conditions wherein a momentum-like
regularising term allow for the tracking of local optima by considering an
ordinary differential equation (ODE). We then derive an efficient algorithm
based on a predictor-corrector method, to track the ODE solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07522</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07522</id><created>2019-09-16</created><authors><author><keyname>Gokhale</keyname><forenames>Pranav</forenames></author><author><keyname>Ding</keyname><forenames>Yongshan</forenames></author><author><keyname>Propson</keyname><forenames>Thomas</forenames></author><author><keyname>Winkler</keyname><forenames>Christopher</forenames></author><author><keyname>Leung</keyname><forenames>Nelson</forenames></author><author><keyname>Shi</keyname><forenames>Yunong</forenames></author><author><keyname>Schuster</keyname><forenames>David I.</forenames></author><author><keyname>Hoffmann</keyname><forenames>Henry</forenames></author><author><keyname>Chong</keyname><forenames>Frederic T.</forenames></author></authors><title>Partial Compilation of Variational Algorithms for Noisy
  Intermediate-Scale Quantum Machines</title><categories>quant-ph cs.SY eess.SY</categories><comments>Appearing in the 52nd Annual IEEE/ACM International Symposium on
  Microarchitecture (MICRO-52), October 12-16, 2019, Columbus, OH, USA</comments><doi>10.1145/3352460.3358313</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum computing is on the cusp of reality with Noisy Intermediate-Scale
Quantum (NISQ) machines currently under development and testing. Some of the
most promising algorithms for these machines are variational algorithms that
employ classical optimization coupled with quantum hardware to evaluate the
quality of each candidate solution. Recent work used GRadient Descent Pulse
Engineering (GRAPE) to translate quantum programs into highly optimized machine
control pulses, resulting in a significant reduction in the execution time of
programs. This is critical, as quantum machines can barely support the
execution of short programs before failing.
  However, GRAPE suffers from high compilation latency, which is untenable in
variational algorithms since compilation is interleaved with computation. We
propose two strategies for partial compilation, exploiting the structure of
variational circuits to pre-compile optimal pulses for specific blocks of
gates. Our results indicate significant pulse speedups ranging from 1.5x-3x in
typical benchmarks, with only a small fraction of the compilation latency of
GRAPE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07526</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07526</id><created>2019-09-16</created><authors><author><keyname>Efremova</keyname><forenames>Dina B.</forenames></author><author><keyname>Sankupellay</keyname><forenames>Mangalam</forenames></author><author><keyname>Konovalov</keyname><forenames>Dmitry A.</forenames></author></authors><title>Data-Efficient Classification of Birdcall Through Convolutional Neural
  Networks Transfer Learning</title><categories>cs.CV cs.MM cs.SD eess.AS eess.IV</categories><comments>Accepted for IEEE Digital Image Computing: Techniques and
  Applications, 2019 (DICTA 2019), 2-4 December 2019 in Perth, Australia,
  http://dicta2019.dictaconference.org/index.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning Convolutional Neural Network (CNN) models are powerful
classification models but require a large amount of training data. In niche
domains such as bird acoustics, it is expensive and difficult to obtain a large
number of training samples. One method of classifying data with a limited
number of training samples is to employ transfer learning. In this research, we
evaluated the effectiveness of birdcall classification using transfer learning
from a larger base dataset (2814 samples in 46 classes) to a smaller target
dataset (351 samples in 10 classes) using the ResNet-50 CNN. We obtained 79%
average validation accuracy on the target dataset in 5-fold cross-validation.
The methodology of transfer learning from an ImageNet-trained CNN to a
project-specific and a much smaller set of classes and images was extended to
the domain of spectrogram images, where the base dataset effectively played the
role of the ImageNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07545</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07545</id><created>2019-09-16</created><authors><author><keyname>Roxas</keyname><forenames>Menandro</forenames></author><author><keyname>Oishi</keyname><forenames>Takeshi</forenames></author></authors><title>Real-Time Variational Fisheye Stereo without Rectification and
  Undistortion</title><categories>cs.RO cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dense 3D maps from wide-angle cameras is beneficial to robotics applications
such as navigation and autonomous driving. In this work, we propose a real-time
dense 3D mapping method for fisheye cameras without explicit rectification and
undistortion. We extend the conventional variational stereo method by
constraining the correspondence search along the epipolar curve using a
trajectory field induced by camera motion. We also propose a fast way of
generating the trajectory field without increasing the processing time compared
to conventional rectified methods. With our implementation, we were able to
achieve real-time processing using modern GPUs. Our results show the advantages
of our non-rectified dense mapping approach compared to rectified variational
methods and non-rectified discrete stereo matching methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07554</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07554</id><created>2019-09-16</created><authors><author><keyname>Wang</keyname><forenames>Yining</forenames></author><author><keyname>Chen</keyname><forenames>Mingzhe</forenames></author><author><keyname>Yang</keyname><forenames>Zhaohui</forenames></author><author><keyname>Hao</keyname><forenames>Xue</forenames></author><author><keyname>Luo</keyname><forenames>Tao</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author></authors><title>Gated Recurrent Units Learning for Optimal Deployment of Visible Light
  Communications Enabled UAVs</title><categories>eess.SP cs.LG stat.ML</categories><comments>This paper has been accepted by the 2019 IEEE Global Communications
  Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of optimizing the deployment of unmanned aerial
vehicles (UAVs) equipped with visible light communication (VLC) capabilities is
studied. In the studied model, the UAVs can simultaneously provide
communications and illumination to service ground users. Ambient illumination
increases the interference over VLC links while reducing the illumination
threshold of the UAVs. Therefore, it is necessary to consider the illumination
distribution of the target area for UAV deployment optimization. This problem
is formulated as an optimization problem whose goal is to minimize the total
transmit power while meeting the illumination and communication requirements of
users. To solve this problem, an algorithm based on the machine learning
framework of gated recurrent units (GRUs) is proposed. Using GRUs, the UAVs can
model the long-term historical illumination distribution and predict the future
illumination distribution. In order to reduce the complexity of the prediction
algorithm while accurately predicting the illumination distribution, a Gaussian
mixture model (GMM) is used to fit the illumination distribution of the target
area at each time slot. Based on the predicted illumination distribution, the
optimization problem is proved to be a convex optimization problem that can be
solved by using duality. Simulations using real data from the Earth
observations group (EOG) at NOAA/NCEI show that the proposed approach can
achieve up to 22.1% reduction in transmit power compared to a conventional
optimal UAV deployment that does not consider the illumination distribution.
The results also show that UAVs must hover at areas having strong illumination,
thus providing useful guidelines on the deployment of VLC-enabled UAVs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07558</identifier>
 <datestamp>2019-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07558</id><created>2019-09-16</created><updated>2019-09-24</updated><authors><author><keyname>Yu</keyname><forenames>Wanting</forenames></author><author><keyname>Yu</keyname><forenames>Hongyi</forenames></author><author><keyname>Jiang</keyname><forenames>Lingyun</forenames></author><author><keyname>Zhang</keyname><forenames>Mengli</forenames></author><author><keyname>Qiao</keyname><forenames>Kai</forenames></author><author><keyname>Wang</keyname><forenames>Linyuan</forenames></author><author><keyname>Yan</keyname><forenames>Bin</forenames></author></authors><title>HAD-GAN: A Human-perception Auxiliary Defense GAN to Defend Adversarial
  Examples</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial examples reveal the vulnerability and unexplained nature of
neural networks. Studying the defense of adversarial examples is of
considerable practical importance. Most adversarial examples that misclassify
networks are often undetectable by humans. In this paper, we propose a defense
model to train the classifier into a human-perception classification model with
shape preference. The proposed model comprising a texture transfer network
(TTN) and an auxiliary defense generative adversarial networks (GAN) is called
Human-perception Auxiliary Defense GAN (HAD-GAN). The TTN is used to extend the
texture samples of a clean image and helps classifiers focus on its shape. GAN
is utilized to form a training framework for the model and generate the
necessary images. A series of experiments conducted on MNIST, Fashion-MNIST and
CIFAR10 show that the proposed model outperforms the state-of-the-art defense
methods for network robustness. The model also demonstrates a significant
improvement on defense capability of adversarial examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07575</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07575</id><created>2019-09-16</created><updated>2019-11-18</updated><authors><author><keyname>Wang</keyname><forenames>Chengyi</forenames></author><author><keyname>Wu</keyname><forenames>Yu</forenames></author><author><keyname>Liu</keyname><forenames>Shujie</forenames></author><author><keyname>Yang</keyname><forenames>Zhenglu</forenames></author><author><keyname>Zhou</keyname><forenames>Ming</forenames></author></authors><title>Bridging the Gap between Pre-Training and Fine-Tuning for End-to-End
  Speech Translation</title><categories>cs.CL eess.AS</categories><comments>AAAI2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end speech translation, a hot topic in recent years, aims to translate
a segment of audio into a specific language with an end-to-end model.
Conventional approaches employ multi-task learning and pre-training methods for
this task, but they suffer from the huge gap between pre-training and
fine-tuning. To address these issues, we propose a Tandem Connectionist
Encoding Network (TCEN) which bridges the gap by reusing all subnets in
fine-tuning, keeping the roles of subnets consistent, and pre-training the
attention module. Furthermore, we propose two simple but effective methods to
guarantee the speech encoder outputs and the MT encoder inputs are consistent
in terms of semantic representation and sequence length. Experimental results
show that our model outperforms baselines 2.2 BLEU on a large benchmark
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07577</identifier>
 <datestamp>2019-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07577</id><created>2019-09-16</created><updated>2019-11-06</updated><authors><author><keyname>Shoeiby</keyname><forenames>Mehrdad</forenames></author><author><keyname>Aliakbarian</keyname><forenames>Sadegh</forenames></author><author><keyname>Anwar</keyname><forenames>Saeed</forenames></author><author><keyname>Petersson</keyname><forenames>Lars</forenames></author></authors><title>Multi-FAN: Multi-Spectral Mosaic Super-Resolution Via Multi-Scale
  Feature Aggregation Network</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel method to super-resolve multi-spectral images
captured by modern real-time single-shot mosaic image sensors, also known as
multi-spectral cameras. Our contribution is two-fold. Firstly, we super-resolve
multi-spectral images from mosaic images rather than image cubes, which helps
to take into account the spatial offset of each wavelength. Secondly, we
introduce an external multi-scale feature aggregation network (Multi-FAN) which
concatenates the feature maps with different levels of semantic information
throughout a super-resolution (SR) network. A cascade of convolutional layers
then implicitly selects the most valuable feature maps to generate a mosaic
image. This mosaic image is then merged with the mosaic image generated by the
SR network to produce a quantitatively superior image. We apply our Multi-FAN
to RCAN (Residual Channel Attention Network), which is the state-of-the-art SR
algorithm. We show that Multi-FAN improves both quantitative results and well
as inference time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07581</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07581</id><created>2019-09-17</created><updated>2019-09-19</updated><authors><author><keyname>Rathore</keyname><forenames>Saima</forenames></author><author><keyname>Iftikhar</keyname><forenames>Muhammad A.</forenames></author><author><keyname>Gurcan</keyname><forenames>Metin N.</forenames></author><author><keyname>Mourelatos</keyname><forenames>Zissimos</forenames></author></authors><title>Radiopathomics: Integration of radiographic and histologic
  characteristics for prognostication in glioblastoma</title><categories>eess.IV cs.CV</categories><comments>10 pages, 5 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Both radiographic (Rad) imaging, such as multi-parametric magnetic resonance
imaging, and digital pathology (Path) images captured from tissue samples are
currently acquired as standard clinical practice for glioblastoma tumors. Both
these data streams have been separately used for diagnosis and treatment
planning, despite the fact that they provide complementary information. In this
research work, we aimed to assess the potential of both Rad and Path images in
combination and comparison. An extensive set of engineered features was
extracted from delineated tumor regions in Rad images, comprising T1, T1-Gd,
T2, T2-FLAIR, and 100 random patches extracted from Path images. Specifically,
the features comprised descriptors of intensity, histogram, and texture, mainly
quantified via gray-level-co-occurrence matrix and gray-level-run-length
matrices. Features extracted from images of 107 glioblastoma patients,
downloaded from The Cancer Imaging Archive, were run through support vector
machine for classification using leave-one-out cross-validation mechanism, and
through support vector regression for prediction of continuous survival
outcome. The Pearson correlation coefficient was estimated to be 0.75, 0.74,
and 0.78 for Rad, Path and RadPath data. The area-under the receiver operating
characteristic curve was estimated to be 0.74, 0.76 and 0.80 for Rad, Path and
RadPath data, when patients were discretized into long- and short-survival
groups based on average survival cutoff. Our results support the notion that
synergistically using Rad and Path images may lead to better prognosis at the
initial presentation of the disease, thereby facilitating the targeted
enrollment of patients into clinical trials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07596</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07596</id><created>2019-09-17</created><authors><author><keyname>Suprem</keyname><forenames>Abhijit</forenames></author><author><keyname>Pu</keyname><forenames>Calton</forenames></author></authors><title>ASSED -- A Framework for Identifying Physical Events through Adaptive
  Social Sensor Data Filtering</title><categories>cs.SI cs.LG eess.SP</categories><journal-ref>ACM DEBS 2019</journal-ref><doi>10.1145/3328905.3329510</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Physical event detection has long been the domain of static event processors
operating on numeric sensor data. This works well for large scale strong-signal
events such as hurricanes, and important classes of events such as earthquakes.
However, for a variety of domains there is insufficient sensor coverage, e.g.,
landslides, wildfires, and flooding. Social networks have provided massive
volume of data from billions of users, but data from these generic social
sensors contain much more noise than physical sensors. One of the most
difficult challenges presented by social sensors is \textit{concept drift},
where the terms associated with a phenomenon evolve and change over time,
rendering static machine learning (ML) classifiers less effective. To address
this problem, we develop the ASSED (Adaptive Social Sensor Event Detection)
framework with an ML-based event processing engine and show how it can perform
simple and complex physical event detection on strong- \textit{and} weak-signal
with low-latency, high scalability, and accurate coverage. Specifically, ASSED
is a framework to support continuous filter generation and updates with machine
learning using streaming data from high-confidence sources (physical and
annotated sensors) and social networks. We build ASSED to support procedures
for integrating high-confidence sources into social sensor event detection to
generate high-quality filters and to perform dynamic filter selection by
tracking its own performance. We demonstrate ASSED capabilities through a
landslide detection application that detects almost 350\% more landslides
compared to static approaches. More importantly, ASSED automates the handling
of concept drift: four years after initial data collection and classifier
training, ASSED achieves event detection accuracy of 0.988 (without expert
manual intervention), compared to 0.762 for static approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07600</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07600</id><created>2019-09-17</created><authors><author><keyname>Zhang</keyname><forenames>Xinlin</forenames></author><author><keyname>Lu</keyname><forenames>Hengfa</forenames></author><author><keyname>Guo</keyname><forenames>Di</forenames></author><author><keyname>Bao</keyname><forenames>Lijun</forenames></author><author><keyname>Huang</keyname><forenames>Feng</forenames></author><author><keyname>Qu</keyname><forenames>Xiaobo</forenames></author></authors><title>A Convergence Proof of Projected Fast Iterative Soft-thresholding
  Algorithm for Parallel Magnetic Resonance Imaging</title><categories>eess.IV cs.CV math.OC physics.med-ph</categories><comments>10 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The boom of non-uniform sampling and compressed sensing techniques
dramatically alleviates the prolonged data acquisition problem of magnetic
resonance imaging. Sparse reconstruction, thanks to its fast computation and
promising performance, has attracted researchers to put numerous efforts on it
and has been adopted in commercial scanners. Algorithms for solving the sparse
reconstruction models play an essential role in sparse reconstruction. Being a
simple and efficient algorithm for sparse reconstruction, pFISTA has been
successfully extended to parallel imaging, however, its convergence criterion
is still an open question, confusing users on the setting of the parameter
which assures the convergence of the algorithm. In this work, we prove the
convergence of the parallel imaging version pFISTA. Specifically, the
convergences of two well-known parallel imaging reconstruction models, SENSE
and SPIRiT, solved by pFISTA are proved. Experiments on brain images
demonstrate the validity of the convergence criterion. The convergence
criterion proofed in this work can help users quickly obtain the satisfy
parameter that admits faithful results and fast convergence speeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07616</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07616</id><created>2019-09-17</created><authors><author><keyname>Duan</keyname><forenames>Qiyou</forenames></author><author><keyname>Kim</keyname><forenames>Taejoon</forenames></author><author><keyname>Dai</keyname><forenames>Lin</forenames></author><author><keyname>Perrins</keyname><forenames>Erik</forenames></author></authors><title>Coherence Statistics of Structured Random Ensembles and Support
  Detection Bounds for OMP</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted for publication in the IEEE Signal Processing Letters</comments><doi>10.1109/LSP.2019.2942737</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A structured random matrix ensemble that maintains constant modulus entries
and unit-norm columns, often called a random phase-rotated (RPR) matrix, is
considered in this paper. We analyze the coherence statistics of RPR
measurement matrices and apply them to acquire probabilistic performance
guarantees of orthogonal matching pursuit (OMP) for support detection (SD). It
is revealed via numerical simulations that the SD performance guarantee
provides a tight characterization, especially when the signal is sparse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07654</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07654</id><created>2019-09-17</created><authors><author><keyname>Fontanini</keyname><forenames>Tomaso</forenames></author><author><keyname>Iotti</keyname><forenames>Eleonora</forenames></author><author><keyname>Prati</keyname><forenames>Andrea</forenames></author></authors><title>MetalGAN: a Cluster-based Adaptive Training for Few-Shot Adversarial
  Colorization</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the majority of works on deep-learning-based image
colorization have focused on how to make a good use of the enormous datasets
currently available. What about when the data at disposal are scarce? The main
objective of this work is to prove that a network can be trained and can
provide excellent colorization results even without a large quantity of data.
The adopted approach is a mixed one, which uses an adversarial method for the
actual colorization, and a meta-learning technique to enhance the generator
model. Also, a clusterization a-priori of the training dataset ensures a
task-oriented division useful for meta-learning, and at the same time reduces
the per-step number of images. This paper describes in detail the method and
its main motivations, and a discussion of results and future developments is
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07655</identifier>
 <datestamp>2019-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07655</id><created>2019-09-17</created><updated>2019-10-29</updated><authors><author><keyname>Tian</keyname><forenames>Xiaohai</forenames></author><author><keyname>Das</keyname><forenames>Rohan Kumar</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author></authors><title>Black-box Attacks on Automatic Speaker Verification using
  Feedback-controlled Voice Conversion</title><categories>eess.AS</categories><comments>6 pages, 3 figures, This paper is submitted to ICASSP 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic speaker verification (ASV) systems in practice are greatly
vulnerable to spoofing attacks. The latest voice conversion technologies are
able to produce perceptually natural sounding speech that mimics any target
speakers. However, the perceptual closeness to a speaker's identity may not be
enough to deceive an ASV system. In this work, we propose a framework that uses
the output scores of an ASV system as the feedback to a voice conversion
system. The attacker framework is a black-box adversary that steals one's voice
identity, because it does not require any knowledge about the ASV system but
the system outputs. Experimental results conducted on ASVspoof 2019 database
confirm that the proposed feedback-controlled voice conversion framework
produces adversarial samples that are more deceptive than the straightforward
voice conversion, thereby boosting the impostor ASV scores. Further, the
perceptual evaluation studies reveal that converted speech does not adversely
affect the voice quality from the baseline system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07658</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07658</id><created>2019-09-17</created><authors><author><keyname>Molina</keyname><forenames>Celia Gomez</forenames></author><author><keyname>Pereira</keyname><forenames>Fernando Quesada</forenames></author><author><keyname>Melcon</keyname><forenames>Alejandro Alvarez</forenames></author><author><keyname>Marini</keyname><forenames>Stephan</forenames></author><author><keyname>Sanchez-Soriano</keyname><forenames>Miguel A.</forenames></author><author><keyname>Boria</keyname><forenames>Vicente E.</forenames></author><author><keyname>Guglielmi</keyname><forenames>Marco</forenames></author></authors><title>Novel Rigorous Multimode Equivalent Network Formulation for Boxed Planar
  Circuits with Arbitrarily Shaped Metallizations</title><categories>eess.SP</categories><comments>7 pages, 10 figures, transaction</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Multimode Equivalent Network (MEN) formulation has been traditionally
employed for the efficient and accurate analysis of waveguide devices. In this
paper, we extend the use of the MEN to the analysis of zero thickness,
multilayer planar circuits in a metallic enclosure. The formulation is
developed for arbitrary shape metallic areas and includes both internal and
external ports in the transverse plane. The BI-RME method is applied to analyze
the arbitrary shaped metallizations and to compute the coupling integrals
needed to solve the corresponding integral equations. On this basis, typical
shielded microstrip circuits of complex geometries, are analyzed in the common
frame of the MEN technique. To validate the theoretical formulation, several
shielded filtering microstrip structures are analyzed, showing good agreement
with respect to both other commercial tools and experimental measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07669</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07669</id><created>2019-09-17</created><authors><author><keyname>Rapetti</keyname><forenames>Lorenzo</forenames></author><author><keyname>Tirupachuri</keyname><forenames>Yeshasvi</forenames></author><author><keyname>Darvish</keyname><forenames>Kourosh</forenames></author><author><keyname>Latella</keyname><forenames>Claudia</forenames></author><author><keyname>Pucci</keyname><forenames>Daniele</forenames></author></authors><title>Model-Based Real-Time Motion Tracking using Dynamical Inverse Kinematics</title><categories>eess.SY cs.RO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper contributes towards the development of motion tracking algorithms
for time-critical applications, proposing an infrastructure for solving
dynamically the inverse kinematics of human models. We present a method based
on the integration of the differential kinematics, and for which the
convergence is proved using Lyapunov analysis. The method is tested in an
experimental scenario where the motion of a subject is tracked in static and
dynamic configurations, and the inverse kinematics is solved both for human and
humanoid models. The architecture is evaluated both terms of accuracy and
computational load, and compared to iterative optimization algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07678</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07678</id><created>2019-09-17</created><authors><author><keyname>Qian</keyname><forenames>Lilin</forenames></author><author><keyname>Xu</keyname><forenames>Xin</forenames></author><author><keyname>Zeng</keyname><forenames>Yujun</forenames></author><author><keyname>Li</keyname><forenames>Xiaohui</forenames></author><author><keyname>Sun</keyname><forenames>Zhenping</forenames></author><author><keyname>Song</keyname><forenames>Hang</forenames></author></authors><title>Synchronous Maneuver Searching and Trajectory Planning for Autonomous
  Vehicles in Dynamic Traffic Environments</title><categories>cs.RO eess.SP</categories><comments>This work has been accepted by IEEE Intelligent Transportation System
  Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the real-time decision-making and local planning process of autonomous
vehicles in dynamic environments, the autonomous driving system may fail to
find a reasonable policy or even gets trapped in some situation due to the
complexity of global tasks and the incompatibility between upper-level maneuver
decisions with the low-level lower level trajectory planning. To solve this
problem, this paper presents a synchronous maneuver searching and trajectory
planning (SMSTP) algorithm based on the topological concept of homotopy.
Firstly, a set of alternative maneuvers with boundary limits are enumerated on
a multi-lane road. Instead of sampling numerous paths in the whole
spatio-temporal space, we, for the first time, propose using Trajectory
Profiles (TPs) to quickly construct the topological maneuvers represented by
different routes, and put forward a corridor generation algorithm based on
graph-search. The bounded corridor further constrains the maneuver's space in
the spatial space. A step-wise heuristic optimization algorithm is then
proposed to synchronously generate a feasible trajectory for each maneuver. To
achieve real-time performance, we initialize the states to be optimized with
the boundary constraints of maneuvers, and we set some heuristic states as
terminal targets in the quadratic cost function. The solution of a feasible
trajectory is always guaranteed only if a specific maneuver is given. The
simulation and realistic driving-test experiments verified that the proposed
SMSTP algorithm has a short computation time which is less than 37ms, and the
experimental results showed the validity and effectiveness of the SMSTP
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07716</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07716</id><created>2019-09-17</created><updated>2019-10-14</updated><authors><author><keyname>Jung</keyname><forenames>Woojin</forenames></author><author><keyname>Yoon</keyname><forenames>Jaeyeon</forenames></author><author><keyname>Choi</keyname><forenames>Joon Yul</forenames></author><author><keyname>Kim</keyname><forenames>Jae Myung</forenames></author><author><keyname>Nam</keyname><forenames>Yoonho</forenames></author><author><keyname>Kim</keyname><forenames>Eung Yeop</forenames></author><author><keyname>Lee</keyname><forenames>Jongho</forenames></author></authors><title>Exploring linearity of deep neural network trained QSM: QSMnet+</title><categories>eess.IV</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, deep neural network-powered quantitative susceptibility mapping
(QSM), QSMnet, successfully performed ill conditioned dipole inversion in QSM
and generated high-quality susceptibility maps. In this paper, the network,
which was trained by healthy volunteer data, is evaluated for hemorrhagic
lesions that have substantially higher susceptibility than healthy tissues in
order to test linearity of QSMnet for susceptibility. The results show that
QSMnet underestimates susceptibility in hemorrhagic lesions, revealing degraded
linearity of the network for the untrained susceptibility range. To overcome
this limitation, a data augmentation method is proposed to generalize the
network for a wider range of susceptibility. The newly trained network, which
is referred to as QSMnet+, is assessed in computer-simulated lesions with an
extended susceptibility range (-1.4 ppm to +1.4 ppm) and also in twelve
hemorrhagic patients. The simulation results demonstrate improved linearity of
QSMnet+ over QSMnet (root mean square error of QSMnet+: 0.04 ppm vs. QSMnet:
0.36 ppm). When applied to patient data, QSMnet+ maps show less noticeable
artifacts to those of conventional QSM maps. Moreover, the susceptibility
values of QSMnet+ in hemorrhagic lesions are better matched to those of the
conventional QSM method than those of QSMnet when analyzed using linear
regression (QSMnet+: slope = 1.05, intercept = -0.03, R2 = 0.93; QSMnet: slope
= 0.68, intercept = 0.06, R2 = 0.86), consolidating improved linearity in
QSMnet+. This study demonstrates the importance of the trained data range in
deep neural network-powered parametric mapping and suggests the data
augmentation approach for generalization of network. The new network can be
applicable for a wide range of susceptibility quantification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07721</identifier>
 <datestamp>2020-02-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07721</id><created>2019-09-17</created><updated>2020-02-07</updated><authors><author><keyname>Yang</keyname><forenames>Kailun</forenames></author><author><keyname>Hu</keyname><forenames>Xinxin</forenames></author><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Xiang</keyname><forenames>Kaite</forenames></author><author><keyname>Wang</keyname><forenames>Kaiwei</forenames></author><author><keyname>Stiefelhagen</keyname><forenames>Rainer</forenames></author></authors><title>DS-PASS: Detail-Sensitive Panoramic Annular Semantic Segmentation
  through SwaftNet for Surrounding Sensing</title><categories>cs.CV cs.RO eess.IV eess.SP</categories><comments>8 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantically interpreting the traffic scene is crucial for autonomous
transportation and robotics systems. However, state-of-the-art semantic
segmentation pipelines are dominantly designed to work with pinhole cameras and
train with narrow Field-of-View (FoV) images. In this sense, the perception
capacity is severely limited to offer higher-level confidence for upstream
navigation tasks. In this paper, we propose a network adaptation framework to
achieve Panoramic Annular Semantic Segmentation (PASS), which allows to re-use
conventional pinhole-view image datasets, enabling modern segmentation networks
to comfortably adapt to panoramic images. Specifically, we adapt our proposed
SwaftNet to enhance the sensitivity to details by implementing attention-based
lateral connections between the detail-critical encoder layers and the
context-critical decoder layers. We benchmark the performance of efficient
segmenters on panoramic segmentation with our extended PASS dataset,
demonstrating that the proposed real-time SwaftNet outperforms state-of-the-art
efficient networks. Furthermore, we assess real-world performance when
deploying the Detail-Sensitive PASS (DS-PASS) system on a mobile robot and an
instrumented vehicle, as well as the benefit of panoramic semantics for visual
odometry, showing the robustness and potential to support diverse navigational
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07749</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07749</id><created>2019-09-17</created><authors><author><keyname>Kassan</keyname><forenames>Sara</forenames><affiliation>MIPS</affiliation></author><author><keyname>Gaber</keyname><forenames>Jaafar</forenames><affiliation>SET</affiliation></author><author><keyname>Lorenz</keyname><forenames>Pascal</forenames><affiliation>MIPS</affiliation></author></authors><title>Autonomous Energy Management system achieving piezoelectric energy
  harvesting in Wireless Sensors</title><categories>cs.NI eess.SP</categories><proxy>ccsd</proxy><journal-ref>Journal on Mobile Networks and Applications (MONET), 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks (WSNs) are extensively used in monitoring
applications such as humidity and temperature sensing in smart buildings,
industrial automation, and predicting crop health. Sensor nodes are deployed in
remote places to sense the data information from the environment and to
transmit the sensing data to the Base Station (BS). When a sensor is drained of
energy, it can no longer achieve its role without a substituted source of
energy. However, limited energy in a sensor's battery prevents the long-term
process in such applications. In addition, replacing the sensors' batteries and
redeploying the sensors is very expensive in terms of time and budget. To
overcome the energy limitation without changing the size of sensors,
researchers have proposed the use of energy harvesting to reload the
rechargeable battery by power. Therefore, efficient power management is
required to increase the benefits of having additional environmental energy.
This paper presents a new self-management of energy based on Proportional
Integral Derivative controller (PID) to tune the energy harvesting and
Microprocessor Controller Unit (MCU) to control the sensor modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07763</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07763</id><created>2019-09-17</created><authors><author><keyname>Labbe-Morissette</keyname><forenames>Guillaume</forenames></author><author><keyname>Gauthier</keyname><forenames>Sylvain</forenames></author></authors><title>A machine vision meta-algorithm for automated recognition of underwater
  objects using sidescan sonar imagery</title><categories>cs.CV cs.LG eess.IV</categories><comments>13 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper details a new method to recognize and detect underwater objects in
real-time sidescan sonar data imagery streams, with case-studies of
applications for underwater archeology, and ghost fishing gear retrieval. We
first synthesize images from sidescan data, apply geometric and radiometric
corrections, then use 2D feature detection algorithms to identify point clouds
of descriptive visual microfeatures such as corners and edges in the sonar
images. We then apply a clustering algorithm on the feature point clouds to
group feature sets into regions of interest, reject false positives, yielding a
georeferenced inventory of objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07765</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07765</id><created>2019-09-12</created><authors><author><keyname>Fu</keyname><forenames>Xingbo</forenames></author><author><keyname>Gao</keyname><forenames>Feng</forenames></author><author><keyname>Wu</keyname><forenames>Jiang</forenames></author><author><keyname>Huang</keyname><forenames>Ruanming</forenames></author><author><keyname>Huang</keyname><forenames>Yichao</forenames></author><author><keyname>Fei</keyname><forenames>Fei</forenames></author></authors><title>A Simulation Approach to Multi-station Solar Irradiance Data Considering
  Temporal Correlations</title><categories>eess.SP cs.SY eess.SY</categories><comments>The 9th International Conference on Innovative Smart Grid
  Technologies (IEEE PES ISGT Asia 2019), Chengdu, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solar energy is one of important renewable energy sources and simulation of
solar irradiance can be used as input for simulation of photovoltaic (PV)
generation. This paper proposes a simulation algorithm of multi-station solar
irradiance data considering temporal correlations. First of all, we group all
the days of the observed data to k clusters for each station based on their
daily features of solar irradiance and the daily states constitute Markov chain
of days. Then, we reduce state permutations of different stations before
getting Markov Transition Probability Matrix (MTPM). In terms of the observed
data and MTPM, the simulation approach is proposed. Finally, we test our
approach by applying to solar irradiance data of three stations and show that
the properties of simulated data match those of the observed data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07766</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07766</id><created>2019-09-17</created><authors><author><keyname>Nguyen</keyname><forenames>Hieu</forenames></author><author><keyname>Li</keyname><forenames>Hui</forenames></author><author><keyname>Qiu</keyname><forenames>Qiang</forenames></author><author><keyname>Wang</keyname><forenames>Yuzeng</forenames></author><author><keyname>Wang</keyname><forenames>Zhaoyang</forenames></author></authors><title>Single-shot 3D shape reconstruction using deep convolutional neural
  networks</title><categories>eess.IV cs.CV cs.LG</categories><comments>6 pages, 4 figures, 1 dataset</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A robust single-shot 3D shape reconstruction technique integrating the fringe
projection profilometry (FPP) technique with the deep convolutional neural
networks (CNNs) is proposed in this letter. The input of the proposed technique
is a single FPP image, and the training and validation data sets are prepared
by using the conventional multi-frequency FPP technique. Unlike the
conventional 3D shape reconstruction methods which involve complex algorithms
and intensive computation, the proposed approach uses an end-to-end network
architecture to directly carry out the transformation of a 2D images to its
corresponding 3D shape. Experiments have been conducted to demonstrate the
validity and robustness of the proposed technique. It is capable of satisfying
various 3D shape reconstruction demands in scientific research and engineering
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07778</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07778</id><created>2019-09-17</created><authors><author><keyname>Appeltans</keyname><forenames>Pieter</forenames></author><author><keyname>Michiels</keyname><forenames>Wim</forenames></author></authors><title>A pseudo-spectra based characterisation of the robust strong H-infinity
  norm of time-delay systems with real-valued and structured uncertainties</title><categories>math.NA cs.NA cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the robust (strong) H-infinity norm of a linear
time-invariant system with discrete delays. The considered system is subject to
real-valued, structured, Frobenius norm bounded uncertainties on the
coefficient matrices. The robust H-infinity norm is the worst case value of the
H-infinity norm over the realisations of the system and hence an important
measure of robust performance in control engineering. However this robust
H-infinity norm is a fragile measure, as for a particular realization of the
uncertainties the H-infinity norm might be sensitive to arbitrarily small
perturbations on the delays. Therefore, we introduce the robust strong
H-infinity norm, inspired by the notion of strong stability of delay
differential equations of neutral type, which takes into account both the
perturbations on the system matrices and infinitesimal small delay
perturbations. This quantity is a continuous function of the nominal system
parameters and delays. The main contribution of this work is the introduction
of a relation between this robust strong H-infinity norm and the the
pseudo-spectrum of an associated singular delay eigenvalue problem. This
relation is subsequently employed in a novel algorithm for computing the robust
strong H-infinity norm of uncertain time-delay systems. Both the theoretical
results and the algorithm are also generalized to systems with uncertainties on
the delays, and systems described by a class of delay differential algebraic
equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07788</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07788</id><created>2019-09-12</created><authors><author><keyname>Zang</keyname><forenames>Yubin</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author><author><keyname>Yang</keyname><forenames>Sigang</forenames></author><author><keyname>Chen</keyname><forenames>Hongwei</forenames></author></authors><title>Electro-optical Neural Networks based on Time-stretch Method</title><categories>eess.SP cs.AI physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel architecture of electro-optical neural networks based
on the time-stretch method is proposed and numerically simulated. By stretching
time-domain ultrashort pulses, multiplications of large scale weight matrices
and vectors can be implemented on light and multiple-layer of feedforward
neural network operations can be easily implemented with fiber loops. Via
simulation, the performance of a three-layer electro-optical neural network is
tested by the handwriting digit recognition task and the accuracy reaches 88%
under considerable noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07789</identifier>
 <datestamp>2019-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07789</id><created>2019-09-12</created><updated>2019-12-22</updated><authors><author><keyname>Namazian</keyname><forenames>Zahra</forenames></author><author><keyname>Roghanian</keyname><forenames>Emad</forenames></author></authors><title>The uncertain surgery time in integrated sequencing, planning and
  scheduling problem of the surgical ward</title><categories>eess.SP math.OC</categories><comments>It is completely wrong. So, mathematical model, results and
  conclusions are not valid. Please withdraw it as soon as possible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The surgical department and adequate access to health care are critical
problems. The operating room plays a fundamental role in the performance of a
hospital. The real problem faces several issues to collect data and optimize
scheduling and planning. In this paper, the planning and integral scheduling
problems were taken into consideration including surgeon work times, patients'
surgery priority, and preparation time of the operation room after each
surgery. Based on this, two mathematical models have been developed. The first
model is a mixed-integer programming model that minimizes the total patient
waiting time. This model was designed for three sections: Public Health Unit
(PHU), Operating Rooms, and Post Anesthesia Care Unit (PACU). This model
includes scheduling, allocating surgery personnel, and sequencing the groups of
patients in each section. The decision-makers, for patients, demonstrate the
experts would determine some priorities. The service times for the patients at
every stage are affected by the proficiency of surgery personnel. In the second
model, a robust optimization approach has been used due to overcoming the
uncertain surgery times. The proposed robust model indicated that the
fluctuations of solutions in the future are less than the deterministic model
at an acceptable level. The computational results reveal some good managerial
insights for hospital administrators. The managers could use this model to
improve system management, quality of services to patients, and patient
satisfaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07791</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07791</id><created>2019-09-17</created><authors><author><keyname>Xue</keyname><forenames>S.</forenames></author><author><keyname>Li</keyname><forenames>A.</forenames></author><author><keyname>Wang</keyname><forenames>J.</forenames></author><author><keyname>Yi</keyname><forenames>N.</forenames></author><author><keyname>Ma</keyname><forenames>Y.</forenames></author><author><keyname>Tafazolli</keyname><forenames>R.</forenames></author><author><keyname>Dodgson</keyname><forenames>T.</forenames></author></authors><title>To Learn or Not to Learn: Deep Learning Assisted Wireless Modem Design</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning is driving a radical paradigm shift in wireless communications,
all the way from the application layer down to the physical layer. Despite
this, there is an ongoing debate as to what additional values artificial
intelligence (or machine learning) could bring to us, particularly on the
physical layer design; and what penalties there may have? These questions
motivate a fundamental rethinking of the wireless modem design in the
artificial intelligence era. Through several physical-layer case studies, we
argue for a significant role that machine learning could play, for instance in
parallel error-control coding and decoding, channel equalization, interference
cancellation, as well as multiuser and multiantenna detection. In addition, we
will also discuss the fundamental bottlenecks of machine learning as well as
their potential solutions in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07801</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07801</id><created>2019-09-16</created><updated>2019-12-06</updated><authors><author><keyname>Khorram</keyname><forenames>Amin</forenames></author><author><keyname>Khalooei</keyname><forenames>Mohammad</forenames></author><author><keyname>Rezghi</keyname><forenames>Mansoor</forenames></author></authors><title>Intelligent Bearing Fault Diagnosis with Convolutional
  Long-Short-Term-Memory Recurrent Neural Network</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fault diagnostics and prognostics are important topics both in practice and
research. There is an intense pressure on industrial plants to continue
reducing unscheduled downtime, performance degradation, and safety hazards,
which requires detecting and recovering of potential faults in its early
stages. Intelligent fault diagnosis is a promising tool due to its ability in
rapidly and efficiently processing collected signals and providing accurate
diagnosis results. Although many studies have developed machine leaning(M.L)
and deep learning(D.L) algorithms for detecting bearing fault, the results have
generally been limited to relatively small train/test datasets and the input
data has been manipulated (selective features used) in order to reach a high
accuracy. In this work, the raw data collected form accelerometers (time-domain
features) are taken as the input of a novel temporal sequence prediction
algorithm in order to present an end-to-end method for fault detection. We used
equivalent temporal sequences as the input of a novel Convolutional
Long-Short-Term-Memory Recurrent Neural Network (CRNN) in order to detect the
bearing fault with the highest accuracy at the shortest possible time. The
method can reach the highest accuracy to the best knowledge of authors of the
present paper voiding any sort of pre-processing or manipulation of the input
data. Effectiveness and feasibility of the fault diagnosis method is validated
by applying it to two commonly used benchmark real vibration datasets and
comparing the result with the other competing intelligent fault diagnosis
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07813</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07813</id><created>2019-09-16</created><authors><author><keyname>Ahuja</keyname><forenames>Sajeev</forenames></author><author><keyname>Arya</keyname><forenames>Raj Kumar</forenames></author></authors><title>Consistent Initialization of the Laplace Transform</title><categories>eess.SY cs.SY</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consistent initialization of the Laplace transform has been a fundamental and
long-standing issue. The consistency of the L- approach has been questioned,
yet it is a popular approach since the L+ approach requires a priori
computation of the 0+ initial conditions, which becomes a diligent task from
the available methods. Also, the L+ Laplace transform of the impulse becomes
zero, thus involving an inconsistency. In contrast to these direct approaches,
some studies propose convoluted methods to address the issue. Here, a direct,
facile, and first-principles novel approach for the L+ transform is proposed.
It computes the consistent 0+ initial conditions and solution based on
singular-nonsingular decomposition of the system model. The inconsistency
associated with the L+ Laplace transform of discontinuous functions and impulse
is not involved in the nonsingular part. The emergence of discontinuity is
easily elucidated from the singular part, and the solution yields the same 0+
initial values as the initial conditions used. Further, physical
first-principles can be used in the midst of the computation to validate the
results to ensure error-free execution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07815</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07815</id><created>2019-09-15</created><authors><author><keyname>Gao</keyname><forenames>Qi</forenames></author><author><keyname>Li</keyname><forenames>Qijie</forenames></author><author><keyname>Pan</keyname><forenames>Shaowu</forenames></author><author><keyname>Wang</keyname><forenames>Hongping</forenames></author><author><keyname>Wei</keyname><forenames>Runjie</forenames></author><author><keyname>Wang</keyname><forenames>Jinjun</forenames></author></authors><title>Particle reconstruction of volumetric particle image velocimetry with
  strategy of machine learning</title><categories>eess.IV cs.LG physics.flu-dyn</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Three-dimensional particle reconstruction with limited two-dimensional
projects is an underdetermined inverse problem that the exact solution is often
difficulty to be obtained. In general, approximate solutions can be obtained by
optimization methods. In the current work, a practical particle reconstruction
method based on convolutional neural network (CNN) is proposed. The proposed
technique can refine the particle reconstruction from a very coarse initial
guess of particle distribution from any traditional algebraic reconstruction
technique (ART) based methods. Compared with available ART-based algorithms,
the novel technique makes significant improvements in terms of reconstruction
quality and at least an order of magnitude faster with dense particle
concentration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07820</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07820</id><created>2019-09-15</created><authors><author><keyname>Liang</keyname><forenames>Sisheng</forenames></author><author><keyname>Yang</keyname><forenames>Zhou</forenames></author><author><keyname>Jin</keyname><forenames>Fang</forenames></author><author><keyname>Chen</keyname><forenames>Yong</forenames></author></authors><title>Job Scheduling on Data Centers with Deep Reinforcement Learning</title><categories>cs.OS cs.LG cs.SY eess.SY</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient job scheduling on data centers under heterogeneous complexity is
crucial but challenging since it involves the allocation of multi-dimensional
resources over time and space. To adapt the complex computing environment in
data centers, we proposed an innovative Advantage Actor-Critic (A2C) deep
reinforcement learning based approach called DeepScheduler for job scheduling.
DeepScheduler consists of two agents, one of which, dubbed the actor, is
responsible for learning the scheduling policy automatically and the other one,
the critic, reduces the estimation error. Unlike previous policy gradient
approaches, DeepScheduler is designed to reduce the gradient estimation
variance and to update parameters efficiently. We show that the DeepScheduler
can achieve competitive scheduling performance using both simulated workloads
and real data collected from an academic data center.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07834</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07834</id><created>2019-09-17</created><updated>2019-09-18</updated><authors><author><keyname>Eraslan</keyname><forenames>Emre</forenames></author><author><keyname>Yildiz</keyname><forenames>Yildiray</forenames></author><author><keyname>Annaswamy</keyname><forenames>Anuradha M.</forenames></author></authors><title>Shared Control Between Pilots and Autopilots: Illustration of a
  Cyber-Physical Human System</title><categories>eess.SY cs.SY</categories><comments>26 pages, 13 figures, 12 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although increased automation has made it easier to control aircraft,
ensuring a safe interaction between the pilots and the autopilots is still a
challenging problem, especially in the presence of severe anomalies. Current
approach consists of autopilot solutions that disengage themselves when they
become ineffective. This may cause reengagement of the pilot at the worst
possible time, which can result in undesired consequences. In this paper, a
series of research studies that propose pilot-autopilot interaction schemes
based on the Capacity for Maneuver (CfM) concept, are covered. CfM refers to
the remaining capacity of the actuators that can be used for bringing the
aircraft to safety. It is demonstrated that CfM-based pilot-autopilot
interaction schemes, or Shared Control Architectures (SCA), can be promising
alternatives to the existing schemes. Two SCAs are tested in the experiments.
In SCA1, the pilot takes over the control from the autopilot using the
monitored CfM information. In SCA2, the pilot takes on the role of a supervisor
helping the autopilot whenever a need arises, based on the CfM information.
Whenever the aircraft experiences a severe anomaly, the pilot assesses the
situation based on his/her CfM monitoring and intervenes by providing two
control system parameter estimates to the autopilot. This increases the
effectiveness of the autopilot. Using human-in-the-loop simulations, it is
shown that CfM based interactions provides smaller tracking errors and larger
overall CfM. The subjects including a commercial airline pilot and several
university students are trained using a systematic procedure. Creation of new
cyber physical &amp; human systems is inevitable along with deeper engagement with
the social science community so as to get better insight into human decision
making. The results reported here should be viewed as a first of several steps
in this research direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07851</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07851</id><created>2019-09-17</created><authors><author><keyname>Wang</keyname><forenames>Shimin</forenames></author><author><keyname>Huang</keyname><forenames>Jie</forenames></author></authors><title>Adaptive Leader-Following Consensus for Multiple Euler-Lagrange Systems
  with an Uncertain Leader System</title><categories>eess.SY cs.SY math.OC</categories><msc-class>93Cxx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the leader-following consensus problem of multiple
Euler-Lagrange systems subject to an uncertain leader system. We first
establish an adaptive distributed observer for a neutrally stable linear leader
system whose system matrix is not known exactly. Under standard assumptions,
this adaptive distributed observer can estimate and pass the leader's state to
each follower through the communication network of the system without knowing
the leader's system matrix exactly. Under the additional assumption that the
leader's state is persistently exciting, this adaptive distributed observer can
also asymptotically learn the parameters of the leader's system matrix. On the
basis of this adaptive distributed observer, we further synthesize an adaptive
distributed control law to solve our problem via the certainty equivalence
principle. Our result allows the leader-following consensus problem of multiple
Euler-Lagrange systems to be solved even if none of the followers knows the
system matrix of the leader system exactly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07858</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07858</id><created>2019-09-17</created><updated>2019-09-18</updated><authors><author><keyname>Sun</keyname><forenames>Jianyong</forenames></author><author><keyname>Zhang</keyname><forenames>Yiqing</forenames></author><author><keyname>Xue</keyname><forenames>Jiang</forenames></author></authors><title>Learning to Search for MIMO Detection</title><categories>cs.IT eess.SP math.IT</categories><comments>paper not complete</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel learning to learn method, called learning to
learn iterative search algorithm(LISA), for signal detection in a multi-input
multi-output (MIMO) system. The idea is to regard the signal detection problem
as a decision making problem over tree. The goal is to learn the optimal
decision policy. In LISA, deep neural networks are used as parameterized policy
function. Through training, optimal parameters of the neural networks are
learned and thus optimal policy can be approximated. Different neural
network-based architectures are used for fixed and varying channel models. LISA
provides soft decisions and does not require any information about the additive
white Gaussian noise. Simulation results show that LISA achieves
state-of-the-art detection performance. Particularly, LISA obtains near maximum
likelihood detection performance in both fixed and varying channel models under
QPSK modulation, and performs significantly better than classical detectors and
recently proposed deep/machine learning based detectors under various
modulations and signal to noise levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07859</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07859</id><created>2019-09-17</created><updated>2019-09-19</updated><authors><author><keyname>K&#xf6;lsch</keyname><forenames>Lukas</forenames></author><author><keyname>Bhatt</keyname><forenames>Kirtan</forenames></author><author><keyname>Krebs</keyname><forenames>Stefan</forenames></author><author><keyname>Hohmann</keyname><forenames>S&#xf6;ren</forenames></author></authors><title>Steady-State Optimal Frequency Control for Lossy Power Grids with
  Distributed Communication</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a distributed and price-based control approach for frequency
regulation in power grids with nonzero line conductances. Both grid and
controller are modeled as a port-Hamiltonian system, where the grid model
consists of differential as well as algebraic equations. Simulations show that
the resulting controller asymptotically stabilizes the frequency while
maintaining minimum overall generation costs in steady state and being robust
in terms of clock drifts and uncontrollable loads. Moreover, it is shown that
active power sharing can be achieved by an appropriate choice of the cost
function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07916</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07916</id><created>2019-09-17</created><updated>2019-10-01</updated><authors><author><keyname>Arabi</keyname><forenames>Ehsan</forenames></author><author><keyname>Garg</keyname><forenames>Kunal</forenames></author><author><keyname>Panagou</keyname><forenames>Dimitra</forenames></author></authors><title>Safety-Critical Adaptive Control with Nonlinear Reference Model Systems</title><categories>eess.SY cs.SY</categories><comments>Submitted to American Control Conference (ACC) 2020, under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a model reference adaptive control architecture is proposed
for uncertain nonlinear systems to achieve prescribed performance guarantees.
Specifically, a general nonlinear reference model system is considered that
captures an ideal and safe system behavior. An adaptive control architecture is
then proposed to suppress the effects of system uncertainties without any prior
knowledge of their magnitude and rate upper bounds. More importantly, the
proposed control architecture enforces the system state trajectories to evolve
within a user-specified prescribed distance from the reference system
trajectories, satisfying the safety constraints. This eliminates the ad-hoc
tuning process for the adaptation rate that is conventionally required in model
reference adaptive control to ensure safety. The efficacy of the proposed
control architecture is also demonstrated through an illustrative numerical
example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07917</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07917</id><created>2019-09-13</created><authors><author><keyname>Hu</keyname><forenames>Yinghua</forenames></author><author><keyname>Menon</keyname><forenames>Vivek V.</forenames></author><author><keyname>Schmidt</keyname><forenames>Andrew</forenames></author><author><keyname>Monson</keyname><forenames>Joshua</forenames></author><author><keyname>French</keyname><forenames>Matthew</forenames></author><author><keyname>Nuzzo</keyname><forenames>Pierluigi</forenames></author></authors><title>Toward Efficient Evaluation of Logic Encryption Schemes: Models and
  Metrics</title><categories>cs.CR cs.SY eess.SY</categories><comments>This report is an extended version of &quot;Y. Hu, V. Venugopalan, A.
  Schmidt, J. Monson, M. French, and P. Nuzzo. Security-driven metrics and
  models for efficient evaluation of logic encryption schemes. In 2019 17th
  ACM/IEEE International Conference on Formal Methods and Models for System
  Design (MEMOCODE). ACM, 2019.&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research in logic encryption over the last decade has resulted in various
techniques to prevent different security threats such as Trojan insertion,
intellectual property leakage, and reverse engineering. However, there is
little agreement on a uniform set of metrics and models to efficiently assess
the achieved security level and the trade-offs between security and overhead.
This paper addresses the above challenges by relying on a general logic
encryption architecture that can encompass all the existing techniques, and a
uniform set of metrics that can capture multiple, possibly conflicting,
security concerns. We apply our modeling framework to four state-of-the-art
encryption techniques, showing that it enables fast and accurate evaluation of
design trade-offs and provides support for the implementation of compound
encryption methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07921</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07921</id><created>2019-09-17</created><updated>2020-01-06</updated><authors><author><keyname>Stacey</keyname><forenames>Nathan</forenames></author><author><keyname>D'Amico</keyname><forenames>Simone</forenames></author></authors><title>Adaptive and Dynamically Constrained Process Noise Estimation for Orbit
  Determination</title><categories>eess.SP math.DS</categories><comments>The previous version is to be published in the proceedings of the
  2019 AAS/AIAA Astrodynamics Specialist Conference which took place in
  Portland, ME on August 11-15, 2019. The current version was submitted for
  publication in the Journal of Guidance, Control, and Dynamics. The journal
  version includes additional simulations in Case Study II</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces two new algorithms to accurately estimate Kalman filter
process noise online for robust orbit determination in the presence of dynamics
model uncertainties. Common orbit determination process noise techniques, such
as state noise compensation and dynamic model compensation, require offline
tuning and a priori knowledge of the dynamical environment. Alternatively, the
discrete time process noise covariance can be estimated through adaptive
filtering. However, current adaptive filtering techniques often use ad hoc
methods to ensure the estimated process noise covariance is positive
semi-definite, and they cannot accurately extrapolate over measurement outages.
Furthermore, adaptive filtering techniques do not constrain the process noise
covariance according to the underlying continuous time dynamical model, and
there has been limited work on adaptive filtering with colored process noise.
To overcome these limitations, a novel approach is developed which optimally
fuses state noise compensation and dynamic model compensation with covariance
matching adaptive filtering. This yields two adaptive and dynamically
constrained process noise techniques that can accurately extrapolate the
discrete time process noise covariance over gaps in measurements. The benefits
of the proposed algorithms are demonstrated through two case studies: an
illustrative one-dimensional example and the autonomous navigation of two
spacecraft orbiting an asteroid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07923</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07923</id><created>2019-09-17</created><authors><author><keyname>Li</keyname><forenames>Haotian</forenames></author><author><keyname>Qin</keyname><forenames>He</forenames></author><author><keyname>Georgiev</keyname><forenames>Todor</forenames></author></authors><title>Lightfield Coordinates Adapted to Asgeirsson's Theorem</title><categories>eess.IV</categories><comments>11 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  John's differential equation and its canonical form, the ultrahyperbolic
equation, plays important role in lightfield imaging. The equation describes a
local constraint on the lightfield, that was first observed as a
&quot;dimensionality gap&quot; in the frequency representation. Related to the
ultrahyperbolic equation, Asgeirsson's theorems describe global properties.
These indicate new, global, constraints on the lightfield. In order to help
validate those theorems on real captured images, we introduce a coordinate
system for the lightfield, which suits better the Asgeirsson theorems, and
analyze behaviour in terms of the new coordinates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07925</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07925</id><created>2019-09-17</created><authors><author><keyname>Ramos-Llord&#xe9;n</keyname><forenames>Gabriel</forenames></author><author><keyname>Ning</keyname><forenames>Lipeng</forenames></author><author><keyname>Liao</keyname><forenames>Congyu</forenames></author><author><keyname>Mukhometzianov</keyname><forenames>Rinat</forenames></author><author><keyname>Michailovich</keyname><forenames>Oleg</forenames></author><author><keyname>Setsompop</keyname><forenames>Kawin</forenames></author><author><keyname>Rathi</keyname><forenames>Yogesh</forenames></author></authors><title>High-fidelity, accelerated whole-brain submillimeter in-vivo diffusion
  MRI using gSlider-Spherical Ridgelets (gSlider-SR)</title><categories>eess.IV physics.ins-det physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To develop an accelerated, robust, and accurate diffusion MRI
acquisition and reconstruction technique for submillimeter whole human brain
in-vivo scan on a clinical scanner.
  Methods: We extend the ultra-high resolution diffusion MRI acquisition
technique, gSlider, by allowing under-sampling in q-space and Radio-Frequency
(RF)-encoded data, thereby accelerating the total acquisition time of
conventional gSlider. The novel method, termed gSlider-SR, compensates for the
lack of acquired information by exploiting redundancy in the dMRI data using a
basis of Spherical Ridgelets (SR), while simultaneously enhancing the
signal-to-noise ratio. Using Monte-Carlo simulation with realistic noise levels
and several acquisitions of in-vivo human brain dMRI data (acquired on a
Siemens Prisma 3T scanner), we demonstrate the efficacy of our method using
several quantitative metrics.
  Results: For high-resolution dMRI data with realistic noise levels
(synthetically added), we show that gSlider-SR can reconstruct high-quality
dMRI data at different acceleration factors preserving both signal and angular
information. With in-vivo data, we demonstrate that gSlider-SR can accurately
reconstruct 860 ${\mu}m$ diffusion MRI data (64 diffusion directions at b =
2000 $s/ {mm}^2$), at comparable quality as that obtained with conventional
gSlider with four averages, thereby providing an eight-fold reduction in scan
time (from 1 h 20 min to 10 min).
  Conclusion: gSlider-SR enables whole-brain high angular resolution dMRI at a
submillimeter spatial resolution with a dramatically reduced acquisition time,
making it feasible to use the proposed scheme on existing clinical scanners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07963</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07963</id><created>2019-09-17</created><authors><author><keyname>Zhang</keyname><forenames>Xinliang</forenames></author><author><keyname>Vaezi</keyname><forenames>Mojtaba</forenames></author></authors><title>Deep Learning based Precoding for the MIMO Gaussian Wiretap Channel</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>To appear in IEEE Globecom 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel precoding method based on supervised deep neural networks is
introduced for the multiple-input multiple-output Gaussian wiretap channel. The
proposed deep learning (DL)-based precoding learns the input covariance matrix
through offline training over a large set of input channels and their
corresponding covariance matrices for efficient, reliable, and secure
transmission of information. Furthermore, by spending time in offline training,
this method remarkably reduces the computation complexity in real-time
applications. Compared to traditional precoding methods, the proposed DL-based
precoding is significantly faster and reaches near-capacity secrecy rates.
DL-based precoding is also more robust than transitional precoding approaches
to the number of antennas at the eavesdropper. This new approach to precoding
is promising in applications in which delay and complexity are critical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07971</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07971</id><created>2019-09-16</created><authors><author><keyname>Brajovic</keyname><forenames>Milos</forenames></author></authors><title>On reconstruction algorithms for signals sparse in Hermite and Fourier
  domains</title><categories>eess.SP cs.IT math.IT</categories><comments>Ph.D. thesis, 241 pages, in Montenegrin/Serbian</comments><journal-ref>University of Montenegro, Faculty of Electrical Engineering, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis consists of original contributions in the area of digital signal
processing. The reconstruction of signals sparse (highly concentrated) in
various transform domains is the primary problem analyzed in the thesis. The
considered domains include Fourier, discrete Hermite, one-dimensional and
two-dimensional discrete cosine transform, as well as various time-frequency
representations. Sparse signals are reconstructed using sparsity measures,
being, in fact, the measures of signal concentration in the considered domains.
The thesis analyzes the compressive sensing reconstruction algorithms and
introduces new approaches to the problem at hand. The missing samples influence
on analyzed transform domains is studied in detail, establishing the relations
with the general compressive sensing theory. This study provides new insights
on phenomena arising due to the reduced number of signal samples. The
theoretical contributions involve new exact mathematical expressions which
describe performance and outcomes of reconstruction algorithms, also including
the study of the influence of additive noise, sparsity level and the number of
available measurements on the reconstruction performance, exact expressions for
reconstruction errors and error probabilities. Parameter optimization of the
discrete Hermite transform is also studied, as well as the additive noise
influence on Hermite coefficients, resulting in new parameter optimization and
denoising algorithms. Additionally, an algorithm for the decomposition of
multivariate multicomponent signals is introduced, as well as an instantaneous
frequency estimation algorithm based on the Wigner distribution. Extensive
numerical examples and experiments with real and synthetic data validate the
presented theory and shed a new light on practical applications of the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.07974</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.07974</id><created>2019-09-17</created><authors><author><keyname>Leeb</keyname><forenames>William</forenames></author></authors><title>Properties of Laplacian Pyramids for Extension and Denoising</title><categories>stat.ML cs.LG eess.IV math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the Laplacian pyramids algorithm of Rabin and Coifman for
extending and denoising a function sampled on a discrete set of points. We
provide mild conditions under which the algorithm converges, and prove
stability bounds on the extended function. We also consider the iterative
application of truncated Laplacian pyramids kernels for denoising signals by
non-local means.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08003</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08003</id><created>2019-09-17</created><authors><author><keyname>Vaghefi</keyname><forenames>Reza Monir</forenames></author><author><keyname>Palat</keyname><forenames>Ramesh Chembil</forenames></author><author><keyname>Marzin</keyname><forenames>Giovanni</forenames></author><author><keyname>Basavaraju</keyname><forenames>Kiran</forenames></author><author><keyname>Feng</keyname><forenames>Yiping</forenames></author><author><keyname>Banu</keyname><forenames>Mihai</forenames></author></authors><title>Achieving Phase Coherency and Gain Stability in Active Antenna Arrays
  for Sub-6 GHz FDD and TDD FD-MIMO: Challenges and Solutions</title><categories>cs.IT eess.SP math.IT</categories><comments>This paper was submitted for publication in IEEE Journal on Selected
  Areas in Communications on August 29, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive MIMO has been the subject of intense interest in both academia and
industry for the past few years. 3GPP standardization for cellular systems have
adopted the principles of massive MIMO and categorized the use of large
rectangular planar arrays at the base station as full-dimension MIMO (FD-MIMO)
to operate in both TDD and FDD. Operating a large antenna array base station
requires the system to overcome several implementation challenges caused by
hardware impairments making practical solutions non-ideal and expensive to
deploy at scale. It is important to learn from existing challenges and
solutions in order to prepare for larger scale deployment for example with cell
free massive MIMO. Hence in this paper, we specifically study the phase and
amplitude instability due to RF impairments using measurements carried out in
the lab and in the field in a commercial LTE network. We investigate the effect
of phase and magnitude errors on the performance of FD-MIMO systems. We discuss
and characterize various sources creating these errors including time varying
phase drift from low cost local oscillator (LO) and internal temperature
variations affecting frequency response of RF chains. The minimum requirements
and tradeoffs of different LO architectures and calibration mechanisms for
practical cellular deployment are discussed. We then provide details of a novel
coherent LO distribution mechanism and related novel array calibration
mechanism that can be applied to both TDD and FDD systems. Measurement results
are provided to validate the performance of these methods used in a 2D
full-connected hybrid beamforming array architecture called High Definition
Active Antenna System (HDAAS). These results showcase the efficacy of the
proposed methods which can easily be extended to other array architectures
including sub-array hybrid beamforming and element-level digitization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08011</identifier>
 <datestamp>2020-02-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08011</id><created>2019-09-17</created><updated>2020-02-21</updated><authors><author><keyname>Maraqa</keyname><forenames>Omar</forenames><affiliation>Member, IEEE</affiliation></author><author><keyname>Rajasekaran</keyname><forenames>Aditya S.</forenames><affiliation>Member, IEEE</affiliation></author><author><keyname>Al-Ahmadi</keyname><forenames>Saad</forenames><affiliation>Fellow, IEEE</affiliation></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames><affiliation>Fellow, IEEE</affiliation></author><author><keyname>Sait</keyname><forenames>Sadiq M.</forenames><affiliation>Senior Member, IEEE</affiliation></author></authors><title>A Survey of Rate-optimal Power Domain NOMA with Enabling Technologies of
  Future Wireless Networks</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>This work has been submitted to the IEEE for possible publication.
  (After 1st revision)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ambitious high data rate applications in the envisioned future B5G
wireless networks require new solutions, including the advent of more advanced
architectures than the ones already used in 5G networks, and the coalition of
different communications schemes and technologies to enable these applications
requirements. Among the candidate communications schemes for future wireless
networks are NOMA schemes that allow serving more than one user in the same
resource block by multiplexing users in other domains than frequency or time.
In this way, NOMA schemes tend to offer several advantages over OMA schemes
such as improved user fairness and spectral efficiency, higher cell-edge
throughput, massive connectivity support, and low transmission latency. With
these merits, NOMA schemes are being increasingly looked at as promising
multiple access schemes for future wireless networks. When the power domain is
used to multiplex the users, it is referred to as the PD-NOMA. In this paper,
we survey the integration of PD-NOMA with the other enabling communication
schemes and technologies that are expected to satisfy the requirements of B5G
networks. In particular, this paper surveys the different rate optimization
scenarios studied in the literature when PD-NOMA is combined with one or more
of the candidate schemes and technologies for B5G networks including advanced
antenna architectures, mmWave and THz communications, CoMP, FD communications,
cognitive radio, VLC, UAV communications and others. The considered system
models, the optimization methods used to maximize the achievable rates, and the
main lessons learnt on the optimization and the performance of these
NOMA-enabled schemes and technologies are discussed in details along with the
future research directions for these combined schemes. Moreover, the role of
machine learning in optimizing these NOMA-enabled technologies is addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08021</identifier>
 <datestamp>2020-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08021</id><created>2019-09-17</created><updated>2020-01-14</updated><authors><author><keyname>Amelkin</keyname><forenames>Victor</forenames></author><author><keyname>Vohra</keyname><forenames>Rakesh</forenames></author></authors><title>Strategic Formation and Reliability of Supply Chain Networks</title><categories>cs.GT cs.SY econ.TH eess.SY math.OC q-fin.TR</categories><comments>revision 1</comments><msc-class>90B15, 90B05, 90B30, 91B24, 91B38, 60K10, 97M40, 91D30</msc-class><acm-class>G.2.2; C.2.3; G.1.6; I.2.11; G.3; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supply chains are the backbone of the global economy. Disruptions to them can
be costly. Centrally managed supply chains invest in ensuring their resilience.
Decentralized supply chains, however, must rely upon the self-interest of their
individual components to maintain the resilience of the entire chain.
  We examine the incentives that independent self-interested agents have in
forming a resilient supply chain network in the face of production disruptions
and competition. In our model, competing suppliers are subject to yield
uncertainty (they deliver less than ordered) and congestion (lead time
uncertainty or, &quot;soft&quot; supply caps). Competing retailers must decide which
suppliers to link to based on both price and reliability. In the presence of
yield uncertainty only, the resulting supply chain networks are sparse.
Retailers concentrate their links on a single supplier, counter to the idea
that they should mitigate yield uncertainty by diversifying their supply base.
This happens because retailers benefit from supply variance. It suggests that
competition will amplify output uncertainty. When congestion is included as
well, the resulting networks are denser and resemble the bipartite expander
graphs that have been proposed in the supply chain literature, thereby,
providing the first example of endogenous formation of resilient supply chain
networks, without resilience being explicitly encoded in payoffs. Finally, we
show that a supplier's investments in improved yield can make it worse off.
This happens because high production output saturates the market, which, in
turn lowers prices and profits for participants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08028</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08028</id><created>2019-09-17</created><authors><author><keyname>Seo</keyname><forenames>Bosung</forenames></author><author><keyname>Mariano</keyname><forenames>Daniel</forenames></author><author><keyname>Beckfield</keyname><forenames>John</forenames></author><author><keyname>Madenur</keyname><forenames>Vinay</forenames></author><author><keyname>Hu</keyname><forenames>Yuming</forenames></author><author><keyname>Reina</keyname><forenames>Tony</forenames></author><author><keyname>Bobar</keyname><forenames>Marcus</forenames></author><author><keyname>Nguyen</keyname><forenames>Mai H.</forenames></author><author><keyname>Altintas</keyname><forenames>Ilkay</forenames></author></authors><title>Cardiac MRI Image Segmentation for Left Ventricle and Right Ventricle
  using Deep Learning</title><categories>eess.IV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this project is to use magnetic resonance imaging (MRI) data to
provide an end-to-end analytics pipeline for left and right ventricle (LV and
RV) segmentation. Another aim of the project is to find a model that would be
generalizable across medical imaging datasets. We utilized a variety of models,
datasets, and tests to determine which one is well suited to this purpose.
Specifically, we implemented three models (2-D U-Net, 3-D U-Net, and DenseNet),
and evaluated them on four datasets (Automated Cardiac Diagnosis Challenge,
MICCAI 2009 LV, Sunnybrook Cardiac Data, MICCAI 2012 RV). While maintaining a
consistent preprocessing strategy, we tested the performance of each model when
trained on data from the same dataset as the test data, and when trained on
data from a different dataset than the test dataset. Data augmentation was also
used to increase the adaptability of the models. The results were compared to
determine performance and generalizability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08029</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08029</id><created>2019-09-17</created><authors><author><keyname>Luo</keyname><forenames>Qinyi</forenames></author><author><keyname>He</keyname><forenames>Jiaao</forenames></author><author><keyname>Zhuo</keyname><forenames>Youwei</forenames></author><author><keyname>Qian</keyname><forenames>Xuehai</forenames></author></authors><title>Heterogeneity-Aware Asynchronous Decentralized Training</title><categories>cs.DC cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed deep learning training usually adopts All-Reduce as the
synchronization mechanism for data parallel algorithms due to its high
performance in homogeneous environment. However, its performance is bounded by
the slowest worker among all workers, and is significantly slower in
heterogeneous situations. AD-PSGD, a newly proposed synchronization method
which provides numerically fast convergence and heterogeneity tolerance,
suffers from deadlock issues and high synchronization overhead. Is it possible
to get the best of both worlds - designing a distributed training method that
has both high performance as All-Reduce in homogeneous environment and good
heterogeneity tolerance as AD-PSGD? In this paper, we propose Ripples, a
high-performance heterogeneity-aware asynchronous decentralized training
approach. We achieve the above goal with intensive synchronization
optimization, emphasizing the interplay between algorithm and system
implementation. To reduce synchronization cost, we propose a novel
communication primitive Partial All-Reduce that allows a large group of workers
to synchronize quickly. To reduce synchronization conflict, we propose static
group scheduling in homogeneous environment and simple techniques (Group Buffer
and Group Division) to avoid conflicts with slightly reduced randomness. Our
experiments show that in homogeneous environment, Ripples is 1.1 times faster
than the state-of-the-art implementation of All-Reduce, 5.1 times faster than
Parameter Server and 4.3 times faster than AD-PSGD. In a heterogeneous setting,
Ripples shows 2 times speedup over All-Reduce, and still obtains 3 times
speedup over the Parameter Server baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08049</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08049</id><created>2019-09-17</created><authors><author><keyname>Khalilian-Gourtani</keyname><forenames>Amirhossein</forenames></author><author><keyname>Minaee</keyname><forenames>Shervin</forenames></author><author><keyname>Wang</keyname><forenames>Yao</forenames></author></authors><title>Masked-RPCA: Sparse and Low-rank Decomposition Under Overlaying Model
  and Application to Moving Object Detection</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Foreground detection in a given video sequence is a pivotal step in many
computer vision applications such as video surveillance system. Robust
Principal Component Analysis (RPCA) performs low-rank and sparse decomposition
and accomplishes such a task when the background is stationary and the
foreground is dynamic and relatively small. A fundamental issue with RPCA is
the assumption that the low-rank and sparse components are added at each
element, whereas in reality, the moving foreground is overlaid on the
background. We propose the representation via masked decomposition (i.e. an
overlaying model) where each element either belongs to the low-rank or the
sparse component, decided by a mask. We propose the Masked-RPCA algorithm to
recover the mask and the low-rank components simultaneously, utilizing
linearizing and alternating direction techniques. We further extend our
formulation to be robust to dynamic changes in the background and enforce
spatial connectivity in the foreground component. Our study shows significant
improvement of the detected mask compared to post-processing on the sparse
component obtained by other frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08050</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08050</id><created>2019-09-17</created><authors><author><keyname>Reddy</keyname><forenames>Chandan K. A.</forenames></author><author><keyname>Beyrami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Pool</keyname><forenames>Jamie</forenames></author><author><keyname>Cutler</keyname><forenames>Ross</forenames></author><author><keyname>Srinivasan</keyname><forenames>Sriram</forenames></author><author><keyname>Gehrke</keyname><forenames>Johannes</forenames></author></authors><title>A scalable noisy speech dataset and online subjective test framework</title><categories>cs.SD cs.LG eess.AS</categories><comments>InterSpeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background noise is a major source of quality impairments in Voice over
Internet Protocol (VoIP) and Public Switched Telephone Network (PSTN) calls.
Recent work shows the efficacy of deep learning for noise suppression, but the
datasets have been relatively small compared to those used in other domains
(e.g., ImageNet) and the associated evaluations have been more focused. In
order to better facilitate deep learning research in Speech Enhancement, we
present a noisy speech dataset (MS-SNSD) that can scale to arbitrary sizes
depending on the number of speakers, noise types, and Speech to Noise Ratio
(SNR) levels desired. We show that increasing dataset sizes increases noise
suppression performance as expected. In addition, we provide an open-source
evaluation methodology to evaluate the results subjectively at scale using
crowdsourcing, with a reference algorithm to normalize the results. To
demonstrate the dataset and evaluation framework we apply it to several noise
suppressors and compare the subjective Mean Opinion Score (MOS) with objective
quality measures such as SNR, PESQ, POLQA, and VISQOL and show why MOS is still
required. Our subjective MOS evaluation is the first large scale evaluation of
Speech Enhancement algorithms that we are aware of.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08062</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08062</id><created>2019-09-17</created><authors><author><keyname>Zhu</keyname><forenames>Haojie</forenames></author><author><keyname>Song</keyname><forenames>Ziyou</forenames></author><author><keyname>Hou</keyname><forenames>Jun</forenames></author><author><keyname>Hofmann</keyname><forenames>Heath</forenames></author><author><keyname>Sun</keyname><forenames>Jing</forenames></author></authors><title>Simultaneous Identification and Control Using Active Signal Injection
  for Series Hybrid Electric Vehicles based on Dynamic Programming</title><categories>eess.SY cs.SY nlin.AO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid electric vehicles (HEVs) have an over-actuated system by including two
power sources, a battery pack and an internal combustion engine. This feature
of HEV is exploited in this paper to simultaneously achieve accurate
identification of battery parameters/states. By actively injecting current
signals, state of charge, state of health, and other battery parameters can be
estimated in a specific sequence to improve the identification performance when
compared to the case where all parameters and states are estimated concurrently
using the baseline current signals. A dynamic programming strategy is developed
to provide the benchmark results about how to balance the conflicting
objectives corresponding to identification and system efficiency. The tradeoff
between different objectives is presented to optimize the current profile so
that the richness of signal can be ensured and the fuel economy can be
optimized. In addition, simulation results show that the Root-Mean-Square error
of the estimation can be decreased by up to 100% at a cost of less than 2%
increase in fuel consumption. With the proposed simultaneous identification and
control algorithm, the parameters/states of the battery can be monitored to
ensure safe and efficient application of the battery for HEVs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08080</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08080</id><created>2019-09-17</created><authors><author><keyname>Fuoli</keyname><forenames>Dario</forenames></author><author><keyname>Gu</keyname><forenames>Shuhang</forenames></author><author><keyname>Timofte</keyname><forenames>Radu</forenames></author></authors><title>Efficient Video Super-Resolution through Recurrent Latent Space
  Propagation</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the recent trend for ultra high definition displays, the demand for high
quality and efficient video super-resolution (VSR) has become more important
than ever. Previous methods adopt complex motion compensation strategies to
exploit temporal information when estimating the missing high frequency
details. However, as the motion estimation problem is a highly challenging
problem, inaccurate motion compensation may affect the performance of VSR
algorithms. Furthermore, the complex motion compensation module may also
introduce a heavy computational burden, which limits the application of these
methods in real systems. In this paper, we propose an efficient recurrent
latent space propagation (RLSP) algorithm for fast VSR. RLSP introduces
high-dimensional latent states to propagate temporal information between frames
in an implicit manner. Our experimental results show that RLSP is a highly
efficient and effective method to deal with the VSR problem. We outperform
current state-of-the-art method DUF with over 70x speed-up.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08093</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08093</id><created>2019-09-10</created><authors><author><keyname>Ghanavi</keyname><forenames>Rozhina</forenames></author><author><keyname>Sabbaghian</keyname><forenames>Maryam</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author></authors><title>Q-Learning Based Aerial Base Station Placement for Fairness Enhancement
  in Mobile Networks</title><categories>cs.NI cs.LG eess.SP stat.ML</categories><comments>Accepted in IEEE GlobalSIP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we use an aerial base station (aerial-BS) to enhance fairness
in a dynamic environment with user mobility. The problem of optimally placing
the aerial-BS is a non-deterministic polynomial-time hard (NP-hard) problem.
Moreover, the network topology is subject to continuous changes due to the user
mobility. These issues intensify the quest to develop an adaptive and fast
algorithm for 3D placement of the aerial-BS. To this end, we propose a method
based on reinforcement learning to achieve these goals. Simulation results show
that our method increases fairness among users in a reasonable computing time,
while the solution is comparatively close to the optimal solution obtained by
exhaustive search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08103</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08103</id><created>2019-09-17</created><authors><author><keyname>Kanda</keyname><forenames>Naoyuki</forenames></author><author><keyname>Horiguchi</keyname><forenames>Shota</forenames></author><author><keyname>Fujita</keyname><forenames>Yusuke</forenames></author><author><keyname>Xue</keyname><forenames>Yawen</forenames></author><author><keyname>Nagamatsu</keyname><forenames>Kenji</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author></authors><title>Simultaneous Speech Recognition and Speaker Diarization for Monaural
  Dialogue Recordings with Target-Speaker Acoustic Models</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted to ASRU 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the use of target-speaker automatic speech
recognition (TS-ASR) for simultaneous speech recognition and speaker
diarization of single-channel dialogue recordings. TS-ASR is a technique to
automatically extract and recognize only the speech of a target speaker given a
short sample utterance of that speaker. One obvious drawback of TS-ASR is that
it cannot be used when the speakers in the recordings are unknown because it
requires a sample of the target speakers in advance of decoding. To remove this
limitation, we propose an iterative method, in which (i) the estimation of
speaker embeddings and (ii) TS-ASR based on the estimated speaker embeddings
are alternately executed. We evaluated the proposed method by using very
challenging dialogue recordings in which the speaker overlap ratio was over
20%. We confirmed that the proposed method significantly reduced both the word
error rate (WER) and diarization error rate (DER). Our proposed method combined
with i-vector speaker embeddings ultimately achieved a WER that differed by
only 2.1 % from that of TS-ASR given oracle speaker embeddings. Furthermore,
our method can solve speaker diarization simultaneously as a by-product and
achieved better DER than that of the conventional clustering-based speaker
diarization method based on i-vector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08111</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08111</id><created>2019-09-17</created><authors><author><keyname>Porter</keyname><forenames>Matthew</forenames></author><author><keyname>Hespanhol</keyname><forenames>Pedro</forenames></author><author><keyname>Aswani</keyname><forenames>Anil</forenames></author><author><keyname>Johnson-Roberson</keyname><forenames>Matthew</forenames></author><author><keyname>Vasudevan</keyname><forenames>Ram</forenames></author></authors><title>Detecting Generalized Replay Attacks via Time-Varying Dynamic
  Watermarking</title><categories>math.OC cs.SY eess.SY</categories><comments>16 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyber-physical systems (CPS) often rely on external communication for
supervisory control or sensing. Unfortunately, these communications render the
system vulnerable to cyber-attacks. Attacks that alter messages, such as replay
attacks that record measurement signals and then play them back to the system,
can cause devastating effects. Dynamic Watermarking methods, which inject a
private excitation into control inputs to secure resulting measurement signals,
have begun addressing the challenges of detecting these attacks, but have been
restricted to linear time invariant (LTI) systems. Though LTI models are
sufficient for some applications, other CPS, such as autonomous vehicles,
require more complex models. This paper develops a linear time-varying (LTV)
extension to previous Dynamic Watermarking methods by designing a matrix
normalization factor to accommodate the temporal changes in the system.
Implementable tests are provided with considerations for real-world systems.
The proposed method is then shown to be able to detect generalized replay
attacks both in theory and in simulation using a LTV vehicle model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08118</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08118</id><created>2019-09-17</created><authors><author><keyname>Zhang</keyname><forenames>Ruiyang</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Sun</keyname><forenames>Hao</forenames></author></authors><title>Physics-guided Convolutional Neural Network (PhyCNN) for Data-driven
  Seismic Response Modeling</title><categories>eess.SP cs.CE</categories><comments>24 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seismic events, among many other natural hazards, reduce due functionality
and exacerbate vulnerability of in-service buildings. Accurate modeling and
prediction of building's response subjected to earthquakes makes possible to
evaluate building performance. To this end, we leverage the recent advances in
deep learning and develop a physics-guided convolutional neural network
(PhyCNN) framework for data-driven seismic response modeling and serviceability
assessment of buildings. The proposed PhyCNN approach is capable of accurately
predicting building's seismic response in a data-driven fashion without the
need of a physics-based analytical/numerical model. The basic concept is to
train a deep PhyCNN model based on available seismic input-output datasets
(e.g., from simulation or sensing) and physics constraints. The trained PhyCNN
can then used as a surrogate model for structural seismic response prediction.
Available physics (e.g., the law of dynamics) can provide constraints to the
network outputs, alleviate overfitting issues, reduce the need of big training
datasets, and thus improve the robustness of the trained model for more
reliable prediction. The trained surrogate model is then utilized for fragility
analysis given certain limit state criteria (e.g., the serviceability state).
In addition, an unsupervised learning algorithm based on K-means clustering is
also proposed to partition the limited number of datasets to training,
validation and prediction categories, so as to maximize the use of limited
datasets. The performance of the proposed approach is demonstrated through
three case studies including both numerical and experimental examples.
Convincing results illustrate that the proposed PhyCNN paradigm outperforms
conventional pure data-based neural networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08124</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08124</id><created>2019-09-17</created><authors><author><keyname>Ma</keyname><forenames>Wen-Loong</forenames></author><author><keyname>Hamed</keyname><forenames>Kaveh Akbari</forenames></author><author><keyname>Ames</keyname><forenames>Aaron D.</forenames></author></authors><title>First Steps Towards Full Model Based Motion Planning and Control of
  Quadrupeds: A Hybrid Zero Dynamics Approach</title><categories>cs.RO cs.SY eess.SY</categories><comments>To be appear in 2019 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hybrid zero dynamics (HZD) approach has become a powerful tool for the
gait planning and control of bipedal robots. This paper aims to extend the HZD
methods to address walking, ambling and trotting behaviors on a quadrupedal
robot. We present a framework that systematically generates a wide range of
optimal trajectories and then provably stabilizes them for the full-order,
nonlinear and hybrid dynamical models of quadrupedal locomotion. The gait
planning is addressed through a scalable nonlinear programming using direct
collocation and HZD. The controller synthesis for the exponential stability is
then achieved through the Poincar\'e sections analysis. In particular, we
employ an iterative optimization algorithm involving linear and bilinear matrix
inequalities (LMIs and BMIs) to design HZD-based controllers that guarantee the
exponential stability of the fixed points for the Poincar\'e return map. The
power of the framework is demonstrated through gait generation and HZD-based
controller synthesis for an advanced quadruped robot, ---Vision 60, with 36
state variables and 12 control inputs. The numerical simulations as well as
real world experiments confirm the validity of the proposed framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08148</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08148</id><created>2019-09-17</created><authors><author><keyname>Li</keyname><forenames>Hongshan</forenames></author><author><keyname>Guo</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Zhi</forenames></author><author><keyname>Xia</keyname><forenames>Shutao</forenames></author><author><keyname>Zhu</keyname><forenames>Wenwu</forenames></author></authors><title>AdaCompress: Adaptive Compression for Online Computer Vision Services</title><categories>cs.MM eess.IV</categories><comments>ACM Multimedia</comments><doi>10.1145/3343031.3350874</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growth of computer vision based applications and services, an
explosive amount of images have been uploaded to cloud servers which host such
computer vision algorithms, usually in the form of deep learning models. JPEG
has been used as the {\em de facto} compression and encapsulation method before
one uploads the images, due to its wide adaptation. However, standard JPEG
configuration does not always perform well for compressing images that are to
be processed by a deep learning model, e.g., the standard quality level of JPEG
leads to 50\% of size overhead (compared with the best quality level selection)
on ImageNet under the same inference accuracy in popular computer vision models
including InceptionNet, ResNet, etc. Knowing this, designing a better JPEG
configuration for online computer vision services is still extremely
challenging: 1) Cloud-based computer vision models are usually a black box to
end-users; thus it is difficult to design JPEG configuration without knowing
their model structures. 2) JPEG configuration has to change when different
users use it. In this paper, we propose a reinforcement learning based JPEG
configuration framework. In particular, we design an agent that adaptively
chooses the compression level according to the input image's features and
backend deep learning models. Then we train the agent in a reinforcement
learning way to adapt it for different deep learning cloud services that act as
the {\em interactive training environment} and feeding a reward with
comprehensive consideration of accuracy and data size. In our real-world
evaluation on Amazon Rekognition, Face++ and Baidu Vision, our approach can
reduce the size of images by 1/2 -- 1/3 while the overall classification
accuracy only decreases slightly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08150</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08150</id><created>2019-09-17</created><authors><author><keyname>Malla</keyname><forenames>Srikanth</forenames></author><author><keyname>Choi</keyname><forenames>Chiho</forenames></author></authors><title>NEMO: Future Object Localization Using Noisy Ego Priors</title><categories>cs.CV cs.RO eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Predictive models for forecasting future behavior of road agents should
consider the multi-modal nature and be aware of the uncertainty of their
predictions. Particularly from the egocentric view where the motion of other
agents is captured with respect to the ego-motion, the uncertainty of
ego-motion prediction is critical to determine their interactive reactions and
behaviors. Along this line, we propose NEMO (Noisy Ego MOtion priors for future
object localization) for future forecast of road agents in the egocentric view.
A predictive distribution of future forecast is jointly modeled with the
uncertainty of predictions. For this, we divide the problem into two tasks:
future ego-motion prediction and future object localization. We first model the
multi-modal distribution of future ego-motion with uncertainty estimates. The
resulting distribution of ego-behavior is used to sample multiple modes of
future ego-motion. Then, each modality is used as a prior to understand the
interactions between the ego-vehicle and target agent. We predict the
multi-modal future locations of the target from individual modes of the
ego-vehicle, modeling the uncertainty of target's behavior. To this end, we
extensively evaluate the proposed framework using the publicly available
benchmark dataset (HEV-I) with an addition of Inertial Measurement Unit (IMU)
data to it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08174</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08174</id><created>2019-09-17</created><authors><author><keyname>You</keyname><forenames>Zhonghui</forenames></author><author><keyname>Yan</keyname><forenames>Kun</forenames></author><author><keyname>Ye</keyname><forenames>Jinmian</forenames></author><author><keyname>Ma</keyname><forenames>Meng</forenames></author><author><keyname>Wang</keyname><forenames>Ping</forenames></author></authors><title>Gate Decorator: Global Filter Pruning Method for Accelerating Deep
  Convolutional Neural Networks</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted by NeurIPS'19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Filter pruning is one of the most effective ways to accelerate and compress
convolutional neural networks (CNNs). In this work, we propose a global filter
pruning algorithm called Gate Decorator, which transforms a vanilla CNN module
by multiplying its output by the channel-wise scaling factors, i.e. gate. When
the scaling factor is set to zero, it is equivalent to removing the
corresponding filter. We use Taylor expansion to estimate the change in the
loss function caused by setting the scaling factor to zero and use the
estimation for the global filter importance ranking. Then we prune the network
by removing those unimportant filters. After pruning, we merge all the scaling
factors into its original module, so no special operations or structures are
introduced. Moreover, we propose an iterative pruning framework called
Tick-Tock to improve pruning accuracy. The extensive experiments demonstrate
the effectiveness of our approaches. For example, we achieve the
state-of-the-art pruning ratio on ResNet-56 by reducing 70% FLOPs without
noticeable loss in accuracy. For ResNet-50 on ImageNet, our pruned model with
40% FLOPs reduction outperforms the baseline model by 0.31% in top-1 accuracy.
Various datasets are used, including CIFAR-10, CIFAR-100, CUB-200, ImageNet
ILSVRC-12 and PASCAL VOC 2011. Code is available at
github.com/youzhonghui/gate-decorator-pruning
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08177</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08177</id><created>2019-09-17</created><authors><author><keyname>Shimobaba</keyname><forenames>Tomoyoshi</forenames></author><author><keyname>Takahashi</keyname><forenames>Takayuki</forenames></author><author><keyname>Yamamoto</keyname><forenames>Yota</forenames></author><author><keyname>Hoshi</keyname><forenames>Ikuo</forenames></author><author><keyname>Shiraki</keyname><forenames>Atsushi</forenames></author><author><keyname>Kakue</keyname><forenames>Takashi</forenames></author><author><keyname>Ito</keyname><forenames>Tomoyoshi</forenames></author></authors><title>Simple complex amplitude encoding of a phase-only hologram using
  binarized amplitude</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For this work, we introduced the use of binary amplitude for our proposed
complex amplitude encoding of a phase-only hologram. By principle, a complex
amplitude in a hologram plane can be represented by the amplitude and its
phase. However, a phase-only hologram contains only phase information of the
complex amplitude, which results in degradation of reconstruction quality from
the hologram. In our method, by approximating the amplitude in the hologram
plane using a binary amplitude, we can finally record the complex amplitude of
an original light in the phase-only hologram. We validated the effectiveness of
our method with two examples, hologram reconstruction and generation of
Hermite-Gaussian beams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08182</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08182</id><created>2019-09-17</created><authors><author><keyname>Nugaliyadde</keyname><forenames>Anupiya</forenames></author><author><keyname>Somaratne</keyname><forenames>Upeka</forenames></author><author><keyname>Wong</keyname><forenames>Kok Wai</forenames></author></authors><title>Predicting Electricity Consumption using Deep Recurrent Neural Networks</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electricity consumption has increased exponentially during the past few
decades. This increase is heavily burdening the electricity distributors.
Therefore, predicting the future demand for electricity consumption will
provide an upper hand to the electricity distributor. Predicting electricity
consumption requires many parameters. The paper presents two approaches with
one using a Recurrent Neural Network (RNN) and another one using a Long Short
Term Memory (LSTM) network, which only considers the previous electricity
consumption to predict the future electricity consumption. These models were
tested on the publicly available London smart meter dataset. To assess the
applicability of the RNN and the LSTM network to predict electricity
consumption, they were tested to predict for an individual house and a block of
houses for a given time period. The predictions were done for daily, trimester
and 13 months, which covers short term, mid-term and long term prediction. Both
the RNN and the LSTM network have achieved an average Root Mean Square error of
0.1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08185</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1909.08185</id><created>2019-09-17</created><authors><author><keyname>Peter</keyname><forenames>Rubin Jose</forenames></author><author><keyname>Murthy</keyname><forenames>Chandra R.</forenames></author></authors><title>Learned-SBL: A Deep Learning Architecture for Sparse Signal Recovery</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>13 pages, 22 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a computationally efficient sparse signal recovery
scheme using Deep Neural Networks (DNN). The architecture of the introduced
neural network is inspired from sparse Bayesian learning (SBL) and named as
Learned-SBL (L-SBL). We design a common architecture to recover sparse as well
as block sparse vectors from single measurement vector (SMV) or multiple
measurement vectors (MMV) depending on the nature of the training data. In the
MMV model, the L-SBL network can be trained to learn any underlying sparsity
pattern among the vectors including joint sparsity, block sparsity, etc. In
particular, for block sparse recovery, learned-SBL does not require any prior
knowledge of block boundaries. In each layer of the L-SBL, an estimate of the
signal covariance matrix is obtained as the output of a neural network. Then a
maximum a posteriori (MAP) estimator of the unknown sparse vector is
implemented with non-trainable parameters. In many applications, the
measurement matrix may be time-varying. The existing DNN based sparse signal
recovery schemes demand the retraining of the neural network using current
measurement matrix. The architecture of L-SBL allows it to accept the
measurement matrix as an input to the network, and thereby avoids the need for
retraining. We also evaluate the performance of Learned-SBL in the detection of
an extended target using a multiple-input multiple-output (MIMO) radar.
Simulation results illustrate that the proposed approach offers superior sparse
recovery performance compared to the state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="9000" completeListSize="16166">4250076|10001</resumptionToken>
</ListRecords>
</OAI-PMH>
