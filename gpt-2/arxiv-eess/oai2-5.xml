<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2020-03-01T06:59:42Z</responseDate>
<request verb="ListRecords" resumptionToken="4250076|4001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1811.11586</identifier>
 <datestamp>2018-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.11586</id><created>2018-11-28</created><authors><author><keyname>Fascista</keyname><forenames>Alessio</forenames></author><author><keyname>Coluccia</keyname><forenames>Angelo</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Seco-Granados</keyname><forenames>Gonzalo</forenames></author></authors><title>Millimeter-Wave Downlink Positioning with a Single-Antenna Receiver</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper addresses the problem of determining the unknown position of a
mobile station for a mmWave MISO system. This setup is motivated by the fact
that massive arrays will be initially implemented only on 5G base stations,
likely leaving mobile stations with one antenna. The maximum likelihood
solution to this problem is devised based on the time of flight and angle of
departure of received downlink signals. While positioning in the uplink would
rely on angle of arrival, it presents scalability limitations that are avoided
in the downlink. To circumvent the multidimensional optimization of the optimal
joint estimator, we propose two novel approaches amenable to practical
implementation thanks to their reduced complexity. A thorough analysis, which
includes the derivation of relevant Cram\'er-Rao lower bounds, shows that it is
possible to achieve quasi-optimal performance even in presence of few
transmissions, low SNRs, and multipath propagation effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.11627</identifier>
 <datestamp>2018-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.11627</id><created>2018-11-28</created><authors><author><keyname>Kang</keyname><forenames>Bosung</forenames></author><author><keyname>Aldayel</keyname><forenames>Omar</forenames></author><author><keyname>Monga</keyname><forenames>Vishal</forenames></author><author><keyname>Rangaswamy</keyname><forenames>Muralidhar</forenames></author></authors><title>Spatio-Spectral Radar Beampattern Design for Co-existence with Wireless
  Communication Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of designing a transmit beampattern for multiple-input
multiple-output (MIMO) radar considering co-existence with wireless
communication systems. The designed beampattern is able to manage the transmit
energy in spatial directions as well as in spectral frequency bands of interest
by minimizing the deviation of the designed beampattern versus a desired one
under a spectral constraint as well as the constant modulus constraint. While
unconstrained beampattern design is straightforward, a key open challenge is
jointly enforcing the spectral constraint in addition to the constant modulus
constraint on the radar waveform. A new approach is proposed in our work, which
involves solving a sequence of constrained quadratic programs such that
constant modulus is achieved at convergence. Further, we show that each problem
in the sequence has a closed form solution leading to analytical tractability.
We evaluate the proposed beampattern with interference control (BIC) algorithm
against the state-of-the-art MIMO beampattern design techniques and show that
BIC achieves closeness to an idealized beampattern along with desired spectral
shaping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.11663</identifier>
 <datestamp>2018-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.11663</id><created>2018-11-28</created><authors><author><keyname>Moore</keyname><forenames>Alastair H.</forenames></author></authors><title>Multiple source direction of arrival estimation using subspace
  pseudointensity vectors</title><categories>cs.SD eess.AS</categories><comments>In Proceedings of the LOCATA Challenge Workshop - a satellite event
  of IWAENC 2018 (arXiv:1811.08482 )</comments><report-no>LOCATAchallenge/2018/02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently proposed subspace pseudointensity method for direction of
arrival estimation is applied in the context of Tasks 1 and 2 of the LOCATA
Challenge using the Eigenmike recordings. Specific implementation details are
described and results reported for the development dataset, for which the
ground truth source directions are available. For both single and multiple
source scenarios, the average absolute error angle is about 9 degrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.11683</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.11683</id><created>2018-11-28</created><updated>2019-05-29</updated><authors><author><keyname>Akbari</keyname><forenames>Hassan</forenames></author><author><keyname>Karaman</keyname><forenames>Svebor</forenames></author><author><keyname>Bhargava</keyname><forenames>Surabhi</forenames></author><author><keyname>Chen</keyname><forenames>Brian</forenames></author><author><keyname>Vondrick</keyname><forenames>Carl</forenames></author><author><keyname>Chang</keyname><forenames>Shih-Fu</forenames></author></authors><title>Multi-level Multimodal Common Semantic Space for Image-Phrase Grounding</title><categories>cs.CV cs.CL cs.LG eess.IV</categories><comments>Accepted in CVPR 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of phrase grounding by lear ing a multi-level common
semantic space shared by the textual and visual modalities. We exploit multiple
levels of feature maps of a Deep Convolutional Neural Network, as well as
contextualized word and sentence embeddings extracted from a character-based
language model. Following dedicated non-linear mappings for visual features at
each level, word, and sentence embeddings, we obtain multiple instantiations of
our common semantic space in which comparisons between any target text and the
visual content is performed with cosine similarity. We guide the model by a
multi-level multimodal attention mechanism which outputs attended visual
features at each level. The best level is chosen to be compared with text
content for maximizing the pertinence scores of image-sentence pairs of the
ground truth. Experiments conducted on three publicly available datasets show
significant performance gains (20%-60% relative) over the state-of-the-art in
phrase localization and set a new performance record on those datasets. We
provide a detailed ablation study to show the contribution of each element of
our approach and release our code on GitHub.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.11695</identifier>
 <datestamp>2018-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.11695</id><created>2018-11-28</created><authors><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Kammoun</keyname><forenames>Abla</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Theoretical Performance Limits of Massive MIMO with Uncorrelated Rician
  Fading Channels</title><categories>cs.IT eess.SP math.IT</categories><comments>17 pages, 5 figures. To appear in IEEE Transactions on
  Communications. This is a longer version containing all the mathematical
  steps for some of the proofs in the Appendices</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers a multicell Massive MIMO network with $L$ cells, each
comprising a BS with $M$ antennas and $K$ single-antenna user equipments.
Within this setting, we are interested in deriving approximations of the
achievable rates in the uplink and downlink under the assumption that
single-cell linear processing is used at each BS and that each intracell link
forms an uncorrelated MIMO Rician fading channel matrix; that is, with a
deterministic line-of-sight (LoS) path and a stochastic non-line-of-sight
component describing a spatial uncorrelated multipath environment. The analysis
is conducted assuming that $N$ and $K$ grow large with a given ratio $N/K$
under the assumption that the data transmission in each cell is affected by
channel estimation errors, pilot contamination, an arbitrary large scale
attenuation and LoS components. Numerical results are used to prove that the
approximations are asymptotically tight, but accurate for systems with finite
dimensions under different operating conditions. The asymptotic results are
also used to evaluate the impact of LoS components. In particular, we exemplify
how the number of antennas for achieving a target rate can be substantially
reduced with LoS links of only a few dBs of strength.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.11785</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.11785</id><created>2018-11-28</created><updated>2019-02-11</updated><authors><author><keyname>Grondin</keyname><forenames>Francois</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>SVD-PHAT: A Fast Sound Source Localization Method</title><categories>eess.AS cs.SD eess.SP</categories><journal-ref>Proceedings of the 2019 IEEE International Conference on
  Acoustics, Speech, and Signal Processing</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new localization method called SVD-PHAT. The SVD-PHAT
method relies on Singular Value Decomposition of the SRP-PHAT projection
matrix. A k-d tree is also proposed to speed up the search for the most likely
direction of arrival of sound. We show that this method performs as accurately
as SRP-PHAT, while reducing significantly the amount of computation required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.11787</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.11787</id><created>2018-11-28</created><authors><author><keyname>Grondin</keyname><forenames>Francois</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>A Study of the Complexity and Accuracy of Direction of Arrival
  Estimation Methods Based on GCC-PHAT for a Pair of Close Microphones</title><categories>eess.AS cs.SD eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the accuracy of various Generalized Cross-Correlation
with Phase Transform (GCC-PHAT) methods for a close pair of microphones. We
investigate interpolation-based methods and also propose another approach based
on Singular Value Decomposition (SVD). All investigated methods are implemented
in C code, and the execution time is measured to determine which approach is
the most appealing for real-time applications on low-cost embedded hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.11874</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.11874</id><created>2018-11-28</created><authors><author><keyname>Gong</keyname><forenames>Chen</forenames></author><author><keyname>Erichson</keyname><forenames>N. Benjamin</forenames></author><author><keyname>Kelly</keyname><forenames>John P.</forenames></author><author><keyname>Trutoiu</keyname><forenames>Laura</forenames></author><author><keyname>Schowengerdt</keyname><forenames>Brian T.</forenames></author><author><keyname>Brunton</keyname><forenames>Steven L.</forenames></author><author><keyname>Seibel</keyname><forenames>Eric J.</forenames></author></authors><title>RetinaMatch: Efficient Template Matching of Retina Images for
  Teleophthalmology</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Retinal template matching and registration is an important challenge in
teleophthalmology with low-cost imaging devices. However, the images from such
devices generally have a small field of view (FOV) and image quality
degradations, making matching difficult. In this work, we develop an efficient
and accurate retinal matching technique that combines dimension reduction and
mutual information (MI), called RetinaMatch. The dimension reduction
initializes the MI optimization as a coarse localization process, which narrows
the optimization domain and avoids local optima. The effectiveness of
RetinaMatch is demonstrated on the open fundus image database STARE with
simulated reduced FOV and anticipated degradations, and on retinal images
acquired by adapter-based optics attached to a smartphone. RetinaMatch achieves
a success rate over 94\% on human retinal images with the matched target
registration errors below 2 pixels on average, excluding the observer
variability. It outperforms the standard template matching solutions. In the
application of measuring vessel diameter repeatedly, single pixel errors are
expected. In addition, our method can be used in the process of image
mosaicking with area-based registration, providing a robust approach when the
feature based methods fail. To the best of our knowledge, this is the first
template matching algorithm for retina images with small template images from
unconstrained retinal areas. In the context of the emerging mixed reality
market, we envision automated retinal image matching and registration methods
as transformative for advanced teleophthalmology and long-term retinal
monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.11883</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.11883</id><created>2018-11-28</created><authors><author><keyname>Malik</keyname><forenames>Rafia</forenames></author><author><keyname>Vu</keyname><forenames>Mai</forenames></author></authors><title>Optimizing Throughput in a MIMO System with a Self-sustained Relay and
  Non-uniform Power Splitting</title><categories>eess.SP</categories><doi>10.1109/LWC.2018.2866551</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to maximizing the transmission rate in a MIMO
relay system, where all nodes are equipped with multiple antennas and the relay
is self-sustained by harvesting energy. We formulate an optimization problem
and use dual-characterization to derive a closed-form solution for the optimal
power splitting ratio and precoding design. We propose an efficient primal-dual
algorithm to jointly optimize the power allocation at source and relay for
transmission and the power splitting at relay for energy harvesting, and show
that using non-uniform power splitting is optimal. Numerical results
demonstrate the significant rate gain of non-uniform power splitting over
traditional uniform splitting especially at low source transmit power. We also
analyze our algorithm numerically and demonstrate its efficiency at reducing
the run-time by several orders of magnitudes compared to a standard solver,
\textcolor{blue}{and existing algorithms in literature
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.11913</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.11913</id><created>2018-11-28</created><authors><author><keyname>Hwang</keyname><forenames>Min-Jae</forenames></author><author><keyname>Soong</keyname><forenames>Frank</forenames></author><author><keyname>Xie</keyname><forenames>Fenglong</forenames></author><author><keyname>Wang</keyname><forenames>Xi</forenames></author><author><keyname>Kang</keyname><forenames>Hong-Goo</forenames></author></authors><title>LP-WaveNet: Linear Prediction-based WaveNet Speech Synthesis</title><categories>eess.AS cs.SD</categories><comments>Submitted to ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a linear prediction (LP)-based waveform generation method via
WaveNet speech synthesis. The WaveNet vocoder, which uses speech parameters as
a conditional input of WaveNet, has significantly improved the quality of
statistical parametric speech synthesis system. However, it is still
challenging to effectively train the neural vocoder when the target database
becomes larger and more expressive. As a solution, the approaches that only
generate the vocal source signal by the neural vocoder have been proposed.
However, they tend to generate synthetic noise because the vocal source is
independently handled without considering the entire speech synthesis process;
where it is inevitable to come up with a mismatch between vocal source and
vocal tract filter. To address this problem, we propose an LP-WaveNet that
structurally models the vocal source in the speech training and inference
processes. The experimental results verify that the proposed system outperforms
the conventional WaveNet vocoders both objectively and subjectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12063</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12063</id><created>2018-11-29</created><authors><author><keyname>Sattiraju</keyname><forenames>Raja</forenames></author><author><keyname>Weinand</keyname><forenames>Andreas</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Performance Analysis of Deep Learning based on Recurrent Neural Networks
  for Channel Coding</title><categories>eess.SP</categories><comments>To be published in IEEE ANTS 2018, Dec 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel Coding has been one of the central disciplines driving the success
stories of current generation LTE systems and beyond. In particular, turbo
codes are mostly used for cellular and other applications where a reliable data
transfer is required for latency-constrained communication in the presence of
data-corrupting noise. However, the decoding algorithm for turbo codes is
computationally intensive and thereby limiting its applicability in hand-held
devices. In this paper, we study the feasibility of using Deep Learning (DL)
architectures based on Recurrent Neural Networks (RNNs) for encoding and
decoding of turbo codes. In this regard, we simulate and use data from various
stages of the transmission chain (turbo encoder output, Additive White Gaussian
Noise (AWGN) channel output, demodulator output) to train our proposed RNN
architecture and compare its performance to the conventional turbo
encoder/decoder algorithms. Simulation results show, that the proposed RNN
model outperforms the decoding performance of a conventional turbo decoder at
low Signal to Noise Ratio (SNR) regions
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12081</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12081</id><created>2018-11-29</created><authors><author><keyname>Neto</keyname><forenames>Fernando Fernandes</forenames></author><author><keyname>Solomon</keyname><forenames>Alemayehu Admasu</forenames></author><author><keyname>de Losso</keyname><forenames>Rodrigo</forenames></author><author><keyname>Garcia</keyname><forenames>Claudio</forenames></author><author><keyname>Cavalcanti</keyname><forenames>Pedro Delano</forenames></author></authors><title>Deep Haar Scattering Networks in Pattern Recognition: A promising
  approach</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to discuss the use of Haar scattering networks,
which is a very simple architecture that naturally supports a large number of
stacked layers, yet with very few parameters, in a relatively broad set of
pattern recognition problems, including regression and classification tasks.
This architecture, basically, consists of stacking convolutional filters, that
can be thought as a generalization of Haar wavelets, followed by non-linear
operators which aim to extract symmetries and invariances that are later fed in
a classification/regression algorithm. We show that good results can be
obtained with the proposed method for both kind of tasks. We have outperformed
the best available algorithms in 4 out of 18 important data classification
problems, and have obtained a more robust performance than ARIMA and ETS time
series methods in regression problems for data with strong periodicities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12119</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12119</id><created>2018-11-29</created><updated>2019-03-27</updated><authors><author><keyname>Ahrens</keyname><forenames>Lia</forenames></author><author><keyname>Ahrens</keyname><forenames>Julian</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>A Machine-Learning Phase Classification Scheme for Anomaly Detection in
  Signals with Periodic Characteristics</title><categories>eess.SP cs.LG</categories><comments>25 pages, 15 figures</comments><doi>10.1186/s13634-019-0619-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a novel machine-learning method for anomaly
detection applicable to data with periodic characteristics where randomly
varying period lengths are explicitly allowed. A multi-dimensional time series
analysis is conducted by training a data-adapted classifier consisting of deep
convolutional neural networks performing phase classification. The entire
algorithm including data pre-processing, period detection, segmentation, and
even dynamic adjustment of the neural networks is implemented for fully
automatic execution. The proposed method is evaluated on three example datasets
from the areas of cardiology, intrusion detection, and signal processing,
presenting reasonable performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12179</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12179</id><created>2018-11-26</created><authors><author><keyname>Sun</keyname><forenames>Baohua</forenames></author><author><keyname>Liu</keyname><forenames>Daniel</forenames></author><author><keyname>Yu</keyname><forenames>Leo</forenames></author><author><keyname>Li</keyname><forenames>Jay</forenames></author><author><keyname>Liu</keyname><forenames>Helen</forenames></author><author><keyname>Zhang</keyname><forenames>Wenhan</forenames></author><author><keyname>Torng</keyname><forenames>Terry</forenames></author></authors><title>MRAM Co-designed Processing-in-Memory CNN Accelerator for Mobile and IoT
  Applications</title><categories>eess.SP</categories><comments>4 pages, 4 figures, 1 table. Accepted by NIPS 2018 MLPCD workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We designed a device for Convolution Neural Network applications with
non-volatile MRAM memory and computing-in-memory co-designed architecture. It
has been successfully fabricated using 22nm technology node CMOS Si process.
More than 40MB MRAM density with 9.9TOPS/W are provided. It enables multiple
models within one single chip for mobile and IoT device applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12182</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12182</id><created>2018-11-27</created><authors><author><keyname>Yazdanian</keyname><forenames>Peyman</forenames></author><author><keyname>Pourahmadi</keyname><forenames>Vahid</forenames></author></authors><title>DeepPos: Deep Supervised Autoencoder Network for CSI Based Indoor
  Localization</title><categories>eess.SP cs.AI cs.LG stat.ML</categories><comments>10 pages, 15 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread mobile devices facilitated the emergence of many new
applications and services. Among them are location-based services (LBS) that
provide services based on user's location. Several techniques have been
presented to enable LBS even in indoor environments where Global Positioning
System (GPS) has low localization accuracy. These methods use some environment
measurements (like Channel State Information (CSI) or Received Signal Strength
(RSS)) for user localization. In this paper, we will use CSI and a novel deep
learning algorithm to design a robust and efficient system for indoor
localization. More precisely, we use supervised autoencoder (SAE) to model the
environment using the data collected during the training phase. Then, during
the testing phase, we use the trained model and estimate the coordinates of the
unknown point by checking different possible labels. Unlike the previous
fingerprinting approaches, in this work, we do not store the {CSI/RSS} of
fingerprints and instead we model the environment only with a single SAE. The
performance of the proposed scheme is then evaluated in two indoor environments
and compared with that of similar approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12183</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12183</id><created>2018-11-26</created><authors><author><keyname>Wu</keyname><forenames>Di</forenames></author><author><keyname>Zhou</keyname><forenames>Enlu</forenames></author></authors><title>Analyzing and provably improving fixed budget ranking and selection
  algorithms</title><categories>math.OC cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the fixed budget formulation of the Ranking and Selection
(R&amp;S) problem with independent normal samples, where the goal is to investigate
different algorithms' convergence rate in terms of their resulting probability
of false selection (PFS). First, we reveal that for the well-known Optimal
Computing Budget Allocation (OCBA) algorithm and its two variants, a constant
initial sample size (independent of the total budget) only amounts to a
sub-exponential (or even polynomial) convergence rate. After that, a
modification is proposed to achieve an exponential convergence rate, where the
improvement is shown by a finite-sample bound on the PFS as well as numerical
results. Finally, we focus on a more tractable two-design case and explicitly
characterize the large deviations rate of PFS for some simplified algorithms.
Our analysis not only develops insights into the algorithms' properties, but
also highlights several useful techniques for analyzing the convergence rate of
fixed budget R\&amp;S algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12192</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12192</id><created>2018-11-28</created><authors><author><keyname>Debarnot</keyname><forenames>Valentin</forenames></author><author><keyname>Escande</keyname><forenames>Paul</forenames></author><author><keyname>Weiss</keyname><forenames>Pierre</forenames></author></authors><title>A scalable estimator of sets of integral operators</title><categories>eess.SP</categories><report-no>in Proceedings of iTWIST'18, Paper-ID: 2, Marseille, France,
  November, 21-23, 2018</report-no><journal-ref>in Proceedings of iTWIST'18, Paper-ID: 2, Marseille, France,
  November, 21-23, 2018</journal-ref><doi>10.1088/1361-6420/ab2fb3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a scalable method to find a subspace $\widehat{\mathcal{H}}$ of
low-rank tensors that simultaneously approximates a set of integral operators.
The method can be seen as a generalization of the Tucker-2 decomposition model,
which was never used in this context. In addition, we propose to construct a
convex set $\widehat{\mathcal{C}} \subset \widehat{\mathcal{H}}$ as the convex
hull of the observed operators. It is a minimax optimal estimator under the
Nikodym metric. We then provide an efficient algorithm to compute projection on
$\widehat{\mathcal{C}}$. We observe a good empirical behavior of the method in
simulations. The main aim of this work is to improve the identifiability of
complex linear operators in blind inverse problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12193</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12193</id><created>2018-11-27</created><authors><author><keyname>Golovastova</keyname><forenames>E. A.</forenames></author></authors><title>The system operating time with two different unreliable servicing
  devices</title><categories>eess.SP</categories><comments>in Russian</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the reliability problem in a system with two different devices,
which can break down.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12194</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12194</id><created>2018-11-28</created><updated>2019-02-17</updated><authors><author><keyname>Ribeiro</keyname><forenames>Ant&#xf4;nio H.</forenames></author><author><keyname>Ribeiro</keyname><forenames>Manoel Horta</forenames></author><author><keyname>Paix&#xe3;o</keyname><forenames>Gabriela</forenames></author><author><keyname>Oliveira</keyname><forenames>Derick</forenames></author><author><keyname>Gomes</keyname><forenames>Paulo R.</forenames></author><author><keyname>Canazart</keyname><forenames>J&#xe9;ssica A.</forenames></author><author><keyname>Pifano</keyname><forenames>Milton</forenames></author><author><keyname>Meira</keyname><forenames>Wagner</forenames><suffix>Jr.</suffix></author><author><keyname>Sch&#xf6;n</keyname><forenames>Thomas B.</forenames></author><author><keyname>Ribeiro</keyname><forenames>Antonio Luiz</forenames></author></authors><title>Automatic Diagnosis of Short-Duration 12-Lead ECG using a Deep
  Convolutional Network</title><categories>eess.SP cs.HC cs.LG stat.ML</categories><comments>Machine Learning for Health (ML4H) Workshop at NeurIPS 2018
  arXiv:1811.07216</comments><report-no>ML4H/2018/82</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a model for predicting electrocardiogram (ECG) abnormalities in
short-duration 12-lead ECG signals which outperformed medical doctors on the
4th year of their cardiology residency. Such exams can provide a full
evaluation of heart activity and have not been studied in previous end-to-end
machine learning papers. Using the database of a large telehealth network, we
built a novel dataset with more than 2 million ECG tracings, orders of
magnitude larger than those used in previous studies. Moreover, our dataset is
more realistic, as it consist of 12-lead ECGs recorded during standard
in-clinics exams. Using this data, we trained a residual neural network with 9
convolutional layers to map 7 to 10 second ECG signals to 6 classes of ECG
abnormalities. Future work should extend these results to cover a large range
of ECG abnormalities, which could improve the accessibility of this diagnostic
tool and avoid wrong diagnosis from medical doctors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12208</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12208</id><created>2018-11-27</created><authors><author><keyname>Ma</keyname><forenames>Dabiao</forenames></author><author><keyname>Su</keyname><forenames>Zhiba</forenames></author><author><keyname>Lu</keyname><forenames>Yuhao</forenames></author><author><keyname>Wang</keyname><forenames>Wenxuan</forenames></author><author><keyname>Li</keyname><forenames>Zhen</forenames></author></authors><title>UFANS: U-shaped Fully-Parallel Acoustic Neural Structure For Statistical
  Parametric Speech Synthesis With 20X Faster</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural networks with Auto-regressive structures, such as Recurrent Neural
Networks (RNNs), have become the most appealing structures for acoustic
modeling of parametric text to speech synthesis (TTS) in ecent studies. Despite
the prominent capacity to capture long-term dependency, these models consist of
massive sequential computations that cannot be fully parallel. In this paper,
we propose a U-shaped Fully-parallel Acoustic Neural Structure (UFANS), which
is a deconvolutional alternative of RNNs for Statistical Parametric Speech
Synthesis (SPSS). The experiments verify that our proposed model is over 20
times faster than RNN based acoustic model, both training and inference on GPU
with comparable speech quality. Furthermore, We also investigate that how long
information dependence really matters to synthesized speech quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12211</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12211</id><created>2018-11-27</created><authors><author><keyname>Liu</keyname><forenames>Jiangyi</forenames></author><author><keyname>Wang</keyname><forenames>Chunping</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author></authors><title>Particle Probability Hypothesis Density Filter based on Pairwise Markov
  Chains</title><categories>eess.SP cs.AI cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most multi-target tracking filters assume that one target and its observation
follow a Hidden Markov Chain (HMC) model, but the implicit independence
assumption of HMC model is invalid in many practical applications, and a
Pairwise Markov Chain (PMC) model is more universally suitable than traditional
HMC model. A particle probability hypothesis density filter based on PMC model
(PF-PMC-PHD) is proposed for the nonlinear multi-target tracking system.
Simulation results show the effectiveness of PF-PMC-PHD filter, and that the
tracking performance of PF-PMC-PHD filter is superior to the particle PHD
filter based on HMC model in a scenario where we kept the local physical
properties of nonlinear and Gaussian HMC models while relaxing their
independence assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12214</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12214</id><created>2018-11-28</created><authors><author><keyname>Lu</keyname><forenames>Chien-Yu</forenames></author><author><keyname>Xue</keyname><forenames>Min-Xin</forenames></author><author><keyname>Chang</keyname><forenames>Chia-Che</forenames></author><author><keyname>Lee</keyname><forenames>Che-Rung</forenames></author><author><keyname>Su</keyname><forenames>Li</forenames></author></authors><title>Play as You Like: Timbre-enhanced Multi-modal Music Style Transfer</title><categories>cs.SD eess.AS</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Style transfer of polyphonic music recordings is a challenging task when
considering the modeling of diverse, imaginative, and reasonable music pieces
in the style different from their original one. To achieve this, learning
stable multi-modal representations for both domain-variant (i.e., style) and
domain-invariant (i.e., content) information of music in an unsupervised manner
is critical. In this paper, we propose an unsupervised music style transfer
method without the need for parallel data. Besides, to characterize the
multi-modal distribution of music pieces, we employ the Multi-modal
Unsupervised Image-to-Image Translation (MUNIT) framework in the proposed
system. This allows one to generate diverse outputs from the learned latent
distributions representing contents and styles. Moreover, to better capture the
granularity of sound, such as the perceptual dimensions of timbre and the
nuance in instrument-specific performance, cognitively plausible features
including mel-frequency cepstral coefficients (MFCC), spectral difference, and
spectral envelope, are combined with the widely-used mel-spectrogram into a
timber-enhanced multi-channel input representation. The Relativistic average
Generative Adversarial Networks (RaGAN) is also utilized to achieve fast
convergence and high stability. We conduct experiments on bilateral style
transfer tasks among three different genres, namely piano solo, guitar solo,
and string quartet. Results demonstrate the advantages of the proposed method
in music style transfer with improved sound quality and in allowing users to
manipulate the output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12215</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12215</id><created>2018-11-28</created><authors><author><keyname>Zhang</keyname><forenames>Qi</forenames></author><author><keyname>Zhu</keyname><forenames>Jiang</forenames></author><author><keyname>Gerstoft</keyname><forenames>Peter</forenames></author><author><keyname>Badiu</keyname><forenames>Mihai-Alin</forenames></author><author><keyname>Xu</keyname><forenames>Zhiwei</forenames></author></authors><title>Gridless Line Spectral Estimation with Multiple Measurement Vector via
  Variational Bayesian Inference</title><categories>eess.SP</categories><comments>5 pages. arXiv admin note: substantial text overlap with
  arXiv:1803.06497</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Line spectral estimation (LSE) from multi snapshot samples is studied
utilizing the variational Bayesian methods. Motivated by the recently proposed
variational line spectral estimation (VALSE) method for a single snapshot, we
develop the multisnapshot VALSE (MVALSE) for multi snapshot scenarios, which is
important for array processing. The MVALSE shares the advantages of the VALSE
method, such as automatically estimating the model order, noise variance and
weight variance, closed-form updates of the posterior probability density
function (PDF) of the frequencies. By using multiple snapshots, MVALSE improves
the recovery performance and it encodes the prior distribution naturally.
Finally, numerical results demonstrate the competitive performance of the
MVALSE compared to state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12220</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12220</id><created>2018-11-29</created><authors><author><keyname>Churchill</keyname><forenames>Victor</forenames></author><author><keyname>Gelb</keyname><forenames>Anne</forenames></author></authors><title>Detecting edges from non-uniform Fourier data via sparse Bayesian
  learning</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent investigations, the problem of detecting edges given non-uniform
Fourier data was reformulated as a sparse signal recovery problem with an
l1-regularized least squares cost function. This result can also be derived by
employing a Bayesian formulation. Specifically, reconstruction of an edge map
using l1 regularization corresponds to a so-called type-I (maximum a
posteriori) Bayesian estimate. In this paper, we use the Bayesian framework to
design an improved algorithm for detecting edges from non-uniform Fourier data.
In particular, we employ what is known as type-II Bayesian estimation,
specifically a method called sparse Bayesian learning. We also show that our
new edge detection method can be used to improve downstream processes that rely
on accurate edge information like image reconstruction, especially with regards
to compressed sensing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12224</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12224</id><created>2018-11-29</created><authors><author><keyname>Sattiraju</keyname><forenames>Raja</forenames></author><author><keyname>Siemons</keyname><forenames>Jasper</forenames></author><author><keyname>Soliman</keyname><forenames>Mohammad</forenames></author><author><keyname>Alshrafi</keyname><forenames>Wasim</forenames></author><author><keyname>Rein</keyname><forenames>Fabian</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Design of a Highly Reliable Wireless Module for Ultra-Low-Latency Short
  Range Applications</title><categories>eess.SP</categories><comments>Published in IEEE WFCS 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current radio systems are currently optimized for capacity and range.
However, certain applications of wireless systems require fast and reliable
communication over short distances. The challenge of these systems is to
communicate with a minimum time delay (latency) while at the same time being
very reliable and resilient to interference. This paper describes the concept
and the proposed abstract architecture of a wireless technology that allows
highly reliable and ultra low latency transmission of data between moving units
over a few meters, the applications of which can be found in multitude of
domains such as Train Communicaion Networks (TCNs), Truck/Tractor - Trailer
Communication, Platooning, and in smart industry in the form of co-ordinating
machines. The paper also describes the set of novelties that were planned to be
realized as part of the final demo hardware
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12228</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12228</id><created>2018-11-29</created><authors><author><keyname>Sattiraju</keyname><forenames>Raja</forenames></author><author><keyname>Kochems</keyname><forenames>Jacob</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Machine Learning Based Obstacle Detection for Automatic Train Pairing</title><categories>eess.SP</categories><comments>Published in IEEE WFCS 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short Range wireless devices are becoming more and more popular for
ubiquitous sensor and actuator connectivity in industrial communication
scenarios. Apart from communication-only scenarios, there are also
mission-critical use cases where the distance between the two communicating
nodes needs to be determined precisely. Applications such as Automatic Guided
Vehicles (AGV's), Automatic Train Pairing additionally require the devices to
scan the environment and detect any potential humans/obstacles. Ultra-Wide Band
(UWB) has emerged as a promising candidate for Real-Time Ranging and
Localization (RTRL) due to advantages such as large channel capacity, better
co-existence with legacy systems due to low transmit power, better performance
in multipath environments etc. In this paper, we evaluate the performance of a
UWB COTS device - TimeDomain P440 which can operate as a ranging radio and a
monostatic radar simultaneously. To this end, we evaluate the possibility of
using Supervised Learning based estimators for predicting the presence of
obstacles by constructing a multiclass hypothesis. Simulation results show that
the Ensemble tree based methods are able to calculate the likelihood of
obstacle collision with accuracies close to 95%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12254</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12254</id><created>2018-11-29</created><authors><author><keyname>Balagopalan</keyname><forenames>Aparna</forenames></author><author><keyname>Novikova</keyname><forenames>Jekaterina</forenames></author><author><keyname>Rudzicz</keyname><forenames>Frank</forenames></author><author><keyname>Ghassemi</keyname><forenames>Marzyeh</forenames></author></authors><title>The Effect of Heterogeneous Data for Alzheimer's Disease Detection from
  Speech</title><categories>cs.LG cs.CL cs.SD eess.AS stat.ML</categories><comments>Machine Learning for Health (ML4H) Workshop at NeurIPS 2018
  arXiv:1811.07216</comments><report-no>ML4H/2018/147</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech datasets for identifying Alzheimer's disease (AD) are generally
restricted to participants performing a single task, e.g. describing an image
shown to them. As a result, models trained on linguistic features derived from
such datasets may not be generalizable across tasks. Building on prior work
demonstrating that same-task data of healthy participants helps improve AD
detection on a single-task dataset of pathological speech, we augment an
AD-specific dataset consisting of subjects describing a picture with multi-task
healthy data. We demonstrate that normative data from multiple speech-based
tasks helps improve AD detection by up to 9%. Visualization of decision
boundaries reveals that models trained on a combination of structured picture
descriptions and unstructured conversational speech have the least out-of-task
error and show the most potential to generalize to multiple tasks. We analyze
the impact of age of the added samples and if they affect fairness in
classification. We also provide explanations for a possible inductive bias
effect across tasks using model-agnostic feature anchors. This work highlights
the need for heterogeneous datasets for encoding changes in multiple facets of
cognition and for developing a task-independent AD detection model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12271</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12271</id><created>2018-11-29</created><authors><author><keyname>Sattiraju</keyname><forenames>Raja</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Reliability Modeling, Analysis and Prediction of Wireless Mobile
  Communications</title><categories>eess.SP</categories><comments>Published in IEEE 79 VTC Spring, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The future Fifth Generation (5G) mobile cellular networks that are currently
in research phase today enable broad range of services/applications beyond
classical mobile communications. One key enabler for Ultra-Reliable services to
be integrated into mobile networks is the \textit{Reliability} of transmission
success of a given data packet. This is harder mainly owing to the
time-dependent effective link qualities of the communicating devices. However,
successful indication of the availability of the instantaneous link quality
(e.g., by the device) would allow opportunistic access of ultra reliable
services/applications when the link conditions are fair enough. This paper
introduces a framework for modeling, predicting and analyzing the theoretical
reliability of the wireless link based on factors such as fading, mobility,
interference etc. The analysis and prediction is based on the part stress
method\cite{Birolini2010} by assuming time dependent factors as
elements/components and their respective Transmission Times To Failure (TTTF).
The proposed framework also supports other reliability analysis techniques such
as Fault Tree Analysis and Accelerated testing. of wireless systems and to
improve the components
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12281</identifier>
 <datestamp>2018-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12281</id><created>2018-11-29</created><authors><author><keyname>Xia</keyname><forenames>Yuxuan</forenames></author><author><keyname>Granstr&#xf6;m</keyname><forenames>Karl</forenames></author><author><keyname>Svensson</keyname><forenames>Lennart</forenames></author><author><keyname>Garc&#xed;a-Fern&#xe1;ndez</keyname><forenames>&#xc1;ngel F.</forenames></author></authors><title>An Implementation of the Poisson Multi-Bernoulli Mixture Trajectory
  Filter via Dual Decomposition</title><categories>eess.SP</categories><comments>8 pages, 2018 21st International Conference on Information Fusion
  (FUSION)</comments><doi>10.23919/ICIF.2018.8455236</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an efficient implementation of the Poisson
multi-Bernoulli mixture (PMBM) trajectory filter. The proposed implementation
performs track-oriented N-scan pruning to limit complexity, and uses dual
decomposition to solve the involved multi-frame assignment problem. In contrast
to the existing PMBM filter for sets of targets, the PMBM trajectory filter is
based on sets of trajectories which ensures that track continuity is formally
maintained. The resulting filter is an efficient and scalable approximation to
a Bayes optimal multi-target tracking algorithm, and its performance is
compared, in a simulation study, to the PMBM target filter, and the delta
generalized labelled multi-Bernoulli filter, in terms of state/trajectory
estimation error and computational time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12290</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12290</id><created>2018-11-29</created><updated>2019-02-17</updated><authors><author><keyname>Wan</keyname><forenames>Li</forenames></author><author><keyname>Sridhar</keyname><forenames>Prashant</forenames></author><author><keyname>Yu</keyname><forenames>Yang</forenames></author><author><keyname>Wang</keyname><forenames>Quan</forenames></author><author><keyname>Moreno</keyname><forenames>Ignacio Lopez</forenames></author></authors><title>Tuplemax Loss for Language Identification</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Submitted to ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many scenarios of a language identification task, the user will specify a
small set of languages which he/she can speak instead of a large set of all
possible languages. We want to model such prior knowledge into the way we train
our neural networks, by replacing the commonly used softmax loss function with
a novel loss function named tuplemax loss. As a matter of fact, a typical
language identification system launched in North America has about 95% users
who could speak no more than two languages. Using the tuplemax loss, our system
achieved a 2.33% error rate, which is a relative 39.4% improvement over the
3.85% error rate of standard softmax loss method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12345</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12345</id><created>2018-11-29</created><updated>2018-11-30</updated><authors><author><keyname>Chen</keyname><forenames>Jia</forenames></author><author><keyname>Wang</keyname><forenames>Gang</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Graph Multiview Canonical Correlation Analysis</title><categories>eess.SP cs.LG stat.ME</categories><doi>10.1109/TSP.2019.2910475</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiview canonical correlation analysis (MCCA) seeks latent low-dimensional
representations encountered with multiview data of shared entities (a.k.a.
common sources). However, existing MCCA approaches do not exploit the geometry
of the common sources, which may be available \emph{a priori}, or can be
constructed using certain domain knowledge. This prior information about the
common sources can be encoded by a graph, and be invoked as a regularizer to
enrich the maximum variance MCCA framework. In this context, the present
paper's novel graph-regularized (G) MCCA approach minimizes the distance
between the wanted canonical variables and the common low-dimensional
representations, while accounting for graph-induced knowledge of the common
sources. Relying on a function capturing the extent low-dimensional
representations of the multiple views are similar, a generalization bound of
GMCCA is established based on Rademacher's complexity. Tailored for setups
where the number of data pairs is smaller than the data vector dimensions, a
graph-regularized dual MCCA approach is also developed. To further deal with
nonlinearities present in the data, graph-regularized kernel MCCA variants are
put forward too. Interestingly, solutions of the graph-regularized linear,
dual, and kernel MCCA, are all provided in terms of generalized eigenvalue
decomposition. Several corroborating numerical tests using real datasets are
provided to showcase the merits of the graph-regularized MCCA variants relative
to several competing alternatives including MCCA, Laplacian-regularized MCCA,
and (graph-regularized) PCA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12408</identifier>
 <datestamp>2018-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12408</id><created>2018-11-29</created><authors><author><keyname>Chuan</keyname><forenames>Ching-Hua</forenames></author><author><keyname>Agres</keyname><forenames>Kat</forenames></author><author><keyname>Herremans</keyname><forenames>Dorien</forenames></author></authors><title>From Context to Concept: Exploring Semantic Relationships in Music with
  Word2Vec</title><categories>cs.SD cs.IR cs.LG eess.AS stat.ML</categories><comments>Accepted for publication in Neural Computing and Applications,
  Springer. In Press</comments><proxy>Dorien Herremans</proxy><msc-class>68Txx, 68Wxx</msc-class><journal-ref>Neural Computing and Applications, Springer. 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the potential of a popular distributional semantics vector space
model, word2vec, for capturing meaningful relationships in ecological (complex
polyphonic) music. More precisely, the skip-gram version of word2vec is used to
model slices of music from a large corpus spanning eight musical genres. In
this newly learned vector space, a metric based on cosine distance is able to
distinguish between functional chord relationships, as well as harmonic
associations in the music. Evidence, based on cosine distance between
chord-pair vectors, suggests that an implicit circle-of-fifths exists in the
vector space. In addition, a comparison between pieces in different keys
reveals that key relationships are represented in word2vec space. These results
suggest that the newly learned embedded vector representation does in fact
capture tonal and harmonic characteristics of music, without receiving explicit
information about the musical content of the constituent slices. In order to
investigate whether proximity in the discovered space of embeddings is
indicative of `semantically-related' slices, we explore a music generation
task, by automatically replacing existing slices from a given piece of music
with new slices. We propose an algorithm to find substitute slices based on
spatial proximity and the pitch class distribution inferred in the chosen
subspace. The results indicate that the size of the subspace used has a
significant effect on whether slices belonging to the same key are selected. In
sum, the proposed word2vec model is able to learn music-vector embeddings that
capture meaningful tonal and harmonic relationships in music, thereby providing
a useful tool for exploring musical properties and comparisons across pieces,
as a potential input representation for deep learning models, and as a music
generation device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12445</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12445</id><created>2018-11-29</created><updated>2019-07-25</updated><authors><author><keyname>Dulek</keyname><forenames>Berkan</forenames></author><author><keyname>Ozturk</keyname><forenames>Cuneyd</forenames></author><author><keyname>Gezici</keyname><forenames>Sinan</forenames></author></authors><title>Optimal Decision Rules for Simple Hypothesis Testing under General
  Criterion Involving Error Probabilities</title><categories>eess.SP</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of simple $M-$ary hypothesis testing under a generic performance
criterion that depends on arbitrary functions of error probabilities is
considered. Using results from convex analysis, it is proved that an optimal
decision rule can be characterized as a randomization among at most two
deterministic decision rules, of the form reminiscent to Bayes rule, if the
boundary points corresponding to each rule have zero probability under each
hypothesis. Otherwise, a randomization among at most $M(M-1)+1$ deterministic
decision rules is sufficient. The form of the deterministic decision rules are
explicitly specified. Likelihood ratios are shown to be sufficient statistics.
Classical performance measures including Bayesian, minimax, Neyman-Pearson,
generalized Neyman-Pearson, restricted Bayesian, and prospect theory based
approaches are all covered under the proposed formulation. A numerical example
is presented for prospect theory based binary hypothesis testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12452</identifier>
 <datestamp>2019-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12452</id><created>2018-11-29</created><updated>2019-01-29</updated><authors><author><keyname>Malik</keyname><forenames>Rafia</forenames></author><author><keyname>Vu</keyname><forenames>Mai</forenames></author></authors><title>Optimal Transmission Using a Self-sustained Relay in a Full-Duplex MIMO
  System</title><categories>eess.SP</categories><journal-ref>IEEE Journal on Selected Areas in Communications, vol. 37, no. 2,
  pp. 374-390, Feb. 2019</journal-ref><doi>10.1109/JSAC.2018.2872617</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates wireless information and power transfer in a
full-duplex MIMO relay channel where the self-sustained relay harvests energy
from both source transmit signal and self-interference signal to decode and
forward source information to a destination. We present a novel technique to
jointly optimize power splitting at the relay and precoding design (power
allocation) for both the source and relay transmissions. We formulate a new
convex optimization problem, establish the dual problem via closed-form optimal
primal solutions, and design an efficient primal-dual algorithm to maximize the
achievable throughput. Numerical results demonstrate the benefits of using
multiple transmit and receive antennas in both information decoding and energy
harvesting. We also extend our analysis to the case when channel state
information is only available at receiving nodes and show how our algorithm can
optimize the power splitting at the relay for it to remain self-sustained.
Through analysis and simulation, we show how an optimal combination of
non-uniform power splitting, variable power allocation, and self-interference
power harvesting effectively exploits a full-duplex MIMO system to achieve
significant performance gains over existing uniform power splitting and
half-duplex transmission techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12467</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12467</id><created>2018-11-29</created><updated>2019-02-07</updated><authors><author><keyname>Amin</keyname><forenames>Moeness G.</forenames></author><author><keyname>Zeng</keyname><forenames>Zhengxin</forenames></author><author><keyname>Shan</keyname><forenames>Tao</forenames></author></authors><title>Hand Gesture Recognition based on Radar Micro-Doppler Signature
  Envelopes</title><categories>eess.SP</categories><comments>6 pages, 7 figures, 2019 radar conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a simple but effective technique in automatic hand gesture
recognition using radar. The proposed technique classifies hand gestures based
on the envelopes of their micro-Doppler signatures. These envelopes capture the
distinctions among different hand movements and their corresponding positive
and negative Doppler frequencies which are generated during each gesture act.
We detect the positive and negative envelopes separately, and form a feature
vector of their augmentation. We use the $k$-nearest neighbor ($k$NN)
classifier and Manhattan distance (L1) measure, in lieu of Euclidean distance
(L2), so as not to diminish small but critical envelope values. It is shown
that this method outperforms both low-dimension representation techniques based
on principal component analysis (PCA) and sparse reconstruction using
Gaussian-windowed Fourier dictionary, and can achieve very high classification
rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12495</identifier>
 <datestamp>2019-04-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12495</id><created>2018-11-29</created><updated>2019-04-05</updated><authors><author><keyname>Mehta</keyname><forenames>Dushyant</forenames></author><author><keyname>Kim</keyname><forenames>Kwang In</forenames></author><author><keyname>Theobalt</keyname><forenames>Christian</forenames></author></authors><title>On Implicit Filter Level Sparsity in Convolutional Neural Networks</title><categories>cs.LG cs.CV eess.SP stat.ML</categories><comments>Accepted at CVPR 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate filter level sparsity that emerges in convolutional neural
networks (CNNs) which employ Batch Normalization and ReLU activation, and are
trained with adaptive gradient descent techniques and L2 regularization or
weight decay. We conduct an extensive experimental study casting our initial
findings into hypotheses and conclusions about the mechanisms underlying the
emergent filter level sparsity. This study allows new insight into the
performance gap obeserved between adapative and non-adaptive gradient descent
methods in practice. Further, analysis of the effect of training strategies and
hyperparameters on the sparsity leads to practical suggestions in designing CNN
training strategies enabling us to explore the tradeoffs between feature
selectivity, network capacity, and generalization performance. Lastly, we show
that the implicit sparsity can be harnessed for neural network speedup at par
or better than explicit sparsification / pruning approaches, with no
modifications to the typical training pipeline required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12539</identifier>
 <datestamp>2019-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12539</id><created>2018-11-29</created><updated>2019-04-15</updated><authors><author><keyname>Duan</keyname><forenames>Jiajun</forenames></author><author><keyname>Yi</keyname><forenames>Zhehan</forenames></author><author><keyname>Shi</keyname><forenames>Di</forenames></author><author><keyname>Xu</keyname><forenames>Hao</forenames></author><author><keyname>Wang</keyname><forenames>Zhiwei</forenames></author></authors><title>A Neural-Network-Based Optimal Control of Ultra-Capacitors with System
  Uncertainties</title><categories>math.OC cs.LG eess.SP</categories><comments>IEEE ISGT NA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a neural-network (NN)-based online optimal control method
(NN-OPT) is proposed for ultra-capacitors (UCs) energy storage system (ESS) in
hybrid AC/DC microgrids involving multiple distributed generations (e.g.,
Photovoltaic (PV) system, battery storage, diesel generator). Conventional
control strategies usually produce large disturbances to buses during charging
and discharging (C&amp;D) processes of UCs, which significantly degrades the power
quality and system performance, especially under fast C&amp;D modes. Therefore, the
optimal control theory is adopted to optimize the C&amp;D profile as well as to
suppress the disturbances caused by UCs implementation. Specifically, an
NN-based intelligent algorithm is developed to learn the optimal control policy
for bidirectional-converter-interfaced UCs. The inaccuracies of system modeling
are also considered in the control design. Since the designed NN-OPT method is
decentralized that only requires the local measurements, plug &amp; play of UCs can
be easily realized with minimal communication efforts. In addition, the PV
system is under the maximum power point tracking (MPPT) control to extract the
maximum benefit. Both islanded and grid-tied modes are considered during the
controller design. Extensive case studies have been conducted to evaluate the
effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12541</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12541</id><created>2018-11-29</created><updated>2018-12-06</updated><authors><author><keyname>Cui</keyname><forenames>Yao</forenames></author><author><keyname>Yi</keyname><forenames>Zhehan</forenames></author><author><keyname>Duan</keyname><forenames>Jiajun</forenames></author><author><keyname>Shi</keyname><forenames>Di</forenames></author><author><keyname>Wang</keyname><forenames>Zhiwei</forenames></author></authors><title>A Rprop-Neural-Network-Based PV Maximum Power Point Tracking Algorithm
  with Short-Circuit Current Limitation</title><categories>eess.SP cs.LG math.OC</categories><comments>2019 IEEE ISGT NA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a resilient-backpropagation-neural-network-(Rprop-NN)
based algorithm for Photovoltaic (PV) maximum power point tracking (MPPT). A
supervision mechanism is proposed to calibrate the Rprop-NN-MPPT reference and
limit short-circuit current caused by incorrect prediction. Conventional MPPT
algorithms (e.g., perturb and observe (P&amp;O), hill climbing, and incremental
conductance (Inc-Cond) etc.) are trial-and-error-based, which may result in
steady-state oscillations and loss of tracking direction under fast-changing
ambient environment. In addition, partial shading is also a challenge due to
the difficulty of finding the global maximum power point on a multi-peak
characteristic curve. As an attempt to address the aforementioned issues, a
novel Rprop-NN MPPT algorithm is developed and elaborated in this work.
Multiple case studies are carried out to verify the effectiveness of the
proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12542</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12542</id><created>2018-11-29</created><updated>2019-05-23</updated><authors><author><keyname>Parada-Mayorga</keyname><forenames>Alejandro</forenames></author><author><keyname>Lau</keyname><forenames>Daniel L.</forenames></author><author><keyname>Giraldo</keyname><forenames>Jhony H.</forenames></author><author><keyname>Arce</keyname><forenames>Gonzalo R.</forenames></author></authors><title>Blue-Noise Sampling on Graphs</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the area of graph signal processing, a graph is a set of nodes arbitrarily
connected by weighted links; a graph signal is a set of scalar values
associated with each node; and sampling is the problem of selecting an optimal
subset of nodes from which a graph signal can be reconstructed. This paper
proposes the use of spatial dithering on the vertex domain of the graph, as a
way to conveniently find statistically good sampling sets. This is done
establishing that there is a family of good sampling sets characterized on the
vertex domain by a maximization of the distance between sampling nodes; in the
Fourier domain, these are characterized by spectrums that are dominated by high
frequencies referred to as blue-noise. The theoretical connection between
blue-noise sampling on graphs and previous results in graph signal processing
is also established, explaining the advantages of the proposed approach.
Restricting our analysis to undirected and connected graphs, numerical tests
are performed in order to compare the effectiveness of blue-noise sampling
against other approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12635</identifier>
 <datestamp>2018-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12635</id><created>2018-11-30</created><authors><author><keyname>Huang</keyname><forenames>Yongwei</forenames></author><author><keyname>Zhou</keyname><forenames>Longtao</forenames></author></authors><title>MISO NOMA Downlink Beamforming Optimization with Per-Antenna Power
  Constraints</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a multiuser downlink beamforming optimization problem for the
non-orthogonal multiple access (NOMA) transmission in a multiple-input
single-output (MISO) system. The total transmission power minimization problem
is formulated subject to both per-antenna power constraints and
quality-of-service (QoS) constraints under the NOMA principal. The problem is a
non-convex quadratically constrained quadratic program, and the conventional
semidefinite program (SDP) relaxation is not tight. In order to tackle the
non-convex NOMA beamforming problem, we construct a second-order cone
approximation for each signal-to-interference-plus-noise ratio (SINR)
constraint and form an iterative algorithm, in which a sequence of second-order
cone programs (SOCPs) are solved. The optimal values of the sequence of SOCPs
are non-increasing, and it converges to a locally optimal value. However, our
extensive simulation results show that the locally optimal value is more or
less as good as the globally optimal value. In particular, we show that the SDP
relaxation is tight for two-user case if one of the SINR constraints is strict
(non-binding) at the optimality. Detailed simulation results are presented to
demonstrate the performance gains of the NOMA downlink beamforming with
per-antenna power constraints through the proposed approximate algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12637</identifier>
 <datestamp>2018-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12637</id><created>2018-11-30</created><authors><author><keyname>Ahmed</keyname><forenames>Umair</forenames></author><author><keyname>Khalid</keyname><forenames>Zubair</forenames></author></authors><title>Sampling Schemes for Accurate Reconstruction and Computation of
  Performance Parameters of Antenna Radiation Pattern</title><categories>eess.SP</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In practice, the finite number of samples of the spherical radiation pattern
or antenna gain are taken on the sphere for both the reconstruction of the
antenna radiation pattern and the computation of mobile handset performance
measures such as directivity and mean effective gain (MEG). The acquisition of
samples is time consuming as the measurements are required to be collected over
the range of frequencies and in multiple spatial directions. It is therefore
desired to have a sampling strategy that takes fewer number of samples for the
accurate reconstruction of radiation pattern and incoming signal power
distribution. In this work, we propose to use equiangular sampling,
Gauss-Legendre sampling and optimal dimensionality sampling schemes on the
sphere for the acquisition of measurements of spherical radiation pattern of
the antenna for its reconstruction, analysis and evaluation of performance
parameters of the antenna. By appropriately choosing the spherical harmonic
degree band-limits of the gain and the power distribution model of the incoming
signal, we demonstrate that the proposed sampling strategies require
significantly less number of samples for the accurate evaluation of MEG than
the existing methods that rely on the approximate evaluation of the surface
integral on the sphere.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12707</identifier>
 <datestamp>2018-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12707</id><created>2018-11-30</created><authors><author><keyname>Jiang</keyname><forenames>Yihan</forenames></author><author><keyname>Kim</keyname><forenames>Hyeji</forenames></author><author><keyname>Asnani</keyname><forenames>Himanshu</forenames></author><author><keyname>Kannan</keyname><forenames>Sreeram</forenames></author><author><keyname>Oh</keyname><forenames>Sewoong</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>LEARN Codes: Inventing Low-latency Codes via Recurrent Neural Networks</title><categories>eess.SP cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing channel codes under low latency constraints is one of the most
demanding requirements in 5G standards. However, sharp characterizations of the
performances of traditional codes are only available in the large block-length
limit. Code designs are guided by those asymptotic analyses and require large
block lengths and long latency to achieve the desired error rate. Furthermore,
when the codes designed for one channel (e.g. Additive White Gaussian Noise
(AWGN) channel) are used for another (e.g. non-AWGN channels), heuristics are
necessary to achieve any nontrivial performance -thereby severely lacking in
robustness as well as adaptivity.
  Obtained by jointly designing Recurrent Neural Network (RNN) based encoder
and decoder, we propose an end-to-end learned neural code which outperforms
canonical convolutional code under block settings. With this gained experience
of designing a novel neural block code, we propose a new class of codes under
low latency constraint - Low-latency Efficient Adaptive Robust Neural (LEARN)
codes, which outperforms the state-of-the-art low latency codes as well as
exhibits robustness and adaptivity properties. LEARN codes show the potential
of designing new versatile and universal codes for future communications via
tools of modern deep learning coupled with communication engineering insights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12739</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12739</id><created>2018-11-30</created><updated>2019-05-16</updated><authors><author><keyname>Halperin</keyname><forenames>Tavi</forenames></author><author><keyname>Ephrat</keyname><forenames>Ariel</forenames></author><author><keyname>Hoshen</keyname><forenames>Yedid</forenames></author></authors><title>Neural separation of observed and unobserved distributions</title><categories>cs.LG cs.CL eess.AS stat.ML</categories><comments>ICML'19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Separating mixed distributions is a long standing challenge for machine
learning and signal processing. Most current methods either rely on making
strong assumptions on the source distributions or rely on having training
samples of each source in the mixture. In this work, we introduce a new
method---Neural Egg Separation---to tackle the scenario of extracting a signal
from an unobserved distribution additively mixed with a signal from an observed
distribution. Our method iteratively learns to separate the known distribution
from progressively finer estimates of the unknown distribution. In some
settings, Neural Egg Separation is initialization sensitive, we therefore
introduce Latent Mixture Masking which ensures a good initialization. Extensive
experiments on audio and image separation tasks show that our method
outperforms current methods that use the same level of supervision, and often
achieves similar performance to full supervision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12802</identifier>
 <datestamp>2018-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12802</id><created>2018-11-28</created><authors><author><keyname>Wu</keyname><forenames>Qiuyi</forenames></author><author><keyname>Fokoue</keyname><forenames>Ernest</forenames></author></authors><title>Naive Dictionary On Musical Corpora: From Knowledge Representation To
  Pattern Recognition</title><categories>cs.IR cs.LG cs.SD eess.AS stat.ML</categories><comments>25 pages</comments><msc-class>62P15, 62P25, 62P99, 68W40, 68W01, 91E10, 91E45, 82-08, 62-07</msc-class><acm-class>E.2; F.1.1; F.2.0; I.1.3; I.1.4; I.2.4; I.2.1; I.2.6; I.5.5; I.7.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose and develop the novel idea of treating musical
sheets as literary documents in the traditional text analytics parlance, to
fully benefit from the vast amount of research already existing in statistical
text mining and topic modelling. We specifically introduce the idea of
representing any given piece of music as a collection of &quot;musical words&quot; that
we codenamed &quot;muselets&quot;, which are essentially musical words of various
lengths. Given the novelty and therefore the extremely difficulty of properly
forming a complete version of a dictionary of muselets, the present paper
focuses on a simpler albeit naive version of the ultimate dictionary, which we
refer to as a Naive Dictionary because of the fact that all the words are of
the same length. We specifically herein construct a naive dictionary featuring
a corpus made up of African American, Chinese, Japanese and Arabic music, on
which we perform both topic modelling and pattern recognition. Although some of
the results based on the Naive Dictionary are reasonably good, we anticipate
phenomenal predictive performances once we get around to actually building a
full scale complete version of our intended dictionary of muselets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12804</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12804</id><created>2018-11-30</created><updated>2020-02-23</updated><authors><author><keyname>Chen</keyname><forenames>Yuxin</forenames></author><author><keyname>Cheng</keyname><forenames>Chen</forenames></author><author><keyname>Fan</keyname><forenames>Jianqing</forenames></author></authors><title>Asymmetry Helps: Eigenvalue and Eigenvector Analyses of Asymmetrically
  Perturbed Low-Rank Matrices</title><categories>math.ST cs.IT cs.NA eess.SP math.IT math.NA stat.ML stat.TH</categories><comments>accepted to Annals of Statistics, 2020. 37 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the interplay between statistical asymmetry and
spectral methods. Suppose we are interested in estimating a rank-1 and
symmetric matrix $\mathbf{M}^{\star}\in \mathbb{R}^{n\times n}$, yet only a
randomly perturbed version $\mathbf{M}$ is observed. The noise matrix
$\mathbf{M}-\mathbf{M}^{\star}$ is composed of zero-mean independent (but not
necessarily homoscedastic) entries and is, therefore, not symmetric in general.
This might arise, for example, when we have two independent samples for each
entry of $\mathbf{M}^{\star}$ and arrange them into an {\em asymmetric} data
matrix $\mathbf{M}$. The aim is to estimate the leading eigenvalue and
eigenvector of $\mathbf{M}^{\star}$. We demonstrate that the leading eigenvalue
of the data matrix $\mathbf{M}$ can be $O(\sqrt{n})$ times more accurate --- up
to some log factor --- than its (unadjusted) leading singular value in
eigenvalue estimation. Further, the perturbation of any linear form of the
leading eigenvector of $\mathbf{M}$ --- say, entrywise eigenvector perturbation
--- is provably well-controlled. This eigen-decomposition approach is fully
adaptive to heteroscedasticity of noise without the need of careful bias
correction or any prior knowledge about the noise variance. We also provide
partial theory for the more general rank-$r$ case. The takeaway message is
this: arranging the data samples in an asymmetric manner and performing
eigen-decomposition could sometimes be beneficial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12817</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12817</id><created>2018-11-30</created><updated>2019-05-27</updated><authors><author><keyname>Mentzer</keyname><forenames>Fabian</forenames></author><author><keyname>Agustsson</keyname><forenames>Eirikur</forenames></author><author><keyname>Tschannen</keyname><forenames>Michael</forenames></author><author><keyname>Timofte</keyname><forenames>Radu</forenames></author><author><keyname>Van Gool</keyname><forenames>Luc</forenames></author></authors><title>Practical Full Resolution Learned Lossless Image Compression</title><categories>cs.CV cs.LG eess.IV</categories><comments>CVPR'19 camera-ready version. Code and models:
  https://github.com/fab-jul/L3C-PyTorch</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the first practical learned lossless image compression system,
L3C, and show that it outperforms the popular engineered codecs, PNG, WebP and
JPEG 2000. At the core of our method is a fully parallelizable hierarchical
probabilistic model for adaptive entropy coding which is optimized end-to-end
for the compression task. In contrast to recent autoregressive discrete
probabilistic models such as PixelCNN, our method i) models the image
distribution jointly with learned auxiliary representations instead of
exclusively modeling the image distribution in RGB space, and ii) only requires
three forward-passes to predict all pixel probabilities instead of one for each
pixel. As a result, L3C obtains over two orders of magnitude speedups when
sampling compared to the fastest PixelCNN variant (Multiscale-PixelCNN).
Furthermore, we find that learning the auxiliary representation is crucial and
outperforms predefined auxiliary representations such as an RGB pyramid
significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12911</identifier>
 <datestamp>2018-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12911</id><created>2018-11-07</created><authors><author><keyname>Shafiei</keyname><forenames>Mehdi</forenames></author><author><keyname>Liu</keyname><forenames>Aaron</forenames></author><author><keyname>Ledwich</keyname><forenames>Gerard</forenames></author><author><keyname>Walker</keyname><forenames>Geoffery</forenames></author><author><keyname>Morosini</keyname><forenames>Gian-Marco</forenames></author><author><keyname>Terry</keyname><forenames>Jack</forenames></author></authors><title>Solar Enablement Initiative in Australia: Report on Efficiently
  Identifying Critical Cases for Evaluating the Voltage Impact of Large PV
  Investment</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing quantity of PV generation connected to distribution networks
is creating challenges in maintaining and controlling voltages in those
distribution networks. Determining the maximum hosting capacity for new PV
installations based on the historical data is an essential task for
distribution networks. Analyzing all historical data in large distribution
networks is impractical. Therefore, this paper focuses on how to time
efficiently identify the critical cases for evaluating the voltage impacts of
the new large PV applications in medium voltage (MV) distribution networks. A
systematic approach is proposed to cluster medium voltage nodes based on
electrical adjacency and time blocks. MV nodes are clustered along with the
voltage magnitudes and time blocks. Critical cases of each cluster can be used
for further power flow study. This method is scalable and can time efficiently
identify cases for evaluating PV investment on medium voltage networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.12914</identifier>
 <datestamp>2018-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1811.12914</id><created>2018-11-28</created><updated>2018-12-03</updated><authors><author><keyname>Uddin</keyname><forenames>Mohammed Belal</forenames></author><author><keyname>Kader</keyname><forenames>Md. Fazlul</forenames></author><author><keyname>Shin</keyname><forenames>Soo Young</forenames></author></authors><title>Device-to-Device Communication Facilitating Full-Duplex Cooperative
  Relaying Using Non-Orthogonal Multiple Access</title><categories>eess.SP</categories><comments>4 pages, 3 figures, Journal Paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter presents a device-to-device (D2D) enabling cellular full-duplex
(FD) cooperative protocol using non-orthogonal multiple access (NOMA), where an
FD relay assists in relaying NOMA far user's signal and transmits a D2D
receiver's signal simultaneously. The ergodic capacity, outage probability, and
diversity order of the proposed protocol are theoretically investigated under
the realistic assumption of imperfect self and known interference cancellation.
The Outcome of the investigation demonstrates the performance gain of the
suggested protocol over conventional FD cooperative NOMA system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00023</identifier>
 <datestamp>2018-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00023</id><created>2018-11-30</created><authors><author><keyname>Huang</keyname><forenames>Qisheng</forenames></author><author><keyname>Zhao</keyname><forenames>Chunming</forenames></author><author><keyname>Jiang</keyname><forenames>Ming</forenames></author><author><keyname>Li</keyname><forenames>Xiaoming</forenames></author><author><keyname>Liang</keyname><forenames>Jing</forenames></author></authors><title>Cascade-Net: a New Deep Learning Architecture for OFDM Detection</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages,5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider using deep neural network for OFDM symbol
detection and demonstrate its performance advantages in combating large Doppler
Shift. In particular, a new architecture named Cascade-Net is proposed for
detection, where deep neural network is cascading with a zero-forcing
preprocessor to prevent the network stucking in a saddle point or a local
minimum point. In addition, we propose a sliding detection approach in order to
detect OFDM symbols with large number of subcarriers. We evaluate this new
architecture, as well as the sliding algorithm, using the Rayleigh channel with
large Doppler spread, which could degrade detection performance in an OFDM
system and is especially severe for high frequency band and mmWave
communications. The numerical results of OFDM detection in SISO scenario show
that cascade-net can achieve better performance than zero-forcing method while
providing robustness against ill conditioned channels. We also show the better
performance of the sliding cascade network (SCN) compared to sliding
zero-forcing detector through numerical simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00070</identifier>
 <datestamp>2018-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00070</id><created>2018-11-30</created><authors><author><keyname>Jovicic</keyname><forenames>Aleksandar</forenames></author><author><keyname>Jereminov</keyname><forenames>Marko</forenames></author><author><keyname>Pileggi</keyname><forenames>Larry</forenames></author><author><keyname>Hug</keyname><forenames>Gabriela</forenames></author></authors><title>A Linear Formulation for Power System State Estimation including RTU and
  PMU Measurements</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel linear formulation for power system state estimation
that simultaneously treats conventional and synchrophasor measurements is
proposed. A linear circuit model for conventional measurements is introduced to
enable a fully linear equivalent circuit representation of the power system.
The estimated system state is then obtained by formulating the optimization
problem to minimize the measurement errors and solving the resulting linear set
of optimality conditions. To evaluate the accuracy of the proposed method,
simulations are performed on several test cases of various sizes and the
results are presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00101</identifier>
 <datestamp>2019-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00101</id><created>2018-11-30</created><updated>2019-04-07</updated><authors><author><keyname>Lu</keyname><forenames>Guo</forenames></author><author><keyname>Ouyang</keyname><forenames>Wanli</forenames></author><author><keyname>Xu</keyname><forenames>Dong</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaoyun</forenames></author><author><keyname>Cai</keyname><forenames>Chunlei</forenames></author><author><keyname>Gao</keyname><forenames>Zhiyong</forenames></author></authors><title>DVC: An End-to-end Deep Video Compression Framework</title><categories>eess.IV cs.CV</categories><comments>Accepted by CVPR 2019. Project page https://github.com/GuoLusjtu/DVC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional video compression approaches use the predictive coding
architecture and encode the corresponding motion information and residual
information. In this paper, taking advantage of both classical architecture in
the conventional video compression method and the powerful non-linear
representation ability of neural networks, we propose the first end-to-end
video compression deep model that jointly optimizes all the components for
video compression. Specifically, learning based optical flow estimation is
utilized to obtain the motion information and reconstruct the current frames.
Then we employ two auto-encoder style neural networks to compress the
corresponding motion and residual information. All the modules are jointly
learned through a single loss function, in which they collaborate with each
other by considering the trade-off between reducing the number of compression
bits and improving quality of the decoded video. Experimental results show that
the proposed approach can outperform the widely used video coding standard
H.264 in terms of PSNR and be even on par with the latest standard H.265 in
terms of MS-SSIM. Code is released at https://github.com/GuoLusjtu/DVC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00115</identifier>
 <datestamp>2018-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00115</id><created>2018-11-30</created><authors><author><keyname>Grondin</keyname><forenames>Francois</forenames></author><author><keyname>Michaud</keyname><forenames>Francois</forenames></author></authors><title>Lightweight and Optimized Sound Source Localization and Tracking Methods
  for Open and Closed Microphone Array Configurations</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human-robot interaction in natural settings requires filtering out the
different sources of sounds from the environment. Such ability usually involves
the use of microphone arrays to localize, track and separate sound sources
online. Multi-microphone signal processing techniques can improve robustness to
noise but the processing cost increases with the number of microphones used,
limiting response time and widespread use on different types of mobile robots.
Since sound source localization methods are the most expensive in terms of
computing resources as they involve scanning a large 3D space, minimizing the
amount of computations required would facilitate their implementation and use
on robots. The robot's shape also brings constraints on the microphone array
geometry and configurations. In addition, sound source localization methods
usually return noisy features that need to be smoothed and filtered by tracking
the sound sources. This paper presents a novel sound source localization
method, called SRP-PHAT-HSDA, that scans space with coarse and fine resolution
grids to reduce the number of memory lookups. A microphone directivity model is
used to reduce the number of directions to scan and ignore non significant
pairs of microphones. A configuration method is also introduced to
automatically set parameters that are normally empirically tuned according to
the shape of the microphone array. For sound source tracking, this paper
presents a modified 3D Kalman (M3K) method capable of simultaneously tracking
in 3D the directions of sound sources. Using a 16-microphone array and low cost
hardware, results show that SRP-PHAT-HSDA and M3K perform at least as well as
other sound source localization and tracking methods while using up to 4 and 30
times less computing resources respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00149</identifier>
 <datestamp>2018-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00149</id><created>2018-12-01</created><authors><author><keyname>Hussain</keyname><forenames>Md. Shamim</forenames></author><author><keyname>Haque</keyname><forenames>Mohammad Ariful</forenames></author></authors><title>SwishNet: A Fast Convolutional Neural Network for Speech, Music and
  Noise Classification and Segmentation</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>7 pages, 3 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech, Music and Noise classification/segmentation is an important
preprocessing step for audio processing/indexing. To this end, we propose a
novel 1D Convolutional Neural Network (CNN) - SwishNet. It is a fast and
lightweight architecture that operates on MFCC features which is suitable to be
added to the front-end of an audio processing pipeline. We showed that the
performance of our network can be improved by distilling knowledge from a 2D
CNN, pretrained on ImageNet. We investigated the performance of our network on
the MUSAN corpus - an openly available comprehensive collection of noise, music
and speech samples, suitable for deep learning. The proposed network achieved
high overall accuracy in clip (length of 0.5-2s) classification (&gt;97% accuracy)
and frame-wise segmentation (&gt;93% accuracy) tasks with even higher accuracy
(&gt;99%) in speech/non-speech discrimination task. To verify the robustness of
our model, we trained it on MUSAN and evaluated it on a different corpus -
GTZAN and found good accuracy with very little fine-tuning. We also
demonstrated that our model is fast on both CPU and GPU, consumes a low amount
of memory and is suitable for implementation in embedded systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00156</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00156</id><created>2018-12-01</created><authors><author><keyname>Sakiyama</keyname><forenames>Akie</forenames></author><author><keyname>Watanabe</keyname><forenames>Kana</forenames></author><author><keyname>Tanaka</keyname><forenames>Yuichi</forenames></author></authors><title>M-Channel Critically Sampled Spectral Graph Filter Banks With Symmetric
  Structure</title><categories>eess.SP</categories><doi>10.1109/LSP.2019.2903683</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a class of $M$-channel spectral graph filter banks with a
symmetric structure, that is, the transform has sampling operations and
spectral graph filters on both the analysis and synthesis sides. The filter
banks achieve maximum decimation, perfect recovery, and orthogonality.
Conventional spectral graph transforms with decimation have significant
limitations with regard to the number of channels, the structures of the
underlying graph, and their filter design. The proposed transform uses sampling
in the graph frequency domain. This enables us to use any variation operators
and apply the transforms to arbitrary graphs even when the filter banks have
symmetric structures. We clarify the perfect reconstruction conditions and show
design examples. An experiment on graph signal denoising conducted to examine
the performance of the proposed filter bank is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00246</identifier>
 <datestamp>2018-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00246</id><created>2018-12-01</created><authors><author><keyname>Ma</keyname><forenames>Rui</forenames></author><author><keyname>Basumallik</keyname><forenames>Sagnik</forenames></author><author><keyname>Eftekharnejad</keyname><forenames>Sara</forenames></author></authors><title>A PMU-based Multivariate Model for Classifying Power System Events</title><categories>eess.SP cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-time transient event identification is essential for power system
situational awareness and protection. The increased penetration of Phasor
Measurement Units (PMUs) enhance power system visualization and real time
monitoring and control. However, a malicious false data injection attack on
PMUs can provide wrong data that might prompt the operator to take incorrect
actions which can eventually jeopardize system reliability. In this paper, a
multivariate method based on text mining is applied to detect false data and
identify transient events by analyzing the attributes of each individual PMU
time series and their relationship. It is shown that the proposed approach is
efficient in detecting false data and identifying each transient event
regardless of the system topology and loading condition as well as the coverage
rate and placement of PMUs. The proposed method is tested on IEEE 30-bus system
and the classification results are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00271</identifier>
 <datestamp>2019-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00271</id><created>2018-12-01</created><updated>2019-04-05</updated><authors><author><keyname>Ravanelli</keyname><forenames>Mirco</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Learning Speaker Representations with Mutual Information</title><categories>eess.AS cs.CL cs.LG cs.NE cs.SD</categories><comments>Submitted to Interspeech 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Learning good representations is of crucial importance in deep learning.
Mutual Information (MI) or similar measures of statistical dependence are
promising tools for learning these representations in an unsupervised way. Even
though the mutual information between two random variables is hard to measure
directly in high dimensional spaces, some recent studies have shown that an
implicit optimization of MI can be achieved with an encoder-discriminator
architecture similar to that of Generative Adversarial Networks (GANs). In this
work, we learn representations that capture speaker identities by maximizing
the mutual information between the encoded representations of chunks of speech
randomly sampled from the same sentence. The proposed encoder relies on the
SincNet architecture and transforms raw speech waveform into a compact feature
vector. The discriminator is fed by either positive samples (of the joint
distribution of encoded chunks) or negative samples (from the product of the
marginals) and is trained to separate them. We report experiments showing that
this approach effectively learns useful speaker representations, leading to
promising results on speaker identification and verification tasks. Our
experiments consider both unsupervised and semi-supervised settings and compare
the performance achieved with different objective functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00348</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00348</id><created>2018-12-02</created><authors><author><keyname>Jiang</keyname><forenames>Wenjie</forenames></author><author><keyname>Li</keyname><forenames>Xianye</forenames></author><author><keyname>Jiang</keyname><forenames>Shan</forenames></author><author><keyname>Wang</keyname><forenames>Yupeng</forenames></author><author><keyname>Zhang</keyname><forenames>Zexin</forenames></author><author><keyname>He</keyname><forenames>Guanbai</forenames></author><author><keyname>Sun</keyname><forenames>Baoqing</forenames></author></authors><title>Increase the frame rate of a camera via temporal ghost imaging</title><categories>eess.IV</categories><doi>10.1016/j.optlaseng.2019.06.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational temporal ghost imaging (CTGI) allows the reconstruction of a
fast signal from a two dimensional detection with no temporal resolution. High
speed spatial modulation is implemented to encode temporal detail of the signal
into the two dimensional detection. By calculating the correlation between the
modulation and the rendered image, the temporal information can be retrieved.
CTGI indicates a way to detect high speed non-reproducible signal from a slow
detector. Based on CTGI, we propose an innovative scheme that can increase the
frame rate of a camera by resolving the temporal detail of every camera image.
To achieve this, CTGI is conducted parallelly to different areas of the scene.
High speed spatial multiplexed modulation is performed, constraining the
continuous scene into a series of short-time-scale frames. All the modulated
frames are accumulated into one image that is eventually used in the
correlation retrieval process. By performing CTGI reconstruction on each area
independently, the temporal detail of the whole scene can be obtained. This
method can have a strong application in ultrafast imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00433</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00433</id><created>2018-12-02</created><updated>2019-06-02</updated><authors><author><keyname>Yalcin</keyname><forenames>Ahmet Zahid</forenames></author><author><keyname>Yuksel</keyname><forenames>Melda</forenames></author></authors><title>Precoder Design For Multi-group Multicasting with a Common Message</title><categories>eess.SP</categories><comments>31 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers precoding for multi-group multicasting with a common
message. The multiple antenna base station communicates with $K$ clusters, each
with $L$ users. There is a common message destined to all users and a private
multicast message for each cluster. We study the weighted sum rate (WSR)
maximization problem for two different schemes: (i) the base station transmits
the superposition of common and multicast messages, (ii) the base station
concatenates the multicast message vector with the common message. We also
formulate a second problem, weighted minimum mean square error (WMMSE)
minimization, and prove that WSR maximization and WMMSE minimization are
equivalent at the optimal solution. Inspired by the WMMSE problem, we suggest a
suboptimal algorithm, based on alternating optimization. We apply this
algorithm to the two transmission schemes, and understand that there is a
fundamental difference between the two. We compare the results with maximal
ratio transmission (MRT), and zero-forcing (ZF) precoding, and investigate the
effects of the number of base station antennas, the number of groups and the
number of users in a group. Finally, we study imperfect successive interference
cancellation (SIC) at the receivers and show that the first transmission scheme
is more robust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00449</identifier>
 <datestamp>2018-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00449</id><created>2018-12-02</created><authors><author><keyname>Kurzo</keyname><forenames>Yann</forenames></author><author><keyname>Burg</keyname><forenames>Andreas</forenames></author><author><keyname>Balatsoukas-Stimming</keyname><forenames>Alexios</forenames></author></authors><title>Design and Implementation of a Neural Network Aided Self-Interference
  Cancellation Scheme for Full-Duplex Radios</title><categories>eess.SP</categories><comments>Presented at the Asilomar Conference for Signals, Systems, and
  Computers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In-band full-duplex systems are able to transmit and receive information
simultaneously on the same frequency band. Due to the strong self-interference
caused by the transmitter to its own receiver, the use of non-linear digital
self-interference cancellation is essential. In this work, we present a
hardware architecture for a neural network based non-linear self-interference
canceller and we compare it with our own hardware implementation of a
conventional polynomial based canceller. We show that, for the same
cancellation performance, the neural network canceller has a significantly
higher throughput and requires fewer hardware resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00498</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00498</id><created>2018-12-02</created><updated>2019-02-13</updated><authors><author><keyname>Dokmani&#x107;</keyname><forenames>Ivan</forenames></author></authors><title>Permutations Unlabeled beyond Sampling Unknown</title><categories>cs.IT eess.SP math.IT</categories><doi>10.1109/LSP.2019.2908505</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent unlabeled sampling result by Unnikrishnan, Haghighatshoar and
Vetterli states that with probability one over iid Gaussian matrices $A$, any
$x$ can be uniquely recovered from an unknown permutation of $y = A x$ as soon
as $A$ has at least twice as many rows as columns. We show that this condition
on $A$ implies something much stronger: that an unknown vector $x$ can be
recovered from measurements $y = T A x$, when the unknown $T$ belongs to an
arbitrary set of invertible, diagonalizable linear transformations
$\mathcal{T}$. The set $\mathcal{T}$ can be finite or countably infinite. When
it is the set of $m \times m$ permutation matrices, we have the classical
unlabeled sampling problem. We show that for almost all $A$ with at least twice
as many rows as columns, all $x$ can be recovered either uniquely, or up to a
scale depending on $\mathcal{T}$, and that the condition on the size of $A$ is
necessary. Our proof is based on vector space geometry. Specializing to
permutations we obtain a simplified proof of the uniqueness result of
Unnikrishnan, Haghighatshoar and Vetterli. In this letter we are only concerned
with uniqueness; stability and algorithms are left for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00544</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00544</id><created>2018-12-02</created><updated>2019-05-06</updated><authors><author><keyname>Esmaili</keyname><forenames>Amirhossein</forenames></author><author><keyname>Kachuee</keyname><forenames>Mohammad</forenames></author><author><keyname>Shabany</keyname><forenames>Mahdi</forenames></author></authors><title>Nonlinear Cuff-less Blood Pressure Estimation of Healthy Subjects Using
  Pulse Transit Time and Arrival Time</title><categories>eess.SP</categories><comments>The collected data set can be accessed using the following url link:
  http://www.kaggle.com/mkachuee/noninvasivebp</comments><journal-ref>IEEE Transactions on Instrumentation and Measurement, 66(12),
  pp.3299-3308, December 2017</journal-ref><doi>10.1109/TIM.2017.2745081</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel blood pressure (BP) estimation method based on
pulse transit time (PTT) and pulse arrival time (PAT) to estimate the systolic
BP (SBP) and the diastolic BP (DBP). A data acquisition hardware is designed
for high-resolution sampling of phonocardiogram (PCG), photoplethysmogram, and
electrocardiogram (ECG). PCG and ECG perform as the proximal timing reference
to obtain PTT and PAT indices, respectively. In order to derive a BP estimator
model, a calibration procedure, including a supervised physical exercise, is
conducted for each individual, which causes changes in their BP, and then, a
number of reference BPs are measured alongside the acquisition of the signals
per subject. It is suggested to use a force-sensing resistor that is placed
under the cuff of the BP reference device to mark the exact moments of
reference BP measurements, which are corresponding to the inflation of the
cuff. Additionally, a novel BP estimator nonlinear model, based on the theory
of elastic tubes, is introduced to estimate the BP using PTT/PAT values
precisely. The proposed method is evaluated on 32 subjects. Using the PTT
index, the correlation coefficients for SBP and DBP estimation are 0.89 and
0.84, respectively. Using the PAT index, the correlation coefficients for SBP
and DBP estimation are 0.95 and 0.84, respectively. The results show that the
proposed method, exploiting the introduced nonlinear model with the use of PAT
index or PTT index, provides a reliable estimation of SBP and DBP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00648</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00648</id><created>2018-12-03</created><updated>2018-12-20</updated><authors><author><keyname>Anthoine</keyname><forenames>Sandrine</forenames></author><author><keyname>Boursier</keyname><forenames>Yannick</forenames></author><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author></authors><title>Proceedings of the fourth &quot;international Traveling Workshop on
  Interactions between low-complexity data models and Sensing Techniques&quot;
  (iTWIST'18)</title><categories>cs.IT cs.CV eess.SP math.IT</categories><comments>Final version, conference website:
  https://sites.google.com/view/itwist18</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The iTWIST workshop series aim at fostering collaboration between
international scientific teams for developing new theories, applications and
generalizations of low-complexity models. These events emphasize dissemination
of ideas through both specific oral and poster presentations, as well as free
discussions. For this fourth edition, iTWIST'18 gathered in CIRM, Marseille,
France, 74 international participants and featured 7 invited talks, 16 oral
presentations, and 21 posters.
  From iTWIST'18, the scientific committee has decided that the workshop
proceedings will adopt the episcience.org philosophy, combined with arXiv.org:
in a nutshell, &quot;the proceedings are equivalent to an overlay page, built above
arXiv.org; they add value to these archives by attaching a scientific caution
to the validated papers.&quot;
  This means that all papers listed in the HTML page of this arxiv publication
(see the menu on the right) have been thoroughly evaluated and approved by two
independent reviewers, and authors have revised their work according to the
comments provided by these reviewers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00693</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00693</id><created>2018-12-03</created><authors><author><keyname>Damm</keyname><forenames>Stefan Reinhold. Timo</forenames></author><author><keyname>Huber</keyname><forenames>Lukas</forenames></author><author><keyname>Andresen</keyname><forenames>Reimer</forenames></author><author><keyname>Barkmann</keyname><forenames>Reinhard</forenames></author><author><keyname>Gl&#xfc;er</keyname><forenames>Claus-C.</forenames></author><author><keyname>Koch</keyname><forenames>Reinhard</forenames></author></authors><title>An Analysis by Synthesis Approach for Automatic Vertebral Shape
  Identification in Clinical QCT</title><categories>eess.IV cs.CV physics.med-ph</categories><comments>Presented on German Conference on Pattern Recognition (GCPR) 2018 in
  Stuttgart</comments><doi>10.1007/978-3-030-12939-2_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative computed tomography (QCT) is a widely used tool for osteoporosis
diagnosis and monitoring. The assessment of cortical markers like cortical bone
mineral density (BMD) and thickness is a demanding task, mainly because of the
limited spatial resolution of QCT. We propose a direct model based method to
automatically identify the surface through the center of the cortex of human
vertebra. We develop a statistical bone model and analyze its probability
distribution after the imaging process. Using an as-rigid-as-possible
deformation we find the cortical surface that maximizes the likelihood of our
model given the input volume. Using the European Spine Phantom (ESP) and a high
resolution \mu CT scan of a cadaveric vertebra, we show that the proposed
method is able to accurately identify the real center of cortex ex-vivo. To
demonstrate the in-vivo applicability of our method we use manually obtained
surfaces for comparison.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00703</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00703</id><created>2018-12-03</created><updated>2019-10-16</updated><authors><author><keyname>Chimmalgi</keyname><forenames>Shrinivas</forenames></author><author><keyname>Prins</keyname><forenames>Peter J.</forenames></author><author><keyname>Wahls</keyname><forenames>Sander</forenames></author></authors><title>Fast Nonlinear Fourier Transform Algorithms Using Higher Order
  Exponential Integrators</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted version</comments><journal-ref>in IEEE Access, vol. 7, pp. 145161-145176, 2019</journal-ref><doi>10.1109/ACCESS.2019.2945480</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nonlinear Fourier transform (NFT) has recently gained significant
attention in fiber optic communications and other engineering fields. Although
several numerical algorithms for computing the NFT have been published, the
design of highly accurate low-complexity algorithms remains a challenge. In
this paper, we present new fast forward NFT algorithms that achieve accuracies
that are orders of magnitudes better than current methods, at comparable run
times and even for moderate sampling intervals. The new algorithms are compared
to existing solutions in multiple, extensive numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00743</identifier>
 <datestamp>2019-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00743</id><created>2018-12-03</created><authors><author><keyname>Zeng</keyname><forenames>Tengchan</forenames></author><author><keyname>Mozaffari</keyname><forenames>Mohammad</forenames></author><author><keyname>Semiari</keyname><forenames>Omid</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Wireless Communications and Control for Swarms of Cellular-Connected
  UAVs</title><categories>eess.SP</categories><doi>10.1016/j.physletb.2019.06.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By using wireless connectivity through cellular base stations (BSs), swarms
of unmanned aerial vehicles (UAVs) can provide a plethora of services ranging
from delivery of goods to surveillance. In particular, UAVs in a swarm can
utilize wireless communications to collect information, like velocity and
heading angle, from surrounding UAVs for coordinating their operations and
maintaining target speed and intra-UAV distance. However, due to the
uncertainty of the wireless channel, wireless communications among UAVs will
experience a transmission delay which can impair the swarm's ability to
stabilize system operation. In this paper, the problem of joint communication
and control is studied for a swarm of three cellular-connected UAVs positioned
in a triangle formation. In particular, a novel approach is proposed for
optimizing the swarm's operation while jointly considering the delay of the
wireless network and the stability of the control system. Based on this
approach, the maximum allowable delay required to prevent the instability of
the swarm is determined. Moreover, by using stochastic geometry, the
reliability of the wireless network is derived as the probability of meeting
the stability requirement of the control system. The simulation results
validate the effectiveness of the proposed joint strategy, and help obtain
insightful design guidelines on how to form a stable swarm of UAVs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00750</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00750</id><created>2018-11-29</created><updated>2019-12-28</updated><authors><author><keyname>Coskun</keyname><forenames>Huseyin</forenames></author></authors><title>Dynamic Ecological System Analysis</title><categories>eess.SY cs.SY math.DS math.OC q-bio.QM</categories><comments>45 pages, 15 figures. arXiv admin note: substantial text overlap with
  arXiv:1811.11885, arXiv:1811.10423</comments><msc-class>34A34, 35A24, 37C60, 37N25, 37N40, 70G60, 91B74, 92B20, 92C42,
  92D30, 92D40, 93C15, 94A15</msc-class><journal-ref>Heliyon 5 (2019)</journal-ref><doi>10.1016/j.heliyon.2019.e02347, 10.31219/osf.io/35xkb</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article develops a new mathematical method for holistic analysis of
nonlinear dynamic compartmental systems through the system decomposition
theory. The method is based on the novel dynamic system and subsystem
partitioning methodologies through which compartmental systems are decomposed
to the utmost level. The dynamic system and subsystem partitioning enable
tracking the evolution of the initial stocks, environmental inputs, and
intercompartmental system flows, as well as the associated storages derived
from these stocks, inputs, and flows individually and separately within the
system. Moreover, the transient and the dynamic direct, indirect, acyclic,
cycling, and transfer (diact) flows and associated storages transmitted along a
given flow path or from one compartment, directly or indirectly, to any other
are analytically characterized, systematically classified, and mathematically
formulated. Further, the article develops a dynamic technique based on the
diact transactions for the quantitative classification of interspecific
interactions and the determination of their strength within food webs. Major
concepts and quantities of the current static network analyses are also
extended to nonlinear dynamic settings and integrated with the proposed dynamic
measures and indices within the proposed unifying mathematical framework.
Therefore, the proposed methodology enables a holistic view and analysis of
ecological systems. We consider that this methodology brings a novel complex
system theory to the service of urgent and challenging environmental problems
of the day and has the potential to lead the way to a more formalistic
ecological science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00797</identifier>
 <datestamp>2019-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00797</id><created>2018-11-29</created><authors><author><keyname>Khobahi</keyname><forenames>Shahin</forenames></author><author><keyname>Naimipour</keyname><forenames>Naveed</forenames></author><author><keyname>Soltanalian</keyname><forenames>Mojtaba</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Deep Signal Recovery with One-Bit Quantization</title><categories>eess.SP cs.LG stat.ML</categories><comments>This paper has been submitted to the 44th International Conference on
  Acoustics, Speech, and Signal Processing (ICASSP 2019)</comments><doi>10.1109/ICASSP.2019.8683876</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning, and more specifically deep learning, have shown remarkable
performance in sensing, communications, and inference. In this paper, we
consider the application of the deep unfolding technique in the problem of
signal reconstruction from its one-bit noisy measurements. Namely, we propose a
model-based machine learning method and unfold the iterations of an inference
optimization algorithm into the layers of a deep neural network for one-bit
signal recovery. The resulting network, which we refer to as DeepRec, can
efficiently handle the recovery of high-dimensional signals from acquired
one-bit noisy measurements. The proposed method results in an improvement in
accuracy and computational efficiency with respect to the original framework as
shown through numerical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00848</identifier>
 <datestamp>2018-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00848</id><created>2018-12-03</created><authors><author><keyname>Gonz&#xe1;lez-Coma</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Su&#xe1;rez-Casal</keyname><forenames>Pedro</forenames></author><author><keyname>Castro</keyname><forenames>Paula M.</forenames></author><author><keyname>Castedo</keyname><forenames>Luis</forenames></author><author><keyname>Joham</keyname><forenames>Michael</forenames></author></authors><title>FDD Channel Estimation via Covariance Identification in Wideband Massive
  MIMO Systems</title><categories>eess.SP</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for channel estimation in wideband massive Multiple-Input
Multiple-Output (MIMO) systems using covariance identification is developed.
The method is useful for Frequency-Division Duplex (FDD) at either sub-6GHz or
millimeter wave (mmWave) frequency bands and takes into account the beam squint
effect caused by the large bandwidth of the signals. The method relies on the
slow time variation of the channel covariance matrix and allows for the
utilization of very short training sequences thanks to the exploitation of the
channel structure, both in the covariance matrix identification and the channel
estimation stages. As a consequence of significantly reducing the training
overhead, the proposed channel estimator has a computational complexity lower
than other existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00851</identifier>
 <datestamp>2018-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00851</id><created>2018-12-03</created><authors><author><keyname>Tayade</keyname><forenames>Shreya</forenames></author><author><keyname>Rost</keyname><forenames>Peter</forenames></author><author><keyname>Maeder</keyname><forenames>Andreas</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Delay constrained Energy Optimization for Edge Cloud Offloading</title><categories>eess.SP</categories><comments>Published in ICC workshop 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resource limited user-devices may offload computation to a cloud server, in
order to reduce power consumption and lower the execution time. However, to
communicate to the cloud server over a wireless channel, additional energy is
consumed for transmitting the data. Also a delay is introduced for offloading
the data and receiving the response. Therefore, an optimal decision needs to be
made that would reduce the energy consumption, while simultaneously satisfying
the delay constraint. In this paper, we obtain an optimal closed form solution
for these decision variables in a multi-user scenario. Furthermore, we
optimally allocate the cloud server resources to the user devices, and evaluate
the minimum delay that the system can provide, for a given bandwidth and number
of user devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00890</identifier>
 <datestamp>2018-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00890</id><created>2018-11-30</created><authors><author><keyname>Giannoni</keyname><forenames>Federico</forenames></author><author><keyname>Mancini</keyname><forenames>Marco</forenames></author><author><keyname>Marinelli</keyname><forenames>Federico</forenames></author></authors><title>Anomaly Detection Models for IoT Time Series Data</title><categories>eess.SP cs.LG</categories><comments>10 pages, 13 figures</comments><msc-class>68-00</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Insitu sensors and Wireless Sensor Networks (WSNs) have become more and more
popular in the last decade, due to their potential to be used in various
applications of many different fields. As of today, WSNs are pretty much used
by any monitoring system: from those that are health care related, to those
that are used for environmental forecasting or surveillance purposes. All
applications that make use of insitu sensors, strongly rely on their correct
operation, which however, is quite difficult to guarantee. These sensors in
fact, are typically cheap and prone to malfunction. Additionally, for many
tasks (e.g. environmental forecasting), sensors are also deployed under
potentially harsh weather condition, making their breakage even more likely.
The high probability of erroneous readings or data corruption during
transmission, brings up the problem of ensuring quality of the data collected
by sensors. Since WSNs have to operate continuously and therefore generate very
large volumes of data every day, the quality control process has to be
automated, scalable and fast enough to be applicable to streaming data. The
most common approach to ensure the quality of sensors data, consists in
automated detection of erroneous readings or anomalous behaviours of sensors.
In the literature, this strategy is known as anomaly detection and can be
pursued in many different ways.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00909</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00909</id><created>2018-12-03</created><authors><author><keyname>Oxvig</keyname><forenames>Christian Schou</forenames></author><author><keyname>Arildsen</keyname><forenames>Thomas</forenames></author></authors><title>Generalised Approximate Message Passing for Non-I.I.D. Sparse Signals</title><categories>eess.SP</categories><comments>3 pages, 1 figure, presented at iTWIST 2018, Marseille</comments><journal-ref>in Proceedings of iTWIST'18, Paper-ID: 24, Marseille, France,
  November, 21-23, 2018</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Generalised approximate message passing (GAMP) is an approximate Bayesian
estimation algorithm for signals observed through a linear transform with a
possibly non-linear subsequent measurement model. By leveraging prior
information about the observed signal, such as sparsity in a known dictionary,
GAMP can for example reconstruct signals from under-determined measurements -
known as compressed sensing. In the sparse signal setting, most existing signal
priors for GAMP assume the input signal to have i.i.d. entries. Here we present
sparse signal priors for GAMP to estimate non-i.d.d. signals through a
non-uniform weighting of the input prior, for example allowing GAMP to support
model-based compressed sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.00982</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.00982</id><created>2018-12-03</created><updated>2019-07-06</updated><authors><author><keyname>Zhao</keyname><forenames>Jian</forenames></author><author><keyname>Sun</keyname><forenames>Yangyang</forenames></author><author><keyname>Zhu</keyname><forenames>Hongbo</forenames></author><author><keyname>Zhu</keyname><forenames>Zheyuan</forenames></author><author><keyname>Antonio-Lopez</keyname><forenames>Jose Enrique</forenames></author><author><keyname>Correa</keyname><forenames>Rodrigo Amezcua</forenames></author><author><keyname>Pang</keyname><forenames>Shuo</forenames></author><author><keyname>Schulzgen</keyname><forenames>Axel</forenames></author></authors><title>Deep Learning Cell Imaging through Anderson Localizing Optical Fibre</title><categories>physics.optics eess.IV</categories><comments>14 pages,7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate a deep-learning-based fibre imaging system which can transfer
real-time artifact-free cell images through a meter-long Anderson localizing
optical fibre. The cell samples are illuminated by an incoherent LED light
source. A deep convolutional neural network is applied to the image
reconstruction process. The network training uses data generated by a set-up
with straight fibre at room temperature (~20 {\deg}C) but can be utilized
directly for high fidelity reconstruction of cell images that are transported
through fibre with a few degrees bend and/or fibre with segments heated up to
50 {\deg}C. In addition, cell images located several millimeters away from the
bare fibre end can be transported and recovered successfully without the
assistance of any distal optics. We further evidence that the trained neural
network is able to reconstruct the images of cells which are never used in the
training process and feature very different morphology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01005</identifier>
 <datestamp>2019-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01005</id><created>2018-12-03</created><updated>2019-04-08</updated><authors><author><keyname>Arafa</keyname><forenames>Ahmed</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Timely Updates in Energy Harvesting Two-hop Networks: Offline and Online
  Policies</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>Submitted for journal publication, November 2018 arXiv admin note:
  substantial text overlap with arXiv:1704.08679</comments><doi>10.1109/TWC.2019.2920351</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two-hop energy harvesting communication network is considered, in which
measurement updates are transmitted by a source to a destination through an
intermediate relay. Updates are to be sent in a timely fashion that minimizes
the age of information, defined as the time elapsed since the most recent
update at the destination was generated at the source. The source and the relay
communicate using energy harvested from nature, which is stored in
infinite-sized batteries. Both nodes use fixed transmission rates, and hence
updates incur fixed delays (service times). Two problems are formulated: an
offline problem, in which the energy arrival information is known a priori, and
an online problem, in which such information is revealed causally over time. In
both problems, it is shown that it is optimal to transmit updates from the
source just in time as the relay is ready to forward them to the destination,
making the source and the relay act as one combined node. A recurring theme in
the optimal policy is that updates should be as uniformly spread out over time
as possible, subject to energy causality and service time constraints. This is
perfectly achieved in the offline setting, and is achieved almost surely in the
online setting by a best effort policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01060</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01060</id><created>2018-12-03</created><authors><author><keyname>Kotecha</keyname><forenames>Nikhil</forenames></author></authors><title>Bach2Bach: Generating Music Using A Deep Reinforcement Learning Approach</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>42 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model of music needs to have the ability to recall past details and have a
clear, coherent understanding of musical structure. Detailed in the paper is a
deep reinforcement learning architecture that predicts and generates polyphonic
music aligned with musical rules. The probabilistic model presented is a
Bi-axial LSTM trained with a pseudo-kernel reminiscent of a convolutional
kernel. To encourage exploration and impose greater global coherence on the
generated music, a deep reinforcement learning approach DQN is adopted. When
analyzed quantitatively and qualitatively, this approach performs well in
composing polyphonic music.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01116</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01116</id><created>2018-12-03</created><authors><author><keyname>Boljanovic</keyname><forenames>Veljko</forenames></author><author><keyname>Yan</keyname><forenames>Han</forenames></author><author><keyname>Cabric</keyname><forenames>Danijela</forenames></author></authors><title>Tracking Sparse mmWave Channel under Time Varying Multipath Scatterers</title><categories>eess.SP</categories><comments>6 pages, 10 figures, presented at 2018 Asilomar Conference on
  Signals, Systems, and Computers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to severe signal attenuation at millimeter-wave (mmWave) frequencies
large antenna arrays are required at both base station and user equipment to
achieve necessary beamfoming gain and compensate for the signal power loss. The
initial access and beamforming algorithms are typically designed assuming
sparsity of mmWave channels, resulting from a very few significant multipath
clusters, and considering fixed locations of terminals and scatterers. Channel
tracking algorithms have been proposed to account for channel variations due to
user mobility. Existing works did not consider mobility of the scatterers,
which adds new challenges and opportunities into a channel tracking problem. In
this work, we consider a more realistic assumption of mobile scatterers and
their impact on channel tracking algorithms. We propose a novel channel
tracking algorithm that takes into account the dynamics of cluster evolution,
and adaptively tracks channel parameters with the objective to reduce training
overhead. We also propose a simple implementation of aperiodic tracking to
accommodate tracking to different channel variations. We analyze the
performance of the proposed tracking algorithm under highly dynamic channels,
and compare it to existing channel tracking algorithms with respect to tracking
accuracy, achievable rate, and required training overhead, when aperiodic and
periodic trackings are used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01124</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01124</id><created>2018-12-03</created><authors><author><keyname>Sankhe</keyname><forenames>Kunal</forenames></author><author><keyname>Belgiovine</keyname><forenames>Mauro</forenames></author><author><keyname>Zhou</keyname><forenames>Fan</forenames></author><author><keyname>Riyaz</keyname><forenames>Shamnaz</forenames></author><author><keyname>Ioannidis</keyname><forenames>Stratis</forenames></author><author><keyname>Chowdhury</keyname><forenames>Kaushik</forenames></author></authors><title>ORACLE: Optimized Radio clAssification through Convolutional neuraL
  nEtworks</title><categories>eess.SP cs.LG</categories><comments>Accepted in IEEE INFOCOM 2019, Paris, France, May 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the architecture and performance of ORACLE, an approach
for detecting a unique radio from a large pool of bit-similar devices (same
hardware, protocol, physical address, MAC ID) using only IQ samples at the
physical layer. ORACLE trains a convolutional neural network (CNN) that
balances computational time and accuracy, showing 99\% classification accuracy
for a 16-node USRP X310 SDR testbed and an external database of $&gt;$100 COTS
WiFi devices. Our work makes the following contributions: (i) it studies the
hardware-centric features within the transmitter chain that causes IQ sample
variations; (ii) for an idealized static channel environment, it proposes a CNN
architecture requiring only raw IQ samples accessible at the front-end, without
channel estimation or prior knowledge of the communication protocol; (iii) for
dynamic channels, it demonstrates a principled method of feedback-driven
transmitter-side modifications that uses channel estimation at the receiver to
increase differentiability for the CNN classifier. The key innovation here is
to intentionally introduce controlled imperfections on the transmitter side
through software directives, while minimizing the change in bit error rate.
Unlike previous work that imposes constant environmental conditions, ORACLE
adopts the `train once deploy anywhere' paradigm with near-perfect device
classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01126</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01126</id><created>2018-12-03</created><authors><author><keyname>Chen</keyname><forenames>Tingjun</forenames></author><author><keyname>Dastjerdi</keyname><forenames>Mahmood Baraani</forenames></author><author><keyname>Zhou</keyname><forenames>Jin</forenames></author><author><keyname>Krishnaswamy</keyname><forenames>Harish</forenames></author><author><keyname>Zussman</keyname><forenames>Gil</forenames></author></authors><title>Wideband Full-Duplex Wireless via Frequency-Domain Equalization: Design
  and Experimentation</title><categories>eess.SP cs.NI</categories><comments>To appear in Proc. ACM MobiCom'19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Full-duplex (FD) wireless can significantly enhance spectrum efficiency but
requires tremendous amount of self-interference (SI) cancellation. Recent
advances in the RFIC community enabled wideband RF SI cancellation (SIC) in
integrated circuits (ICs) via frequency-domain equalization (FDE), where RF
filters channelize the SI signal path. Unlike other FD implementations, that
mostly rely on delay lines, FDE-based cancellers can be realized in
small-form-factor devices. However, the fundamental limits and higher layer
challenges associated with these cancellers were not explored yet. Therefore,
and in order to support the integration with a software-defined radio (SDR) and
to facilitate experimentation in a testbed with several nodes, we design and
implement an FDE-based RF canceller on a printed circuit board (PCB). We derive
and experimentally validate the PCB canceller model and present a canceller
configuration scheme based on an optimization problem. We then extensively
evaluate the performance of the FDE-based FD radio in the SDR testbed.
Experiments show that it achieves 95dB overall SIC (52dB from RF SIC) across
20MHz bandwidth, and an average link-level FD gain of 1.87x. We also conduct
experiments in: (i) uplink-downlink networks with inter-user interference, and
(ii) heterogeneous networks with half-duplex and FD users. The experimental FD
gains in the two types of networks confirm previous analytical results. They
depend on the users' SNR values and the number of FD users, and are 1.14x-1.25x
and 1.25x-1.73x, respectively. Finally, we numerically evaluate and compare the
RFIC and PCB implementations and study various design tradeoffs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01155</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01155</id><created>2018-12-03</created><updated>2019-05-21</updated><authors><author><keyname>Mehrvarz</keyname><forenames>Amin</forenames></author><author><keyname>Salarieh</keyname><forenames>Hasan</forenames></author><author><keyname>Alasty</keyname><forenames>Aria</forenames></author><author><keyname>Vatankhah</keyname><forenames>Ramin</forenames></author></authors><title>Boundary Vibration Control of Strain Gradient Timoshenko
  Micro-Cantilevers Using Piezoelectric Actuators</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the problem of boundary control of vibration in a clamped-free
strain gradient Timoshenko micro-cantilever is studied. For getting systems
closer to reality, the force or moment exertion conditions should be modeled.
To this end, a piezoelectric layer is laminated on one side of the beam and the
controlling actuation is applied through the piezoelectric voltage. The beam
and piezoelectric layer are coupled and modeled at the same time and the
dynamic equations and boundary conditions of the system are achieved using the
Hamilton principle. To achieve the purpose of eliminating vibration of the
system, the control law is obtained from a Lyapunov function using Lasalle
invariant set theorem. The control law has a form of feedback from the spatial
derivatives of boundary states of the beam. The finite element method using the
strain gradient Timoshenko beam element has been used and then the simulation
is performed to illustrate the impact of the proposed controller to the micro
beam.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01221</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01221</id><created>2018-12-04</created><authors><author><keyname>Kazaz</keyname><forenames>Tarik</forenames></author><author><keyname>Coutino</keyname><forenames>Mario</forenames></author><author><keyname>Janssen</keyname><forenames>Gerard J. M.</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author><author><keyname>van der Veen</keyname><forenames>Alle-Jan</forenames></author></authors><title>Joint Ranging and Clock Synchronization for Dense Heterogeneous IoT
  Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>52nd Annual Asilomar Conference on Signals, Systems, and Computers</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Synchronization and ranging in internet of things (IoT) networks are
challenging due to the narrowband nature of signals used for communication
between IoT nodes. Recently, several estimators for range estimation using
phase difference of arrival (PDoA) measurements of narrowband signals have been
proposed. However, these estimators are based on data models which do not
consider the impact of clock-skew on the range estimation. In this paper,
clock-skew and range estimation are studied under a unified framework. We
derive a novel and precise data model for PDoA measurements which incorporates
the unknown clock-skew effects. We then formulate joint estimation of the
clock-skew and range as a two-dimensional (2-D) frequency estimation problem of
a single complex sinusoid. Furthermore, we propose: (i) a two-way communication
protocol for collecting PDoA measurements and (ii) a weighted least squares
(WLS) algorithm for joint estimation of clock-skew and range leveraging the
shift invariance property of the measurement data. Finally, through numerical
experiments, the performance of the proposed protocol and estimator is compared
against the Cramer Rao lower bound demonstrating that the proposed estimator is
asymptotically efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01234</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01234</id><created>2018-12-04</created><authors><author><keyname>Ma</keyname><forenames>Xiaofu</forenames></author><author><keyname>Gao</keyname><forenames>Qinghai</forenames></author><author><keyname>Wang</keyname><forenames>Ji</forenames></author><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey H.</forenames></author></authors><title>Dynamic Sounding for Multi-User MIMO in Wireless LANs</title><categories>eess.SP cs.NI</categories><comments>IEEE Transactions on Consumer Electronics, 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consumer electronic (CE) devices increasingly rely on wireless local area
networks (WLANs). Next generation WLANs will continue to exploit multiple
antenna systems to satisfy the growing need for WLAN system capacity.
Multiple-input multiple-output (MIMO) antenna systems improve the spectral
efficiency and single user throughput. Multi-user MIMO (MU-MIMO) systems
exploit the spatial separation of users for increasing the sum-throughput. In
an MU-MIMO system, efficient channel sounding is essential for achieving
optimal performance. The system analysis in this paper provides insights into
the rate at which to perform channel sounding. This paper shows that optimal
sounding intervals exist for single user transmit beamforming (SU-TxBF) and
MU-MIMO, and proposes a low-complexity dynamic sounding approach for practical
MU-MIMO WLAN deployments. The proposed approach adjusts the sounding interval
adaptively based on the real-time learning outcomes in the given radio
environment. Using real over-the-air channel measurements, significant
throughput improvements (up to 31.8%) are demonstrated by adopting the proposed
dynamic sounding approach, which is compliant with IEEE 802.11ac.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01241</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01241</id><created>2018-12-04</created><authors><author><keyname>Ma</keyname><forenames>Xiaofu</forenames></author><author><keyname>Gao</keyname><forenames>Qinghai</forenames></author><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey H.</forenames></author></authors><title>Hypergraph matching for MU-MIMO user grouping in wireless LANs</title><categories>eess.SP cs.CC cs.DS</categories><comments>Ad Hoc Networks, 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the user grouping problem of downlink wireless local
area networks (WLANs) with multi-user MIMO (MU-MIMO). Particularly, we focus on
the problem of whether single user transmit beamforming (SU-TxBF) or MU-MIMO
should be utilized, and how many users and which users should be in a
multi-user (MU) group. We formulate the problem for maximizing the system
throughput subject to the multi-user air time fairness (MU-ATF) criterion. We
show that hypergraphs provide a suitable mathematical model and effective tool
for finding the optimal or close to optimal solution. We show that the optimal
grouping problem can be solved efficiently for the case where only SU-TxBF and
2-user MU groups are allowed in the system. For the general case, where any
number of users can be assigned to groups of different sizes, we develop an
efficient graph matching algorithm (GMA) based on graph theory principles. We
evaluate the proposed algorithm in terms of system throughput using an 802.11ac
emulator, which is created using collected channel measurements from an indoor
environment and simulated channel samples for outdoor scenarios. We show that
our GMA achieves at least 93% of the optimal system throughput in all
considered test cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01259</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01259</id><created>2018-12-04</created><updated>2019-10-16</updated><authors><author><keyname>Saeed</keyname><forenames>Nasir</forenames></author><author><keyname>Guo</keyname><forenames>Shuaishuai</forenames></author><author><keyname>Park</keyname><forenames>Ki-Hong</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Optical Camera Communications: Survey, Use Cases, Challenges, and Future
  Trends</title><categories>eess.IV eess.SP</categories><comments>submitted to Physical Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a camera or an image sensor receiver based optical wireless
communications (OWC) techniques have attracted particular interest in areas
such as the internet of things, indoor localization, motion capture, and
intelligent transportation systems. As a supplementary technique of high-speed
OWC based on photo-detectors, communications hinging on image sensors as
receivers do not need much modification to the current infrastructure, such
that the implementation complexity and cost are quite low. Therefore, in this
paper, we present a comprehensive survey of optical camera communication (OCC)
techniques, and their use in localization, navigation, and motion capture. This
survey is distinguishable from the existing reviews on this topic by covering
multiple aspects of OCC and its various applications. The first part of the
paper focuses on the standardization, channel characterization, modulation,
coding, and synchronization of OCC systems while the second part of the article
presents the literature on OCC based localization, navigation, and motion
capture. Finally, in the last part of the paper, we present the challenges and
future research directions of OCC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01269</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01269</id><created>2018-12-04</created><updated>2019-02-18</updated><authors><author><keyname>Chou</keyname><forenames>Szu-Yu</forenames></author><author><keyname>Cheng</keyname><forenames>Kai-Hsiang</forenames></author><author><keyname>Jang</keyname><forenames>Jyh-Shing Roger</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Learning to match transient sound events using attentional similarity
  for few-shot sound recognition</title><categories>cs.SD eess.AS</categories><comments>This is a pre-print version of an ICASSP 2019 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a novel attentional similarity module for the
problem of few-shot sound recognition. Given a few examples of an unseen sound
event, a classifier must be quickly adapted to recognize the new sound event
without much fine-tuning. The proposed attentional similarity module can be
plugged into any metric-based learning method for few-shot learning, allowing
the resulting model to especially match related short sound events. Extensive
experiments on two datasets shows that the proposed module consistently
improves the performance of five different metric-based learning methods for
few-shot sound recognition. The relative improvement ranges from +4.1% to +7.7%
for 5-shot 5-way accuracy for the ESC-50 dataset, and from +2.1% to +6.5% for
noiseESC-50. Qualitative results demonstrate that our method contributes in
particular to the recognition of transient sound events.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01274</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01274</id><created>2018-12-04</created><authors><author><keyname>Brihuega</keyname><forenames>Alberto</forenames></author><author><keyname>Anttila</keyname><forenames>Lauri</forenames></author><author><keyname>Abdelaziz</keyname><forenames>Mahmoud</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>Digital Predistortion in Large-Array Digital Beamforming Transmitters</title><categories>eess.SP</categories><comments>8 pages, Accepted for publication in Asilomar Conference on Signals,
  Systems, and Computers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we propose a novel digital predistortion (DPD) solution that
allows to considerably reduce the complexity resulting from linearizing a set
of power amplifiers (PAs) in single-user large-scale digital beamforming
transmitters. In contrast to current state-of-the art solutions that assume a
dedicated DPD per power amplifier, which is unfeasible in the context of large
antenna arrays, the proposed solution only requires a single DPD in order to
linearize an arbitrary number of power amplifiers. To this end, the proposed
DPD predistorts the signal at the input of the digital precoder based on
minimizing the nonlinear distortion of the combined signal at the intended
receiver direction. This is a desirable feature, since the resulting emissions
in other directions get partially diluted due to less coherent superposition.
With this approach, only a single DPD is required, yielding great complexity
and energy savings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01278</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01278</id><created>2018-12-04</created><authors><author><keyname>Lin</keyname><forenames>Kin Wah Edward</forenames></author><author><keyname>T.</keyname><forenames>Balamurali B.</forenames></author><author><keyname>Koh</keyname><forenames>Enyan</forenames></author><author><keyname>Lui</keyname><forenames>Simon</forenames></author><author><keyname>Herremans</keyname><forenames>Dorien</forenames></author></authors><title>Singing Voice Separation Using a Deep Convolutional Neural Network
  Trained by Ideal Binary Mask and Cross Entropy</title><categories>cs.SD cs.AI cs.LG eess.AS stat.ML</categories><comments>In Press, Neural Computing and Applications, Springer. 2019</comments><proxy>Dorien Herremans</proxy><msc-class>68-XX, 68Txx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Separating a singing voice from its music accompaniment remains an important
challenge in the field of music information retrieval. We present a unique
neural network approach inspired by a technique that has revolutionized the
field of vision: pixel-wise image classification, which we combine with cross
entropy loss and pretraining of the CNN as an autoencoder on singing voice
spectrograms. The pixel-wise classification technique directly estimates the
sound source label for each time-frequency (T-F) bin in our spectrogram image,
thus eliminating common pre- and postprocessing tasks. The proposed network is
trained by using the Ideal Binary Mask (IBM) as the target output label. The
IBM identifies the dominant sound source in each T-F bin of the magnitude
spectrogram of a mixture signal, by considering each T-F bin as a pixel with a
multi-label (for each sound source). Cross entropy is used as the training
objective, so as to minimize the average probability error between the target
and predicted label for each pixel. By treating the singing voice separation
problem as a pixel-wise classification task, we additionally eliminate one of
the commonly used, yet not easy to comprehend, postprocessing steps: the Wiener
filter postprocessing.
  The proposed CNN outperforms the first runner up in the Music Information
Retrieval Evaluation eXchange (MIREX) 2016 and the winner of MIREX 2014 with a
gain of 2.2702 ~ 5.9563 dB global normalized source to distortion ratio (GNSDR)
when applied to the iKala dataset. An experiment with the DSD100 dataset on the
full-tracks song evaluation task also shows that our model is able to compete
with cutting-edge singing voice separation systems which use multi-channel
modeling, data augmentation, and model blending.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01346</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01346</id><created>2018-12-04</created><authors><author><keyname>Chetupalli</keyname><forenames>Srikanth Raj</forenames></author><author><keyname>Sreenivas</keyname><forenames>Thippur V.</forenames></author></authors><title>LSTM based AE-DNN constraint for better late reverb suppression in
  multi-channel LP formulation</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prediction of late reverberation component using multi-channel linear
prediction (MCLP) in short-time Fourier transform (STFT) domain is an effective
means to enhance reverberant speech. Traditionally, a speech power spectral
density (PSD) weighted prediction error (WPE) minimization approach is used to
estimate the prediction filters. The method is sensitive to the estimate of the
desired signal PSD. In this paper, we propose a deep neural network (DNN) based
non-linear estimate for the desired signal PSD. An auto encoder trained on
clean speech STFT coefficients is used as the desired signal prior. We explore
two different architectures based on (i) fully-connected (FC) feed-forward, and
(ii) recurrent long short-term memory (LSTM) layers. Experiments using real
room impulse responses show that the LSTM-DNN based PSD estimate performs
better than the traditional methods for late reverb suppression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01385</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01385</id><created>2018-12-04</created><authors><author><keyname>Ali</keyname><forenames>Ayyaz</forenames></author><author><keyname>Shah</keyname><forenames>Syed Waqas Haider</forenames></author><author><keyname>Iqbal</keyname><forenames>Khalid</forenames></author></authors><title>Design of an Efficient Single-Stage and 2-Stages Class-E Power Amplifier
  (2.4GHz) for Internet-of-Things</title><categories>eess.SP</categories><comments>16th International Conference on Frontiers of Information Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, the designs of a single-stage and 2-stage 2.4 GHz power
amplifier (PA) are presented. The proposed PAs have been designed to provide
high gain and improved efficiency using harmonic suppression and optimized
impedance matching techniques. There are two harmonic suppression circuits,
each stage of the PA consists of 2 capacitors and 2 inductors, which will help
to suppress the harmonic frequency for 2.4 GHz. These suppression circuits will
help to enhance the overall efficiency of the PAs. Both the PAs are provided
with a VCC supply of 4.2V. Input and output impedances are matched to 50 ohms.
Simulation and experimental results are presented, where the simulated gain and
power added efficiency (PAE) for single stage PA are 17:58dB and 53%,
respectively. While the experimental gain and PAE are 16:7dB and 49.5%,
respectively. On the other hand, for 2-stages PA, simulated gain comes out to
be 34.6dB and PAE is 55%, while the experimental gain and PAE are 30.5dB and
53.1%, respectively. The final design is being fabricated on the Taconic
printed circuit board (PCB) with a thickness of 0.79mm and the dielectric
constant value of 3.2 and its dimensions are 4.6cm x 3.4cm for single stage and
5.9cm x 3.6cm for 2-stages PA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01399</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01399</id><created>2018-12-04</created><authors><author><keyname>Meynard</keyname><forenames>Adrien</forenames></author></authors><title>Joint nonstationary blind source separation and spectral analysis</title><categories>eess.SP</categories><comments>in Proceedings of iTWIST'18, Paper-ID: 13, Marseille, France,
  November, 21-23, 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We address a nonstationary blind source separation (BSS) problem. The model
includes both nonstationary sources and mixing. Therefore, we introduce an
algorithm for joint BSS and estimation of stationarity-breaking deformations
and spectra. Finally, its performances are evaluated on a synthetic example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01501</identifier>
 <datestamp>2019-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01501</id><created>2018-12-04</created><updated>2019-05-06</updated><authors><author><keyname>Shon</keyname><forenames>Suwon</forenames></author><author><keyname>Ali</keyname><forenames>Ahmed</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Domain Attentive Fusion for End-to-end Dialect Identification with
  Unknown Target Domain</title><categories>eess.AS cs.LG cs.SD</categories><comments>ICASSP 2019, revised typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end deep learning language or dialect identification systems operate
on the spectrogram or other acoustic feature and directly generate
identification scores for each class. An important issue for end-to-end systems
is to have some knowledge of the application domain, because the system can be
vulnerable to use cases that were not seen in the training phase; such a
scenario is often referred to as a domain mismatched condition. In general, we
assume that there is enough variation in the training dataset to expose the
system to multiple domains. In this work, we study how to best make use a
training dataset in order to have maximum effectiveness on unknown target
domains. Our goal is to process the input without any knowledge of the target
domain while preserving robust performance on other domains as well. To
accomplish this objective, we propose a domain attentive fusion approach for
end-to-end dialect/language identification systems. To help with
experimentation, we collect a dataset from three different domains, and create
experimental protocols for a domain mismatched condition. The results of our
proposed approach, which were tested on a variety of broadcast and YouTube
data, shows significant performance gain compared to traditional approaches,
even without any prior target domain information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01521</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01521</id><created>2018-12-04</created><authors><author><keyname>Salvati</keyname><forenames>Daniele</forenames></author><author><keyname>Drioli</keyname><forenames>Carlo</forenames></author><author><keyname>Foresti</keyname><forenames>Gian Luca</forenames></author></authors><title>Localization and Tracking of an Acoustic Source using a Diagonal
  Unloading Beamforming and a Kalman Filter</title><categories>cs.SD eess.AS</categories><comments>In Proceedings of the LOCATA Challenge Workshop - a satellite event
  of IWAENC 2018 (arXiv:1811.08482)</comments><report-no>LOCATAchallenge/2018/07</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the signal processing framework and some results for the IEEE AASP
challenge on acoustic source localization and tracking (LOCATA). The system is
designed for the direction of arrival (DOA) estimation in single-source
scenarios. The proposed framework consists of four main building blocks:
pre-processing, voice activity detection (VAD), localization, tracking. The
signal pre-processing pipeline includes the short-time Fourier transform (STFT)
of the multichannel input captured by the array and the cross power spectral
density (CPSD) matrices estimation. The VAD is calculated with a trace-based
threshold of the CPSD matrices. The localization is then computed using our
recently proposed diagonal unloading (DU) beamforming, which has low-complexity
and high resolution. The DOA estimation is finally smoothed with a Kalman filer
(KF). Experimental results on the LOCATA development dataset are reported in
terms of the root mean square error (RMSE) for a 7-microphone linear array, the
12-microphone pseudo-spherical array integrated in a prototype head for a
humanoid robot, and the 32-microphone spherical array.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01540</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01540</id><created>2018-12-04</created><authors><author><keyname>Rencker</keyname><forenames>Lucas</forenames></author><author><keyname>Bach</keyname><forenames>Francis</forenames></author><author><keyname>Wang</keyname><forenames>Wenwu</forenames></author><author><keyname>Plumbley</keyname><forenames>Mark D.</forenames></author></authors><title>Fast Iterative Shrinkage for Signal Declipping and Dequantization</title><categories>eess.SP</categories><comments>in Proceedings of iTWIST'18, Paper-ID: 4, Marseille, France,
  November, 21-23, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of recovering a sparse signal from clipped or
quantized measurements. We show how these two problems can be formulated as
minimizing the distance to a convex feasibility set, which provides a convex
and differentiable cost function. We then propose a fast iterative
shrinkage/thresholding algorithm that minimizes the proposed cost, which
provides a fast and efficient algorithm to recover sparse signals from clipped
and quantized measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01570</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01570</id><created>2018-12-04</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Wang</keyname><forenames>Wenwu</forenames></author><author><keyname>Kilic</keyname><forenames>Volkan</forenames></author></authors><title>Intensity Particle Flow SMC-PHD Filter For Audio Speaker Tracking</title><categories>cs.SD eess.AS</categories><comments>In Proceedings of the LOCATA Challenge Workshop - a satellite event
  of IWAENC 2018 (arXiv:1811.08482 )</comments><report-no>LOCATAchallenge/2018/04</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-zero diffusion particle flow Sequential Monte Carlo probability
hypothesis density (NPF-SMC-PHD) filtering has been recently introduced for
multi-speaker tracking. However, the NPF does not consider the missing
detection which plays a key role in estimation of the number of speakers with
their states. To address this limitation, we propose to use intensity particle
flow (IPF) in NPFSMC-PHD filter. The proposed method, IPF-SMC-PHD, considers
the clutter intensity and detection probability while no data association
algorithms are used for the calculation of particle flow. Experiments on the
LOCATA (acoustic source Localization and Tracking) dataset with the sequences
of task 4 show that our proposed IPF-SMC-PHD filter improves the tracking
performance in terms of estimation accuracy as compared to its baseline
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01731</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01731</id><created>2018-12-04</created><authors><author><keyname>Mun</keyname><forenames>Seongkyu</forenames></author><author><keyname>Shon</keyname><forenames>Suwon</forenames></author></authors><title>Domain Mismatch Robust Acoustic Scene Classification using Channel
  Information Conversion</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent acoustic scene classification (ASC) research field, training and
test device channel mismatch have become an issue for the real world
implementation. To address the issue, this paper proposes a channel domain
conversion using factorized hierarchical variational autoencoder. Proposed
method adapts both the source and target domain to a pre-defined specific
domain. Unlike the conventional approach, the relationship between the target
and source domain and information of each domain are not required in the
adaptation process. Based on the experimental results using the IEEE detection
and classification of acoustic scenes and event 2018 task 1-B dataset and the
baseline system, it is shown that the proposed approach can mitigate the
channel mismatching issue of different recording devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01767</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01767</id><created>2018-12-04</created><authors><author><keyname>Wen</keyname><forenames>Qingsong</forenames></author><author><keyname>Gao</keyname><forenames>Jingkun</forenames></author><author><keyname>Song</keyname><forenames>Xiaomin</forenames></author><author><keyname>Sun</keyname><forenames>Liang</forenames></author><author><keyname>Xu</keyname><forenames>Huan</forenames></author><author><keyname>Zhu</keyname><forenames>Shenghuo</forenames></author></authors><title>RobustSTL: A Robust Seasonal-Trend Decomposition Algorithm for Long Time
  Series</title><categories>cs.LG eess.SP stat.AP stat.ML</categories><comments>Accepted to the thirty-third AAAI Conference on Artificial
  Intelligence (AAAI 2019), 9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decomposing complex time series into trend, seasonality, and remainder
components is an important task to facilitate time series anomaly detection and
forecasting. Although numerous methods have been proposed, there are still many
time series characteristics exhibiting in real-world data which are not
addressed properly, including 1) ability to handle seasonality fluctuation and
shift, and abrupt change in trend and reminder; 2) robustness on data with
anomalies; 3) applicability on time series with long seasonality period. In the
paper, we propose a novel and generic time series decomposition algorithm to
address these challenges. Specifically, we extract the trend component robustly
by solving a regression problem using the least absolute deviations loss with
sparse regularization. Based on the extracted trend, we apply the the non-local
seasonal filtering to extract the seasonality component. This process is
repeated until accurate decomposition is obtained. Experiments on different
synthetic and real-world time series datasets demonstrate that our method
outperforms existing solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01779</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01779</id><created>2018-12-03</created><authors><author><keyname>Gupta</keyname><forenames>Vibhuti</forenames></author></authors><title>Voice Disorder Detection Using Long Short Term Memory (LSTM) Model</title><categories>q-bio.QM cs.LG cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated detection of voice disorders with computational methods is a recent
research area in the medical domain since it requires a rigorous endoscopy for
the accurate diagnosis. Efficient screening methods are required for the
diagnosis of voice disorders so as to provide timely medical facilities in
minimal resources. Detecting Voice disorder using computational methods is a
challenging problem since audio data is continuous due to which extracting
relevant features and applying machine learning is hard and unreliable. This
paper proposes a Long short term memory model (LSTM) to detect pathological
voice disorders and evaluates its performance in a real 400 testing samples
without any labels. Different feature extraction methods are used to provide
the best set of features before applying LSTM model for classification. The
paper describes the approach and experiments that show promising results with
22% sensitivity, 97% specificity and 56% unweighted average recall.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01780</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01780</id><created>2018-12-03</created><authors><author><keyname>Rida</keyname><forenames>Imad</forenames></author></authors><title>Feature Extraction for Temporal Signal Recognition: An Overview</title><categories>eess.AS cs.SD eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Due to the huge progress of the recording devices, data from heterogeneous
nature can be recorded, such as spatial, temporal and spatio-temporal.
Nowadays, time-based data is of particular interest since it has the ability to
capture the characteristics evolution of the data over time. The temporal data
could be gait, auditory scene, piece of music, and so on. In this paper, we are
particularly interested in feature extraction for two different temporal
recognition applications namely, audio and human behavior analysis and
recognition. Indeed, relevant and discriminative features are of critical and
fundamental importance to achieve high performances in any automatic pattern
recognition system. This work is intended to provide researchers with a brief
overview of the different existing features through an understanding of basic
taxonomies which may serve as a reference to identify the adequate features for
a specific task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01833</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01833</id><created>2018-12-05</created><updated>2018-12-07</updated><authors><author><keyname>Boon</keyname><forenames>Tay Yong</forenames></author><author><keyname>Rongde</keyname><forenames>Ian Tay</forenames></author><author><keyname>Yi</keyname><forenames>Loy Liang</forenames></author><author><keyname>Fun</keyname><forenames>Aw Ke</forenames></author><author><keyname>Li</keyname><forenames>Ong Zhi</forenames></author><author><keyname>Manzhos</keyname><forenames>Sergei</forenames></author></authors><title>A Scheme for Ultrasensitive Detection of Molecules by Using Vibrational
  Spectroscopy in Combination with Signal Processing</title><categories>physics.comp-ph eess.SP</categories><comments>17 pages, 1 table, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that combining vibrational spectroscopy with signal processing can
result in a scheme for ultrasensitive detection of molecules. We consider the
vibrational spectrum as a signal on the energy axis and apply a matched filter
on that axis. On the example of a nerve agent molecule, we show that this
allows detecting a molecule by its vibrational spectrum even when the recorded
spectrum is completely buried in noise, when conventional spectroscopic
detection is impossible. Detection is predicted to be possible with
signal-to-noise ratios in recorded spectra as low as 0.1. We study the
importance of spectral range used for detection as well as of the quality of
the computed spectrum used to program the filter, specifically, the role of
anharmonicity, of the exchange correlation functional, and of the basis set.
The use of the full spectral range rather than of a narrow spectral window with
key vibrations is shown to be advantageous, as well as accounting for
anharmonicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01874</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01874</id><created>2018-12-05</created><authors><author><keyname>Hu</keyname><forenames>Qiyang</forenames></author><author><keyname>Waelchli</keyname><forenames>Adrian</forenames></author><author><keyname>Portenier</keyname><forenames>Tiziano</forenames></author><author><keyname>Zwicker</keyname><forenames>Matthias</forenames></author><author><keyname>Favaro</keyname><forenames>Paolo</forenames></author></authors><title>Video Synthesis from a Single Image and Motion Stroke</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new method to automatically generate a video
sequence from a single image and a user provided motion stroke. Generating a
video sequence based on a single input image has many applications in visual
content creation, but it is tedious and time-consuming to produce even for
experienced artists. Automatic methods have been proposed to address this
issue, but most existing video prediction approaches require multiple input
frames. In addition, generated sequences have limited variety since the output
is mostly determined by the input frames, without allowing the user to provide
additional constraints on the result. In our technique, users can control the
generated animation using a sketch stroke on a single input image. We train our
system such that the trajectory of the animated object follows the stroke,
which makes it both more flexible and more controllable. From a single image,
users can generate a variety of video sequences corresponding to different
sketch inputs. Our method is the first system that, given a single frame and a
motion stroke, can generate animations by recurrently generating videos frame
by frame. An important benefit of the recurrent nature of our architecture is
that it facilitates the synthesis of an arbitrary number of generated frames.
Our architecture uses an autoencoder and a generative adversarial network (GAN)
to generate sharp texture images, and we use another GAN to guarantee that
transitions between frames are realistic and smooth. We demonstrate the
effectiveness of our approach on the MNIST, KTH, and Human 3.6M datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01932</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01932</id><created>2018-12-05</created><authors><author><keyname>Dorffer</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>Lab-STICC UMR 6285, CNRS, ENSTA Bretagne</affiliation></author><author><keyname>Dr&#xe9;meau</keyname><forenames>Ang&#xe9;lique</forenames><affiliation>Lab-STICC UMR 6285, CNRS, ENSTA Bretagne</affiliation></author><author><keyname>Herzet</keyname><forenames>Cedric</forenames><affiliation>INRIA Centre Rennes-Bretagne Atlantique and Lab-STICC UMR 6285, CNRS, IMT-Atlantique</affiliation></author></authors><title>Efficient atom selection strategy for iterative sparse approximations</title><categories>eess.SP</categories><comments>in Proceedings of iTWIST'18, Paper-ID: 14, Marseille, France,
  November, 21-23, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a low-computational strategy for the efficient implementation of
the &quot;atom selection step&quot; in sparse representation algorithms. The proposed
procedure is based on simple tests enabling to identify subsets of atoms which
cannot be selected. Our procedure applies on both discrete or continuous
dictionaries. Experiments performed on DOA and Gaussian deconvolution problems
show the computational gain induced by the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01951</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01951</id><created>2018-12-05</created><authors><author><keyname>Kamal</keyname><forenames>Uday</forenames></author><author><keyname>Rafi</keyname><forenames>Abdul Muntakim</forenames></author><author><keyname>Hoque</keyname><forenames>Rakibul</forenames></author><author><keyname>Hasan</keyname><forenames>Md. Kamrul</forenames></author></authors><title>Lung Cancer Tumor Region Segmentation Using Recurrent 3D-DenseUNet</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lung cancer is one of the most severe and widespread that constitutes a major
public health problem and has a high mortality rate. In this regard, proper
segmentation of lung tumor from X-ray, Computed Tomography (CT scan) or,
Magnetic Resonance Imaging (MRI) is the stepping stone towards achieving
completely automated diagnosis system for lung cancer detection. With the
advancement of technology and availability of data, the valuable time of a
radiologist can be saved using computer tools for tumor segmentation. In this
work, we present a data driven approach for lung tumor segmentation from CT
scans by using Recurrent 3D-DenseUNet, a novel fusion of Convolutional and
Recurrent neural network. Our approach is to train this network using
image-volumes with tumor only slices of size (256 X 256 X 8). A data-driven
adaptive weighting method is also used in our approach to differentiate between
tumorous and non-tumorous image-slices, which shows more promise than crude
intensity thresholding of 0.70, that we have used in this work for competition
purpose. Our model has been trained and tested on the NSCLC-Radiomics dataset
of 260 patients, provided by The Cancer Imaging Archive (TCIA) for 2018 IEEE
VIP Cup. In this dataset, our proposed approach achieves an average dice score
of 0.74, mean surface distance of 1.719 and 95% Hausdorff distance of 7.249.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01989</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.01989</id><created>2018-12-05</created><authors><author><keyname>Salafian</keyname><forenames>Bahareh</forenames></author><author><keyname>Kafieh</keyname><forenames>Rahele</forenames></author><author><keyname>Rashno</keyname><forenames>Abdolreza</forenames></author><author><keyname>Pourazizi</keyname><forenames>Mohsen</forenames></author><author><keyname>Sadri</keyname><forenames>Saeid</forenames></author></authors><title>Automatic Segmentation of Choroid Layer in EDI OCT Images Using Graph
  Theory in Neutrosophic Space</title><categories>eess.IV</categories><comments>36 pages, 25 figures and 2 tables</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The choroid is vascular tissue located underneath the retina and supplies
oxygen to the outer retina; any damage to this tissue can be a precursor to
retinal disease. Choroid is almost invisible in Enhanced Depth Imaging Optical
Coherence Tomography (EDI-OCT) images and it is hard for an ophthalmologist to
detect this layer manually. This paper presents an automatic method of
choroidal segmentation from EDI-OCT images in neutrosophic space. In
neutrosophic approach for image processing, extracting any information from an
image and applying any process on it, is modeled by three sets including true,
false, and indeterminacy sets. At first, we transform each image to the
neutrosophic space; then, we calculate weights between each two nodes and apply
the Dijkstra algorithm in order to detect Retinal Pigment Epithelium (RPE)
layer. Based on RPE localization and applying gamma correction and homomorphic
filter to false set, we segment choroid layer by similar approach used for RPE.
The proposed algorithm is tested on 32 EDI OCT images of Heidelberg 3D OCT
Spectralis from 11 people and is compared with manual segmentation. The results
showed an unsigned error of 3.34 pixels (12.9 Micrometer) for macular images
and 6.55 pixels (25.3 Micrometer) for prepapillary images; which macular error
is lower than two other methods (7.71 pixels and 9.79 pixels). Furthermore, the
proposed method on prepapillary data is novel and published works are
concentrated on macular data. Identification of the boundary can help to
determine the loss or change of choroid, which can be used as features for
automatic determination of the retinal diseases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02030</identifier>
 <datestamp>2019-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02030</id><created>2018-12-05</created><updated>2019-03-19</updated><authors><author><keyname>Liu</keyname><forenames>Dongzhu</forenames></author><author><keyname>Zhu</keyname><forenames>Guangxu</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author></authors><title>Wireless Data Acquisition for Edge Learning: Data-Importance Aware
  Retransmission</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>This is an updated version: 1) extension to general classifiers; 2)
  consideration of imbalanced classification in the experiments. Submitted to
  IEEE Journal for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By deploying machine-learning algorithms at the network edge, edge learning
can leverage the enormous real-time data generated by billions of mobile
devices to train AI models, which enable intelligent mobile applications. In
this emerging research area, one key direction is to efficiently utilize radio
resources for wireless data acquisition to minimize the latency of executing a
learning task at an edge server. Along this direction, we consider the specific
problem of retransmission decision in each communication round to ensure both
reliability and quantity of those training data for accelerating model
convergence. To solve the problem, a new retransmission protocol called
data-importance aware automatic-repeat-request (importance ARQ) is proposed.
Unlike the classic ARQ focusing merely on reliability, importance ARQ
selectively retransmits a data sample based on its uncertainty which helps
learning and can be measured using the model under training. Underpinning the
proposed protocol is a derived elegant communication-learning relation between
two corresponding metrics, i.e., signal-to-noise ratio (SNR) and data
uncertainty. This relation facilitates the design of a simple threshold based
policy for importance ARQ. The policy is first derived based on the classic
classifier model of support vector machine (SVM), where the uncertainty of a
data sample is measured by its distance to the decision boundary. The policy is
then extended to the more complex model of convolutional neural networks (CNN)
where data uncertainty is measured by entropy. Extensive experiments have been
conducted for both the SVM and CNN using real datasets with balanced and
imbalanced distributions. Experimental results demonstrate that importance ARQ
effectively copes with channel fading and noise in wireless data acquisition to
achieve faster model convergence than the conventional channel-aware ARQ.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02048</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02048</id><created>2018-12-05</created><authors><author><keyname>Aref</keyname><forenames>Vahid</forenames></author></authors><title>Nonlinear Fourier Transform of Truncated Multi-Soliton Pulses</title><categories>cs.IT eess.SP math.IT</categories><comments>This paper has been accepted for presentation at 12th ITG Conference
  on Systems, Communications and Coding (SCC) 2019, Feb. 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-soliton pulses, as special solutions of the Nonlinear Schroedinger
Equation (NLSE), are potential candidates for optical fiber transmission where
the information is modulated and recovered in the so-called nonlinear Fourier
domain. For data communication, the exponentially decaying tails of a
multi-soliton must be truncated. Such a windowing changes the nonlinear Fourier
spectrum of the pulse. The results of this paper are twofold: (i) we derive the
simple closed-form expressions for the nonlinear spectrum, discrete and
continuous spectrum, of a symmetrically truncated multi-soliton pulse from
tight approximation of the truncated tails. We numerically show the accuracy of
the closed-form expressions. (ii) We show how to find, in general, the
eigenvalues of the discrete spectrum from the continuous spectrum. We present
this method for the application in hand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02092</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02092</id><created>2018-12-05</created><updated>2018-12-06</updated><authors><author><keyname>Aref</keyname><forenames>Vahid</forenames></author><author><keyname>Le</keyname><forenames>Son T.</forenames></author><author><keyname>Buelow</keyname><forenames>Henning</forenames></author></authors><title>An Efficient Nonlinear Fourier Transform Algorithm for Detection of
  Eigenvalues from Continuous Spectrum</title><categories>cs.IT eess.SP math.IT</categories><comments>This paper has been accepted for presentation at the Optical
  Networking and Communication Conference &amp; Exhibition (OFC) 2019, March 2019-
  Presentation Number: M1I.5</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an efficient, fast and robust Nonlinear Fourier Transform (NFT)
algorithm to detect eigenvalues of the discrete spectrum. It outperforms other
known NFT algorithms as it detects the eigenvalues from the continuous
spectrum, the numerically more robust part of the nonlinear spectrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02109</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02109</id><created>2018-12-05</created><authors><author><keyname>Wang</keyname><forenames>Fen</forenames></author><author><keyname>Cheung</keyname><forenames>Gene</forenames></author><author><keyname>Wang</keyname><forenames>Yongchao</forenames></author></authors><title>Low-complexity Graph Sampling with Noise and Signal Reconstruction via
  Neumann Series</title><categories>eess.SP</categories><doi>10.1109/TSP.2019.2940129</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph sampling addresses the problem of selecting a node subset in a graph to
collect samples, so that a K-bandlimited signal can be reconstructed in high
fidelity. Assuming an independent and identically distributed (i.i.d.) noise
model, minimizing the expected mean square error (MMSE) leads to the known
A-optimality criterion for graph sampling, which is expensive to compute and
difficult to optimize. In this paper, we propose an augmented objective based
on Neumann series that well approximates the original criterion and is amenable
to greedy optimization. Specifically, we show that a shifted A-optimal
criterion can be equivalently written as a function of an ideal low-pass (LP)
graph filter, which in turn can be approximated efficiently via fast graph
Fourier transform (FGFT). Minimizing the new objective, we select nodes
greedily without large matrix inversions using a matrix inverse lemma. Further,
for the dynamic network case where node availability varies across time, we
propose an extended sampling strategy that replaces offline samples one-by-one
in the selected set. For signal reconstruction, we propose an accompanied
biased signal recovery strategy that reuses the approximated filter from
sampling. Experiments show that our reconstruction is more robust to large
noise than the least square (LS) solution, and our sampling strategy far
outperforms several existing schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02146</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02146</id><created>2018-12-04</created><authors><author><keyname>Ma</keyname><forenames>Xiaofu</forenames></author><author><keyname>Guha</keyname><forenames>Sayantan</forenames></author><author><keyname>Choi</keyname><forenames>Junsung</forenames></author><author><keyname>Anderson</keyname><forenames>Christopher R</forenames></author><author><keyname>Nealy</keyname><forenames>Randall</forenames></author><author><keyname>Withers</keyname><forenames>Jared</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey H</forenames></author><author><keyname>Dietrich</keyname><forenames>Carl</forenames></author></authors><title>Analysis of directional antenna for railroad crossing safety
  applications</title><categories>eess.SP</categories><comments>IEEE Annual Consumer Communications &amp; Networking Conference (CCNC),
  2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rapidly deployable and cost-effective railroad crossing early warning
system integrated with the railway system is attractive due to its protection
of the unmanned grade crossings, which requires a warning system with
long-distance communication link. In this paper, we investigate the problem of
suitable antenna selection for such a railway warning system First, the antenna
criteria for railroad crossing safety applications are described based on
practical system considerations, the safe distances on the road and on the
railway. Then, the optimal antenna pattern is derived theoretically to get the
smallest size which fits for the practical installation. We also conducted a
feasibility study of an array antenna through measurements on a near field
scanner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02172</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02172</id><created>2018-12-05</created><authors><author><keyname>Ma</keyname><forenames>Xiaofu</forenames></author><author><keyname>Czauski</keyname><forenames>Thaddeus</forenames></author><author><keyname>Yang</keyname><forenames>Taeyoung</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey H</forenames></author></authors><title>Demonstration Paper: Wirelessly Sensing Medication Administration:
  Cyber-Physical Event Detection and Notification Utilizing Multi-Element
  Chipless RFID</title><categories>eess.SP</categories><comments>Proceedings of the Wireless Health 2014 on National Institutes of
  Health</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medication administration is one pathway by which Adverse Drug Events (ADE)
can occur. While Electronic Medical Administration Record (eMAR) systems help
reduce the number of ADEs, current eMAR implementations suffer from workarounds
that defeat safety and verification mechanisms meant to limit the number of
potential ADEs that occur during medication administration. In this paper, we
introduce Multi-Element ChipLess (MECL) RFID tags which enable real-time event
notifications through event signatures. Event signatures correspond to the
physical configuration of different RFID elements in a chipless RFID tag.
Augmenting physical objects, such as a pill container, with MECL-RFID can allow
caregivers to detect the moment a particular pill container is opened or
closed. We present the fundamentals behind real-time event detection using
MECL-RFID and propose a cyber-physical intervention system that can be used to
reduce ADEs through realtime event monitoring and notifications sent to
clinicians administering medication. We also present a prototype MECL-RFID to
demonstrate potential future improvements to eMAR systems that minimize ADEs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02339</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02339</id><created>2018-12-05</created><updated>2019-07-19</updated><authors><author><keyname>Tian</keyname><forenames>Qiao</forenames></author><author><keyname>Wan</keyname><forenames>Xucheng</forenames></author><author><keyname>Liu</keyname><forenames>Shan</forenames></author></authors><title>Generative Adversarial Network based Speaker Adaptation for High
  Fidelity WaveNet Vocoder</title><categories>eess.AS cs.SD</categories><comments>5 pages, 4 figure, 1 table, 6 equations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although state-of-the-art parallel WaveNet has addressed the issue of
real-time waveform generation, there remains problems. Firstly, due to the
noisy input signal of the model, there is still a gap between the quality of
generated and natural waveforms. Secondly, a parallel WaveNet is trained under
a distillation framework, which makes it tedious to adapt a well trained model
to a new speaker. To address these two problems, in this paper we propose an
end-to-end adaptation method based on the generative adversarial network (GAN),
which can reduce the computational cost for the training of new speaker
adaptation. Our subjective experiments shows that the proposed training method
can further reduce the quality gap between generated and natural waveforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02366</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02366</id><created>2018-12-06</created><authors><author><keyname>Li</keyname><forenames>Shiyong</forenames></author><author><keyname>Amin</keyname><forenames>Moeness</forenames></author><author><keyname>Zhao</keyname><forenames>Guoqiang</forenames></author><author><keyname>Sun</keyname><forenames>Houjun</forenames></author></authors><title>Radar Imaging by Sparse Optimization Incorporating MRF Clustering Prior</title><categories>eess.SP</categories><comments>5 pages, 10 figures, IEEE Geoscience and Remote Sensing Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent progress in compressive sensing states the importance of exploiting
intrinsic structures in sparse signal reconstruction. In this letter, we
propose a Markov random field (MRF) prior in conjunction with fast iterative
shrinkagethresholding algorithm (FISTA) for image reconstruction. The MRF prior
is used to represent the support of sparse signals with clustered nonzero
coefficients. The proposed approach is applied to the inverse synthetic
aperture radar (ISAR) imaging problem. Simulations and experimental results are
provided to demonstrate the performance advantages of this approach in
comparison with the standard FISTA and existing MRF-based methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02373</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02373</id><created>2018-12-06</created><authors><author><keyname>Wen</keyname><forenames>Dingzhu</forenames></author><author><keyname>Zhu</keyname><forenames>Guangxu</forenames></author><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author></authors><title>Reduced-Dimension Design of MIMO Over-the-Air Computing for Data
  Aggregation in Clustered IoT Networks</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>Submitted to IEEE Journal for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One basic operation of Internet-of-Things (IoT) networks is aggregating
distributed sensing-data over wireless-channels for function-computation,
called wireless-data-aggregation (WDA). Targeting dense sensors, a recently
developed technology called over-the-air computing (AirComp) can dramatically
reduce the WDA latency by aggregating distributed data &quot;over-the-air&quot; using the
waveform-superposition property of a multi-access channel. In this work, we
design multiple-input-multiple-output (MIMO) AirComp for computing a
vector-valued function in a clustered IoT network with multi-antenna sensors
forming clusters and a multi-antenna access-point (AP) performing WDA. The
resultant high-dimensional but low-rank MIMO channels makes it important to
reduce channel or signal dimensionality in AirComp to avoid exposure to noise
from channel null-spaces. Motivated by this, we develop a framework of
reduced-dimension MIMO AirComp, featuring decomposed-aggregation-beamforming
(DAB). Consider the case of separable channel-clusters with non-overlapping
angle-of-arrival ranges. The optimal DAB has the structure where
inner-components extract the dominant eigen-spaces of corresponding
channel-clusters and outer-components jointly equalize the resultant
low-dimensional channels. Consider the more complex case of inseparable
clusters. We propose a suboptimal DAB design where the inner-component performs
both dimension-reduction and joint-equalization over clustered-channel
covariance matrices and the outer-component jointly equalizes the small-scale
fading-channels. Furthermore, efficient algorithms for rank-optimization of
individual DAB components and channel-feedback leveraging the AirComp principle
are developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02399</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02399</id><created>2018-12-06</created><authors><author><keyname>A&#x11f;caer</keyname><forenames>Semih</forenames></author><author><keyname>Martin</keyname><forenames>Rainer</forenames></author></authors><title>Binaural Source Localization based on Modulation-Domain Features and
  Decision Pooling</title><categories>cs.SD eess.AS</categories><comments>In Proceedings of the LOCATA Challenge Workshop - a satellite event
  of IWAENC 2018 (arXiv:1811.08482)</comments><report-no>LOCATAchallenge/2018/12</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we apply Amplitude Modulation Spectrum (AMS) features to the
source localization problem. Our approach computes 36 bilateral features for 2s
long signal segments and estimates the azimuthal directions of a sound source
through a binaurally trained classifier. This directional information of a
sound source could be e.g. used to steer the beamformer in a hearing aid to the
source of interest in order to increase the SNR. We evaluated our approach on
the development set of the IEEE-AASP Challenge on sound source localization and
tracking (LOCATA) and achieved a 4.25{\deg} smaller MAE than the baseline
approach. Additionally, our approach is computationally less complex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02447</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02447</id><created>2018-12-06</created><authors><author><keyname>Meghanani</keyname><forenames>Amit</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>A G</forenames></author></authors><title>Pitch-synchronous DCT features: A pilot study on speaker identification</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new feature, namely, pitchsynchronous discrete cosine transform
(PS-DCT), for the task of speaker identification. These features are obtained
directly from the voiced segments of the speech signal, without any preemphasis
or windowing. The feature vectors are vector quantized, to create one separate
codebook for each speaker during training. The performance of the PS-DCT
features is shown to be good, and hence it can be used to supplement other
features for the speaker identification task. Speaker identification is also
performed using Mel-frequency cepstral coefficient (MFCC) features and combined
with the proposed features to improve its performance. For this pilot study, 30
speakers (14 female and 16 male) have been picked up randomly from the TIMIT
database for the speaker identification task. On this data, both the proposed
features and MFCC give an identification accuracy of 90% and 96.7% for codebook
sizes of 16 and 32, respectively, and the combined features achieve 100%
performance. Apart from the speaker identification task, this work also shows
the capability of DCT to capture discriminative information from the speech
signal with minimal pre-processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02455</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02455</id><created>2018-12-06</created><authors><author><keyname>Liu</keyname><forenames>Dan</forenames></author><author><keyname>Liu</keyname><forenames>Junhua</forenames></author><author><keyname>Guo</keyname><forenames>Wu</forenames></author><author><keyname>Xiong</keyname><forenames>Shifu</forenames></author><author><keyname>Ma</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Song</keyname><forenames>Rui</forenames></author><author><keyname>Wu</keyname><forenames>Chongliang</forenames></author><author><keyname>Liu</keyname><forenames>Quan</forenames></author></authors><title>The USTC-NEL Speech Translation system at IWSLT 2018</title><categories>cs.CL cs.SD eess.AS</categories><comments>5 pages, 8 tabels</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the USTC-NEL system to the speech translation task of
the IWSLT Evaluation 2018. The system is a conventional pipeline system which
contains 3 modules: speech recognition, post-processing and machine
translation. We train a group of hybrid-HMM models for our speech recognition,
and for machine translation we train transformer based neural machine
translation models with speech recognition output style text as input.
Experiments conducted on the IWSLT 2018 task indicate that, compared to
baseline system from KIT, our system achieved 14.9 BLEU improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02483</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02483</id><created>2018-12-06</created><authors><author><keyname>Jameel</keyname><forenames>Furqan</forenames></author><author><keyname>Wyne</keyname><forenames>Shurjeel</forenames></author><author><keyname>Nawaz</keyname><forenames>Syed Junaid</forenames></author><author><keyname>Chang</keyname><forenames>Zheng</forenames></author></authors><title>Propagation Channels for mmWave Vehicular Communications:
  State-of-the-art and Future Research Directions</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular communications essentially support automotive applications for
safety and infotainment. For this reason, industry leaders envision an enhanced
role of vehicular communications in the fifth generation of mobile
communications technology. Over the years, the number of vehicle-mounted
sensors has increased steadily, which potentially leads to more volume of
critical data communications in a short time. Also, emerging applications such
as remote/autonomous driving and infotainment such as high-definition movie
streaming require data-rates on the order of multiple Gbit/s. Such high
data-rates require a large system bandwidth, but very limited bandwidth is
available in the sub-6 GHz cellular bands. This has sparked research interest
in the millimeter wave (mmWave) band (10 GHz-300 GHz), where a large bandwidth
is available to support the high data-rate and low-latency communications
envisioned for emerging vehicular applications. However, leveraging mmWave
communications requires a thorough understanding of the relevant vehicular
propagation channels, which are significantly different from those investigated
below 6 GHz. Despite their significance, very few investigations of mmWave
vehicular channels are reported in the literature. This work highlights the key
attributes of mmWave vehicular communication channels and surveys the recent
literature on channel characterization efforts in order to provide a gap
analysis and propose possible directions for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02506</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02506</id><created>2018-12-06</created><authors><author><keyname>Salem</keyname><forenames>Abdelhamid</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author></authors><title>Sum Rate and Fairness Analysis for the MU-MIMO Downlink under PSK
  Signalling: Interference Suppression vs Exploitation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the sum rate performance of multi-user
multiple-input multiple-output (MU-MIMO) systems, with a finite constellation
phase-shift keying (PSK) input alphabet. We analytically calculate and compare
the achievable sum rate in three downlink transmission scenarios: 1) without
precoding, 2) with zero forcing (ZF) precoding 3) with closed form constructive
interference (CI) precoding technique. In light of this, new analytical
expressions for the average sum rate are derived in the three cases, and Monte
Carlo simulations are provided throughout to validate the analysis.
Furthermore, based on the derived expressions, a power allocation scheme that
can ensure fairness among the users is also proposed. The results in this work
demonstrate that, the CI strictly outperforms the other two schemes, and the
performance gap between the considered schemes increases with increase in the
MIMO size. In addition, the CI provides higher fairness and the power
allocation algorithm proposed in this paper can achieve maximum fairness index.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02538</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02538</id><created>2018-11-19</created><authors><author><keyname>Kozlowski</keyname><forenames>Michal</forenames></author><author><keyname>McConville</keyname><forenames>Ryan</forenames></author><author><keyname>Santos-Rodriguez</keyname><forenames>Raul</forenames></author><author><keyname>Piechocki</keyname><forenames>Robert</forenames></author></authors><title>Energy Efficiency in Reinforcement Learning for Wireless Sensor Networks</title><categories>eess.SP cs.LG stat.ML</categories><comments>This paper was accepted on 30/07/2018 and presented at the ECML-PKDD
  Workshop Green Data Mining 2018 on 14/09/2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As sensor networks for health monitoring become more prevalent, so will the
need to control their usage and consumption of energy. This paper presents a
method which leverages the algorithm's performance and energy consumption. By
utilising Reinforcement Learning (RL) techniques, we provide an adaptive
framework, which continuously performs weak training in an energy-aware system.
We motivate this using a realistic example of residential localisation based on
Received Signal Strength (RSS). The method is cheap in terms of work-hours,
calibration and energy usage. It achieves this by utilising other sensors
available in the environment. These other sensors provide weak labels, which
are then used to employ the State-Action-Reward-State-Action (SARSA) algorithm
and train the model over time. Our approach is evaluated on a simulated
localisation environment and validated on a widely available pervasive health
dataset which facilitates realistic residential localisation using RSS. We show
that our method is cheaper to implement and requires less effort, whilst at the
same time providing a performance enhancement and energy savings over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02585</identifier>
 <datestamp>2019-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02585</id><created>2018-12-04</created><updated>2019-01-30</updated><authors><author><keyname>Raykov</keyname><forenames>Yordan P.</forenames></author><author><keyname>Evers</keyname><forenames>Luc J. W.</forenames></author><author><keyname>Badawy</keyname><forenames>Reham</forenames></author><author><keyname>Faber</keyname><forenames>Marjan J.</forenames></author><author><keyname>Bloem</keyname><forenames>Bastiaan R.</forenames></author><author><keyname>Claes</keyname><forenames>Kasper</forenames></author><author><keyname>Little</keyname><forenames>Max A.</forenames></author></authors><title>Probabilistic modelling of gait for remote passive monitoring
  applications</title><categories>eess.SP math.PR</categories><comments>Machine Learning for Health (ML4H) Workshop at NeurIPS 2018
  arXiv:cs/0101200</comments><report-no>ML4H/2018/153</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Passive and non-obtrusive health monitoring using wearables can potentially
bring new insights into the user's health status throughout the day and may
support clinical diagnosis and treatment. However, identifying segments of
free-living data that sufficiently reflect the user's health is challenging. In
this work we have studied the problem of modelling real-life gait which is a
very indicative behaviour for multiple movement disorders including Parkinson's
disease (PD). We have developed a probabilistic framework for unsupervised
analysis of the gait, clustering it into different types, which can be used to
evaluate gait abnormalities occurring in daily life. Using a unique dataset
which contains sensor and video recordings of people with and without PD in
their own living environment, we show that our model driven approach achieves
high accuracy gait detection and can capture clinical improvement after
medication intake.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02588</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02588</id><created>2018-12-04</created><updated>2018-12-20</updated><authors><author><keyname>Sadiq</keyname><forenames>Alishba</forenames></author><author><keyname>Usman</keyname><forenames>Muhammad</forenames></author><author><keyname>Khan</keyname><forenames>Shujaat</forenames></author><author><keyname>Naseem</keyname><forenames>Imran</forenames></author><author><keyname>Moinuddin</keyname><forenames>Muhammad</forenames></author><author><keyname>Al-Saggaf</keyname><forenames>Ubaid M.</forenames></author></authors><title>q-LMF: Quantum Calculus-based Least Mean Fourth Algorithm</title><categories>eess.SP cs.LG cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel estimation is an essential part of modern communication systems as it
enhances the overall performance of the system. In recent past a variety of
adaptive learning methods have been designed to enhance the robustness and
convergence speed of the learning process. However, the need for an optimal
technique is still there. Herein, for non-Gaussian noisy environment we propose
a new class of stochastic gradient algorithm for channel identification. The
proposed $q$-least mean fourth ($q$-LMF) is an extension of least mean fourth
(LMF) algorithm and it is based on the $q$-calculus which is also known as
Jackson derivative. The proposed algorithm utilizes a novel concept of
error-correlation energy and normalization of signal to ensure high convergence
rate, better stability and low steady-state error. Contrary to the conventional
LMF, the proposed method has more freedom for large step-sizes. Extensive
experiments show significant gain in the performance of the proposed $q$-LMF
algorithm in comparison to the contemporary techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02615</identifier>
 <datestamp>2019-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02615</id><created>2018-12-06</created><updated>2019-04-08</updated><authors><author><keyname>Shang</keyname><forenames>Jin</forenames></author><author><keyname>Farooq</keyname><forenames>Muhammad Junaid</forenames></author><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author></authors><title>Real-Time Transmission Mechanism Design for Wireless IoT Sensors with
  Energy Harvesting under Power Saving Mode</title><categories>cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet of things (IoT) comprises of wireless sensors and actuators
connected via access points to the Internet. Often, the sensing devices are
remotely deployed with limited battery power and are equipped with energy
harvesting equipment. These devices transmit real-time data to the base station
(BS), which is used in applications such as anomaly detection. Under sufficient
power availability, wireless transmissions from sensors can be scheduled at
regular time intervals to maintain real-time data acquisition. However, once
the battery is significantly depleted, the devices enter into power saving mode
and need to be more selective in transmitting information to the BS.
Transmitting a particular piece of sensed data consumes power while discarding
it may result in loss of utility at the BS. The goal is to design an optimal
dynamic policy which enables the device to decide whether to transmit or to
discard a piece of sensing data particularly under the power saving mode. This
will enable the sensor to prolong its operation while causing minimum loss of
utility to the application. We develop an analytical framework to capture the
utility of the IoT sensor transmissions and leverage dynamic programming based
approach to derive an optimal real-time transmission policy that is based on
the statistics of information arrival, the likelihood of harvested energy, and
designed lifetime of the sensors. Numerical results show that if the statistics
of future data valuation are accurately predicted, there is a significant
increase in utility obtained at the BS as well as the battery lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02617</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02617</id><created>2018-12-04</created><authors><author><keyname>Hattab</keyname><forenames>Ghaith</forenames></author><author><keyname>Cabric</keyname><forenames>Danijela</forenames></author></authors><title>Distributed Wideband Spatio-Spectral Sensing for Unlicensed Massive IoT
  Communications</title><categories>eess.SP</categories><comments>This paper is accepted for publication in the IEEE Global
  Communications Conference 2018 (GLOBECOM'18)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a dynamic spectrum sensing-based architecture to
provide connectivity for a massive number of Internet-of-things (IoT) objects
over the unlicensed spectrum. Specifically, the architecture relies on
deploying sensing access points (SAPs), e.g., small cells with sensing
capabilities, that aim to (i) identify a large number of narrowband channels in
a wideband spectrum, as many massive IoT applications have low-rate
requirements, and (ii) aggressively reuse the unlicensed channels at the SAPs'
locations as IoT devices typically transmit at low power, occupying a small
spatial footprint. Instead of enforcing each SAP to sense the entire spectrum,
we develop a sensing assignment scheduler that ensures each one senses a subset
of the spectrum. We then develop a distributed spatio-spectral cooperative
sensing algorithm that enables each SAP to have local information about the
occupancy of the entire spectrum. We present numerical simulations to validate
the effectiveness of the proposed system in the presence of WiFi access points
(APs). It is shown that the proposed system outperforms non-cooperative and
centralized schemes in terms of reliably identifying more available
spatio-spectral blocks with a lower misdetection of transmitting WiFi APs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02658</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02658</id><created>2018-12-06</created><updated>2019-07-16</updated><authors><author><keyname>Hu</keyname><forenames>Xiaoyan</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author><author><keyname>Yang</keyname><forenames>Kun</forenames></author><author><keyname>Zheng</keyname><forenames>Zhongbin</forenames></author></authors><title>UAV-Assisted Relaying and Edge Computing: Scheduling and Trajectory
  Optimization</title><categories>eess.SP</categories><comments>14 pages, 8 figures</comments><doi>10.1109/TWC.2019.2928539</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study an unmanned aerial vehicle (UAV)-assisted mobile edge
computing (MEC) architecture, in which a UAV roaming around the area may serve
as a computing server to help user equipment (UEs) compute their tasks or act
as a relay for further offloading their computation tasks to the access point
(AP). We aim to minimize the weighted sum energy consumption of the UAV and UEs
subject to the task constraints, the information-causality constraints, the
bandwidth allocation constraints and the UAV's trajectory constraints. The
required optimization is nonconvex, and an alternating optimization algorithm
is proposed to jointly optimize the computation resource scheduling, bandwidth
allocation, and the UAV's trajectory in an iterative fashion. Numerical results
demonstrate that significant performance gain is obtained over conventional
methods. Also, the advantages of the proposed algorithm are more prominent when
handling computation-intensive latency-critical tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02705</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02705</id><created>2018-12-06</created><authors><author><keyname>Klautau</keyname><forenames>Aldebaro</forenames></author></authors><title>Frequency Tracking: LMS and RLS Applied to Speech Formant Estimation
  (2000)</title><categories>eess.AS cs.SD eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Introduction Several speech processing algorithms assume the signal is
stationary during short intervals (approximately 20 to 30 ms). This assumption
is valid for several applications, but it is too restrictive in some contexts.
This work investigates the application of adaptive signal processing to the
problem of estimating the formant frequencies of speech. Two algorithms were
implemented and tested. The first one is the conventional Least-Mean-Square
(LMS) algorithm, and the second is the conventional Recursive Least-Squares
(RLS) algorithm. The formant frequencies are the resonant frequencies of the
vocal tract. The speech is the result of the convolution between the excitation
and the vocal tract impulse response [Rabiner, 78], thus a kind of
&quot;deconvolution&quot; is required to recover the formants. This is not an easy
problem because one does not have the excitation signal available. There are
several algorithms for formant estimation [Rabiner, 78], [Snell, 93], [Laprie,
94
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02724</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02724</id><created>2018-11-30</created><authors><author><keyname>Vazirizade</keyname><forenames>Sayyed Mohsen</forenames></author><author><keyname>Bakhshi</keyname><forenames>Ali</forenames></author><author><keyname>Bahar</keyname><forenames>Omid</forenames></author></authors><title>Structural Damage Detection Using Ensemble Empirical Mode Decomposition,
  Hilbert Transform and Artificial Neural Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Civil structures are on the verge of changing which leads energy dissipation
capacity to decline. Structural Health Monitoring (SHM) as a process in order
to implement a damage detection strategy and assess the condition of structure
plays a key role in structural reliability. Earthquake is a recognized factor
in variation of structures condition, inasmuch as inelastic behavior of a
building subjected to design level earthquakes is plausible. In this study
Hilbert Huang Transformation (HHT) is superseded by Ensemble Empirical Mode
decomposition (EEMD) and Hilbert Transform (HT) together. Albeit analogous,
EEMD brings more appropriate Intrinsic Mode Functions (IMFs) than Empirical
Mode Decomposition (EMD). IMFs are employed to assess first mode frequency and
mode shape. Afterward, Artificial Neural Networks (ANN) is applied to predict
story acceleration based on acceleration of structure during previous moments.
ANN functions precisely. Therefore, any congruency between predicted and
measured acceleration provides onset of damage. Then another ANN method is
applied to estimate stiffness matrix. Though first mode shape and frequency is
calculated in advance, it essentially requires an inverse problem to be solved
in order to find stiffness matrix. This task is done by ANN. In other words,
these two ANN methods are exercised to forecast location and measure severity
of damage respectively. This algorithm is implemented on one nonlinear
moment-resisting steel frame and the results are acceptable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02752</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02752</id><created>2018-11-25</created><authors><author><keyname>Khalili</keyname><forenames>Masoomeh</forenames></author><author><keyname>Ghatee</keyname><forenames>Mehdi</forenames></author><author><keyname>Teimouri</keyname><forenames>Mehdi</forenames></author><author><keyname>Bejani</keyname><forenames>Mohammad Mahdi</forenames></author></authors><title>Roadside acoustic sensors to support vulnerable pedestrians via their
  smartphone</title><categories>eess.SP</categories><comments>7 Pages, 8 Figures, 4 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new warning system based on smartphones that evaluates the risk
of motor vehicle for vulnerable pedestrian (VP). The acoustic sensors are
embedded in roadside to receive vehicles sounds and they are classified into
heavy vehicle, light vehicle with low speed, light vehicle with high speed, and
no vehicle classes. For this aim, we extract new features by Mel-frequency
Cepstrum Coefficients (MFCC) and Linear Predictive Coefficients (LPC)
algorithms. We use different classification algorithms and show that MLP neural
network achieves at least 96.77% in accuracy criterion. To install this system,
directional microphones are embedded on roadside and the risk is classified
there. Then, for every microphone, a danger area is defined and the warning
alarms have been sent to every VPs smartphones covered in this danger area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02760</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02760</id><created>2018-12-06</created><updated>2019-02-01</updated><authors><author><keyname>Rodriguez-Fernandez</keyname><forenames>Javier</forenames></author><author><keyname>Lopez-Valcarce</keyname><forenames>Roberto</forenames></author><author><keyname>Gonzalez-Prelcic</keyname><forenames>Nuria</forenames></author></authors><title>Hybrid precoding and combining for frequency-selective mmWave MIMO
  Systems with per-antenna power constraints</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Configuring hybrid precoders and combiners is a major challenge to deploy
practical mmWave communication systems. Prior work addresses the problem of
designing hybrid precoders and combiner, yet focusing on finding solutions
under a total transmit power constraint. The design of hybrid precoders and
combiners in practical system, is constrained, however, by a per antenna
transmit power, since each antenna element in the array is connected to a power
amplifier (PA) that has to operate within its linear region. In this paper, we
focus on the problem of hybrid precoding and combining with per-antenna power
constraints, and under a frequency-selective bandlimited channel model. We
first propose an all-digital solution to this problem, and develop a hybrid
precoding and combining strategy that aims at matching this solution by
minimizing the chordal distance between the all-digital precoders (combiners)
and their hybrid approximations. Finally, since minimizing this metric does not
guarantee that the final spectral efficiency will be maximized, we optimize the
resulting spectral efficiency taking into account the per-antenna power
constraints. Simulation results show the effectiveness of our all-digital and
hybrid solutions, while emphasizing the differences with respect to the
corresponding solution under a total power constraints. As shown in our
numerical results, the proposed all-digital solution performs similarly to the
case in which a total power constraint is considered. Further, our proposed
hybrid solution is also shown to exhibit near-optimum performance, and the
influence of different system parameters is also shown, thereby showing the
suitability of our proposed framework to deploy practical mmWave MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02792</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02792</id><created>2018-12-06</created><authors><author><keyname>Hosseini</keyname><forenames>Nozhan</forenames></author><author><keyname>Jamal</keyname><forenames>Hosseinali</forenames></author><author><keyname>Matolak</keyname><forenames>David W.</forenames></author><author><keyname>Haque</keyname><forenames>Jamal</forenames></author><author><keyname>Magesacher</keyname><forenames>Thomas</forenames></author></authors><title>UAV Command and Control, Navigation and Surveillance: A Review of
  Potential 5G and Satellite Systems</title><categories>eess.SP</categories><comments>10 pages, 5 figures, IEEE aerospace conference</comments><report-no>N. Hosseini, H. Jamal, J. Haque, T. Magesacher and D. W. Matolak,
  &quot;UAV Command and Control, Navigation and Surveillance: A Review of Potential
  5G and Satellite Systems,&quot; 2019 IEEE Aerospace Conference, Big Sky, MT, USA,
  2019, pp. 1-10</report-no><journal-ref>2019 IEEE Aerospace Conference, Big Sky, MT, USA, 2019, pp. 1-10</journal-ref><doi>10.1109/AERO.2019.8741719</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Drones, unmanned aerial vehicles (UAVs), or unmanned aerial systems (UAS) are
expected to be an important component of 5G/beyond 5G (B5G) communications.
This includes their use within cellular architectures (5G UAVs), in which they
can facilitate both wireless broadcast and point-to-point transmissions,
usually using small UAS (sUAS). Allowing UAS to operate within airspace along
with commercial, cargo, and other piloted aircraft will likely require
dedicated and protected aviation spectrum at least in the near term, while
regulatory authorities adapt to their use. The command and control (C2), or
control and non-payload communications (CNPC) link provides safety critical
information for the control of the UAV both in terrestrial-based line of sight
(LOS) conditions and in satellite communication links for so-called beyond LOS
(BLOS) conditions. In this paper, we provide an overview of these CNPC links as
they may be used in 5G and satellite systems by describing basic concepts and
challenges. We review new entrant technologies that might be used for UAV C2 as
well as for payload communication, such as millimeter wave (mmWave) systems,
and also review navigation and surveillance challenges. A brief discussion of
UAV-to-UAV communication and hardware issues are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02800</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02800</id><created>2018-12-06</created><authors><author><keyname>Montenbruck</keyname><forenames>Jan Maximilian</forenames></author><author><keyname>Zeng</keyname><forenames>Shen</forenames></author></authors><title>On Lossless Causal Compression of Periodic Signals</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and study a scheme for lossless causal compression of periodic
real-valued signals. In particular, our technique compresses a vector-valued
signal to a scalar-valued signal by mixing it with another periodic signal. The
conditions for being able to reconstruct the original signal then amount to
certain non-resonances between the periods of the two signals. The proposed
compression scheme turns out to implicitly be inherent to communication
networks with round-robin scheduling and digital photography with active pixel
sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02865</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02865</id><created>2018-12-06</created><authors><author><keyname>Mokatren</keyname><forenames>Lubna Shibly</forenames></author><author><keyname>Ansari</keyname><forenames>Rashid</forenames></author><author><keyname>Cetin</keyname><forenames>Ahmet Enis</forenames></author><author><keyname>Leow</keyname><forenames>Alex D.</forenames></author><author><keyname>Ajilore</keyname><forenames>Olusola</forenames></author><author><keyname>Klumpp</keyname><forenames>Heide</forenames></author><author><keyname>Vural</keyname><forenames>Fatos T. Yarman</forenames></author></authors><title>EEG Classification based on Image Configuration in Social Anxiety
  Disorder</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of detecting the presence of Social Anxiety Disorder (SAD) using
Electroencephalography (EEG) for classification has seen limited study and is
addressed with a new approach that seeks to exploit the knowledge of EEG sensor
spatial configuration. Two classification models, one which ignores the
configuration (model 1) and one that exploits it with different interpolation
methods (model 2), are studied. Performance of these two models is examined for
analyzing 34 EEG data channels each consisting of five frequency bands and
further decomposed with a filter bank. The data are collected from 64 subjects
consisting of healthy controls and patients with SAD. Validity of our
hypothesis that model 2 will significantly outperform model 1 is borne out in
the results, with accuracy $6$--$7\%$ higher for model 2 for each machine
learning algorithm we investigated. Convolutional Neural Networks (CNN) were
found to provide much better performance than SVM and kNNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02871</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02871</id><created>2018-12-06</created><authors><author><keyname>Gong</keyname><forenames>Xiao</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author></authors><title>A Low-rank Tensor Dictionary Learning Method for Multi-spectral Images
  Denoising</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a 3-order tensor, a multi-spectral image (MSI) has dozens of spectral
bands, which can deliver more information for real scenes. However, real MSIs
are often corrupted by noises in the sensing process, which will further
deteriorate the performance of higher-level classification and recognition
tasks. In this paper, we propose a Low-rank Tensor Dictionary Learning (LTDL)
method for MSI denoising. Firstly, we extract blocks from the MSI and cluster
them into groups. Then instead of using the exactly low-rank model, we consider
a nearly low-rank approximation, which is closer to the latent low-rank
structure of the clean groups of real MSIs. In addition, we propose to learn an
spatial dictionary and an spectral dictionary, which contain the spatial
features and spectral features respectively of the whole MSI and are shared
among different groups. Hence the LTDL method utilizes both the latent low-rank
prior of each group and the correlation of different groups via the shared
dictionaries. Experiments on synthetic data validate the effectiveness of
dictionary learning by the LTDL. Experiments on real MSIs demonstrate the
superior denoising performance of the proposed method in comparison to
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02910</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02910</id><created>2018-12-07</created><authors><author><keyname>Wang</keyname><forenames>Xuehe</forenames></author><author><keyname>Duan</keyname><forenames>Lingjie</forenames></author></authors><title>Dynamic Pricing and Capacity Allocation of UAV-provided Mobile Services</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to its agility and mobility, the unmanned aerial vehicle (UAV) is a
promising technology to provide high-quality mobile services (e.g., fast
Internet access, edge computing, and local caching) to ground users. Major
Internet Service Providers (ISPs) want to enable UAV-provided services (UPS) to
improve and enrich the current mobile services for additional profit. This
profit-maximization problem is not easy as the UAV has limited energy storage
and needs to fly closely to serve users, requiring an optimal energy allocation
for balancing both hovering time and service capacity. When hovering in a
hotspot, how the UAV should dynamically price its capacity-limited UPS
according to randomly arriving users with private service valuations is another
question. We prove that the UAV should ask for a higher price if the leftover
hovering time is longer or its service capacity is smaller, and its expected
profit approaches to that under complete user information if the hovering time
is sufficiently large. As the hotspot's user occurrence rate increases, a
shorter hovering time or a larger service capacity should be allocated.
Finally, when the UAV faces multiple hotspot candidates with different user
occurrence rates and flying distances, we prove that it is optimal to deploy
the UAV to serve a single hotspot. With multiple UAVs, however, this result can
be reversed with UAVs' forking deployment to different hotspots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.02966</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.02966</id><created>2018-12-07</created><authors><author><keyname>Haugdal</keyname><forenames>Hallvar</forenames></author><author><keyname>Uhlen</keyname><forenames>Kjetil</forenames></author></authors><title>Mode Shape Estimation using Complex Principal Component Analysis and
  k-Means Clustering</title><categories>eess.SP</categories><comments>8 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an empirical method for identifying low damped modes and
corresponding mode shapes using frequency measurements from a Wide Area
Monitoring System. The method consists of two main steps: Firstly, Complex
Principal Component Analysis is used in combination with the Hilbert Transform
and Empirical Mode Decomposition to provide estimates of modes and mode shapes.
The estimates are stored as multidimensional points. Secondly, the points are
grouped using a clustering algorithm, and new averaged estimates of modes and
mode shapes are computed as the centroids of the clusters. Applying the method
on data resulting from a non-linear power system simulator yields estimates of
dominant modes and corresponding mode shapes that are similar to those
resulting from modal analysis of the linearized system model. Encouraged by the
results, the method is further tested with real PMU data at transmission grid
level. Initial results indicate that the performance of the proposed method is
promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03021</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03021</id><created>2018-12-07</created><authors><author><keyname>Jarne</keyname><forenames>Cecilia</forenames></author><author><keyname>Alcain</keyname><forenames>Pablo N.</forenames></author></authors><title>A method to align time series segments based on envelope features as
  anchor points</title><categories>eess.SP cs.SD eess.AS</categories><journal-ref>ANALES AFA, [S.l.], v. 30, n. 3, p. 68-71, oct. 2019. ISSN
  1850-1168</journal-ref><doi>10.31527/analesafa.2019.30.3.68</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the time series analysis field, there is not a unique recipe for studying
signal similarities. On the other hand, averaging signals of the same nature is
an essential tool in the analysis of different kinds of data. Here we propose a
method to align and average segments of time series with similar patterns. A
simple implementation based on \textit{python} code is provided for the
procedure. The analysis was inspired by the study of canary sound syllables,
but it is possible to apply it in semi periodic signals of different nature and
not necessarily related to sounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03091</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03091</id><created>2018-12-07</created><authors><author><keyname>Daher</keyname><forenames>Elie Bou</forenames></author></authors><title>Analysis and Design of Nonuniform Arrays for Direction Finding</title><categories>eess.SP</categories><comments>Ph.D. Dissertation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this research is to employ non-uniform arrays in different
active and passive sensing applications for both narrowband and wideband
operations, while providing a multitude of array processing methodologies that
assist in dealing with the different encountered challenges. The problem of
direction-of-arrival (DOA) estimation using non-uniform arrays is considered.
The different challenges that are treated include the reduction of the
available degrees-of-freedom (DOFs), the presence of coherent targets, and the
mutual coupling effect in practical antenna arrays. Multi-frequency operation
is exploited to increase the DOFs that are available for DOA estimation using
both high-resolution subspace and sparse reconstruction techniques. In
addition, a sparsity-based interpolation technique is presented to perform DOA
estimation with increased DOFs. Moreover, a DOA estimation approach for a
mixture of coherent and uncorrelated targets based on sparse reconstruction and
active non-uniform arrays under narrowband signal platform is proposed. The
aforementioned approaches deal with ideal operational scenarios. To address a
more practical scenario, various methods for DOA estimation using non-uniform
arrays in the presence of mutual coupling are presented. Extensive numerical
simulations which validate the different proposed methods are also included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03109</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03109</id><created>2018-12-02</created><authors><author><keyname>Soltani</keyname><forenames>Mohammad Dehghani</forenames></author><author><keyname>Arfaoui</keyname><forenames>Mohamed Amine</forenames></author><author><keyname>Tavakkolnia</keyname><forenames>Iman</forenames></author><author><keyname>Ghrayeb</keyname><forenames>Ali</forenames></author><author><keyname>Safari</keyname><forenames>Majid</forenames></author><author><keyname>Assi</keyname><forenames>Chadi</forenames></author><author><keyname>Hasna</keyname><forenames>Mazen</forenames></author><author><keyname>Haas</keyname><forenames>Harald</forenames></author></authors><title>Bidirectional Optical Spatial Modulation for Mobile Users: Towards a
  Practical Design for LiFi Systems</title><categories>eess.SP</categories><comments>30 pages, 14 figures, Journal paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among the challenges of realizing the full potential of light-fidelity (LiFi)
cellular networks are user mobility, random device orientation and blockage. We
study the impact of those challenges on the performance of LiFi in an indoor
environment using measurement-based channel models. We adopt spatial modulation
(SM), which has been shown to be energy efficient in many applications,
including LiFi. We consider two configurations for placing the photodiodes
(PDs) on the user equipment (UE). The first one is referred to as the screen
receiver (SR) whereby all the PDs are located on one face of the UE, whereas
the other one is a multi-directional receiver (MDR), in which the PDs are
located on different sides of the UE. The latter configuration was motivated by
the fact that SR exhibited poor performance in the presence of random device
orientation and blockage. We show that MDR outperforms SR by over $10$ dB at
BER of $3.8\times10^{-3}$. Moreover, an adaptive access point (AP) selection
scheme for SM is considered where the number of APs are chosen adaptively in an
effort to achieve the lowest energy requirement for a target BER and spectral
efficiency. The user performance with random orientation and blockage in the
whole room is evaluated for sitting and walking activities. For the latter, we
invoke the orientation-based random waypoint (ORWP) mobility model. We also
study the performance of the underlying system on the uplink channel where the
same techniques are used for the downlink channel. Specifically, as the
transmitted uplink power is constrained, the energy efficiency of SM is
evaluated analytically. It is shown that the multi-directional transmitter
(MDT) with adaptive SM is highly energy efficient. As a benchmark, we compare
the performance of the proposed framework to that of the conventional spatial
multiplexing system, and demonstrate the superiority of the proposed one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03111</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03111</id><created>2018-12-07</created><authors><author><keyname>Ma</keyname><forenames>Haoyi</forenames></author><author><keyname>Acton</keyname><forenames>Scott T.</forenames></author><author><keyname>Lin</keyname><forenames>Zongli</forenames></author></authors><title>SITUP: Scale Invariant Tracking using Average Peak-to-Correlation Energy</title><categories>eess.IV</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust and accurate scale estimation of a target object is a challenging task
in visual object tracking. Most existing tracking methods cannot accommodate
large scale variation in complex image sequences and thus result in inferior
performance. In this paper, we propose to incorporate a novel criterion called
the average peak-to-correlation energy into the multiresolution translation
filter framework to obtain robust and accurate scale estimation. The resulting
system is named SITUP: Scale Invariant Tracking using Average
Peak-to-Correlation Energy. SITUP effectively tackles the problem of fixed
template size in standard discriminative correlation filter based trackers.
Extensive empirical evaluation on the publicly available tracking benchmark
datasets demonstrates that the proposed scale searching framework meets the
demands of scale variation challenges effectively while providing superior
performance over other scale adaptive variants of standard discriminative
correlation filter based trackers. Also, SITUP obtains favorable performance
compared to state-of-the-art trackers for various scenarios while operating in
real-time on a single CPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03156</identifier>
 <datestamp>2018-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03156</id><created>2018-12-07</created><authors><author><keyname>Bastopcu</keyname><forenames>Melih</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Scheduling a Human Channel</title><categories>cs.IT cs.NI cs.SY eess.SP math.IT math.OC</categories><comments>Appeared at Asilomar Conference, October 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a system where a human operator processes a sequence of tasks
that are similar in nature under a total time constraint. In these systems, the
performance of the operator depends on its past utilization. This is akin to
$\textit{state-dependent}$ channels where the past actions of the transmitter
affects the future quality of the channel (also known as
$\textit{action-dependent}$ or $\textit{use-dependent}$ channels). For
$\textit{human channels}$, a well-known psychological phenomena, known as
$\textit{Yerkes-Dodson law}$, states that a human operator performs worse when
he/she is over-utilized or under-utilized. Over such a $\textit{use-dependent}$
human channel, we consider the problem of maximizing a utility function, which
is monotonically increasing and concave in the time allocated for each task,
under explicit minimum and maximum $\textit{utilization}$ constraints. We show
that the optimal solution is to keep the utilization ratio of the operator as
high as possible, and to process all the tasks. We prove that the optimal
policy consists of two major strategies: utilize the operator without resting
until reaching the maximum allowable utilization ratio, and then alternate
between working and resting the operator each time reaching the maximum
allowable utilization at the end of work-period. We show that even though the
tasks are similar in difficulty, the time allocated for the tasks can be
different depending on the strategy in which a task is processed; however, the
tasks processed in the same strategy are processed equally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03203</identifier>
 <datestamp>2018-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03203</id><created>2018-12-07</created><authors><author><keyname>Zheng</keyname><forenames>Xiangtian</forenames></author><author><keyname>Wang</keyname><forenames>Bin</forenames></author><author><keyname>Xie</keyname><forenames>Le</forenames></author></authors><title>Synthetic Dynamic PMU Data Generation: A Generative Adversarial Network
  Approach</title><categories>eess.SP cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper concerns with the production of synthetic phasor measurement unit
(PMU) data for research and education purposes. Due to the confidentiality of
real PMU data and no public access to the real power systems infrastructure
information, the lack of credible realistic data becomes a growing concern.
Instead of constructing synthetic power grids and then producing synthetic PMU
measurement data by time simulations, we propose a model-free approach to
directly generate synthetic PMU data. we train the generative adversarial
network (GAN) with real PMU data, which can be used to generate synthetic PMU
data capturing the system dynamic behaviors. To validate the sequential
generation by GAN to mimic PMU data, we theoretically analyze GAN's capacity of
learning system dynamics. Further by evaluating the synthetic PMU data by a
proposed quantitative method, we verify GAN's potential to synthesize realistic
samples and meanwhile realize that GAN model in this paper still has room to
improve. Moreover it is the first time that such generative model is applied to
synthesize PMU data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03278</identifier>
 <datestamp>2018-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03278</id><created>2018-12-08</created><authors><author><keyname>Liu</keyname><forenames>Fang</forenames></author><author><keyname>Chen</keyname><forenames>Lihua</forenames></author><author><keyname>Kijowski</keyname><forenames>Richard</forenames></author><author><keyname>Feng</keyname><forenames>Li</forenames></author></authors><title>SANTIS: Sampling-Augmented Neural neTwork with Incoherent Structure for
  MR image reconstruction</title><categories>cs.CV eess.IV physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning holds great promise in the reconstruction of undersampled
Magnetic Resonance Imaging (MRI) data, providing new opportunities to escalate
the performance of rapid MRI. In existing deep learning-based reconstruction
methods, supervised training is performed using artifact-free reference images
and their corresponding undersampled pairs. The undersampled images are
generated by a fixed undersampling pattern in the training, and the trained
network is then applied to reconstruct new images acquired with the same
pattern in the inference. While such a training strategy can maintain a
favorable reconstruction for a pre-selected undersampling pattern, the
robustness of the trained network against any discrepancy of undersampling
schemes is typically poor. We developed a novel deep learning-based
reconstruction framework called SANTIS for efficient MR image reconstruction
with improved robustness against sampling pattern discrepancy. SANTIS uses a
data cycle-consistent adversarial network combining efficient end-to-end
convolutional neural network mapping, data fidelity enforcement and adversarial
training for reconstructing accelerated MR images more faithfully. A training
strategy employing sampling augmentation with extensive variation of
undersampling patterns was further introduced to promote the robustness of the
trained network. Compared to conventional reconstruction and standard deep
learning methods, SANTIS achieved consistent better reconstruction performance,
with lower errors, greater image sharpness and higher similarity with respect
to the reference regardless of the undersampling patterns during inference.
This novel concept behind SANTIS can particularly be useful towards improving
the robustness of deep learning-based image reconstruction against discrepancy
between training and evaluation, which is currently an important but less
studied open question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03279</identifier>
 <datestamp>2018-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03279</id><created>2018-12-08</created><authors><author><keyname>Mejstrik</keyname><forenames>Thomas</forenames></author><author><keyname>Evangelista</keyname><forenames>Gianpaolo</forenames></author></authors><title>Estimates of the Reconstruction Error in Partially Redressed Warped
  Frames Expansions</title><categories>cs.SD eess.AS math.NA</categories><comments>8 pages, 5 figures, 4 tables, conference paper</comments><journal-ref>Proc. of Digital Audio Effect Conf. (DAFx'16). Brno, Czech
  Republic, September 2016, pp. 9-16</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent work, redressed warped frames have been introduced for the analysis
and synthesis of audio signals with non-uniform frequency and time resolutions.
In these frames, the allocation of frequency bands or time intervals of the
elements of the representation can be uniquely described by means of a warping
map. Inverse warping applied after time-frequency sampling provides the key to
reduce or eliminate dispersion of the warped frame elements in the conjugate
variable, making it possible, e.g., to construct frequency warped frames with
synchronous time alignment through frequency. The redressing procedure is
however exact only when the analysis and synthesis windows have compact support
in the domain where warping is applied. This implies that frequency warped
frames cannot have compact support in the time domain. This property is
undesirable when online computation is required. Approximations in which the
time support is finite are however possible, which lead to small reconstruction
errors. In this paper we study the approximation error for compactly supported
frequency warped analysis-synthesis elements, providing a few examples and case
studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03315</identifier>
 <datestamp>2020-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03315</id><created>2018-12-08</created><authors><author><keyname>Cheng</keyname><forenames>Cheng</forenames></author><author><keyname>Ma</keyname><forenames>Guijun</forenames></author><author><keyname>Zhang</keyname><forenames>Yong</forenames></author><author><keyname>Sun</keyname><forenames>Mingyang</forenames></author><author><keyname>Teng</keyname><forenames>Fei</forenames></author><author><keyname>Ding</keyname><forenames>Han</forenames></author><author><keyname>Yuan</keyname><forenames>Ye</forenames></author></authors><title>Online Bearing Remaining Useful Life Prediction Based on a Novel
  Degradation Indicator and Convolutional Neural Networks</title><categories>cs.LG eess.SP stat.ML</categories><doi>10.1109/TMECH.2020.2971503</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In industrial applications, nearly half the failures of motors are caused by
the degradation of rolling element bearings (REBs). Therefore, accurately
estimating the remaining useful life (RUL) for REBs are of crucial importance
to ensure the reliability and safety of mechanical systems. To tackle this
challenge, model-based approaches are often limited by the complexity of
mathematical modeling. Conventional data-driven approaches, on the other hand,
require massive efforts to extract the degradation features and construct
health index. In this paper, a novel online data-driven framework is proposed
to exploit the adoption of deep convolutional neural networks (CNN) in
predicting the RUL of bearings. More concretely, the raw vibrations of training
bearings are first processed using the Hilbert-Huang transform (HHT) and a
novel nonlinear degradation indicator is constructed as the label for learning.
The CNN is then employed to identify the hidden pattern between the extracted
degradation indicator and the vibration of training bearings, which makes it
possible to estimate the degradation of the test bearings automatically.
Finally, testing bearings' RULs are predicted by using a $\epsilon$-support
vector regression model. The superior performance of the proposed RUL
estimation framework, compared with the state-of-the-art approaches, is
demonstrated through the experimental results. The generality of the proposed
CNN model is also validated by transferring to bearings undergoing different
operating conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03347</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03347</id><created>2018-12-08</created><updated>2019-06-24</updated><authors><author><keyname>Shipilov</keyname><forenames>D.</forenames></author><author><keyname>Bezyazeekov</keyname><forenames>P. A.</forenames></author><author><keyname>Budnev</keyname><forenames>N. M.</forenames></author><author><keyname>Chernykh</keyname><forenames>D.</forenames></author><author><keyname>Fedorov</keyname><forenames>O.</forenames></author><author><keyname>Gress</keyname><forenames>O. A.</forenames></author><author><keyname>Haungs</keyname><forenames>A.</forenames></author><author><keyname>Hiller</keyname><forenames>R.</forenames></author><author><keyname>Huege</keyname><forenames>T.</forenames></author><author><keyname>Kazarina</keyname><forenames>Y.</forenames></author><author><keyname>Kleifges</keyname><forenames>M.</forenames></author><author><keyname>Korosteleva</keyname><forenames>E. E.</forenames></author><author><keyname>Kostunin</keyname><forenames>D.</forenames></author><author><keyname>Kuzmichev</keyname><forenames>L. A.</forenames></author><author><keyname>Lenok</keyname><forenames>V.</forenames></author><author><keyname>Lubsandorzhiev</keyname><forenames>N.</forenames></author><author><keyname>Marshalkina</keyname><forenames>T.</forenames></author><author><keyname>Monkhoev</keyname><forenames>R.</forenames></author><author><keyname>Osipova</keyname><forenames>E.</forenames></author><author><keyname>Pakhorukov</keyname><forenames>A.</forenames></author><author><keyname>Pankov</keyname><forenames>L.</forenames></author><author><keyname>Prosin</keyname><forenames>V. V.</forenames></author><author><keyname>Schr&#xf6;der</keyname><forenames>F. G.</forenames></author><author><keyname>Zagorodnikov</keyname><forenames>A.</forenames></author></authors><title>Signal recognition and background suppression by matched filters and
  neural networks for Tunka-Rex</title><categories>astro-ph.IM cs.LG eess.SP</categories><comments>ARENA2018 proceedings</comments><doi>10.1051/epjconf/201921602003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Tunka Radio Extension (Tunka-Rex) is a digital antenna array, which
measures the radio emission of the cosmic-ray air-showers in the frequency band
of 30-80 MHz. Tunka-Rex is co-located with TAIGA experiment in Siberia and
consists of 63 antennas, 57 of them are in a densely instrumented area of about
1 km\textsuperscript{2}. In the present work we discuss the improvements of the
signal reconstruction applied for the Tunka-Rex. At the first stage we
implemented matched filtering using averaged signals as template. The
simulation study has shown that matched filtering allows one to decrease the
threshold of signal detection and increase its purity. However, the maximum
performance of matched filtering is achievable only in case of white noise,
while in reality the noise is not fully random due to different reasons. To
recognize hidden features of the noise and treat them, we decided to use
convolutional neural network with autoencoder architecture. Taking the recorded
trace as an input, the autoencoder returns denoised trace, i.e. removes all
signal-unrelated amplitudes. We present the comparison between standard method
of signal reconstruction, matched filtering and autoencoder, and discuss the
prospects of application of neural networks for lowering the threshold of
digital antenna arrays for cosmic-ray detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03358</identifier>
 <datestamp>2018-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03358</id><created>2018-12-08</created><authors><author><keyname>McGaffin</keyname><forenames>Madison G.</forenames></author><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Fessler</keyname><forenames>Jeffrey A.</forenames></author><author><keyname>Sick</keyname><forenames>Volker</forenames></author></authors><title>A practical light transport system model for chemiluminescence
  distribution reconstruction</title><categories>eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Plenoptic cameras and other integral photography instruments capture richer
angular information from a scene than traditional 2D cameras. This extra
information is used to estimate depth, perform superresolution or reconstruct
3D information from the scene. Many of these applications involve solving a
large-scale numerical optimization problem. Most published approaches model the
camera(s) using pre-computed matrices that require large amounts of memory and
are not well-suited to modern many-core processors. We propose a flexible
camera model based on light transport and use it to model plenoptic and
traditional cameras. We implement the proposed model on a GPU and use it to
reconstruct simulated and real 3D chemiluminescence distributions (flames) from
images taken by traditional and plenoptic cameras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03415</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03415</id><created>2018-12-08</created><updated>2019-08-03</updated><authors><author><keyname>Das</keyname><forenames>Sagnik</forenames></author><author><keyname>Gandhi</keyname><forenames>Nisha</forenames></author><author><keyname>Naik</keyname><forenames>Tejas</forenames></author><author><keyname>Shilkrot</keyname><forenames>Roy</forenames></author></authors><title>Increase Apparent Public Speaking Fluency By Speech Augmentation</title><categories>cs.SD eess.AS</categories><journal-ref>2019 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)</journal-ref><doi>10.1109/ICASSP.2019.8682937</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluent and confident speech is desirable to every speaker. But professional
speech delivering requires a great deal of experience and practice. In this
paper, we propose a speech stream manipulation system which can help
non-professional speakers to produce fluent, professional-like speech content,
in turn contributing towards better listener engagement and comprehension. We
propose to achieve this task by manipulating the disfluencies in human speech,
like the sounds 'uh' and 'um', the filler words and awkward long silences.
Given any unrehearsed speech we segment and silence the filled pauses and
doctor the duration of imposed silence as well as other long pauses
('disfluent') by a predictive model learned using professional speech dataset.
Finally, we output a audio stream in which speaker sounds more fluent,
confident and practiced compared to the original speech he/she recorded.
According to our quantitative evaluation, we significantly increase the fluency
of speech by reducing rate of pauses and fillers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03483</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03483</id><created>2018-12-09</created><updated>2019-02-14</updated><authors><author><keyname>Adi</keyname><forenames>Yossi</forenames></author><author><keyname>Zeghidour</keyname><forenames>Neil</forenames></author><author><keyname>Collobert</keyname><forenames>Ronan</forenames></author><author><keyname>Usunier</keyname><forenames>Nicolas</forenames></author><author><keyname>Liptchinsky</keyname><forenames>Vitaliy</forenames></author><author><keyname>Synnaeve</keyname><forenames>Gabriel</forenames></author></authors><title>To Reverse the Gradient or Not: An Empirical Comparison of Adversarial
  and Multi-task Learning in Speech Recognition</title><categories>cs.LG cs.CL cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transcribed datasets typically contain speaker identity for each instance in
the data. We investigate two ways to incorporate this information during
training: Multi-Task Learning and Adversarial Learning. In multi-task learning,
the goal is speaker prediction; we expect a performance improvement with this
joint training if the two tasks of speech recognition and speaker recognition
share a common set of underlying features. In contrast, adversarial learning is
a means to learn representations invariant to the speaker. We then expect
better performance if this learnt invariance helps generalizing to new
speakers. While the two approaches seem natural in the context of speech
recognition, they are incompatible because they correspond to opposite
gradients back-propagated to the model. In order to better understand the
effect of these approaches in terms of error rates, we compare both strategies
in controlled settings. Moreover, we explore the use of additional
untranscribed data in a semi-supervised, adversarial learning manner to improve
error rates. Our results show that deep models trained on big datasets already
develop invariant representations to speakers without any auxiliary loss. When
considering adversarial learning and multi-task learning, the impact on the
acoustic model seems minor. However, models trained in a semi-supervised manner
can improve error-rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03492</identifier>
 <datestamp>2019-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03492</id><created>2018-12-09</created><authors><author><keyname>Sheikhi</keyname><forenames>Mohammad Amin</forenames></author><author><keyname>Razavizadeh</keyname><forenames>S. Mohammad</forenames></author></authors><title>Security Vulnerability of FDD Massive MIMO Systems in Downlink Training
  Phase</title><categories>cs.CR cs.IT eess.SP math.IT</categories><comments>Presented in International Symposium on Telecommunication (IST2018)
  IEEE conference</comments><journal-ref>2018 9th International Symposium on Telecommunications (IST),
  Tehran, Iran, 2018, pp. 492-496</journal-ref><doi>10.1109/ISTEL.2018.8661082</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider downlink channel training of a frequency division duplex (FDD)
massive multiple-input-multiple-output (MIMO) system when a multi-antenna
jammer is present in the network. The jammer intends to degrade mean square
error (MSE) of the downlink channel training by designing an attack based on
second-order statistics of its channel. The channels are assumed to be
spatially correlated. First, a closed-form expression for the channel
estimation MSE is derived and then the jammer determines the conditions under
which the MSE is maximized. Numerical results demonstrate that the proposed
jamming can severely increase the estimation MSE even if the optimal training
signals with a large number of pilot symbols are used by the legitimate system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03629</identifier>
 <datestamp>2018-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03629</id><created>2018-12-10</created><authors><author><keyname>Zhu</keyname><forenames>Dalin</forenames></author><author><keyname>Bendlin</keyname><forenames>Ralf</forenames></author><author><keyname>Akoum</keyname><forenames>Salam</forenames></author><author><keyname>Ghosh</keyname><forenames>Arunabha</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Double-Sequence Frequency Synchronization for Wideband Millimeter-Wave
  Systems with Few-Bit ADCs</title><categories>eess.SP</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose and evaluate two novel double-sequence
low-resolution frequency synchronization methods in millimeter-wave (mmWave)
systems. In our system model, the base station uses analog beams to send the
synchronization signal with infinite-resolution digital-to-analog converters.
The user equipment employs a fully digital front end to detect the
synchronization signal with low-resolution analog-to-digital converters (ADCs).
The key ingredient of the proposed methods is the custom designed
synchronization sequence pairs, from which there exists an invertible function
(a ratio metric) of the carrier frequency offset (CFO) to be estimated. We use
numerical examples to show that the ratio metric is robust to the quantization
distortion. Further, we analytically characterize the CFO estimation
performances of our proposed designs assuming a single user. To implement our
proposed methods in a multi-user scenario, we propose to optimize the
double-sequence design parameters such that: (i) for each individual user, the
impact of the quantization distortion on the CFO estimation accuracy is
minimized, and (ii) the resulting frequency range of estimation can capture as
many users' CFOs as possible. Numerical results reveal that our proposed
algorithms provide a flexible means to estimate CFO in a variety of
low-resolution settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03640</identifier>
 <datestamp>2019-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03640</id><created>2018-12-10</created><updated>2019-06-03</updated><authors><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Zappone</keyname><forenames>Alessio</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Deep Learning Power Allocation in Massive MIMO</title><categories>eess.SP cs.IT cs.LG math.IT</categories><comments>5 pages, 2 figures; presented at ASILOMAR 2018. The training set is
  available online at https://data.ieeemlc.org while the Matlab code available
  at https://github.com/lucasanguinetti/ allows to generate further samples</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work advocates the use of deep learning to perform max-min and max-prod
power allocation in the downlink of Massive MIMO networks. More precisely, a
deep neural network is trained to learn the map between the positions of user
equipments (UEs) and the optimal power allocation policies, and then used to
predict the power allocation profiles for a new set of UEs' positions. The use
of deep learning significantly improves the complexity-performance trade-off of
power allocation, compared to traditional optimization-oriented methods.
Particularly, the proposed approach does not require the computation of any
statistical average, which would be instead necessary by using standard
methods, and is able to guarantee near-optimal performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03655</identifier>
 <datestamp>2018-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03655</id><created>2018-12-10</created><authors><author><keyname>Waheed</keyname><forenames>Muhammad Zeeshan</forenames></author><author><keyname>Campo</keyname><forenames>Pablo Pascual</forenames></author><author><keyname>Korpi</keyname><forenames>Dani</forenames></author><author><keyname>Kiayani</keyname><forenames>Adnan</forenames></author><author><keyname>Anttila</keyname><forenames>Lauri</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>Digital Cancellation of Passive Intermodulation in FDD Transceivers</title><categories>eess.SP nlin.AO</categories><comments>7 pages, 7 figures, accepted to 2018 Asilomar Conference on Signals,
  Systems, and Computers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern radio systems and transceivers utilize carrier aggregation (CA) to
meet the demands for higher and higher data rates. However, the adoption of CA
in the existing Long Term Evolution (LTE)-Advanced and emerging 5G New Radio
(NR) mobile networks, in case of frequency division duplexing (FDD), may incur
self-interference challenges with certain band combinations. More specifically,
the nonlinear distortion products of the transmit signals or component carriers
(CCs), stemming from the passive radio frequency (RF) front-end components of
the transceiver, can appear in one or more of the configured receiver bands,
potentially leading to the receiver desensitization. In this paper, we present
advanced baseband equivalent signal models for such passive intermodulation
(PIM) distortion viewed from the RX point of view, considering also potential
memory effects in the PIM generation. Then, building on these signal models, a
digital self-interference cancellation technique operating in the transceiver
digital front-end is presented. The performance of the proposed solution is
evaluated with real-life RF measurements for LTE-Advanced type user equipment
(UE) with dual CC inter-band CA, demonstrating excellent suppression
properties. The findings in this work indicate that digital cancellation is a
feasible approach for improving the receiver sensitivity of mobile devices that
may be prone to RF front-end induced PIM challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03792</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03792</id><created>2018-12-10</created><authors><author><keyname>Wan</keyname><forenames>Zhiquan</forenames></author><author><keyname>Yu</keyname><forenames>Zhenming</forenames></author><author><keyname>Shu</keyname><forenames>* Liang</forenames></author><author><keyname>Zhao</keyname><forenames>Yilun</forenames></author><author><keyname>Zhang</keyname><forenames>Haojie</forenames></author><author><keyname>Xu</keyname><forenames>Kun</forenames></author></authors><title>Intelligent optical performance monitor using multi-task learning based
  artificial neural network</title><categories>eess.SP</categories><doi>10.1364/OE.27.011281</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An intelligent optical performance monitor using multi-task learning based
artificial neural network (MTL-ANN) is designed for simultaneous OSNR
monitoring and modulation format identification (MFI). Signals' amplitude
histograms (AHs) after constant module algorithm are selected as the input
features for MTL-ANN. The experimental results of 20-Gbaud NRZ-OOK, PAM4 and
PAM8 signals demonstrate that MTL-ANN could achieve OSNR monitoring and MFI
simultaneously with higher accuracy and stability compared with single-task
learning based ANNs (STL-ANNs). The results show an MFI accuracy of 100% and
OSNR monitoring root-mean-square error of 0.63 dB for the three modulation
formats under consideration. Furthermore, the number of neuron needed for the
single MTL-ANN is almost the half of STL-ANN, which enables reduced-complexity
optical performance monitoring devices for real-time performance monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03826</identifier>
 <datestamp>2018-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03826</id><created>2018-11-27</created><authors><author><keyname>Salin</keyname><forenames>Mikhail B.</forenames></author><author><keyname>Kosteev</keyname><forenames>Dmitrii A.</forenames></author></authors><title>Examples of usage of nearfield acoustic holography methods for far field
  estimations: Part 1. CW signals</title><categories>eess.AS cs.SD physics.app-ph</categories><msc-class>78.02</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is devoted to the usage of nearfield acoustic holography methods
for estimating far field of the object. An experiment was carried out in
anechoic chamber. First, acoustic filed was recorded in a plane that was close
to source. This signals records were used to reconstruct the far field by
computation routines. Second, the signal in the far field is measured and the
results are compared. Several methods are tested and research on possible
reduction of the microphone array size is carried out. The most significant
reduction of the measurement facility complexity is usage a linear array in
stead of the planar array that is made possible due to introduced computation
routines
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03902</identifier>
 <datestamp>2018-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03902</id><created>2018-12-10</created><authors><author><keyname>Kadam</keyname><forenames>Sachin</forenames></author><author><keyname>Raut</keyname><forenames>Chaitanya S.</forenames></author><author><keyname>Meena</keyname><forenames>Amandeep</forenames></author><author><keyname>Kasbekar</keyname><forenames>Gaurav S.</forenames></author></authors><title>Fast Node Cardinality Estimation and Cognitive MAC Protocol Design for
  Heterogeneous Machine-to-Machine Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine-to-Machine (M2M) networks are an emerging technology with
applications in numerous areas including smart grids, smart cities, vehicular
telematics, and healthcare. In this paper, we design two estimation protocols
for rapidly obtaining separate estimates of the number of active nodes of each
traffic type in a heterogeneous M2M network with $T$ types of M2M nodes (e.g.,
those that send emergency, periodic, normal type data etc), where $T \geq 2$ is
an arbitrary integer. One of these protocols, Method I, is a simple scheme, and
the other, Method II, is more sophisticated and performs better than Method I.
Also, we design a medium access control (MAC) protocol that supports
multi-channel operation for a heterogeneous M2M network with an arbitrary
number of types of M2M nodes, operating as a secondary network using Cognitive
Radio technology. Our Cognitive MAC protocol uses the proposed node cardinality
estimation protocols to rapidly estimate the number of active nodes of each
type in every time frame; these estimates are used to find the optimal
contention probabilities to be used in the MAC protocol. We compute a closed
form expression for the expected number of time slots required by Method I to
execute as well as a simple upper bound on it. Also, we mathematically analyze
the performance of the Cognitive MAC protocol and obtain expressions for the
expected number of successful contentions per frame and the expected amount of
energy consumed. Finally, we evaluate the performances of our proposed
estimation protocols and Cognitive MAC protocol using simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03914</identifier>
 <datestamp>2018-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03914</id><created>2018-12-10</created><authors><author><keyname>Reddy</keyname><forenames>Chandan K A</forenames></author><author><keyname>Bhat</keyname><forenames>Gautam</forenames></author><author><keyname>Shankar</keyname><forenames>Nikhil</forenames></author><author><keyname>Panahi</keyname><forenames>Issa</forenames></author></authors><title>A Computationally Efficient and Practically Feasible Two Microphones
  Blind Speech Separation Method</title><categories>cs.SD eess.AS</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, Blind Speech Separation techniques are computationally
expensive as they update the demixing matrix at every time frame index, making
them impractical to use in many Real-Time applications. In this paper, a robust
data-driven two-microphone sound source localization method is used as a
criterion to reduce the computational complexity of the Independent Vector
Analysis (IVA) Blind Speech Separation (BSS) method. IVA is used to separate
convolutedly mixed speech and noise sources. The practical feasibility of the
proposed method is proved by implementing it on a smartphone device to separate
speech and noise in Real-World scenarios for Hearing-Aid applications. The
experimental results with objective and subjective tests reveal the practical
usability of the developed method in many real-world applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03916</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03916</id><created>2018-12-10</created><authors><author><keyname>Reddy</keyname><forenames>Chandan K A</forenames></author><author><keyname>Shankar</keyname><forenames>Nikhil</forenames></author><author><keyname>Bhat</keyname><forenames>Gautam</forenames></author><author><keyname>Charan</keyname><forenames>Ram</forenames></author><author><keyname>Panahi</keyname><forenames>Issa</forenames></author></authors><title>An individualized super Gaussian single microphone Speech Enhancement
  for hearing aid users with smartphone as an assistive device</title><categories>cs.SD eess.AS</categories><comments>5 pages</comments><doi>10.1109/LSP.2017.2750979</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we derive a new super Gaussian Joint Maximum a Posteriori
based single microphone speech enhancement gain function. The developed Speech
Enhancement method is implemented on a smartphone, and this arrangement
functions as an assistive device to hearing aids. We introduce a tradeoff
parameter in the derived gain function that allows the smartphone user to
customize their listening preference, by controlling the amount of noise
suppression and speech distortion in real-time based on their level of hearing
comfort perceived in noisy real world acoustic environment. Objective quality
and intelligibility measures show the effectiveness of the proposed method in
comparison to benchmark techniques considered in this paper. Subjective results
reflect the usefulness of the developed Speech Enhancement application in
real-world noisy conditions at signal to noise ratio levels of 0 dB and 5 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03919</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03919</id><created>2018-12-10</created><updated>2019-08-02</updated><authors><author><keyname>Wiesner</keyname><forenames>Matthew</forenames></author><author><keyname>Renduchintala</keyname><forenames>Adithya</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author><author><keyname>Liu</keyname><forenames>Chunxi</forenames></author><author><keyname>Dehak</keyname><forenames>Najim</forenames></author><author><keyname>Khudanpur</keyname><forenames>Sanjeev</forenames></author></authors><title>Pretraining by Backtranslation for End-to-end ASR in Low-Resource
  Settings</title><categories>eess.AS cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore training attention-based encoder-decoder ASR in low-resource
settings. These models perform poorly when trained on small amounts of
transcribed speech, in part because they depend on having sufficient
target-side text to train the attention and decoder networks. In this paper we
address this shortcoming by pretraining our network parameters using only
text-based data and transcribed speech from other languages. We analyze the
relative contributions of both sources of data. Across 3 test languages, our
text-based approach resulted in a 20% average relative improvement over a
text-based augmentation technique without pretraining. Using transcribed speech
from nearby languages gives a further 20-30% relative reduction in character
error rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03929</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03929</id><created>2018-12-10</created><updated>2019-10-20</updated><authors><author><keyname>Jang</keyname><forenames>Hyeryung</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Gardner</keyname><forenames>Brian</forenames></author><author><keyname>Gr&#xfc;ning</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>An Introduction to Spiking Neural Networks: Probabilistic Models,
  Learning Rules, and Applications</title><categories>eess.SP cs.IT cs.LG cs.NE math.IT stat.ML</categories><comments>This article is now superseded by arXiv:1910.01059. To appear on IEEE
  Signal Processing Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spiking Neural Networks (SNNs) are distributed trainable systems whose
computing elements, or neurons, are characterized by internal analog dynamics
and by digital and sparse synaptic communications. The sparsity of the synaptic
spiking inputs and the corresponding event-driven nature of neural processing
can be leveraged by hardware implementations that have demonstrated significant
energy reductions as compared to conventional Artificial Neural Networks
(ANNs). Most existing training algorithms for SNNs have been designed either
for biological plausibility or through conversion from pre-trained ANNs via
rate encoding. This paper aims at providing an introduction to SNNs by focusing
on a probabilistic signal processing methodology that enables the direct
derivation of learning rules leveraging the unique time encoding capabilities
of SNNs. To this end, the paper adopts discrete-time probabilistic models for
networked spiking neurons, and it derives supervised and unsupervised learning
rules from first principles by using variational inference. Examples and open
research problems are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03977</identifier>
 <datestamp>2019-03-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03977</id><created>2018-12-10</created><authors><author><keyname>Khobahi</keyname><forenames>Shahin</forenames></author><author><keyname>Soltanalian</keyname><forenames>Mojtaba</forenames></author></authors><title>Signal Recovery From 1-Bit Quantized Noisy Samples via Adaptive
  Thresholding</title><categories>cs.IT cs.SY eess.SP math.IT</categories><comments>This is a pre-print version of the original conference paper that has
  been accepted at the 2018 IEEE Asilomar Conference on Signals, Systems, and
  Computers</comments><doi>10.1109/ACSSC.2018.8645383</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of signal recovery from 1-bit noisy
measurements. We present an efficient method to obtain an estimation of the
signal of interest when the measurements are corrupted by white or colored
noise. To the best of our knowledge, the proposed framework is the pioneer
effort in the area of 1-bit sampling and signal recovery in providing a unified
framework to deal with the presence of noise with an arbitrary covariance
matrix including that of the colored noise. The proposed method is based on a
constrained quadratic program (CQP) formulation utilizing an adaptive
quantization thresholding approach, that further enables us to accurately
recover the signal of interest from its 1-bit noisy measurements. In addition,
due to the adaptive nature of the proposed method, it can recover both fixed
and time-varying parameters from their quantized 1-bit samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.03985</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.03985</id><created>2018-12-08</created><authors><author><keyname>Lin</keyname><forenames>Shengtao</forenames></author><author><keyname>Wang</keyname><forenames>Zinan</forenames></author><author><keyname>Xiong</keyname><forenames>Ji</forenames></author><author><keyname>Fu</keyname><forenames>Yun</forenames></author><author><keyname>Jiang</keyname><forenames>Jialin</forenames></author><author><keyname>Wu</keyname><forenames>Yue</forenames></author><author><keyname>Chen</keyname><forenames>Yongxiang</forenames></author><author><keyname>Lu</keyname><forenames>Chongyu</forenames></author><author><keyname>Rao</keyname><forenames>Yunjiang</forenames></author></authors><title>Rayleigh fading suppression in one-dimension optical scatters</title><categories>eess.SP physics.optics</categories><comments>9 pages, 5 figures</comments><journal-ref>IEEE Access 2019</journal-ref><doi>10.1109/ACCESS.2019.2895126</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Highly coherent wave is favorable for applications in which phase retrieval
is necessary, yet a high coherent wave is prone to encounter Rayleigh fading
phenomenon as it passes through a medium of random scatters. As an exemplary
case, phase-sensitive optical time-domain reflectometry (\Phi-OTDR) utilizes
coherent interference of backscattering light along a fiber to achieve
ultra-sensitive acoustic sensing, but sensing locations with fading won't be
functional. Apart from the sensing domain, fading is also ubiquitous in optical
imaging and wireless telecommunication, therefore it is of great interest. In
this paper, we theoretically describe and experimentally verify how the fading
phenomena in one-dimension optical scatters will be suppressed with arbitrary
number of independent probing channels. We initially theoretically explained
why fading would cause severe noise in the demodulated phase of \Phi-OTDR; then
M-degree summation of incoherent scattered light-waves is studied for the
purpose of eliminating fading. Finally, the gain of the retrieved phase
signal-to-noise-ratio and its fluctuations were analytically derived and
experimentally verified. This work provides a guideline for fading elimination
in one-dimension optical scatters, and it also provides insight for optical
imaging and wireless telecommunication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04079</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04079</id><created>2018-12-07</created><authors><author><keyname>Chambon</keyname><forenames>Stanislas</forenames></author><author><keyname>Thorey</keyname><forenames>Valentin</forenames></author><author><keyname>Arnal</keyname><forenames>Pierrick J.</forenames></author><author><keyname>Mignot</keyname><forenames>Emmanuel</forenames></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames></author></authors><title>DOSED: a deep learning approach to detect multiple sleep micro-events in
  EEG signal</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: Electroencephalography (EEG) monitors brain activity during sleep
and is used to identify sleep disorders. In sleep medicine, clinicians
interpret raw EEG signals in so-called sleep stages, which are assigned by
experts to every 30s window of signal. For diagnosis, they also rely on shorter
prototypical micro-architecture events which exhibit variable durations and
shapes, such as spindles, K-complexes or arousals. Annotating such events is
traditionally performed by a trained sleep expert, making the process time
consuming, tedious and subject to inter-scorer variability. To automate this
procedure, various methods have been developed, yet these are event-specific
and rely on the extraction of hand-crafted features.
  New method: We propose a novel deep learning architecure called Dreem One
Shot Event Detector (DOSED). DOSED jointly predicts locations, durations and
types of events in EEG time series. The proposed approach, applied here on
sleep related micro-architecture events, is inspired by object detectors
developed for computer vision such as YOLO and SSD. It relies on a
convolutional neural network that builds a feature representation from raw EEG
signals, as well as two modules performing localization and classification
respectively.
  Results and comparison with other methods: The proposed approach is tested on
4 datasets and 3 types of events (spindles, K-complexes, arousals) and compared
to the current state-of-the-art detection algorithms.
  Conclusions: Results demonstrate the versatility of this new approach and
improved performance compared to the current state-of-the-art detection
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04087</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04087</id><created>2018-12-07</created><authors><author><keyname>Mahoor</keyname><forenames>Mohsen</forenames></author><author><keyname>Majzoobi</keyname><forenames>Alireza</forenames></author><author><keyname>Khodaei</keyname><forenames>Amin</forenames></author></authors><title>Distribution asset management through coordinated microgrid scheduling</title><categories>eess.SP cs.SY</categories><comments>This is an open access article published by the IET under the
  Creative Commons Attribution -NonCommercial License</comments><journal-ref>IET Smart Grid, 2018, Vol. 1 Iss. 4, pp. 159-168</journal-ref><doi>10.1049/iet-stg.2018.0076</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distribution Asset Management is an important task performed by utility
companies to prolong the lifetime of the critical distribution assets and to
accordingly ensure grid reliability by preventing unplanned outages. This study
focuses on microgrid applications for distribution asset management as a viable
and less expensive alternative to traditional utility practices in this area. A
microgrid is as an emerging distribution technology that encompasses a variety
of distribution technologies including distributed generation, demand response,
and energy storage. Moreover, the substation transformer, as the most critical
component in a distribution grid, is selected as the component of the choice
for asset management studies. The resulting model is a microgrid-based
distribution transformer asset management model in which microgrid exchanged
power with the utility grid is reshaped in such a way that the distribution
transformer lifetime is maximised. Numerical simulations on a test
utility-owned microgrid demonstrate the effectiveness of the proposed model to
reshape the loading of the distribution transformer at the point of
interconnection in order to increase its lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04110</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04110</id><created>2018-12-07</created><authors><author><keyname>Maksymenko</keyname><forenames>Kostiantyn</forenames><affiliation>UCA, ATHENA</affiliation></author><author><keyname>Clerc</keyname><forenames>Maureen</forenames><affiliation>ATHENA, UCA</affiliation></author><author><keyname>Papadopoulo</keyname><forenames>Th&#xe9;odore</forenames><affiliation>UCA</affiliation></author></authors><title>Data-driven cortical clustering to provide a family of plausible
  solutions to M/EEG inverse problem</title><categories>eess.SP cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The M/EEG inverse problem is ill-posed. Thus additional hypotheses are needed
to constrain the solution space. In this work, we consider that brain activity
which generates an M/EEG signal is a connected cortical region. We study the
case when only one region is active at once. We show that even in this simple
case several configurations can explain the data. As opposed to methods based
on convex optimization which are forced to select one possible solution, we
propose an approach which is able to find several &quot;good&quot; candidates - regions
which are different in term of their sizes and/or positions but fit the data
with similar accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04115</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04115</id><created>2018-12-10</created><authors><author><keyname>Hu</keyname><forenames>Yuting</forenames></author><author><keyname>Long</keyname><forenames>Zhiling</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>A High-Speed, Real-Time Vision System for Texture Tracking and Thread
  Counting</title><categories>eess.IV</categories><comments>5 pages, 6 figures</comments><journal-ref>IEEE Signal Processing Letters, vol. 25, no. 6, pp. 758-762, 2018</journal-ref><doi>10.1109/LSP.2018.2825309</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In garment manufacturing, an automatic sewing machine is desirable to reduce
cost. To accomplish this, a high speed vision system is required to track
fabric motions and recognize repetitive weave patterns with high accuracy, from
a micro perspective near a sewing zone. In this paper, we present an innovative
framework for real-time texture tracking and weave pattern recognition. Our
framework includes a module for motion estimation using blob detection and
feature matching. It also includes a module for lattice detection to facilitate
the weave pattern recognition. Our lattice detection algorithm utilizes blob
detection and template matching to assess pair-wise similarity in blobs'
appearance. In addition, it extracts information of dominant orientations to
obtain a global constraint in the topology. By incorporating both constraints
in the appearance similarity and the global topology, the algorithm determines
a lattice that characterizes the topological structure of the repetitive weave
pattern, thus allowing for thread counting. In our experiments, the proposed
thread-based texture tracking system is capable of tracking denim fabric with
high accuracy (e.g., 0.03 degree rotation and 0.02 weave-thread' translation
errors) and high speed (3 frames per second), demonstrating its high potential
for automatic real-time textile manufacturing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04174</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04174</id><created>2018-12-10</created><authors><author><keyname>Hu</keyname><forenames>Yuting</forenames></author><author><keyname>Long</keyname><forenames>Zhiling</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Scale Selective Extended Local Binary Pattern for Texture Classification</title><categories>eess.IV</categories><comments>IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), 2017</comments><doi>10.1109/ICASSP.2017.7952389</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new texture descriptor, scale selective extended
local binary pattern (SSELBP), to characterize texture images with scale
variations. We first utilize multi-scale extended local binary patterns (ELBP)
with rotation-invariant and uniform mappings to capture robust local micro- and
macro-features. Then, we build a scale space using Gaussian filters and
calculate the histogram of multi-scale ELBPs for the image at each scale.
Finally, we select the maximum values from the corresponding bins of
multi-scale ELBP histograms at different scales as scale-invariant features. A
comprehensive evaluation on public texture databases (KTH-TIPS and UMD) shows
that the proposed SSELBP has high accuracy comparable to state-of-the-art
texture descriptors on gray-scale-, rotation-, and scale-invariant texture
classification but uses only one-third of the feature dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04183</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04183</id><created>2018-12-10</created><authors><author><keyname>Hu</keyname><forenames>Yuting</forenames></author><author><keyname>Long</keyname><forenames>Zhiling</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Completed Local Derivative Pattern for Rotation Invariant Texture
  Classification</title><categories>eess.IV</categories><comments>IEEE International Conference on Image Processing (ICIP 2016)</comments><doi>10.1109/ICIP.2016.7533020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new texture descriptor, completed local
derivative pattern (CLDP). In contrast to completed local binary pattern
(CLBP), which involves only local differences at each scale, CLDP encodes the
directional variation of the local differences of two scales as a complementary
component to local patterns in CLBP. The new component in CLDP, with regarded
as the directional derivative pattern, reflects the directional smoothness of
local textures without increasing computation complexity. Experimental results
on the Outex database show that CLDP, as a uni-scale pattern, outperforms
uni-scale state-of-the-art texture descriptors on texture classification and
has comparable performance with multi-scale texture descriptors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04186</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04186</id><created>2018-12-10</created><authors><author><keyname>Herremans</keyname><forenames>Dorien</forenames></author><author><keyname>Chuan</keyname><forenames>Ching-Hua</forenames></author><author><keyname>Chew</keyname><forenames>Elaine</forenames></author></authors><title>A Functional Taxonomy of Music Generation Systems</title><categories>cs.SD cs.LG eess.AS</categories><comments>survey, music generation, taxonomy, functional survey, survey,
  automatic composition, algorithmic composition</comments><proxy>Dorien Herremans</proxy><msc-class>68Txx, 68-XX</msc-class><journal-ref>ACM Computing Surveys (CSUR), 50(5), 69.
  https://dl.acm.org/citation.cfm?id=3145473.3108242</journal-ref><doi>10.1145/3108242</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital advances have transformed the face of automatic music generation
since its beginnings at the dawn of computing. Despite the many breakthroughs,
issues such as the musical tasks targeted by different machines and the degree
to which they succeed remain open questions. We present a functional taxonomy
for music generation systems with reference to existing systems. The taxonomy
organizes systems according to the purposes for which they were designed. It
also reveals the inter-relatedness amongst the systems. This design-centered
approach contrasts with predominant methods-based surveys and facilitates the
identification of grand challenges to set the stage for new breakthroughs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04196</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04196</id><created>2018-12-10</created><authors><author><keyname>El-Moaty</keyname><forenames>Ahmed M. Abd</forenames></author><author><keyname>Zerguine</keyname><forenames>Azzedine</forenames></author></authors><title>Sparse Channel Estimation with Gradient-Based Algorithms: A comparative
  Study</title><categories>eess.SP</categories><comments>5 pages, 4 Figures, The 15th International Multi-Conference on
  Systems, Signals and Devices</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel state information (CSI) is very crucial for any wireless
communication systems. Typically, CSI can be characterized at the receiver side
using channel impulse response (CIR). Many observations have shown that the CIR
of broadband multipath wireless channels are often sparse. To this point, the
family of least mean square (LMS)-based algorithms have been widely used to
estimate the CIR, unfortunately, the performance of LMS family is not much
accurate in terms of sparse channel estimation. The Least Mean Mixed Norm
(LMMN) algorithm combines the advantages of both the Least Mean square (LMS)
and the Least Mean Fourth (LMF)algorithm, which makes this algorithm stands in
a very special position among the family members in terms of convergence and
steady state error. In this paper, we held a fair comparative study between the
LMMN and a number of the LMS-based algorithms, such as the LMS algorithm, the
zero-attracting (ZA-LMS) algorithm, and the normalized (NLMS) algorithm.
Simulation results are carried out to compare the performance of all these
algorithms with the LMMN algorithm. The results show that the LMMN algorithm
outperforms the rest of these algorithms in the identification of sparse
systems in terms of both fast convergence and the steady state error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04311</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04311</id><created>2018-12-11</created><authors><author><keyname>Kr&#xe9;m&#xe9;</keyname><forenames>A. ~Marina</forenames></author><author><keyname>Emiya</keyname><forenames>Valentin</forenames></author><author><keyname>Chaux</keyname><forenames>Caroline</forenames></author></authors><title>Phase inpainting in time-frequency plane</title><categories>eess.SP</categories><comments>In Proceedings of iTWIST'18, Paper-ID: &lt;35&gt;, Marseille, France,
  November, 21-23, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new problem of missing data reconstruction in the time-frequency
plane. This problem called phase inpainting, consists in reconstructing a
signal from time-frequency observations where all amplitudes and some phases
are known while the remaining phases are missing. A mathematical formulation of
this problem is given. We propose three alternatives of existing algorithms. An
iterative algorithm: Griffin and Lim and two semidefinite programming
optimization algorithms: PhaseLift and PhaseCut. The obtained results show that
knowledge of certain phases improves the reconstruction's quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04315</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04315</id><created>2018-12-11</created><authors><author><keyname>Yahaya</keyname><forenames>Farouk</forenames></author><author><keyname>Puigt</keyname><forenames>Matthieu</forenames></author><author><keyname>Delmaire</keyname><forenames>Gilles</forenames></author><author><keyname>Roussel</keyname><forenames>Gilles</forenames></author></authors><title>Faster-than-fast NMF using random projections and Nesterov iterations</title><categories>eess.SP cs.IT math.IT</categories><comments>in Proceedings of iTWIST'18, Paper-ID: 28, Marseille, France,
  November, 21-23, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random projections have been recently implemented in Nonnegative Matrix
Factorization (NMF) to speed-up the NMF computations, with a negligible loss of
performance. In this paper, we investigate the effects of such projections when
the NMF technique uses the fast Nesterov gradient descent (NeNMF). We
experimentally show the randomized subspace iteration to significantly speed-up
NeNMF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04342</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04342</id><created>2018-12-11</created><updated>2019-02-14</updated><authors><author><keyname>Zhang</keyname><forenames>Ya-Jie</forenames></author><author><keyname>Pan</keyname><forenames>Shifeng</forenames></author><author><keyname>He</keyname><forenames>Lei</forenames></author><author><keyname>Ling</keyname><forenames>Zhen-Hua</forenames></author></authors><title>Learning latent representations for style control and transfer in
  end-to-end speech synthesis</title><categories>cs.CL cs.SD eess.AS</categories><comments>Paper accepted by ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce the Variational Autoencoder (VAE) to an
end-to-end speech synthesis model, to learn the latent representation of
speaking styles in an unsupervised manner. The style representation learned
through VAE shows good properties such as disentangling, scaling, and
combination, which makes it easy for style control. Style transfer can be
achieved in this framework by first inferring style representation through the
recognition network of VAE, then feeding it into TTS network to guide the style
in synthesizing speech. To avoid Kullback-Leibler (KL) divergence collapse in
training, several techniques are adopted. Finally, the proposed model shows
good performance of style control and outperforms Global Style Token (GST)
model in ABX preference tests on style transfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04417</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04417</id><created>2018-12-11</created><authors><author><keyname>Li</keyname><forenames>Xiaofei</forenames></author><author><keyname>Ban</keyname><forenames>Yutong</forenames></author><author><keyname>Girin</keyname><forenames>Laurent</forenames></author><author><keyname>Alameda-Pineda</keyname><forenames>Xavier</forenames></author><author><keyname>Horaud</keyname><forenames>Radu</forenames></author></authors><title>A cascaded multiple-speaker localization and tracking system</title><categories>cs.SD eess.AS</categories><comments>In Proceedings of the LOCATA Challenge Workshop - a satellite event
  of IWAENC 2018 (arXiv:1811.08482 )</comments><report-no>LOCATAchallenge/2018/06</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an online multiple-speaker localization and tracking
method, as the INRIA-Perception contribution to the LOCATA Challenge 2018.
First, the recursive least-square method is used to adaptively estimate the
direct-path relative transfer function as an interchannel localization feature.
The feature is assumed to associate with a single speaker at each
time-frequency bin. Second, a complex Gaussian mixture model (CGMM) is used as
a generative model of the features. The weight of each CGMM component
represents the probability that this component corresponds to an active
speaker, and is adaptively estimated with an online optimization algorithm.
Finally, taking the CGMM component weights as observations, a Bayesian
multiple-speaker tracking method based on the variational expectation
maximization algorithm is used. The tracker accounts for the variation of
active speakers and the localization miss measurements, by introducing speaker
birth and sleeping processes. The experiments carried out on the development
dataset of the challenge are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04430</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04430</id><created>2018-12-11</created><updated>2019-10-06</updated><authors><author><keyname>Tsimtsios</keyname><forenames>Aristotelis M.</forenames></author><author><keyname>Nikolaidis</keyname><forenames>Vassilis C.</forenames></author></authors><title>Towards Plug-and-Play Protection for Meshed Distribution Systems with DG</title><categories>eess.SP</categories><comments>Accepted for publication in the IEEE Transactions on Smart Grid</comments><doi>10.1109/TSG.2019.2945694</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future distribution systems are expected to display increased complexity,
mainly due to looped/meshed operation, switch between grid-connected and
islanded mode and considerable integration of distributed generation. This
paper investigates a plug-and-play protection solution for overhead
distribution systems with such variable operation conditions, employing
existing numerical relay capabilities. This solution is applied by designing
plug-and-play, communication-assisted, multifunctional relays with integrated
protection element settings, which apply universally to all distribution system
conditions, rendering the protection scheme independent of a specific system.
Hence, the need for user-defined settings or future revisions due to system
changes is eliminated. The scheme ensures coordination between main line relays
and backup protection of laterals, without a coordination study. There is no
need to replace or modify existing lateral protection means for this purpose;
only their known time-overcurrent curves are uploaded to the relays by the
user. The scheme is described and evaluated through simulations in two test
systems. Meaningful conclusions are finally derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04431</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04431</id><created>2018-12-05</created><authors><author><keyname>Rikos</keyname><forenames>Apostolos I.</forenames></author></authors><title>Distributed Weight Balancing in Directed Topologies</title><categories>cs.DC cs.DS eess.SP</categories><comments>doctoral thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This doctoral thesis concerns novel distributed algorithms for weight
balancing over directed (communication) topologies. A directed topology
(digraph) with nonnegative (or positive) weights assigned on each edge is
weight-balanced if, for each node, the sum of the weights of in-coming edges
equals the sum of the weights of out-going edges. The novel algorithms
introduced in this thesis can facilitate the development of strategies for
generating weight balanced digraphs, in a distributed manner, and find numerous
applications in coordination and control of multi-component systems. In the
first part of this thesis, we introduce a novel distributed algorithm that
operates over a static topology and solves the weight balancing problem when
the weights are restricted to be nonnegative integers. In the second part of
the thesis, we present a novel distributed algorithm which solves the integer
weight balancing problem in the presence of arbitrary (time-varying and
inhomogeneous) delays that might affect the transmission at a particular link
at a particular time. In the third part of this thesis, we present a novel
distributed algorithm for obtaining admissible and balanced integer weights for
the case when there are lower and upper weight constraints on the communication
links. In the fourth part of this thesis we present a novel distributed
algorithm which solves the integer weight balancing problem under lower and
upper weight constraints over the communication links for the case where
arbitrary (time-varying and inhomogeneous) time delays and possible packet
drops affect the transmission at a particular link at a particular time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04476</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04476</id><created>2018-12-08</created><authors><author><keyname>Farsad</keyname><forenames>Nariman</forenames></author><author><keyname>Murin</keyname><forenames>Yonathan</forenames></author><author><keyname>Guo</keyname><forenames>Weisi</forenames></author><author><keyname>Chae</keyname><forenames>Chan-Byoung</forenames></author><author><keyname>Eckford</keyname><forenames>Andrew</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Communication System Design and Analysis for Asynchronous Molecular
  Timing Channels</title><categories>eess.SP cs.IT math.IT</categories><comments>This paper has been accepted for publication at IEEE Transactions on
  Molecular, Biological, and Multi-Scale Communications. arXiv admin note: text
  overlap with arXiv:1609.02109</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two new asynchronous modulation techniques for molecular timing (MT) channels
are proposed. One based on modulating information on the time between two
consecutive releases of indistinguishable information particles, and one based
on using distinguishable particles. For comparison, we consider the
synchronized modulation scheme where information is encoded in the time of
release and decoded from the time of arrival of particles. We show that all
three modulation techniques result in a system that can be modeled as an
additive noise channel, and we derive the expression for the probability
density function of the noise. Next, we focus on binary communication and
derive the associated optimal detection rules for each modulation. Since the
noise associated with these modulations has an infinite variance, geometric
power is used as a measure for the noise power, and we derive an expression for
the geometric SNR (G-SNR) for each modulation scheme. Numerical evaluations
indicate that for these systems the bit error rate (BER) is constant at a given
G-SNR, similar to the relation between BER and SNR in additive Gaussian noise
channels. We also demonstrate that the asynchronous modulation based on two
distinguishable particles can achieve a BER performance close to the
synchronized modulation scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04570</identifier>
 <datestamp>2018-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04570</id><created>2018-12-11</created><authors><author><keyname>Batabyal</keyname><forenames>Tamal</forenames></author><author><keyname>Weller</keyname><forenames>Daniel S.</forenames></author><author><keyname>Acton</keyname><forenames>Scott T.</forenames></author></authors><title>PrecoG: an efficient unitary split preconditioner for the
  transform-domain LMS filter via graph Laplacian regularization</title><categories>eess.SP</categories><comments>Preprint, Submitted to Signal Processing, Elsevier</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Transform-domain least mean squares (LMS) adaptive filters encompass the
class of algorithms in which the input data are subjected to a unitary
transform followed by a power normalization stage and an LMS adaptive filter.
Because of the data-independent nature of conventional transformations, such a
transformation improves the convergence of the LMS filter only for certain
classes of input data. However, for input data from unknown classes or a
specific set of classes, it is difficult to decide which transformation to use.
This decision necessitates a learning framework that obtains such a
transformation using input data, which improves the condition number after
transformation with minor additional computation. It is hypothesized that the
underlying data topology affects the selection of the transformation. With the
data modeled as a weighted graph and the input autocorrelation matrix known or
computed beforehand, we propose a method, PrecoG, that obtains the desired
transform by recursively estimating the graph Laplacian matrix. Additionally,
we show the efficacy of the transformation as a generalized split
preconditioner on a linear system of equations with an ill-conditioned real
positive definite matrix. PrecoG shows significantly improved
post-transformation condition number as compared to the existing
state-of-the-art techniques that involve unitary and non-unitary transforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04571</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04571</id><created>2018-12-10</created><authors><author><keyname>Mlynarski</keyname><forenames>Pawel</forenames></author><author><keyname>Delingette</keyname><forenames>Herv&#xe9;</forenames></author><author><keyname>Criminisi</keyname><forenames>Antonio</forenames></author><author><keyname>Ayache</keyname><forenames>Nicholas</forenames></author></authors><title>Deep Learning with Mixed Supervision for Brain Tumor Segmentation</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>Submitted to SPIE Journal of Medical Imaging</comments><doi>10.1117/1.JMI.6.3.034002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the current state-of-the-art methods for tumor segmentation are based
on machine learning models trained on manually segmented images. This type of
training data is particularly costly, as manual delineation of tumors is not
only time-consuming but also requires medical expertise. On the other hand,
images with a provided global label (indicating presence or absence of a tumor)
are less informative but can be obtained at a substantially lower cost. In this
paper, we propose to use both types of training data (fully-annotated and
weakly-annotated) to train a deep learning model for segmentation. The idea of
our approach is to extend segmentation networks with an additional branch
performing image-level classification. The model is jointly trained for
segmentation and classification tasks in order to exploit information contained
in weakly-annotated images while preventing the network to learn features which
are irrelevant for the segmentation task. We evaluate our method on the
challenging task of brain tumor segmentation in Magnetic Resonance images from
BRATS 2018 challenge. We show that the proposed approach provides a significant
improvement of segmentation performance compared to the standard supervised
learning. The observed improvement is proportional to the ratio between
weakly-annotated and fully-annotated images available for training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04613</identifier>
 <datestamp>2019-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04613</id><created>2018-12-11</created><authors><author><keyname>Salazar</keyname><forenames>Edgar</forenames></author><author><keyname>Parada-Mayorga</keyname><forenames>Alejandro</forenames></author><author><keyname>Arce</keyname><forenames>Gonzalo R.</forenames></author></authors><title>Spectral Zooming and Resolution Limits of Spatial Spectral Compressive
  Spectral Imagers</title><categories>eess.IV</categories><doi>10.1109/TCI.2019.2893596</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently introduced Spatial Spectral Compressive Spectral Imager (SSCSI)
has been proposed as an alternative to carry out spatial and spectral coding
using a binary on-off coded aperture. In SSCSI, the pixel pitch size of the
coded aperture, as well as its location with respect to the detector array,
play a critical role in the quality of image reconstruction. In this paper, a
rigorous discretization model for this architecture is developed, based on a
light propagation analysis across the imager. The attainable spatial and
spectral resolution, and the various parameters affecting them, is derived
through this process. Much like the displacement of zoom lens components leads
to higher spatial resolution of a scene, a shift of the coded aperture in the
SSCSI in reference to the detector leads to higher spectral resolution. This
allows the recovery of spectrally detailed datacubes by physically displacing
the mask towards the spectral plane. To prove the underlying concepts, computer
simulations and experimental data are presented in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04618</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04618</id><created>2018-12-11</created><authors><author><keyname>Chew</keyname><forenames>Jeremy</forenames></author><author><keyname>Sun</keyname><forenames>Yingxiang</forenames></author><author><keyname>Jayasinghe</keyname><forenames>Lahiru</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author></authors><title>DCASE 2018 Challenge: Solution for Task 5</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To address Task 5 in the Detection and Classification of Acoustic Scenes and
Events (DCASE) 2018 challenge, in this paper, we propose an ensemble learning
system. The proposed system consists of three different models, based on
convolutional neural network and long short memory recurrent neural network.
With extracted features such as spectrogram and mel-frequency cepstrum
coefficients from different channels, the proposed system can classify
different domestic activities effectively. Experimental results obtained from
the provided development dataset show that good performance with F1-score of
92.19% can be achieved. Compared with the baseline system, our proposed system
significantly improves the performance of F1-score by 7.69%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04692</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04692</id><created>2018-11-09</created><authors><author><keyname>Ghanbarisabagh</keyname><forenames>Mohammad</forenames></author><author><keyname>Vetharatnam</keyname><forenames>Gobi</forenames></author><author><keyname>Giacoumidis</keyname><forenames>Elias</forenames></author><author><keyname>Rouzegar</keyname><forenames>Hossein</forenames></author><author><keyname>Mallouki</keyname><forenames>Nasreddine</forenames></author></authors><title>A Survey on High-Capacity OFDM-based Passive Optical Networks</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exponential growth of demand for high-speed internet and high bandwidth
applications such as interactive entertainment in access networks mandates the
requirement for higher optical signal speeds. On the other hand, since cost and
energy efficiency should be concurrently preserved in access networks, PONs
have emerged as a breakthrough solution. This survey shows that future-proof
PONs should be supported by an adaptively modulated WDM-OFDM architecture to
maximize signal capacity and transmission-reach, while the employment of
reflective semiconductor optical amplification and re-modulation can
potentially prevent the employment of an additional light source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04708</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04708</id><created>2018-12-11</created><authors><author><keyname>Cappabianco</keyname><forenames>F&#xe1;bio A. M.</forenames></author><author><keyname>da Silva</keyname><forenames>Petrus P. C. E.</forenames></author></authors><title>Non-local Operational Anisotropic Diffusion Filter</title><categories>eess.IV cs.CV</categories><comments>7 pages, 10 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  High-frequency noise is present in several modalities of medical images. It
originates from the acquisition process and may be related to the scanner
configurations, the scanned body, or to other external factors. This way,
prospective filters are an important tool to improve the image quality. In this
paper, we propose a non-local weighted operational anisotropic diffusion filter
and evaluate its effect on magnetic resonance images and on kV/CBCT
radiotherapy images. We also provide a detailed analysis of non-local parameter
settings. Results show that the new filter enhances previous local
implementations and has potential application in radiotherapy treatments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04709</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04709</id><created>2018-11-13</created><authors><author><keyname>Udalcovs</keyname><forenames>Aleksejs</forenames></author><author><keyname>Lin</keyname><forenames>Rui</forenames></author><author><keyname>Ozolins</keyname><forenames>Oskars</forenames></author><author><keyname>Gan</keyname><forenames>Lin</forenames></author><author><keyname>Zhang</keyname><forenames>Lu</forenames></author><author><keyname>Pang</keyname><forenames>Xiaodan</forenames></author><author><keyname>Schatz</keyname><forenames>Richard</forenames></author><author><keyname>Djupsj&#xf6;backa</keyname><forenames>Anders</forenames></author><author><keyname>Tang</keyname><forenames>Ming</forenames></author><author><keyname>Fu</keyname><forenames>Songnian</forenames></author><author><keyname>Liu</keyname><forenames>Deming</forenames></author><author><keyname>Tong</keyname><forenames>Weijun</forenames></author><author><keyname>Popov</keyname><forenames>Sergei</forenames></author><author><keyname>Jacobsen</keyname><forenames>Gunnar</forenames></author><author><keyname>Chen</keyname><forenames>Jiajia</forenames></author></authors><title>Inter-Core Crosstalk in Multicore Fibers: Impact on
  56-Gbaud/{\lambda}/Core PAM-4 Transmission</title><categories>eess.SP</categories><comments>3 pages, 44th European Conference on Optical Communication (ECOC
  2018), Rome, Italy, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We experimentally demonstrate the impact of inter-core crosstalk in multicore
fibers on 56Gbaud PAM-4 signal quality after 2.5-km transmission over a
weakly-coupled and uncoupled sevencore fibers, revealing the crosstalk
dependence on carrier central wavelength in range of 1540-1560 nm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04715</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04715</id><created>2018-11-26</created><authors><author><keyname>Abyaneh</keyname><forenames>Amirhossein Yazdani</forenames></author><author><keyname>Foumani</keyname><forenames>Ali Hosein Gharari</forenames></author><author><keyname>Pourahmadi</keyname><forenames>Vahid</forenames></author></authors><title>Deep Neural Networks Meet CSI-Based Authentication</title><categories>cs.NI cs.CR cs.LG eess.SP stat.ML</categories><comments>7 pages, 14 Figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first step of a secure communication is authenticating legible users and
detecting the malicious ones. In the last recent years, some promising schemes
proposed using wireless medium network's features, in particular, channel state
information (CSI) as a means for authentication. These schemes mainly compare
user's previous CSI with the new received CSI to determine if the user is in
fact what it is claiming to be. Despite high accuracy, these approaches lack
the stability in authentication when the users rotate in their positions. This
is due to a significant change in CSI when a user rotates which mislead the
authenticator when it compares the new CSI with the previous ones. Our approach
presents a way of extracting features from raw CSI measurements which are
stable towards rotation. We extract these features by the means of a deep
neural network. We also present a scenario in which users can be {efficiently}
authenticated while they are at certain locations in an environment (even if
they rotate); and, they will be rejected if they change their location. Also,
experimental results are presented to show the performance of the proposed
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04723</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04723</id><created>2018-12-10</created><authors><author><keyname>Kaygusuz</keyname><forenames>Cengiz</forenames></author><author><keyname>Zuluaga</keyname><forenames>Julian</forenames></author></authors><title>Impact of Intervals on the Emotional Effect in Western Music</title><categories>q-bio.NC cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Every art form ultimately aims to invoke an emotional response over the
audience, and music is no different. While the precise perception of music is a
highly subjective topic, there is an agreement in the &quot;feeling&quot; of a piece of
music in broad terms. Based on this observation, in this study, we aimed to
determine the emotional feeling associated with short passages of music;
specifically by analyzing the melodic aspects. We have used the dataset put
together by Eerola et. al. which is comprised of labeled short passages of film
music. Our initial survey of the dataset indicated that other than &quot;happy&quot; and
&quot;sad&quot; labels do not possess a melodic structure. We transcribed the main melody
of the happy and sad tracks and used the intervals between the notes to
classify them. Our experiments have shown that treating a melody as a
bag-of-intervals do not possess any predictive power whatsoever, whereas
counting intervals with respect to the key of the melody yielded a classifier
with 85% accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04816</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04816</id><created>2018-12-12</created><authors><author><keyname>Zhang</keyname><forenames>Chongyang</forenames></author><author><keyname>Zhu</keyname><forenames>Guofeng</forenames></author><author><keyname>Chen</keyname><forenames>Minxin</forenames></author><author><keyname>Chen</keyname><forenames>Hong</forenames></author><author><keyname>Wu</keyname><forenames>Chenjian</forenames></author></authors><title>Image Segmentation Based on Multiscale Fast Spectral Clustering</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, spectral clustering has become one of the most popular
clustering algorithms for image segmentation. However, it has restricted
applicability to large-scale images due to its high computational complexity.
In this paper, we first propose a novel algorithm called Fast Spectral
Clustering based on quad-tree decomposition. The algorithm focuses on the
spectral clustering at superpixel level and its computational complexity is
O(nlogn) + O(m) + O(m^(3/2)); its memory cost is O(m), where n and m are the
numbers of pixels and the superpixels of a image. Then we propose Multiscale
Fast Spectral Clustering by improving Fast Spectral Clustering, which is based
on the hierarchical structure of the quad-tree. The computational complexity of
Multiscale Fast Spectral Clustering is O(nlogn) and its memory cost is O(m).
Extensive experiments on real large-scale images demonstrate that Multiscale
Fast Spectral Clustering outperforms Normalized cut in terms of lower
computational complexity and memory cost, with comparable clustering accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04818</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04818</id><created>2018-12-12</created><updated>2019-05-11</updated><authors><author><keyname>Saadatnejad</keyname><forenames>Saeed</forenames></author><author><keyname>Oveisi</keyname><forenames>Mohammadhosein</forenames></author><author><keyname>Hashemi</keyname><forenames>Matin</forenames></author></authors><title>LSTM-Based ECG Classification for Continuous Monitoring on Personal
  Wearable Devices</title><categories>eess.SP cs.HC cs.NE</categories><comments>Accepted for publication in IEEE Journal of Biomedical and Health
  Informatics (J-BHI)</comments><journal-ref>IEEE Journal of Biomedical and Health Informatics (JBHI), Vol. 24,
  No. 2, February 2020</journal-ref><doi>10.1109/JBHI.2019.2911367</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: A novel ECG classification algorithm is proposed for continuous
cardiac monitoring on wearable devices with limited processing capacity.
Methods: The proposed solution employs a novel architecture consisting of
wavelet transform and multiple LSTM recurrent neural networks. Results:
Experimental evaluations show superior ECG classification performance compared
to previous works. Measurements on different hardware platforms show the
proposed algorithm meets timing requirements for continuous and real-time
execution on wearable devices. Conclusion: In contrast to many
compute-intensive deep-learning based approaches, the proposed algorithm is
lightweight, and therefore, brings continuous monitoring with accurate
LSTM-based ECG classification to wearable devices. Significance: The proposed
algorithm is both accurate and lightweight. The source code is available online
[1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04832</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04832</id><created>2018-12-12</created><authors><author><keyname>Herremans</keyname><forenames>Dorien</forenames></author><author><keyname>Chew</keyname><forenames>Elaine</forenames></author></authors><title>MorpheuS: generating structured music with constrained patterns and
  tension</title><categories>cs.SD eess.AS</categories><comments>IEEE Transactions on Affective Computing. PP(99)</comments><proxy>Dorien Herremans</proxy><doi>10.1109/TAFFC.2017.2737984</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic music generation systems have gained in popularity and
sophistication as advances in cloud computing have enabled large-scale complex
computations such as deep models and optimization algorithms on personal
devices. Yet, they still face an important challenge, that of long-term
structure, which is key to conveying a sense of musical coherence. We present
the MorpheuS music generation system designed to tackle this problem. MorpheuS'
novel framework has the ability to generate polyphonic pieces with a given
tension profile and long- and short-term repeated pattern structures. A
mathematical model for tonal tension quantifies the tension profile and
state-of-the-art pattern detection algorithms extract repeated patterns in a
template piece. An efficient optimization metaheuristic, variable neighborhood
search, generates music by assigning pitches that best fit the prescribed
tension profile to the template rhythm while hard constraining long-term
structure through the detected patterns. This ability to generate affective
music with specific tension profile and long-term structure is particularly
useful in a game or film music context. Music generated by the MorpheuS system
has been performed live in concerts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04843</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04843</id><created>2018-12-12</created><authors><author><keyname>Zhang</keyname><forenames>Miaomiao</forenames></author><author><keyname>Markovsky</keyname><forenames>Ivan</forenames></author><author><keyname>Schretter</keyname><forenames>Colas</forenames></author><author><keyname>D'hooge</keyname><forenames>Jan</forenames></author></authors><title>A Low-Rank and Joint-Sparse Model for Ultrasound Signal Reconstruction</title><categories>eess.SP</categories><comments>in Proceedings of iTWIST'18, Paper-ID: 32, Marseille, France,
  November, 21-23, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the introduction of very dense sensor arrays in ultrasound (US) imaging,
data transfer rate and data storage became a bottleneck in ultrasound system
design. To reduce the amount of sampled channel data, we propose to use a
low-rank and joint-sparse model to represent US signals and exploit the
correlations between adjacent receiving channels. Results show that the
proposed method is adapted to the ultrasound signals and can recover high
quality image approximations from as low as 10% of the samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04942</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04942</id><created>2018-12-12</created><authors><author><keyname>Madmoni</keyname><forenames>Lior</forenames></author><author><keyname>Beit-On</keyname><forenames>Hanan</forenames></author><author><keyname>Morgenstern</keyname><forenames>Hai</forenames></author><author><keyname>Rafaely</keyname><forenames>Boaz</forenames></author></authors><title>Description of algorithms for Ben-Gurion University Submission to the
  LOCATA challenge</title><categories>cs.SD eess.AS</categories><comments>In Proceedings of the LOCATA Challenge Workshop - a satellite event
  of IWAENC 2018 (arXiv:1811.08482 )</comments><report-no>LOCATAchallenge/2018/03</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper summarizes the methods used to localize the sources recorded for
the LOCalization And TrAcking (LOCATA) challenge. The tasks of stationary
sources and arrays were considered, i.e., tasks 1 and 2 of the challenge, which
were recorded with the Nao robot array, and the Eigenmike array. For both
arrays, direction of arrival (DOA) estimation has been performed with
measurements in the short time Fourier transform domain, and with direct-path
dominance (DPD) based tests, which aim to identify time-frequency (TF) bins
dominated by the direct sound. For the recordings with Nao, a DPD test which is
applied directly to the microphone signals was used. For the Eigenmike
recordings, a DPD based test designed for plane-wave density measurements in
the spherical harmonics domain was used. After acquiring DOA estimates with TF
bins that passed the DPD tests, a stage of k-means clustering is performed, to
assign a final DOA estimate for each speaker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04943</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04943</id><created>2018-12-11</created><authors><author><keyname>Chan</keyname><forenames>Susan</forenames></author><author><keyname>Halimi</keyname><forenames>Abderrahim</forenames></author><author><keyname>Zhu</keyname><forenames>Feng</forenames></author><author><keyname>Gyongy</keyname><forenames>Istvan</forenames></author><author><keyname>Henderson</keyname><forenames>Robert K.</forenames></author><author><keyname>Bowman</keyname><forenames>Richard</forenames></author><author><keyname>McLaughlin</keyname><forenames>Steve</forenames></author><author><keyname>Buller</keyname><forenames>Gerald S.</forenames></author><author><keyname>Leach</keyname><forenames>Jonathan</forenames></author></authors><title>Long-range depth imaging using a single-photon detector array and
  non-local data fusion</title><categories>eess.IV physics.optics</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The ability to measure and record high-resolution depth images at long
stand-off distances is important for a wide range of applications, including
connected and automotive vehicles, defense and security, and agriculture and
mining. In LIDAR (light detection and ranging) applications, single-photon
sensitive detection is an emerging approach, offering high sensitivity to light
and picosecond temporal resolution, and consequently excellent
surface-to-surface resolution. The use of large format CMOS single-photon
detector arrays provides high spatial resolution and allows the timing
information to be acquired simultaneously across many pixels. In this work, we
combine state-of-the-art single-photon detector array technology with non-local
data fusion to generate high resolution three-dimensional depth information of
long-range targets. The system is based on a visible pulsed illumination system
at 670~nm and a 240~$\times$ 320 pixel array sensor, achieving sub-centimeter
precision in all three spatial dimensions at a distance of 150 meters. The
non-local data fusion combines information from an optical image with sparse
sampling of the single-photon array data, providing accurate depth information
at low signature regions of the target.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04967</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04967</id><created>2018-12-12</created><updated>2018-12-18</updated><authors><author><keyname>Xiong</keyname><forenames>Wenjun</forenames></author><author><keyname>Lagerstr&#xf6;m</keyname><forenames>Robert</forenames></author></authors><title>Security and Privacy Issues for Connected Vehicles</title><categories>eess.SP cs.CR</categories><comments>There is a crucial mistake with the code, and the model is far from
  completion. With the agreement of all of the author, we decide to withdraw
  this paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern vehicles contain more than a hundred Electronic Control Units (ECUs)
that communicate over different in-vehicle networks, and they are often
connected to the Internet, which makes them vulnerable to various
cyber-attacks. Besides, data collected by the connected vehicles is directly
connected to the vehicular network. Thus, big vehicular data are collected,
which are valuable and generate insights into driver behavior. Previously, a
probabilistic modeling and simulation language named vehicleLang is presented
to analyze the security of connected vehicles. However, the privacy issues of
vehicular data have not been addressed. To fill in the gap, this work present a
privacy specification for vehicles based on vehicleLang, which uses the Meta
Attack Language (MAL) to assess the security of connected vehicles in a formal
way, with a special focus on the privacy aspect. To evaluate this work, test
cases are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04994</identifier>
 <datestamp>2018-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.04994</id><created>2018-12-12</created><updated>2018-12-13</updated><authors><author><keyname>Fruehwirt</keyname><forenames>Wolfgang</forenames></author><author><keyname>Cobb</keyname><forenames>Adam D.</forenames></author><author><keyname>Mairhofer</keyname><forenames>Martin</forenames></author><author><keyname>Weydemann</keyname><forenames>Leonard</forenames></author><author><keyname>Garn</keyname><forenames>Heinrich</forenames></author><author><keyname>Schmidt</keyname><forenames>Reinhold</forenames></author><author><keyname>Benke</keyname><forenames>Thomas</forenames></author><author><keyname>Dal-Bianco</keyname><forenames>Peter</forenames></author><author><keyname>Ransmayr</keyname><forenames>Gerhard</forenames></author><author><keyname>Waser</keyname><forenames>Markus</forenames></author><author><keyname>Grossegger</keyname><forenames>Dieter</forenames></author><author><keyname>Zhang</keyname><forenames>Pengfei</forenames></author><author><keyname>Dorffner</keyname><forenames>Georg</forenames></author><author><keyname>Roberts</keyname><forenames>Stephen</forenames></author></authors><title>Bayesian deep neural networks for low-cost neurophysiological markers of
  Alzheimer's disease severity</title><categories>stat.ML cs.LG eess.SP q-bio.NC</categories><comments>Machine Learning for Health (ML4H) Workshop at NeurIPS 2018
  arXiv:1811.07216</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As societies around the world are ageing, the number of Alzheimer's disease
(AD) patients is rapidly increasing. To date, no low-cost, non-invasive
biomarkers have been established to advance the objectivization of AD diagnosis
and progression assessment. Here, we utilize Bayesian neural networks to
develop a multivariate predictor for AD severity using a wide range of
quantitative EEG (QEEG) markers. The Bayesian treatment of neural networks both
automatically controls model complexity and provides a predictive distribution
over the target function, giving uncertainty bounds for our regression task. It
is therefore well suited to clinical neuroscience, where data sets are
typically sparse and practitioners require a precise assessment of the
predictive uncertainty. We use data of one of the largest prospective AD EEG
trials ever conducted to demonstrate the potential of Bayesian deep learning in
this domain, while comparing two distinct Bayesian neural network approaches,
i.e., Monte Carlo dropout and Hamiltonian Monte Carlo.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05046</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05046</id><created>2018-12-12</created><authors><author><keyname>Wei</keyname><forenames>Zhongxiang</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author></authors><title>User-Centric Distributed Antenna Transmission: Secure Precoding and
  Antenna Selection with Interference Exploitation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address physical layer security in distributed antenna (DA) systems, where
eavesdroppers (Eves) can intercept the information transmitted for the intended
receiver (IR). To realize a user-centric, power-efficient and physical layer
security-addressing system, we aim at minimizing total power consumption by
jointly designing DA selection and secure precoding. Different from the
conventional artificial noise (AN)-aided secure transmission, where AN is
treated as an undesired element for the IR, we design AN such that it is
constructive to the IR while keeping destructive to the Eves. Importantly, we
investigate two practical scenarios, where the IR and Eves' channel state
information (CSI) is imperfectly obtained or the Eves' CSI is completely
unknown. To handle the CSI uncertainties, we solve the problems in
probabilistic and deterministic robust optimization respectively, both
satisfying the IR' signal-to-interference-and-ratio (SINR) requirement by use
of constructive AN and addressing security against the Eves. Simulation results
demonstrate our algorithms consume much less power compared to the centralized
antenna (CA) systems with/without antenna selection, as well as the DA systems
with conventional AN processing. Last but not least, by the proposed
algorithms, the activation of DAs closely relates to users' locations and
quality-of-service (QoS) requirements, featuring a user-centric and on-demand
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05052</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05052</id><created>2018-12-12</created><authors><author><keyname>Wagner</keyname><forenames>Martin R.</forenames></author><author><keyname>Jereminov</keyname><forenames>Marko</forenames></author><author><keyname>Pileggi</keyname><forenames>Larry</forenames></author></authors><title>Linear Power Grid State Estimation with Modeling Uncertainties</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in power system State Estimation (SE) have included
equivalent circuit models for representing measurement data that allows
incorporation of both PMU and RTU measurements within the state estimator. In
this paper, we introduce a probabilistic framework with a new RTU model that
renders the complete SE problem linear while not affecting its accuracy. It is
demonstrated that the probabilistic state of a system can be efficiently and
accurately estimated not only with the uncertainties from the measurement data,
but also while including variations from transmission network models. To
demonstrate accuracy and scalability we present probabilistic state estimation
results for the 82k test case that represents the transmission level grid of
the entire USA. It is shown that the estimated state distributions include the
true grid state, while their mean exactly corresponds to the estimated
deterministic state obtained from the nonlinear state estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05131</identifier>
 <datestamp>2018-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05131</id><created>2018-12-12</created><authors><author><keyname>Granstr&#xf6;m</keyname><forenames>Karl</forenames></author><author><keyname>Svensson</keyname><forenames>Lennart</forenames></author><author><keyname>Xia</keyname><forenames>Yuxuan</forenames></author><author><keyname>Williams</keyname><forenames>Jason</forenames></author><author><keyname>Garcia-Fernandez</keyname><forenames>Angel F</forenames></author></authors><title>Poisson multi-Bernoulli mixture trackers: continuity through random
  finite sets of trajectories</title><categories>eess.SP cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Poisson multi-Bernoulli mixture (PMBM) is an unlabelled multi-target
distribution for which the prediction and update are closed. It has a Poisson
birth process, and new Bernoulli components are generated on each new
measurement as a part of the Bayesian measurement update. The PMBM filter is
similar to the multiple hypothesis tracker (MHT), but seemingly does not
provide explicit continuity between time steps. This paper considers a recently
developed formulation of the multi-target tracking problem as a random finite
set (RFS) of trajectories, and derives two trajectory RFS filters, called PMBM
trackers. The PMBM trackers efficiently estimate the set of trajectories, and
share hypothesis structure with the PMBM filter. By showing that the prediction
and update in the PMBM filter can be viewed as an efficient method for
calculating the time marginals of the RFS of trajectories, continuity in the
same sense as MHT is established for the PMBM filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05177</identifier>
 <datestamp>2018-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05177</id><created>2018-12-12</created><authors><author><keyname>Aabed</keyname><forenames>Mohammed A.</forenames></author><author><keyname>Kwon</keyname><forenames>Gukyeong</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Power of Tempospatially Unified Spectral Density for Perceptual Video
  Quality Assessment</title><categories>cs.CV eess.IV</categories><comments>6 pages, 4 figures, 3 tables</comments><journal-ref>M. A. Aabed, G. Kwon, and G. AlRegib, &quot;Power of Tempospatially
  Unified Spectral Density for Perceptual Video Quality Assessment,&quot; 2017 IEEE
  International Conference on Multimedia and Expo (ICME), Hong Kong, 2017, pp.
  1476-1481</journal-ref><doi>10.1109/ICME.2017.8019333</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a perceptual video quality assessment (PVQA) metric for distorted
videos by analyzing the power spectral density (PSD) of a group of pictures.
This is an estimation approach that relies on the changes in video dynamic
calculated in the frequency domain and are primarily caused by distortion. We
obtain a feature map by processing a 3D PSD tensor obtained from a set of
distorted frames. This is a full-reference tempospatial approach that considers
both temporal and spatial PSD characteristics. This makes it ubiquitously
suitable for videos with varying motion patterns and spatial contents. Our
technique does not make any assumptions on the coding conditions, streaming
conditions or distortion. This approach is also computationally inexpensive
which makes it feasible for real-time and practical implementations. We
validate our proposed metric by testing it on a variety of distorted sequences
from PVQA databases. The results show that our metric estimates the perceptual
quality at the sequence level accurately. We report the correlation
coefficients with the differential mean opinion scores (DMOS) reported in the
databases. The results show high and competitive correlations compared with the
state of the art techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05252</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05252</id><created>2018-12-12</created><updated>2019-08-23</updated><authors><author><keyname>Peng</keyname><forenames>Gao</forenames></author><author><keyname>Jiang</keyname><forenames>Zhengkai</forenames></author><author><keyname>You</keyname><forenames>Haoxuan</forenames></author><author><keyname>Lu</keyname><forenames>Pan</forenames></author><author><keyname>Hoi</keyname><forenames>Steven</forenames></author><author><keyname>Wang</keyname><forenames>Xiaogang</forenames></author><author><keyname>Li</keyname><forenames>Hongsheng</forenames></author></authors><title>Dynamic Fusion with Intra- and Inter- Modality Attention Flow for Visual
  Question Answering</title><categories>cs.CV eess.IV</categories><comments>CVPR 2019 ORAL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning effective fusion of multi-modality features is at the heart of
visual question answering. We propose a novel method of dynamically fusing
multi-modal features with intra- and inter-modality information flow, which
alternatively pass dynamic information between and across the visual and
language modalities. It can robustly capture the high-level interactions
between language and vision domains, thus significantly improves the
performance of visual question answering. We also show that the proposed
dynamic intra-modality attention flow conditioned on the other modality can
dynamically modulate the intra-modality attention of the target modality, which
is vital for multimodality feature fusion. Experimental evaluations on the VQA
2.0 dataset show that the proposed method achieves state-of-the-art VQA
performance. Extensive ablation studies are carried out for the comprehensive
analysis of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05253</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05253</id><created>2018-12-12</created><updated>2019-09-01</updated><authors><author><keyname>Deng</keyname><forenames>Yan</forenames></author><author><keyname>He</keyname><forenames>Lei</forenames></author><author><keyname>Soong</keyname><forenames>Frank</forenames></author></authors><title>Modeling Multi-speaker Latent Space to Improve Neural TTS: Quick
  Enrolling New Speaker and Enhancing Premium Voice</title><categories>eess.AS cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural TTS has shown it can generate high quality synthesized speech. In this
paper, we investigate the multi-speaker latent space to improve neural TTS for
adapting the system to new speakers with only several minutes of speech or
enhancing a premium voice by utilizing the data from other speakers for richer
contextual coverage and better generalization. A multi-speaker neural TTS model
is built with the embedded speaker information in both spectral and speaker
latent space. The experimental results show that, with less than 5 minutes of
training data from a new speaker, the new model can achieve an MOS score of
4.16 in naturalness and 4.64 in speaker similarity close to human recordings
(4.74). For a well-trained premium voice, we can achieve an MOS score of 4.5
for out-of-domain texts, which is comparable to an MOS of 4.58 for professional
recordings, and significantly outperforms single speaker result of 4.28.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05329</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05329</id><created>2018-12-13</created><updated>2019-01-02</updated><authors><author><keyname>Gu</keyname><forenames>Jun</forenames></author><author><keyname>Xu</keyname><forenames>Guangluan</forenames></author><author><keyname>Zhang</keyname><forenames>Yue</forenames></author><author><keyname>Sun</keyname><forenames>Xian</forenames></author><author><keyname>Wen</keyname><forenames>Ran</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author></authors><title>Wider Channel Attention Network for Remote Sensing Image
  Super-resolution</title><categories>cs.CV eess.IV</categories><comments>This work is proposed for remote sensing images, but the idea of the
  whole paper do not foucs on the characteristics of remote sensing images. The
  content of the article does not match the title. In this case, we want to do
  some experiments on the natural images to verify the three tricks in our work</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, deep convolutional neural networks (CNNs) have obtained promising
results in image processing tasks including super-resolution (SR). However,
most CNN-based SR methods treat low-resolution (LR) inputs and features equally
across channels, rarely notice the loss of information flow caused by the
activation function and fail to leverage the representation ability of CNNs. In
this letter, we propose a novel single-image super-resolution (SISR) algorithm
named Wider Channel Attention Network (WCAN) for remote sensing images.
Firstly, the channel attention mechanism is used to adaptively recalibrate the
importance of each channel at the middle of the wider attention block (WAB).
Secondly, we propose the Local Memory Connection (LMC) to enhance the
information flow. Finally, the features within each WAB are fused to take
advantage of the network's representation capability and further improve
information and gradient flow. Analytic experiments on a public remote sensing
data set (UC Merced) show that our WCAN achieves better accuracy and visual
improvements against most state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05359</identifier>
 <datestamp>2018-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05359</id><created>2018-12-13</created><authors><author><keyname>Feuillen</keyname><forenames>Thomas</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author></authors><title>An extreme bit-rate reduction scheme for 2D radar localization</title><categories>eess.SP</categories><comments>in Proceedings of iTWIST'18, Paper-ID: 29, Marseille, France,
  November, 21-23, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we further expand on the work in [1] that focused on the
localization of targets in a 2D space using 1-bit dithered measurements coming
from a 2 receiving antennae radar. Our aim is to further reduce the hardware
requirements and bit-rate, by dropping one of the baseband IQ channel from each
receiving antenna. To that end, the structure of the received signals is
exploited to recover the positions of multiple targets. Simulations are
performed to highlight the accuracy and limitations of the proposed scheme
under severe bit-rate reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05417</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05417</id><created>2018-12-13</created><updated>2018-12-18</updated><authors><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author></authors><title>A Simple Method for 5G Positioning and Synchronization without
  Line-of-Sight</title><categories>eess.SP</categories><comments>5 pages, 3 figures, Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 5G mmWave, joint positioning and synchronization can be achieved even when
the line-of-sight path is blocked. In this technical note, we describe a simple
method to determine a coarse estimate of the user state and the environment.
This method is based on geometric consistency of the 5G mmWave measurements and
can be used as a pre-processor for other more sophisticated methods, in order
to reduce their complexity. A link to MATLAB source code is provided at the end
of the document.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05498</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05498</id><created>2018-11-12</created><authors><author><keyname>Burke</keyname><forenames>Claire</forenames></author><author><keyname>Rashman</keyname><forenames>Maisie</forenames></author><author><keyname>Wich</keyname><forenames>Serge</forenames></author><author><keyname>Symons</keyname><forenames>Andy</forenames></author><author><keyname>Theron</keyname><forenames>Cobus</forenames></author><author><keyname>Longmore</keyname><forenames>Steve</forenames></author></authors><title>Optimising observing strategies for monitoring animals using
  drone-mounted thermal infrared cameras</title><categories>eess.SP astro-ph.IM</categories><comments>Accepted for publication in International Journal of Remote Sensing:
  Drones. 30 pages, 13 figures</comments><doi>10.1080/01431161.2018.1558372</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proliferation of relatively affordable off-the-shelf drones offers great
opportunities for wildlife monitoring and conservation. Similarly the recent
reduction in cost of thermal infrared cameras also offers new promise in this
field, as they have the advantage over conventional RGB cameras of being able
to distinguish animals based on their body heat and being able to detect
animals at night. However, the use of drone-mounted thermal infrared cameras
comes with several technical challenges. In this paper we address some of these
issues, namely thermal contrast problems due to heat from the ground,
absorption and emission of thermal infrared radiation by the atmosphere,
obscuration by vegetation, and optimizing the flying height of drones for a
best balance between covering a large area and being able to accurately image
and identify animals of interest. We demonstrate the application of these
methods with a case study using field data, and make the first ever detection
of the critically endangered riverine rabbit (Bunolagus monticularis) in
thermal infrared data. We provide a web-tool so that the community can easily
apply these techniques to other studies
(http://www.astro.ljmu.ac.uk/~aricburk/uav_calc/).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05501</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05501</id><created>2018-12-11</created><authors><author><keyname>Nagata</keyname><forenames>Kenji</forenames></author><author><keyname>Mototake</keyname><forenames>Yoh-ichi</forenames></author><author><keyname>Muraoka</keyname><forenames>Rei</forenames></author><author><keyname>Sasaki</keyname><forenames>Takehiko</forenames></author><author><keyname>Okada</keyname><forenames>Masato</forenames></author></authors><title>Bayesian Spectral Deconvolution Based on Poisson Distribution: Bayesian
  Measurement and Virtual Measurement Analytics (VMA)</title><categories>eess.SP cs.LG physics.data-an stat.ML</categories><comments>8 pages, 8 figures</comments><doi>10.7566/JPSJ.88.044003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new method of Bayesian measurement for spectral
deconvolution, which regresses spectral data into the sum of unimodal basis
function such as Gaussian or Lorentzian functions. Bayesian measurement is a
framework for considering not only the target physical model but also the
measurement model as a probabilistic model, and enables us to estimate the
parameter of a physical model with its confidence interval through a Bayesian
posterior distribution given a measurement data set. The measurement with
Poisson noise is one of the most effective system to apply our proposed method.
Since the measurement time is strongly related to the signal-to-noise ratio for
the Poisson noise model, Bayesian measurement with Poisson noise model enables
us to clarify the relationship between the measurement time and the limit of
estimation. In this study, we establish the probabilistic model with Poisson
noise for spectral deconvolution. Bayesian measurement enables us to perform
virtual and computer simulation for a certain measurement through the
established probabilistic model. This property is called &quot;Virtual Measurement
Analytics(VMA)&quot; in this paper. We also show that the relationship between the
measurement time and the limit of estimation can be extracted by using the
proposed method in a simulation of synthetic data and real data for XPS
measurement of MoS$_2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05517</identifier>
 <datestamp>2018-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05517</id><created>2018-12-13</created><authors><author><keyname>Simou</keyname><forenames>Effrosyni</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Graph Signal Representation with Wasserstein Barycenters</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications signals reside on the vertices of weighted graphs. Thus,
there is the need to learn low dimensional representations for graph signals
that will allow for data analysis and interpretation. Existing unsupervised
dimensionality reduction methods for graph signals have focused on dictionary
learning. In these works the graph is taken into consideration by imposing a
structure or a parametrization on the dictionary and the signals are
represented as linear combinations of the atoms in the dictionary. However, the
assumption that graph signals can be represented using linear combinations of
atoms is not always appropriate. In this paper we propose a novel
representation framework based on non-linear and geometry-aware combinations of
graph signals by leveraging the mathematical theory of Optimal Transport. We
represent graph signals as Wasserstein barycenters and demonstrate through our
experiments the potential of our proposed framework for low-dimensional graph
signal representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05536</identifier>
 <datestamp>2018-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05536</id><created>2018-11-13</created><authors><author><keyname>Van Kerrebrouck</keyname><forenames>Joris</forenames></author><author><keyname>Pang</keyname><forenames>Xiaodan</forenames></author><author><keyname>Ozolins</keyname><forenames>Oskars</forenames></author><author><keyname>Lin</keyname><forenames>Rui</forenames></author><author><keyname>Udalcovs</keyname><forenames>Aleksejs</forenames></author><author><keyname>Zhang</keyname><forenames>Lu</forenames></author><author><keyname>Li</keyname><forenames>Haolin</forenames></author><author><keyname>Spiga</keyname><forenames>Silvia</forenames></author><author><keyname>Amann</keyname><forenames>Markus-Christian</forenames></author><author><keyname>Gan</keyname><forenames>Lin</forenames></author><author><keyname>Tang</keyname><forenames>Ming</forenames></author><author><keyname>Fu</keyname><forenames>Songnian</forenames></author><author><keyname>Schatz</keyname><forenames>Richard</forenames></author><author><keyname>Jacobsen</keyname><forenames>Gunnar</forenames></author><author><keyname>Popov</keyname><forenames>Sergei</forenames></author><author><keyname>Liu</keyname><forenames>Deming</forenames></author><author><keyname>Tong</keyname><forenames>Weijun</forenames></author><author><keyname>Torfs</keyname><forenames>Guy</forenames></author><author><keyname>Bauwelinck</keyname><forenames>Johan</forenames></author><author><keyname>Chen</keyname><forenames>Jiajia</forenames></author><author><keyname>Yin</keyname><forenames>Xin</forenames></author></authors><title>High-speed PAM4-based Optical SDM Interconnects with Directly Modulated
  Long-wavelength VCSEL</title><categories>eess.SP cs.NI</categories><comments>7 pages, accepted to publication in 'Journal of Lightwave Technology
  (JLT)</comments><doi>10.1109/JLT.2018.2875538</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports the demonstration of high-speed PAM-4 transmission using a
1.5-{\mu}m single-mode vertical cavity surface emitting laser (SM-VCSEL) over
multicore fiber with 7 cores over different distances. We have successfully
generated up to 70 Gbaud 4-level pulse amplitude modulation (PAM-4) signals
with a VCSEL in optical back-to-back, and transmitted 50 Gbaud PAM-4 signals
over both 1-km dispersion-uncompensated and 10-km dispersion-compensated in
each core, enabling a total data throughput of 700 Gbps over the 7-core fiber.
Moreover, 56 Gbaud PAM-4 over 1-km has also been shown, whereby unfortunately
not all cores provide the required 3.8 $\times$ 10 $^{-3}$ bit error rate (BER)
for the 7% overhead-hard decision forward error correction (7% OH HDFEC). The
limited bandwidth of the VCSEL and the adverse chromatic dispersion of the
fiber are suppressed with pre-equalization based on accurate end-to-end channel
characterizations. With a digital post-equalization, BER performance below the
7% OH-HDFEC limit is achieved over all cores. The demonstrated results show a
great potential to realize high-capacity and compact short-reach optical
interconnects for data centers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05539</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05539</id><created>2018-12-11</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Wu</keyname><forenames>Shangsong</forenames></author></authors><title>Controlled islanding for a hybrid AC/DC grid with VSC-HVDC using
  semi-supervised spectral clustering</title><categories>eess.SP cs.SY</categories><comments>Accepted by IEEE Access</comments><journal-ref>IEEE Access 7 (2019) 10478-10490</journal-ref><doi>10.1109/ACCESS.2018.2886533</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the last resort of emergency control, controlled islanding is an effective
means of preventing fault-propagation and a system-wide blackout. However,
conventional AC transmission lines are unavailable to be employed for power
exchange between these islands. To make full use of the DC power modulation
capability of VSC-HVDC links, a new controlled islanding model is put forward
for an AC/VSC-HVDC hybrid grid to minimize the composite power-flow disruption,
in which the DC-terminals belonging to a VSC-HVDC link are placed in different
islands. To solve this model, a semi-supervised spectral clustering-based
approach is proposed by transforming the problem into a weighted undirected
graph segmentation problem. The novelty of our work is to find an optimal
islanding solution in real time such that the power exchanges between islands
are implemented via a VSC-HVDC link to reduce the generation-load imbalance.
The simulation results on the IEEE 39-bus system and a real-world system verify
the effectiveness and superiority of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05555</identifier>
 <datestamp>2018-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05555</id><created>2018-12-12</created><authors><author><keyname>Zhao</keyname><forenames>Zheng</forenames></author><author><keyname>S&#xe4;rkk&#xe4;</keyname><forenames>Simo</forenames></author><author><keyname>Rad</keyname><forenames>Ali Bahrami</forenames></author></authors><title>Kalman-based Spectro-Temporal ECG Analysis using Deep Convolutional
  Networks for Atrial Fibrillation Detection</title><categories>eess.SP cs.LG stat.ML</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we propose a novel ECG classification framework for atrial
fibrillation (AF) detection using spectro-temporal representation (i.e., time
varying spectrum) and deep convolutional networks. In the first step we use a
Bayesian spectro-temporal representation based on the estimation of
time-varying coefficients of Fourier series using Kalman filter and smoother.
Next, we derive an alternative model based on a stochastic oscillator
differential equation to accelerate the estimation of the spectro-temporal
representation in lengthy signals. Finally, after comparative evaluations of
different convolutional architectures, we propose an efficient deep
convolutional neural network to classify the 2D spectro-temporal ECG data.
  The ECG spectro-temporal data are classified into four different classes: AF,
non-AF normal rhythm (Normal), non-AF abnormal rhythm (Other), and noisy
segments (Noisy). The performance of the proposed methods is evaluated and
scored with the PhysioNet/Computing in Cardiology (CinC) 2017 dataset. The
experimental results show that the proposed method achieves the overall F1
score of 80.2%, which is in line with the state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05600</identifier>
 <datestamp>2018-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05600</id><created>2018-12-12</created><updated>2018-12-21</updated><authors><author><keyname>Giacoumidis</keyname><forenames>Elias</forenames></author><author><keyname>Wei</keyname><forenames>Jinlong</forenames></author><author><keyname>Aldaya</keyname><forenames>Ivan</forenames></author><author><keyname>Sanchez</keyname><forenames>Christian</forenames></author><author><keyname>Mrabet</keyname><forenames>Hichem</forenames></author><author><keyname>Barry</keyname><forenames>Liam P.</forenames></author></authors><title>Fiber-induced nonlinearity compensation in coherent optical systems by
  affinity propagation soft-clustering</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a tremendous need to maximize signal capacity without sacrificing
energy consumption and complexity in optical fiber communications due to the
rise of network traffic demand and critical latency-aware services such as
telemedicine and the Internet-of-Things. In this work, the first
system-agnostic and training-data-free fiber nonlinearity compensator (NLC)
using affinity propagation (AP) clustering is experimentally demonstrated. It
is shown that compared to linear equalization, AP can increase the signal
quality-factor up to about 5 dB in 16-quadrature-amplitude-modulated coherent
optical systems by effectively tackling deterministic and stochastic
nonlinearities. AP outperforms benchmark clustering algorithms and complex
deterministic schemes such as K-means, fuzzy-logic, digital-back propagation
and Volterra-based NLC, offering a power margin extension of up to 4 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05683</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05683</id><created>2018-11-12</created><authors><author><keyname>Gan</keyname><forenames>Lin</forenames></author><author><keyname>Zhou</keyname><forenames>Jiajun</forenames></author><author><keyname>Huo</keyname><forenames>Liang</forenames></author><author><keyname>Shen</keyname><forenames>Li</forenames></author><author><keyname>Yang</keyname><forenames>Chen</forenames></author><author><keyname>Tong</keyname><forenames>Weijun</forenames></author><author><keyname>Fu</keyname><forenames>Songnian</forenames></author><author><keyname>Tang</keyname><forenames>Ming</forenames></author><author><keyname>Liu</keyname><forenames>Deming</forenames></author></authors><title>Crosstalk Impacts on Homogeneous Weakly-Coupled Multicore Fiber Based
  IM/DD System</title><categories>eess.SP physics.optics</categories><comments>3 pages, 11 figures;</comments><journal-ref>Asia Communications and Photonics Conference (ACP 2018), Su1D.8</journal-ref><doi>10.1109/ACP.2018.8595879</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We numerically discussed crosstalk impacts on homogeneous weakly-coupled
multicore fiber based intensity modulation/direct-detection (IM/DD) systems
taking into account mean crosstalk power fluctuation, walk-off between cores,
laser frequency offset, and laser linewidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05705</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05705</id><created>2018-12-13</created><updated>2018-12-30</updated><authors><author><keyname>Hersche</keyname><forenames>Michael</forenames></author><author><keyname>Mill&#xe1;n</keyname><forenames>Jos&#xe9; del R.</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author><author><keyname>Rahimi</keyname><forenames>Abbas</forenames></author></authors><title>Exploring Embedding Methods in Binary Hyperdimensional Computing: A Case
  Study for Motor-Imagery based Brain-Computer Interfaces</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Key properties of brain-inspired hyperdimensional (HD) computing make it a
prime candidate for energy-efficient and fast learning in biosignal processing.
The main challenge is however to formulate embedding methods that map biosignal
measures to a binary HD space. In this paper, we explore variety of such
embedding methods and examine them with a challenging application of motor
imagery brain-computer interface (MI-BCI) from electroencephalography (EEG)
recordings. We explore embedding methods including random projections,
quantization based thermometer and Gray coding, and learning HD representations
using end-to-end training. All these methods, differing in complexity, aim to
represent EEG signals in binary HD space, e.g. with 10,000 bits. This leads to
development of a set of HD learning and classification methods that can be
selectively chosen (or configured) based on accuracy and/or computational
complexity requirements of a given task. We compare them with state-of-the-art
linear support vector machine (SVM) on an NVIDIA TX2 board using the 4-class
BCI competition IV-2a dataset as well as a new 3-class dataset. Compared to
SVM, results on 3-class dataset show that simple thermometer embedding achieves
moderate average accuracy (79.56% vs. 82.67%) with 26.8$\times$ faster training
time and 22.3$\times$ lower energy; on the other hand, switching to end-to-end
training with learned HD representations wipes out these training benefits
while boosting the accuracy to 84.22% (1.55% higher than SVM). Similar trend is
observed on the 4-class dataset where SVM achieves on average 74.29%: the
thermometer embedding achieves 89.9$\times$ faster training time and
58.7$\times$ lower energy, but a lower accuracy (67.09%) than the learned
representation of 72.54%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05710</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05710</id><created>2018-12-12</created><updated>2020-02-09</updated><authors><author><keyname>Ma</keyname><forenames>Dabiao</forenames></author><author><keyname>Su</keyname><forenames>Zhiba</forenames></author><author><keyname>Wang</keyname><forenames>Wenxuan</forenames></author><author><keyname>Lu</keyname><forenames>Yuhao</forenames></author></authors><title>FPETS : Fully Parallel End-to-End Text-to-Speech System</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end Text-to-speech (TTS) system can greatly improve the quality of
synthesised speech. But it usually suffers form high time latency due to its
auto-regressive structure. And the synthesised speech may also suffer from some
error modes, e.g. repeated words, mispronunciations, and skipped words. In this
paper, we propose a novel non-autoregressive, fully parallel end-to-end TTS
system (FPETS). It utilizes a new alignment model and the recently proposed
U-shape convolutional structure, UFANS. Different from RNN, UFANS can capture
long term information in a fully parallel manner. Trainable position encoding
and two-step training strategy are used for learning better alignments.
Experimental results show FPETS utilizes the power of parallel computation and
reaches a significant speed up of inference compared with state-of-the-art
end-to-end TTS systems. More specifically, FPETS is 600X faster than Tacotron2,
50X faster than DCTTS and 10X faster than Deep Voice3. And FPETS can generates
audios with equal or better quality and fewer errors comparing with other
system. As far as we know, FPETS is the first end-to-end TTS system which is
fully parallel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05772</identifier>
 <datestamp>2018-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05772</id><created>2018-12-13</created><authors><author><keyname>Kamran</keyname><forenames>Rashmi</forenames></author><author><keyname>Naaz</keyname><forenames>Sana</forenames></author><author><keyname>Manikandan</keyname><forenames>Sarath</forenames></author><author><keyname>Goyal</keyname><forenames>Sandeep</forenames></author><author><keyname>Ashok</keyname><forenames>Rakesh</forenames></author><author><keyname>Gupta</keyname><forenames>Shalabh</forenames></author></authors><title>A Polarization Multiplexed Carrier based Coherent Link with Adaptive
  Polarization Control</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmitting polarization multiplexed carrier makes the receiver of a
coherent system local oscillator-less and frequency offset-free. A polarization
multiplexed carrier based self-homodyne (PMC-SH) system with an adaptive
polarization control (PC) can replace pulse amplitude modulation (PAM- 4) data
center interconnects. An adaptive PC technique is practically implemented by
using an electrically controlled PC along-with control circuitry for PMC-SH
systems. The de-multiplexing of the carrier and the modulated signal by using
this technique is validated through simulations for a 50 Gbaud PMC-SH
quadrature phase shift keying (QPSK) system with 20km standard single mode
fiber (SSMF). We successfully demonstrate 16 Gbaud PMC-SH systems with adaptive
PC for 10km SSMF channel. A bit error rate (BER) of 5.9 x 10^(-5) is achieved
with 32 Gb/s PMC-SHQPSK system without any signal processing while a BER of 8.7
x 10^(-3) is achieved with a 64 Gb/s PMC-SH quadrature amplitude modulation
(16QAM) system after equalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05796</identifier>
 <datestamp>2019-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05796</id><created>2018-12-14</created><updated>2019-03-13</updated><authors><author><keyname>Yamaguchi</keyname><forenames>Masataka</forenames></author><author><keyname>Koizumi</keyname><forenames>Yuma</forenames></author><author><keyname>Harada</keyname><forenames>Noboru</forenames></author></authors><title>AdaFlow: Domain-Adaptive Density Estimator with Application to Anomaly
  Detection and Unpaired Cross-Domain Translation</title><categories>stat.ML cs.LG cs.SD eess.AS</categories><comments>Accepted to ICASSP2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle unsupervised anomaly detection (UAD), a problem of detecting data
that significantly differ from normal data. UAD is typically solved by using
density estimation. Recently, deep neural network (DNN)-based density
estimators, such as Normalizing Flows, have been attracting attention. However,
one of their drawbacks is the difficulty in adapting them to the change in the
normal data's distribution. To address this difficulty, we propose AdaFlow, a
new DNN-based density estimator that can be easily adapted to the change of the
distribution. AdaFlow is a unified model of a Normalizing Flow and Adaptive
Batch-Normalizations, a module that enables DNNs to adapt to new distributions.
AdaFlow can be adapted to a new distribution by just conducting forward
propagation once per sample; hence, it can be used on devices that have limited
computational resources. We have confirmed the effectiveness of the proposed
model through an anomaly detection in a sound task. We also propose a method of
applying AdaFlow to the unpaired cross-domain translation problem, in which one
has to train a cross-domain translation model with only unpaired samples. We
have confirmed that our model can be used for the cross-domain translation
problem through experiments on image datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05888</identifier>
 <datestamp>2018-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05888</id><created>2018-12-14</created><authors><author><keyname>Grzywalski</keyname><forenames>Tomasz</forenames></author><author><keyname>Maciaszek</keyname><forenames>Adam</forenames></author><author><keyname>Biniakowski</keyname><forenames>Adam</forenames></author><author><keyname>Orwat</keyname><forenames>Jan</forenames></author><author><keyname>Drgas</keyname><forenames>Szymon</forenames></author><author><keyname>Piecuch</keyname><forenames>Mateusz</forenames></author><author><keyname>Belluzzo</keyname><forenames>Riccardo</forenames></author><author><keyname>Joachimiak</keyname><forenames>Krzysztof</forenames></author><author><keyname>Niemiec</keyname><forenames>Dawid</forenames></author><author><keyname>Ptaszynski</keyname><forenames>Jakub</forenames></author><author><keyname>Szarzynski</keyname><forenames>Krzysztof</forenames></author></authors><title>Parameterization of Sequence of MFCCs for DNN-based voice disorder
  detection</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article a DNN-based system for detection of three common voice
disorders (vocal nodules, polyps and cysts; laryngeal neoplasm; unilateral
vocal paralysis) is presented. The input to the algorithm is (at least 3-second
long) audio recording of sustained vowel sound /a:/. The algorithm was
developed as part of the &quot;2018 FEMH Voice Data Challenge&quot; organized by Far
Eastern Memorial Hospital and obtained score value (defined in the challenge
specification) of 77.44. This was the second best result before final
submission. Final challenge results are not yet known during writing of this
document. The document also reports changes that were made for the final
submission which improved the score value in cross-validation by 0.6% points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05901</identifier>
 <datestamp>2018-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05901</id><created>2018-12-14</created><authors><author><keyname>Lebarbenchon</keyname><forenames>Romain</forenames></author><author><keyname>Camberlein</keyname><forenames>Ewen</forenames></author><author><keyname>di Carlo</keyname><forenames>Diego</forenames></author><author><keyname>Gaultier</keyname><forenames>Cl&#xe9;ment</forenames></author><author><keyname>Deleforge</keyname><forenames>Antoine</forenames></author><author><keyname>Bertin</keyname><forenames>Nancy</forenames></author></authors><title>Evaluation of an open-source implementation of the SRP-PHAT algorithm
  within the 2018 LOCATA challenge</title><categories>cs.SD eess.AS</categories><comments>In Proceedings of the LOCATA Challenge Workshop - a satellite event
  of IWAENC 2018 (arXiv:1811.08482 )</comments><report-no>LOCATAchallenge/2018/01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short paper presents an efficient, flexible implementation of the
SRP-PHAT multichannel sound source localization method. The method is evaluated
on the single-source tasks of the LOCATA 2018 development dataset, and an
associated Matlab toolbox is made available online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05902</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05902</id><created>2018-12-12</created><authors><author><keyname>Rajendran</keyname><forenames>Lalit K.</forenames></author><author><keyname>Bane</keyname><forenames>Sally P. M.</forenames></author><author><keyname>Vlachos</keyname><forenames>Pavlos P.</forenames></author></authors><title>PIV/BOS Synthetic Image Generation in Variable Density Environments for
  Error Analysis and Experiment Design</title><categories>eess.IV physics.flu-dyn physics.optics</categories><comments>11 pages, 4 figures. Submitted to Measurement Science and Technology</comments><doi>10.1088/1361-6501/ab1ca8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an image generation methodology based on ray tracing that can be
used to render realistic images of Particle Image Velocimetry (PIV) and
Background Oriented Schlieren (BOS) experiments in the presence of
density/refractive index gradients. This methodology enables the simulation of
aero-thermodynamics experiments for experiment design, error, and uncertainty
analysis. Images are generated by emanating light rays from the particles or
dot pattern, and propagating them through the density gradient field and the
optical elements, up to the camera sensor. The rendered images are realistic,
and can replicate the features of a given experimental setup, like optical
aberrations and perspective effects, which can be deliberately introduced for
error analysis. We demonstrate this methodology by simulating a BOS experiment
with a known density field obtained from direct numerical simulations (DNS) of
homogeneous buoyancy driven turbulence, and comparing the light ray
displacements from ray tracing to results from BOS theory. The light ray
displacements show good agreement with the reference data. This methodology
provides a framework for further development of simulation tools for use in
experiment design and development of image analysis tools for PIV and BOS
applications. An implementation of the proposed methodology in a Python-CUDA
program is made available as an open source software for researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05919</identifier>
 <datestamp>2018-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05919</id><created>2018-12-14</created><authors><author><keyname>Nimr</keyname><forenames>Ahmad</forenames></author><author><keyname>Chafii</keyname><forenames>Marwa</forenames></author><author><keyname>Fettweis</keyname><forenames>Gerhard</forenames></author></authors><title>Practical GFDM-based Linear Receivers</title><categories>eess.SP</categories><comments>Accepted in the 12th International ITG Conference on Systems,
  Communications and Coding 2019, Rostock, Germany</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conventional receiver designs of generalized frequency division
multiplexing (GFDM) consider a large scale multiple-input multiple-output
(MIMO) system with a block circular matrix of combined channel and modulation.
Exploiting this structure, several approaches have been proposed for low
complexity joint linear minimum mean squared error (LMMSE) receiver. However,
the joint design is complicated and inappropriate for hardware implementation.
In this paper, we define the concept of GFDM-based linear receivers, which
first performs channel equalization (CEq) and afterwards the equalized signal
is processed with GFDM demodulator. We show that the optimal joint LMMSE
receiver is equivalent to a GFDM-based one, that applies LMMSE-CEq and
zero-forcing demodulation. For orthogonal modulation, the optimal LMMSE
receiver has an implementation-friendly structure. For the non-orthogonal case,
we propose two practical designs that approach the performance of the joint
LMMSE. Finally, we analytically prove that GFDM-based receivers achieve equal
signal-to-interference-plus-noise ratio per subsymbols within the same
subcarrier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05920</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05920</id><created>2018-12-13</created><updated>2019-02-15</updated><authors><author><keyname>Ravanelli</keyname><forenames>Mirco</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Speech and Speaker Recognition from Raw Waveform with SincNet</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>arXiv admin note: substantial text overlap with arXiv:1811.09725,
  arXiv:1808.00158</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep neural networks can learn complex and abstract representations, that are
progressively obtained by combining simpler ones. A recent trend in speech and
speaker recognition consists in discovering these representations starting from
raw audio samples directly. Differently from standard hand-crafted features
such as MFCCs or FBANK, the raw waveform can potentially help neural networks
discover better and more customized representations. The high-dimensional raw
inputs, however, can make training significantly more challenging. This paper
summarizes our recent efforts to develop a neural architecture that efficiently
processes speech from audio waveforms. In particular, we propose SincNet, a
novel Convolutional Neural Network (CNN) that encourages the first layer to
discover meaningful filters by exploiting parametrized sinc functions. In
contrast to standard CNNs, which learn all the elements of each filter, only
low and high cutoff frequencies of band-pass filters are directly learned from
data. This inductive bias offers a very compact way to derive a customized
front-end, that only depends on some parameters with a clear physical meaning.
Our experiments, conducted on both speaker and speech recognition, show that
the proposed architecture converges faster, performs better, and is more
computationally efficient than standard CNNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05945</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05945</id><created>2018-12-14</created><updated>2019-09-27</updated><authors><author><keyname>Omeiza</keyname><forenames>Daniel</forenames></author><author><keyname>Adewole</keyname><forenames>Kayode</forenames></author><author><keyname>Nkemelu</keyname><forenames>Daniel</forenames></author></authors><title>EEG-based Communication with a Predictive Text Algorithm</title><categories>cs.HC cs.IR cs.LG eess.SP</categories><comments>Conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several changes occur in the brain in response to voluntary and involuntary
activities performed by a person. The ability to retrieve data from the brain
within a time space provides basis for in-depth analyses that offer insight on
what changes occur in the brain during its decision making processes. In this
work, we present the technical description and software implementation of an
electroencephalographic (EEG) based intelligent communication system. We use
EEG dry sensors to read brain waves data in real-time with which we compute the
likelihood that a voluntary eye blink has been made by a person and use the
decision to trigger buttons on a user interface in order to produce text using
a modification of the T9 algorithm. Our results indicate that EEG-based
technology can be effectively applied in facilitating speech for people with
severe speech and muscular disabilities, providing a foundation for future work
in the area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05954</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05954</id><created>2018-12-14</created><updated>2019-06-20</updated><authors><author><keyname>Cordero-Grande</keyname><forenames>Lucilio</forenames></author><author><keyname>Christiaens</keyname><forenames>Daan</forenames></author><author><keyname>Hutter</keyname><forenames>Jana</forenames></author><author><keyname>Price</keyname><forenames>Anthony N.</forenames></author><author><keyname>Hajnal</keyname><forenames>Joseph V.</forenames></author></authors><title>Complex diffusion-weighted image estimation via matrix recovery under
  general noise models</title><categories>eess.IV stat.AP</categories><comments>26 pages, 9 figures</comments><msc-class>62P10</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a patch-based singular value shrinkage method for diffusion
magnetic resonance image estimation targeted at low signal to noise ratio and
accelerated acquisitions. It operates on the complex data resulting from a
sensitivity encoding reconstruction, where asymptotically optimal signal
recovery guarantees can be attained by modeling the noise propagation in the
reconstruction and subsequently simulating or calculating the limit singular
value spectrum. Simple strategies are presented to deal with phase
inconsistencies and optimize patch construction. The pertinence of our
contributions is quantitatively validated on synthetic data, an in vivo adult
example, and challenging neonatal and fetal cohorts. Our methodology is
compared with related approaches, which generally operate on magnitude-only
data and use data-based noise level estimation and singular value truncation.
Visual examples are provided to illustrate effectiveness in generating denoised
and debiased diffusion estimates with well preserved spatial and diffusion
detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05971</identifier>
 <datestamp>2018-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05971</id><created>2018-12-14</created><authors><author><keyname>Bechensteen</keyname><forenames>Arne</forenames></author><author><keyname>Blanc-F&#xe9;raud</keyname><forenames>Laure</forenames></author><author><keyname>Aubert</keyname><forenames>Gilles</forenames></author></authors><title>Single molecule localization by $\ell_2-\ell_0$ constrained optimization</title><categories>eess.IV cs.IT math.IT math.OC</categories><comments>In Proceedings of iTWIST'18, Paper-ID: 13, Marseille, France,
  November, 21-23, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single Molecule Localization Microscopy (SMLM) enables the acquisition of
high-resolution images by alternating between activation of a sparse subset of
fluorescent molecules present in a sample and localization. In this work, the
localization problem is formulated as a constrained sparse approximation
problem which is resolved by rewriting the $\ell_0$ pseudo-norm using an
auxiliary term. In the preliminary experiments with the simulated ISBI datasets
the algorithm yields as good results as the state-of-the-art in high-density
molecule localization algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.05981</identifier>
 <datestamp>2018-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.05981</id><created>2018-12-14</created><authors><author><keyname>Douglas</keyname><forenames>Scott C.</forenames></author><author><keyname>Yu</keyname><forenames>Jiutian</forenames></author></authors><title>Why ReLU Units Sometimes Die: Analysis of Single-Unit Error
  Backpropagation in Neural Networks</title><categories>cs.LG eess.SP stat.ML</categories><comments>5 pages, 7 figures, Proc. 52nd Asilomar Conference on Signals,
  Systems, and Computers, Pacific Grove, CA, October 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, neural networks in machine learning use rectified linear units
(ReLUs) in early processing layers for better performance. Training these
structures sometimes results in &quot;dying ReLU units&quot; with near-zero outputs. We
first explore this condition via simulation using the CIFAR-10 dataset and
variants of two popular convolutive neural network architectures. Our
explorations show that the output activation probability Pr[y&gt;0] is generally
less than 0.5 at system convergence for layers that do not employ skip
connections, and this activation probability tends to decrease as one
progresses from input layer to output layer. Employing a simplified model of a
single ReLU unit trained by a variant of error backpropagation, we then perform
a statistical convergence analysis to explore the model's evolutionary
behavior. Our analysis describes the potentially-slower convergence speeds of
dying ReLU units, and this issue can occur regardless of how the weights are
initialized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06029</identifier>
 <datestamp>2018-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06029</id><created>2018-12-14</created><authors><author><keyname>Reyhani-Galangashi</keyname><forenames>Omid</forenames></author></authors><title>A Brief Overview of Novel Approaches in Designing High Performance VCOs</title><categories>eess.SP</categories><comments>4 pages, 10 figures, 2016 1st International Conference on New
  Research Achievements in Electrical and Computer Engineering, Tehran, Iran</comments><journal-ref>2016 1st International Conference on New Research Achievements in
  Electrical and Computer Engineering, Held in AmirKabir University of
  Technology, Tehran, Iran</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Not only a voltage controlled oscillator (VCO) is one of the most significant
component of every telecommunication system, but also it has been widely used
in many other high-speed systems. In fact, a VCO has an important role in
system operation, in other word, VCO is the heart of a system which gives
existence to it. Nowadays, designing a high performance VCO for different
applications is a challenging task for engineers. Moreover, up to now many
designs and solutions have been proposed by the scientists to improve the
performance of VCOs to be exploited in different cutting-edge applications. In
this paper I will give a brief overview of the new techniques in designing high
performance VCOs. Furthermore, the results of the proposed solutions have been
compared with each other to see which method has advantages over the others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06087</identifier>
 <datestamp>2019-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06087</id><created>2018-12-14</created><updated>2019-05-06</updated><authors><author><keyname>Michelashvili</keyname><forenames>Michael</forenames></author><author><keyname>Benaim</keyname><forenames>Sagie</forenames></author><author><keyname>Wolf</keyname><forenames>Lior</forenames></author></authors><title>Semi-Supervised Monaural Singing Voice Separation With a Masking Network
  Trained on Synthetic Mixtures</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of semi-supervised singing voice separation, in which
the training data contains a set of samples of mixed music (singing and
instrumental) and an unmatched set of instrumental music. Our solution employs
a single mapping function g, which, applied to a mixed sample, recovers the
underlying instrumental music, and, applied to an instrumental sample, returns
the same sample. The network g is trained using purely instrumental samples, as
well as on synthetic mixed samples that are created by mixing reconstructed
singing voices with random instrumental samples. Our results indicate that we
are on a par with or better than fully supervised methods, which are also
provided with training samples of unmixed singing voices, and are better than
other recent semi-supervised methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06220</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06220</id><created>2018-12-14</created><authors><author><keyname>Chen</keyname><forenames>Haiyong</forenames></author><author><keyname>Pang</keyname><forenames>Yue</forenames></author><author><keyname>Hu</keyname><forenames>Qidi</forenames></author><author><keyname>Liu</keyname><forenames>Kun</forenames></author></authors><title>Solar Cell Surface Defect Inspection Based on Multispectral
  Convolutional Neural Network</title><categories>cs.CV eess.IV</categories><comments>14 pages, 7 figures,14 tables</comments><doi>10.1007/s10845-018-1458-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similar and indeterminate defect detection of solar cell surface with
heterogeneous texture and complex background is a challenge of solar cell
manufacturing. The traditional manufacturing process relies on human eye
detection which requires a large number of workers without a stable and good
detection effect. In order to solve the problem, a visual defect detection
method based on multi-spectral deep convolutional neural network (CNN) is
designed in this paper. Firstly, a selected CNN model is established. By
adjusting the depth and width of the model, the influence of model depth and
kernel size on the recognition result is evaluated. The optimal CNN model
structure is selected. Secondly, the light spectrum features of solar cell
color image are analyzed. It is found that a variety of defects exhibited
different distinguishable characteristics in different spectral bands. Thus, a
multi-spectral CNN model is constructed to enhance the discrimination ability
of the model to distinguish between complex texture background features and
defect features. Finally, some experimental results and K-fold cross validation
show that the multi-spectral deep CNN model can effectively detect the solar
cell surface defects with higher accuracy and greater adaptability. The
accuracy of defect recognition reaches 94.30%. Applying such an algorithm can
increase the efficiency of solar cell manufacturing and make the manufacturing
process smarter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06238</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06238</id><created>2018-12-15</created><authors><author><keyname>Hattab</keyname><forenames>Ghaith</forenames></author><author><keyname>Cabric</keyname><forenames>Danijela</forenames></author></authors><title>Distributed Wideband Sensing-based Architecture for Unlicensed Massive
  IoT Communications</title><categories>eess.SP</categories><comments>The paper is submitted to the IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing Internet connectivity to a massive number of Internet-of-things
(IoT) objects over the unlicensed spectrum requires: (i) identifying a very
large number of narrowband channels in a wideband spectrum and (ii)
aggressively reusing the available channels over space to accommodate the high
density of IoT devices. To this end, we propose a sensing-based architecture
that identifies spectral and spatial resources at a fine resolution. In
particular, we first propose a sensing assignment scheduler, where each base
station (BS) is assigned a subset of the spectrum to sense at a high
resolution. We then propose a distributed sensing algorithm, where BSs locally
process and share their sensing reports, so that each BS obtains occupancy
information of the wideband spectrum at its location. Once the spatio-spectral
resource blocks are identified, we further propose a distributed resource
allocation algorithm that maintains high spatial reuse of spectral
opportunities while limiting the intra-network and inter-network interference.
Numerical simulations are presented to validate the effectiveness of the
proposed distributed algorithms, comparing them to centralized and
non-cooperative schemes. It is shown that our architecture identifies more
spatio-spectral resources, with lower misdetection of incumbents. As a result,
more IoT devices are connected with limited interference into incumbents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06349</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06349</id><created>2018-12-15</created><updated>2019-11-21</updated><authors><author><keyname>Barkan</keyname><forenames>Oren</forenames></author><author><keyname>Tsiris</keyname><forenames>David</forenames></author><author><keyname>Katz</keyname><forenames>Ori</forenames></author><author><keyname>Koenigstein</keyname><forenames>Noam</forenames></author></authors><title>InverSynth: Deep Estimation of Synthesizer Parameter Configurations from
  Audio Signals</title><categories>cs.SD eess.AS stat.ML</categories><comments>To appear in IEEE/ACM Transactions on Audio Speech and Language
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sound synthesis is a complex field that requires domain expertise. Manual
tuning of synthesizer parameters to match a specific sound can be an exhaustive
task, even for experienced sound engineers. In this paper, we introduce
InverSynth - an automatic method for synthesizer parameters tuning to match a
given input sound. InverSynth is based on strided convolutional neural networks
and is capable of inferring the synthesizer parameters configuration from the
input spectrogram and even from the raw audio. The effectiveness InverSynth is
demonstrated on a subtractive synthesizer with four frequency modulated
oscillators, envelope generator and a gater effect. We present extensive
quantitative and qualitative results that showcase the superiority InverSynth
over several baselines. Furthermore, we show that the network depth is an
important factor that contributes to the prediction accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06363</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06363</id><created>2018-12-15</created><updated>2019-08-26</updated><authors><author><keyname>Huang</keyname><forenames>Tong</forenames></author><author><keyname>Freris</keyname><forenames>Nikolaos M.</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author><author><keyname>Xie</keyname><forenames>Le</forenames></author></authors><title>A Synchrophasor Data-driven Method for Forced Oscillation Localization
  under Resonance Conditions</title><categories>eess.SP</categories><comments>This manuscript has been submitted to IEEE Transactions on Power
  Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a data-driven algorithm of locating the source of forced
oscillations and suggests the physical interpretation of the method. By
leveraging the sparsity of the forced oscillation sources along with the
low-rank nature of synchrophasor data, the problem of source localization under
resonance conditions is cast as computing the sparse and low-rank components
using Robust Principal Component Analysis (RPCA), which can be efficiently
solved by the exact Augmented Lagrange Multiplier method. Based on this problem
formulation, an efficient and practically implementable algorithm is proposed
to pinpoint the forced oscillation source during real-time operation.
Furthermore, we provide theoretical insights into the efficacy of the proposed
approach by use of physical model-based analysis, in specific by establishing
the fact that the rank of the resonance component matrix is at most 2. The
effectiveness of the proposed method is validated in the IEEE 68-bus power
system and the WECC 179-bus benchmark system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06594</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06594</id><created>2018-12-02</created><authors><author><keyname>Keller</keyname><forenames>Sebastian Mathias</forenames><affiliation>Cozak</affiliation></author><author><keyname>Samarin</keyname><forenames>Maxim</forenames><affiliation>Cozak</affiliation></author><author><keyname>Meyer</keyname><forenames>Antonia</forenames><affiliation>Cozak</affiliation></author><author><keyname>Kosak</keyname><forenames>Vitalii</forenames><affiliation>Cozak</affiliation></author><author><keyname>Gschwandtner</keyname><forenames>Ute</forenames></author><author><keyname>Fuhr</keyname><forenames>Peter</forenames></author><author><keyname>Roth</keyname><forenames>Volker</forenames></author></authors><title>Computational EEG in Personalized Medicine: A study in Parkinson's
  Disease</title><categories>q-bio.NC cs.LG eess.SP q-bio.QM stat.ML</categories><comments>Machine Learning for Health (ML4H) Workshop at NeurIPS 2018
  arXiv:811.07216</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recordings of electrical brain activity carry information about a person's
cognitive health. For recording EEG signals, a very common setting is for a
subject to be at rest with its eyes closed. Analysis of these recordings often
involve a dimensionality reduction step in which electrodes are grouped into 10
or more regions (depending on the number of electrodes available). Then an
average over each group is taken which serves as a feature in subsequent
evaluation. Currently, the most prominent features used in clinical practice
are based on spectral power densities. In our work we consider a simplified
grouping of electrodes into two regions only. In addition to spectral features
we introduce a secondary, non-redundant view on brain activity through the lens
of Tsallis Entropy $S_{q=2}$. We further take EEG measurements not only in an
eyes closed (ec) but also in an eyes open (eo) state. For our cohort of healthy
controls (HC) and individuals suffering from Parkinson's disease (PD), the
question we are asking is the following: How well can one discriminate between
HC and PD within this simplified, binary grouping? This question is motivated
by the commercial availability of inexpensive and easy to use portable EEG
devices. If enough information is retained in this binary grouping, then such
simple devices could potentially be used as personal monitoring tools, as
standard screening tools by general practitioners or as digital biomarkers for
easy long term monitoring during neurological studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06595</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06595</id><created>2018-12-16</created><authors><author><keyname>Ouyang</keyname><forenames>Chongjun</forenames></author><author><keyname>Yang</keyname><forenames>Hongwen</forenames></author></authors><title>Massive MIMO Antenna Selection: Asymptotic Upper Capacity Bound and
  Partial CSI</title><categories>eess.SP</categories><comments>Part of this article is submitted to 2019 ICC</comments><msc-class>41-00</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Antenna selection (AS) is regarded as the key promising technology to reduce
hardware cost but keep relatively high spectral efficiency in multi-antenna
systems. By selecting a subset of antennas to transceive messages, AS greatly
alleviates the requirement on Radio Frequency (RF) chains. This paper studies
receive antenna selection in massive multiple-input multiple-output (MIMO)
systems. The receiver, equipped with a large-scale antenna array whose size is
much larger than that of the transmitter, selects a subset of antennas to
receive messages. A low-complexity asymptotic approximated upper capacity bound
is derived in the limit of massive MIMO systems over independent and identical
distributed (i.i.d.) Rayleigh flat fading channel, assuming that the channel
side information (CSI) is only available at the receiver. Furthermore,
numerical simulations are provided to demonstrate the approximation precision
of the asymptotic results and the tightness of the capacity bound. Besides the
asymptotic analysis of the upper bound, more discussions on the ergodic
capacity of the antenna selection systems are exhibited. By defining the number
of corresponding rows in the channel matrix as the amount of acquired CSI, the
relationship between the achievable channel capacity and the amount of acquired
CSI is investigated. Our findings indicate that this relationship approximately
follows the Pareto principle, i.e., most of the capacity can be achieved by
acquiring a small portion of full CSI. Finally, on the basis of this observed
law, an adaptive AS algorithm is proposed, which can achieve most of the
transmission rate but requires much less CSI and computation complexity
compared to state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06603</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06603</id><created>2018-12-16</created><authors><author><keyname>Khawaja</keyname><forenames>Wahab</forenames></author><author><keyname>Ozdemir</keyname><forenames>Ozgur</forenames></author><author><keyname>Erden</keyname><forenames>Fatih</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Matolak</keyname><forenames>David</forenames></author></authors><title>UWB Air-to-Ground Propagation Channel Measurements and Modeling using
  UAVs</title><categories>eess.SP</categories><comments>This paper is accepted for publication in Aerospace 2019 Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an experimental study of the air-to-ground (AG)
propagation channel through ultrawideband(UWB) measurements in an open area
using unmanned-aerial-vehicles (UAVs). Measurements were performed using UWB
radios operating at a frequency range of 3.1 GHz - 4.8 GHz and UWB planar
elliptical dipole antennas having an omni-directional pattern in the azimuth
plane and typical donut shaped pattern in the elevation plane. Three scenarios
were considered for the channel measurements: (i)two receivers (RXs) at
different heights above the ground and placed close to each other in
line-of-sight (LOS) with the transmitter (TX) on the UAV and the UAV is
hovering; (ii) RXs are in obstructed line-of-sight (OLOS) with the UAV TX due
to foliage, and the UAV is hovering; and, (iii) UAV is moving in a circular
path. Different horizontal and vertical distances between the RXs and TX were
used in the measurements. In addition, two different antenna orientations were
used on the UAV antennas (vertical and horizontal) to analyze the effects of
antenna radiation patterns on the UWB AG propagation. From the empirical
results, it was observed that the received power depends mainly on the antenna
radiation pattern in the elevation plane when the antennas are oriented in the
same direction, as expected for these omni-azimuth antennas. Moreover, the
overall antenna gain at the TX and RX can be approximated using trigonometric
functions of the elevation angle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06613</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06613</id><created>2018-12-16</created><authors><author><keyname>Xu</keyname><forenames>Zhijing</forenames></author><author><keyname>Wang</keyname><forenames>Juan</forenames></author><author><keyname>Zhang</keyname><forenames>Ying</forenames></author><author><keyname>He</keyname><forenames>Xiangjian</forenames></author></authors><title>Voiceprint recognition of Parkinson patients based on deep learning</title><categories>cs.SD cs.CV cs.LG eess.AS</categories><comments>10 pages,4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  More than 90% of the Parkinson Disease (PD) patients suffer from vocal
disorders. Speech impairment is already indicator of PD. This study focuses on
PD diagnosis through voiceprint features. In this paper, a method based on Deep
Neural Network (DNN) recognition and classification combined with Mini-Batch
Gradient Descent (MBGD) is proposed to distinguish PD patients from healthy
people using voiceprint features. In order to exact the voiceprint features
from patients, Weighted Mel Frequency Cepstrum Coefficients (WMFCC) is applied.
The proposed method is tested on experimental data obtained by the voice
recordings of three sustained vowels /a/, /o/ and /u/ from participants (48 PD
and 20 healthy people). The results show that the proposed method achieves a
high accuracy of diagnosis of PD patients from healthy people, than the
conventional methods like Support Vector Machine (SVM) and other mentioned in
this paper. The accuracy achieved is 89.5%. WMFCC approach can solve the
problem that the high-order cepstrum coefficients are small and the features
component's representation ability to the audio is weak. MBGD reduces the
computational loads of the loss function, and increases the training speed of
the system. DNN classifier enhances the classification ability of voiceprint
features. Therefore, the above approaches can provide a solid solution for the
quick auxiliary diagnosis of PD in early stage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06635</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06635</id><created>2018-12-17</created><updated>2019-07-05</updated><authors><author><keyname>Dantas</keyname><forenames>Cassio Fraga</forenames><affiliation>PANAMA</affiliation></author><author><keyname>Gribonval</keyname><forenames>R&#xe9;mi</forenames><affiliation>PANAMA</affiliation></author></authors><title>Stable safe screening and structured dictionaries for faster L1
  regularization</title><categories>cs.LG eess.SP stat.ML</categories><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Signal Processing, Institute of Electrical
  and Electronics Engineers, 2019, 67 (14), pp.3756-3769</journal-ref><doi>10.1109/TSP.2019.2919404</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a way to combine two acceleration techniques for
the $\ell\_{1}$-regularized least squares problem: safe screening tests, which
allow to eliminate useless dictionary atoms; and the use of fast structured
approximations of the dictionary matrix. To do so, we introduce a new family of
screening tests, termed stable screening, which can cope with approximation
errors on the dictionary atoms while keeping the safety of the test (i.e. zero
risk of rejecting atoms belonging to the solution support). Some of the main
existing screening tests are extended to this new framework. The proposed
algorithm consists in using a coarser (but faster) approximation of the
dictionary at the initial iterations and then switching to better
approximations until eventually adopting the original dictionary. A systematic
switching criterion based on the duality gap saturation and the screening ratio
is derived.Simulation results show significant reductions in both computational
complexity and execution times for a wide range of tested scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06638</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06638</id><created>2018-12-17</created><updated>2018-12-19</updated><authors><author><keyname>Jiang</keyname><forenames>Peiwen</forenames></author><author><keyname>Wang</keyname><forenames>Tianqi</forenames></author><author><keyname>Han</keyname><forenames>Bin</forenames></author><author><keyname>Gao</keyname><forenames>Xuanxuan</forenames></author><author><keyname>Zhang</keyname><forenames>Jing</forenames></author><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>Artificial Intelligence-aided OFDM Receiver: Design and Experimental
  Results</title><categories>eess.SP cs.IT cs.LG math.IT stat.ML</categories><comments>29 pages, 13 figures, submitted to IEEE Journal on Selected Areas in
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal frequency division multiplexing (OFDM) is one of the key
technologies that are widely applied in current communication systems.
Recently, artificial intelligence (AI)-aided OFDM receivers have been brought
to the forefront to break the bottleneck of the traditional OFDM systems. In
this paper, we investigate two AI-aided OFDM receivers, data-driven fully
connected-deep neural network (FC-DNN) receiver and model-driven ComNet
receiver, respectively. We first study their performance under different
channel models through simulation and then establish a real-time video
transmission system using a 5G rapid prototyping (RaPro) system for
over-the-air (OTA) test. To address the performance gap between the simulation
and the OTA test caused by the discrepancy between the channel model for
offline training and real environments, we develop a novel online training
strategy, called SwitchNet receiver. The SwitchNet receiver is with a flexible
and extendable architecture and can adapts to real channel by training one
parameter online. The OTA test verifies its feasibility and robustness to real
environments and indicates its potential for future communications systems. At
the end of this paper, we discuss some challenges to inspire future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06669</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06669</id><created>2018-12-17</created><updated>2019-06-12</updated><authors><author><keyname>Colombo</keyname><forenames>Florian</forenames></author><author><keyname>Brea</keyname><forenames>Johanni</forenames></author><author><keyname>Gerstner</keyname><forenames>Wulfram</forenames></author></authors><title>Learning to Generate Music with BachProp</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><journal-ref>in Proceedings of the 16th Sound and Music Computing Conference.
  2019. p. 380-386</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As deep learning advances, algorithms of music composition increase in
performance. However, most of the successful models are designed for specific
musical structures. Here, we present BachProp, an algorithmic composer that can
generate music scores in many styles given sufficient training data. To adapt
BachProp to a broad range of musical styles, we propose a novel representation
of music and train a deep network to predict the note transition probabilities
of a given music corpus. In this paper, new music scores generated by BachProp
are compared with the original corpora as well as with different network
architectures and other related models. We show that BachProp captures
important features of the original datasets better than other models and invite
the reader to a qualitative comparison on a large collection of generated
songs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06672</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06672</id><created>2018-12-17</created><authors><author><keyname>Dekkers</keyname><forenames>Gert</forenames></author><author><keyname>Rosas</keyname><forenames>Fernando</forenames></author><author><keyname>Lauwereins</keyname><forenames>Steven</forenames></author><author><keyname>Rajendran</keyname><forenames>Sreeraj</forenames></author><author><keyname>Pollin</keyname><forenames>Sofie</forenames></author><author><keyname>Vanrumste</keyname><forenames>Bart</forenames></author><author><keyname>van Waterschoot</keyname><forenames>Toon</forenames></author><author><keyname>Verhelst</keyname><forenames>Marian</forenames></author><author><keyname>Karsmakers</keyname><forenames>Peter</forenames></author></authors><title>A multi-layered energy consumption model for smart wireless acoustic
  sensor networks</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart sensing is expected to become a pervasive technology in smart cities
and environments of the near future. These services are improving their
capabilities due to integrated devices shrinking in size while maintaining
their computational power, which can run diverse Machine Learning algorithms
and achieve high performance in various data-processing tasks. One attractive
sensor modality to be used for smart sensing are acoustic sensors, which can
convey highly informative data while keeping a moderate energy consumption.
Unfortunately, the energy budget of current wireless sensor networks is usually
not enough to support the requirements of standard microphones. Therefore,
energy efficiency needs to be increased at all layers --- sensing, signal
processing and communication --- in order to bring wireless smart acoustic
sensors into the market. To help to attain this goal, this paper introduces
WASN-EM: an energy consumption model for wireless acoustic sensors networks
(WASN), whose aim is to aid in the development of novel techniques to increase
the energy-efficient of smart wireless acoustic sensors. This model provides a
first step of exploration prior to custom design of a smart wireless acoustic
sensor, and also can be used to compare the energy consumption of different
protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06697</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06697</id><created>2018-12-17</created><authors><author><keyname>Mosgaard</keyname><forenames>Lars D.</forenames></author><author><keyname>Pelegrin-Garcia</keyname><forenames>David</forenames></author><author><keyname>Elmedyb</keyname><forenames>Thomas B.</forenames></author><author><keyname>Pihl</keyname><forenames>Michael J.</forenames></author><author><keyname>Mowlaee</keyname><forenames>Pejman</forenames></author></authors><title>Circular Statistics-based low complexity DOA estimation for hearing aid
  application</title><categories>cs.SD eess.AS</categories><comments>In Proceedings of the LOCATA Challenge Workshop - a satellite event
  of IWAENC 2018 (arXiv:1811.08482 )</comments><report-no>LOCATAchallenge/2018/08</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proposed Circular statistics-based Inter-Microphone Phase difference
estimation Localizer (CIMPL) method is tailored toward binaural hearing aid
systems with microphone arrays in each unit. The method utilizes the circular
statistics (circular mean and circular variance) of inter-microphone phase
difference (IPD) across different microphone pairs. These IPDs are firstly
mapped to time delays through a variance-weighted linear fit, then mapped to
azimuth direction-of-arrival (DoA) and lastly information of different
microphone pairs is combined. The variance is carried through the different
transformations and acts as a reliability index of the estimated angle. Both
the resulting angle and variance are fed into a wrapped Kalman filter, which
provides a smoothed estimate of the DoA. The proposed method improves the
accuracy of the tracked angle of a single moving source compared with the
benchmark method provided by the LOCATA challenge, and it runs approximately 75
times faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06719</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06719</id><created>2018-12-17</created><authors><author><keyname>Dirksen</keyname><forenames>Sjoerd</forenames></author><author><keyname>Mendelson</keyname><forenames>Shahar</forenames></author></authors><title>Robust one-bit compressed sensing with partial circulant matrices</title><categories>cs.IT eess.SP math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present optimal sample complexity estimates for one-bit compressed sensing
problems in a realistic scenario: the procedure uses a structured matrix (a
randomly sub-sampled circulant matrix) and is robust to analog pre-quantization
noise as well as to adversarial bit corruptions in the quantization process.
Our results imply that quantization is not a statistically expensive procedure
in the presence of nontrivial analog noise: recovery requires the same sample
size one would have needed had the measurement matrix been Gaussian and the
noisy analog measurements been given as data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06723</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06723</id><created>2018-12-17</created><authors><author><keyname>Jovicic</keyname><forenames>Aleksandar</forenames></author><author><keyname>Jereminov</keyname><forenames>Marko</forenames></author><author><keyname>Pileggi</keyname><forenames>Larry</forenames></author><author><keyname>Hug</keyname><forenames>Gabriela</forenames></author></authors><title>An Equivalent Circuit Formulation for Power System State Estimation
  including PMUs</title><categories>eess.SP</categories><comments>2018 North American Power Symposium, Fargo, ND</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel formulation for the power system state estimation is
proposed, based on the recently introduced equivalent split-circuit formulation
of the power flow problem. The formulation models the conventional and time
synchronized measurements simultaneously and contains a significantly lower
level of nonlinearity compared to the available hybrid state estimators. The
appropriate circuit models are derived for different types of measurements and
integrated into the existing circuit framework for the power flow problem. A
constrained optimization problem is then formulated to estimate the states of
the system in rectangular coordinates, while satisfying the circuit equations
and bounds on the measurement data. To further prove the concept and validate
the accuracy of the proposed formulation, several test cases are solved and the
results are presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06737</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06737</id><created>2018-12-17</created><authors><author><keyname>Kervazo</keyname><forenames>Christophe</forenames></author><author><keyname>Bobin</keyname><forenames>Jerome</forenames></author><author><keyname>Chenot</keyname><forenames>Cecile</forenames></author></authors><title>Heuristics for Efficient Sparse Blind Source Separation</title><categories>cs.LG astro-ph.IM eess.SP stat.ML</categories><comments>in Proceedings of iTWIST'18, Paper-ID: 11, Marseille, France,
  November, 21-23, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse Blind Source Separation (sparse BSS) is a key method to analyze
multichannel data in fields ranging from medical imaging to astrophysics.
However, since it relies on seeking the solution of a non-convex penalized
matrix factorization problem, its performances largely depend on the
optimization strategy. In this context, Proximal Alternating Linearized
Minimization (PALM) has become a standard algorithm which, despite its
theoretical grounding, generally provides poor practical separation results. In
this work, we propose a novel strategy that combines a heuristic approach with
PALM. We show its relevance on realistic astrophysical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06798</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06798</id><created>2018-12-14</created><authors><author><keyname>Immink</keyname><forenames>Kees A. Schouhamer</forenames></author><author><keyname>Cai</keyname><forenames>Kui</forenames></author></authors><title>Properties and constructions of constrained codes for DNA-based data
  storage</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe properties and constructions of constraint-based codes for
DNA-based data storage which account for the maximum repetition length and
AT/GC balance. We present algorithms for computing the number of sequences with
maximum repetition length and AT/GC balance constraint. We describe routines
for translating binary runlength limited and/or balanced strings into DNA
strands, and compute the efficiency of such routines. We show that the
implementation of AT/GC-balanced codes is straightforward accomplished with
binary balanced codes. We present codes that account for both the maximum
repetition length and AT/GC balance. We compute the redundancy difference
between the binary and a fully fledged quaternary approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06799</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06799</id><created>2018-12-14</created><authors><author><keyname>Sirichotedumrong</keyname><forenames>Warit</forenames></author><author><keyname>Chuman</keyname><forenames>Tatsuya</forenames></author><author><keyname>Kiya</keyname><forenames>Hitoshi</forenames></author></authors><title>Grayscale-Based Image Encryption Considering Color Sub-sampling
  Operation for Encryption-then-Compression Systems</title><categories>cs.CR cs.MM eess.IV</categories><comments>Accepted in 2018 IEEE 7th Global Conference on Consumer Electronics
  (GCCE 2018). arXiv admin note: text overlap with arXiv:1810.13067</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new grayscale-based block scrambling image encryption scheme is presented
to enhance the security of Encryption-then-Compression (EtC) systems, which are
used to securely transmit images through an untrusted channel provider. The
proposed scheme enables the use of a smaller block size and a larger number of
blocks than the conventional scheme. Images encrypted using the proposed scheme
include less color information due to the use of grayscale images even when the
original image has three color channels. These features enhance security
against various attacks, such as jigsaw puzzle solver and brute-force attacks.
Moreover, it allows the use of color sub-sampling, which can improve the
compression performance, although the encrypted images have no color
information. In an experiment, encrypted images were uploaded to and then
downloaded from Facebook and Twitter, and the results demonstrated that the
proposed scheme is effective for EtC systems, while maintaining a high
compression performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06811</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06811</id><created>2018-12-17</created><authors><author><keyname>Comminiello</keyname><forenames>Danilo</forenames></author><author><keyname>Lella</keyname><forenames>Marco</forenames></author><author><keyname>Scardapane</keyname><forenames>Simone</forenames></author><author><keyname>Uncini</keyname><forenames>Aurelio</forenames></author></authors><title>Quaternion Convolutional Neural Networks for Detection and Localization
  of 3D Sound Events</title><categories>eess.AS cs.LG cs.SD</categories><comments>Submitted to ICASSP 2019</comments><journal-ref>2019 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)</journal-ref><doi>10.1109/ICASSP.2019.8682711</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning from data in the quaternion domain enables us to exploit internal
dependencies of 4D signals and treating them as a single entity. One of the
models that perfectly suits with quaternion-valued data processing is
represented by 3D acoustic signals in their spherical harmonics decomposition.
In this paper, we address the problem of localizing and detecting sound events
in the spatial sound field by using quaternion-valued data processing. In
particular, we consider the spherical harmonic components of the signals
captured by a first-order ambisonic microphone and process them by using a
quaternion convolutional neural network. Experimental results show that the
proposed approach exploits the correlated nature of the ambisonic signals, thus
improving accuracy results in 3D sound event detection and localization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06831</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06831</id><created>2018-12-17</created><updated>2018-12-17</updated><authors><author><keyname>Ma</keyname><forenames>Ganggang</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Zeng</keyname><forenames>Yong</forenames></author><author><keyname>Moghadam</keyname><forenames>Mohammad R. Vedady</forenames></author></authors><title>A Generic Receiver Architecture for MIMO Wireless Power Transfer with
  Non-Linear Energy Harvesting</title><categories>eess.SP</categories><doi>10.1109/LSP.2018.2890164</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter investigates a multiple-input multiple-output (MIMO) wireless
power transfer (WPT) system under practical non-liner energy harvesting (EH)
models. We propose a new generic energy receiver (ER) architecture consisting
of $N$ receive antennas and $L$ rectifiers, for which one power splitter is
inserted after each antenna to adaptively split the received radio frequency
(RF) signals among the $L$ rectifiers for efficient non-linear RF-to-direct
current (DC) conversion. With the proposed architecture, we maximize the total
harvested DC power at the ER, by jointly optimizing the transmit energy
beamforming at the energy transmitter (ET) and the power splitting ratios at
the ER. Numerical results show that our proposed design by exploiting the
nonlinearity of EH significantly improves the harvested DC power at the ER, as
compared to two conventional designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06856</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06856</id><created>2018-12-17</created><authors><author><keyname>Chuchvara</keyname><forenames>Aleksandra</forenames></author><author><keyname>Barsi</keyname><forenames>Attila</forenames></author><author><keyname>Gotchev</keyname><forenames>Atanas</forenames></author></authors><title>Fast and Accurate Depth Estimation from Sparse Light Fields</title><categories>eess.IV</categories><comments>15 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a fast and accurate method for dense depth reconstruction from
sparsely sampled light fields obtained using a synchronized camera array. In
our method, the source images are over-segmented into non-overlapping compact
superpixels that are used as basic data units for depth estimation and
refinement. Superpixel representation provides a desirable reduction in the
computational cost while preserving the image geometry with respect to the
object contours. Each superpixel is modeled as a plane in the image space,
allowing depth values to vary smoothly within the superpixel area. Initial
depth maps, which are obtained by plane sweeping, are iteratively refined by
propagating good correspondences within an image. To ensure the fast
convergence of the iterative optimization process, we employ a highly parallel
propagation scheme that operates on all the superpixels of all the images at
once, making full use of the parallel graphics hardware. A few optimization
iterations of the energy function incorporating superpixel-wise smoothness and
geometric consistency constraints allows to recover depth with high accuracy in
textured and textureless regions as well as areas with occlusions, producing
dense globally consistent depth maps. We demonstrate that while the depth
reconstruction takes about a second per full high-definition view, the accuracy
of the obtained depth maps is comparable with the state-of-the-art results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06857</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06857</id><created>2018-12-17</created><authors><author><keyname>Ozdenizci</keyname><forenames>Ozan</forenames></author><author><keyname>Wang</keyname><forenames>Ye</forenames></author><author><keyname>Koike-Akino</keyname><forenames>Toshiaki</forenames></author><author><keyname>Erdogmus</keyname><forenames>Deniz</forenames></author></authors><title>Transfer Learning in Brain-Computer Interfaces with Adversarial
  Variational Autoencoders</title><categories>cs.LG cs.HC eess.SP</categories><comments>9th International IEEE EMBS Conference on Neural Engineering (NER'19)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce adversarial neural networks for representation learning as a
novel approach to transfer learning in brain-computer interfaces (BCIs). The
proposed approach aims to learn subject-invariant representations by
simultaneously training a conditional variational autoencoder (cVAE) and an
adversarial network. We use shallow convolutional architectures to realize the
cVAE, and the learned encoder is transferred to extract subject-invariant
features from unseen BCI users' data for decoding. We demonstrate a
proof-of-concept of our approach based on analyses of electroencephalographic
(EEG) data recorded during a motor imagery BCI experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06858</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06858</id><created>2018-12-17</created><authors><author><keyname>Pan</keyname><forenames>Guangyuan</forenames></author><author><keyname>Fu</keyname><forenames>Liping</forenames></author><author><keyname>Yu</keyname><forenames>Ruifan</forenames></author><author><keyname>Muresan</keyname><forenames>Matthew</forenames></author></authors><title>Winter Road Surface Condition Recognition Using A Pretrained Deep
  Convolutional Network</title><categories>eess.IV cs.CV</categories><journal-ref>Transportation Research Board 97th Annual Meeting, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the application of the latest machine learning
technique deep neural networks for classifying road surface conditions (RSC)
based on images from smartphones. Traditional machine learning techniques such
as support vector machine (SVM) and random forests (RF) have been attempted in
literature; however, their classification performance has been less than
desirable due to challenges associated with image noises caused by sunlight
glare and residual salts. A deep learning model based on convolutional neural
network (CNN) is proposed and evaluated for its potential to address these
challenges for improved classification accuracy. In the proposed approach we
introduce the idea of applying an existing CNN model that has been pre-trained
using millions of images with proven high recognition accuracy. The model is
extended with two additional fully-connected layers of neurons for learning the
specific features of the RSC images. The whole model is then trained with a low
learning rate for fine-tuning by using a small set of RSC images. Results show
that the proposed model has the highest classification performance in
comparison to the traditional machine learning techniques. The testing accuracy
with different training dataset sizes is also analyzed, showing the potential
of achieving much higher accuracy with a larger training dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06888</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06888</id><created>2018-12-17</created><authors><author><keyname>Kisil</keyname><forenames>Ilia</forenames></author><author><keyname>Moniri</keyname><forenames>Ahmad</forenames></author><author><keyname>Mandic</keyname><forenames>Danilo P.</forenames></author></authors><title>Tensor Ensemble Learning for Multidimensional Data</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In big data applications, classical ensemble learning is typically infeasible
on the raw input data and dimensionality reduction techniques are necessary. To
this end, novel framework that generalises classic flat-view ensemble learning
to multidimensional tensor-valued data is introduced. This is achieved by
virtue of tensor decompositions, whereby the proposed method, referred to as
tensor ensemble learning (TEL), decomposes every input data sample into
multiple factors which allows for a flexibility in the choice of multiple
learning algorithms in order to improve test performance. The TEL framework is
shown to naturally compress multidimensional data in order to take advantage of
the inherent multi-way data structure and exploit the benefit of ensemble
learning. The proposed framework is verified through the application of Higher
Order Singular Value Decomposition (HOSVD) to the ETH-80 dataset and is shown
to outperform the classical ensemble learning approach of bootstrap
aggregating.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06928</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06928</id><created>2018-11-12</created><updated>2019-08-17</updated><authors><author><keyname>Younus</keyname><forenames>Safwan Hafeedh</forenames></author><author><keyname>Al-Hameed</keyname><forenames>Aubida A.</forenames></author><author><keyname>Elmirghani</keyname><forenames>Jaafar M. H.</forenames></author></authors><title>Multi-branch Transmitter for Indoor Visible Light Communication Systems</title><categories>eess.SP cs.NI physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main aims of indoor visible light communication (VLC) systems is
to deliver a high data rate service in single user and in multiuser scenarios.
A key obstacle is the ability of the indoor VLC channel to support high data
rates in the scenarios of interest. Here, we assess the potential of a
multi-branch transmitter (MBT) and its use to achieve higher data rates in
single user and multiuser indoor VLC systems. For the single user VLC system,
the performance of the MBT is examined with a wide field of view (W-FOV)
receiver and an angle diversity receiver (ADR) while for the multiuser VLC
system we evaluate the performance of the MBT with a non-imaging angle
diversity receiver (NI-ADR). In addition, for the multiuser VLC system, we
propose subcarrier multiplexing (SCM) tones to allocate an optimum transmitter
to each user. Furthermore, wavelength division multiplexing (WDM) is examined
to support higher data rates for each user while using on-off-keying (OOK)
modulation. In addition, the impact of the user's mobility on the multi-user
VLC system performance is studied. The effect of diffuse reflections, mobility
and lighting constraints are taken into account. In addition, the effect of
co-channel interference (CCI) is considered in the multiuser VLC system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06938</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06938</id><created>2018-11-12</created><authors><author><keyname>Younus</keyname><forenames>Safwan Hafeedh</forenames></author><author><keyname>Hussein</keyname><forenames>Ahmed Taha</forenames></author><author><keyname>Alresheedi</keyname><forenames>Mohammed T.</forenames></author><author><keyname>Elmirghani</keyname><forenames>Jaafar M. H.</forenames></author></authors><title>VLC Systems with CGHs</title><categories>eess.SP cs.NI physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The achievable data rate in indoor wireless systems that employ visible light
communication (VLC) can be limited by multipath propagation. Here, we use
computer generated holograms (CGHs) in VLC system design to improve the
achievable system data rate. The CGHs are utilized to produce a fixed broad
beam from the light source, selecting the light source that offers the best
performance. The CGHs direct this beam to a specific zone on the room's
communication floor where the receiver is located. This reduces the effect of
diffuse reflections. Consequently, decreasing the intersymbol interference
(ISI) and enabling the VLC indoor channel to support higher data rates. We
consider two settings to examine our propose VLC system and consider lighting
constraints. We evaluate the performance in idealistic and realistic room
setting in a diffuse environment with up to second order reflections and also
under mobility. The results show that using the CGHs enhances the 3dB bandwidth
of the VLC channel and improves the received optical power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06953</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06953</id><created>2018-12-17</created><authors><author><keyname>Malekzadeh</keyname><forenames>Saber</forenames></author><author><keyname>Gholizadeh</keyname><forenames>Mohammad Hossein</forenames></author><author><keyname>Razavi</keyname><forenames>Seyed Naser</forenames></author></authors><title>Persian Vowel recognition with MFCC and ANN on PCVC speech dataset</title><categories>cs.SD cs.CL cs.LG eess.AS</categories><comments>The 5th International Conference of Electrical Engineering, Computer
  Science and Information Technology 2018</comments><doi>10.13140/RG.2.2.12187.72486</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a new method for recognition of consonant-vowel phonemes
combination on a new Persian speech dataset titled as PCVC (Persian
Consonant-Vowel Combination) is proposed which is used to recognize Persian
phonemes. In PCVC dataset, there are 20 sets of audio samples from 10 speakers
which are combinations of 23 consonant and 6 vowel phonemes of Persian
language. In each sample, there is a combination of one vowel and one
consonant. First, the consonant phoneme is pronounced and just after it, the
vowel phoneme is pronounced. Each sound sample is a frame of 2 seconds of
audio. In every 2 seconds, there is an average of 0.5 second speech and the
rest is silence. In this paper, the proposed method is the implementations of
the MFCC (Mel Frequency Cepstrum Coefficients) on every partitioned sound
sample. Then, every train sample of MFCC vector is given to a multilayer
perceptron feed-forward ANN (Artificial Neural Network) for training process.
At the end, the test samples are examined on ANN model for phoneme recognition.
After training and testing process, the results are presented in recognition of
vowels. Then, the average percent of recognition for vowel phonemes are
computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.06972</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.06972</id><created>2018-12-18</created><authors><author><keyname>Carlson</keyname><forenames>Brent</forenames></author><author><keyname>Boven</keyname><forenames>Paul</forenames></author><author><keyname>Caputa</keyname><forenames>Kris</forenames></author></authors><title>Sample clock frequency offset (SCFO) Resolution Team 3 (RT-3)
  investigation</title><categories>eess.SP astro-ph.IM</categories><comments>44 pages, 20+ figures</comments><report-no>RT-3, SKA1 CSP Memo 0021</report-no><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This Resolution Team 3 (RT-3) report contains the results of the
investigation of key aspects of the proposed Sample Clock Frequency Offset
(SCFO) scheme for the Mid SKA1 telescope. This is a scheme, first proposed by
one author (Carlson) at a meeting at the SKAO 25-Jan-2013, to digitize the
analog signal at each antenna at a slightly different sample rate and transmit
the data to the CSP Mid.CBF for subsequent digital re-sampling to a common
sample clock frequency before channelization, correlation, and beamforming. The
primary purpose for doing this is to cause de-correlation of sample
clock-related self-interference to be able to improve correlated and beamformed
signal quality. This report includes an investigation of the efficacy of the
method, investigation of its implementation by SADT, DISH, and CSP,
presentation of further supporting modeling results augmenting the original
modeling work, a note on expansion to SKA-2, as well as possible draw-backs and
concerns. Finally, there are potential additional benefits in signal quality in
implementing the SCFO scheme, in particular de-correlation of aliased RFI
(particularly for Nyquist Zone-2 digitized signals) as well as relaxation of
signal-chain anti-aliasing filters transition band roll-off and reject band
attenuation prior to digitization in the antenna.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07017</identifier>
 <datestamp>2019-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07017</id><created>2018-12-17</created><updated>2019-01-09</updated><authors><author><keyname>RezezadehAzar</keyname><forenames>Shahla</forenames></author><author><keyname>Ahmadi</keyname><forenames>Ali</forenames></author><author><keyname>Malekzadeh</keyname><forenames>Saber</forenames></author><author><keyname>Samami</keyname><forenames>Maryam</forenames></author></authors><title>Instrument-Independent Dastgah Recognition of Iranian Classical Music
  Using AzarNet</title><categories>cs.SD cs.LG eess.AS</categories><comments>Submitted to the 27th Iranian Conference on Electrical Engineering
  (ICEE 2019)</comments><doi>10.13140/RG.2.2.18688.89602</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, AzarNet, a deep neural network (DNN), is proposed to
recognizing seven different Dastgahs of Iranian classical music in Maryam
Iranian classical music (MICM) dataset. Over the last years, there has been
remarkable interest in employing feature learning and DNNs which lead to
decreasing the required engineering effort. DNNs have shown better performance
in many classification tasks such as audio signal classification compares to
shallow processing architectures. Despite image data, audio data need some
preprocessing steps to extract spectra and temporal features. Some
transformations like Short-Time Fourier Transform (STFT) have been used in the
state of art researches to transform audio signals from time-domain to
time-frequency domain to extract both temporal and spectra features. In this
research, the STFT output results which are extracted features are given to
AzarNet for learning and classification processes. It is worth noting that, the
mentioned dataset contains music tracks composed with two instruments (violin
and straw). The overall f1 score of AzarNet on test set, for average of all
seven classes was 86.21% which is the best result ever reported in Dastgah
classification according to our best knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07032</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07032</id><created>2018-12-17</created><updated>2019-07-26</updated><authors><author><keyname>Kervadec</keyname><forenames>Hoel</forenames></author><author><keyname>Bouchtiba</keyname><forenames>Jihene</forenames></author><author><keyname>Desrosiers</keyname><forenames>Christian</forenames></author><author><keyname>Granger</keyname><forenames>&#xc9;ric</forenames></author><author><keyname>Dolz</keyname><forenames>Jose</forenames></author><author><keyname>Ayed</keyname><forenames>Ismail Ben</forenames></author></authors><title>Boundary loss for highly unbalanced segmentation</title><categories>eess.IV cs.CV</categories><comments>Talk at MIDL 2019 [arXiv:1907.08612]</comments><journal-ref>Proceedings of The 2nd International Conference on Medical Imaging
  with Deep Learning, PMLR 102:285-296, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Widely used loss functions for convolutional neural network (CNN)
segmentation, e.g., Dice or cross-entropy, are based on integrals (summations)
over the segmentation regions. Unfortunately, it is quite common in medical
image analysis to have highly unbalanced segmentations, where standard losses
contain regional terms with values that differ considerably --typically of
several orders of magnitude-- across segmentation classes, which may affect
training performance and stability. The purpose of this study is to build a
boundary loss, which takes the form of a distance metric on the space of
contours, not regions. We argue that a boundary loss can mitigate the
difficulties of regional losses in the context of highly unbalanced
segmentation problems because it uses integrals over the boundary between
regions instead of unbalanced integrals over regions. Furthermore, a boundary
loss provides information that is complementary to regional losses.
Unfortunately, it is not straightforward to represent the boundary points
corresponding to the regional softmax outputs of a CNN. Our boundary loss is
inspired by discrete (graph-based) optimization techniques for computing
gradient flows of curve evolution. Following an integral approach for computing
boundary variations, we express a non-symmetric L2 distance on the space of
shapes as a regional integral, which avoids completely local differential
computations involving contour points. Our boundary loss is the sum of linear
functions of the regional softmax probability outputs of the network.
Therefore, it can easily be combined with standard regional losses and
implemented with any existing deep network architecture for N-D segmentation.
Our boundary loss has been validated on two benchmark datasets corresponding to
difficult, highly unbalanced segmentation problems: the ischemic stroke lesion
(ISLES) and white matter hyperintensities (WMH).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07106</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07106</id><created>2018-12-12</created><authors><author><keyname>Li</keyname><forenames>Zhe</forenames></author><author><keyname>Ding</keyname><forenames>Caiwen</forenames></author><author><keyname>Wang</keyname><forenames>Siyue</forenames></author><author><keyname>Wen</keyname><forenames>Wujie</forenames></author><author><keyname>Zhuo</keyname><forenames>Youwei</forenames></author><author><keyname>Liu</keyname><forenames>Chang</forenames></author><author><keyname>Qiu</keyname><forenames>Qinru</forenames></author><author><keyname>Xu</keyname><forenames>Wenyao</forenames></author><author><keyname>Lin</keyname><forenames>Xue</forenames></author><author><keyname>Qian</keyname><forenames>Xuehai</forenames></author><author><keyname>Wang</keyname><forenames>Yanzhi</forenames></author></authors><title>E-RNN: Design Optimization for Efficient Recurrent Neural Networks in
  FPGAs</title><categories>cs.CV cs.LG eess.SP</categories><comments>In The 25th International Symposium on High-Performance Computer
  Architecture (HPCA 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent Neural Networks (RNNs) are becoming increasingly important for time
series-related applications which require efficient and real-time
implementations. The two major types are Long Short-Term Memory (LSTM) and
Gated Recurrent Unit (GRU) networks. It is a challenging task to have
real-time, efficient, and accurate hardware RNN implementations because of the
high sensitivity to imprecision accumulation and the requirement of special
activation function implementations.
  A key limitation of the prior works is the lack of a systematic design
optimization framework of RNN model and hardware implementations, especially
when the block size (or compression ratio) should be jointly optimized with RNN
type, layer size, etc. In this paper, we adopt the block-circulant matrix-based
framework, and present the Efficient RNN (E-RNN) framework for FPGA
implementations of the Automatic Speech Recognition (ASR) application. The
overall goal is to improve performance/energy efficiency under accuracy
requirement. We use the alternating direction method of multipliers (ADMM)
technique for more accurate block-circulant training, and present two design
explorations providing guidance on block size and reducing RNN training trials.
Based on the two observations, we decompose E-RNN in two phases: Phase I on
determining RNN model to reduce computation and storage subject to accuracy
requirement, and Phase II on hardware implementations given RNN model,
including processing element design/optimization, quantization, activation
implementation, etc. Experimental results on actual FPGA deployments show that
E-RNN achieves a maximum energy efficiency improvement of 37.4$\times$ compared
with ESE, and more than 2$\times$ compared with C-LSTM, under the same
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07110</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07110</id><created>2018-12-17</created><updated>2018-12-19</updated><authors><author><keyname>Oliveira</keyname><forenames>Am&#xe9;rico</forenames></author><author><keyname>Pereira</keyname><forenames>S&#xe9;rgio</forenames></author><author><keyname>Silva</keyname><forenames>Carlos A.</forenames></author></authors><title>Retinal vessel segmentation based on Fully Convolutional Neural Networks</title><categories>eess.IV cs.LG stat.ML</categories><comments>Support repository for this work:
  https://github.com/americofmoliveira/VesselSegmentation_ESWA</comments><journal-ref>Expert Systems with Applications Volume 112, 1 December 2018,
  Pages 229-242</journal-ref><doi>10.1016/j.eswa.2018.06.034</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The retinal vascular condition is a reliable biomarker of several
ophthalmologic and cardiovascular diseases, so automatic vessel segmentation
may be crucial to diagnose and monitor them. In this paper, we propose a novel
method that combines the multiscale analysis provided by the Stationary Wavelet
Transform with a multiscale Fully Convolutional Neural Network to cope with the
varying width and direction of the vessel structure in the retina. Our proposal
uses rotation operations as the basis of a joint strategy for both data
augmentation and prediction, which allows us to explore the information learned
during training to refine the segmentation. The method was evaluated on three
publicly available databases, achieving an average accuracy of 0.9576, 0.9694,
and 0.9653, and average area under the ROC curve of 0.9821, 0.9905, and 0.9855
on the DRIVE, STARE, and CHASE_DB1 databases, respectively. It also appears to
be robust to the training set and to the inter-rater variability, which shows
its potential for real-world applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07115</identifier>
 <datestamp>2019-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07115</id><created>2018-12-17</created><updated>2019-01-29</updated><authors><author><keyname>Lanham</keyname><forenames>S. Andrew</forenames></author><author><keyname>Cuvelier</keyname><forenames>Travis C.</forenames></author><author><keyname>Ostrove</keyname><forenames>Corey</forenames></author><author><keyname>La Cour</keyname><forenames>Brian</forenames></author><author><keyname>Ott</keyname><forenames>Granville</forenames></author><author><keyname>Heath</keyname><forenames>Robert</forenames><suffix>Jr</suffix></author></authors><title>A Noncoherent Space-Time Code from Quantum Error Correction</title><categories>eess.SP cs.IT math.IT quant-ph</categories><comments>6 pages, one figure, accepted at the 53rd annual Conference on
  Information Sciences and Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we develop a space-time block code for noncoherent
communication using techniques from the field of quantum error correction. We
decompose the multiple-input multiple-output (MIMO) channel into operators from
quantum mechanics, and design a non-coherent space time code using the quantum
stabilizer formalism. We derive an optimal decoder, and analyze the former
through a quantum mechanical lens. We compare our approach to a comparable
coherent approach and a noncoherent differential approach, achieving comparable
or better performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07126</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07126</id><created>2018-12-17</created><authors><author><keyname>Zhou</keyname><forenames>Yichao</forenames></author><author><keyname>Chu</keyname><forenames>Wei</forenames></author><author><keyname>Young</keyname><forenames>Sam</forenames></author><author><keyname>Chen</keyname><forenames>Xin</forenames></author></authors><title>BandNet: A Neural Network-based, Multi-Instrument Beatles-Style MIDI
  Music Composition Machine</title><categories>cs.SD cs.MM eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a recurrent neural network (RNN)-based MIDI music
composition machine that is able to learn musical knowledge from existing
Beatles' songs and generate music in the style of the Beatles with little human
intervention. In the learning stage, a sequence of stylistically uniform,
multiple-channel music samples was modeled by a RNN. In the composition stage,
a short clip of randomly-generated music was used as a seed for the RNN to
start music score prediction. To form structured music, segments of generated
music from different seeds were concatenated together. To improve the quality
and structure of the generated music, we integrated music theory knowledge into
the model, such as controlling the spacing of gaps in the vocal melody,
normalizing the timing of chord changes, and requiring notes to be related to
the song's key (C major, for example). This integration improved the quality of
the generated music as verified by a professional composer. We also conducted a
subjective listening test that showed our generated music was close to original
music by the Beatles in terms of style similarity, professional quality, and
interestingness. Generated music samples are at https://goo.gl/uaLXoB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07159</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07159</id><created>2018-12-17</created><updated>2018-12-26</updated><authors><author><keyname>Ramani</keyname><forenames>Dhruv</forenames></author><author><keyname>Karmakar</keyname><forenames>Samarjit</forenames></author><author><keyname>Panda</keyname><forenames>Anirban</forenames></author><author><keyname>Ahmed</keyname><forenames>Asad</forenames></author><author><keyname>Tangri</keyname><forenames>Pratham</forenames></author></authors><title>Autoencoder Based Architecture For Fast &amp; Real Time Audio Style Transfer</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, there has been great interest in the field of audio style transfer,
where a stylized audio is generated by imposing the style of a reference audio
on the content of a target audio. We improve on the current approaches which
use neural networks to extract the content and the style of the audio signal
and propose a new autoencoder based architecture for the task. This network
generates a stylized audio for a content audio in a single forward pass. The
proposed network architecture proves to be advantageous over the quality of
audio produced and the time taken to train the network. The network is
experimented on speech signals to confirm the validity of our proposal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07241</identifier>
 <datestamp>2019-05-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07241</id><created>2018-12-18</created><updated>2019-05-03</updated><authors><author><keyname>Sun</keyname><forenames>Yin</forenames></author><author><keyname>Cyr</keyname><forenames>Benjamin</forenames></author></authors><title>Sampling for Data Freshness Optimization: Non-linear Age Functions</title><categories>cs.SY cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study how to take samples at a data source for improving
the freshness of received data samples at a remote receiver. We use non-linear
functions of the age of information to measure data freshness, and provide a
survey of non-linear age functions and their applications. The sampler design
problem is studied to optimize these data freshness metrics, even when there is
a sampling rate constraint. This sampling problem is formulated as a
constrained Markov decision process (MDP) with a possibly uncountable state
space. We present a complete characterization of the optimal solution to this
MDP: The optimal sampling policy is a deterministic or randomized threshold
policy, where the threshold and the randomization probabilities are
characterized based on the optimal objective value of the MDP and the sampling
rate constraint. The optimal sampling policy can be computed by bisection
search, and the curse of dimensionality is circumvented. These age optimality
results hold for (i) general data freshness metrics represented by monotonic
functions of the age of information, (ii) general service time distributions of
the queueing server, (iii) both continuoustime and discrete-time sampling
problems, and (iv) sampling problems both with and without the sampling rate
constraint. Numerical results suggest that the optimal sampling policies can be
much better than zero-wait sampling and the classic uniform sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07253</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07253</id><created>2018-12-18</created><updated>2019-07-01</updated><authors><author><keyname>Matthiesen</keyname><forenames>Bho</forenames></author><author><keyname>Jorswieck</keyname><forenames>Eduard A.</forenames></author></authors><title>Efficient Global Optimal Resource Allocation in Non-Orthogonal
  Interference Networks</title><categories>cs.IT eess.SP math.IT math.OC</categories><comments>submitted to IEEE Transactions on Signal Processing; Source code
  available at https://github.com/bmatthiesen/efficient-global-opt</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 67, no. 21, pp.
  5612-5627, Nov. 2019</journal-ref><doi>10.1109/TSP.2019.2941068</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many resource allocation tasks are challenging global (i.e., non-convex)
optimization problems. The main issue is that the computational complexity of
these problems grows exponentially in the number of variables instead of
polynomially as for many convex optimization problems. However, often the
non-convexity stems only from a subset of variables. Conventional global
optimization frameworks like monotonic optimization or DC programming treat all
variables as global variables and require complicated, problem specific
decomposition approaches to exploit the convexity in some variables. To
overcome this challenge, we develop an easy-to-use algorithm that inherently
differentiates between convex and non-convex variables, preserving the low
computational complexity in the number of convex variables. Another issue with
these widely used frameworks is that they may suffer from severe numerical
problems. We discuss this issue in detail and provide a clear motivating
example. The solution to this problem is to replace the traditional approach of
finding an {\epsilon}-approximate solution by the novel concept of
{\epsilon}-essential feasibility. The underlying algorithmic approach is called
successive incumbent transcending (SIT) algorithm and builds the foundation of
our developed algorithm. A further highlight of this algorithm is that it
inherently treats fractional objectives making the use of Dinkelbach's
iterative algorithm obsolete. Numerical experiments show a speed-up of four
orders of magnitude over state-of-the-art algorithms and almost three orders of
magnitude of additional speed-up over Dinkelbach's algorithm for fractional
programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07254</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07254</id><created>2018-12-18</created><authors><author><keyname>Panayiotou</keyname><forenames>Tania</forenames></author><author><keyname>Savva</keyname><forenames>Giannis</forenames></author><author><keyname>Shariati</keyname><forenames>Behnam</forenames></author><author><keyname>Tomkos</keyname><forenames>Ioannis</forenames></author><author><keyname>Ellinas</keyname><forenames>Georgios</forenames></author></authors><title>Machine Learning for QoT Estimation of Unseen Optical Network States</title><categories>cs.NI eess.SP</categories><comments>accepted for publication in the Optical Networking and Communication
  Conference &amp; Exhibition (OFC), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply deep graph convolutional neural networks for Quality-of-Transmission
estimation of unseen network states capturing, apart from other important
impairments, the inter-core crosstalk that is prominent in optical networks
operating with multicore fibers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07380</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07380</id><created>2018-12-15</created><updated>2018-12-19</updated><authors><author><keyname>Goy</keyname><forenames>Alexandre</forenames></author><author><keyname>Rughoobur</keyname><forenames>Girish</forenames></author><author><keyname>Li</keyname><forenames>Shuai</forenames></author><author><keyname>Arthur</keyname><forenames>Kwabena</forenames></author><author><keyname>Akinwande</keyname><forenames>Akintunde I.</forenames></author><author><keyname>Barbastathis</keyname><forenames>George</forenames></author></authors><title>High-Resolution Limited-Angle Phase Tomography of Dense Layered Objects
  Using Deep Neural Networks</title><categories>eess.IV physics.optics</categories><comments>9 pages, 5 figures, 1 table</comments><doi>10.1073/pnas.1821378116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Machine Learning-based method for tomographic reconstruction of
dense layered objects, with range of projection angles limited to $\pm
$10$^\circ$. Whereas previous approaches to phase tomography generally require
two steps, first to retrieve phase projections from intensity projections and
then perform tomographic reconstruction on the retrieved phase projections, in
our work a physics-informed pre-processor followed by a Deep Neural Network
(DNN) conduct the three-dimensional reconstruction directly from the intensity
projections. We demonstrate this single-step method experimentally in the
visible optical domain on a scaled up integrated circuit phantom. We show that
even under conditions of highly attenuated photon fluxes a DNN trained only on
synthetic data can be used to successfully reconstruct physical samples
disjoint from the synthetic training set. Thus, the need of producing a large
number of physical examples for training is ameliorated. The method is
generally applicable to tomography with electromagnetic or other types of
radiation at all bands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07394</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07394</id><created>2018-12-16</created><authors><author><keyname>Chen</keyname><forenames>Zhao</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Decentralized Computation Offloading for Multi-User Mobile Edge
  Computing: A Deep Reinforcement Learning Approach</title><categories>cs.LG eess.SP math.OC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile edge computing (MEC) emerges recently as a promising solution to
relieve resource-limited mobile devices from computation-intensive tasks, which
enables devices to offload workloads to nearby MEC servers and improve the
quality of computation experience. Nevertheless, by considering a MEC system
consisting of multiple mobile users with stochastic task arrivals and wireless
channels in this paper, the design of computation offloading policies is
challenging to minimize the long-term average computation cost in terms of
power consumption and buffering delay. A deep reinforcement learning (DRL)
based decentralized dynamic computation offloading strategy is investigated to
build a scalable MEC system with limited feedback. Specifically, a continuous
action space-based DRL approach named deep deterministic policy gradient (DDPG)
is adopted to learn efficient computation offloading policies independently at
each mobile user. Thus, powers of both local execution and task offloading can
be adaptively allocated by the learned policies from each user's local
observation of the MEC system. Numerical results are illustrated to demonstrate
that efficient policies can be learned at each user, and performance of the
proposed DDPG based decentralized strategy outperforms the conventional deep
Q-network (DQN) based discrete power control strategy and some other greedy
strategies with reduced computation cost. Besides, the power-delay tradeoff is
also analyzed for both the DDPG based and DQN based strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07421</identifier>
 <datestamp>2019-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07421</id><created>2018-12-08</created><updated>2019-03-12</updated><authors><author><keyname>Mousavi</keyname><forenames>Sajad</forenames></author><author><keyname>Afghah</keyname><forenames>Fatemeh</forenames></author><author><keyname>Acharya</keyname><forenames>U. Rajendra</forenames></author></authors><title>Inter- and intra- patient ECG heartbeat classification for arrhythmia
  detection: a sequence to sequence deep learning approach</title><categories>q-bio.QM eess.SP physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electrocardiogram (ECG) signal is a common and powerful tool to study heart
function and diagnose several abnormal arrhythmias. While there have been
remarkable improvements in cardiac arrhythmia classification methods, they
still cannot offer acceptable performance in detecting different heart
conditions, especially when dealing with imbalanced datasets. In this paper, we
propose a solution to address this limitation of current classification
approaches by developing an automatic heartbeat classification method using
deep convolutional neural networks and sequence to sequence models. We
evaluated the proposed method on the MIT-BIH arrhythmia database, considering
the intra-patient and inter-patient paradigms, and the AAMI EC57 standard. The
evaluation results for both paradigms show that our method achieves the best
performance in the literature (a positive predictive value of 96.46% and
sensitivity of 100% for the category S, and a positive predictive value of
98.68% and sensitivity of 97.40% for the category F for the intra-patient
scheme; a positive predictive value of 92.57% and sensitivity of 88.94% for the
category S, and a positive predictive value of 99.50% and sensitivity of 99.94%
for the category V for the inter-patient scheme.). The source code is available
at https://github.com/SajadMo/ECG-Heartbeat-Classification-seq2seq-model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07422</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07422</id><created>2018-12-08</created><updated>2019-02-14</updated><authors><author><keyname>Mousavi</keyname><forenames>Sajad</forenames></author><author><keyname>Afghah</keyname><forenames>Fatemeh</forenames></author><author><keyname>Razi</keyname><forenames>Abolfazl</forenames></author><author><keyname>Acharya</keyname><forenames>U. Rajendra</forenames></author></authors><title>ECGNET: Learning where to attend for detection of atrial fibrillation
  with deep visual attention</title><categories>q-bio.QM eess.SP physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of the patterns associated with Atrial Fibrillation (AF) and
the high level of noise affecting these patterns have significantly limited the
current signal processing and shallow machine learning approaches to get
accurate AF detection results. Deep neural networks have shown to be very
powerful to learn the non-linear patterns in the data. While a deep learning
approach attempts to learn complex pattern related to the presence of AF in the
ECG, they can benefit from knowing which parts of the signal is more important
to focus during learning. In this paper, we introduce a two-channel deep neural
network to more accurately detect AF presented in the ECG signal. The first
channel takes in a preprocessed ECG signal and automatically learns where to
attend for detection of AF. The second channel simultaneously takes in the
preprocessed ECG signal to consider all features of entire signals. The model
shows via visualization that what parts of the given ECG signal are important
to attend while trying to detect atrial fibrillation. In addition, this
combination significantly improves the performance of the atrial fibrillation
detection (achieved a sensitivity of 99.53%, specificity of 99.26% and accuracy
of 99.40% on the MIT-BIH atrial fibrillation database with 5-s ECG segments.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07492</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07492</id><created>2018-11-01</created><authors><author><keyname>Liu</keyname><forenames>Kai</forenames></author><author><keyname>Feng</keyname><forenames>Hui</forenames></author><author><keyname>Yang</keyname><forenames>Tao</forenames></author><author><keyname>Hu</keyname><forenames>Bo</forenames></author></authors><title>Robust Beamforming for Downlink 3D-MIMO Systems with $l_1$-norm Bounded
  CSI Uncertainty</title><categories>eess.SP</categories><comments>Accepted by WCSP 2018, Hangzhou, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel robust beamforming scheme is proposed in three
dimensional multi-input multi-output (3D-MIMO) systems. As one of the typical
deployments of massive MIMO, a 3D-MIMO system owns sparse channels in angular
domain. Thus, various of sparse channel estimation algorithms produce sparse
channel estimation errors which can be utilized to narrow down the perturbation
region of imperfect CSI. We investigate a $l_1$-norm bounded channel
uncertainty model for the robust beamforming problems, which captures the
sparse nature of channel errors. Compared with the conventional spherical
uncertainty, we prove that the scheme with $l_1$-norm bounded uncertainty
consumes less beamforming power with the same signal to interference and noise
ratio (SINR) thresholds. The proposed scheme is reformulated as a second-order
cone programming (SOCP) and simulation results verify the effectiveness of our
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07493</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07493</id><created>2018-11-08</created><authors><author><keyname>Yang</keyname><forenames>Sen</forenames></author><author><keyname>Wang</keyname><forenames>Wenshuo</forenames></author><author><keyname>Lu</keyname><forenames>Chao</forenames></author><author><keyname>Gong</keyname><forenames>Jianwei</forenames></author><author><keyname>Xi</keyname><forenames>Junqiang</forenames></author></authors><title>A Time Efficient Approach for Decision-Making Style Recognition in
  Lane-Change Behavior</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast recognizing driver's decision-making style of changing lanes plays a
pivotal role in safety-oriented and personalized vehicle control system design.
This paper presents a time-efficient recognition method by integrating k-means
clustering (k-MC) with K-nearest neighbor (KNN), called kMC-KNN. The
mathematical morphology is implemented to automatically label the
decision-making data into three styles (moderate, vague, and aggressive), while
the integration of kMC and KNN helps to improve the recognition speed and
accuracy. Our developed mathematical morphology-based clustering algorithm is
then validated by comparing to agglomerative hierarchical clustering.
Experimental results demonstrate that the developed kMC-KNN method, in
comparison to the traditional KNN, can shorten the recognition time by over
72.67% with recognition accuracy of 90%-98%. In addition, our developed kMC-KNN
method also outperforms the support vector machine (SVM) in recognition
accuracy and stability. The developed time-efficient recognition approach would
have great application potential to the in-vehicle embedded solutions with
restricted design specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07495</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07495</id><created>2018-11-21</created><authors><author><keyname>Zheng</keyname><forenames>Jiaqi</forenames></author></authors><title>GPR-based Detection of Voids and Evaluation of Grouting Under Semi-rigid
  Basement</title><categories>eess.SP</categories><comments>Master's thesis, in Chinese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The void underneath semi-rigid base is a common defect in roads. There are
some difficulties in the detection and repair for this kind of hidden damage,
as well as in the evaluation of the effects of grouting treatment. For the
detection and maintenance of roads, it is essential to study the detection and
judging for voids underneath base and the evaluation of the spread of grout.
Through theoretical analysis, numerical simulation and analysis of real data,
this research generated the characteristics of under-base voids of different
types and dimensions on GPR images, proposed the detecting and
dimension-measuring methods for under-base voids, and studied the process and
effects of data analysis techniques.
  (1) The characteristics of under-base voids of different types (air-filled,
water-filled or grout-treated) and dimensions (height and horizontal
dimensions), on A-scan and B-scan GPR image respectively, were analyzed
theoretically.
  (2) Approaches for detecting voids and for estimating its height were
studied, focusing on voids with a height ranging from 0.01m to 0.3m.
  (3) The approach for estimating the horizontal dimension of voids was
studied, focusing on voids with a length ranging from 0.04m to 0.52m.
  (4) The data processing process was discussed. Also, the effects of different
data processing techniques were studied in terms of noise filtering and
attenuation compensation, and their influence on the image characteristics was
also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07498</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07498</id><created>2018-11-29</created><authors><author><keyname>Ukil</keyname><forenames>Arijit</forenames></author><author><keyname>Bandyopadhyay</keyname><forenames>Soma</forenames></author><author><keyname>Puri</keyname><forenames>Chetanya</forenames></author><author><keyname>Singh</keyname><forenames>Rituraj</forenames></author><author><keyname>Pal</keyname><forenames>Arpan</forenames></author></authors><title>Class Augmented Semi-Supervised Learning for Practical Clinical
  Analytics on Physiological Signals</title><categories>physics.med-ph eess.SP stat.ML</categories><comments>Machine Learning for Health (ML4H) Workshop at NeurIPS 2018,
  Montreal, Canada, December, 2018</comments><report-no>ML4H/2018/15</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational analysis on physiological signals would provide immense impact
for enabling automated clinical analytics. However, the class imbalance issue
where negative or minority class instances are rare in number impairs the
robustness of the practical solution. The key idea of our approach is
intelligent augmentation of minority class examples to construct smooth,
unbiased decision boundary for robust semi-supervised learning. This solves the
practical class imbalance problem in anomaly detection task for computational
clinical analytics using physiological signals. We choose two critical cardiac
marker physiological signals: Heart sound or Phonocardiogram (PCG) and
Electrocardiogram (ECG) to validate our claim of robust anomaly detection of
clinical events under augmented class learning, where intelligent synthesis of
minority class instances attempt to balance the class distribution. We perform
extensive experiments on publicly available expert-labelled MIT-Physionet PCG
and ECG datasets that establish high performance merit of the proposed scheme,
and our scheme fittingly performs better than the state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07499</identifier>
 <datestamp>2019-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07499</id><created>2018-12-02</created><updated>2019-04-21</updated><authors><author><keyname>Wang</keyname><forenames>Guang</forenames></author><author><keyname>Chen</keyname><forenames>Xiuyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Fan</forenames></author><author><keyname>Wang</keyname><forenames>Yang</forenames></author><author><keyname>Zhang</keyname><forenames>Desheng</forenames></author></authors><title>Experience: Understanding Long-Term Evolving Patterns of Shared Electric
  Vehicle Networks</title><categories>eess.SP cs.NI</categories><comments>This work is a pre-print version to appear at MobiCom 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the ever-growing concerns on air pollution and energy security, many
cities have started to update their taxi fleets with electric ones. Although
environmentally friendly, the rapid promotion of electric taxis raises problems
to both taxi drivers and governments, e.g., prolonged waiting/charging time,
unbalanced utilization of charging infrastructures and reduced taxi supply due
to the long charging time. In this paper, we make the first effort to
understand the long-term evolving patterns through a five-year study on one of
the largest electric taxi networks in the world, i.e., the Shenzhen electric
taxi network in China. In particular, we perform a comprehensive measurement
investigation called ePat to explore the evolving mobility and charging
patterns of electric vehicles. Our ePat is based on 4.8 TB taxi GPS data, 240
GB taxi transaction data, and metadata from 117 charging stations, during an
evolving process from 427 electric taxis in 2013 to 13,178 in 2018. Moreover,
ePat also explores the impacts of various contexts and benefits during the
evolving process. Our ePat as a comprehensive investigation of the electric
taxi network mobility and charging evolving has the potential to advance the
understanding of the evolving patterns of electric taxi networks and pave the
way for analyzing future shared autonomous vehicles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07501</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07501</id><created>2018-12-12</created><authors><author><keyname>Li</keyname><forenames>Ming</forenames></author><author><keyname>Wang</keyname><forenames>Zihuan</forenames></author><author><keyname>Li</keyname><forenames>Hongyu</forenames></author><author><keyname>Liu</keyname><forenames>Qian</forenames></author><author><keyname>Zhou</keyname><forenames>Liang</forenames></author></authors><title>A Hardware-Efficient Hybrid Beamforming Solution for mmWave MIMO Systems</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In millimeter wave (mmWave) communication systems, existing hybrid
beamforming solutions generally require a large number of high-resolution phase
shifters (PSs) to realize analog beamformers, which still suffer from high
hardware complexity and power consumption. Targeting at this problem, this
article introduces a novel hardware-efficient hybrid precoding/combining
architecture, which only employs a limited number of simple phase over-samplers
(POSs) and a switch (SW) network to achieve maximum hardware efficiency while
maintaining satisfactory spectral efficiency performance. The POS can be
realized by a simple circuit and simultaneously outputs several parallel
signals with different phases. With the aid of a simple switch network, the
analog precoder/combiner is implemented by feeding the signals with appropriate
phases to antenna arrays or RF chains. We analyze the design challenges of this
POS-SW-based hybrid beamforming architecture and present potential solutions to
the fundamental issues, especially the precoder/combiner design and the channel
estimation strategy. Simulation results demonstrate that this
hardware-efficient structure can achieve comparable spectral efficiency but
much higher energy efficiency than that of the traditional structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07502</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07502</id><created>2018-12-13</created><authors><author><keyname>Golani</keyname><forenames>Ori</forenames></author><author><keyname>Pilori</keyname><forenames>Dario</forenames></author><author><keyname>Bosco</keyname><forenames>Gabriella</forenames></author><author><keyname>Shtaif</keyname><forenames>Mark</forenames></author></authors><title>Correlated Non-Linear Phase Noise in Multi-Subcarrier Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore correlated nonlinear phase noise (NLPN) in multi-subcarrier
systems. We derive an analytical model for predicting the covariance between
the NLPN affecting different subcarriers, and offer a simple algorithm which
uses the correlations for improved NLPN mitigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07504</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07504</id><created>2018-12-14</created><updated>2019-05-16</updated><authors><author><keyname>Hoshen</keyname><forenames>Yedid</forenames></author></authors><title>Towards Unsupervised Single-Channel Blind Source Separation using
  Adversarial Pair Unmix-and-Remix</title><categories>eess.SP cs.LG cs.SD eess.AS stat.ML</categories><comments>ICASSP'19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind single-channel source separation is a long standing signal processing
challenge. Many methods were proposed to solve this task utilizing multiple
signal priors such as low rank, sparsity, temporal continuity etc. The recent
advance of generative adversarial models presented new opportunities in signal
regression tasks. The power of adversarial training however has not yet been
realized for blind source separation tasks. In this work, we propose a novel
method for blind source separation (BSS) using adversarial methods. We rely on
the independence of sources for creating adversarial constraints on pairs of
approximately separated sources, which ensure good separation. Experiments are
carried out on image sources validating the good performance of our approach,
and presenting our method as a promising approach for solving BSS for general
signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07505</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07505</id><created>2018-12-15</created><authors><author><keyname>Pinto</keyname><forenames>S.</forenames></author><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author></authors><title>Direction Finding Based on Multi-Step Knowledge-Aided Iterative
  Conjugate Gradient Algorithms</title><categories>eess.SP cs.IT cs.LG cs.SD eess.AS math.IT math.OC stat.ML</categories><comments>7 figures, 11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present direction-of-arrival (DoA) estimation algorithms
based on the Krylov subspace that effectively exploit prior knowledge of the
signals that impinge on a sensor array. The proposed multi-step knowledge-aided
iterative conjugate gradient (CG) (MS-KAI-CG) algorithms perform subtraction of
the unwanted terms found in the estimated covariance matrix of the sensor data.
Furthermore, we develop a version of MS-KAI-CG equipped with forward-backward
averaging, called MS-KAI-CG-FB, which is appropriate for scenarios with
correlated signals. Unlike current knowledge-aided methods, which take
advantage of known DoAs to enhance the estimation of the covariance matrix of
the input data, the MS-KAI-CG algorithms take advantage of the knowledge of the
structure of the forward-backward smoothed covariance matrix and its
disturbance terms. Simulations with both uncorrelated and correlated signals
show that the MS-KAI-CG algorithms outperform existing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07507</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07507</id><created>2018-12-16</created><authors><author><keyname>Krikidis</keyname><forenames>Ioannis</forenames></author></authors><title>Average Age of Information in Wireless Powered Sensor Networks</title><categories>eess.SP cs.SY</categories><comments>IEEE Wireless Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we deal with the age of information (AoI) for a sensor
network with wireless power transfer (WPT) capabilities. Specifically, we study
a simple network topology, where a sensor node harvests energy from radio
frequency signals (transmitted by a dedicated energy source) to transmit
real-time status updates. The sensor node generates an update when its
capacitor/battery becomes fully charged and transmits by using all the
available energy without further energy management. The average AoI performance
of the considered greedy policy is derived in closed form and is a function of
the capacitor's size. The optimal value of the capacitor that maximizes the
freshness of the information, corresponds to a simple optimization problem
requiring a one-dimensional search. The derived theoretical results provide
useful performance bounds for practical WPT networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07509</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07509</id><created>2018-12-18</created><authors><author><keyname>Lutnick</keyname><forenames>Brendon</forenames></author><author><keyname>Ginley</keyname><forenames>Brandon</forenames></author><author><keyname>Govind</keyname><forenames>Darshana</forenames></author><author><keyname>McGarry</keyname><forenames>Sean D.</forenames></author><author><keyname>LaViolette</keyname><forenames>Peter S.</forenames></author><author><keyname>Yacoub</keyname><forenames>Rabi</forenames></author><author><keyname>Jain</keyname><forenames>Sanjay</forenames></author><author><keyname>Tomaszewski</keyname><forenames>John E.</forenames></author><author><keyname>Jen</keyname><forenames>Kuang-Yu</forenames></author><author><keyname>Sarder</keyname><forenames>Pinaki</forenames></author></authors><title>Iterative annotation to ease neural network training: Specialized
  machine learning in medical image analysis</title><categories>eess.IV cs.CV cs.HC cs.LG stat.ML</categories><comments>15 pages, 7 figures, 2 supplemental figures (on the last page)</comments><journal-ref>Nature Machine Intelligence 1.2 (2019): 112</journal-ref><doi>10.1038/s42256-019-0018-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural networks promise to bring robust, quantitative analysis to medical
fields, but adoption is limited by the technicalities of training these
networks. To address this translation gap between medical researchers and
neural networks in the field of pathology, we have created an intuitive
interface which utilizes the commonly used whole slide image (WSI) viewer,
Aperio ImageScope (Leica Biosystems Imaging, Inc.), for the annotation and
display of neural network predictions on WSIs. Leveraging this, we propose the
use of a human-in-the-loop strategy to reduce the burden of WSI annotation. We
track network performance improvements as a function of iteration and quantify
the use of this pipeline for the segmentation of renal histologic findings on
WSIs. More specifically, we present network performance when applied to
segmentation of renal micro compartments, and demonstrate multi-class
segmentation in human and mouse renal tissue slides. Finally, to show the
adaptability of this technique to other medical imaging fields, we demonstrate
its ability to iteratively segment human prostate glands from radiology imaging
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07513</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07513</id><created>2018-12-17</created><authors><author><keyname>Jiang</keyname><forenames>Xiaoda</forenames></author><author><keyname>Lu</keyname><forenames>Hancheng</forenames></author></authors><title>Joint Rate and Resource Allocation in Hybrid Digital-Analog Transmission
  over Fading Channels</title><categories>eess.SP cs.IT cs.PF math.IT</categories><comments>14 pages, 10 figures, This paper has already been published in IEEE
  Transactions on Vehicular Technology</comments><journal-ref>Published in IEEE Transactions on Vehicular Technology ( Volume:
  67 , Issue: 10 , Oct. 2018 )</journal-ref><doi>10.1109/TVT.2018.2857515</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In hybrid digital-analog (HDA) systems, resource allocation has been utilized
to achieve desired distortion performance. However, existing studies on this
issue assume error-free digital transmission, which is not valid for fading
channels. With time-varying channel fading, the exact channel state information
is not available at the transmitter. Thus, random outage and resulting digital
distortion cannot be ignored. Moreover, rate allocation should be considered in
resource allocation, since it not only determines the amount of information for
digital transmission and that for analog transmission, but also affects the
outage probability. Based on above observations, in this paper, we attempt to
perform joint rate and resource allocation strategies to optimize system
distortion in HDA systems over fading channels. Consider a bandwidth expansion
scenario where a memoryless Gaussian source is transmitted in an HDA system
with the entropy-constrained scalar quantizer (ECSQ). Firstly, we formulate the
joint allocation problem as an expected system distortion minimization problem
where both analog and digital distortion are considered. Then, in the limit of
low outage probability, we decompose the problem into two coupled sub-problems
based on the block coordinate descent method, and propose an iterative gradient
algorithm to approach the optimal solution. Furthermore, we extend our work to
the multivariate Gaussian source scenario where a two-stage fast algorithm
integrating rounding and greedy strategies is proposed to optimize the joint
rate and resource allocation problem. Finally, simulation results demonstrate
that the proposed algorithms can achieve up to 2.3dB gains in terms of
signal-to-distortion ratio over existing schemes under the single Gaussian
source scenario, and up to 3.5dB gains under the multivariate Gaussian source
scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07514</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07514</id><created>2018-12-17</created><authors><author><keyname>Phan-Huy</keyname><forenames>D. -T.</forenames></author><author><keyname>Kokar</keyname><forenames>Y.</forenames></author><author><keyname>Rachedi</keyname><forenames>K.</forenames></author><author><keyname>Pajusco</keyname><forenames>P.</forenames></author><author><keyname>Mokh</keyname><forenames>A.</forenames></author><author><keyname>Magounaki</keyname><forenames>T.</forenames></author><author><keyname>Masood</keyname><forenames>R.</forenames></author><author><keyname>Buey</keyname><forenames>C.</forenames></author><author><keyname>Ratajczak</keyname><forenames>P.</forenames></author><author><keyname>Malhouroux-Gaffet</keyname><forenames>N.</forenames></author><author><keyname>Conrat</keyname><forenames>J. -M.</forenames></author><author><keyname>Pr&#xe9;votet</keyname><forenames>J. -C.</forenames></author><author><keyname>Ourir</keyname><forenames>A.</forenames></author><author><keyname>de Rosny</keyname><forenames>J.</forenames></author><author><keyname>Crussi&#xe8;re</keyname><forenames>M.</forenames></author><author><keyname>H&#xe9;lard</keyname><forenames>M.</forenames></author><author><keyname>Gati</keyname><forenames>A.</forenames></author><author><keyname>Sarrebourse</keyname><forenames>T.</forenames></author><author><keyname>Di Renzo</keyname><forenames>M.</forenames></author></authors><title>Single-Carrier Spatial Modulation for the Internet of Things: Design and
  Performance Evaluation by Using Real Compact and Reconfigurable Antennas</title><categories>eess.SP</categories><comments>Submitted for publication to IEEE journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, for the first time, we propose two new solutions to boost the
data rate between small connected objects such as glasses and cams and the 5th
generation (5G) mobile network, based on spatial modulation, single carrier
waveform, compact reconfigurable antennas at the object side and massive
multiple input multiple output (M-MIMO) at the network side. In the first new
wireless communication system, a &quot;transmitting object&quot; uses transmit spatial
modulation with a compact reconfigurable antenna and a constant envelop
amplifier to transmit in high data rate with a low complexity and low power
consumption. The space-time digital processing capability of the M-MIMO 5G base
station is used to detect such signal. In the second new wireless communication
system, a &quot;receiving object&quot; uses receive spatial modulation, a compact
multiport antenna and a low complexity detection algorithm to receive in high
data rate with a low complexity signal processing. The space-time beamforming
capability of the M-MIMO 5G base stations is exploited to deliver a signal that
is pre-equalized enough to be detected by the object. For the first time, we
present experiments showing that M-MIMO allows for the re-introduction of
single carrier modulation waveform. For the first time, we present performance
results obtained with real existing compact antennas and compact reconfigurable
antennas, showing that the two new communication systems outperform
conventional modulation in terms of energy efficiency and complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07515</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07515</id><created>2018-12-17</created><authors><author><keyname>Jia</keyname><forenames>Mengshuo</forenames></author><author><keyname>Shen</keyname><forenames>Chen</forenames></author><author><keyname>Wang</keyname><forenames>Zhiwen</forenames></author></authors><title>A Distributed Probabilistic Modeling Algorithm for the Aggregated Power
  Forecast Error of Multiple Newly Built Wind Farms</title><categories>eess.SP math.PR</categories><journal-ref>M. Jia, C. Shen, and Z. Wang, &quot;A Distributed Probabilistic
  Modeling Algorithm for the Aggregated Power Forecast Error of Multiple Newly
  Built Wind Farms,&quot; IEEE Transactions on Sustainable Energy, Oct 2018</journal-ref><doi>10.1109/TSTE.2018.2873710,</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The extensive penetration of wind farms (WFs) presents challenges to the
operation of distribution networks (DNs). Building a probability distribution
of the aggregated wind power forecast error is of great value for decision
making. However, as a result of recent government incentives, many WFs are
being newly built with little historical data for training distribution models.
Moreover, WFs with different stakeholders may refuse to submit the raw data to
a data center for model training. To address these problems, a Gaussian mixture
model (GMM) is applied to build the distribution of the aggregated wind power
forecast error; then, the maximum a posteriori (MAP) estimation method is
adopted to overcome the limited training data problem in GMM parameter
estimation. Next, a distributed MAP estimation method is developed based on the
average consensus filter algorithm to address the data privacy issue. The
distribution control center is introduced into the distributed estimation
process to acquire more precise estimation results and better adapt to the DN
control architecture. The effectiveness of the proposed algorithm is
empirically verified using historical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07516</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07516</id><created>2018-12-16</created><updated>2019-07-27</updated><authors><author><keyname>Chen</keyname><forenames>Erkai</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author><author><keyname>Zhang</keyname><forenames>Nan</forenames></author></authors><title>User-Centric Joint Access-Backhaul Design for Full-Duplex
  Self-Backhauled Wireless Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>to appear in IEEE Trans. on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Full-duplex self-backhauling is promising to provide cost-effective and
flexible backhaul connectivity for ultra-dense wireless networks, but also
poses a great challenge to resource management between the access and backhaul
links. In this paper, we propose a user-centric joint access-backhaul
transmission framework for full-duplex self-backhauled wireless networks. In
the access link, user-centric clustering is adopted so that each user is
cooperatively served by multiple small base stations (SBSs). In the backhaul
link, user-centric multicast transmission is proposed so that each user's
message is treated as a common message and multicast to its serving SBS
cluster. We first formulate an optimization problem to maximize the network
weighted sum rate through joint access-backhaul beamforming and SBS clustering
when global channel state information (CSI) is available. This problem is
efficiently solved via the successive lower-bound maximization approach with a
novel approximate objective function and the iterative link removal technique.
We then extend the study to the stochastic joint access-backhaul beamforming
optimization with partial CSI. Simulation results demonstrate the effectiveness
of the proposed algorithms for both full CSI and partial CSI scenarios. They
also show that the transmission design with partial CSI can greatly reduce the
CSI overhead with little performance degradation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07517</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07517</id><created>2018-12-16</created><updated>2019-02-07</updated><authors><author><keyname>Park</keyname><forenames>Hyunbin</forenames></author><author><keyname>Kim</keyname><forenames>Dohyun</forenames></author><author><keyname>Kim</keyname><forenames>Shiho</forenames></author></authors><title>Digital Neuron: A Hardware Inference Accelerator for Convolutional Deep
  Neural Networks</title><categories>eess.SP cs.AR</categories><comments>8 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a Digital Neuron, a hardware inference accelerator for
convolutional deep neural networks with integer inputs and integer weights for
embedded systems. The main idea to reduce circuit area and power consumption is
manipulating dot products between input feature and weight vectors by Barrel
shifters and parallel adders. The reduced area allows the more computational
engines to be mounted on an inference accelerator, resulting in high throughput
compared to prior HW accelerators. We verified that the multiplication of
integer numbers with 3-partial sub-integers does not cause significant loss of
inference accuracy compared to 32-bit floating point calculation. The proposed
digital neuron can perform 800 MAC operations in one clock for computation for
convolution as well as full-connection. This paper provides a scheme that
reuses input, weight, and output of all layers to reduce DRAM access. In
addition, this paper proposes a configurable architecture that can provide
inference of adaptable feature of convolutional neural networks. The throughput
in terms of Watt of the digital neuron is achieved 754.7 GMACs/W.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07518</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07518</id><created>2018-12-15</created><updated>2019-11-30</updated><authors><author><keyname>Safari</keyname><forenames>Mohammad Sadegh</forenames></author><author><keyname>Pourahmadi</keyname><forenames>Vahid</forenames></author><author><keyname>Sodagari</keyname><forenames>Shabnam</forenames></author></authors><title>Deep UL2DL: Channel Knowledge Transfer from Uplink to Downlink</title><categories>eess.SP cs.LG stat.ML</categories><comments>16 pages, 20 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge of the channel state information (CSI) at the transmitter side is
one of the primary sources of information that can be used for the efficient
allocation of wireless resources. Obtaining downlink (DL) CSI in Frequency
Division Duplexing (FDD) systems from uplink (UL) CSI is not as straightforward
as in TDD systems. Therefore, users usually feed the DL-CSI back to the
transmitter. To remove the need for feedback (and thus having less signaling
overhead), we propose to use two recent deep neural network structures, i.e.,
convolutional neural networks and generative adversarial networks (GANs) to
infer the DL-CSI by observing the UL-CSI. The core idea of our data-driven
scheme is exploiting the fact that both DL and UL channels share the same
propagation environment. As such, we extracted the environment information from
the UL channel response to a latent domain and then transferred the derived
environment information from the latent domain to predict the DL channel. To
overcome incorrect latent domain and the problem of oversimplistic assumptions,
in this work, we did not use any specific parametric model and instead used
data-driven approaches to discover the underlying structure of data without any
prior model assumptions. To overcome the challenge of capturing the UL-DL joint
distribution, we used a mean square error-based variant of the GAN structure
with improved convergence properties called boundary equilibrium GAN (BEGAN).
For training and testing we used simulated data of Extended Vehicular-A (EVA)
and Extended Typical Urban (ETU) models. Simulation results verified that our
methods can accurately infer and predict the downlink CSI from the uplink CSI
for different multipath environments in FDD communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07545</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07545</id><created>2018-12-18</created><updated>2019-07-31</updated><authors><author><keyname>Aldana-L&#xf3;pez</keyname><forenames>R.</forenames></author><author><keyname>G&#xf3;mez-Guti&#xe9;rrez</keyname><forenames>D.</forenames></author><author><keyname>Defoort</keyname><forenames>M.</forenames></author><author><keyname>S&#xe1;nchez-Torres</keyname><forenames>J. D.</forenames></author><author><keyname>Mu&#xf1;oz-V&#xe1;zquez</keyname><forenames>A. J.</forenames></author></authors><title>A class of robust consensus algorithms with predefined-time convergence
  under switching topologies</title><categories>math.OC cs.MA cs.SY eess.SY</categories><comments>International Journal of Robust and Nonlinear Control, 2019</comments><doi>10.1002/rnc.4715</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the robust consensus problem under switching topologies.
Contrary to existing methods, the proposed approach provides decentralized
protocols that achieve consensus for networked multi-agent systems in a
predefined time. Namely, the protocol design provides a tuning parameter that
allows setting the convergence time of the agents to a consensus state. An
appropriate Lyapunov analysis exposes the capability of the current proposal to
achieve predefined-time consensus over switching topologies despite the
presence of bounded perturbations. Finally, the paper presents a comparison
showing that the suggested approach subsumes existing fixed-time consensus
algorithms and provides extra degrees of freedom to obtain predefined-time
consensus protocols that are less over-engineered, i.e., the difference between
the estimated convergence time and its actual value is lower in our approach.
Numerical results are given to illustrate the effectiveness and advantages of
the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07568</identifier>
 <datestamp>2018-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07568</id><created>2018-12-17</created><authors><author><keyname>Sanford</keyname><forenames>Clayton</forenames></author><author><keyname>Cousins</keyname><forenames>Cyrus</forenames></author><author><keyname>Upfal</keyname><forenames>Eli</forenames></author></authors><title>Uniform Convergence Bounds for Codec Selection</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We frame the problem of selecting an optimal audio encoding scheme as a
supervised learning task. Through uniform convergence theory, we guarantee
approximately optimal codec selection while controlling for selection bias. We
present rigorous statistical guarantees for the codec selection problem that
hold for arbitrary distributions over audio sequences and for arbitrary quality
metrics. Our techniques can thus balance sound quality and compression ratio,
and use audio samples from the distribution to select a codec that performs
well on that particular type of data. The applications of our technique are
immense, as it can be used to optimize for quality and bandwidth usage of
streaming and other digital media, while significantly outperforming approaches
that apply a fixed codec to all data sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07665</identifier>
 <datestamp>2019-06-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07665</id><created>2018-12-18</created><updated>2019-06-04</updated><authors><author><keyname>Liu</keyname><forenames>Xiao</forenames></author><author><keyname>Liu</keyname><forenames>Yuanwei</forenames></author><author><keyname>Chen</keyname><forenames>Yue</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Trajectory Design and Power Control for Multi-UAV Assisted Wireless
  Networks: A Machine Learning Approach</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel framework is proposed for the trajectory design of multiple unmanned
aerial vehicles (UAVs) based on the prediction of users' mobility information.
The problem of joint trajectory design and power control is formulated for
maximizing the instantaneous sum transmit rate while satisfying the rate
requirement of users. In an effort to solve this pertinent problem, a
three-step approach is proposed which is based on machine learning techniques
to obtain both the position information of users and the trajectory design of
UAVs. Firstly, a multi-agent Q-learning based placement algorithm is proposed
for determining the optimal positions of the UAVs based on the initial location
of the users. Secondly, in an effort to determine the mobility information of
users based on a real dataset, their position data is collected from Twitter to
describe the anonymous user-trajectories in the physical world. In the
meantime, an echo state network (ESN) based prediction algorithm is proposed
for predicting the future positions of users based on the real dataset.
Thirdly, a multi-agent Q-learning based algorithm is conceived for predicting
the position of UAVs in each time slot based on the movement of users. In this
algorithm, multiple UAVs act as agents to find optimal actions by interacting
with their environment and learn from their mistakes. Additionally, we also
prove that the proposed multi-agent Q-learning based trajectory design and
power control algorithm can converge under mild conditions. Numerical results
are provided to demonstrate that as the size of the reservoir increases, the
proposed ESN approach improves the prediction accuracy. Finally, we demonstrate
that throughput gains of about 17% are achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07706</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07706</id><created>2018-12-18</created><updated>2018-12-31</updated><authors><author><keyname>Yang</keyname><forenames>Jun</forenames></author><author><keyname>Zhou</keyname><forenames>Zhou</forenames></author></authors><title>Spectral Inference under Complex Temporal Dynamics</title><categories>math.ST eess.SP stat.ME stat.TH</categories><comments>86 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop unified theory and methodology for the inference of evolutionary
Fourier power spectra for a general class of locally stationary and possibly
nonlinear processes. In particular, simultaneous confidence regions (SCR) with
asymptotically correct coverage rates are constructed for the evolutionary
spectral densities on a nearly optimally dense grid of the joint time-frequency
domain. A simulation based bootstrap method is proposed to implement the SCR.
The SCR enables researchers and practitioners to visually evaluate the
magnitude and pattern of the evolutionary power spectra with asymptotically
accurate statistical guarantee. The SCR also serves as a unified tool for a
wide range of statistical inference problems in time-frequency analysis ranging
from tests for white noise, stationarity and time-frequency separability to the
validation for non-stationary linear models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07711</identifier>
 <datestamp>2018-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07711</id><created>2018-12-18</created><authors><author><keyname>Dinesh</keyname><forenames>Chinthaka</forenames></author><author><keyname>Cheung</keyname><forenames>Gene</forenames></author><author><keyname>Bajic</keyname><forenames>Ivan V.</forenames></author></authors><title>3D Point Cloud Denoising via Bipartite Graph Approximation and
  Reweighted Graph Laplacian</title><categories>eess.SP</categories><comments>14 pages, 7 figures, Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Point cloud is a collection of 3D coordinates that are discrete geometric
samples of an object's 2D surfaces. Imperfection in the acquisition process
means that point clouds are often corrupted with noise. Building on recent
advances in graph signal processing, we design local algorithms for 3D point
cloud denoising. Specifically, we design a reweighted graph Laplacian
regularizer (RGLR) for surface normals and demonstrate its merits in rotation
invariance, promotion of piecewise smoothness, and ease of optimization. Using
RGLR as a signal prior, we formulate an optimization problem with a general
lp-norm fidelity term that can explicitly model two types of independent noise:
small but non-sparse noise (using l2 fidelity term) and large but sparser noise
(using l1 fidelity term).
  To establish a linear relationship between normals and 3D point coordinates,
we first perform bipartite graph approximation to divide the point cloud into
two disjoint node sets (red and blue). We then optimize the red and blue nodes'
coordinates alternately. For l2-norm fidelity term, we iteratively solve an
unconstrained quadratic programming (QP) problem, efficiently computed using
conjugate gradient with a bounded condition number to ensure numerical
stability. For l1-norm fidelity term, we iteratively minimize an l1-l2 cost
function sing accelerated proximal gradient (APG), where a good step size is
chosen via Lipschitz continuity analysis. Finally, we propose simple mean and
median filters for flat patches of a given point cloud to estimate the noise
variance given the noise type, which in turn is used to compute a weight
parameter trading off the fidelity term and signal prior in the problem
formulation. Extensive experiments show state-of-the-art denoising performance
among local methods using our proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07715</identifier>
 <datestamp>2018-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07715</id><created>2018-12-19</created><authors><author><keyname>Raza</keyname><forenames>Khalid</forenames></author><author><keyname>Singh</keyname><forenames>Nripendra Kumar</forenames></author></authors><title>A Tour of Unsupervised Deep Learning for Medical Image Analysis</title><categories>eess.IV cs.CV cs.LG</categories><comments>29 pages, 6 figures, 8 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interpretation of medical images for diagnosis and treatment of complex
disease from high-dimensional and heterogeneous data remains a key challenge in
transforming healthcare. In the last few years, both supervised and
unsupervised deep learning achieved promising results in the area of medical
imaging and image analysis. Unlike supervised learning which is biased towards
how it is being supervised and manual efforts to create class label for the
algorithm, unsupervised learning derive insights directly from the data itself,
group the data and help to make data driven decisions without any external
bias. This review systematically presents various unsupervised models applied
to medical image analysis, including autoencoders and its several variants,
Restricted Boltzmann machines, Deep belief networks, Deep Boltzmann machine and
Generative adversarial network. Future research opportunities and challenges of
unsupervised techniques for medical image analysis have also been discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07729</identifier>
 <datestamp>2018-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07729</id><created>2018-12-18</created><authors><author><keyname>Pishgar</keyname><forenames>Maryam</forenames></author><author><keyname>Karim</keyname><forenames>Fazle</forenames></author><author><keyname>Majumdar</keyname><forenames>Somshubra</forenames></author><author><keyname>Darabi</keyname><forenames>Houshang</forenames></author></authors><title>Pathological Voice Classification Using Mel-Cepstrum Vectors and Support
  Vector Machine</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Accepted at IEEE BigData 2018 Workshop - FEMH Voice Data Challenge</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vocal disorders have affected several patients all over the world. Due to the
inherent difficulty of diagnosing vocal disorders without sophisticated
equipment and trained personnel, a number of patients remain undiagnosed. To
alleviate the monetary cost of diagnosis, there has been a recent growth in the
use of data analysis to accurately detect and diagnose individuals for a
fraction of the cost. We propose a cheap, efficient and accurate model to
diagnose whether a patient suffers from one of three vocal disorders on the
FEMH 2018 challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07737</identifier>
 <datestamp>2018-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07737</id><created>2018-12-18</created><authors><author><keyname>Liang</keyname><forenames>Yongxin</forenames></author><author><keyname>Jiang</keyname><forenames>Jialin</forenames></author><author><keyname>Chen</keyname><forenames>Yongxiang</forenames></author><author><keyname>Zhu</keyname><forenames>Richeng</forenames></author><author><keyname>Lu</keyname><forenames>Chongyu</forenames></author><author><keyname>Wang</keyname><forenames>Zinan</forenames></author></authors><title>Optimized Feedforward Neural Network Training for Efficient Brillouin
  Frequency Shift Retrieval in Fiber</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial neural networks (ANNs) can be used to replace traditional methods
in various fields, making signal processing more efficient and meeting the
real-time processing requirements of the Internet of Things (IoT). As a special
type of ANN, recently the feedforward neural network (FNN) has been used to
replace the time-consuming Lorentzian curve fitting (LCF) method in Brillouin
optical time-domain analysis (BOTDA) to retrieve the Brillouin frequency shift
(BFS), which could be used as the indicator in temperature/strain sensing, etc.
However, FNN needs to be re-trained if the generalization ability is not
satisfactory, or the frequency scanning step is changing in the experiment.
This is a cumbersome and inefficient process. In this paper, FNN only needs to
be trained once with the proposed method. 150.62 km BOTDA is built to verify
the performance of the trained FNN. Simulation and experimental results show
that the proposed method is promising in BOTDA because of its high
computational efficiency and wide adaptability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07776</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07776</id><created>2018-12-19</created><updated>2019-10-17</updated><authors><author><keyname>Sadeghi</keyname><forenames>Bashir</forenames></author><author><keyname>Yu</keyname><forenames>Runyi</forenames></author><author><keyname>Boddeti</keyname><forenames>Vishnu Naresh</forenames></author></authors><title>Constrained Sampling: Optimum Reconstruction in Subspace with Minimax
  Regret Constraint</title><categories>eess.SP</categories><comments>13 pages, 5 figures, 2 tables</comments><doi>10.1109/TSP.2019.2925608</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of optimum reconstruction in generalized
sampling-reconstruction processes (GSRPs). We propose constrained GSRP, a novel
framework that minimizes the reconstruction error for inputs in a subspace,
subject to a constraint on the maximum regret-error for any other signal in the
entire signal space. This framework addresses the primary limitation of
existing GSRPs (consistent, subspace and minimax regret), namely, the
assumption that the \emph{a priori} subspace is either fully known or fully
ignored. We formulate constrained GSRP as a constrained optimization problem,
the solution to which turns out to be a convex combination of the subspace and
the minimax regret samplings. Detailed theoretical analysis on the
reconstruction error shows that constrained sampling achieves a reconstruction
that is 1) (sub)optimal for signals in the input subspace, 2) robust for
signals around the input subspace, and 3) reasonably bounded for any other
signals with a simple choice of the constraint parameter. Experimental results
on sampling-reconstruction of a Gaussian input and a speech signal demonstrate
the effectiveness of the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07777</identifier>
 <datestamp>2018-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07777</id><created>2018-12-19</created><authors><author><keyname>Wang</keyname><forenames>Yicong</forenames></author><author><keyname>de Veciana</keyname><forenames>Gustavo</forenames></author><author><keyname>Shimizu</keyname><forenames>Takayuki</forenames></author><author><keyname>Lu</keyname><forenames>Hongsheng</forenames></author></authors><title>Performance and Scaling of Collaborative Sensing and Networking for
  Automated Driving Applications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A critical requirement for automated driving systems is enabling situational
awareness in dynamically changing environments. To that end vehicles will be
equipped with diverse sensors, e.g., LIDAR, cameras, mmWave radar, etc.
Unfortunately the sensing `coverage' is limited by environmental obstructions,
e.g., other vehicles, buildings, people, objects etc. A possible solution is to
adopt collaborative sensing amongst vehicles possibly assisted by
infrastructure. This paper introduces new models and performance analysis for
vehicular collaborative sensing and networking. In particular, coverage gains
are quantified, as are their dependence on the penetration of vehicles
participating in collaborative sensing. We also evaluate the associated
communication loads in terms of the Vehicle-to-Vehicle (V2V) and
Vehicle-to-Infrastructure (V2I) capacity requirements and how these depend on
penetration. We further explore how collaboration with sensing capable
infrastructure improves sensing performance, as well as the benefits in
utilizing spatio-temporal dynamics, e.g., collaborating with vehicles moving in
the opposite direction. Collaborative sensing is shown to greatly improve
sensing performance, e.g., improves coverage from 20% to 80% with a 20%
penetration. In scenarios with limited penetration and high coverage
requirements, infrastructure can be used to both help sense the environment and
relay data. Once penetration is high enough, sensing vehicles provide good
coverage and data traffic can be effectively `offloaded' to V2V connectivity,
making V2I resources available to support other in-car services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07853</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07853</id><created>2018-12-19</created><updated>2019-06-12</updated><authors><author><keyname>Brighente</keyname><forenames>Alessandro</forenames></author><author><keyname>Formaggio</keyname><forenames>Francesco</forenames></author><author><keyname>Di Nunzio</keyname><forenames>Giorgio Maria</forenames></author><author><keyname>Tomasin</keyname><forenames>Stefano</forenames></author></authors><title>Machine Learning For In-Region Location Verification In Wireless
  Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In-region location verification (IRLV) aims at verifying whether a user is
inside a region of interest (ROI). In wireless networks, IRLV can exploit the
features of the channel between the user and a set of trusted access points. In
practice, the channel feature statistics is not available and we resort to
machine learning (ML) solutions for IRLV. We first show that solutions based on
either neural networks (NNs) or support vector machines (SVMs) and typical loss
functions are Neyman-Pearson (N-P)-optimal at learning convergence for
sufficiently complex learning machines and large training datasets . Indeed,
for finite training, ML solutions are more accurate than the N-P test based on
estimated channel statistics. Then, as estimating channel features outside the
ROI may be difficult, we consider one-class classifiers, namely auto-encoders
NNs and one-class SVMs, which however are not equivalent to the generalized
likelihood ratio test (GLRT), typically replacing the N-P test in the one-class
problem. Numerical results support the results in realistic wireless networks,
with channel models including path-loss, shadowing, and fading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07934</identifier>
 <datestamp>2019-04-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07934</id><created>2018-12-19</created><updated>2019-04-24</updated><authors><author><keyname>Biswas</keyname><forenames>Sudip</forenames></author><author><keyname>Singh</keyname><forenames>Keshav</forenames></author><author><keyname>Taghizadeh</keyname><forenames>Omid</forenames></author><author><keyname>Ratnarajah</keyname><forenames>Tharmalingam</forenames></author></authors><title>Coexistence of MIMO Radar and FD MIMO Cellular Systems with QoS
  Considerations</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Wireless Communications, vol. 17, no. 11, pp.
  7281-7294, Nov. 2018</journal-ref><doi>10.1109/TWC.2018.2866044</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, the feasibility of spectrum sharing between a multiple-input
multiple-output (MIMO) radar system (RS) and a MIMO cellular system (CS),
comprising of a full duplex (FD) base station (BS) serving multiple downlink
and uplink users at the same time and frequency is investigated. While a joint
transceiver design technique at the CS's BS and users is proposed to maximise
the probability of detection (PoD) of the MIMO RS, subject to constraints of
quality of service (QoS) of users and transmit power at the CS, null-space
based waveform projection is used to mitigate the interference from RS towards
CS. In particular, the proposed technique optimises the performance of PoD of
RS by maximising its lower bound, which is obtained by exploiting the
monotonically increasing relationship of PoD and its non-centrality parameter.
Numerical results show the utility of the proposed spectrum sharing framework,
but with certain trade-offs in performance corresponding to RS's transmit
power, RS's PoD, CS's residual self interference power at the FD BS and QoS of
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07989</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07989</id><created>2018-12-19</created><updated>2019-06-26</updated><authors><author><keyname>Zhang</keyname><forenames>Xiaodan</forenames></author><author><keyname>Gao</keyname><forenames>Xinbo</forenames></author><author><keyname>Lu</keyname><forenames>Wen</forenames></author><author><keyname>He</keyname><forenames>Lihuo</forenames></author></authors><title>A Gated Peripheral-Foveal Convolutional Neural Network for Unified Image
  Aesthetic Prediction</title><categories>cs.CV eess.IV</categories><comments>Add more experiments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning fine-grained details is a key issue in image aesthetic assessment.
Most of the previous methods extract the fine-grained details via random
cropping strategy, which may undermine the integrity of semantic information.
Extensive studies show that humans perceive fine-grained details with a mixture
of foveal vision and peripheral vision. Fovea has the highest possible visual
acuity and is responsible for seeing the details. The peripheral vision is used
for perceiving the broad spatial scene and selecting the attended regions for
the fovea. Inspired by these observations, we propose a Gated Peripheral-Foveal
Convolutional Neural Network (GPF-CNN). It is a dedicated double-subnet neural
network, i.e. a peripheral subnet and a foveal subnet. The former aims to mimic
the functions of peripheral vision to encode the holistic information and
provide the attended regions. The latter aims to extract fine-grained features
on these key regions. Considering that the peripheral vision and foveal vision
play different roles in processing different visual stimuli, we further employ
a gated information fusion (GIF) network to weight their contributions. The
weights are determined through the fully connected layers followed by a sigmoid
function. We conduct comprehensive experiments on the standard AVA and
Photo.net datasets for unified aesthetic prediction tasks: (i) aesthetic
quality classification; (ii) aesthetic score regression; and (iii) aesthetic
score distribution prediction. The experimental results demonstrate the
effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.07998</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.07998</id><created>2018-12-18</created><updated>2019-05-15</updated><authors><author><keyname>Shen</keyname><forenames>Yifei</forenames></author><author><keyname>Shi</keyname><forenames>Yuanming</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled B.</forenames></author></authors><title>LORM: Learning to Optimize for Resource Management in Wireless Networks
  with Few Training Samples</title><categories>eess.SP cs.IT cs.LG math.IT</categories><comments>arXiv admin note: text overlap with arXiv:1811.07107</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Effective resource management plays a pivotal role in wireless networks,
which, unfortunately, results in challenging mixed-integer nonlinear
programming (MINLP) problems in most cases. Machine learning-based methods have
recently emerged as a disruptive way to obtain near-optimal performance for
MINLPs with affordable computational complexity. There have been some attempts
in applying such methods to resource management in wireless networks, but these
attempts require huge amounts of training samples and lack the capability to
handle constrained problems. Furthermore, they suffer from severe performance
deterioration when the network parameters change, which commonly happens and is
referred to as the task mismatch problem. In this paper, to reduce the sample
complexity and address the feasibility issue, we propose a framework of
Learning to Optimize for Resource Management (LORM). Instead of the end-to-end
learning approach adopted in previous studies, LORM learns the optimal pruning
policy in the branch-and-bound algorithm for MINLPs via a sample-efficient
method, namely, imitation learning. To further address the task mismatch
problem, we develop a transfer learning method via self-imitation in LORM,
named LORM-TL, which can quickly adapt a pre-trained machine learning model to
the new task with only a few additional unlabeled training samples. Numerical
simulations will demonstrate that LORM outperforms specialized state-of-the-art
algorithms and achieves near-optimal performance, while achieving significant
speedup compared with the branch-and-bound algorithm. Moreover, LORM-TL, by
relying on a few unlabeled samples, achieves comparable performance with the
model trained from scratch with sufficient labeled samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08043</identifier>
 <datestamp>2018-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08043</id><created>2018-12-19</created><authors><author><keyname>Vedula</keyname><forenames>Sanketh</forenames></author><author><keyname>Senouf</keyname><forenames>Ortal</forenames></author><author><keyname>Zurakhov</keyname><forenames>Grigoriy</forenames></author><author><keyname>Bronstein</keyname><forenames>Alex</forenames></author><author><keyname>Michailovich</keyname><forenames>Oleg</forenames></author><author><keyname>Zibulevsky</keyname><forenames>Michael</forenames></author></authors><title>Learning beamforming in ultrasound imaging</title><categories>cs.CV eess.IV physics.med-ph</categories><comments>Submitted to MIDL 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Medical ultrasound (US) is a widespread imaging modality owing its popularity
to cost efficiency, portability, speed, and lack of harmful ionizing radiation.
In this paper, we demonstrate that replacing the traditional ultrasound
processing pipeline with a data-driven, learnable counterpart leads to
significant improvement in image quality. Moreover, we demonstrate that greater
improvement can be achieved through a learning-based design of the transmitted
beam patterns simultaneously with learning an image reconstruction pipeline. We
evaluate our method on an in-vivo first-harmonic cardiac ultrasound dataset
acquired from volunteers and demonstrate the significance of the learned
pipeline and transmit beam patterns on the image quality when compared to
standard transmit and receive beamformers used in high frame-rate US imaging.
We believe that the presented methodology provides a fundamentally different
perspective on the classical problem of ultrasound beam pattern design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08067</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08067</id><created>2018-12-19</created><updated>2019-03-27</updated><authors><author><keyname>Li</keyname><forenames>Qing</forenames></author><author><keyname>Cao</keyname><forenames>Xiaozhi</forenames></author><author><keyname>Ye</keyname><forenames>Huihui</forenames></author><author><keyname>Liao</keyname><forenames>Congyu</forenames></author><author><keyname>He</keyname><forenames>Hongjian</forenames></author><author><keyname>Zhong</keyname><forenames>Jianhui</forenames></author></authors><title>Ultrashort Echo Time Magnetic Resonance Fingerprinting (UTE-MRF) for
  Simultaneous Quantification of Long and Ultrashort T2 Tissues</title><categories>physics.med-ph eess.IV</categories><comments>32 pages, 12 figures, 1 table</comments><journal-ref>Magnetic Resonance in Medicine (2019)</journal-ref><doi>10.1002/mrm.27812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To demonstrate an ultrashort echo time magnetic resonance
fingerprinting (UTE-MRF) method that can simultaneously quantify tissue
relaxometries for muscle and bone in musculoskeletal systems and tissue
components in brain and therefore can synthesize pseudo-CT images.
  Methods: A FISP-MRF sequence with half pulse excitation and half spoke radial
acquisition was designed to sample fast T2 decay signals. Sinusoidal echo time
(TE) pattern was applied to enhance MRF sensitivity for tissues with short and
ultrashort T2 values. The performance of UTE-MRF was evaluated via simulations,
phantoms, and in vivo experiments.
  Results: A minimal TE of 0.05 ms was achieved in UTE-MRF. Simulations
indicated that extension of TE sampling increased T2 quantification accuracy in
cortical bone and tendon, and had little impact on long T2 muscle
quantifications. For a rubber phantom, an average T1/T2 of 162/1.07 ms from
UTE-MRF were compared well with gold standard T2 of 190 ms from IR-UTE and T2*
of 1.03 ms from UTE sequence. For a long T2 agarose phantom, the linear
regression slope between UTE-MRF and gold standard was 1.07 (R2=0.991) for T1
and 1.04 (R2=0.994) for T2. In vivo experiments showed the detection of
cortical bone and Achilles tendon, where the averaged T2 was respectively 1.0
ms and 15 ms. Scalp images were in good agreement with CT.
  Conclusion: UTE-MRF with sinusoidal TE variations shows its capability to
produce pseudo-CT images and simultaneously output T1, T2, proton density, and
B0 maps for tissues with long T2 and short/ultrashort T2 in the brain and
musculoskeletal system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08148</identifier>
 <datestamp>2018-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08148</id><created>2018-12-19</created><authors><author><keyname>Bastopcu</keyname><forenames>Melih</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Minimizing Age of Information with Soft Updates</title><categories>cs.IT cs.NI cs.SI eess.SP math.IT math.OC</categories><comments>Submitted for publication, December 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an information updating system where an information provider and
an information receiver engage in an update process over time. Different from
the existing literature where updates are countable (hard) and take effect
either immediately or after a delay, but $instantaneously$ in both cases, here
updates start taking effect right away but $gradually$ over time. We coin this
setting $soft$ $updates$. When the updating process starts, the age decreases
until the soft update period ends. We constrain the number of times the
information provider and the information receiver meet (number of update
periods) and the total duration of the update periods. We consider two models
for the decrease of age during an update period: In the first model, the rate
of decrease of age is proportional to the current age, and in the second model,
the rate of decrease of age is constant. The first model results in an
exponentially decaying age, and the second model results in a linearly decaying
age. In both cases, we determine the optimum updating schemes, by determining
the optimum start times and optimum durations of the updates, subject to the
constraints on the number of update periods and the total update duration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08246</identifier>
 <datestamp>2019-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08246</id><created>2018-12-19</created><updated>2019-04-10</updated><authors><author><keyname>Ban</keyname><forenames>Yutong</forenames></author><author><keyname>Alameda-PIneda</keyname><forenames>Xavier</forenames></author><author><keyname>Evers</keyname><forenames>Christine</forenames></author><author><keyname>Horaud</keyname><forenames>Radu</forenames></author></authors><title>Tracking Multiple Audio Sources with the von Mises Distribution and
  Variational EM</title><categories>cs.SD eess.AS</categories><comments>IEEE Signal Processing Letters, 2019</comments><doi>10.1109/LSP.2019.2908376</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the problem of simultaneously tracking several
moving audio sources, namely the problem of estimating source trajectories from
a sequence of observed features. We propose to use the von Mises distribution
to model audio-source directions of arrival with circular random variables.
This leads to a Bayesian filtering formulation which is intractable because of
the combinatorial explosion of associating observed variables with latent
variables, over time. We propose a variational approximation of the filtering
distribution. We infer a variational expectation-maximization algorithm that is
both computationally tractable and time efficient. We propose an audio-source
birth method that favors smooth source trajectories and which is used both to
initialize the number of active sources and to detect new sources. We perform
experiments with the recently released LOCATA dataset comprising two moving
sources and a moving microphone array mounted onto a robot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08277</identifier>
 <datestamp>2019-06-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08277</id><created>2018-12-19</created><updated>2019-05-30</updated><authors><author><keyname>Herszterg</keyname><forenames>Ian</forenames></author><author><keyname>Poggi</keyname><forenames>Marcus</forenames></author><author><keyname>Vidal</keyname><forenames>Thibaut</forenames></author></authors><title>Two-Dimensional Phase Unwrapping via Balanced Spanning Forests</title><categories>eess.SP cs.DS math.OC</categories><doi>10.1287/ijoc.2018.0832</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phase unwrapping is the process of recovering a continuous phase signal from
an original signal wrapped in the ($-\pi$,$\pi$] interval. It is a critical
step of coherent signal processing, with applications such as synthetic
aperture radar, acoustic imaging, magnetic resonance, X-ray crystallography,
and seismic processing. In the field of computational optics, this problem is
classically treated as a norm-minimization problem, in which one seeks to
minimize the differences between the gradients of the original wrapped signal
and those of the continuous unwrapped signal. When the L0-norm is considered,
the number of differences should be minimized, leading to a difficult
combinatorial optimization problem. We propose an approximate model for the
L0-norm phase unwrapping problem in 2D, in which the singularities of the
wrapped phase image are associated with a graph where the vertices have $-1$ or
$+1$ polarities. The objective is to find a minimum-cost balanced spanning
forest where the sum of the polarities is equal to zero in each tree. We
introduce a set of primal and dual heuristics, a branch-and-cut algorithm, and
a hybrid metaheuristic to efficiently find exact or heuristic solutions. These
approaches move us one step closer to optimal solutions for 2D L0-norm phase
unwrapping; such solutions were previously viewed, in the signal processing
literature, as highly desirable but not achievable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08287</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08287</id><created>2018-12-19</created><authors><author><keyname>Ghamisi</keyname><forenames>Pedram</forenames></author><author><keyname>Rasti</keyname><forenames>Behnood</forenames></author><author><keyname>Yokoya</keyname><forenames>Naoto</forenames></author><author><keyname>Wang</keyname><forenames>Qunming</forenames></author><author><keyname>Hofle</keyname><forenames>Bernhard</forenames></author><author><keyname>Bruzzone</keyname><forenames>Lorenzo</forenames></author><author><keyname>Bovolo</keyname><forenames>Francesca</forenames></author><author><keyname>Chi</keyname><forenames>Mingmin</forenames></author><author><keyname>Anders</keyname><forenames>Katharina</forenames></author><author><keyname>Gloaguen</keyname><forenames>Richard</forenames></author><author><keyname>Atkinson</keyname><forenames>Peter M.</forenames></author><author><keyname>Benediktsson</keyname><forenames>Jon Atli</forenames></author></authors><title>Multisource and Multitemporal Data Fusion in Remote Sensing</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sharp and recent increase in the availability of data captured by
different sensors combined with their considerably heterogeneous natures poses
a serious challenge for the effective and efficient processing of remotely
sensed data. Such an increase in remote sensing and ancillary datasets,
however, opens up the possibility of utilizing multimodal datasets in a joint
manner to further improve the performance of the processing approaches with
respect to the application at hand. Multisource data fusion has, therefore,
received enormous attention from researchers worldwide for a wide variety of
applications. Moreover, thanks to the revisit capability of several spaceborne
sensors, the integration of the temporal information with the spatial and/or
spectral/backscattering information of the remotely sensed data is possible and
helps to move from a representation of 2D/3D data to 4D data structures, where
the time variable adds new information as well as challenges for the
information extraction algorithms. There are a huge number of research works
dedicated to multisource and multitemporal data fusion, but the methods for the
fusion of different modalities have expanded in different paths according to
each research community. This paper brings together the advances of multisource
and multitemporal data fusion approaches with respect to different research
communities and provides a thorough and discipline-specific starting point for
researchers at different levels (i.e., students, researchers, and senior
researchers) willing to conduct novel investigations on this challenging topic
by supplying sufficient detail and references.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08318</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08318</id><created>2018-12-19</created><authors><author><keyname>Vechtomova</keyname><forenames>Olga</forenames></author><author><keyname>Bahuleyan</keyname><forenames>Hareesh</forenames></author><author><keyname>Ghabussi</keyname><forenames>Amirpasha</forenames></author><author><keyname>John</keyname><forenames>Vineet</forenames></author></authors><title>Generating lyrics with variational autoencoder and multi-modal artist
  embeddings</title><categories>cs.CL cs.SD eess.AS</categories><comments>5 pages, 5 tables, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a system for generating song lyrics lines conditioned on the style
of a specified artist. The system uses a variational autoencoder with artist
embeddings. We propose the pre-training of artist embeddings with the
representations learned by a CNN classifier, which is trained to predict
artists based on MEL spectrograms of their song clips. This work is the first
step towards combining audio and text modalities of songs for generating lyrics
conditioned on the artist's style. Our preliminary results suggest that there
is a benefit in initializing artists' embeddings with the representations
learned by a spectrogram classifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08349</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08349</id><created>2018-12-19</created><authors><author><keyname>Hou</keyname><forenames>Xiaochao</forenames></author><author><keyname>Sun</keyname><forenames>Yao</forenames></author><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>He</keyname><forenames>Jinsong</forenames></author><author><keyname>Pou</keyname><forenames>Josep</forenames></author></authors><title>An Improved Decentralized Control of Grid-Connected Cascaded Inverters
  with Different Power Capacities</title><categories>eess.SP</categories><comments>4 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existing decentralized control for cascaded inverters is based on the
assumption that all modules have same capacities, and a local
fixed-amplitude-varied-phase voltage control is adopted for each inverter
module. However, available source power capacities of cascaded inverters may be
different in some practical applications. To address this issue, this letter
proposes an improved decentralized control scheme, in which the voltage
amplitudes are varied according to their individual available powers. Moreover,
a power factor consistency control is proposed to achieve autonomous voltage
phase synchronization. The steady-state analysis and synchronization mechanism
of cascaded inverters are illustrated. In addition, the proposed strategy has
other advantages, such as adjustable grid power factor and immune to the grid
voltage fault. The effectiveness of the proposed control is tested by
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08350</identifier>
 <datestamp>2019-04-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08350</id><created>2018-12-19</created><updated>2019-04-11</updated><authors><author><keyname>Wang</keyname><forenames>Tsun-Hsuan</forenames></author><author><keyname>Wang</keyname><forenames>Fu-En</forenames></author><author><keyname>Lin</keyname><forenames>Juan-Ting</forenames></author><author><keyname>Tsai</keyname><forenames>Yi-Hsuan</forenames></author><author><keyname>Chiu</keyname><forenames>Wei-Chen</forenames></author><author><keyname>Sun</keyname><forenames>Min</forenames></author></authors><title>Plug-and-Play: Improve Depth Estimation via Sparse Data Propagation</title><categories>eess.IV cs.CV</categories><comments>7 pages. 7 figures. ver.2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel plug-and-play (PnP) module for improving depth prediction
with taking arbitrary patterns of sparse depths as input. Given any pre-trained
depth prediction model, our PnP module updates the intermediate feature map
such that the model outputs new depths consistent with the given sparse depths.
Our method requires no additional training and can be applied to practical
applications such as leveraging both RGB and sparse LiDAR points to robustly
estimate dense depth map. Our approach achieves consistent improvements on
various state-of-the-art methods on indoor (i.e., NYU-v2) and outdoor (i.e.,
KITTI) datasets. Various types of LiDARs are also synthesized in our
experiments to verify the general applicability of our PnP module in practice.
For project page, see https://zswang666.github.io/PnP-Depth-Project-Page/
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08364</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08364</id><created>2018-12-20</created><authors><author><keyname>Ziabari</keyname><forenames>Amirkoushyar</forenames></author><author><keyname>Ye</keyname><forenames>Dong Hye</forenames></author><author><keyname>Fu</keyname><forenames>Lin</forenames></author><author><keyname>Srivastava</keyname><forenames>Somesh</forenames></author><author><keyname>Sauer</keyname><forenames>Ken D.</forenames></author><author><keyname>Thibault</keyname><forenames>Jean-Baptist</forenames></author><author><keyname>Bouman</keyname><forenames>Charles A.</forenames></author></authors><title>Model Based Iterative Reconstruction With Spatially Adaptive Sinogram
  Weights for Wide-Cone Cardiac CT</title><categories>eess.IV physics.med-ph</categories><comments>The 5th international Conference on image formation in X-ray Computed
  Tomography (Proceedings of CT Meeting). Compared to original publication, we
  slightly modified figure 4 for better clarity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the recent introduction of CT scanners with large cone angles, wide
coverage detectors now provide a desirable scanning platform for cardiac CT
that allows whole heart imaging in a single rotation. On these scanners, while
half-scan data is strictly sufficient to produce images with the best temporal
resolution, acquiring a full 360 degree rotation worth of data is beneficial
for wide-cone image reconstruction at negligible additional radiation dose.
Applying Model-Based Iterative Reconstruction (MBIR) algorithm to the heart has
shown to yield significant enhancement in image quality for cardiac CT. But
imaging the heart in large cone angle geometry leads to apparently conflicting
data usage considerations. On the one hand, in addition to using the fastest
available scanner rotation speed, a minimal complete data set of 180 degrees
plus the fan angle is typically used to minimize both cardiac and respiratory
motion. On the other hand, a full 360 degree acquisition helps better handle
the challenges of missing frequencies and incomplete projections associated
with wide-cone half-scan data acquisition. In this paper, we develop a
Spatially Adaptive sinogram Weights MBIR algorithm (SAW-MBIR) that is designed
to achieve the benefits of both half and full-scan reconstructions in order to
maximize temporal resolution over the heart region while providing stable
results over the whole volume covered with the wide-area detector.
Spatially-adaptive sinogram weights applied to each projection measurement in
SAW-MBIR are designed to selectively perform backprojection from the full and
half-scan portion of the sinogram based on both projection angle and
reconstructed voxel location. We demonstrate with experimental results of
SAW-MBIR applied to whole-heart cardiac CT clinical data that overall temporal
resolution matches half-scan while full volume image quality is on par with
full-scan MBIR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08367</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08367</id><created>2018-12-20</created><authors><author><keyname>Ziabari</keyname><forenames>Amirkoushyar</forenames></author><author><keyname>Ye</keyname><forenames>Dong Hye</forenames></author><author><keyname>Srivastava</keyname><forenames>Somesh</forenames></author><author><keyname>Sauer</keyname><forenames>Ken D.</forenames></author><author><keyname>Thibault</keyname><forenames>Jean-Baptiste</forenames></author><author><keyname>Bouman</keyname><forenames>Charles A.</forenames></author></authors><title>2.5D Deep Learning for CT Image Reconstruction using a Multi-GPU
  implementation</title><categories>eess.IV</categories><comments>IEEE Asilomar conference on signals systems and computers, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While Model Based Iterative Reconstruction (MBIR) of CT scans has been shown
to have better image quality than Filtered Back Projection (FBP), its use has
been limited by its high computational cost. More recently, deep convolutional
neural networks (CNN) have shown great promise in both denoising and
reconstruction applications. In this research, we propose a fast reconstruction
algorithm, which we call Deep Learning MBIR (DL-MBIR), for approximating MBIR
using a deep residual neural network. The DL-MBIR method is trained to produce
reconstructions that approximate true MBIR images using a 16 layer residual
convolutional neural network implemented on multiple GPUs using Google
Tensorflow. In addition, we propose 2D, 2.5D and 3D variations on the DL-MBIR
method and show that the 2.5D method achieves similar quality to the fully 3D
method, but with reduced computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08400</identifier>
 <datestamp>2019-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08400</id><created>2018-12-20</created><updated>2019-05-05</updated><authors><author><keyname>Nakatani</keyname><forenames>Tomohiro</forenames></author><author><keyname>Kinoshita</keyname><forenames>Keisuke</forenames></author></authors><title>A unified convolutional beamformer for simultaneous denoising and
  dereverberation</title><categories>eess.AS cs.SD</categories><comments>Published in IEEE Signal Processing Letters</comments><journal-ref>IEEE Signal Processing Letters, vol. 26, no. 6, pp. 903-907, June
  2019</journal-ref><doi>10.1109/LSP.2019.2911179</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method for estimating a convolutional beamformer that
can perform denoising and dereverberation simultaneously in an optimal way. The
application of dereverberation based on a weighted prediction error (WPE)
method followed by denoising based on a minimum variance distortionless
response (MVDR) beamformer has conventionally been considered a promising
approach, however, the optimality of this approach cannot be guaranteed. To
realize the optimal integration of denoising and dereverberation, we present a
method that unifies the WPE dereverberation method and a variant of the MVDR
beamformer, namely a minimum power distortionless response (MPDR) beamformer,
into a single convolutional beamformer, and we optimize it based on a single
unified optimization criterion. The proposed beamformer is referred to as a
Weighted Power minimization Distortionless response (WPD) beamformer.
Experiments show that the proposed method substantially improves the speech
enhancement performance in terms of both objective speech enhancement measures
and automatic speech recognition (ASR) performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08430</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08430</id><created>2018-12-20</created><authors><author><keyname>Mahdiani</keyname><forenames>Hamid Reza</forenames><affiliation>Computer Science and Engineering Department, Shahid Beheshti University, Tehran, IRAN-Institute for Cognitive and Brain Science, Shahid Beheshti University, Tehran, Iran</affiliation></author><author><keyname>Bojnordi</keyname><forenames>Mahdi Nazm</forenames><affiliation>School of Computing, University of Utah, Salt Lake City, USA</affiliation></author><author><keyname>Fakhraie</keyname><forenames>Sied Mehdi</forenames><affiliation>Electrical and Computer Engineering Department, University of Tehran, Tehran, IRAN</affiliation></author></authors><title>Soft Realization: a Bio-inspired Implementation Paradigm</title><categories>cs.ET eess.SP q-bio.NC</categories><comments>The Imprecise (Approximate) computing and Relaxed Fault Tolerance
  concept are some but not all instances of the Soft Realization. The soft
  realization and imprecise computing are first introduced around 2005 as H.R.
  Mahdiani Phd Thesis proposal. The first imprecise computing paper is
  published in 2010. This manuscript is written in 2012, submitted to Nature in
  2017 and rejected by the editors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researchers traditionally solve the computational problems through rigorous
and deterministic algorithms called as Hard Computing. These precise algorithms
have widely been realized using digital technology as an inherently reliable
and accurate implementation platform, either in hardware or software forms.
This rigid form of implementation which we refer as Hard Realization relies on
strict algorithmic accuracy constraints dictated to digital design engineers.
Hard realization admits paying as much as necessary implementation costs to
preserve computation precision and determinism throughout all the design and
implementation steps. Despite its prior accomplishments, this conventional
paradigm has encountered serious challenges with today's emerging applications
and implementation technologies. Unlike traditional hard computing, the
emerging soft and bio-inspired algorithms do not rely on fully precise and
deterministic computation. Moreover, the incoming nanotechnologies face
increasing reliability issues that prevent them from being efficiently
exploited in hard realization of applications. This article examines Soft
Realization, a novel bio-inspired approach to design and implementation of an
important category of applications noticing the internal brain structure. The
proposed paradigm mitigates major weaknesses of hard realization by (1)
alleviating incompatibilities with today's soft and bio-inspired algorithms
such as artificial neural networks, fuzzy systems, and human sense signal
processing applications, and (2) resolving the destructive inconsistency with
unreliable nanotechnologies. Our experimental results on a set of well-known
soft applications implemented using the proposed soft realization paradigm in
both reliable and unreliable technologies indicate that significant energy,
delay, and area savings can be obtained compared to the conventional
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08466</identifier>
 <datestamp>2019-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08466</id><created>2018-12-20</created><updated>2019-01-17</updated><authors><author><keyname>Kilgour</keyname><forenames>Kevin</forenames></author><author><keyname>Zuluaga</keyname><forenames>Mauricio</forenames></author><author><keyname>Roblek</keyname><forenames>Dominik</forenames></author><author><keyname>Sharifi</keyname><forenames>Matthew</forenames></author></authors><title>Fr\'echet Audio Distance: A Metric for Evaluating Music Enhancement
  Algorithms</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the Fr\'echet Audio Distance (FAD), a novel, reference-free
evaluation metric for music enhancement algorithms. We demonstrate how typical
evaluation metrics for speech enhancement and blind source separation can fail
to accurately measure the perceived effect of a wide variety of distortions. As
an alternative, we propose adapting the Fr\'echet Inception Distance (FID)
metric used to evaluate generative image models to the audio domain. FAD is
validated using a wide variety of artificial distortions and is compared to the
signal based metrics signal to distortion ratio (SDR), cosine distance and
magnitude L2 distance. We show that, with a correlation coefficient of 0.52,
FAD correlates more closely with human perception than either SDR, cosine
distance or magnitude L2 distance, with correlation coefficients of 0.39, -0.15
and -0.01 respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08471</identifier>
 <datestamp>2019-04-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08471</id><created>2018-12-20</created><updated>2019-04-10</updated><authors><author><keyname>Li</keyname><forenames>Xiaofei</forenames></author><author><keyname>Girin</keyname><forenames>Laurent</forenames></author><author><keyname>Gannot</keyname><forenames>Sharon</forenames></author><author><keyname>Horaud</keyname><forenames>Radu</forenames></author></authors><title>Multichannel Online Dereverberation based on Spectral Magnitude Inverse
  Filtering</title><categories>cs.SD eess.AS</categories><comments>Paper submitted to IEEE/ACM Transactions on Audio, Speech and
  Language Processing. IEEE Signal Processing Letters, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of multichannel online dereverberation. The
proposed method is carried out in the short-time Fourier transform (STFT)
domain, and for each frequency band independently. In the STFT domain, the
time-domain room impulse response is approximately represented by the
convolutive transfer function (CTF). The multichannel CTFs are adaptively
identified based on the cross-relation method, and using the recursive least
square criterion. Instead of the complex-valued CTF convolution model, we use a
nonnegative convolution model between the STFT magnitude of the source signal
and the CTF magnitude, which is just a coarse approximation of the former
model, but is shown to be more robust against the CTF perturbations. Based on
this nonnegative model, we propose an online STFT magnitude inverse filtering
method. The inverse filters of the CTF magnitude are formulated based on the
multiple-input/output inverse theorem (MINT), and adaptively estimated based on
the gradient descent criterion. Finally, the inverse filtering is applied to
the STFT magnitude of the microphone signals, obtaining an estimate of the STFT
magnitude of the source signal. Experiments regarding both speech enhancement
and automatic speech recognition are conducted, which demonstrate that the
proposed method can effectively suppress reverberation, even for the difficult
case of a moving speaker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08555</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08555</id><created>2018-12-20</created><updated>2019-11-25</updated><authors><author><keyname>Casas</keyname><forenames>Leslie</forenames></author><author><keyname>Klimmek</keyname><forenames>Attila</forenames></author><author><keyname>Navab</keyname><forenames>Nassir</forenames></author><author><keyname>Belagiannis</keyname><forenames>Vasileios</forenames></author></authors><title>Adversarial Signal Denoising with Encoder-Decoder Networks</title><categories>cs.LG eess.SP stat.ML</categories><comments>7 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The presence of noise is common in signal processing independent of the
signal type. Deep neural networks have shown good performance in removing
signal noise, especially in the image domain. In this work, we consider deep
neural networks as a denoising tool where our focus is on one dimensional
signals. For that purpose, we introduce an encoder-decoder network architecture
to denoise signals, represented by a sequence of measurements. Instead of
relying only on the standard reconstruction error to train the encoder-decoder
network, we treat the task of signal denoising as distribution alignment
between the clean and noisy signals. Then, we propose to train the
encoder-decoder with adversarial learning, where the goal is to align the clean
and noisy signal latent representation. Unlike standard adversarial learning,
we do not have access to the distribution of the clean signal's latent
representation in advance. For that reason, we propose a new formulation where
both clean and noisy signals pass through the encoder to produce the latent
representation. Afterwards, a discriminator neural network has to detect
whether the latent representation comes from the clean or noisy signal. At the
end of training, aligning the two signal distributions results in removing the
noise. In our experiments, we study two signal types with complex noise models.
First, we evaluate on electrocardiography and later on motion signal denoising.
We show better performance than the related learning-based and non-learning
approaches, such as autoencoders, wavenet denoiser, recurrent neural networks
and wavelets, demonstrating the benefits of adversarial learning for one
dimensional signal denoising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08593</identifier>
 <datestamp>2018-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08593</id><created>2018-12-16</created><updated>2018-12-21</updated><authors><author><keyname>Sadeghi</keyname><forenames>Alireza</forenames></author><author><keyname>Sheikholeslami</keyname><forenames>Fatemeh</forenames></author><author><keyname>Marques</keyname><forenames>Antonio G.</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Reinforcement Learning for Adaptive Caching with Dynamic Storage Pricing</title><categories>eess.SP cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Small base stations (SBs) of fifth-generation (5G) cellular networks are
envisioned to have storage devices to locally serve requests for reusable and
popular contents by \emph{caching} them at the edge of the network, close to
the end users. The ultimate goal is to shift part of the predictable load on
the back-haul links, from on-peak to off-peak periods, contributing to a better
overall network performance and service experience. To enable the SBs with
efficient \textit{fetch-cache} decision-making schemes operating in dynamic
settings, this paper introduces simple but flexible generic time-varying
fetching and caching costs, which are then used to formulate a constrained
minimization of the aggregate cost across files and time. Since caching
decisions per time slot influence the content availability in future slots, the
novel formulation for optimal fetch-cache decisions falls into the class of
dynamic programming. Under this generic formulation, first by considering
stationary distributions for the costs and file popularities, an efficient
reinforcement learning-based solver known as value iteration algorithm can be
used to solve the emerging optimization problem. Later, it is shown that
practical limitations on cache capacity can be handled using a particular
instance of the generic dynamic pricing formulation. Under this setting, to
provide a light-weight online solver for the corresponding optimization, the
well-known reinforcement learning algorithm, $Q$-learning, is employed to find
optimal fetch-cache decisions. Numerical tests corroborating the merits of the
proposed approach wrap up the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08600</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08600</id><created>2018-12-17</created><authors><author><keyname>Malekzadeh</keyname><forenames>Saber</forenames></author><author><keyname>Gholizadeh</keyname><forenames>Mohammad Hossein</forenames></author><author><keyname>Razavi</keyname><forenames>Seyed Naser</forenames></author></authors><title>Persian phonemes recognition using PPNet</title><categories>eess.AS cs.LG cs.SD</categories><comments>Submitted to &quot;Journal of Signal Processing Systems&quot;. arXiv admin
  note: substantial text overlap with arXiv:1812.06953</comments><doi>10.13140/RG.2.2.34836.96647</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a new approach for recognition of Persian phonemes on the PCVC
speech dataset is proposed. Nowadays deep neural networks are playing main rule
in classification tasks. However the best results in speech recognition are not
as good as human recognition rate yet. Deep learning techniques are shown their
outstanding performance over so many classification tasks like image
classification, document classification, etc. Also in some tasks their
performance were even better than human. So the reason why ASR (automatic
speech recognition) systems are not as good as the human speech recognition
system is mostly depend on features of data is fed to deep neural networks. In
this research first sound samples are cut for exact extraction of phoneme
sounds in 50ms samples. Then phonemes are grouped in 30 groups; Containing 23
consonants, 6 vowels and a silence phoneme. STFT (Short time Fourier transform)
is applied on them and Then STFT results are given to PPNet (A new deep
convolutional neural network architecture) classifier and a total average of
75.87% accuracy is reached which is the best result ever compared to other
algorithms on Separated Persian phonemes (Like in PCVC speech dataset).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08723</identifier>
 <datestamp>2018-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08723</id><created>2018-12-20</created><authors><author><keyname>Avron</keyname><forenames>Haim</forenames></author><author><keyname>Kapralov</keyname><forenames>Michael</forenames></author><author><keyname>Musco</keyname><forenames>Cameron</forenames></author><author><keyname>Musco</keyname><forenames>Christopher</forenames></author><author><keyname>Velingker</keyname><forenames>Ameya</forenames></author><author><keyname>Zandieh</keyname><forenames>Amir</forenames></author></authors><title>A Universal Sampling Method for Reconstructing Signals with Simple
  Fourier Transforms</title><categories>cs.DS cs.LG eess.SP math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconstructing continuous signals from a small number of discrete samples is
a fundamental problem across science and engineering. In practice, we are often
interested in signals with 'simple' Fourier structure, such as bandlimited,
multiband, and Fourier sparse signals. More broadly, any prior knowledge about
a signal's Fourier power spectrum can constrain its complexity. Intuitively,
signals with more highly constrained Fourier structure require fewer samples to
reconstruct.
  We formalize this intuition by showing that, roughly, a continuous signal
from a given class can be approximately reconstructed using a number of samples
proportional to the *statistical dimension* of the allowed power spectrum of
that class. Further, in nearly all settings, this natural measure tightly
characterizes the sample complexity of signal reconstruction.
  Surprisingly, we also show that, up to logarithmic factors, a universal
non-uniform sampling strategy can achieve this optimal complexity for *any
class of signals*. We present a simple and efficient algorithm for recovering a
signal from the samples taken. For bandlimited and sparse signals, our method
matches the state-of-the-art. At the same time, it gives the first
computationally and sample efficient solution to a broad range of problems,
including multiband signal reconstruction and kriging and Gaussian process
regression tasks in one dimension.
  Our work is based on a novel connection between randomized linear algebra and
signal reconstruction with constrained Fourier structure. We extend tools based
on statistical leverage score sampling and column-based matrix reconstruction
to the approximation of continuous linear operators that arise in signal
reconstruction. We believe that these extensions are of independent interest
and serve as a foundation for tackling a broad range of continuous time
problems using randomized methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08914</identifier>
 <datestamp>2018-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08914</id><created>2018-12-20</created><authors><author><keyname>Kim</keyname><forenames>Jang-Hyun</forenames></author><author><keyname>Yoo</keyname><forenames>Jaejun</forenames></author><author><keyname>Chun</keyname><forenames>Sanghyuk</forenames></author><author><keyname>Kim</keyname><forenames>Adrian</forenames></author><author><keyname>Ha</keyname><forenames>Jung-Woo</forenames></author></authors><title>Multi-Domain Processing via Hybrid Denoising Networks for Speech
  Enhancement</title><categories>eess.AS cs.SD</categories><comments>7pages, 6 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a hybrid framework that leverages the trade-off between temporal
and frequency precision in audio representations to improve the performance of
speech enhancement task. We first show that conventional approaches using
specific representations such as raw-audio and spectrograms are each effective
at targeting different types of noise. By integrating both approaches, our
model can learn multi-scale and multi-domain features, effectively removing
noise existing on different regions on the time-frequency space in a
complementary way. Experimental results show that the proposed hybrid model
yields better performance and robustness than using each model individually.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.08992</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.08992</id><created>2018-12-21</created><authors><author><keyname>Shankar</keyname><forenames>Shiva</forenames></author></authors><title>Structurally Stable Properties of Control Systems</title><categories>math.OC cs.SY eess.SY</categories><comments>http://www.mathnet.ru/ConfLogos/1287/Abstr_book_final.pdf, 2018</comments><msc-class>39A14, 93B25, 13P25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Talk dedicated to the 110th anniversary of L.S.Pontryagin.
  Steklov Mathematical Institute of Russian Academy of Sciences, Moscow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09024</identifier>
 <datestamp>2018-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09024</id><created>2018-12-21</created><authors><author><keyname>Immink</keyname><forenames>Kees A. Schouhamer</forenames></author><author><keyname>Cai</keyname><forenames>Kui</forenames></author></authors><title>An Unsupervised Learning Approach for Data Detection in the Presence of
  Channel Mismatch and Additive Noise</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate machine learning based on clustering techniques that are
suitable for the detection of encoded strings of q-ary symbols transmitted over
a noisy channel with partially unknown characteristics. We consider the
detection of the q-ary data as a classification problem, where objects are
recognized from a corrupted vector, which is obtained by an unknown corruption
process. We first evaluate the error performance of k- means clustering
technique without constrained coding. Secondly, we apply constrained codes that
create an environment that improves the detection reliability and it allows a
wider range of channel uncertainties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09034</identifier>
 <datestamp>2018-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09034</id><created>2018-12-21</created><authors><author><keyname>Immink</keyname><forenames>Kees A. Schouhamer</forenames></author><author><keyname>Cai</keyname><forenames>Kui</forenames></author></authors><title>Computation of the spectrum of $\text{dc}^2$-balanced codes</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply the central limit theorem for deriving approximations to the
auto-correlation function and power density function (spectrum) of second-order
spectral null (dc2-balanced) codes.We show that the auto-correlation function
of dc2-balanced codes can be accurately approximated by a cubic function. We
show that the difference between the approximate and exact spectrum is less
than 0.04 dB for codeword length n = 256.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09048</identifier>
 <datestamp>2018-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09048</id><created>2018-12-21</created><authors><author><keyname>Sharma</keyname><forenames>Rakesh K.</forenames></author><author><keyname>Sircar</keyname><forenames>Pradip</forenames></author></authors><title>Parametric Modeling of EEG Signals</title><categories>eess.SP</categories><comments>6 pages, 5 figures, International Conference on Mathematical Biology
  (ICMB 2004), IIT Kanpur, Kanpur, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new signal model is suggested for parametric representation
of the electroencephalogram (EEG) signals. The proposed model which is an
amplitude and frequency modulated sinusoidal signal model, has been found to
capture the non-stationary characteristics of the EEG signal with good
accuracy. When the EEG signal is considered for longer duration of time, the
model parameters have turned to be time-variant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09127</identifier>
 <datestamp>2018-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09127</id><created>2018-12-03</created><authors><author><keyname>Nguyen</keyname><forenames>Trung</forenames></author><author><keyname>Lakshmanan</keyname><forenames>Barth</forenames></author><author><keyname>Sheng</keyname><forenames>Weihua</forenames></author></authors><title>A Smart Security System with Face Recognition</title><categories>cs.MM cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web-based technology has improved drastically in the past decade. As a
result, security technology has become a major help to protect our daily life.
In this paper, we propose a robust security based on face recognition system
(SoF). In particular, we develop this system to giving access into a home for
authenticated users. The classifier is trained by using a new adaptive learning
method. The training data are initially collected from social networks. The
accuracy of the classifier is incrementally improved as the user starts using
the system. A novel method has been introduced to improve the classifier model
by human interaction and social media. By using a deep learning framework -
TensorFlow, it will be easy to reuse the framework to adopt with many devices
and applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09244</identifier>
 <datestamp>2019-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09244</id><created>2018-12-21</created><updated>2019-06-05</updated><authors><author><keyname>Chrupa&#x142;a</keyname><forenames>Grzegorz</forenames></author></authors><title>Symbolic inductive bias for visually grounded learning of spoken
  language</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>ACL 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A widespread approach to processing spoken language is to first automatically
transcribe it into text. An alternative is to use an end-to-end approach:
recent works have proposed to learn semantic embeddings of spoken language from
images with spoken captions, without an intermediate transcription step. We
propose to use multitask learning to exploit existing transcribed speech within
the end-to-end setting. We describe a three-task architecture which combines
the objectives of matching spoken captions with corresponding images, speech
with text, and text with images. We show that the addition of the speech/text
task leads to substantial performance improvements on image retrieval when
compared to training the speech/image task in isolation. We conjecture that
this is due to a strong inductive bias transcribed speech provides to the
model, and offer supporting evidence for this.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09323</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09323</id><created>2018-12-22</created><authors><author><keyname>Yeh</keyname><forenames>Chih-Kuan</forenames></author><author><keyname>Chen</keyname><forenames>Jianshu</forenames></author><author><keyname>Yu</keyname><forenames>Chengzhu</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>Unsupervised Speech Recognition via Segmental Empirical Output
  Distribution Matching</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>Published as a conference paper at ICLR 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of training speech recognition systems without using
any labeled data, under the assumption that the learner can only access to the
input utterances and a phoneme language model estimated from a non-overlapping
corpus. We propose a fully unsupervised learning algorithm that alternates
between solving two sub-problems: (i) learn a phoneme classifier for a given
set of phoneme segmentation boundaries, and (ii) refining the phoneme
boundaries based on a given classifier. To solve the first sub-problem, we
introduce a novel unsupervised cost function named Segmental Empirical Output
Distribution Matching, which generalizes the work in (Liu et al., 2017) to
segmental structures. For the second sub-problem, we develop an approximate MAP
approach to refining the boundaries obtained from Wang et al. (2017).
Experimental results on TIMIT dataset demonstrate the success of this fully
unsupervised phoneme recognition system, which achieves a phone error rate
(PER) of 41.6%. Although it is still far away from the state-of-the-art
supervised systems, we show that with oracle boundaries and matching language
model, the PER could be improved to 32.5%.This performance approaches the
supervised system of the same model architecture, demonstrating the great
potential of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09324</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09324</id><created>2018-12-21</created><updated>2019-12-21</updated><authors><author><keyname>Papayiannis</keyname><forenames>Constantinos</forenames></author><author><keyname>Evers</keyname><forenames>Christine</forenames></author><author><keyname>Naylor</keyname><forenames>Patrick A.</forenames></author></authors><title>End-to-End Classification of Reverberant Rooms using DNNs</title><categories>eess.AS cs.SD</categories><comments>Submitted to IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reverberation is present in our workplaces, our homes and even in places
designed as auditoria, such as concert halls and theatres. This work
investigates how deep learning can use the effect of reverberation on speech to
classify a recording in terms of the room in which it was recorded in.
Approaches previously taken in the literature for the task relied on handpicked
acoustic parameters as features used by classifiers. Estimating the values of
these parameters from reverberant speech involves estimation errors, inevitably
impacting the classification accuracy. This paper shows how DNNs can perform
the classification in an end-to-end fashion, therefore by operating directly on
reverberant speech. Based on the above, a method for the training of
generalisable DNN classifiers and a DNN architecture for the task are proposed.
A study is also made on the relationship between feature-maps derived by DNNs
and acoustic parameters that describe known properties of reverberation. In the
experiments shown, AIRs are used that were measured in 7 real rooms. The
classification accuracy of DNNs is compared between the case of having access
to the AIRs and the case of having access only to the reverberant speech
recorded in the same rooms. The experiments show that with access to the AIRs a
DNN achieves an accuracy of 99.1% and with access only to reverberant speech,
the proposed DNN achieves an accuracy of 86.9%. The experiments replicate the
testing procedure used in previous work, which relied on handpicked acoustic
parameters, allowing the direct evaluation of the benefit of using deep
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09477</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09477</id><created>2018-12-22</created><authors><author><keyname>Yang</keyname><forenames>Tingxiao</forenames></author><author><keyname>Yoshimura</keyname><forenames>Yuichiro</forenames></author><author><keyname>Morita</keyname><forenames>Akira</forenames></author><author><keyname>Namiki</keyname><forenames>Takao</forenames></author><author><keyname>Nakaguchi</keyname><forenames>Toshiya</forenames></author></authors><title>Fully Automatic Segmentation of Sublingual Veins from Retrained U-Net
  Model for Few Near Infrared Images</title><categories>cs.CV eess.IV</categories><comments>IMQA 2018 Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sublingual vein is commonly used to diagnose the health status. The width of
main sublingual veins gives information of the blood circulation. Therefore, it
is necessary to segment the main sublingual veins from the tongue
automatically. In general, the dataset in the medical field is small, which is
a challenge for training the deep learning model. In order to train the model
with a small data set, the proposed method for automatically segmenting the
sublingual veins is to re-train U-net model with different sets of the limited
number of labels for the same training images. With pre-knowledge of the
segmentation, the loss of the trained model will be convergence easier. To
improve the performance of the segmentation further, a novel strategy of data
augmentation was utilized. The operation for masking output of the model with
the input was randomly switched on or switched off in each training step. This
approach will force the model to learn the contrast invariance and avoid
overfitting. Images of dataset were taken with the developed device using eight
near infrared LEDs. The final segmentation results were evaluated on the
validation dataset by the IoU metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09484</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09484</id><created>2018-12-22</created><authors><author><keyname>Mingote</keyname><forenames>Victoria</forenames></author><author><keyname>Miguel</keyname><forenames>Antonio</forenames></author><author><keyname>Ortega</keyname><forenames>Alfonso</forenames></author><author><keyname>Lleida</keyname><forenames>Eduardo</forenames></author></authors><title>Differentiable Supervector Extraction for Encoding Speaker and Phrase
  Information in Text Dependent Speaker Verification</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>5 pages, IberSPEECH 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new differentiable neural network alignment
mechanism for text-dependent speaker verification which uses alignment models
to produce a supervector representation of an utterance. Unlike previous works
with similar approaches, we do not extract the embedding of an utterance from
the mean reduction of the temporal dimension. Our system replaces the mean by a
phrase alignment model to keep the temporal structure of each phrase which is
relevant in this application since the phonetic information is part of the
identity in the verification task. Moreover, we can apply a convolutional
neural network as front-end, and thanks to the alignment process being
differentiable, we can train the whole network to produce a supervector for
each utterance which will be discriminative with respect to the speaker and the
phrase simultaneously. As we show, this choice has the advantage that the
supervector encodes the phrase and speaker information providing good
performance in text-dependent speaker verification tasks. In this work, the
process of verification is performed using a basic similarity metric, due to
simplicity, compared to other more elaborate models that are commonly used. The
new model using alignment to produce supervectors was tested on the
RSR2015-Part I database for text-dependent speaker verification, providing
competitive results compared to similar size networks using the mean to extract
embeddings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09506</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09506</id><created>2018-12-22</created><authors><author><keyname>Mannepalli</keyname><forenames>Teja</forenames></author><author><keyname>Routray</keyname><forenames>Aurobinda</forenames></author></authors><title>Certainty based Reduced Sparse Solution for Dense Array EEG Source
  Localization</title><categories>eess.SP</categories><comments>IEEE Transactions on Neural Systems &amp; Rehabilitation Engineering,
  2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The EEG source localization is an ill-posed problem. It involves estimation
of the sources which outnumbers the number of measurements. For a given
measurement at given time all sources are not active which makes the problem as
sparse inversion problem. This paper presents a new approach for dense array
EEG source localization. This paper aims at reducing the solution space to only
most certain sources and thereby reducing the problem of ill-posedness. This
employs a two-stage method where the first stage finds the most certain sources
that are likely to produce the observed EEG by using a statistical measure of
sources, the second stage solves the inverse problem by restricting the
solution space to only most certain sources and their neighbors. This reduces
the solution space for other source localization methods hence improvise their
accuracy in localizing the active neurological sources in the brain which is
the main goal. This method has been validated and applied to real 256 channel
data and the results were analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09571</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09571</id><created>2018-12-22</created><authors><author><keyname>Abdelmoaty</keyname><forenames>Ahmed</forenames></author></authors><title>Channel Modeling for Over-water Communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over-water communication has been an important research field of wireless
communications and radar. Since there are so many parameters in this
environment that are changing continuously in the spatial and temporal domains
such as weather and sea surface parameters. Hence, accurately modeling the
over-water propagation channel is very crucial and challenging at the same
time. In this report, we will shed some light on the parabolic equation (PE)
method which is one of the main methods used to model the radio waves
propagation over variable terrain and through the homogeneous and inhomogeneous
atmosphere. Besides ray-tracing, PE is among the most widely used approaches
nowadays for deterministically analyze over-water channels. We are trying to
pave the way for better understanding of the mathematical background for the PE
and develop a tool to perform advanced analysis for the over-water
communication channel taking into consideration its spatial and temporal
behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09592</identifier>
 <datestamp>2019-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09592</id><created>2018-12-22</created><updated>2019-01-17</updated><authors><author><keyname>Huang</keyname><forenames>Song-Wen</forenames></author><author><keyname>Pados</keyname><forenames>Dimitris A.</forenames></author></authors><title>Multicarrier Chirp-Division Multiplexing for Wireless Communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a multicarrier chirp-division multiplexing (MCDM) system in which
orthogonal chirp waveforms are utilized as frequency subcarriers. Orthogonal
characteristics of chirp subcarriers are analyzed in respect to
cross-correlation coefficients among subcarriers. Moreover, orthogonal chirp
transform (OCT) is developed to implement MCDM systems. In addition, we design
a low complexity receiver, including packet synchronization, carrier frequency
offset compensation, channel estimation, and symbol detection. Proposed MCDM
systems have both advantages of chirp waveforms and multicarrier architectures.
Computational complexity of our proposed detector is discussed in detail. The
bit-error-rate (BER) performance of the MCDM system is evaluated in simulations
and indoor radio frequency (RF) experiments. We have demonstrated effectiveness
of MCDM systems both in simulation and experimental results, comparing to
orthogonal frequency division multiplexing (OFDM) systems. Moreover, MCDM can
be further applied to higher order modulations for enabling higher data rates
for RF wireless communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09593</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09593</id><created>2018-12-22</created><authors><author><keyname>de Souza</keyname><forenames>Joao Henrique Inacio</forenames></author><author><keyname>Abrao</keyname><forenames>Taufik</forenames></author></authors><title>Hybrid Hughes-Hartogs Power Allocation Algorithms for OFDMA Systems</title><categories>eess.SP</categories><comments>23 pages, 7 figures, 3 tables, IET Signal processing, 2018</comments><doi>10.1049/iet-spr.2018.5080</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work analyzes the discrete solution of Hughes-Hartogs (HH) for the
transmission rate maximization problem with power constraint in the OFDMA
systems and explores mechanisms to reduce the computational complexity of
greedy algorithms. In addition to the solution characterization, a
computational complexity analysis is developed, considering the number of
executed operations for running time purpose. Moreover, we have compared the
system capacity via the throughput obtained with the HH solution, and its
variants combined with three complexity reduction mechanisms. These tools
consist of an initial allocation bit vector calculated by rounding the results
of the water-filling (WF) solution, the multiple subchannels per iteration
updating, and the adoption of a subchannel grouping procedure. Our findings
indicate that the update of multiple subchannels and the subcarriers grouping
techniques reduce the number of iterations required for convergence of the
original HH, with some throughput degradation. Also, the bit-allocation
mechanism based on the WF is deployed as an alternative to overcome the HH
solution, increasing the computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09595</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09595</id><created>2018-12-22</created><authors><author><keyname>Ganguly</keyname><forenames>Biswarup</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author></authors><title>Kinect Sensor Based Gesture Recognition for Surveillance Application</title><categories>eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Hand gesture recognition has been granted as one of the emerging fields in
research today providing a natural way of communication between man and a
machine. Gestures are some forms of body motions which a person expresses when
doing a work or giving a reply. Human body tracking is a well studied topic in
todays era of Human Computer Interaction and it can be formed by the virtue of
human skeleton structures. These skeleton structures have been detected
successfully due to the smart progress of some devices, used to measure depth.
Human body movements have been viewed using these depth sensors which can
provide sufficient accuracy while tracking full body in real time mode with low
cost. In reality action and reaction activities are hardly periodic in a multi
person perspective situation. Also recognizing their complex a-periodic
gestures are highly challenging for detection in surveillance system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09798</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09798</id><created>2018-12-23</created><authors><author><keyname>Choi</keyname><forenames>Yoona</forenames></author><author><keyname>Lee</keyname><forenames>Bowon</forenames></author></authors><title>Pansori: ASR Corpus Generation from Open Online Video Contents</title><categories>eess.AS cs.CL cs.SD</categories><comments>5 pages with appendix</comments><journal-ref>Proceedings of IEEE Seoul Section Student Paper Contest 2018,
  Hongik University, pp. 117--121, Nov 2018</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper introduces Pansori, a program used to create ASR (automatic speech
recognition) corpora from online video contents. It utilizes a cloud-based
speech API to easily create a corpus in different languages. Using this
program, we semi-automatically generated the Pansori-TEDxKR dataset from Korean
TED conference talks with community-transcribed subtitles. It is the first
high-quality corpus for the Korean language freely available for independent
research. Pansori is released as an open-source software and the generated
corpus is released under a permissive public license for community use and
participation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09954</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09954</id><created>2018-12-24</created><authors><author><keyname>Kazi</keyname><forenames>Anees</forenames><affiliation>Computer Aided Medical Procedures, Technische Universit Munchen, Germany</affiliation></author><author><keyname>krishna</keyname><forenames>S. Arvind</forenames><affiliation>National Institute of Technology Tiruchirappalli, India</affiliation></author><author><keyname>Shekarforoush</keyname><forenames>Shayan</forenames><affiliation>Sharif University of Technology, Iran</affiliation></author><author><keyname>Kortuem</keyname><forenames>Karsten</forenames><affiliation>Augenklinik der Universitat, Klinikum der Universitat Munchen, Germany</affiliation></author><author><keyname>Albarqouni</keyname><forenames>Shadi</forenames><affiliation>Computer Aided Medical Procedures, Technische Universit Munchen, Germany</affiliation></author><author><keyname>Navab</keyname><forenames>Nassir</forenames><affiliation>Computer Aided Medical Procedures, Technische Universit Munchen, Germany</affiliation><affiliation>Johns Hopkins University, Baltimore MD, USA</affiliation></author></authors><title>Self-Attention Equipped Graph Convolutions for Disease Prediction</title><categories>cs.LG eess.IV stat.ML</categories><comments>4 pages, 4 figures, paper accepted in ISBI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-modal data comprising imaging (MRI, fMRI, PET, etc.) and non-imaging
(clinical test, demographics, etc.) data can be collected together and used for
disease prediction. Such diverse data gives complementary information about the
patient\'s condition to make an informed diagnosis. A model capable of
leveraging the individuality of each multi-modal data is required for better
disease prediction. We propose a graph convolution based deep model which takes
into account the distinctiveness of each element of the multi-modal data. We
incorporate a novel self-attention layer, which weights every element of the
demographic data by exploring its relation to the underlying disease. We
demonstrate the superiority of our developed technique in terms of
computational speed and performance when compared to state-of-the-art methods.
Our method outperforms other methods with a significant margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.09985</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.09985</id><created>2018-12-24</created><authors><author><keyname>Yu</keyname><forenames>Y.</forenames></author><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author><author><keyname>Zakharov</keyname><forenames>Y.</forenames></author></authors><title>Study of Robust Diffusion Recursive Least Squares Algorithms with Side
  Information for Networked Agents</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>6 pages, 4 figures</comments><doi>10.1109/TSP.2019.2893846</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work develops a robust diffusion recursive least squares algorithm to
mitigate the performance degradation often experienced in networks of agents in
the presence of impulsive noise. This algorithm minimizes an exponentially
weighted least-squares cost function subject to a time-dependent constraint on
the squared norm of the intermediate estimate update at each node. With the
help of side information, the constraint is recursively updated in a diffusion
strategy. Moreover, a control strategy for resetting the constraint is also
proposed to retain good tracking capability when the estimated parameters
suddenly change. Simulations show the superiority of the proposed algorithm
over previously reported techniques in various impulsive noise scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10061</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10061</id><created>2018-12-25</created><authors><author><keyname>Rajaratnam</keyname><forenames>Krishan</forenames></author><author><keyname>Kalita</keyname><forenames>Jugal</forenames></author></authors><title>Noise Flooding for Detecting Audio Adversarial Examples Against
  Automatic Speech Recognition</title><categories>cs.SD cs.CL cs.CR cs.LG eess.AS</categories><comments>Orally presented at the 18th IEEE International Symposium on Signal
  Processing and Information Technology (ISSPIT) in Louisville, Kentucky, USA,
  December 2018. 5 pages, 2 figures</comments><doi>10.1109/ISSPIT.2018.8642623</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural models enjoy widespread use across a variety of tasks and have grown
to become crucial components of many industrial systems. Despite their
effectiveness and extensive popularity, they are not without their exploitable
flaws. Initially applied to computer vision systems, the generation of
adversarial examples is a process in which seemingly imperceptible
perturbations are made to an image, with the purpose of inducing a deep
learning based classifier to misclassify the image. Due to recent trends in
speech processing, this has become a noticeable issue in speech recognition
models. In late 2017, an attack was shown to be quite effective against the
Speech Commands classification model. Limited-vocabulary speech classifiers,
such as the Speech Commands model, are used quite frequently in a variety of
applications, particularly in managing automated attendants in telephony
contexts. As such, adversarial examples produced by this attack could have
real-world consequences. While previous work in defending against these
adversarial examples has investigated using audio preprocessing to reduce or
distort adversarial noise, this work explores the idea of flooding particular
frequency bands of an audio signal with random noise in order to detect
adversarial examples. This technique of flooding, which does not require
retraining or modifying the model, is inspired by work done in computer vision
and builds on the idea that speech classifiers are relatively robust to natural
noise. A combined defense incorporating 5 different frequency bands for
flooding the signal with noise outperformed other existing defenses in the
audio space, detecting adversarial examples with 91.8% precision and 93.5%
recall.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10083</identifier>
 <datestamp>2019-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10083</id><created>2018-12-25</created><authors><author><keyname>Cai</keyname><forenames>Shanyong</forenames></author><author><keyname>Zhang</keyname><forenames>Zhiguo</forenames></author><author><keyname>Chen</keyname><forenames>Xue</forenames></author></authors><title>Turbulence-Resistant All Optical Relaying Based on Few-Mode EDFA in
  Free-Space Optical Systems</title><categories>eess.SP</categories><doi>10.1109/JLT.2019.2897428</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the communication performance of a few-mode EDFA based
all-optical relaying system for atmospheric channels in this paper. A dual-hop
free space optical communication model based on the relay with two-mode EDFA is
derived. The BER performance is numerically calculated. Compared with
all-optical relaying system with single-mode EDFA, the power budget is
increased by 4 dB, 7.5 dB and 11.5 dB at BER = 1E-4 under the refractive index
structure constant Cn2 = 2E-14, 5E-14 and 1E-13 respectively when a few mode
fiber supporting 4 modes is utilized as the receiving fiber at the destination.
The optimal relay location is slightly backward from the middle of the link.
The BER performance is the best when mode-dependent gain of FM-EDFA is zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10095</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10095</id><created>2018-12-25</created><authors><author><keyname>Samui</keyname><forenames>Suman</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Indrajit</forenames></author><author><keyname>Ghosh</keyname><forenames>Soumya K.</forenames></author></authors><title>Tensor-Train Long Short-Term Memory for Monaural Speech Enhancement</title><categories>cs.SD cs.LG eess.AS</categories><comments>Submitted to IEEE Signal Processing Letters</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In recent years, Long Short-Term Memory (LSTM) has become a popular choice
for speech separation and speech enhancement task. The capability of LSTM
network can be enhanced by widening and adding more layers. However, this would
introduce millions of parameters in the network and also increase the
requirement of computational resources. These limitations hinders the efficient
implementation of RNN models in low-end devices such as mobile phones and
embedded systems with limited memory. To overcome these issues, we proposed to
use an efficient alternative approach of reducing parameters by representing
the weight matrix parameters of LSTM based on Tensor-Train (TT) format. We
called this Tensor-Train factorized LSTM as TT-LSTM model. Based on this
TT-LSTM units, we proposed a deep TensorNet model for single-channel speech
enhancement task. Experimental results in various test conditions and in terms
of standard speech quality and intelligibility metrics, demonstrated that the
proposed deep TT-LSTM based speech enhancement framework can achieve
competitive performances with the state-of-the-art uncompressed RNN model, even
though the proposed model architecture is orders of magnitude less complex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10199</identifier>
 <datestamp>2019-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10199</id><created>2018-12-25</created><updated>2019-12-03</updated><authors><author><keyname>Zeng</keyname><forenames>Qiang</forenames></author><author><keyname>Su</keyname><forenames>Jianhai</forenames></author><author><keyname>Fu</keyname><forenames>Chenglong</forenames></author><author><keyname>Kayas</keyname><forenames>Golam</forenames></author><author><keyname>Luo</keyname><forenames>Lannan</forenames></author></authors><title>A Multiversion Programming Inspired Approach to Detecting Audio
  Adversarial Examples</title><categories>cs.SD cs.CR eess.AS</categories><comments>8 pages, 4 figures, AICS 2019, The AAAI-19 Workshop on Artificial
  Intelligence for Cyber Security (AICS), 2019</comments><report-no>AICS/2019/06</report-no><journal-ref>The AAAI-19 Workshop on Artificial Intelligence for Cyber Security
  (AICS), 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial examples (AEs) are crafted by adding human-imperceptible
perturbations to inputs such that a machine-learning based classifier
incorrectly labels them. They have become a severe threat to the
trustworthiness of machine learning. While AEs in the image domain have been
well studied, audio AEs are less investigated. Recently, multiple techniques
are proposed to generate audio AEs, which makes countermeasures against them an
urgent task. Our experiments show that, given an AE, the transcription results
by different Automatic Speech Recognition (ASR) systems differ significantly,
as they use different architectures, parameters, and training datasets.
Inspired by Multiversion Programming, we propose a novel audio AE detection
approach, which utilizes multiple off-the-shelf ASR systems to determine
whether an audio input is an AE. The evaluation shows that the detection
achieves accuracies over 98.6%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10227</identifier>
 <datestamp>2019-03-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10227</id><created>2018-12-26</created><updated>2019-03-21</updated><authors><author><keyname>Zhang</keyname><forenames>Yangsong</forenames></author><author><keyname>Yin</keyname><forenames>Erwei</forenames></author><author><keyname>Li</keyname><forenames>Fali</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Guo</keyname><forenames>Daqing</forenames></author><author><keyname>Yao</keyname><forenames>Dezhong</forenames></author><author><keyname>Xu</keyname><forenames>Peng</forenames></author></authors><title>Hierarchical feature fusion framework for frequency recognition in
  SSVEP-based BCIs</title><categories>q-bio.NC eess.SP</categories><comments>25 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Effective frequency recognition algorithms are critical in steady-state
visual evoked potential (SSVEP) based brain-computer interfaces (BCIs). In this
study, we present a hierarchical feature fusion framework which can be used to
design high-performance frequency recognition methods. The proposed framework
includes two primary technique for fusing features: spatial dimension fusion
(SD) and frequency dimension fusion (FD). Both SD and FD fusions are obtained
using a weighted strategy with a nonlinear function. To assess our novel
methods, we used the correlated component analysis (CORRCA) method to
investigate the efficiency and effectiveness of the proposed framework.
Experimental results were obtained from a benchmark dataset of thirty-five
subjects and indicate that the extended CORRCA method used within the framework
significantly outperforms the original CORCCA method. Accordingly, the proposed
framework holds promise to enhance the performance of frequency recognition
methods in SSVEP-based BCIs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10260</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10260</id><created>2018-12-26</created><authors><author><keyname>Lee</keyname><forenames>Kong Aik</forenames></author><author><keyname>Wang</keyname><forenames>Qiongqiong</forenames></author><author><keyname>Koshinaka</keyname><forenames>Takafumi</forenames></author></authors><title>The CORAL+ Algorithm for Unsupervised Domain Adaptation of PLDA</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art speaker recognition systems comprise an x-vector (or
i-vector) speaker embedding front-end followed by a probabilistic linear
discriminant analysis (PLDA) backend. The effectiveness of these components
relies on the availability of a large collection of labeled training data. In
practice, it is common that the domains (e.g., language, demographic) in which
the system are deployed differs from that we trained the system. To close the
gap due to the domain mismatch, we propose an unsupervised PLDA adaptation
algorithm to learn from a small amount of unlabeled in-domain data. The
proposed method was inspired by a prior work on feature-based domain adaptation
technique known as the correlation alignment (CORAL). We refer to the
model-based adaptation technique proposed in this paper as CORAL+. The efficacy
of the proposed technique is experimentally validated on the recent NIST 2016
and 2018 Speaker Recognition Evaluation (SRE'16, SRE'18) datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10312</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10312</id><created>2018-12-26</created><authors><author><keyname>Sarkheil</keyname><forenames>Morteza</forenames></author><author><keyname>Azmi</keyname><forenames>Paeiz</forenames></author><author><keyname>Forouzesh</keyname><forenames>Moslem</forenames></author><author><keyname>Kuhestani</keyname><forenames>Ali</forenames></author></authors><title>Covert Transmission with Antenna Selection and Using an External Jammer</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper adopts the antenna selection technique to enhance the covert rate
in a wireless communication network comprised of a source, a destination , an
external jammer and an eavesdropper. In the covert communication, the level of
transmit power is low and hence a source with multiple antennas can be adopted
to send the information toward the single antenna destination while
concurrently, the jammer transmits an artificial noise signal. For this system
model, we consider a scenario where the source is forced to select one or
several of its antennas to transmit its confidential information due to its
limited RF chains. Furthermore, we consider two different jamming scenarios to
support our covert communication: 1) The destination is unable to cancel the
jamming signal, 2) The destination can subtract the jamming signal. For such a
communication network, our aim is to maximize the covert rate subject to power
constraint and covert communication requirement. In the first scenario, the
optimization problem is non-convex, and hence, it can be solved through using
Difference of Convex function (DC) method while the optimization problem of the
second scenario is intrinsically convex. Our numerical results show that the
higher the number of selected antennas at the transmitter, the higher the
covert rate will be achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10316</identifier>
 <datestamp>2019-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10316</id><created>2018-12-26</created><updated>2019-04-29</updated><authors><author><keyname>Lai</keyname><forenames>Ke</forenames></author><author><keyname>Lei</keyname><forenames>Jing</forenames></author><author><keyname>Wen</keyname><forenames>Lei</forenames></author><author><keyname>Chen</keyname><forenames>Gaojie</forenames></author><author><keyname>Xiao</keyname><forenames>Pei</forenames></author><author><keyname>Maaref</keyname><forenames>Amine</forenames></author></authors><title>Hybrid Codeword Position Index Modulation for Sparse Code Multiple
  Access System</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel variation of codeword position index based sparse code
multiple access (CPI-SCMA) system, which is termed as hybrid codeword position
index modulated sparse code multiple access (HCPI-SCMA), is proposed to further
improve the transmission efficiency (TE). In this scheme, unlike the
conventional CPI-SCMA that uses only one kind of bits-toindices (BTI) mapper,
the codeword positions which are padded with zeros in CPI-SCMA are also
utilized to transmit additional information. Since multiple index selectors are
used in a HCPISCMA codeword, the original message passing algorithm (MPA) no
longer works in HCPI-SCMA; hence, a modified MPA is proposed to detect the
received signals. It is shown in the simulations and analysis that the proposed
scheme can achieve both higher TE and better error rate performance in the
region of high signal-to-noise ratio (SNR) compare to the conventional SCMA
(C-SCMA). Moreover, compared with CPI-SCMA, HCPISCMA can achieve higher TE with
approximately the same error rate performance compared to CPI-SCMA at high
SNRs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10318</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10318</id><created>2018-12-26</created><authors><author><keyname>Yao</keyname><forenames>Rugui</forenames></author><author><keyname>Zhang</keyname><forenames>Yuxin</forenames></author><author><keyname>Qi</keyname><forenames>Nan</forenames></author><author><keyname>Tsiftsis</keyname><forenames>Theodoros A.</forenames></author></authors><title>Machine Learning-Based Antenna Selection in Untrusted Relay Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the transmit antenna selection based on machine learning
(ML) schemes in untrusted relay networks. First, we state the conventional
antenna selection scheme. Then, we implement three ML schemes, namely, the
support vector machine-based scheme, the naive-Bayes-based scheme, and the
k-nearest neighbors-based scheme, which are applied to select the best antenna
with the highest secrecy rate. The simulation results are presented in terms of
system secrecy rate and secrecy outage probability. From the simulation, we can
conclude that the proposed ML-based antenna selection schemes can achieve the
same performance without amplification at the relay, or small performance
degradation with transmitted power constraint at the relay, comparing with
conventional schemes. However, when the training is completed, the proposed
schemes can perform the antenna selection with a small computational
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10366</identifier>
 <datestamp>2019-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10366</id><created>2018-12-26</created><updated>2019-04-05</updated><authors><author><keyname>Zhang</keyname><forenames>Yide</forenames></author><author><keyname>Zhu</keyname><forenames>Yinhao</forenames></author><author><keyname>Nichols</keyname><forenames>Evan</forenames></author><author><keyname>Wang</keyname><forenames>Qingfei</forenames></author><author><keyname>Zhang</keyname><forenames>Siyuan</forenames></author><author><keyname>Smith</keyname><forenames>Cody</forenames></author><author><keyname>Howard</keyname><forenames>Scott</forenames></author></authors><title>A Poisson-Gaussian Denoising Dataset with Real Fluorescence Microscopy
  Images</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>Camera-ready version for CVPR 2019. The Fluorescence Microscopy
  Denoising (FMD) dataset is available at
  https://drive.google.com/drive/folders/1aygMzSDdoq63IqSk-ly8cMq0_owup8UM</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluorescence microscopy has enabled a dramatic development in modern biology.
Due to its inherently weak signal, fluorescence microscopy is not only much
noisier than photography, but also presented with Poisson-Gaussian noise where
Poisson noise, or shot noise, is the dominating noise source. To get clean
fluorescence microscopy images, it is highly desirable to have effective
denoising algorithms and datasets that are specifically designed to denoise
fluorescence microscopy images. While such algorithms exist, no such datasets
are available. In this paper, we fill this gap by constructing a dataset - the
Fluorescence Microscopy Denoising (FMD) dataset - that is dedicated to
Poisson-Gaussian denoising. The dataset consists of 12,000 real fluorescence
microscopy images obtained with commercial confocal, two-photon, and wide-field
microscopes and representative biological samples such as cells, zebrafish, and
mouse brain tissues. We use image averaging to effectively obtain ground truth
images and 60,000 noisy images with different noise levels. We use this dataset
to benchmark 10 representative denoising algorithms and find that deep learning
methods have the best performance. To our knowledge, this is the first real
microscopy image dataset for Poisson-Gaussian denoising purposes and it could
be an important tool for high-quality, real-time denoising applications in
biomedical research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10386</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10386</id><created>2018-12-26</created><authors><author><keyname>Sereda</keyname><forenames>Iana</forenames></author><author><keyname>Alekseev</keyname><forenames>Sergey</forenames></author><author><keyname>Koneva</keyname><forenames>Aleksandra</forenames></author><author><keyname>Kataev</keyname><forenames>Roman</forenames></author><author><keyname>Osipov</keyname><forenames>Grigory</forenames></author></authors><title>ECG Segmentation by Neural Networks: Errors and Correction</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study we examined the question of how error correction occurs in an
ensemble of deep convolutional networks, trained for an important applied
problem: segmentation of Electrocardiograms(ECG). We also explore the
possibility of using the information about ensemble errors to evaluate a
quality of data representation, built by the network. This possibility arises
from the effect of distillation of outliers, which was demonstarted for the
ensemble, described in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10455</identifier>
 <datestamp>2018-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10455</id><created>2018-12-26</created><authors><author><keyname>Buyukates</keyname><forenames>Baturalp</forenames></author><author><keyname>Soysal</keyname><forenames>Alkan</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Age of Information in Multihop Multicast Networks</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>Submitted for publication, December 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the age of information in a multihop multicast network where
there is a single source node sending time-sensitive updates to $n^L$ end
nodes, and $L$ denotes the number of hops. In the first hop, the source node
sends updates to $n$ first-hop receiver nodes, and in the second hop each
first-hop receiver node relays the update packets that it has received to $n$
further users that are connected to it. This network architecture continues in
further hops such that each receiver node in hop $\ell$ is connected to $n$
further receiver nodes in hop $\ell+1$. We study the age of information
experienced by the end nodes, and in particular, its scaling as a function of
$n$. We show that, using an earliest $k$ transmission scheme in each hop, the
age of information at the end nodes can be made a constant independent of $n$.
In particular, the source node transmits each update packet to the earliest
$k_1$ of the $n$ first-hop nodes, and each first-hop node that receives the
update relays it to the earliest $k_2$ out of $n$ second-hop nodes that are
connected to it and so on. We determine the optimum $k_\ell$ stopping value for
each hop $\ell$ for arbitrary shifted exponential link delays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10470</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10470</id><created>2018-12-22</created><authors><author><keyname>Mathias</keyname><forenames>Luis C.</forenames></author><author><keyname>de Melo</keyname><forenames>Leonimer F.</forenames></author><author><keyname>Abrao</keyname><forenames>Taufik</forenames></author></authors><title>3-D Localization with Multiple LEDs Lamps in OFDM-VLC system</title><categories>eess.SP</categories><comments>28 pages, 12 figures, transaction paper</comments><journal-ref>IEEE Access, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible light communication (VLC) based localization is a potential candidate
for wide range indoor localization applications. In this paper, we propose a
VLC architecture based on orthogonal frequency division multiplexing (OFDM)
with multiple functionalities integrated in the same system, i.e., the 3- D
receiver location, the control of the room illumination intensity, as well as
the data transmission capability. Herein we propose an original methodology for
LED power discrimination applying spatial optical OFDM (SO-OFDM) structure for
position estimation. The hybrid locator initially makes a first estimate using
a weighted angle-of-arrival (WAoA)-based locator which is then used as the
starting point of the recursive estimator based on the strength of the received
signal (RSS). Hence, the first stage is deployed to increase convergence
probability, reducing the root-mean-square error (RMSE) and the number of
iterations of the second stage. Also, a performance vs computational complexity
comparative analysis is carried out with parameter variations of these
estimators. The numerical results indicate a decade improvement in the RMSE for
each two decades of decrement of power noise on the receiver photodiode. The
best clipping factor is obtained through the analysis of locator accuracy and
transmission capacity for each simulated system. Finally, the numerical results
also demonstrate effectiveness, robustness, and efficiency of the proposed
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10471</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10471</id><created>2018-12-23</created><authors><author><keyname>Kuske</keyname><forenames>Jan</forenames></author><author><keyname>Petra</keyname><forenames>Stefania</forenames></author></authors><title>Performance Bounds For Co-/Sparse Box Constrained Signal Recovery</title><categories>math.OC cs.IT cs.NA eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recovery of structured signals from a few linear measurements is a
central point in both compressed sensing (CS) and discrete tomography. In CS
the signal structure is described by means of a low complexity model e.g.
co-/sparsity. The CS theory shows that any signal/image can be undersampled at
a rate dependent on its intrinsic complexity. Moreover, in such undersampling
regimes, the signal can be recovered by sparsity promoting convex
regularization like $\ell_1$- or total variation (TV-) minimization. Precise
relations between many low complexity measures and the sufficient number of
random measurements are known for many sparsity promoting norms. However, a
precise estimate of the undersampling rate for the TV seminorm is still
lacking. We address this issue by: a) providing dual certificates testing
uniqueness of a given cosparse signal with bounded signal values, b)
approximating the undersampling rates via the statistical dimension of the TV
descent cone and c) showing empirically that the provided rates also hold for
tomographic measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10506</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10506</id><created>2018-12-26</created><updated>2019-05-17</updated><authors><author><keyname>Zhang</keyname><forenames>Han</forenames></author><author><keyname>Ai</keyname><forenames>Bo</forenames></author><author><keyname>Xu</keyname><forenames>Wenjun</forenames></author><author><keyname>Xu</keyname><forenames>Li</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Multi-Antenna Channel Interpolation via Tucker Decomposed Extreme
  Learning Machine</title><categories>eess.SP cs.IT cs.LG math.IT</categories><comments>8 Pages, 2 figures</comments><doi>10.1109/TVT.2019.2913865</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel interpolation is an essential technique for providing high-accuracy
estimation of the channel state information (CSI) for wireless systems design
where the frequency-space structural correlations of multi-antenna channel are
typically hidden in matrix or tensor forms. In this letter, a modified extreme
learning machine (ELM) that can process tensorial data, or ELM model with
tensorial inputs (TELM), is proposed to handle the channel interpolation task.
The TELM inherits many good properties from ELMs. Based on the TELM, the Tucker
decomposed extreme learning machine (TDELM) is proposed for further improving
the performance. Furthermore, we establish a theoretical argument to measure
the interpolation capability of the proposed learning machines. Experimental
results verify that our proposed learning machines can achieve comparable mean
squared error (MSE) performance against the traditional ELMs but with 15%
shorter running time, and outperform the other methods for a 20% margin
measured in MSE for channel interpolation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10538</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10538</id><created>2018-12-26</created><authors><author><keyname>Plaut</keyname><forenames>Elad</forenames></author><author><keyname>Giryes</keyname><forenames>Raja</forenames></author></authors><title>A Greedy Approach to $\ell_{0,\infty}$ Based Convolutional Sparse Coding</title><categories>eess.IV cs.LG eess.SP stat.ML</categories><comments>Accepted for publication in SIAM Journal on Imaging Sciences (SIIMS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse coding techniques for image processing traditionally rely on a
processing of small overlapping patches separately followed by averaging. This
has the disadvantage that the reconstructed image no longer obeys the sparsity
prior used in the processing. For this purpose convolutional sparse coding has
been introduced, where a shift-invariant dictionary is used and the sparsity of
the recovered image is maintained. Most such strategies target the $\ell_0$
&quot;norm&quot; or the $\ell_1$ norm of the whole image, which may create an imbalanced
sparsity across various regions in the image. In order to face this challenge,
the $\ell_{0,\infty}$ &quot;norm&quot; has been proposed as an alternative that &quot;operates
locally while thinking globally&quot;. The approaches taken for tackling the
non-convexity of these optimization problems have been either using a convex
relaxation or local pursuit algorithms. In this paper, we present an efficient
greedy method for sparse coding and dictionary learning, which is specifically
tailored to $\ell_{0,\infty}$, and is based on matching pursuit. We demonstrate
the usage of our approach in salt-and-pepper noise removal and image
inpainting. A code package which reproduces the experiments presented in this
work is available at https://web.eng.tau.ac.il/~raja
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10569</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10569</id><created>2018-12-26</created><authors><author><keyname>Sihag</keyname><forenames>Saurabh</forenames></author><author><keyname>Tajer</keyname><forenames>Ali</forenames></author></authors><title>Secure Estimation under Causative Attacks</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of secure parameter estimation when the
estimation algorithm is prone to causative attacks. Causative attacks, in
principle, target decision-making algorithms to alter their decisions by making
them oblivious to specific attacks. Such attacks influence inference algorithms
by tampering with the mechanism through which the algorithm is provided with
the statistical model of the population about which an inferential decision is
made. Causative attacks are viable, for instance, by contaminating the
historical or training data, or by compromising an expert who provides the
model. In the presence of causative attacks, the inference algorithms operate
under a distorted statistical model for the population from which they collect
data samples. This paper introduces specific notions of secure estimation and
provides a framework under which secure estimation under causative attacks can
be formulated. A central premise underlying the secure estimation framework is
that forming secure estimates introduces a new dimension to the estimation
objective, which pertains to detecting attacks and isolating the true model.
Since detection and isolation decisions are imperfect, their inclusion induces
an inherent coupling between the desired secure estimation objective and the
auxiliary detection and isolation decisions that need to be formed in
conjunction with the estimates. This paper establishes the fundamental
interplay among the decisions involved and characterizes the general decision
rules in closed-form for any desired estimation cost function. Furthermore, to
circumvent the computational complexity associated with growing parameter
dimension or attack complexity, a scalable estimation algorithm and its
attendant optimality guarantees are provided. The theory developed is applied
to secure parameter estimation in a sensor network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10617</identifier>
 <datestamp>2020-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10617</id><created>2018-12-26</created><updated>2019-06-11</updated><authors><author><keyname>Shetty</keyname><forenames>Gaurav N.</forenames></author><author><keyname>Slavakis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Bose</keyname><forenames>Abhishek</forenames></author><author><keyname>Nakarmi</keyname><forenames>Ukash</forenames></author><author><keyname>Scutari</keyname><forenames>Gesualdo</forenames></author><author><keyname>Ying</keyname><forenames>Leslie</forenames></author></authors><title>Bi-Linear Modeling of Data Manifolds for Dynamic-MRI Recovery</title><categories>eess.IV cs.LG stat.ML</categories><doi>10.1109/TMI.2019.2934125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper puts forth a novel bi-linear modeling framework for data recovery
via manifold-learning and sparse-approximation arguments and considers its
application to dynamic magnetic-resonance imaging (dMRI). Each temporal-domain
MR image is viewed as a point that lies onto or close to a smooth manifold, and
landmark points are identified to describe the point cloud concisely. To
facilitate computations, a dimensionality reduction module generates
low-dimensional/compressed renditions of the landmark points. Recovery of the
high-fidelity MRI data is realized by solving a non-convex minimization task
for the linear decompression operator and those affine combinations of landmark
points which locally approximate the latent manifold geometry. An algorithm
with guaranteed convergence to stationary solutions of the non-convex
minimization task is also provided. The aforementioned framework exploits the
underlying spatio-temporal patterns and geometry of the acquired data without
any prior training on external data or information. Extensive numerical results
on simulated as well as real cardiac-cine and perfusion MRI data illustrate
noteworthy improvements of the advocated machine-learning framework over
state-of-the-art reconstruction techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10637</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10637</id><created>2018-12-27</created><authors><author><keyname>Wang</keyname><forenames>Deqing</forenames></author><author><keyname>Cong</keyname><forenames>Fengyu</forenames></author><author><keyname>Ristaniemi</keyname><forenames>Tapani</forenames></author></authors><title>Sparse Nonnegative CANDECOMP/PARAFAC Decomposition in Block Coordinate
  Descent Framework: A Comparison Study</title><categories>stat.ML cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonnegative CANDECOMP/PARAFAC (NCP) decomposition is an important tool to
process nonnegative tensor. Sometimes, additional sparse regularization is
needed to extract meaningful nonnegative and sparse components. Thus, an
optimization method for NCP that can impose sparsity efficiently is required.
In this paper, we construct NCP with sparse regularization (sparse NCP) by
l1-norm. Several popular optimization methods in block coordinate descent
framework are employed to solve the sparse NCP, all of which are deeply
analyzed with mathematical solutions. We compare these methods by experiments
on synthetic and real tensor data, both of which contain third-order and
fourth-order cases. After comparison, the methods that have fast computation
and high effectiveness to impose sparsity will be concluded. In addition, we
proposed an accelerated method to compute the objective function and relative
error of sparse NCP, which has significantly improved the computation of tensor
decomposition especially for higher-order tensor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10932</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10932</id><created>2018-12-28</created><updated>2019-10-15</updated><authors><author><keyname>Wu</keyname><forenames>Chong</forenames></author><author><keyname>Zhang</keyname><forenames>Le</forenames></author><author><keyname>Zhang</keyname><forenames>Houwang</forenames></author><author><keyname>Yan</keyname><forenames>Hong</forenames></author></authors><title>Superpixels using Fuzzy Simple Linear Iterative Clustering and Fast
  Precise Number Control</title><categories>eess.IV</categories><comments>9 pages, 21 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most superpixel methods are sensitive to noise. What's more, most of them
cannot control the superpixel number precisely. To solve these problems, in
this paper, we propose a robust superpixel method called fuzzy simple linear
iterative clustering (Fuzzy SLIC), which adopts a local spatial fuzzy C-means
clustering and dynamic fuzzy superpixels. We develop a fast and precise
superpixel number control algorithm called onion peeling (OP) algorithm. Fuzzy
SLIC is non-sensitive to most types of noise like Gaussian, salt and pepper,
and multiplicative noise. With the OP algorithm, it can control the superpixel
number precisely without losing much computational efficiency. At the same
time, it outperforms state-of-the-art methods in generating similar superpixel
segmentation. In the validation experiments, we tested Fuzzy SLIC and Fuzzy
SLICNC (using OP algorithm). We compared them with SLIC, LSC, and SNIC on the
BSD500 and MSRC benchmarks. The experiment results show that our methods
outperform state-of-the-art techniques in both noise-free and noisy
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.10944</identifier>
 <datestamp>2019-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.10944</id><created>2018-12-28</created><updated>2019-01-08</updated><authors><author><keyname>Wei</keyname><forenames>Peng</forenames></author><author><keyname>Xiao</keyname><forenames>Yue</forenames></author><author><keyname>Dan</keyname><forenames>Lilin</forenames></author></authors><title>N-continuous Aided GFDM Signaling</title><categories>eess.SP cs.IT math.IT</categories><comments>19 pages, 9 figures, 1 tables. arXiv admin note: text overlap with
  arXiv:1608.00661</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An N-continuous-based generalized frequency division multiplexing (GFDM)
transceiver architecture is investigated, which operates with the aid of
time-domain N-continuous orthogonal frequency devision multiplexing
(TD-NC-OFDM), hence called time-domain N-continuous GFDM (TD-NC-GFDM). More
specifically, the basis signals conceived allow us to attain compact spectrum
as an explicit benefit of sidelobe suppression, which constitute the smooth
signal capable of eliminating the discontinuities imposed by the cyclic shift
GFDM filters and their high-order derivatives. The proposed N-continuous GFDM
signaling has relatively low interference through evaluating the
signal-to-interference ratio (SIR) that significantly decreases upon increasing
the number of GFDM subsymbols. Furthermore, a signal recovery algorithm for
reception is adopted by constructing a decoding matrix for eliminating the
interference caused by the smooth signal, which exhibits an explicit error
performance improvement compared to TD-NC-OFDM. It is demonstrated that
N-continuous GFDM outperforms TD-NC-OFDM in terms of sidelobe suppression,
while achieving small BER performance degradation with a small roll-off filter
compared to original OFDM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11006</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11006</id><created>2018-12-17</created><authors><author><keyname>Rubin</keyname><forenames>Moran</forenames></author><author><keyname>Stein</keyname><forenames>Omer</forenames></author><author><keyname>Turko</keyname><forenames>Nir A.</forenames></author><author><keyname>Nygate</keyname><forenames>Yoav</forenames></author><author><keyname>Roitshtain</keyname><forenames>Darina</forenames></author><author><keyname>Karako</keyname><forenames>Lidor</forenames></author><author><keyname>Barnea</keyname><forenames>Itay</forenames></author><author><keyname>Giryes</keyname><forenames>Raja</forenames></author><author><keyname>Shaked</keyname><forenames>Natan T.</forenames></author></authors><title>TOP-GAN: Label-Free Cancer Cell Classification Using Deep Learning with
  a Small Training Set</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new deep learning approach for medical imaging that copes with
the problem of a small training set, the main bottleneck of deep learning, and
apply it for classification of healthy and cancer cells acquired by
quantitative phase imaging. The proposed method, called transferring of
pre-trained generative adversarial network (TOP-GAN), is a hybridization
between transfer learning and generative adversarial networks (GANs). Healthy
cells and cancer cells of different metastatic potential have been imaged by
low-coherence off-axis holography. After the acquisition, the optical path
delay maps of the cells have been extracted and directly used as an input to
the deep networks. In order to cope with the small number of classified images,
we have used GANs to train a large number of unclassified images from another
cell type (sperm cells). After this preliminary training, and after
transforming the last layer of the network with new ones, we have designed an
automatic classifier for the correct cell type (healthy/primary
cancer/metastatic cancer) with 90-99% accuracy, although small training sets of
down to several images have been used. These results are better in comparison
to other classic methods that aim at coping with the same problem of a small
training set. We believe that our approach makes the combination of holographic
microscopy and deep learning networks more accessible to the medical field by
enabling a rapid, automatic and accurate classification in stain-free imaging
flow cytometry. Furthermore, our approach is expected to be applicable to many
other medical image classification tasks, suffering from a small training set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11029</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11029</id><created>2018-12-28</created><authors><author><keyname>Wang</keyname><forenames>Fei</forenames></author><author><keyname>Lin</keyname><forenames>Shujin</forenames></author><author><keyname>Li</keyname><forenames>Hanhui</forenames></author><author><keyname>Wu</keyname><forenames>Hefeng</forenames></author><author><keyname>Jiang</keyname><forenames>Junkun</forenames></author><author><keyname>Wang</keyname><forenames>Ruomei</forenames></author><author><keyname>Luo</keyname><forenames>Xiaonan</forenames></author></authors><title>Multi-column Point-CNN for Sketch Segmentation</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional sketch segmentation methods mainly rely on handcrafted features
and complicate models, and their performance is far from satisfactory due to
the abstract representation of sketches. Recent success of Deep Neural Networks
(DNNs) in related tasks suggests DNNs could be a practical solution for this
problem, yet the suitable datasets for learning and evaluating DNNs are
limited. To this end, we introduce SketchSeg, a large dataset consisting of
10,000 pixel-wisely labeled sketches.Besides, due to the lack of colors and
textures in sketches, conventional DNNs learned on natural images are not
optimal for tackling our problem.Therefore, we further propose the Multi-column
Point-CNN (MCPNet), which (1) directly takes sampled points as its input to
reduce computational costs, and (2) adopts multiple columns with different
filter sizes to better capture the structures of sketches. Extensive
experiments validate that the MCPNet is superior to conventional DNNs like FCN.
The SketchSeg dataset is publicly available on
https://drive.google.com/open?id=1OpCBvkInhxvfAHuVs-spDEppb8iXFC3C.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11030</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11030</id><created>2018-12-25</created><authors><author><keyname>Vargas</keyname><forenames>Viviana Lorena</forenames></author><author><keyname>Pesco</keyname><forenames>Sinesio</forenames></author></authors><title>Vector Field-based Simulation of Tree-Like Non-Stationary Geostatistical
  Models</title><categories>eess.IV stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a new non-stationary multiple point geostatistical algorithm
called vector field-based simulation is proposed. The motivation behind this
work is the modeling of a certain structures that exhibit directional features
with branching, like a tree, as can be frequently found in fan deltas or
turbidity channels. From an image construction approach, the main idea of this
work is that instead of using the training image as a source of patterns, it
may be used to create a new object called a training vector field (TVF). This
object assigns a vector to each point in the reservoir within the training
image. The vector represents the direction in which the reservoir develops. The
TVF is defined as an approximation of the tangent line at each point in the
contour curve of the reservoir. This vector field has a great potential to
better capture the non-stationary nature of the training image since the vector
not only gives information about the point where it was defined but naturally
captures the local trend near that point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11031</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11031</id><created>2018-12-14</created><authors><author><keyname>Yetis</keyname><forenames>Cenk M.</forenames></author><author><keyname>Chang</keyname><forenames>Ronald Y.</forenames></author></authors><title>Distributed Multi-Stream Beamforming in MIMO Multi-Relay Interference
  Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>18 pages, 10 figures, and 4 tables. This paper is to appear in IEEE
  Access</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, multi-stream transmission in interference networks aided by
multiple amplify-and-forward (AF) relays in the presence of direct links is
considered. The objective is to minimize the sum power of transmitters and
relays by beamforming optimization under the stream
signal-to-interference-plus-noise-ratio (SINR) constraints. For transmit
beamforming optimization, the problem is a well-known non-convex quadratically
constrained quadratic program (QCQP) that is NP-hard to solve. After
semi-definite relaxation (SDR), the problem can be optimally solved via
alternating direction method of multipliers (ADMM) algorithm for distributed
implementation. Analytical and extensive numerical analyses demonstrate that
the proposed ADMM solution converges to the optimal centralized solution. The
convergence rate, computational complexity, and message exchange load of the
proposed algorithm outperforms the existing solutions. Furthermore, by SINR
approximation at the relay side, distributed joint transmit and relay
beamforming optimization is also proposed that further improves the total power
saving at the cost of increased complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11034</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11034</id><created>2018-12-17</created><authors><author><keyname>Rashno</keyname><forenames>Elyas</forenames></author><author><keyname>Minaei-Bidgolia</keyname><forenames>Behrouz</forenames></author><author><keyname>Guo</keyname><forenames>Yanhui</forenames></author></authors><title>An effective clustering method based on data indeterminacy in
  neutrosophic set domain</title><categories>eess.IV</categories><comments>Submitted to: Engineering Applications of Artificial Intelligence,
  Elsevier</comments><doi>10.1016/j.engappai.2019.103411</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a new clustering algorithm is proposed based on neutrosophic
set (NS) theory. The main contribution is to use NS to handle boundary and
outlier points as challenging points of clustering methods. In the first step,
a new definition of data indeterminacy (indeterminacy set) is proposed in NS
domain based on density properties of data. Lower indeterminacy is assigned to
data points in dense regions and vice versa. In the second step, indeterminacy
set is presented for a proposed cost function in NS domain by considering a set
of main clusters and a noisy cluster. In the proposed cost function, two
conditions based on distance from cluster centers and value of indeterminacy,
are considered for each data point. In the third step, the proposed cost
function is minimized by gradient descend methods. Data points are clustered
based on their membership degrees. Outlier points are assigned to noise
cluster; and boundary points are assigned to main clusters with almost same
membership degrees. To show the effectiveness of the proposed method, three
types of datasets including diamond, UCI and image datasets are used. Results
demonstrate that the proposed cost function handles boundary and outlier points
with more accurate membership degrees and outperforms existing state of the art
clustering methods in all datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11045</identifier>
 <datestamp>2019-08-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11045</id><created>2018-12-19</created><authors><author><keyname>Rashno</keyname><forenames>Elyas</forenames></author><author><keyname>Norouzi</keyname><forenames>Sanaz Saki</forenames></author><author><keyname>Minaei-bidgoli</keyname><forenames>Behrouz</forenames></author><author><keyname>Guo</keyname><forenames>Yanhui</forenames></author></authors><title>Certainty of outlier and boundary points processing in data mining</title><categories>eess.SP eess.IV</categories><comments>Conference Paper, 6 pages</comments><doi>10.1109/IranianCEE.2019.8786544</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data certainty is one of the issues in the real-world applications which is
caused by unwanted noise in data. Recently, more attentions have been paid to
overcome this problem. We proposed a new method based on neutrosophic set (NS)
theory to detect boundary and outlier points as challenging points in
clustering methods. Generally, firstly, a certainty value is assigned to data
points based on the proposed definition in NS. Then, certainty set is presented
for the proposed cost function in NS domain by considering a set of main
clusters and noise cluster. After that, the proposed cost function is minimized
by gradient descent method. Data points are clustered based on their membership
degrees. Outlier points are assigned to noise cluster and boundary points are
assigned to main clusters with almost same membership degrees. To show the
effectiveness of the proposed method, two types of datasets including 3
datasets in Scatter type and 4 datasets in UCI type are used. Results
demonstrate that the proposed cost function handles boundary and outlier points
with more accurate membership degrees and outperforms existing state of the art
clustering methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11054</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11054</id><created>2018-12-23</created><authors><author><keyname>Wu</keyname><forenames>Hejun</forenames></author><author><keyname>Ding</keyname><forenames>Ao</forenames></author><author><keyname>Li</keyname><forenames>Lvzhou</forenames></author></authors><title>Triangle Extension: Efficient Localizability Detection in Wireless
  Sensor Networks</title><categories>eess.SP</categories><comments>14 pages, 23 figures, 9 tables</comments><msc-class>68T40</msc-class><doi>10.1109/TWC.2017.2748563</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining whether nodes can be localized, called localizability detection,
is essential for wireless sensor networks (WSNs). This step is required for
localizing nodes, achieving low-cost deployments, and identifying prerequisites
in location-based applications. Centralized graph algorithms are inapplicable
to a resource-limited WSN because of their high computation and communication
costs, whereas distributed approaches may miss a large number of theoretically
localizable nodes in a resource-limited WSN. In this paper, we propose an
efficient and effective distributed approach in order to address this problem.
Furthermore, we prove the correctness of our algorithm and analyze the reasons
our algorithm can find more localizable nodes while requiring fewer known
location nodes than existing algorithms, under the same network configurations.
The time complexity of our algorithm is linear with respect to the number of
nodes in a network. We conduct both simulations and real-world WSN experiments
to evaluate our algorithm under various network settings. The results show that
our algorithm significantly outperforms the existing algorithms in terms of
both the latency and the accuracy of localizability detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11062</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11062</id><created>2018-12-22</created><updated>2019-09-20</updated><authors><author><keyname>Battistelli</keyname><forenames>Giorgio</forenames></author><author><keyname>Chisci</keyname><forenames>Luigi</forenames></author><author><keyname>Forti</keyname><forenames>Nicola</forenames></author><author><keyname>Gherardini</keyname><forenames>Stefano</forenames></author></authors><title>MAP moving horizon estimation for threshold measurements with
  application to field monitoring</title><categories>eess.SY cs.SY</categories><comments>16 pages, 8 figures, v2: close to the published version. arXiv admin
  note: text overlap with arXiv:1804.02167</comments><journal-ref>Int. J. Adapt. Control Signal Process., 1-16 (2019)</journal-ref><doi>10.1002/acs.3049</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The paper deals with state estimation of a spatially distributed system given
noisy measurements from pointwise-in-time-and-space threshold sensors spread
over the spatial domain of interest. A Maximum A posteriori Probability (MAP)
approach is undertaken and a Moving Horizon (MH) approximation of the MAP
cost-function is adopted. It is proved that, under system linearity and
log-concavity of the noise probability density functions, the proposed MH-MAP
state estimator amounts to the solution, at each sampling interval, of a convex
optimization problem. Moreover, a suitable centralized solution for large-scale
systems is proposed with a substantial decrease of the computational
complexity. The latter algorithm is shown to be feasible for the state
estimation of spatially-dependent dynamic fields described by Partial
Differential Equations (PDE) via the use of the Finite Element (FE) spatial
discretization method. A simulation case-study concerning estimation of a
diffusion field is presented in order to demonstrate the effectiveness of the
proposed approach. Quite remarkably, the numerical tests exhibit a
noise-assisted behavior of the proposed approach in that the estimation
accuracy results optimal in the presence of measurement noise with non-null
variance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11065</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11065</id><created>2018-12-22</created><authors><author><keyname>Shamshad</keyname><forenames>Fahad</forenames></author><author><keyname>Abbas</keyname><forenames>Farwa</forenames></author><author><keyname>Ahmed</keyname><forenames>Ali</forenames></author></authors><title>Deep Ptych: Subsampled Fourier Ptychography using Generative Priors</title><categories>cs.LG eess.IV eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel framework to regularize the highly ill-posed and
non-linear Fourier ptychography problem using generative models. We demonstrate
experimentally that our proposed algorithm, Deep Ptych, outperforms the
existing Fourier ptychography techniques, in terms of quality of reconstruction
and robustness against noise, using far fewer samples. We further modify the
proposed approach to allow the generative model to explore solutions outside
the range, leading to improved performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11071</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11071</id><created>2018-12-24</created><authors><author><keyname>Tabares-Ospina</keyname><forenames>H&#xe9;ctor A.</forenames></author><author><keyname>Candelo-Becerra</keyname><forenames>John E.</forenames></author></authors><title>Geometrical representation of real and reactive powers of load demand by
  orbit diagrams in the Mandelbrot set</title><categories>eess.SP math.DS math.GN</categories><comments>18 pages, 9 figures</comments><journal-ref>Discrete and Continuous Dynamical Systems - Series B, 2019</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents the geometrical representation of the load demand by
using orbits diagrams in the Mandelbrot set, to identify changing behaviors
during a day period of the real and reactive powers. To perform this, different
power combinations were used to represent the fractal diagrams with an
algorithm that considers the mathematical model of Mandelbrot set and orbits
diagrams. A qualitative analysis of the orbits is performed to identify the
fractal graphic patterns with respect to the real and reactive power
consumptions. The results show repetitive graphic patterns in the fractal space
of the power consumption during the day, which help represent the consumption
behavior on a daily load demand curve. The orbit diagrams save form and
structure relations during the daily behavior of the power consumption. This
work shows a different method of evaluating load demand behavior by using orbit
diagrams as a potential tool that will lead to identify load behavior, useful
in operational decisions and power system planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11078</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11078</id><created>2018-12-23</created><authors><author><keyname>Tabares-Ospina</keyname><forenames>H&#xe9;ctor A.</forenames></author><author><keyname>Candelo-Becerra</keyname><forenames>John E.</forenames></author></authors><title>Topological properties of fractal Julia sets related to the signs and
  magnitudes of the real and reactive powers</title><categories>eess.SP math.DS math.GN</categories><comments>18 pages, 10 figures. arXiv admin note: text overlap with
  arXiv:1812.11071</comments><journal-ref>Fractals, ISSN 0218-348X,
  https://www.worldscientific.com/worldscinet/fractals, 2018</journal-ref><doi>10.1142/S0218348X1950066X</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In AC electrical systems, the power depends on the real power (P) due to
resistive elements and the reactive power (Q) due to the inductive and
capacitive elements, which are commonly studied by using phasor and scalar
methods. Thus, this paper focuses on applying the fractal Julia sets to observe
the topological properties related to the signs and magnitudes of the real and
reactive powers consumed or supplied by an electrical circuit. To perform this,
different power combinations were used to represent the fractal diagrams with
an algorithm that considers the mathematical model of Julia sets. The study
considers three type of loads: the first study considers the change of real
power when the reactive power is fixed; the second study deals with the change
of the reactive power when the real power is fixed; and finally, the third
study contemplates that both real and reactive powers change. Furthermore, the
fractal diagrams of the power in the four quadrants of the complex plane are
studied to identify the topological properties that each sign and magnitude
represent. A qualitative analysis of the diagrams helps to identify that the
complex power loads present some fractal graphic patterns, with respect to the
signs and magnitudes considered in the different quadrants of the complex
planes. The diagrams represented in the complex planes save a relation in the
forms and structure with other points studied, concluding that the power is
related to other figures in other quadrants. Thus, this result allows a new
study of the behavior of the power in an electrical circuit, showing a clear
relation of the different fractal diagrams that the Julia sets obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11081</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11081</id><created>2018-12-24</created><authors><author><keyname>Yang</keyname><forenames>Fan</forenames></author><author><keyname>Zhu</keyname><forenames>Yixiao</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Ruan</keyname><forenames>Xiaoke</forenames></author><author><keyname>Li</keyname><forenames>Yanping</forenames></author><author><keyname>Zhang</keyname><forenames>Fan</forenames></author></authors><title>Up to 168-Gb/s PAM-4 direct detection transmission with silicon
  travelling wave Mach-Zehnder modulator</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on a silicon travelling wave Mach-Zehnder modulator, we demonstrate
record 168Gb/s (84Gbaud) and 160Gb/s (80Gbaud) PAM-4 direct detection
transmission over 1km and 2km SSMF, respectively, with bit error rates below
20% HD-FEC threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11109</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11109</id><created>2018-12-28</created><authors><author><keyname>Wang</keyname><forenames>Zhen</forenames></author><author><keyname>Hegazy</keyname><forenames>Tamir</forenames></author><author><keyname>Long</keyname><forenames>Zhiling</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Noise-robust detection and tracking of salt domes in postmigrated
  volumes using texture, tensors, and subspace learning</title><categories>eess.IV</categories><journal-ref>Geophysics, vol. 80, no. 6, pp. WD101-WD116, Sep. 2015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The identification of salt dome boundaries in migrated seismic data volumes
is important for locating petroleum reservoirs. The presence of noise in the
data makes computer-aided salt dome interpretation even more challenging. In
this paper, we develop noise-robust algorithms that can label boundaries of
salt domes both effectively and efficiently. Our research is twofold. First, we
utilize a texture-based gradient to accomplish salt dome detection. We show
that by employing a dissimilarity measure based on two-dimensional (2D)
discrete Fourier transform (DFT), the algorithm is capable of efficiently
detecting salt dome boundaries with accuracy. At the same time, our analysis
shows that the proposed algorithm is robust to noise. Once the detection is
performed for an initial 2D seismic section, we propose to track the initial
boundaries through the data volume to accomplish an efficient labeling process
by avoiding parameters tuning that would have been necessary if detection had
been performed for every seismic section. The tracking process involves a
tensor-based subspace learning process, in which we build texture tensors using
patches from different seismic sections. To accommodate noise components with
various levels in a texture tensor, we employ noise-adjusted principal
component analysis (NA-PCA), so that principal components corresponding to
greater signal-to-noise ratio values may be selected for tracking. We validate
our detection and tracking algorithms through experiments using seismic
datasets acquired from Netherland offshore F3 block in the North Sea with very
encouraging results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11183</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11183</id><created>2018-12-28</created><authors><author><keyname>Wen</keyname><forenames>Junhao</forenames><affiliation>for the Alzheimers Disease Neuroimaging Initiative</affiliation></author><author><keyname>Samper-Gonzalez</keyname><forenames>Jorge</forenames><affiliation>for the Alzheimers Disease Neuroimaging Initiative</affiliation></author><author><keyname>Bottani</keyname><forenames>Simona</forenames><affiliation>for the Alzheimers Disease Neuroimaging Initiative</affiliation></author><author><keyname>Routier</keyname><forenames>Alexandre</forenames><affiliation>for the Alzheimers Disease Neuroimaging Initiative</affiliation></author><author><keyname>Burgos</keyname><forenames>Ninon</forenames><affiliation>for the Alzheimers Disease Neuroimaging Initiative</affiliation></author><author><keyname>Jacquemont</keyname><forenames>Thomas</forenames><affiliation>for the Alzheimers Disease Neuroimaging Initiative</affiliation></author><author><keyname>Fontanella</keyname><forenames>Sabrina</forenames><affiliation>for the Alzheimers Disease Neuroimaging Initiative</affiliation></author><author><keyname>Durrleman</keyname><forenames>Stanley</forenames><affiliation>for the Alzheimers Disease Neuroimaging Initiative</affiliation></author><author><keyname>Epelbaum</keyname><forenames>Stephane</forenames><affiliation>for the Alzheimers Disease Neuroimaging Initiative</affiliation></author><author><keyname>Bertrand</keyname><forenames>Anne</forenames><affiliation>for the Alzheimers Disease Neuroimaging Initiative</affiliation></author><author><keyname>Colliot</keyname><forenames>Olivier</forenames><affiliation>for the Alzheimers Disease Neuroimaging Initiative</affiliation></author></authors><title>Reproducible evaluation of diffusion MRI features for automatic
  classification of patients with Alzheimers disease</title><categories>q-bio.QM cs.LG eess.IV stat.ML</categories><comments>51 pages, 5 figure and 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diffusion MRI is the modality of choice to study alterations of white matter.
In the past years, various works have used diffusion MRI for automatic
classification of Alzheimers disease. However, the performances obtained with
different approaches are difficult to compare because of variations in
components such as input data, participant selection, image preprocessing,
feature extraction, feature selection (FS) and cross-validation (CV) procedure.
Moreover, these studies are also difficult to reproduce because these different
components are not readily available. In a previous work (Samper-Gonzalez et
al. 2018), we proposed an open-source framework for the reproducible evaluation
of AD classification from T1-weighted (T1w) MRI and PET data. In the present
paper, we extend this framework to diffusion MRI data. The framework comprises:
tools to automatically convert ADNI data into the BIDS standard, pipelines for
image preprocessing and feature extraction, baseline classifiers and a rigorous
CV procedure. We demonstrate the use of the framework through assessing the
influence of diffusion tensor imaging (DTI) metrics (fractional anisotropy -
FA, mean diffusivity - MD), feature types, imaging modalities (diffusion MRI or
T1w MRI), data imbalance and FS bias. First, voxel-wise features generally gave
better performances than regional features. Secondly, FA and MD provided
comparable results for voxel-wise features. Thirdly, T1w MRI performed better
than diffusion MRI. Fourthly, we demonstrated that using non-nested validation
of FS leads to unreliable and over-optimistic results. All the code is publicly
available: general-purpose tools have been integrated into the Clinica software
(www.clinica.run) and the paper-specific code is available at:
https://gitlab.icm-institute.org/aramislab/AD-ML.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11214</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11214</id><created>2018-12-28</created><updated>2019-06-01</updated><authors><author><keyname>Andreux</keyname><forenames>Mathieu</forenames></author><author><keyname>Angles</keyname><forenames>Tom&#xe1;s</forenames></author><author><keyname>Exarchakis</keyname><forenames>Georgios</forenames></author><author><keyname>Leonarduzzi</keyname><forenames>Roberto</forenames></author><author><keyname>Rochette</keyname><forenames>Gaspar</forenames></author><author><keyname>Thiry</keyname><forenames>Louis</forenames></author><author><keyname>Zarka</keyname><forenames>John</forenames></author><author><keyname>Mallat</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>And&#xe9;n</keyname><forenames>Joakim</forenames></author><author><keyname>Belilovsky</keyname><forenames>Eugene</forenames></author><author><keyname>Bruna</keyname><forenames>Joan</forenames></author><author><keyname>Lostanlen</keyname><forenames>Vincent</forenames></author><author><keyname>Hirn</keyname><forenames>Matthew J.</forenames></author><author><keyname>Oyallon</keyname><forenames>Edouard</forenames></author><author><keyname>Zhang</keyname><forenames>Sixin</forenames></author><author><keyname>Cella</keyname><forenames>Carmine</forenames></author><author><keyname>Eickenberg</keyname><forenames>Michael</forenames></author></authors><title>Kymatio: Scattering Transforms in Python</title><categories>cs.LG cs.CV cs.SD eess.AS stat.ML</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The wavelet scattering transform is an invariant signal representation
suitable for many signal processing and machine learning applications. We
present the Kymatio software package, an easy-to-use, high-performance Python
implementation of the scattering transform in 1D, 2D, and 3D that is compatible
with modern deep learning frameworks. All transforms may be executed on a GPU
(in addition to CPU), offering a considerable speed up over CPU
implementations. The package also has a small memory footprint, resulting
inefficient memory usage. The source code, documentation, and examples are
available undera BSD license at https://www.kymat.io/
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11233</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11233</id><created>2018-12-28</created><authors><author><keyname>Kaymak</keyname><forenames>Yagiz</forenames></author><author><keyname>Fathi-Kazerooni</keyname><forenames>Sina</forenames></author><author><keyname>Rojas-Cessa</keyname><forenames>Roberto</forenames></author><author><keyname>Feng</keyname><forenames>JiangHua</forenames></author><author><keyname>Ansari</keyname><forenames>Nirwan</forenames></author><author><keyname>Zhou</keyname><forenames>MengChu</forenames></author><author><keyname>Zhang</keyname><forenames>Tairan</forenames></author></authors><title>Beam with Adaptive Divergence Angle in Free-Space Optical Communications
  for High-Speed Trains</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an adaptive beam that adapts its divergence angle
according to the receiver aperture diameter and the communication distance to
improve the received power and ease the alignment between the communicating
optical transceivers in a free-space optical communications (FSOC) system for
high-speed trains (HSTs). We compare the received power, signal-to-noise ratio,
bit error rate, and the maximum communication distance of the proposed adaptive
beam with a beam that uses a fixed divergence angle of 1 mrad. The proposed
adaptive beam yields a higher received power with an increase of 33 dB in
average over the fixed-divergence beam under varying visibility conditions and
distance. Moreover, the proposed adaptive divergence angle extends the
communication distance of a FSOC system for HSTs to about three times under
different visibility conditions as compared to a fixed divergence beam. We also
propose a new ground transceiver placement that places the ground transceivers
of a FSOC system for HSTs on gantries placed above the train passage instead of
placing them next to track. The proposed transceiver placement provides a
received-power increase of 3.8 dB in average over the conventional placement of
ground-station transceivers next to the track.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11266</identifier>
 <datestamp>2020-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11266</id><created>2018-12-28</created><updated>2020-01-13</updated><authors><author><keyname>Bian</keyname><forenames>Desong</forenames></author><author><keyname>Yu</keyname><forenames>Zhe</forenames></author><author><keyname>Shi</keyname><forenames>Di</forenames></author><author><keyname>Diao</keyname><forenames>Ruisheng</forenames></author><author><keyname>Wang</keyname><forenames>Zhiwei</forenames></author></authors><title>Online Low Frequency Oscillation Detection and Analysis System with an
  Ensemble Filter</title><categories>eess.SP</categories><comments>9 pages, 11 figures. This work has been accepted by CSEE Journal of
  Power and Energy Systems in 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread deployment of phasor measurement unit (PMU) overpower systems
makes it possible to monitor and analyze grid dynamics in real-time.
Low-frequency oscillation is harmful to power system equipment and operation,
and in the worst-case scenario may lead to cascading failures. Therefore, it is
critical to detect and identify them as soon as they appear. This paper
presents an online low-frequency oscillation detection and analysis (LFODA)
system, which has the merit of significantly reducing the chance of false alarm
via a voting schema and a time-serial filter. A novel algorithm based on
density-based spatial clustering of applications with noise (DBSCAN) is
proposed to classify oscillation modes as well as to group their corresponding
buses/monitoring sites. Performance of the LFODA system is evaluated through
experiments using both simulated and real-world PMU data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11292</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11292</id><created>2018-12-29</created><updated>2019-09-26</updated><authors><author><keyname>Li</keyname><forenames>Lin</forenames></author><author><keyname>Cai</keyname><forenames>Haiyan</forenames></author><author><keyname>Han</keyname><forenames>Hongxia</forenames></author><author><keyname>Jiang</keyname><forenames>Qingtang</forenames></author><author><keyname>Ji</keyname><forenames>Hongbing</forenames></author></authors><title>Adaptive Short-time Fourier Transform and Synchrosqueezing Transform for
  Non-stationary Signal Separation</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The synchrosqueezing transform, a kind of reassignment method, aims to
sharpen the time-frequency representation and to separate the components of a
multicomponent non-stationary signal. In this paper, we consider the short-time
Fourier transform (STFT) with a time-varying parameter, called the adaptive
STFT. Based on the local approximation of linear frequency modulation mode, we
analyze the well-separated condition of non-stationary multicomponent signals
using the adaptive STFT with the Gaussian window function. We propose the
STFT-based synchrosqueezing transform (FSST) with a time-varying parameter,
named the adaptive FSST, to enhance the time-frequency concentration and
resolution of a multicomponent signal, and to separate its components more
accurately. In addition, we also propose the 2nd-order adaptive FSST to further
improve the adaptive FSST for the non-stationary signals with fast-varying
frequencies. Furthermore, we present a localized optimization algorithm based
on our well-separated condition to estimate the time-varying parameter
adaptively and automatically. Simulation results on synthetic signals and the
bat echolocation signal are provided to demonstrate the effectiveness and
robustness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11356</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11356</id><created>2018-12-29</created><updated>2019-08-12</updated><authors><author><keyname>Feng</keyname><forenames>Donghan</forenames></author><author><keyname>Wu</keyname><forenames>Fan</forenames></author><author><keyname>Zhou</keyname><forenames>Yun</forenames></author><author><keyname>Rahman</keyname><forenames>Usama</forenames></author><author><keyname>Zhao</keyname><forenames>Xiaojin</forenames></author><author><keyname>Fang</keyname><forenames>Chen</forenames></author></authors><title>A multi-agent based rolling optimization method for restoration
  scheduling of the electrical distribution system with distributed generation</title><categories>eess.SP</categories><comments>In Section 4, the results of restoration shown in Fig. 7 to Fig. 9
  and Table 4 are incorrect. The restoration results shown in Fig. 7 and the
  corresponding detailed data shown in Table 4 are exactly the results at 35
  min. As a result, the following rolling process has an incorrect initial
  condition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resiliency against major disasters is a most essential characteristic of the
future electrical distribution system (EDS). A multi-agent based rolling
optimization method for the EDS restoration scheduling is proposed in this
paper. When blackout occurs, considering the risk of loosing the centralized
authority due to the failure of core communication network, the agents
available after disaster or cyber attack identify the communication connected
parts (CCPs) in the EDS with distributed communication. A multi-time intervals
optimization model is formulated for the restoration scheduling in a CCP. A
rolling optimization process for the entire EDS restoration is proposed. At the
scheduling/rescheduling moments in the rolling process, the CCPs in the EDS are
re-identified and restoration schedules for the CCPs are renewed. A modified
IEEE 123 bus EDS is utilized to demonstrate the effectiveness of the proposed
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11364</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11364</id><created>2018-12-29</created><updated>2019-09-26</updated><authors><author><keyname>Li</keyname><forenames>Lin</forenames></author><author><keyname>Cai</keyname><forenames>Haiyan</forenames></author><author><keyname>Jiang</keyname><forenames>Qingtang</forenames></author></authors><title>Adaptive Synchrosqueezing Transform with a Time-Varying Parameter for
  Non-stationary Signal Separation</title><categories>eess.SP cs.NA math.NA</categories><comments>arXiv admin note: text overlap with arXiv:1812.11292</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The continuous wavelet transform (CWT) is a linear time-frequency
representation and a powerful tool for analyzing non-stationary signals. The
synchrosqueezing transform (SST) is a special type of the reassignment method
which not only enhances the energy concentration of CWT in the time-frequency
plane, but also separates the components of multicomponent signals. The &quot;bump
wavelet&quot; and Morlet's wavelet are commonly used continuous wavelets for the
wavelet-based SST. There is a parameter in these wavelets which controls the
widths of the time-frequency localization window. In most literature on SST,
this parameter is a fixed positive constant. In this paper, we consider the CWT
with a time-varying parameter (called the adaptive CWT) and the corresponding
SST (called the adaptive SST) for instantaneous frequency estimation and
multicomponent signal separation. We also introduce the 2nd-order adaptive SST.
We analyze the separation conditions for non-stationary multicomponent signals
with the local approximation of linear frequency modulation mode. We derive
well-separated conditions of a multicomponent signal based on the adaptive CWT.
We propose methods to select the time-varying parameter so that the
corresponding adaptive SSTs of the components of a multicomponent signal have
sharp representations and are well-separated, and hence the components can be
recovered more accurately. We provide comparison experimental results to
demonstrate the efficiency and robustness of the proposed adaptive CWT and
adaptive SST in separating components of multicomponent signals with fast
varying frequencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11368</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11368</id><created>2018-12-29</created><authors><author><keyname>Wei</keyname><forenames>Yiheng</forenames></author><author><keyname>Yin</keyname><forenames>Weidi</forenames></author><author><keyname>Chen</keyname><forenames>Yuquan</forenames></author><author><keyname>Wang</keyname><forenames>Yong</forenames></author></authors><title>Description and Realization for a Class of Irrational Transfer Functions</title><categories>eess.SP math.DS</categories><comments>9 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an exact description scheme which is an extension to the
well-established frequency distributed model method for a class of irrational
transfer functions. The method relaxes the constraints on the zero initial
instant by introducing the generalized Laplace transform, which provides a wide
range of applicability. With the discretization of continuous frequency band,
the infinite dimensional equivalent model is approximated by a finite
dimensional one. Finally, a fair comparison to the well-known Charef method is
presented, demonstrating its added value with respect to the state of art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11455</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11455</id><created>2018-12-29</created><authors><author><keyname>Xiaobo</keyname><forenames>Jiang</forenames></author><author><keyname>Fang</keyname><forenames>Zhang</forenames></author><author><keyname>Zhen</keyname><forenames>Zeng</forenames></author></authors><title>High-performance Decoder for Convolutional Code with Deep Neural Network</title><categories>eess.SP</categories><comments>6pages,10figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of deep neural network for decoding error control code will encounter
two problems, namely, the high-precision requirements of the error control code
and the complexity of the neural network due to the long code. In this paper, a
deep neural network decoder is proposed to solve the decoding problem of long
code by using the nature of convolutional code window decoding. A deep neural
network decoder is utilized as a weak classifier, and an integrated decoder is
proposed to improve the decoding performance greatly. The Viterbi decoder is
improved by approximately 2 db at a bit error rate of level 5. Both decoder
methods proposed in this paper can be decoded in parallel and are suitable for
high-bit-rate applications. This study reveals that the accuracy of neural
networks can reach level 8 more.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11539</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11539</id><created>2018-12-30</created><updated>2019-05-09</updated><authors><author><keyname>Teganya</keyname><forenames>Yves</forenames></author><author><keyname>Romero</keyname><forenames>Daniel</forenames></author><author><keyname>Ramos</keyname><forenames>Luis Miguel Lopez</forenames></author><author><keyname>Beferull-Lozano</keyname><forenames>Baltasar</forenames></author></authors><title>Location-free Spectrum Cartography</title><categories>eess.SP</categories><comments>14 pages, 12 figures, 1 table. Submitted to IEEE Transactions on
  Signal Processing</comments><doi>10.1109/TSP.2019.2923151</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum cartography constructs maps of metrics such as channel gain or
received signal power across a geographic area of interest using spatially
distributed sensor measurements. Applications of these maps include network
planning, interference coordination, power control, localization, and cognitive
radios to name a few. Since existing spectrum cartography techniques require
accurate estimates of the sensor locations, their performance is drastically
impaired by multipath affecting the positioning pilot signals, as occurs in
indoor or dense urban scenarios. To overcome such a limitation, this paper
introduces a novel paradigm for spectrum cartography, where estimation of
spectral maps relies on features of these positioning signals rather than on
location estimates. Specific learning algorithms are built upon this approach
and offer a markedly improved estimation performance than existing approaches
relying on localization, as demonstrated by simulation studies in indoor
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11544</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11544</id><created>2018-12-30</created><authors><author><keyname>Alsulami</keyname><forenames>Osama</forenames></author><author><keyname>Hussein</keyname><forenames>Ahmed Taha</forenames></author><author><keyname>Alresheedi</keyname><forenames>Mohammed T.</forenames></author><author><keyname>Elmirghani</keyname><forenames>Jaafar M. H.</forenames></author></authors><title>Optical Wireless Communication Systems, A Survey</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past few years, the demand for high data rate services has increased
dramatically. The congestion in the radio frequency (RF) spectrum (3 kHz ~ 300
GHz) is expected to limit the growth of future wireless systems unless new
parts of the spectrum are opened. Even with the use of advanced engineering,
such as signal processing and advanced modulation schemes, it will be very
challenging to meet the demands of the users in the next decades using the
existing carrier frequencies. On the other hand, there is a potential band of
the spectrum available that can provide tens of Gbps to Tbps for users in the
near future. Optical wireless communication (OWC) systems are among the
promising solutions to the bandwidth limitation problem faced by radio systems.
In this paper, we give a tutorial survey of the most significant issues in OWC
systems that operate at short ranges such as indoor systems. We consider the
challenging issues facing these systems such as (i) link design and system
requirements, (ii) transmitter structures, (iii) receiver structures, (iv)
challenges and possible techniques to mitigate the impairments in these
systems, (v) the main applications and (vi) open research issues. In indoor OWC
systems we describe channel modelling, mobility and dispersion mitigation
techniques. Infrared communication (IRC) and visible light communication (VLC)
are presented as potential implementation approaches for OWC systems and are
comprehensively discussed. Moreover, open research issues in OWC systems are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11675</identifier>
 <datestamp>2019-10-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11675</id><created>2018-12-30</created><updated>2019-10-17</updated><authors><author><keyname>Fan</keyname><forenames>Fenglei</forenames></author><author><keyname>Li</keyname><forenames>Mengzhou</forenames></author><author><keyname>Teng</keyname><forenames>Yueyang</forenames></author><author><keyname>Wang</keyname><forenames>Ge</forenames></author></authors><title>Soft-Autoencoder and Its Wavelet Shrinkage Interpretation</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, deep learning becomes the main focus of machine learning research
and has greatly impacted many fields. However, deep learning is criticized for
lack of interpretability. As a successful unsupervised model in deep learning,
the autoencoder embraces a wide spectrum of applications, yet it suffers from
the model opaqueness as well. In this paper, we propose a new type of
convolutional autoencoders, termed as Soft-Autoencoder (Soft-AE), in which the
activation functions of encoding layers are implemented with adaptable
soft-thresholding units while decoding layers are realized with linear units.
Consequently, Soft-AE can be naturally interpreted as a learned cascaded
wavelet shrinkage system. Our denoising experiments demonstrate that Soft-AE
not only is interpretable but also offers a competitive performance relative to
its counterparts. Furthermore, we propose a generalized linear unit (GeLU) and
its truncated variant (tGeLU) to allow autoencoder for more tasks from
denoising to deblurring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11750</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11750</id><created>2018-12-31</created><updated>2019-02-17</updated><authors><author><keyname>Yang</keyname><forenames>Kai</forenames></author><author><keyname>Jiang</keyname><forenames>Tao</forenames></author><author><keyname>Shi</keyname><forenames>Yuanming</forenames></author><author><keyname>Ding</keyname><forenames>Zhi</forenames></author></authors><title>Federated Learning via Over-the-Air Computation</title><categories>cs.LG cs.IT eess.SP math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stringent requirements for low-latency and privacy of the emerging
high-stake applications with intelligent devices such as drones and smart
vehicles make the cloud computing inapplicable in these scenarios. Instead,
edge machine learning becomes increasingly attractive for performing training
and inference directly at network edges without sending data to a centralized
data center. This stimulates a nascent field termed as federated learning for
training a machine learning model on computation, storage, energy and bandwidth
limited mobile devices in a distributed manner. To preserve data privacy and
address the issues of unbalanced and non-IID data points across different
devices, the federated averaging algorithm has been proposed for global model
aggregation by computing the weighted average of locally updated model at each
selected device. However, the limited communication bandwidth becomes the main
bottleneck for aggregating the locally computed updates. We thus propose a
novel over-the-air computation based approach for fast global model aggregation
via exploring the superposition property of a wireless multiple-access channel.
This is achieved by joint device selection and beamforming design, which is
modeled as a sparse and low-rank optimization problem to support efficient
algorithms design. To achieve this goal, we provide a
difference-of-convex-functions (DC) representation for the sparse and low-rank
function to enhance sparsity and accurately detect the fixed-rank constraint in
the procedure of device selection. A DC algorithm is further developed to solve
the resulting DC program with global convergence guarantees. The algorithmic
advantages and admirable performance of the proposed methodologies are
demonstrated through extensive numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11811</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11811</id><created>2018-12-31</created><authors><author><keyname>Kosmanos</keyname><forenames>Dimitrios</forenames></author><author><keyname>Argyriou</keyname><forenames>Antonios</forenames></author><author><keyname>Maglaras</keyname><forenames>Leandros</forenames></author></authors><title>Estimating the Relative Speed of RF Jammers in VANETs</title><categories>cs.CR eess.SP</categories><comments>13 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular Ad-Hoc Networks (VANETs) aim at enhancing road safety and providing
a comfortable driving environment by delivering early warning and infotainment
messages to the drivers. Jamming attacks, however, pose a significant threat to
their performance. In this paper, we propose a novel Relative Speed Estimation
Algorithm (RSEA) of a moving interfering vehicle that approaches a Transmitter
($Tx$) - Receiver ($Rx$) pair, that interferes with their Radio Frequency (RF)
communication by conducting a Denial of Service (DoS) attack. Our scheme is
completely sensorless and passive and uses a pilot-based received signal
without hardware or computational cost in order to, firstly, estimate the
combined channel between the transmitter - receiver and jammer - receiver and
secondly, to estimate the jamming signal and the relative speed between the
jammer - receiver using the RF Doppler shift. Moreover, the relative speed
metric exploits the Angle of Projection (AOP) of the speed vector of the jammer
in the axis of its motion in order to form a two-dimensional representation of
the geographical area. This approach can effectively be applied both for a
jamming signal completely unknown to the receiver and for a jamming signal
partly known to the receiver. Our speed estimator method is proven to have
quite accurate performance, with a Mean Absolute Error (MAE) value of
approximately $10\%$ compared to the optimal zero MAE value under different
jamming attack scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11891</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11891</id><created>2018-12-31</created><authors><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Khajehnejad</keyname><forenames>Amin</forenames></author></authors><title>How did Donald Trump Surprisingly Win the 2016 United States
  Presidential Election? an Information-Theoretic Perspective (Clean Sensing
  for Big Data Analytics:Optimal Strategies,Estimation Error Bounds Tighter
  than the Cram\'{e}r-Rao Bound)</title><categories>cs.IT cs.LG eess.SP math.IT math.OC stat.ML</categories><comments>45 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Donald Trump was lagging behind in nearly all opinion polls leading up to the
2016 US presidential election, but he surprisingly won the election. This
raises the following important questions: 1) why most opinion polls were not
accurate in 2016? and 2) how to improve the accuracies of opinion polls? In
this paper, we study the inaccuracies of opinion polls in the 2016 election
through the lens of information theory. We first propose a general framework of
parameter estimation, called clean sensing (polling), which performs optimal
parameter estimation with sensing cost constraints, from heterogeneous and
potentially distorted data sources. We then cast the opinion polling as a
problem of parameter estimation from potentially distorted heterogeneous data
sources, and derive the optimal polling strategy using heterogenous and
possibly distorted data under cost constraints. Our results show that a larger
number of data samples do not necessarily lead to better polling accuracy,
which give a possible explanation of the inaccuracies of opinion polls in 2016.
The optimal sensing strategy should instead optimally allocate sensing
resources over heterogenous data sources according to several factors including
data quality, and, moreover, for a particular data source, it should strike an
optimal balance between the quality of data samples, and the quantity of data
samples.
  As a byproduct of this research, in a general setting, we derive a group of
new lower bounds on the mean-squared errors of general unbiased and biased
parameter estimators. These new lower bounds can be tighter than the classical
Cram\'{e}r-Rao bound (CRB) and Chapman-Robbins bound. Our derivations are via
studying the Lagrange dual problems of certain convex programs. The classical
Cram\'{e}r-Rao bound and Chapman-Robbins bound follow naturally from our
results for special cases of these convex programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11946</identifier>
 <datestamp>2019-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11946</id><created>2018-12-27</created><authors><author><keyname>Miguel</keyname><forenames>Antonio</forenames></author><author><keyname>Llombart</keyname><forenames>Jorge</forenames></author><author><keyname>Ortega</keyname><forenames>Alfonso</forenames></author><author><keyname>Lleida</keyname><forenames>Eduardo</forenames></author></authors><title>Tied Hidden Factors in Neural Networks for End-to-End Speaker
  Recognition</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><journal-ref>Proc. Interspeech 2017, 2819-2823</journal-ref><doi>10.21437/Interspeech.2017-1314</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a method to model speaker and session variability
and able to generate likelihood ratios using neural networks in an end-to-end
phrase dependent speaker verification system. As in Joint Factor Analysis, the
model uses tied hidden variables to model speaker and session variability and a
MAP adaptation of some of the parameters of the model. In the training
procedure our method jointly estimates the network parameters and the values of
the speaker and channel hidden variables. This is done in a two-step
backpropagation algorithm, first the network weights and factor loading
matrices are updated and then the hidden variables, whose gradients are
calculated by aggregating the corresponding speaker or session frames, since
these hidden variables are tied. The last layer of the network is defined as a
linear regression probabilistic model whose inputs are the previous layer
outputs. This choice has the advantage that it produces likelihoods and
additionally it can be adapted during the enrolment using MAP without the need
of a gradient optimization. The decisions are made based on the ratio of the
output likelihoods of two neural network models, speaker adapted and universal
background model. The method was evaluated on the RSR2015 database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11972</identifier>
 <datestamp>2019-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1812.11972</id><created>2018-12-24</created><authors><author><keyname>Tabares-Ospina</keyname><forenames>H&#xe9;ctor A.</forenames></author><author><keyname>Candelo-Becerra</keyname><forenames>John E.</forenames></author></authors><title>Fractal representation of the power daily demand based on topological
  properties of Julia sets</title><categories>eess.SP math.DS math.GN</categories><comments>18 pages, 10 figures. arXiv admin note: substantial text overlap with
  arXiv:1812.11078, arXiv:1812.11071</comments><journal-ref>International Journal of Electrical and Computer Engineering,
  ISSN, 20888708,
  https://www.scimagojr.com/journalsearch.php?q=21100373959&amp;tip=sid, 2018</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In a power system, the load demand considers two components such as the real
power (P) because of resistive elements, and the reactive power (Q) because
inductive or capacitive elements. This paper presents a graphical
representation of the electric power demand based on the topological properties
of the Julia Sets, with the purpose of observing the different graphic patterns
and relationship with the hourly load consumptions. An algorithm that iterates
complex numbers related to power is used to represent each fractal diagram of
the load demand. The results show some representative patterns related to each
value of the power consumption and similar behaviour in the fractal diagrams,
which allows to understand consumption behaviours from the different hours of
the day. This study allows to make a relation among the different consumptions
of the day to create relationships that lead to the prediction of different
behaviour patterns of the curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00062</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00062</id><created>2018-12-31</created><updated>2019-06-20</updated><authors><author><keyname>Choi</keyname><forenames>Hyomin</forenames></author><author><keyname>Bajic</keyname><forenames>Ivan V.</forenames></author></authors><title>Deep Frame Prediction for Video Coding</title><categories>eess.IV cs.CV</categories><comments>This paper is accepted by IEEE Transactions on Circuits and Systems
  for Video Technology in 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel frame prediction method using a deep neural network (DNN),
with the goal of improving video coding efficiency. The proposed DNN makes use
of decoded frames, at both encoder and decoder, to predict textures of the
current coding block. Unlike conventional inter-prediction, the proposed method
does not require any motion information to be transferred between the encoder
and the decoder. Still, both uni-directional and bi-directional prediction are
possible using the proposed DNN, which is enabled by the use of the temporal
index channel, in addition to color channels. In this study, we developed a
jointly trained DNN for both uni- and bi- directional prediction, as well as
separate networks for uni- and bi-directional prediction, and compared the
efficacy of both approaches. The proposed DNNs were compared with the
conventional motion-compensated prediction in the latest video coding standard,
HEVC, in terms of BD-Bitrate. The experiments show that the proposed joint DNN
(for both uni- and bi-directional prediction) reduces the luminance bitrate by
about 4.4%, 2.4%, and 2.3% in the Low delay P, Low delay, and Random access
configurations, respectively. In addition, using the separately trained DNNs
brings further bit savings of about 0.3%-0.5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00106</identifier>
 <datestamp>2019-08-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00106</id><created>2019-01-01</created><updated>2019-08-18</updated><authors><author><keyname>Li</keyname><forenames>Zhipeng</forenames></author><author><keyname>Ravishankar</keyname><forenames>Saiprasad</forenames></author><author><keyname>Long</keyname><forenames>Yong</forenames></author><author><keyname>Fessler</keyname><forenames>Jeffrey A.</forenames></author></authors><title>DECT-MULTRA: Dual-Energy CT Image Decomposition With Learned Mixed
  Material Models and Efficient Clustering</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dual energy computed tomography (DECT) imaging plays an important role in
advanced imaging applications due to its material decomposition capability.
Image-domain decomposition operates directly on CT images using linear matrix
inversion, but the decomposed material images can be severely degraded by noise
and artifacts. This paper proposes a new method dubbed DECT-MULTRA for
image-domain DECT material decomposition that combines conventional penalized
weighted-least squares (PWLS) estimation with regularization based on a mixed
union of learned transforms (MULTRA) model. Our proposed approach pre-learns a
union of common-material sparsifying transforms from patches extracted from all
the basis materials, and a union of cross-material sparsifying transforms from
multi-material patches. The common-material transforms capture the common
properties among different material images, while the cross-material transforms
capture the cross-dependencies. The proposed PWLS formulation is optimized
efficiently by alternating between an image update step and a sparse coding and
clustering step, with both of these steps having closed-form solutions. The
effectiveness of our method is validated with both XCAT phantom and clinical
head data. The results demonstrate that our proposed method provides superior
material image quality and decomposition accuracy compared to other competing
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00136</identifier>
 <datestamp>2019-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00136</id><created>2019-01-01</created><updated>2019-04-13</updated><authors><author><keyname>Mohades</keyname><forenames>Mohamad Mahdi</forenames></author><author><keyname>Majidian</keyname><forenames>Sina</forenames></author><author><keyname>Kahaei</keyname><forenames>Mohammad Hossein</forenames></author></authors><title>Haplotype Assembly Using Manifold Optimization and Error Correction
  Mechanism</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent matrix completion based methods have not been able to properly model
the Haplotype Assembly Problem (HAP) for noisy observations. To cope with such
a case, in this letter we propose a new Minimum Error Correction (MEC) based
matrix completion optimization problem over the manifold of rank-one matrices.
The convergence of a specific iterative algorithm for solving this problem is
proved. Simulation results illustrate that the proposed method not only
outperforms some well-known matrix completion based methods, but also presents
a more accurate result compared to a most recent MEC based algorithm for
haplotype estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00221</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00221</id><created>2019-01-01</created><updated>2019-07-16</updated><authors><author><keyname>Kamran</keyname><forenames>Rashmi</forenames></author><author><keyname>Gupta</keyname><forenames>Shalabh</forenames></author></authors><title>High-Capacity Coherent DCIs using PolMuxed Carrier and LO-Less Receiver</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A PAM4 based direct detection system has been standardized for short-distance
data center interconnects because of its simple architecture. Performance of
the PAM4 systems is limited for high dispersion values or demands complicated
signal processing for further increase in data rates. A polarization
multiplexed carrier based self-homodyne (PMC-SH) link with adaptive
polarization control is a practical approach with an laser oscillator (LO)-less
and carrier phase recovery (CPR)-free coherent receiver that can replace PAM4
links for achieving high data rates. We analytically find that PMC-SH scheme
results in a significantly better BER for a given transmission rate or can
achieve doubling of the data rate for given bandwidth of electronics and laser
power (when compared with PAM4). Practical implementation of the proposed
system with adaptive polarization control is also discussed. Presented
theoretical frame work highlights the advantages of such self-homodyne systems
over PAM4 based systems in terms of SNR requirements and capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00234</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00234</id><created>2019-01-01</created><updated>2019-08-30</updated><authors><author><keyname>Moin</keyname><forenames>Ali</forenames></author><author><keyname>Zhou</keyname><forenames>Andy</forenames></author><author><keyname>Benatti</keyname><forenames>Simone</forenames></author><author><keyname>Rahimi</keyname><forenames>Abbas</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author><author><keyname>Rabaey</keyname><forenames>Jan M.</forenames></author></authors><title>Analysis of Contraction Effort Level in EMG-Based Gesture Recognition
  Using Hyperdimensional Computing</title><categories>cs.HC cs.LG eess.SP</categories><comments>Published as a conference paper at the IEEE BioCAS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Varying contraction levels of muscles is a big challenge in
electromyography-based gesture recognition. Some use cases require the
classifier to be robust against varying force changes, while others demand to
distinguish between different effort levels of performing the same gesture. We
use brain-inspired hyperdimensional computing paradigm to build classification
models that are both robust to these variations and able to recognize multiple
contraction levels. Experimental results on 5 subjects performing 9 gestures
with 3 effort levels show up to 39.17% accuracy drop when training and testing
across different effort levels, with up to 30.35% recovery after applying our
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00235</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00235</id><created>2019-01-01</created><authors><author><keyname>Rebollo-Neira</keyname><forenames>Laura</forenames></author></authors><title>Effective high compression of ECG signals at low level distortion</title><categories>eess.SP</categories><comments>Software for implementing the approach has been made available on
  http://www.nonlinear-approx.info/examples/node012.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An effective method for compression of ECG signals, which falls within the
transform lossy compression category, is proposed. The transformation is
realized by a fast wavelet transform. The effectiveness of the approach, in
relation to the simplicity and speed of its implementation, is a consequence of
the efficient storage of the outputs of the algorithm which is realized in
compressed Hierarchical Data Format. The compression performance is tested on
the MIT-BIH Arrhythmia database producing compression results which largely
improve upon recently reported benchmarks on the same database. For a
distortion corresponding to a percentage root-mean-square difference PRD of
0.53, in mean value, the achieved average compression ratio is 23.17 with
quality score of 43.93. For a mean value of PRD up to 1.71 the compression
ratio increases up to 62.5. The compression of a 30 min record is realized in
an average time of 0.14 s. The insignificant delay for the compression process,
together with the high compression ratio achieved at low level distortion and
the negligible time for the signal recovery, uphold the suitability of the
technique for supporting distant clinical health care.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00236</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00236</id><created>2019-01-01</created><authors><author><keyname>Zhang</keyname><forenames>Yong</forenames></author><author><keyname>Yang</keyname><forenames>Bin</forenames></author><author><keyname>Ge</keyname><forenames>Xiaohu</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author></authors><title>Performance Analysis of Non-Orthogonal Multicast in Two-tier
  Heterogeneous Networks</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the explosive growth of mobile services, non-orthogonal
broadcast/multicast transmissions can effectively improves spectrum efficiency.
Nonorthogonal multiple access (NOMA) represents a paradigm shift from
conventional orthogonal multiple-access (OMA) concepts and has been recognized
as one of the key enabling technologies for fifth-generation (5G) mobile
networks. In this paper, a two-tier heterogeneous network is studied, in which
the wireless signal power is partitioned by the NOMA scheme. Moreover, the
coverage probability, the average rate and the average QoE are derived to
evaluate network performance. Simulation results show that compared with the
OMA method, non-orthogonal broadcast/multicast method improve both the average
user rate and QoE in the two-tier heterogeneous network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00244</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00244</id><created>2019-01-01</created><authors><author><keyname>Chen</keyname><forenames>Kai</forenames></author><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Ge</keyname><forenames>Xiaohu</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Tian</keyname><forenames>Lin</forenames></author><author><keyname>Shi</keyname><forenames>Jinglin</forenames></author></authors><title>Energy Efficiency Optimization of Generalized Spatial Modulation with
  Sub-Connected Hybrid Precoding</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy efficiency (EE) optimization of millimeter wave (mm-Wave) massive
multiple-input multiple-output (MIMO) systems is emerging as an important
challenge for the fifth generation (5G) mobile communication systems. However,
the power of radio frequency (RF) chains increases sharply due to the high
carrier frequency in mm-Wave massive MIMO systems. To overcome this issue, a
new energy efficiency optimization solution is proposed based on the structure
of the generalized spatial modulation (GSM) and sub-connected hybrid precoding
(HP). Moreover, the computation power of mm-Wave massive MIMO systems is
considered for optimizing the EE. Simulation results indicate that the EE of
the GSM-HP scheme outperforms the full digital precoding (FDP) scheme in the
mm-Wave massive MIMO scene, and 88\% computation power can be saved by the
proposed GSM-HP scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00250</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00250</id><created>2019-01-01</created><authors><author><keyname>Weinberg</keyname><forenames>Graham V.</forenames></author></authors><title>Extension of the Geometric Mean Constant False Alarm Rate Detector to
  Multiple Pulses</title><categories>stat.AP eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of sliding window detection processes, based upon a single
cell under test, and operating in clutter modelled by a Pareto distribution,
has been examined extensively. This includes the construction of decision rules
with the complete constant false alarm rate property. However, the case where
there are multiple pulses available has only been examined in the partial
constant false alarm rate scenario. This paper outlines in the latter case how
the probability of false alarm can be produced, for a geometric mean detector,
using properties of gamma distributions. The extension of this result, to the
full constant false alarm rate detector case, is then presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00256</identifier>
 <datestamp>2019-04-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00256</id><created>2019-01-01</created><updated>2019-04-11</updated><authors><author><keyname>Kuo</keyname><forenames>Han-Wen</forenames></author><author><keyname>Lau</keyname><forenames>Yenson</forenames></author><author><keyname>Zhang</keyname><forenames>Yuqian</forenames></author><author><keyname>Wright</keyname><forenames>John</forenames></author></authors><title>Geometry and Symmetry in Short-and-Sparse Deconvolution</title><categories>eess.SP cs.LG eess.IV math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the $\textit{Short-and-Sparse (SaS) deconvolution}$ problem of
recovering a short signal $\mathbf a_0$ and a sparse signal $\mathbf x_0$ from
their convolution. We propose a method based on nonconvex optimization, which
under certain conditions recovers the target short and sparse signals, up to a
signed shift symmetry which is intrinsic to this model. This symmetry plays a
central role in shaping the optimization landscape for deconvolution. We give a
$\textit{regional analysis}$, which characterizes this landscape geometrically,
on a union of subspaces. Our geometric characterization holds when the
length-$p_0$ short signal $\mathbf a_0$ has shift coherence $\mu$, and $\mathbf
x_0$ follows a random sparsity model with sparsity rate $\theta \in
\Bigl[\frac{c_1}{p_0}, \frac{c_2}{p_0\sqrt\mu +
\sqrt{p_0}}\Bigr]\cdot\frac{1}{\log^2p_0}$. Based on this geometry, we give a
provable method that successfully solves SaS deconvolution with high
probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00273</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00273</id><created>2019-01-02</created><authors><author><keyname>Subramaniam</keyname><forenames>Arvind</forenames></author><author><keyname>K</keyname><forenames>Rajitha</forenames></author></authors><title>Spectral Reflectance based Heart Rate Measurement from Facial Video</title><categories>eess.IV</categories><comments>HR measurement, Recursive Least Squares filtering, Feature Point
  Recovery, Illumination Rectification</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Remote detection of the cardiac pulse has a number of applications in sports
and medicine, and can be used to determine the physiological state of the
subject. Previous approaches to estimate Heart Rate from video require the
subject to remain stationary and employ background information to eliminate
illumination interferences. The present research proposes a spectral
reflectance based novel illumination rectification method to eliminate
illumination variations in the video. Our method does not rely on the
background of the video and is robust to extreme motion interferences (head
movements). Furthermore, in order to tackle extreme motion artifacts, the
present framework introduces a novel feature point recovery system which
recovers the feature tracking points lost during extreme head movements of the
subject. Finally, the individual HR estimates from multiple feature points are
combined to produce an average HR. We evaluate the efficacy of our framework on
the MAHNOB HCI dataset, a publicly available dataset employed by previous
methods. Our HR measurement framework outperformed previous methods and had a
root mean square error of 5.21%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00276</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00276</id><created>2019-01-02</created><authors><author><keyname>Zhang</keyname><forenames>Miao</forenames></author><author><keyname>Li</keyname><forenames>Huiqi</forenames></author><author><keyname>Lyu</keyname><forenames>Juan</forenames></author><author><keyname>Ling</keyname><forenames>Sai Ho</forenames></author><author><keyname>Su</keyname><forenames>Steven</forenames></author></authors><title>Multi-level CNN for lung nodule classification with Gaussian Process
  assisted hyperparameter optimization</title><categories>cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates lung nodule classification by using deep neural
networks (DNNs). Hyperparameter optimization in DNNs is a computationally
expensive problem, where evaluating a hyperparameter configuration may take
several hours or even days. Bayesian optimization has been recently introduced
for the automatically searching of optimal hyperparameter configurations of
DNNs. It applies probabilistic surrogate models to approximate the validation
error function of hyperparameter configurations, such as Gaussian processes,
and reduce the computational complexity to a large extent. However, most
existing surrogate models adopt stationary covariance functions to measure the
difference between hyperparameter points based on spatial distance without
considering its spatial locations. This distance-based assumption together with
the condition of constant smoothness throughout the whole hyperparameter search
space clearly violates the property that the points far away from optimal
points usually get similarly poor performance even though each two of them have
huge spatial distance between them. In this paper, a non-stationary kernel is
proposed which allows the surrogate model to adapt to functions whose
smoothness varies with the spatial location of inputs, and a multi-level
convolutional neural network (ML-CNN) is built for lung nodule classification
whose hyperparameter configuration is optimized by using the proposed
non-stationary kernel based Gaussian surrogate model. Our algorithm searches
the surrogate for optimal setting via hyperparameter importance based
evolutionary strategy, and the experiments demonstrate our algorithm
outperforms manual tuning and well-established hyperparameter optimization
methods such as Random search, Gaussian processes with stationary kernels, and
recently proposed Hyperparameter Optimization via RBF and Dynamic coordinate
search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00295</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00295</id><created>2019-01-02</created><authors><author><keyname>Du</keyname><forenames>Xingjian</forenames></author><author><keyname>Zhu</keyname><forenames>Mengyao</forenames></author><author><keyname>Shi</keyname><forenames>Xuan</forenames></author><author><keyname>Zhang</keyname><forenames>Xinpeng</forenames></author><author><keyname>Zhang</keyname><forenames>Wen</forenames></author><author><keyname>Chen</keyname><forenames>Jingdong</forenames></author></authors><title>End-to-End Model for Speech Enhancement by Consistent Spectrogram
  Masking</title><categories>cs.SD cs.AI cs.MM eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, phase processing is attracting increasinginterest in speech
enhancement community. Some researchersintegrate phase estimations module into
speech enhancementmodels by using complex-valued short-time Fourier
transform(STFT) spectrogram based training targets, e.g. Complex RatioMask
(cRM) [1]. However, masking on spectrogram would violentits consistency
constraints. In this work, we prove that theinconsistent problem enlarges the
solution space of the speechenhancement model and causes unintended artifacts.
ConsistencySpectrogram Masking (CSM) is proposed to estimate the
complexspectrogram of a signal with the consistency constraint in asimple but
not trivial way. The experiments comparing ourCSM based end-to-end model with
other methods are conductedto confirm that the CSM accelerate the model
training andhave significant improvements in speech quality. From
ourexperimental results, we assured that our method could enha
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00381</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00381</id><created>2018-12-31</created><authors><author><keyname>Hu</keyname><forenames>Yan</forenames></author><author><keyname>Chen</keyname><forenames>Qian</forenames></author><author><keyname>Liang</keyname><forenames>Yichao</forenames></author><author><keyname>Feng</keyname><forenames>Shijie</forenames></author><author><keyname>Tao</keyname><forenames>Tianyang</forenames></author><author><keyname>Zuo</keyname><forenames>Chao</forenames></author></authors><title>Microscopic 3D measurement of shiny surfaces based on a multi-frequency
  phase-shifting scheme</title><categories>eess.IV physics.optics</categories><comments>8 pages, 7 figures</comments><doi>10.1016/j.optlaseng.2019.05.019</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Microscopic fringe projection profilometry is a powerful 3D measurement
technique with a theoretical measurement accuracy better than one micron
provided that the measured targets can be imaged with good fringe visibility.
However, practically, the 3D shape of the measured surface can hardly be fully
reconstructed due to the defocus of the dense fringes and complex surface
reflexivity characteristics, which lead to low fringe quality and intensity
saturation. To address this problem, we propose to calculate phases of these
highlighted areas from a subset of the fringe sequence which is not subjected
to the intensity saturation. By using the proposed multi-frequency
phase-shifting scheme, the integrity of the 3D surface reconstruction can be
significantly improved. The ultimate phase maps obtained from unsaturated
intensities are used to achieve high-accuracy 3D recovering of shiny surfaces
based on a phase stereo matching method. Experimental results on different
metal surfaces show that our approach is able to retrieve the complete
morphology of shiny surfaces with high accuracy and fidelity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00406</identifier>
 <datestamp>2019-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00406</id><created>2019-01-02</created><updated>2019-03-18</updated><authors><author><keyname>Wu</keyname><forenames>Hao</forenames></author><author><keyname>Lu</keyname><forenames>Hancheng</forenames></author></authors><title>Delay and Power Tradeoff with Consideration of Caching Capabilities in
  Dense Wireless Networks</title><categories>eess.SP cs.NI</categories><comments>30 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enabling caching capabilities in dense small cell networks (DSCNs) has a
direct impact on file delivery delay and power consumption. Most existing work
studied these two performance metrics separately in cache-enabled DSCNs.
However, file delivery delay and power consumption are coupled with each other
and cannot be minimized simultaneously. In this paper, we investigate the
optimal tradoff between these two performance metrics. Firstly, we formulate
the joint file delivery delay and power consumption optimization (JDPO) problem
where power control, user association and file placement are jointly
considered. Then we convert it to a form that can be handled by Generalized
Benders Decomposition (GDB). with GDB, we decompose the converted JDPO problem
into two smaller problems, i.e., primal problem related to power control and
master problem related to user association and file placement. An iterative
algorithm is proposed and proved to be $\epsilon$-optimal, in which the primal
problem and master problem are solved iteratively to approach the optimal
solution. To further reduce the complexity of the master problem, an
accelerated algorithm based on semi-definite relaxation is proposed. Finally,
the simulation results demonstrate that the proposed algorithm can approach the
optimal tradeoff between file delivery delay and power consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00408</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00408</id><created>2018-12-27</created><authors><author><keyname>Hosseinalizadeh</keyname><forenames>Teimour</forenames></author><author><keyname>Salamati</keyname><forenames>S. Mahmoud</forenames></author><author><keyname>Salamati</keyname><forenames>S. Ali</forenames></author><author><keyname>Gharehpetian</keyname><forenames>G. B.</forenames></author></authors><title>Improvement of Identification Procedure Using Hybrid Cuckoo Search
  Algorithm for TurbineGovernor and Excitation System</title><categories>eess.SP cs.SY</categories><comments>10 pages, 9 figures, 3 tables, Published in: IEEE Transactions on
  Energy Conversion</comments><journal-ref>IEEE Trans. on Enrgy Conv, 2018</journal-ref><doi>10.1109/TEC.2018.2868747</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a new method is introduced in order to modify identification
process of a gas power plant using a metaheuristic algorithm named Cuckoo
Search (CS). Simulations play a significant role in dynamic analyses of power
plants. This paper points out to a practical approach in model selection and
parameter estimation of gas power plants. The identification and validation
process concentrates on two subsystems: governor-turbine and exciter. Standard
models GGOV1 and STB6 are preferred for the dynamical structures of
governor-turbine and exciter respectively. Considering definite standard
structure, main parameters of dynamical model are pre estimated via system
identification methods based on field data. Then obtained parameters are tuned
carefully using an iterative Cuckoo algorithm. Models must be validated by
results derived via a trial and error series of simulation in comparison to
measured test data. The procedure gradually yields in a valid model with
precise estimated parameters. Simulation results show accuracy of identified
models. Besides, a whiteness analysis has been performed in order to show the
authenticity of the proposed method in another way. Despite various detailed
models, practical attempts of model selection, identification, and validation
in a real gas unit could rarely be found among literature. In this paper,
Chabahar power plant in Iran, with total install capacity of 320 MW, is chosen
as a benchmark for model validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00417</identifier>
 <datestamp>2019-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00417</id><created>2018-12-21</created><updated>2019-03-27</updated><authors><author><keyname>Yeh</keyname><forenames>Li-Hao</forenames></author><author><keyname>Chowdhury</keyname><forenames>Shwetadwip</forenames></author><author><keyname>Waller</keyname><forenames>Laura</forenames></author></authors><title>Computational structured illumination for high-content fluorescent and
  phase microscopy</title><categories>eess.IV physics.optics</categories><journal-ref>Biomed. Opt. Express 10, 1978-1998 (2019)</journal-ref><doi>10.1364/BOE.10.001978</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-content biological microscopy targets high-resolution imaging across
large fields-of-view (FOVs). Recent works have demonstrated that computational
imaging can provide efficient solutions for high-content microscopy. Here, we
use speckle structured illumination microscopy (SIM) as a robust and
cost-effective solution for high-content fluorescence microscopy with
simultaneous high-content quantitative phase (QP). This multi-modal
compatibility is essential for studies requiring cross-correlative biological
analysis. Our method uses laterally-translated Scotch tape to generate
high-resolution speckle illumination patterns across a large FOV. Custom
optimization algorithms then jointly reconstruct the sample's super-resolution
fluorescent (incoherent) and QP (coherent) distributions, while digitally
correcting for system imperfections such as unknown speckle illumination
patterns, system aberrations and pattern translations. Beyond previous linear
SIM works, we achieve resolution gains of 4x the objective's
diffraction-limited native resolution, resulting in 700 nm fluorescence and 1.2
um QP resolution, across a FOV of 2x2.7 mm^2, giving a space-bandwidth product
(SBP) of 60 megapixels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00447</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00447</id><created>2019-01-02</created><authors><author><keyname>Barazideh</keyname><forenames>Reza</forenames></author><author><keyname>Niknam</keyname><forenames>Solmaz</forenames></author><author><keyname>Natarajan</keyname><forenames>Balasubramaniam</forenames></author></authors><title>Impulsive Noise Detection in OFDM-based Systems: A Deep Learning
  Perspective</title><categories>eess.SP</categories><comments>Accepted in IEEE CCWC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient removal of impulsive noise (IN) from received signal is essential
in many communication applications. In this paper, we propose a two stage IN
mitigation approach for orthogonal frequency-division multiplexing (OFDM)-based
communication systems. In the first stage, a deep neural network (DNN) is used
to detect the instances of impulsivity. Then, the detected IN is blanked in the
suppression stage to alleviate the harmful effects of outliers. Simulation
results demonstrate the superior bit error rate (BER) performance of this
approach relative to classic approaches such as blanking and clipping that use
threshold to detect the IN. We demonstrate the robustness of the DNN-based
approach under (i) mismatch between IN models considered for training and
testing, and (ii) bursty impulsive environment when the receiver is empowered
with interleaving techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00464</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00464</id><created>2019-01-02</created><authors><author><keyname>Barazideh</keyname><forenames>Reza</forenames></author><author><keyname>Sun</keyname><forenames>Wensheng</forenames></author><author><keyname>Natarajan</keyname><forenames>Balasubramaniam</forenames></author><author><keyname>Nikitin</keyname><forenames>Alexei V.</forenames></author><author><keyname>Wang</keyname><forenames>Zhaohui</forenames></author></authors><title>Impulsive Noise Mitigation in Underwater Acoustic Communication Systems:
  Experimental Studies</title><categories>eess.SP</categories><comments>Accepted in IEEE CCWC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Impulsive noise is a major impediment to orthogonal frequency-division
multiplexing (OFDM) based underwater acoustic (UWA) communications. In this
work, we evaluate the performance of a memoryless analog nonlinear preprocessor
(MANP) that is used to mitigate outliers. The proposed MANP exhibits
intermittent nonlinearity only in the presence of the impulsive noise and
suppresses the power of outliers based on their amplitudes. Since the outliers
are distinguishable in the analog domain prior to anti-aliasing filtering, the
MANP outperforms its digital counterparts in all scenarios. Experimental
results using data collected in an under-ice environment, demonstrate the
superior BER performance of our approach relative to classical nonlinear
approaches such as blanking and clipping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00512</identifier>
 <datestamp>2019-01-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00512</id><created>2019-01-02</created><authors><author><keyname>Netzer</keyname><forenames>Eitan</forenames></author><author><keyname>Frid</keyname><forenames>Alex</forenames></author><author><keyname>Feldman</keyname><forenames>Dan</forenames></author></authors><title>Real-Time EEG Classification via Coresets for BCI Applications</title><categories>cs.DS cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A brain-computer interface (BCI) based on the motor imagery (MI) paradigm
translates one's motor intention into a control signal by classifying the
Electroencephalogram (EEG) signal of different tasks. However, most existing
systems either (i) use a high-quality algorithm to train the data off-line and
run only classification in real-time, since the off-line algorithm is too slow,
or (ii) use low-quality heuristics that are sufficiently fast for real-time
training but introduces relatively large classification error. In this work, we
propose a novel processing pipeline that allows real-time and parallel learning
of EEG signals using high-quality but possibly inefficient algorithms. This is
done by forging a link between BCI and core-sets, a technique that originated
in computational geometry for handling streaming data via data summarization.
  We suggest an algorithm that maintains the representation such coreset
tailored to handle the EEG signal which enables: (i) real time and continuous
computation of the Common Spatial Pattern (CSP) feature extraction method on a
coreset representation of the signal (instead on the signal itself) , (ii)
improvement of the CSP algorithm efficiency with provable guarantees by
applying CSP algorithm on the coreset, and (iii) real time addition of the data
trials (EEG data windows) to the coreset.
  For simplicity, we focus on the CSP algorithm, which is a classic algorithm.
Nevertheless, we expect that our coreset will be extended to other algorithms
in future papers. In the experimental results we show that our system can
indeed learn EEG signals in real-time for example a 64 channels setup with
hundreds of time samples per second. Full open source is provided to reproduce
the experiment and in the hope that it will be used and extended to more
coresets and BCI applications in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00707</identifier>
 <datestamp>2019-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00707</id><created>2019-01-03</created><updated>2019-03-06</updated><authors><author><keyname>Ming</keyname><forenames>Huaiping</forenames></author><author><keyname>He</keyname><forenames>Lei</forenames></author><author><keyname>Guo</keyname><forenames>Haohan</forenames></author><author><keyname>Soong</keyname><forenames>Frank K.</forenames></author></authors><title>Feature reinforcement with word embedding and parsing information in
  neural TTS</title><categories>cs.SD cs.CL eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a feature reinforcement method under the
sequence-to-sequence neural text-to-speech (TTS) synthesis framework. The
proposed method utilizes the multiple input encoder to take three levels of
text information, i.e., phoneme sequence, pre-trained word embedding, and
grammatical structure of sentences from parser as the input feature for the
neural TTS system. The added word and sentence level information can be viewed
as the feature based pre-training strategy, which clearly enhances the model
generalization ability. The proposed method not only improves the system
robustness significantly but also improves the synthesized speech to near
recording quality in our experiments for out-of-domain text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00726</identifier>
 <datestamp>2019-01-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00726</id><created>2018-12-05</created><authors><author><keyname>Lemenkova</keyname><forenames>Polina</forenames></author></authors><title>Topology, homogeneity and scale factors for object detection:
  application of eCognition software for urban mapping using multispectral
  satellite image</title><categories>eess.IV cs.CV</categories><comments>6 pages, 12 figures, INSO2015, Ed. by A. Girgvliani et al. Akaki
  Tsereteli State University, Kutaisi (Imereti), Georgia</comments><msc-class>68U10</msc-class><acm-class>I.4.6</acm-class><journal-ref>Proceedings of 7th International Conference 'Internet and Society.
  Modelling' INSO2015, 2015 (80-85)</journal-ref><doi>10.6084/m9.figshare.7211588</doi><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The research scope of this paper is to apply spatial object based image
analysis (OBIA) method for processing panchromatic multispectral image covering
study area of Brussels for urban mapping. The aim is to map different land
cover types and more specifically, built-up areas from the very high resolution
(VHR) satellite image using OBIA approach. A case study covers urban landscapes
in the eastern areas of the city of Brussels, Belgium. Technically, this
research was performed in eCognition raster processing software demonstrating
excellent results of image segmentation and classification. The tools embedded
in eCognition enabled to perform image segmentation and objects classification
processes in a semi-automated regime, which is useful for the city planning,
spatial analysis and urban growth analysis. The combination of the OBIA method
together with technical tools of the eCognition demonstrated applicability of
this method for urban mapping in densely populated areas, e.g. in megapolis and
capital cities. The methodology included multiresolution segmentation and
classification of the created objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00959</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00959</id><created>2019-01-03</created><updated>2019-01-23</updated><authors><author><keyname>Bhattacharyya</keyname><forenames>Rajarshi</forenames></author><author><keyname>Bura</keyname><forenames>Archana</forenames></author><author><keyname>Rengarajan</keyname><forenames>Desik</forenames></author><author><keyname>Rumuly</keyname><forenames>Mason</forenames></author><author><keyname>Shakkottai</keyname><forenames>Srinivas</forenames></author><author><keyname>Kalathil</keyname><forenames>Dileep</forenames></author><author><keyname>Mok</keyname><forenames>Ricky K. P.</forenames></author><author><keyname>Dhamdhere</keyname><forenames>Amogh</forenames></author></authors><title>QFlow: A Reinforcement Learning Approach to High QoE Video Streaming
  over Wireless Networks</title><categories>cs.LG eess.IV stat.ML</categories><comments>Submitted to MobiHoc 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Internet access has brought legions of heterogeneous applications
all sharing the same resources. However, current wireless edge networks that
cater to worst or average case performance lack the agility to best serve these
diverse sessions. Simultaneously, software reconfigurable infrastructure has
become increasingly mainstream to the point that dynamic per packet and per
flow decisions are possible at multiple layers of the communications stack.
Exploiting such reconfigurability requires the design of a system that can
enable a configuration, measure the impact on the application performance
(Quality of Experience), and adaptively select a new configuration.
Effectively, this feedback loop is a Markov Decision Process whose parameters
are unknown. The goal of this work is to design, develop and demonstrate QFlow
that instantiates this feedback loop as an application of reinforcement
learning (RL). Our context is that of reconfigurable (priority) queueing, and
we use the popular application of video streaming as our use case. We develop
both model-free and model-based RL approaches that are tailored to the problem
of determining which clients should be assigned to which queue at each decision
period. Through experimental validation, we show how the RL-based control
policies on QFlow are able to schedule the right clients for prioritization in
a high-load scenario to outperform the status quo, as well as the best known
solutions with over 25% improvement in QoE, and a perfect QoE score of 5 over
85% of the time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.00971</identifier>
 <datestamp>2019-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.00971</id><created>2019-01-03</created><authors><author><keyname>Raghavan</keyname><forenames>Vasanthan</forenames></author><author><keyname>Li</keyname><forenames>Junyi</forenames></author></authors><title>Evolution of Physical-Layer Communications Research in the Post-5G Era</title><categories>cs.IT eess.SP math.IT</categories><comments>11 pages, 4 figures, 2 tables, Accepted for publication in IEEE
  Access</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolving Fifth Generation New Radio (5G-NR) cellular standardization
efforts at the Third Generation Partnership Project (3GPP) brings into focus a
number of questions on relevant research problems in physical-layer
communications for study by both academia and industry. To address this
question, we show that the peak download data rates for both WiFi and cellular
systems have been scaling exponentially with time over the last twenty five
years. While keeping up with the historic cellular trends will be possible in
the near-term with a modest bandwidth and hardware complexity expansion, even a
reasonable stretching of this road-map into the far future would require
significant bandwidth accretion, perhaps possible at the millimeter wave,
sub-millimeter wave, or Terahertz (THz) regimes. The consequent increase in
focus on systems at higher carrier frequencies necessitates a paradigm shift
from the reuse of over-simplified (yet mathematically elegant) models, often
inherited from sub-6 GHz systems, to a more holistic view where real
measurements guide, motivate and refine the building of relevant but possibly
complicated models, solution space(s), and good solutions. To motivate the need
for this shift, we illustrate how the traditional abstraction fails to
correctly estimate the delay spread of millimeter wave wireless channels and
hand blockage losses at higher carrier frequencies. We conclude this paper with
a broad set of implications for future research prospects at the physical-layer
including key use-cases, possible research policy initiatives, and structural
changes needed in telecommunications departments at universities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01079</identifier>
 <datestamp>2019-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01079</id><created>2019-01-04</created><authors><author><keyname>Hassen</keyname><forenames>Sonia Ben</forenames></author><author><keyname>Bellili</keyname><forenames>Faouzi</forenames></author><author><keyname>Samet</keyname><forenames>Abdelaziz</forenames></author><author><keyname>Affes</keyname><forenames>Sofi&#xe8;ne</forenames></author></authors><title>Angular Parameters Estimation of Multiple Incoherently Distributed
  Sources Generating Noncircular Signals</title><categories>eess.SP</categories><comments>15 pages, 9 figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  We introduce a new method for the estimation of the angular parameters [i.e.,
central directions of arrival (DOAs) and angular spreads] of multiple
non-circular and incoherently-distributed (ID) sources and thoroughly analyze
its performance. By decoupling the estimation of the central DOAs from that of
the angular spreads, we reduce significantly the complexity of the proposed
technique. The latter outperforms most well-known state-of-the-art techniques
in terms of estimation accuracy and robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01081</identifier>
 <datestamp>2019-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01081</id><created>2019-01-04</created><updated>2019-01-10</updated><authors><author><keyname>Lanucara</keyname><forenames>Marco</forenames></author></authors><title>Noise performance of the complex monopulse ratio</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper provides a characterization of the complex monopulse ratio in terms
of autocorrelation and power spectral density of its fluctuations during
satellite tracking, taking into account the presence of additive noise on sum
and difference channels. The considered spectral structure and statistical
distribution of the incoming signal is of interest for satellite missions. In
particular it is assumed that the signal available at the monopulse processor
after frequency down conversion contains a Gaussian term produced by low pass
filtering of a constant envelope modulation, plus a monochromatic component
representative of a possible residual carrier. The results can be used for
optimizing the design of a monopulse tracking system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01085</identifier>
 <datestamp>2019-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01085</id><created>2019-01-04</created><authors><author><keyname>Sahidullah</keyname><forenames>Md</forenames></author><author><keyname>Delgado</keyname><forenames>Hector</forenames></author><author><keyname>Todisco</keyname><forenames>Massimiliano</forenames></author><author><keyname>Kinnunen</keyname><forenames>Tomi</forenames></author><author><keyname>Evans</keyname><forenames>Nicholas</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Lee</keyname><forenames>Kong-Aik</forenames></author></authors><title>Introduction to Voice Presentation Attack Detection and Recent Advances</title><categories>cs.SD cs.LG cs.MM eess.AS</categories><comments>Published as a book-chapter in Handbook of Biometric Anti-Spoofing
  Presentation Attack Detection (Second Edition)</comments><journal-ref>Published in Handbook of Biometric Anti-Spoofing Presentation
  Attack Detection (Second Edition eBook ISBN 978-3-319-92627-8), 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past few years significant progress has been made in the field of
presentation attack detection (PAD) for automatic speaker recognition (ASV).
This includes the development of new speech corpora, standard evaluation
protocols and advancements in front-end feature extraction and back-end
classifiers. The use of standard databases and evaluation protocols has enabled
for the first time the meaningful benchmarking of different PAD solutions. This
chapter summarises the progress, with a focus on studies completed in the last
three years. The article presents a summary of findings and lessons learned
from two ASVspoof challenges, the first community-led benchmarking efforts.
These show that ASV PAD remains an unsolved problem and that further attention
is required to develop generalised PAD solutions which have potential to detect
diverse and previously unseen spoofing attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01102</identifier>
 <datestamp>2019-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01102</id><created>2018-12-04</created><authors><author><keyname>Cheng</keyname><forenames>Dong</forenames></author><author><keyname>Kou</keyname><forenames>Kit Ian</forenames></author></authors><title>Multichannel reconstruction from nonuniform samples with application to
  image recovery</title><categories>math.CA eess.IV math.NA</categories><comments>27 pages, 9 figures</comments><msc-class>42A15, 94A12, 65T50, 94A08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multichannel trigonometric reconstruction from uniform samples was
proposed recently. It not only makes use of multichannel information about the
signal but is also capable to generate various kinds of interpolation formulas
according to the types and amounts of the collected samples. The paper presents
the theory of multichannel interpolation from nonuniform samples. Two distinct
models of nonuniform sampling patterns are considered, namely recurrent and
generic nonuniform sampling. Each model involves two types of samples:
nonuniform samples of the observed signal and its derivatives. Numerical
examples and quantitative error analysis are provided to demonstrate the
effectiveness of the proposed algorithms. Additionally, the proposed algorithm
for recovering highly corrupted images is also investigated. In comparison with
the median filter and correction operation treatment, our approach produces
superior results with lower errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01119</identifier>
 <datestamp>2019-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01119</id><created>2018-12-27</created><authors><author><keyname>Feng</keyname><forenames>Mingjie</forenames></author><author><keyname>Mao</keyname><forenames>Shiwen</forenames></author></authors><title>Dealing with Limited Backhaul Capacity in Millimeter Wave Systems: A
  Deep Reinforcement Learning Approach</title><categories>eess.SP cs.LG stat.ML</categories><comments>Appear to IEEE Communications Magazine. Version with math contents
  and equations</comments><doi>10.1109/MCOM.2019.1800565</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter Wave (MmWave) communication is one of the key technology of the
fifth generation (5G) wireless systems to achieve the expected 1000x data rate.
With large bandwidth at mmWave band, the link capacity between users and base
stations (BS) can be much higher compared to sub-6GHz wireless systems.
Meanwhile, due to the high cost of infrastructure upgrade, it would be
difficult for operators to drastically enhance the capacity of backhaul links
between mmWave BSs and the core network. As a result, the data rate provided by
backhaul may not be sufficient to support all mmWave links, the backhaul
connection becomes the new bottleneck that limits the system performance. On
the other hand, as mmWave channels are subject to random blockage, the data
rates of mmWave users significantly vary over time. With limited backhaul
capacity and highly dynamic data rates of users, how to allocate backhaul
resource to each user remains a challenge for mmWave systems. In this article,
we present a deep reinforcement learning (DRL) approach to address this
challenge. By learning the blockage pattern, the system dynamics can be
captured and predicted, resulting in efficient utilization of backhaul
resource. We begin with a discussion on DRL and its application in wireless
systems. We then investigate the problem backhaul resource allocation and
present the DRL based solution. Finally, we discuss open problems for future
research and conclude this article.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01126</identifier>
 <datestamp>2019-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01126</id><created>2018-12-17</created><authors><author><keyname>Jia</keyname><forenames>Mengshuo</forenames></author><author><keyname>Shen</keyname><forenames>Chen</forenames></author><author><keyname>Wang</keyname><forenames>Zhiwen</forenames></author><author><keyname>Yu</keyname><forenames>Zhitong</forenames></author></authors><title>Privacy-Preserving Probabilistic Forecasting for Temporal-spatial
  Correlated Wind Farms</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adopting Secure scalar product and Secure sum techniques, we propose a
privacy-preserving method to build the joint and conditional probability
distribution functions of multiple wind farms' output considering the
temporal-spatial correlation. The proposed method can protect the raw data of
wind farms (WFs) from disclosure, and are mathematically equivalent to the
centralized method which needs to gather the raw data of all WFs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01140</identifier>
 <datestamp>2019-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01140</id><created>2018-12-31</created><authors><author><keyname>Nallathambi</keyname><forenames>Gabriel</forenames></author><author><keyname>Principe</keyname><forenames>Jose C.</forenames></author></authors><title>Theory and Algorithms for Pulse Signal Processing</title><categories>eess.SP cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The integrate and fire converter transforms an analog signal into train of
biphasic pulses. The pulse train has information encoded in the timing and
polarity of pulses. While it has been shown that any finite bandwidth analog
signal can be reconstructed from these pulse trains with an error as small as
desired, there is a need for fundamental signal processing techniques to
operate directly on pulse trains without signal reconstruction. In this paper,
the feasibility of performing online the signal processing operations of
addition, multiplication, and convolution of analog signals using their pulses
train representations is explored. Theoretical framework to perform signal
processing with pulse trains imposing minimal restrictions is derived, and
algorithms for online implementation of the operators are developed.
Performance of the algorithms in processing simulated data is studied. An
application of noise subtraction and representation of relevant features of
interest in electrocardiogram signal is demonstrated with mean pulse rate less
than 20 pulses per second.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01141</identifier>
 <datestamp>2019-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01141</id><created>2018-12-28</created><authors><author><keyname>Wu</keyname><forenames>Huan</forenames></author><author><keyname>Wang</keyname><forenames>Hongda</forenames></author><author><keyname>Choy</keyname><forenames>Chiu-Sing</forenames></author><author><keyname>Shu</keyname><forenames>Chester</forenames></author><author><keyname>Lu</keyname><forenames>Chao</forenames></author></authors><title>BOTDA Fiber Sensor System Based on FPGA Accelerated Support Vector
  Regression</title><categories>eess.SP</categories><comments>8 pgaes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brillouin optical time domain analyzer (BOTDA) fiber sensors have shown
strong capability in static long haul distributed temperature/strain sensing.
However, in applications such as structural health monitoring and leakage
detection, real-time measurement is quite necessary. The measurement time of
temperature/strain in a BOTDA system includes data acquisition time and
post-processing time. In this work, we propose to use hardware accelerated
support vector regression (SVR) for the post-processing of the collected BOTDA
data. Ideal Lorentzian curves under different temperatures with different
linewidths are used to train the SVR model to determine the linear SVR decision
function. The performance of SVR is evaluated under different signal-to-noise
ratios (SNRs) experimentally. After the model coefficients are determined,
algorithm-specific hardware accelerators based on field programmable gate
arrays (FPGAs) are used to realize SVR decision function. During the
implementation, hardware optimization techniques based on loop dependence
analysis and batch processing are proposed to reduce the execution latency. Our
FPGA implementations can achieve up to 42x speedup compared with software
implementation on an i7-5960x computer. The post-processing time for 96,100
BGSs along 38.44-km FUT is only 0.46 seconds with FPGA board ZCU104, making the
post-processing time no longer a limiting factor for dynamic sensing. Moreover,
the energy efficiency of our FPGA implementation can reach up to 226.1x higher
than software implementation based on CPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01189</identifier>
 <datestamp>2019-03-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01189</id><created>2019-01-04</created><updated>2019-03-07</updated><authors><author><keyname>Fonseca</keyname><forenames>Eduardo</forenames></author><author><keyname>Plakal</keyname><forenames>Manoj</forenames></author><author><keyname>Ellis</keyname><forenames>Daniel P. W.</forenames></author><author><keyname>Font</keyname><forenames>Frederic</forenames></author><author><keyname>Favory</keyname><forenames>Xavier</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>Learning Sound Event Classifiers from Web Audio with Noisy Labels</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>International Conference on Acoustics, Speech, and Signal Processing
  (ICASSP 2019)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As sound event classification moves towards larger datasets, issues of label
noise become inevitable. Web sites can supply large volumes of user-contributed
audio and metadata, but inferring labels from this metadata introduces errors
due to unreliable inputs, and limitations in the mapping. There is, however,
little research into the impact of these errors. To foster the investigation of
label noise in sound event classification we present FSDnoisy18k, a dataset
containing 42.5 hours of audio across 20 sound classes, including a small
amount of manually-labeled data and a larger quantity of real-world noisy data.
We characterize the label noise empirically, and provide a CNN baseline system.
Experiments suggest that training with large amounts of noisy data can
outperform training with smaller amounts of carefully-labeled data. We also
show that noise-robust loss functions can be effective in improving performance
in presence of corrupted labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01296</identifier>
 <datestamp>2019-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01296</id><created>2019-01-04</created><authors><author><keyname>Weinberg</keyname><forenames>Graham V.</forenames></author></authors><title>Compensating for Interference in Sliding Window Detection Processes
  using a Bayesian Paradigm</title><categories>eess.SP stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sliding window detectors are non-coherent decision processes, designed in an
attempt to control the probability of false alarm, for application to radar
target detection. In earlier low resolution radar systems it was possible to
specify such detectors quite easily, due to the Gaussian nature of clutter
returns, in an X-band maritime surveillance radar context. As radar resolution
improved with corresponding developments in modern technology, it became
difficult to construct sliding window detectors with the constant false alarm
rate property. However, over the last eight years this situation has been
rectified, due to improved understanding of the way in which such detectors
should be constructed. This paper examines the Bayesian approach to the
construction of such detectors. In particular, the design of sliding window
detectors, with the constant false alarm rate property, with the capacity to
manage interfering targets, will be outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01342</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01342</id><created>2019-01-04</created><updated>2019-05-24</updated><authors><author><keyname>Roth</keyname><forenames>Joseph</forenames></author><author><keyname>Chaudhuri</keyname><forenames>Sourish</forenames></author><author><keyname>Klejch</keyname><forenames>Ondrej</forenames></author><author><keyname>Marvin</keyname><forenames>Radhika</forenames></author><author><keyname>Gallagher</keyname><forenames>Andrew</forenames></author><author><keyname>Kaver</keyname><forenames>Liat</forenames></author><author><keyname>Ramaswamy</keyname><forenames>Sharadh</forenames></author><author><keyname>Stopczynski</keyname><forenames>Arkadiusz</forenames></author><author><keyname>Schmid</keyname><forenames>Cordelia</forenames></author><author><keyname>Xi</keyname><forenames>Zhonghua</forenames></author><author><keyname>Pantofaru</keyname><forenames>Caroline</forenames></author></authors><title>AVA-ActiveSpeaker: An Audio-Visual Dataset for Active Speaker Detection</title><categories>cs.CV cs.MM cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active speaker detection is an important component in video analysis
algorithms for applications such as speaker diarization, video re-targeting for
meetings, speech enhancement, and human-robot interaction. The absence of a
large, carefully labeled audio-visual dataset for this task has constrained
algorithm evaluations with respect to data diversity, environments, and
accuracy. This has made comparisons and improvements difficult. In this paper,
we present the AVA Active Speaker detection dataset (AVA-ActiveSpeaker) that
will be released publicly to facilitate algorithm development and enable
comparisons. The dataset contains temporally labeled face tracks in video,
where each face instance is labeled as speaking or not, and whether the speech
is audible. This dataset contains about 3.65 million human labeled frames or
about 38.5 hours of face tracks, and the corresponding audio. We also present a
new audio-visual approach for active speaker detection, and analyze its
performance, demonstrating both its strength and the contributions of the
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01388</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01388</id><created>2019-01-05</created><updated>2019-07-10</updated><authors><author><keyname>Andrade-Loarca</keyname><forenames>H&#xe9;ctor</forenames></author><author><keyname>Kutyniok</keyname><forenames>Gitta</forenames></author><author><keyname>&#xd6;ktem</keyname><forenames>Ozan</forenames></author><author><keyname>Petersen</keyname><forenames>Philipp</forenames></author></authors><title>Extraction of digital wavefront sets using applied harmonic analysis and
  deep neural networks</title><categories>eess.IV cs.LG eess.SP stat.ML</categories><msc-class>35A18, 65T60, 68T10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microlocal analysis provides deep insight into singularity structures and is
often crucial for solving inverse problems, predominately, in imaging sciences.
Of particular importance is the analysis of wavefront sets and the correct
extraction of those. In this paper, we introduce the first algorithmic approach
to extract the wavefront set of images, which combines data-based and
model-based methods. Based on a celebrated property of the shearlet transform
to unravel information on the wavefront set, we extract the wavefront set of an
image by first applying a discrete shearlet transform and then feeding local
patches of this transform to a deep convolutional neural network trained on
labeled data. The resulting algorithm outperforms all competing algorithms in
edge-orientation and ramp-orientation detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01421</identifier>
 <datestamp>2019-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01421</id><created>2019-01-05</created><authors><author><keyname>Sun</keyname><forenames>Xuyao</forenames></author><author><keyname>Qi</keyname><forenames>Chenhao</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>Beam Training and Allocation for Multiuser Millimeter Wave Massive MIMO
  Systems</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate beam training and allocation for multiuser millimeter wave
massive MIMO systems. An orthogonal pilot based beam training scheme is first
developed to reduce the number of training times, where all users can
simultaneously perform the beam training with the base station (BS). As the
number of users increases, the same beam from the BS may point to different
users, leading to beam conflict and multiuser interference. Therefore, a
quality-of-service (QoS) constrained (QC) beam allocation scheme is proposed to
maximize the equivalent channel gain of the QoS-satisfied users, under the
premise that the number of the QoS-satisfied users without beam conflict is
maximized. To reduce the overhead of beam training, two partial beam training
schemes, an interlaced scanning (IS) and a selection probability (SP) based
schemes, are proposed. The overhead of beam training for the IS-based scheme
can be reduced by nearly half while the overhead for the SP-based scheme is
flexible. Simulation results show that the QC-based beam allocation scheme can
effectively mitigate the interference caused by the beam conflict and
significantly improve the spectral efficiency while the IS-based and SP-based
schemes significantly reduce the overhead of beam training at the cost of
sacrificing spectral efficiency a little.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01422</identifier>
 <datestamp>2019-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01422</id><created>2019-01-05</created><authors><author><keyname>Garakani</keyname><forenames>Golnoosh</forenames></author><author><keyname>Ghane</keyname><forenames>Hamed</forenames></author><author><keyname>Menhaj</keyname><forenames>Mohammad Bagher</forenames></author></authors><title>Control of a 2-DoF robotic arm using a P300-based brain-computer
  interface</title><categories>cs.HC cs.RO cs.SY eess.SP</categories><comments>20 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, a novel control algorithm for a P-300 based brain-computer
interface is fully developed to control a 2-DoF robotic arm. Eight subjects
including 5 men and 3 women, perform a 2-dimensional target tracking task in a
simulated environment. Their EEG signals from visual cortex are recorded and
P-300 components are extracted and evaluated to perform a real-time BCI based
controller. The volunteer's intention is recognized and will be decoded as an
appropriate command to control the cursor. The final goal of the system is to
control a simulated robotic arm in a 2-dimensional space for writing some
English letters. The results show that the system allows the robot end-effector
to move between arbitrary positions in a point-to-point session with the
desired accuracy. This model is tested on and compared with Dataset II of the
BCI Competition. The best result is obtained with a multi-class SVM solution as
the classifier, with a recognition rate of 97 percent, without pre-channel
selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01424</identifier>
 <datestamp>2019-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01424</id><created>2019-01-05</created><authors><author><keyname>Sun</keyname><forenames>Xuyao</forenames></author><author><keyname>Qi</keyname><forenames>Chenhao</forenames></author></authors><title>Codeword Selection and Hybrid Precoding for Multiuser Millimeter Wave
  Massive MIMO Systems</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aiming at maximizing the achievable sum-rate of wideband multiuser mmWave
massive MIMO systems, the hybrid precoding is studied. Since each computation
of the achievable sum-rate can be performed only after the analog precoder and
digital precoder are both determined, the maximization of the achievable
sum-rate has intractable computational complexity. By introducing the
interference free (IF) achievable sum-rate, the design of the analog and
digital precoders can be decoupled. To avoid the beam conflict and maximize the
IF achievable sum-rate, a Hungarian-based codeword selection algorithm is
proposed for the analog precoding design. Simulation results verify the
effectiveness of the proposed scheme and show that better performance can be
achieved compared with existing schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01425</identifier>
 <datestamp>2019-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01425</id><created>2019-01-05</created><authors><author><keyname>Chen</keyname><forenames>Kangjian</forenames></author><author><keyname>Qi</keyname><forenames>Chenhao</forenames></author></authors><title>Beam Training based on Dynamic Hierarchical Codebook for Millimeter Wave
  Massive MIMO</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beam training based on hierarchical codebook for millimeter wave (mmWave)
massive MIMO is investigated. Unlike the existing work using the same
hierarchical codebook to estimate different multi-path components (MPCs),
dynamic hierarchical codebooks which are updated according to the estimated
MPCs are adopted. Firstly, a generalized hierarchical codebook design method is
proposed. Then based on this method, a beam training method which dynamically
updates the hierarchical codebook by removing the contribution of the estimated
MPCs from the codebook is proposed. Simulation results verify the effectiveness
of our method and show that the proposed method outperforms the existing ones
in terms of the success detection rate of beam training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01468</identifier>
 <datestamp>2019-03-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01468</id><created>2019-01-05</created><updated>2019-03-10</updated><authors><author><keyname>Kuznetsov</keyname><forenames>Nikolay</forenames></author><author><keyname>Yuldashev</keyname><forenames>Marat</forenames></author><author><keyname>Yuldashev</keyname><forenames>Renat</forenames></author><author><keyname>Blagov</keyname><forenames>Mikhail</forenames></author><author><keyname>Kudryashova</keyname><forenames>Elena</forenames></author><author><keyname>Kuznetsova</keyname><forenames>Olga</forenames></author><author><keyname>Mokaev</keyname><forenames>Timur</forenames></author></authors><title>Charge pump phase-locked loop with phase-frequency detector: closed form
  mathematical model</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Charge pump phase-locked loop with phase-frequency detector (CP-PLL) is an
electrical circuit, widely used in digital systems for frequency synthesis and
synchronization of the clock signals. In this paper a non-linear second-order
model of CP-PLL is rigorously derived. The obtained model obviates the
shortcomings of previously known second-order models of CP-PLL. Pull-in time is
estimated for the obtained second-order CP-PLL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01502</identifier>
 <datestamp>2019-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01502</id><created>2019-01-06</created><authors><author><keyname>Wu</keyname><forenames>Yuzhong</forenames></author><author><keyname>Lee</keyname><forenames>Tan</forenames></author></authors><title>Enhancing Sound Texture in CNN-Based Acoustic Scene Classification</title><categories>cs.SD cs.LG eess.AS eess.SP stat.ML</categories><comments>Submitted to ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic scene classification is the task of identifying the scene from which
the audio signal is recorded. Convolutional neural network (CNN) models are
widely adopted with proven successes in acoustic scene classification. However,
there is little insight on how an audio scene is perceived in CNN, as what have
been demonstrated in image recognition research. In the present study, the
Class Activation Mapping (CAM) is utilized to analyze how the log-magnitude
Mel-scale filter-bank (log-Mel) features of different acoustic scenes are
learned in a CNN classifier. It is noted that distinct high-energy
time-frequency components of audio signals generally do not correspond to
strong activation on CAM, while the background sound texture are well learned
in CNN. In order to make the sound texture more salient, we propose to apply
the Difference of Gaussian (DoG) and Sobel operator to process the log-Mel
features and enhance edge information of the time-frequency image. Experimental
results on the DCASE 2017 ASC challenge show that using edge enhanced log-Mel
images as input feature of CNN significantly improves the performance of audio
scene classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01548</identifier>
 <datestamp>2019-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01548</id><created>2019-01-06</created><authors><author><keyname>Schmitt</keyname><forenames>Michael</forenames></author><author><keyname>Baier</keyname><forenames>Gerald</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author></authors><title>Potential of nonlocally filtered pursuit monostatic TanDEM-X data for
  coastline detection</title><categories>eess.IV</categories><journal-ref>ISPRS Journal of Photogrammetry and Remote Sensing 148: 130-141</journal-ref><doi>10.1016/j.isprsjprs.2018.12.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article investigates the potential of nonlocally filtered pursuit
monostatic TanDEM-X data for coastline detection in comparison to conventional
TanDEM-X data, i.e. image pairs acquired in repeat-pass or bistatic mode. For
this task, an unsupervised coastline detection procedure based on scale-space
representations and K-medians clustering as well as morphological image
post-processing is proposed. Since this procedure exploits a clear
discriminability of &quot;dark&quot; and &quot;bright&quot; appearances of water and land surfaces,
respectively, in both SAR amplitude and coherence imagery, TanDEM-X InSAR data
acquired in pursuit monostatic mode is expected to provide a promising benefit.
In addition, we investigate the benefit introduced by a utilization of a
non-local InSAR filter for amplitude denoising and coherence estimation instead
of a conventional box-car filter. Experiments carried out on real TanDEM-X
pursuit monostatic data confirm our expectations and illustrate the advantage
of the employed data configuration over conventional TanDEM-X products for
automatic coastline detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01656</identifier>
 <datestamp>2019-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01656</id><created>2019-01-06</created><authors><author><keyname>Ma</keyname><forenames>Wenyan</forenames></author><author><keyname>Qi</keyname><forenames>Chenhao</forenames></author></authors><title>Beamspace Channel Estimation for Millimeter Wave Massive MIMO System
  with Hybrid Precoding and Combining</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a framework of beamspace channel estimation in millimeter wave
(mmWave) massive MIMO system is proposed. The framework includes the design of
hybrid precoding and combining matrix as well as the search method for the
largest entry of over-sampled beamspace receiving matrix. Then based on the
framework, three channel estimation schemes including identity matrix
approximation (IA)-based scheme, scattered zero off-diagonal (SZO)-based scheme
and concentrated zero off-diagonal (CZO)-based scheme are proposed. These
schemes together with the existing channel estimation schemes are compared in
terms of computational complexity, estimation error and total time slots for
channel training. Simulation results show that the proposed schemes outperform
the existing schemes and can approach the performance of the ideal case. In
particular, total time slots for channel training can be substantially reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01657</identifier>
 <datestamp>2019-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01657</id><created>2019-01-06</created><authors><author><keyname>Qi</keyname><forenames>Chenhao</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author></authors><title>Precoding Design for Energy Efficiency of Multibeam Satellite
  Communications</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Instead of merely improving the spectral efficiency (SE), improving the
energy efficiency (EE) is another important concern for multibeam satellite
systems, due to the power constraint of satellites. However, so far there has
been no detailed work on the precoding design concerning the EE for multibeam
satellite. In this work, the EE maximization problem is investigated for
multibeam satellite systems under the total power constraint as well as the
quality of service (QoS) constraints. Precoding design algorithms based on zero
forcing (ZF) and sequential convex approximation (SCA) are presented
respectively. In particular, these algorithms are verified by the real measured
channel data of multibeam satellite systems. Numerical results show that the
precoding algorithm based on SCA outperforms that based on ZF. It is also
implied that the EE cannot be always improved by solely increasing the power of
the satellite, while reducing the satellite operation power is an effective way
for the EE improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01709</identifier>
 <datestamp>2019-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01709</id><created>2019-01-07</created><updated>2019-01-14</updated><authors><author><keyname>Berkels</keyname><forenames>Benjamin</forenames></author><author><keyname>Liebscher</keyname><forenames>Christian H.</forenames></author></authors><title>Joint non-rigid image registration and reconstruction for quantitative
  atomic resolution scanning transmission electron microscopy</title><categories>physics.app-ph eess.IV</categories><journal-ref>Ultramicroscopy, 198:49-57, March 2019</journal-ref><doi>10.1016/j.ultramic.2018.12.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aberration corrected scanning transmission electron microscopes (STEM) enable
to determine local strain fields, composition and bonding states at atomic
resolution. The precision to locate atomic columns is often obstructed by scan
artifacts limiting the quantitative interpretation of STEM datasets. Here, a
novel bias-corrected non-rigid registration approach is presented that
compensates for fast and slow scan artifacts in STEM image series. The
bias-correction is responsible for the correction of the slow scan artifacts
and based on a explicit coupling of the deformations of the individual images
in a series via a minimization of the average deformation. This allows to
reduce fast scan noise in an image series and slow scan distortions
simultaneously. The novel approach is tested on synthetic and experimental
images and its implication on atomic resolution strain and elemental mapping is
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01752</identifier>
 <datestamp>2019-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01752</id><created>2019-01-07</created><authors><author><keyname>Viet</keyname><forenames>Dung Nguyen</forenames></author><author><keyname>Di Renzo</keyname><forenames>Marco</forenames></author><author><keyname>Basavarajappa</keyname><forenames>Vedaprabhu</forenames></author><author><keyname>Exposito</keyname><forenames>Beatriz Bedia</forenames></author><author><keyname>Basterrechea</keyname><forenames>Jose</forenames></author><author><keyname>Phan-Huy</keyname><forenames>Dinh-Thuy</forenames></author></authors><title>Spatial Modulation Based on Reconfigurable Antennas: Performance
  Evaluation by Using the Prototype of a Reconfigurable Antenna</title><categories>eess.SP</categories><comments>Submitted for journal publication</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we study the performance of spatial modulation based on
reconfigurable antennas. Two main contributions are provided. We introduce an
analytical framework to compute the error probability, which is shown to be
accurate and useful for system optimization. We design and implement the
prototype of a reconfigurable antenna that is specifically designed for
application to spatial modulation, and that provides multiple radiation
patterns that are used to encode the information bits. By using the measured
antenna radiation patterns, we show that spatial modulation based on
reconfigurable antennas work in practice, and that its performance can be
optimized by appropriately optimizing the radiation patterns to use for a given
data rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01758</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01758</id><created>2019-01-07</created><updated>2019-06-27</updated><authors><author><keyname>Yan</keyname><forenames>Linjie</forenames></author><author><keyname>Addabbo</keyname><forenames>Pia</forenames></author><author><keyname>Hao</keyname><forenames>Chengpeng</forenames></author><author><keyname>Orlando</keyname><forenames>Danilo</forenames></author><author><keyname>Farina</keyname><forenames>Alfonso</forenames></author></authors><title>New ECCM Techniques Against Noise-like and/or Coherent Interferers</title><categories>eess.SP</categories><comments>submitted for journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-stage adaptive architectures are conceived to face with the problem
of target detection buried in noise, clutter, and intentional interference.
First, a scenario where the radar system is under the electronic attack of
noise-like interferers is considered. In this context, two sets of training
samples are jointly exploited to devise a novel two-step estimation procedure
of the interference covariance matrix. Then, this estimate is plugged in the
adaptive matched filter to mitigate the deleterious effects of the noise-like
jammers on radar sensitivity. Besides, a second scenario, which also includes
the presence of coherent jammers, is addressed. Specifically, the sparse nature
of data is brought to light and the compressive sensing paradigm is applied to
estimate target response and coherent jammers amplitudes. The likelihood ratio
test, where the unknown parameters are replaced by previous estimates, is
designed and assessed. Remarkably, the sparse approach allows for echo
classification and estimation of both angles of arrival and number of the
interfering sources. The performance analysis, conducted resorting to simulated
data, highlights the effectiveness of the newly proposed architectures also in
comparison with suitable competing architectures (when they exist).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01895</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01895</id><created>2019-01-07</created><authors><author><keyname>Brehler</keyname><forenames>Marius</forenames></author><author><keyname>Schirwon</keyname><forenames>Malte</forenames></author><author><keyname>Krummrich</keyname><forenames>Peter M.</forenames></author><author><keyname>G&#xf6;ddeke</keyname><forenames>Dominik</forenames></author></authors><title>Simulation of Nonlinear Signal Propagation in Multimode Fibers on
  Multi-GPU Systems</title><categories>physics.comp-ph eess.SP</categories><doi>10.1016/j.cnsns.2019.105150</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mode-division multiplexing (MDM) is seen as a possible solution to satisfy
the rising capacity demands of optical communication networks. To make MDM a
success, fibers supporting the propagation of a huge number of modes are of
interest. Many of the system aspects occurring during the propagation can be
evaluated by using appropriate models. However, fibers are a nonlinear medium
and, therefore, numerical simulations are required. For a large number of
modes, the simulation of the nonlinear signal propagation leads to new
challenges, for example regarding the required memory, which we address with an
implementation incorporating multiple GPU-accelerators. Within this paper, we
evaluate two different approaches to realize the communication between the GPUs
and analyze the performance for simulations involving up to 8 Tesla GPUs. We
show results for a MDM transmission system utilizing the extremely large but
practically very relevant number of 120 spatial modes as an application example
and analyze the impact of the nonlinear effects on the transmitted signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01931</identifier>
 <datestamp>2019-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01931</id><created>2019-01-07</created><authors><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Garcia</keyname><forenames>Nil</forenames></author><author><keyname>Kim</keyname><forenames>Hyowon</forenames></author><author><keyname>Seco-Granados</keyname><forenames>Gonzalo</forenames></author><author><keyname>Kim</keyname><forenames>Sunwoo</forenames></author><author><keyname>Wen</keyname><forenames>Fuxi</forenames></author><author><keyname>Fr&#xf6;hle</keyname><forenames>Markus</forenames></author></authors><title>5G mmWave Downlink Vehicular Positioning</title><categories>eess.SP</categories><comments>Globecom 2018 paper with corrected figure # 7 (RMSE now significantly
  higher than CRB)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G new radio (NR) provides new opportunities for accurate positioning from a
single reference station: large bandwidth combined with multiple antennas, at
both the base station and user sides, allows for unparalleled angle and delay
resolution. Nevertheless, positioning quality is affected by multipath and
clock biases. We study, in terms of performance bounds and algorithms, the
ability to localize a vehicle in the presence of multipath and unknown user
clock bias. We find that when a sufficient number of paths is present, a
vehicle can still be localized thanks to redundancy in the geometric
constraints. Moreover, the 5G NR signals enable a vehicle to build up a map of
the environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01960</identifier>
 <datestamp>2019-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01960</id><created>2019-01-07</created><updated>2019-04-30</updated><authors><author><keyname>Bahadir</keyname><forenames>Cagla Deniz</forenames></author><author><keyname>Dalca</keyname><forenames>Adrian V.</forenames></author><author><keyname>Sabuncu</keyname><forenames>Mert R.</forenames></author></authors><title>Learning-based Optimization of the Under-sampling Pattern in MRI</title><categories>eess.IV cs.LG stat.ML</categories><comments>13 pages, 5 figures, Accepted as a conference paper in IPMI</comments><msc-class>68T01</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acquisition of Magnetic Resonance Imaging (MRI) scans can be accelerated by
under-sampling in k-space (i.e., the Fourier domain). In this paper, we
consider the problem of optimizing the sub-sampling pattern in a data-driven
fashion. Since the reconstruction model's performance depends on the
sub-sampling pattern, we combine the two problems. For a given sparsity
constraint, our method optimizes the sub-sampling pattern and reconstruction
model, using an end-to-end learning strategy. Our algorithm learns from
full-resolution data that are under-sampled retrospectively, yielding a
sub-sampling pattern and reconstruction model that are customized to the type
of images represented in the training data. The proposed method, which we call
LOUPE (Learning-based Optimization of the Under-sampling PattErn), was
implemented by modifying a U-Net, a widely-used convolutional neural network
architecture, that we append with the forward model that encodes the
under-sampling process. Our experiments with T1-weighted structural brain MRI
scans show that the optimized sub-sampling pattern can yield significantly more
accurate reconstructions compared to standard random uniform, variable density
or equispaced under-sampling schemes. The code is made available at:
https://github.com/cagladbahadir/LOUPE .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.01995</identifier>
 <datestamp>2019-03-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.01995</id><created>2019-01-06</created><updated>2019-03-22</updated><authors><author><keyname>Bao</keyname><forenames>Yuequan</forenames></author><author><keyname>Tang</keyname><forenames>Zhiyi</forenames></author><author><keyname>Li</keyname><forenames>Hui</forenames></author></authors><title>Compressive-Sensing Data Reconstruction for Structural Health
  Monitoring: A Machine-Learning Approach</title><categories>eess.SP cs.LG stat.ML</categories><comments>14 pages, 9 figures, submitted to Structural Health Monitoring
  (https://journals.sagepub.com/home/shm)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing (CS) has been studied and applied in structural health
monitoring for wireless data acquisition and transmission, structural modal
identification, and spare damage identification. The key issue in CS is finding
the optimal solution for sparse optimization. In the past years, many
algorithms have been proposed in the field of applied mathematics. In this
paper, we propose a machine-learning-based approach to solve the CS
data-reconstruction problem. By treating a computation process as a data flow,
the process of CS-based data reconstruction is formalized into a standard
supervised-learning task. The prior knowledge, i.e., the basis matrix and the
CS-sampled signals, are used as the input and the target of the network; the
basis coefficient matrix is embedded as the parameters of a certain layer; the
objective function of conventional compressive sensing is set as the loss
function of the network. Regularized by l1-norm, these basis coefficients are
optimized to reduce the error between the original CS-sampled signals and the
masked reconstructed signals with a common optimization algorithm. Also, the
proposed network can handle complex bases, such as a Fourier basis. Benefiting
from the nature of a multi-neuron layer, multiple signal channels can be
reconstructed simultaneously. Meanwhile, the disassembled use of a large-scale
basis makes the method memory-efficient. A numerical example of multiple
sinusoidal waves and an example of field-test wireless data from a suspension
bridge are carried out to illustrate the data-reconstruction ability of the
proposed approach. The results show that high reconstruction accuracy can be
obtained by the machine learning-based approach. Also, the parameters of the
network have clear meanings; the inference of the mapping between input and
output is fully transparent, making the CS data reconstruction neural network
interpretable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02005</identifier>
 <datestamp>2019-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02005</id><created>2019-01-07</created><updated>2019-01-09</updated><authors><author><keyname>Yao</keyname><forenames>Rugui</forenames></author><author><keyname>Zhang</keyname><forenames>Yuxin</forenames></author><author><keyname>Wang</keyname><forenames>Shengyao</forenames></author><author><keyname>Qi</keyname><forenames>Nan</forenames></author><author><keyname>Tsiftsis</keyname><forenames>Theodoros A.</forenames></author><author><keyname>Miridakis</keyname><forenames>Nikos I.</forenames></author></authors><title>Deep Learning Assisted Antenna Selection in Untrusted Relay Networks</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1812.10318</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter mainly studies the transmit antenna selection(TAS) based on deep
learning (DL) scheme in untrusted relay networks. In previous work, we discover
that machine learning (ML)-based antenna selection schemes have small
performance degradation caused by complicated coupling relationship between
achievable secrecy rate and the channel gains. To solve the issue, we here
introduce deep neural network (DNN) to decouple the complicated relationship.
The simulation results show the DNN scheme can achieve better decoupling and
thus perform almost the same performance with conventional exhausted searching
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02038</identifier>
 <datestamp>2019-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02038</id><created>2019-01-07</created><updated>2019-05-04</updated><authors><author><keyname>Xue</keyname><forenames>Yujia</forenames></author><author><keyname>Cheng</keyname><forenames>Shiyi</forenames></author><author><keyname>Li</keyname><forenames>Yunzhe</forenames></author><author><keyname>Tian</keyname><forenames>Lei</forenames></author></authors><title>Reliable deep-learning-based phase imaging with uncertainty
  quantification</title><categories>eess.IV</categories><journal-ref>Optica 6, 618-629 (2019)</journal-ref><doi>10.1364/OPTICA.6.000618</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emerging deep-learning (DL)-based techniques have significant potential to
revolutionize biomedical imaging. However, one outstanding challenge is the
lack of reliability assessment in the DL predictions, whose errors are commonly
revealed only in hindsight. Here, we propose a new Bayesian convolutional
neural network (BNN)-based framework that overcomes this issue by quantifying
the uncertainty of DL predictions. Foremost, we show that BNN-predicted
uncertainty maps provide surrogate estimates of the true error from the network
model and measurement itself. The uncertainty maps characterize imperfections
often unknown in real-world applications, such as noise, model error,
incomplete training data, and out-of-distribution testing data. Quantifying
this uncertainty provides a per-pixel estimate of the confidence level of the
DL prediction as well as the quality of the model and dataset. We demonstrate
this framework in the application of large space-bandwidth product phase
imaging using a physics-guided coded illumination scheme. From only five
multiplexed illumination measurements, our BNN predicts gigapixel phase images
in both static and dynamic biological samples with quantitative credibility
assessment. Furthermore, we show that low-certainty regions can identify
spatially and temporally rare biological phenomena. We believe our uncertainty
learning framework is widely applicable to many DL-based biomedical imaging
techniques for assessing the reliability of DL predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02050</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02050</id><created>2019-01-07</created><authors><author><keyname>Park</keyname><forenames>Sangwook</forenames></author><author><keyname>Han</keyname><forenames>David K.</forenames></author><author><keyname>Ko</keyname><forenames>Hanseok</forenames></author></authors><title>Sinusoidal wave generating network based on adversarial learning and its
  application: synthesizing frog sounds for data augmentation</title><categories>cs.SD cs.LG eess.AS</categories><comments>This paper has been revised from our previous manuscripts as
  following reviewer's comments in ICML, NIP, and IEEE TSP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simulators that generate observations based on theoretical models can be
important tools for development, prediction, and assessment of signal
processing algorithms. In order to design these simulators, painstaking effort
is required to construct mathematical models according to their application.
Complex models are sometimes necessary to represent a variety of real
phenomena. In contrast, obtaining synthetic observations from generative models
developed from real observations often require much less effort. This paper
proposes a generative model based on adversarial learning. Given that
observations are typically signals composed of a linear combination of
sinusoidal waves and random noises, sinusoidal wave generating networks are
first designed based on an adversarial network. Audio waveform generation can
then be performed using the proposed network. Several approaches to designing
the objective function of the proposed network using adversarial learning are
investigated experimentally. In addition, amphibian sound classification is
performed using a convolutional neural network trained with real and synthetic
sounds. Both qualitative and quantitative results show that the proposed
generative model makes realistic signals and is very helpful for data
augmentation and data analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02053</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02053</id><created>2018-12-18</created><authors><author><keyname>Acharya</keyname><forenames>Anish</forenames></author></authors><title>Detecting the Trend in Musical Taste over the Decade -- A Novel Feature
  Extraction Algorithm to Classify Musical Content with Simple Features</title><categories>cs.IR cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes a novel feature selection algorithm to classify Songs into
different groups. Classification of musical content is often a non-trivial job
and still relatively less explored area. The main idea conveyed in this article
is to come up with a new feature selection scheme that does the classification
job elegantly and with high accuracy but with simpler but wisely chosen small
number of features thus being less prone to over-fitting. This uses a very
basic general idea about the structure of the audio signal which is generally
in the shape of a trapezium. So, using this general idea of the Musical
Community we propose three frames to be considered and analyzed for feature
extraction for each of the audio signal -- opening, stanzas and closing -- and
it has been established with the help of a lot of experiments that this scheme
leads to much efficient classification with less complex features in a low
dimensional feature space thus is also a computationally less expensive method.
Step by step analysis of feature extraction, feature ranking, dimensionality
reduction using PCA has been carried in this article. Sequential Forward
selection (SFS) algorithm is used to explore the most significant features both
with the raw Fisher Discriminant Ratio (FDR) and also with the significant
eigen-values after PCA. Also during classification extensive validation and
cross validation has been done in a monte-carlo manner to ensure validity of
the claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02057</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02057</id><created>2018-12-16</created><authors><author><keyname>Yuan</keyname><forenames>Ye</forenames></author><author><keyname>Ma</keyname><forenames>Guijun</forenames></author><author><keyname>Cheng</keyname><forenames>Cheng</forenames></author><author><keyname>Zhou</keyname><forenames>Beitong</forenames></author><author><keyname>Zhao</keyname><forenames>Huan</forenames></author><author><keyname>Zhang</keyname><forenames>Hai-Tao</forenames></author><author><keyname>Ding</keyname><forenames>Han</forenames></author></authors><title>Artificial Intelligent Diagnosis and Monitoring in Manufacturing</title><categories>cs.LG eess.SP stat.ML</categories><doi>10.1093/nsr/nwz190</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The manufacturing sector is heavily influenced by artificial
intelligence-based technologies with the extraordinary increases in
computational power and data volumes. It has been reported that 35% of US
manufacturers are currently collecting data from sensors for manufacturing
processes enhancement. Nevertheless, many are still struggling to achieve the
'Industry 4.0', which aims to achieve nearly 50% reduction in maintenance cost
and total machine downtime by proper health management. For increasing
productivity and reducing operating costs, a central challenge lies in the
detection of faults or wearing parts in machining operations. Here we propose a
data-driven, end-to-end framework for monitoring of manufacturing systems. This
framework, derived from deep learning techniques, evaluates fused sensory
measurements to detect and even predict faults and wearing conditions. This
work exploits the predictive power of deep learning to extract hidden
degradation features from noisy data. We demonstrate the proposed framework on
several representative experimental manufacturing datasets drawn from a wide
variety of applications, ranging from mechanical to electrical systems. Results
reveal that the framework performs well in all benchmark applications examined
and can be applied in diverse contexts, indicating its potential for use as a
critical corner stone in smart manufacturing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02069</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02069</id><created>2019-01-03</created><authors><author><keyname>Liu</keyname><forenames>Jie</forenames></author><author><keyname>Chen</keyname><forenames>Zhi-Xi</forenames></author><author><keyname>Dong</keyname><forenames>Wen-Hui</forenames></author><author><keyname>Wang</keyname><forenames>Xiao</forenames></author><author><keyname>Shi</keyname><forenames>Jia</forenames></author><author><keyname>Teng</keyname><forenames>Hong-Liang</forenames></author><author><keyname>Dai</keyname><forenames>Xi-Wang</forenames></author><author><keyname>Yau</keyname><forenames>Stephen S. -T.</forenames></author><author><keyname>Liang</keyname><forenames>Chang-Hong</forenames></author><author><keyname>Feng</keyname><forenames>Ping-Fa</forenames></author></authors><title>Microwave Integrated Circuits Design with Relational Induction Neural
  Network</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The automation design of microwave integrated circuits (MWIC) has long been
viewed as a fundamental challenge for artificial intelligence owing to its
larger solution space and structural complexity than Go. Here, we developed a
novel artificial agent, termed Relational Induction Neural Network, that can
lead to an automotive design of MWIC and avoid brute-force computing to examine
every possible solution, which is a significant breakthrough in the field of
electronics. Through the experiments on microwave transmission line circuit,
filter circuit and antenna circuit design tasks, strongly competitive results
are obtained respectively. Compared with the traditional reinforcement learning
method, the learning curve shows that the proposed architecture is able to
quickly converge to the pre-designed MWIC model and the convergence rate is up
to four orders of magnitude. This is the first study which has been shown that
an agent through training or learning to automatically induct the relationship
between MWIC's structures without incorporating any of the additional prior
knowledge. Notably, the relationship can be explained in terms of the MWIC
theory and electromagnetic field distribution. Our work bridges the divide
between artificial intelligence and MWIC and can extend to mechanical wave,
mechanics and other related fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02070</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02070</id><created>2019-01-07</created><authors><author><keyname>Jiang</keyname><forenames>Chiyu &quot;Max&quot;</forenames></author><author><keyname>Wang</keyname><forenames>Dequan</forenames></author><author><keyname>Huang</keyname><forenames>Jingwei</forenames></author><author><keyname>Marcus</keyname><forenames>Philip</forenames></author><author><keyname>Nie&#xdf;ner</keyname><forenames>Matthias</forenames></author></authors><title>Convolutional Neural Networks on non-uniform geometrical signals using
  Euclidean spectral transformation</title><categories>cs.CV cs.AI cs.CG cs.LG eess.SP</categories><comments>Accepted as a conference paper at ICLR 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Networks (CNN) have been successful in processing data
signals that are uniformly sampled in the spatial domain (e.g., images).
However, most data signals do not natively exist on a grid, and in the process
of being sampled onto a uniform physical grid suffer significant aliasing error
and information loss. Moreover, signals can exist in different topological
structures as, for example, points, lines, surfaces and volumes. It has been
challenging to analyze signals with mixed topologies (for example, point cloud
with surface mesh). To this end, we develop mathematical formulations for
Non-Uniform Fourier Transforms (NUFT) to directly, and optimally, sample
nonuniform data signals of different topologies defined on a simplex mesh into
the spectral domain with no spatial sampling error. The spectral transform is
performed in the Euclidean space, which removes the translation ambiguity from
works on the graph spectrum. Our representation has four distinct advantages:
(1) the process causes no spatial sampling error during the initial sampling,
(2) the generality of this approach provides a unified framework for using CNNs
to analyze signals of mixed topologies, (3) it allows us to leverage
state-of-the-art backbone CNN architectures for effective learning without
having to design a particular architecture for a particular data structure in
an ad-hoc fashion, and (4) the representation allows weighted meshes where each
element has a different weight (i.e., texture) indicating local properties. We
achieve results on par with the state-of-the-art for the 3D shape retrieval
task, and a new state-of-the-art for the point cloud to surface reconstruction
task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02113</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02113</id><created>2019-01-07</created><authors><author><keyname>Matthews</keyname><forenames>Richard</forenames></author><author><keyname>Sorrel</keyname><forenames>Matthew</forenames></author><author><keyname>Falkner</keyname><forenames>Nickolas</forenames></author></authors><title>Determining Image Sensor Temperature Using Dark Current</title><categories>eess.IV</categories><comments>20 pages, 10 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The state of the art method for fingerprinting digital cameras focuses on the
non-uniform output of an array of photodiodes due to the distinct construction
of the PN junction when excited by photons. This photo-response non-uniformity
(PRNU) noise has shown to be effective but ignores knowledge of image sensor
output under equilibrium states without excitation (dark current). The dark
current response (DSN) traditionally has been deemed unsuitable as a source of
fingerprinting as it is unstable across multiple variables including exposure
time and temperature. As such it is currently ignored even though studies have
shown it to be a viable method similar to that of PRNU. We hypothesise that DSN
is not only a viable method for forensic identification but, through proper
analysis of the thermal component, can lead to insights regarding the specific
temperature at which an individual image under test was taken. We also show
that digital filtering based on the discrete cosine transformation, rather than
the state-of-the-art wavelet filtering, there is significant computational gain
albeit with some performance degradation. This approach is beneficial for
triage purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02153</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02153</id><created>2019-01-07</created><authors><author><keyname>Cakmak</keyname><forenames>Ahmet Faruk</forenames></author><author><keyname>Balcilar</keyname><forenames>Muhammet</forenames></author></authors><title>Audio Captcha Recognition Using RastaPLP Features by SVM</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>9 pages, 4 figures</comments><msc-class>68T10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, CAPTCHAs are computer generated tests that human can pass but
current computer systems can not. They have common usage in various web
services in order to be able to detect a human from computer programs
autonomously. In this way, owners can protect their web services from bots. In
addition to visual CAPTCHAs which consist of distorted images, mostly test
images, that a user must write some description about that image, there are a
significant amount of audio CAPTCHAs as well. Briefly, audio CAPTCHAs are sound
files which consist of human sound under heavy noise where the speaker
pronounces a bunch of digits consecutively. Generally, in those sound files,
there are some periodic and non-periodic noises to get difficult to recognize
them with a program but not for a human listener. We gathered numerous randomly
collected audio file to train and then test them using our SVM algorithm to be
able to extract digits out of each conversation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02273</identifier>
 <datestamp>2019-09-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02273</id><created>2019-01-08</created><authors><author><keyname>Feng</keyname><forenames>Shiyang</forenames></author><author><keyname>Chen</keyname><forenames>Tianyue</forenames></author><author><keyname>Sun</keyname><forenames>Hao</forenames></author></authors><title>Long Short-Term Memory Spatial Transformer Network</title><categories>eess.IV</categories><doi>10.1109/ITAIC.2019.8785574</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial transformer network has been used in a layered form in conjunction
with a convolutional network to enable the model to transform data spatially.
In this paper, we propose a combined spatial transformer network (STN) and a
Long Short-Term Memory network (LSTM) to classify digits in sequences formed by
MINST elements. This LSTM-STN model has a top-down attention mechanism profit
from LSTM layer, so that the STN layer can perform short-term independent
elements for the statement in the process of spatial transformation, thus
avoiding the distortion that may be caused when the entire sequence is
spatially transformed. It also avoids the influence of this distortion on the
subsequent classification process using convolutional neural networks and
achieves a single digit error of 1.6\% compared with 2.2\% of Convolutional
Neural Network with STN layer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02334</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02334</id><created>2019-01-08</created><authors><author><keyname>Shah</keyname><forenames>Syed Waqas Haider</forenames></author><author><keyname>Rahman</keyname><forenames>M. Mahboob ur</forenames></author><author><keyname>Mian</keyname><forenames>Adnan N.</forenames></author><author><keyname>Imran</keyname><forenames>Ali</forenames></author><author><keyname>Mumtaz</keyname><forenames>Shahid</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author></authors><title>On the Impact of Mode Selection on Effective Capacity of
  Device-to-Device Communication</title><categories>eess.SP</categories><comments>11 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a device to device (D2D) link which utilizes the mode selection to
decide between the direct mode and cellular mode. This paper investigates the
impact of mode selection on effective capacity (EC) (the maximum sustainable
constant arrival rate at a transmitters queue under statistical quality of
service constraints) of a D2D link for both overlay and underlay scenarios. Due
to lack of channel state information, the transmit device sends data at a fixed
rate and fixed power; this fact combined with mode selection makes the D2D
channel a Markov service process. Thus, the EC is obtained by calculating the
entries of the transition probability matrix corresponding to the Markov D2D
channel. Numerical results show that the EC decays exponentially (and the gain
of overlay D2D over underlay D2D diminishes) with the increase in estimation
error of the pathloss measurements utilized by the mode selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02348</identifier>
 <datestamp>2019-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02348</id><created>2019-01-05</created><updated>2019-03-15</updated><authors><author><keyname>Mo&#x161;ner</keyname><forenames>Ladislav</forenames></author><author><keyname>Wu</keyname><forenames>Minhua</forenames></author><author><keyname>Raju</keyname><forenames>Anirudh</forenames></author><author><keyname>Parthasarathi</keyname><forenames>Sree Hari Krishnan</forenames></author><author><keyname>Kumatani</keyname><forenames>Kenichi</forenames></author><author><keyname>Sundaram</keyname><forenames>Shiva</forenames></author><author><keyname>Maas</keyname><forenames>Roland</forenames></author><author><keyname>Hoffmeister</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>Improving noise robustness of automatic speech recognition via parallel
  data and teacher-student learning</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>To Appear in ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For real-world speech recognition applications, noise robustness is still a
challenge. In this work, we adopt the teacher-student (T/S) learning technique
using a parallel clean and noisy corpus for improving automatic speech
recognition (ASR) performance under multimedia noise. On top of that, we apply
a logits selection method which only preserves the k highest values to prevent
wrong emphasis of knowledge from the teacher and to reduce bandwidth needed for
transferring data. We incorporate up to 8000 hours of untranscribed data for
training and present our results on sequence trained models apart from cross
entropy trained ones. The best sequence trained student model yields relative
word error rate (WER) reductions of approximately 10.1%, 28.7% and 19.6% on our
clean, simulated noisy and real test sets respectively comparing to a sequence
trained teacher.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02352</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02352</id><created>2019-01-04</created><authors><author><keyname>Wang</keyname><forenames>Huibing</forenames></author><author><keyname>Li</keyname><forenames>Haohao</forenames></author><author><keyname>Fu</keyname><forenames>Xianping</forenames></author></authors><title>Auto-weighted Mutli-view Sparse Reconstructive Embedding</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the development of multimedia era, multi-view data is generated in
various fields. Contrast with those single-view data, multi-view data brings
more useful information and should be carefully excavated. Therefore, it is
essential to fully exploit the complementary information embedded in multiple
views to enhance the performances of many tasks. Especially for those
high-dimensional data, how to develop a multi-view dimension reduction
algorithm to obtain the low-dimensional representations is of vital importance
but chanllenging. In this paper, we propose a novel multi-view dimensional
reduction algorithm named Auto-weighted Mutli-view Sparse Reconstructive
Embedding (AMSRE) to deal with this problem. AMSRE fully exploits the sparse
reconstructive correlations between features from multiple views. Furthermore,
it is equipped with an auto-weighted technique to treat multiple views
discriminatively according to their contributions. Various experiments have
verified the excellent performances of the proposed AMSRE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02355</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02355</id><created>2019-01-05</created><authors><author><keyname>Deng</keyname><forenames>Yang</forenames></author><author><keyname>Sun</keyname><forenames>Yao</forenames></author><author><keyname>Zhu</keyname><forenames>Yongpei</forenames></author><author><keyname>Xu</keyname><forenames>Yue</forenames></author><author><keyname>Yang</keyname><forenames>Qianxi</forenames></author><author><keyname>Zhang</keyname><forenames>Shuo</forenames></author><author><keyname>Zhu</keyname><forenames>Mingwang</forenames></author><author><keyname>Sun</keyname><forenames>Jirang</forenames></author><author><keyname>Zhao</keyname><forenames>Weiling</forenames></author><author><keyname>Zhou</keyname><forenames>Xiaobo</forenames></author><author><keyname>Yuan</keyname><forenames>Kehong</forenames></author></authors><title>Efforts estimation of doctors annotating medical image</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate annotation of medical image is the crucial step for image AI
clinical application. However, annotating medical image will incur a great deal
of annotation effort and expense due to its high complexity and needing
experienced doctors. To alleviate annotation cost, some active learning methods
are proposed. But such methods just cut the number of annotation candidates and
do not study how many efforts the doctor will exactly take, which is not enough
since even annotating a small amount of medical data will take a lot of time
for the doctor.
  In this paper, we propose a new criterion to evaluate efforts of doctors
annotating medical image. First, by coming active learning and U-shape network,
we employ a suggestive annotation strategy to choose the most effective
annotation candidates. Then we exploit a fine annotation platform to alleviate
annotating efforts on each candidate and first utilize a new criterion to
quantitatively calculate the efforts taken by doctors. In our work, we take MR
brain tissue segmentation as an example to evaluate the proposed method.
  Extensive experiments on the well-known IBSR18 dataset and MRBrainS18
Challenge dataset show that, using proposed strategy, state-of-the-art
segmentation performance can be achieved by using only 60% annotation
candidates and annotation efforts can be alleviated by at least 44%, 44%, 47%
on CSF, GM, WM separately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02436</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02436</id><created>2019-01-08</created><authors><author><keyname>Majzoobi</keyname><forenames>Layla</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author><author><keyname>Shah-Mansouri</keyname><forenames>Vahid</forenames></author></authors><title>Analysis of Distributed ADMM Algorithm for Consensus Optimization in
  Presence of Node Error</title><categories>eess.SP cs.DC</categories><doi>10.1109/TSP.2019.2896266</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alternating Direction Method of Multipliers (ADMM) is a popular convex
optimization algorithm, which can be employed for solving distributed consensus
optimization problems. In this setting agents locally estimate the optimal
solution of an optimization problem and exchange messages with their neighbors
over a connected network. The distributed algorithms are typically exposed to
different types of errors in practice, e.g., due to quantization or
communication noise or loss. We here focus on analyzing the convergence of
distributed ADMM for consensus optimization in presence of additive random node
error, in which case, the nodes communicate a noisy version of their latest
estimate of the solution to their neighbors in each iteration. We present
analytical upper and lower bounds on the mean squared steady state error of the
algorithm in case that the local objective functions are strongly convex and
have Lipschitz continuous gradients. In addition we show that, when the local
objective functions are convex and the additive node error is bounded, the
estimation error of the noisy ADMM for consensus optimization is also bounded.
Numerical results are provided which demonstrate the effectiveness of the
presented analyses and shed light on the role of the system and network
parameters on performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02455</identifier>
 <datestamp>2019-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02455</id><created>2019-01-08</created><authors><author><keyname>Chung</keyname><forenames>Jaebum</forenames></author><author><keyname>Martinez</keyname><forenames>Gloria W.</forenames></author><author><keyname>Lencioni</keyname><forenames>Karen</forenames></author><author><keyname>Sadda</keyname><forenames>Srinivas</forenames></author><author><keyname>Yang</keyname><forenames>Changhuei</forenames></author></authors><title>Computational aberration compensation by coded aperture-based correction
  of aberration obtained from Fourier ptychography (CACAO-FP)</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a novel generalized optical measurement system and computational
approach to determine and correct aberrations in optical systems. We developed
a computational imaging method capable of reconstructing an optical system's
aberration by harnessing Fourier ptychography (FP) with no spatial coherence
requirement. It can then recover the high resolution image latent in the
aberrated image via deconvolution. Deconvolution is made robust to noise by
using coded apertures to capture images. We term this method: coded
aperture-based correction of aberration obtained from Fourier ptychography
(CACAO-FP). It is well-suited for various imaging scenarios with the presence
of aberration where providing a spatially coherent illumination is very
challenging or impossible. We report the demonstration of CACAO-FP with a
variety of samples including an in-vivo imaging experiment on the eye of a
rhesus macaque to correct for its inherent aberration in the rendered retinal
images. CACAO-FP ultimately allows for a poorly designed imaging lens to
achieve diffraction-limited performance over a wide field of view by converting
optical design complexity to computational algorithms in post-processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02480</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02480</id><created>2019-01-08</created><updated>2019-10-16</updated><authors><author><keyname>Hsieh</keyname><forenames>Chung-Han</forenames></author><author><keyname>Barmish</keyname><forenames>B. Ross</forenames></author><author><keyname>Gubner</keyname><forenames>John A.</forenames></author></authors><title>On Positive Solutions of a Delay Equation Arising When Trading in
  Financial Markets</title><categories>math.OC cs.SY eess.SY q-fin.MF</categories><comments>Accepted to IEEE Transactions on Automatic Control</comments><msc-class>93EXX</msc-class><doi>10.1109/TAC.2019.2945885</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a discrete-time, linear state equation with delay which arises as
a model for a trader's account value when buying and selling a risky asset in a
financial market. The state equation includes a nonnegative feedback gain
$\alpha$ and a sequence $v(k)$ which models asset returns which are within
known bounds but otherwise arbitrary. We introduce two thresholds, $\alpha_-$
and $\alpha_+$, depending on these bounds, and prove that for $\alpha &lt;
\alpha_-$, state positivity is guaranteed for all time and all asset-return
sequences; i.e., bankruptcy is ruled out and positive solutions of the state
equation are continuable indefinitely. On the other hand, for $\alpha &gt;
\alpha_+$, we show that there is always a sequence of asset returns for which
the state fails to be positive for all time; i.e., along this sequence,
bankruptcy is certain and the solution of the state equation ceases to be
meaningful after some finite time. Finally, this paper also includes a
conjecture which says that for the &quot;gap&quot; interval $\alpha_- \leq \alpha \leq
\alpha_+,$ state positivity is also guaranteed for all time. Support for the
conjecture, both theoretical and computational, is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02495</identifier>
 <datestamp>2019-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02495</id><created>2019-01-08</created><authors><author><keyname>Terneux</keyname><forenames>Andr&#xe9;s Estrella</forenames></author><author><keyname>Nicolalde</keyname><forenames>Dami&#xe1;n</forenames></author><author><keyname>Nicolalde</keyname><forenames>Daniel</forenames></author><author><keyname>Merino-Viteri</keyname><forenames>Andr&#xe9;s</forenames></author></authors><title>Presence-absence estimation in audio recordings of tropical frog
  communities</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>27 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One non-invasive way to study frog communities is by analyzing long-term
samples of acoustic material containing calls. This immense task has been
optimized by the development of Machine Learning tools to extract ecological
information. We explored a likelihood-ratio audio detector based on Gaussian
mixture model classification of 10 frog species, and applied it to estimate
presence-absence in audio recordings from an actual amphibian monitoring
performed at Yasun\'i National Park in the Ecuadorian Amazonia. A modified
filter-bank was used to extract 20 cepstral features that model the spectral
content of frog calls. Experiments were carried out to investigate the
hyperparameters and the minimum frog-call time needed to train an accurate GMM
classifier. With 64 Gaussians and 12 seconds of training time, the classifier
achieved an average weighted error rate of 0.9% on the 10-fold cross-validation
for nine species classification, as compared to 3% with MFCC and 1.8% with PLP
features. For testing, 10 GMMs were trained using all the available
training-validation dataset to study 23.5 hours in 141, 10-minute long samples
of unidentified real-world audio recorded at two frog communities in 2001 with
analog equipment. To evaluate automatic presence-absence estimation, we
characterized the audio samples with 10 binary variables each corresponding to
a frog species, and manually labeled a sub-set of 18 samples using headphones.
A recall of 87.5% and precision of 100% with average accuracy of 96.66%
suggests good generalization ability of the algorithm, and provides evidence of
the validity of this approach to study real-world audio recorded in a tropical
acoustic environment. Finally, we applied the algorithm to the available
corpus, and show its potentiality to gain insights into the temporal
reproductive behavior of frogs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02500</identifier>
 <datestamp>2019-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02500</id><created>2019-01-08</created><updated>2019-04-16</updated><authors><author><keyname>Yang</keyname><forenames>Hong-Chuan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Data-oriented Wireless Transmission for Effective QoS Provision in
  Future Wireless Systems</title><categories>eess.SP</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future wireless systems need to support diverse big data and Internet of
Things (IoT) applications with dramatically different quality of service (QoS)
requirements. Novel designs across the protocol stack are required to achieve
effective and efficient QoS provision. In this article, we introduce a novel
data oriented approach for the design and analysis of advanced wireless
transmission technologies. Unlike conventional channel-oriented approach, we
propose to optimally design transmission strategies for individual data
transmission sessions, considering both the QoS requirement and instantaneous
operating environment. The resulting design can effectively satisfy highly
stringent performance and efficiency requirements of future applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02513</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02513</id><created>2019-01-08</created><updated>2019-02-17</updated><authors><author><keyname>Erdil</keyname><forenames>Ertunc</forenames></author><author><keyname>Argunsah</keyname><forenames>Ali Ozgur</forenames></author><author><keyname>Tasdizen</keyname><forenames>Tolga</forenames></author><author><keyname>Unay</keyname><forenames>Devrim</forenames></author><author><keyname>Cetin</keyname><forenames>Mujdat</forenames></author></authors><title>Combining nonparametric spatial context priors with nonparametric shape
  priors for dendritic spine segmentation in 2-photon microscopy images</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>IEEE International Symposium on Biomedical Imaging</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data driven segmentation is an important initial step of shape prior-based
segmentation methods since it is assumed that the data term brings a curve to a
plausible level so that shape and data terms can then work together to produce
better segmentations. When purely data driven segmentation produces poor
results, the final segmentation is generally affected adversely. One challenge
faced by many existing data terms is due to the fact that they consider only
pixel intensities to decide whether to assign a pixel to the foreground or to
the background region. When the distributions of the foreground and background
pixel intensities have significant overlap, such data terms become ineffective,
as they produce uncertain results for many pixels in a test image. In such
cases, using prior information about the spatial context of the object to be
segmented together with the data term can bring a curve to a plausible stage,
which would then serve as a good initial point to launch shape-based
segmentation. In this paper, we propose a new segmentation approach that
combines nonparametric context priors with a learned-intensity-based data term
and nonparametric shape priors. We perform experiments for dendritic spine
segmentation in both 2D and 3D 2-photon microscopy images. The experimental
results demonstrate that using spatial context priors leads to significant
improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02520</identifier>
 <datestamp>2019-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02520</id><created>2018-12-19</created><authors><author><keyname>He</keyname><forenames>Yuchen</forenames></author><author><keyname>Kang</keyname><forenames>Sung Ha</forenames></author></authors><title>Lattice Identification and Separation: Theory and Algorithm</title><categories>eess.IV cs.CV math.MG math.NA</categories><comments>30 Pages plus 4 pages of Appendix. 4 Pages of References. 24 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by lattice mixture identification and grain boundary detection, we
present a framework for lattice pattern representation and comparison, and
propose an efficient algorithm for lattice separation. We define new scale and
shape descriptors, which helps to considerably reduce the size of equivalence
classes of lattice bases. These finitely many equivalence relations are fully
characterized by modular group theory. We construct the lattice space
$\mathscr{L}$ based on the equivalent descriptors and define a metric
$d_{\mathscr{L}}$ to accurately quantify the visual similarities and
differences between lattices. Furthermore, we introduce the Lattice
Identification and Separation Algorithm (LISA), which identifies each lattice
patterns from superposed lattices. LISA finds lattice candidates from the high
responses in the image spectrum, then sequentially extracts different layers of
lattice patterns one by one. Analyzing the frequency components, we reveal the
intricate dependency of LISA's performances on particle radius, lattice
density, and relative translations. Various numerical experiments are designed
to show LISA's robustness against a large number of lattice layers, moir\'{e}
patterns and missing particles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02610</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02610</id><created>2019-01-09</created><authors><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>Wang</keyname><forenames>Long Gang</forenames></author><author><keyname>Teixeira</keyname><forenames>Fernando L.</forenames></author></authors><title>Performance Analysis and Dynamic Evolution of Deep Convolutional Neural
  Network for Nonlinear Inverse Scattering</title><categories>physics.comp-ph cs.LG eess.SP</categories><comments>1 pages,4 figures</comments><doi>10.1109/LAWP.2019.2927543</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The solution of nonlinear electromagnetic (EM) inverse scattering problems is
typically hindered by several challenges such as ill-posedness, strong
nonlinearity, and high computational costs. Recently, deep learning has been
demonstrated to be a promising tool in addressing these challenges. In
particular, it is possible to establish a connection between a deep
convolutional neural network (CNN) and iterative solution methods of nonlinear
EM inverse scattering. This has led to the development of an efficient
CNN-based solution to nonlinear EM inverse problems, termed DeepNIS. It has
been shown that DeepNIS can outperform conventional nonlinear inverse
scattering methods in terms of both image quality and computational time. In
this work, we quantitatively evaluate the performance of DeepNIS as a function
of the number of layers using structure similarity measure (SSIM) and
mean-square error (MSE) metrics. In addition, we probe the dynamic evolution
behavior of DeepNIS by examining its near-isometry property. It is shown that
after a proper training stage the proposed CNN is near optimal in terms of the
stability and generalization ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02613</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02613</id><created>2019-01-09</created><updated>2019-01-18</updated><authors><author><keyname>Rahmati</keyname><forenames>Ali</forenames></author><author><keyname>He</keyname><forenames>Xiaofan</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author></authors><title>Dynamic Mobility-Aware Interference Avoidance for Aerial Base Stations
  in Cognitive Radio Networks</title><categories>cs.NI cs.IT eess.SP math.IT</categories><comments>9 pages, 13 figures, to be presented in Proc. IEEE INFOCOM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aerial base station (ABS) is a promising solution for public safety as it can
be deployed in coexistence with cellular networks to form a temporary
communication network. However, the interference from the primary cellular
network may severely degrade the performance of an ABS network. With this
consideration, an adaptive dynamic interference avoidance scheme is proposed in
this work for ABSs coexisting with a primary network. In the proposed scheme,
the mobile ABSs can reconfigure their locations to mitigate the interference
from the primary network, so as to better relay the data from the designated
source(s) to destination(s). To this end, the single/multi-commodity maximum
flow problems are formulated and the weighted Cheeger constant is adopted as a
criterion to improve the maximum flow of the ABS network. In addition, a
distributed algorithm is proposed to compute the optimal ABS moving directions.
Moreover, the trade-off between the maximum flow and the shortest path
trajectories is investigated and an energy-efficient approach is developed as
well. Simulation results show that the proposed approach is effective in
improving the maximum network flow and the energy-efficient approach can save
up to 39% of the energy for the ABSs with marginal degradation in the maximum
network flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02620</identifier>
 <datestamp>2019-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02620</id><created>2019-01-09</created><authors><author><keyname>El-Shafie</keyname><forenames>Al-Hussein A.</forenames></author><author><keyname>Zaki</keyname><forenames>Mohamed</forenames></author><author><keyname>Habib</keyname><forenames>Serag El-Din</forenames></author></authors><title>Fast CNN-Based Object Tracking Using Localization Layers and Deep
  Features Interpolation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object trackers based on Convolution Neural Network (CNN) have achieved
state-of-the-art performance on recent tracking benchmarks, while they suffer
from slow computational speed. The high computational load arises from the
extraction of the feature maps of the candidate and training patches in every
video frame. The candidate and training patches are typically placed randomly
around the previous target location and the estimated target location
respectively. In this paper, we propose novel schemes to speed-up the
processing of the CNN-based trackers. We input the whole region-of-interest
once to the CNN to eliminate the redundant computations of the random candidate
patches. In addition to classifying each candidate patch as an object or
background, we adapt the CNN to classify the target location inside the object
patches as a coarse localization step, and we employ bilinear interpolation for
the CNN feature maps as a fine localization step. Moreover, bilinear
interpolation is exploited to generate CNN feature maps of the training patches
without actually forwarding the training patches through the network which
achieves a significant reduction of the required computations. Our tracker does
not rely on offline video training. It achieves competitive performance results
on the OTB benchmark with 8x speed improvements compared to the equivalent
tracker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02640</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02640</id><created>2019-01-09</created><authors><author><keyname>M&#xe9;riaux</keyname><forenames>Bruno</forenames></author><author><keyname>Ren</keyname><forenames>Chengfang</forenames></author><author><keyname>Korso</keyname><forenames>Mohammed Nabil El</forenames></author><author><keyname>Breloy</keyname><forenames>Arnaud</forenames></author><author><keyname>Forster</keyname><forenames>Philippe</forenames></author></authors><title>Asymptotic Performance of Complex M-estimators for Multivariate Location
  and Scatter Estimation</title><categories>eess.SP</categories><journal-ref>IEEE Signal Processing Letters, 26 2 (2019) 367-371</journal-ref><doi>10.1109/LSP.2019.2891201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The joint estimation of means and scatter matrices is often a core problem in
multivariate analysis. In order to overcome robustness issues, such as outliers
from Gaussian assumption, M-estimators are now preferred to the traditional
sample mean and sample covariance matrix. These estimators are well established
and studied in the real case since the seventies. Their extension to the
complex case has drawn recent interest. In this letter, we derive the
asymptotic performance of complex M-estimators for multivariate location and
scatter matrix estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02748</identifier>
 <datestamp>2019-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02748</id><created>2019-01-09</created><authors><author><keyname>Madsen</keyname><forenames>Peter</forenames></author><author><keyname>Clausen</keyname><forenames>Anders T.</forenames></author><author><keyname>Dochhan</keyname><forenames>Annika</forenames></author><author><keyname>Eiselt</keyname><forenames>Michael</forenames></author></authors><title>Experimental Investigation of the Effect of Pilot Tone Modulation on
  Partial Response Modulation Formats</title><categories>eess.SP</categories><comments>Project BlueSpace (EU funding No. 762055)</comments><doi>10.1109/ECOC.2018.8535574</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an experimental investigation of 8% pilot tone modulation
depth is a system transmitting NRZ, PAM4 and Duobinary. The penalty from the
pilot tone increases with signal amplitude levels and reaches a received power
penalty of 3 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02826</identifier>
 <datestamp>2019-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02826</id><created>2019-01-08</created><updated>2019-05-22</updated><authors><author><keyname>Bock</keyname><forenames>Andreas</forenames></author><author><keyname>Arnaudon</keyname><forenames>Alexis</forenames></author><author><keyname>Cotter</keyname><forenames>Colin</forenames></author></authors><title>Selective metamorphosis for growth modelling with applications to
  landmarks</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We present a framework for shape matching in computational anatomy allowing
users control of the degree to which the matching is diffeomorphic. This
control is given as a function defined over the image and parameterises the
template deformation. By modelling localised template deformation we have a
mathematical description of growth only in specified parts of an image. The
location can either be specified from prior knowledge of the growth location or
learned from data. For simplicity, we consider landmark matching and infer the
distribution of a finite dimensional parameterisation of the control via Markov
chain Monte Carlo. Preliminary numerical results are shown and future paths of
investigation are laid out. Well-posedness of this new problem is studied
together with an analysis of the associated geodesic equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02921</identifier>
 <datestamp>2019-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02921</id><created>2019-01-09</created><authors><author><keyname>Wang</keyname><forenames>Zhen</forenames></author><author><keyname>Long</keyname><forenames>Zhiling</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Tensor-based subspace learning for tracking salt-dome boundaries</title><categories>eess.IV</categories><journal-ref>Proceedings of IEEE ICIP 2015, Quebec City, Canada, Sep. 2015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exploration of petroleum reservoirs has a close relationship with the
identification of salt domes. To efficiently interpret salt-dome structures, in
this paper, we propose a method that tracks salt-dome boundaries through
seismic volumes using a tensor-based subspace learning algorithm. We build
texture tensors by classifying image patches acquired along the boundary
regions of seismic sections and contrast maps. With features extracted from the
subspaces of texture tensors, we can identify tracked points in neighboring
sections and label salt-dome boundaries by optimally connecting these points.
Experimental results show that the proposed method outperforms the
state-of-the-art salt-dome detection method by employing texture information
and tensor-based analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02934</identifier>
 <datestamp>2019-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.02934</id><created>2019-01-09</created><authors><author><keyname>Erdogan</keyname><forenames>Eylem</forenames></author><author><keyname>Afana</keyname><forenames>Ali</forenames></author><author><keyname>Sokun</keyname><forenames>Hamza U.</forenames></author><author><keyname>Ikki</keyname><forenames>Salama</forenames></author><author><keyname>Durak-Ata</keyname><forenames>Lutfiye</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author></authors><title>Signal Space Cognitive Cooperation</title><categories>eess.SP</categories><doi>10.1109/TVT.2018.2885593</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a new transmission scheme, signal space cognitive cooperation,
is introduced by applying the idea of signal space diversity in an underlay
spectrum sharing decode-and-forward multi-relay cooperative network. In the
proposed structure, the secondary source signal is rotated by a certain angle
and then the source and the secondary best relay transmit the in-phase and the
quadrature components of the rotated signal. As a consequence, two source
signals, rather than one, are transmitted in two-time slots which improves data
rates considerably, compared to the conventional cognitive cooperative schemes.
In this work, proactive relaying mode is used in which the best relay is
selected based on the max-min selection criterion before executing the
transmission. Considering both statistical and the instantaneous channel state
information of the feedback channel between the primary receiver and the
secondary network, two power allocation methods are adopted at the source. For
both methods, closed-form expressions of error probability are derived.
Moreover, asymptotic analysis is performed and diversity gain is obtained to
provide further insights about the system performance. Finally, analytical
expressions are verified by Monte-Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03001</identifier>
 <datestamp>2019-05-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03001</id><created>2019-01-09</created><updated>2019-05-02</updated><authors><author><keyname>Ihsan</keyname><forenames>Ullah</forenames></author><author><keyname>Wang</keyname><forenames>Ziqing</forenames></author><author><keyname>Malaney</keyname><forenames>Robert</forenames></author><author><keyname>Dempster</keyname><forenames>Andrew</forenames></author><author><keyname>Yan</keyname><forenames>Shihao</forenames></author></authors><title>Artificial Intelligence and Location Verification in Vehicular Networks</title><categories>eess.SP cs.CR</categories><comments>6 Pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Location information claimed by devices will play an ever-increasing role in
future wireless networks such as 5G, the Internet of Things (IoT). Against this
background, the verification of such claimed location information will be an
issue of growing importance. A formal information-theoretic Location
Verification System (LVS) can address this issue to some extent, but such a
system usually operates within the limits of idealistic assumptions on a-priori
information on the proportion of genuine users in the field. In this work we
address this critical limitation by using a Neural Network (NN) showing how
such a NN based LVS is capable of efficiently functioning even when the
proportion of genuine users is completely unknown a-priori. We demonstrate the
improved performance of this new form of LVS based on Time of Arrival
measurements from multiple verifying base stations within the context of
vehicular networks, quantifying how our NN-LVS outperforms the stand-alone
information-theoretic LVS in a range of anticipated real-world conditions. We
also show the efficient performance for the NN-LVS when the users' signals have
added Non-Line-of-Site (NLoS) bias in them. This new LVS can be applied to a
range of location-centric applications within the domain of the IoT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03057</identifier>
 <datestamp>2019-03-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03057</id><created>2019-01-10</created><updated>2019-02-09</updated><authors><author><keyname>Zhang</keyname><forenames>He</forenames></author><author><keyname>Jiang</keyname><forenames>Shaowei</forenames></author><author><keyname>Liao</keyname><forenames>Jun</forenames></author><author><keyname>Deng</keyname><forenames>Junjing</forenames></author><author><keyname>Liu</keyname><forenames>Jian</forenames></author><author><keyname>Zhang</keyname><forenames>Yongbing</forenames></author><author><keyname>Zheng</keyname><forenames>Guoan</forenames></author></authors><title>Near-field Fourier ptychography: super-resolution phase retrieval via
  speckle illumination</title><categories>physics.optics eess.IV</categories><comments>15 pages, 14 figures</comments><doi>10.1364/OE.27.007498</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Achieving high spatial resolution is the goal of many imaging systems.
Designing a high-resolution lens with diffraction-limited performance over a
large field of view remains a difficult task in imaging system design. On the
other hand, creating a complex speckle pattern with wavelength-limited spatial
features is effortless and can be implemented via a simple random diffuser.
With this observation and inspired by the concept of near-field ptychography,
we report a new imaging modality, termed near-field Fourier ptychography, for
tackling high-resolution imaging challenges in both microscopic and macroscopic
imaging settings. The meaning of 'near-field' is referred to placing the object
at a short defocus distance with a large Fresnel number. In our
implementations, we project a speckle pattern with fine spatial features on the
object instead of directly resolving the spatial features via a high-resolution
lens. We then translate the object (or speckle) to different positions and
acquire the corresponding images using a low-resolution lens. A ptychographic
phase retrieval process is used to recover the complex object, the unknown
speckle pattern, and the coherent transfer function at the same time. In a
microscopic imaging setup, we use a 0.12 numerical aperture (NA) lens to
achieve a NA of 0.85 in the reconstruction process. In a macroscale
photographic imaging setup, we achieve ~7-fold resolution gain using a
photographic lens. The final achievable resolution is not determined by the
collection optics. Instead, it is determined by the feature size of the speckle
pattern. The reported imaging modality can be employed in light, coherent
X-ray, and transmission electron imaging systems to increase resolution and
provide quantitative absorption and phase contrast of the object.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03146</identifier>
 <datestamp>2019-04-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03146</id><created>2019-01-10</created><updated>2019-04-01</updated><authors><author><keyname>Pellegrini</keyname><forenames>Thomas</forenames></author><author><keyname>Cances</keyname><forenames>L&#xe9;o</forenames></author></authors><title>Cosine-similarity penalty to discriminate sound classes in
  weakly-supervised sound event detection</title><categories>cs.SD eess.AS</categories><comments>8 pages, accepted at IJCNN 2019. Code:
  https://github.com/topel/ijcnn19_submission</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The design of new methods and models when only weakly-labeled data are
available is of paramount importance in order to reduce the costs of manual
annotation and the considerable human effort associated with it. In this work,
we address Sound Event Detection in the case where a weakly annotated dataset
is available for training. The weak annotations provide tags of audio events
but do not provide temporal boundaries. The objective is twofold: 1) audio
tagging, i.e. multi-label classification at recording level, 2) sound event
detection, i.e. localization of the event boundaries within the recordings.
This work focuses mainly on the second objective. We explore an approach
inspired by Multiple Instance Learning, in which we train a convolutional
recurrent neural network to give predictions at frame-level, using a custom
loss function based on the weak labels and the statistics of the frame-based
predictions. Since some sound classes cannot be distinguished with this
approach, we improve the method by penalizing similarity between the
predictions of the positive classes during training. On the test set used in
the DCASE 2018 challenge, consisting of 288 recordings and 10 sound classes,
the addition of a penalty resulted in a localization F-score of 34.75%, and
brought 10% relative improvement compared to not using the penalty. Our best
model achieved a 26.20% F-score on the DCASE-2018 official Eval subset close to
the 10-system ensemble approach that ranked second in the challenge with a
29.9% F-score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03257</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03257</id><created>2019-01-10</created><updated>2019-12-21</updated><authors><author><keyname>Papayiannis</keyname><forenames>Constantinos</forenames></author><author><keyname>Evers</keyname><forenames>Christine</forenames></author><author><keyname>Naylor</keyname><forenames>Patrick A.</forenames></author></authors><title>Data Augmentation of Room Classifiers using Generative Adversarial
  Networks</title><categories>eess.AS cs.SD</categories><comments>Submitted to IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classification of acoustic environments allows for machines to better
understand the auditory world around them. The use of deep learning in order to
teach machines to discriminate between different rooms is a new area of
research. Similarly to other learning tasks, this task suffers from the
high-dimensionality and the limited availability of training data. Data
augmentation methods have proven useful in addressing this issue in the tasks
of sound event detection and scene classification. This paper proposes a method
for data augmentation for the task of room classification from reverberant
speech. Generative Adversarial Networks (GANs) are trained that generate
artificial data as if they were measured in real rooms. This provides
additional training examples to the classifiers without the need for any
additional data collection, which is time-consuming and often impractical. A
representation of acoustic environments is proposed, which is used to train the
GANs. The representation is based on a sparse model for the early reflections,
a stochastic model for the reverberant tail and a mixing mechanism between the
two. In the experiments shown, the proposed data augmentation method increases
the test accuracy of a CNN-RNN room classifier from 89.4% to 95.5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03295</identifier>
 <datestamp>2019-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03295</id><created>2019-01-04</created><authors><author><keyname>Rajan</keyname><forenames>Deepta</forenames></author><author><keyname>Beymer</keyname><forenames>David</forenames></author><author><keyname>Narayan</keyname><forenames>Girish</forenames></author></authors><title>Generalization Studies of Neural Network Models for Cardiac Disease
  Detection Using Limited Channel ECG</title><categories>eess.SP cs.LG stat.ML</categories><comments>IEEE Computing in Cardiology (CinC) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acceleration of machine learning research in healthcare is challenged by lack
of large annotated and balanced datasets. Furthermore, dealing with measurement
inaccuracies and exploiting unsupervised data are considered to be central to
improving existing solutions. In particular, a primary objective in predictive
modeling is to generalize well to both unseen variations within the observed
classes, and unseen classes. In this work, we consider such a challenging
problem in machine learning driven diagnosis: detecting a gamut of
cardiovascular conditions (e.g. infarction, dysrhythmia etc.) from limited
channel ECG measurements. Though deep neural networks have achieved
unprecedented success in predictive modeling, they rely solely on
discriminative models that can generalize poorly to unseen classes. We argue
that unsupervised learning can be utilized to construct effective latent spaces
that facilitate better generalization. This work extensively compares the
generalization of our proposed approach against a state-of-the-art deep
learning solution. Our results show significant improvements in F1-scores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03299</identifier>
 <datestamp>2019-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03299</id><created>2018-12-11</created><authors><author><keyname>Artzi</keyname><forenames>Nitzan S.</forenames></author><author><keyname>Shriki</keyname><forenames>Oren</forenames></author></authors><title>An Analysis of the Accuracy of the P300 BCI</title><categories>eess.SP cs.LG q-bio.NC stat.ML</categories><doi>10.1080/2326263X.2018.1552357</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The P300 Brain-Computer Interface (BCI) is a well-established communication
channel for severely disabled people. The P300 event-related potential is
mostly characterized by its amplitude or its area, which correlate with the
spelling accuracy of the P300 speller. Here, we introduce a novel approach for
estimating the efficiency of this BCI by considering the P300 signal-to-noise
ratio (SNR), a parameter that estimates the spatial and temporal noise levels
and has a significantly stronger correlation with spelling accuracy.
Furthermore, we suggest a Gaussian noise model, which utilizes the P300
event-related potential SNR to predict spelling accuracy under various
conditions for LDA-based classification. We demonstrate the utility of this
analysis using real data and discuss its potential applications, such as
speeding up the process of electrode selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03315</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03315</id><created>2019-01-10</created><authors><author><keyname>Shmarov</keyname><forenames>Fedor</forenames></author><author><keyname>Soudjani</keyname><forenames>Sadegh</forenames></author><author><keyname>Paoletti</keyname><forenames>Nicola</forenames></author><author><keyname>Bartocci</keyname><forenames>Ezio</forenames></author><author><keyname>Lin</keyname><forenames>Shan</forenames></author><author><keyname>Smolka</keyname><forenames>Scott A.</forenames></author><author><keyname>Zuliani</keyname><forenames>Paolo</forenames></author></authors><title>Automated Synthesis of Safe Digital Controllers for Sampled-Data
  Stochastic Nonlinear Systems</title><categories>eess.SY cs.SC cs.SY math.DS math.OC</categories><comments>12 pages, 4 figures, 4 tables</comments><msc-class>68N30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new method for the automated synthesis of digital controllers
with formal safety guarantees for systems with nonlinear dynamics, noisy output
measurements, and stochastic disturbances. Our method derives digital
controllers such that the corresponding closed-loop system, modeled as a
sampled-data stochastic control system, satisfies a safety specification with
probability above a given threshold. The proposed synthesis method alternates
between two steps: generation of a candidate controller pc, and verification of
the candidate. pc is found by maximizing a Monte Carlo estimate of the safety
probability, and by using a non-validated ODE solver for simulating the system.
Such a candidate is therefore sub-optimal but can be generated very rapidly. To
rule out unstable candidate controllers, we prove and utilize Lyapunov's
indirect method for instability of sampled-data nonlinear systems. In the
subsequent verification step, we use a validated solver based on SMT
(Satisfiability Modulo Theories) to compute a numerically and statistically
valid confidence interval for the safety probability of pc. If the probability
so obtained is not above the threshold, we expand the search space for
candidates by increasing the controller degree. We evaluate our technique on
three case studies: an artificial pancreas model, a powertrain control model,
and a quadruple-tank process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03326</identifier>
 <datestamp>2019-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03326</id><created>2019-01-10</created><authors><author><keyname>Attar</keyname><forenames>Rahman</forenames></author><author><keyname>Pereanez</keyname><forenames>Marco</forenames></author><author><keyname>Gooya</keyname><forenames>Ali</forenames></author><author><keyname>Alba</keyname><forenames>Xenia</forenames></author><author><keyname>Zhang</keyname><forenames>Le</forenames></author><author><keyname>Piechnik</keyname><forenames>Stefan K.</forenames></author><author><keyname>Neubauer</keyname><forenames>Stefan</forenames></author><author><keyname>Petersen</keyname><forenames>Steffen E.</forenames></author><author><keyname>Frangi</keyname><forenames>Alejandro F.</forenames></author></authors><title>High Throughput Computation of Reference Ranges of Biventricular Cardiac
  Function on the UK Biobank Population Cohort</title><categories>eess.IV cs.LG stat.ML</categories><comments>Accepted in STACOM workshop of MICCAI2018</comments><report-no>LNCS volume number: 11395</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exploitation of large-scale population data has the potential to improve
healthcare by discovering and understanding patterns and trends within this
data. To enable high throughput analysis of cardiac imaging data automatically,
a pipeline should comprise quality monitoring of the input images, segmentation
of the cardiac structures, assessment of the segmentation quality, and parsing
of cardiac functional indexes. We present a fully automatic, high throughput
image parsing workflow for the analysis of cardiac MR images, and test its
performance on the UK Biobank (UKB) cardiac dataset. The proposed pipeline is
capable of performing end-to-end image processing including: data organisation,
image quality assessment, shape model initialisation, segmentation,
segmentation quality assessment, and functional parameter computation; all
without any user interaction. To the best of our knowledge,this is the first
paper tackling the fully automatic 3D analysis of the UKB population study,
providing reference ranges for all key cardiovascular functional indexes, from
both left and right ventricles of the heart. We tested our workflow on a
reference cohort of 800 healthy subjects for which manual delineations, and
reference functional indexes exist. Our results show statistically significant
agreement between the manually obtained reference indexes, and those
automatically computed using our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03328</identifier>
 <datestamp>2019-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03328</id><created>2019-01-10</created><authors><author><keyname>Zhou</keyname><forenames>Caifa</forenames></author><author><keyname>Wieser</keyname><forenames>Andreas</forenames></author></authors><title>Modified Jaccard Index Analysis and Adaptive Feature Selection for
  Location Fingerprinting with Limited Computational Complexity</title><categories>stat.AP eess.SP</categories><comments>15 pagers, 10 figures, 10 tables, revised version for publishing to
  TLBS. arXiv admin note: text overlap with arXiv:1711.07812</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an approach for fingerprinting-based positioning which reduces the
data requirements and computational complexity of the online positioning stage.
It is based on a segmentation of the entire region of interest into subregions,
identification of candidate subregions during the online-stage, and position
estimation using a preselected subset of relevant features. The subregion
selection uses a modified Jaccard index which quantifies the similarity between
the features observed by the user and those available within the reference
fingerprint map. The adaptive feature selection is achieved using an adaptive
forward-backward greedy search which determines a subset of features for each
subregion, relevant with respect to a given fingerprinting-based positioning
method. In an empirical study using signals of opportunity for fingerprinting
the proposed subregion and feature selection reduce the processing time during
the online-stage by a factor of about 10 while the positioning accuracy does
not deteriorate significantly. In fact, in one of the two study cases the 90th
percentile of the circular error increased by 7.5% while in the other study
case we even found a reduction of the corresponding circular error by 30%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03329</identifier>
 <datestamp>2019-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03329</id><created>2019-01-10</created><authors><author><keyname>Savindu</keyname><forenames>H. P.</forenames></author><author><keyname>Iroshan</keyname><forenames>K. A.</forenames></author><author><keyname>Panangala</keyname><forenames>C. D.</forenames></author><author><keyname>Perera</keyname><forenames>W. L. D. W. P.</forenames></author><author><keyname>De Silva</keyname><forenames>A. C</forenames></author></authors><title>BrailleBand: Blind Support Haptic Wearable Band for Communication using
  Braille Language</title><categories>cs.HC eess.SP</categories><comments>6 pages, 4 figures, In proceedings of 2017 IEEE International
  Conference on Systems, Man, and Cybernetics (SMC), pp. 1381-1386. Banff,
  Canada</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Visually impaired people are neglected from many modern communication and
interaction procedures. Assistive technologies such as text-to-speech and
braille displays are the most commonly used means of connecting such visually
impaired people with mobile phones and other smart devices. Both these
solutions face usability issues, thus this study focused on developing a user
friendly wearable solution called the &quot;BrailleBand&quot; with haptic technology
while preserving affordability. The &quot;BrailleBand&quot; enables passive reading using
the Braille language. Connectivity between the BrailleBand and the smart device
(phone) is established using Bluetooth protocol. It consists of six nodes in
three bands worn on the arm to map the braille alphabet, which are actuated to
give the sense of touch corresponding to the characters. Three mobile
applications were developed for training the visually impaired and to integrate
existing smart mobile applications such as navigation and short message service
(SMS) with the device BrailleBand. The adaptability, usability and efficiency
of reading was tested on a sample of blind users which reflected progressive
results. Even though, the reading accuracy depends on the time duration between
the characters (character gap) an average Character Transfer Rate of 0.4375
characters per second can be achieved with a character gap of 1000 ms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03373</identifier>
 <datestamp>2019-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03373</id><created>2018-12-07</created><authors><author><keyname>Virgillito</keyname><forenames>Emanuele</forenames></author><author><keyname>Castoldi</keyname><forenames>Andrea</forenames></author><author><keyname>Straullu</keyname><forenames>Stefano</forenames></author><author><keyname>Abrate</keyname><forenames>Silvio</forenames></author><author><keyname>Pastorelli</keyname><forenames>Rosanna</forenames></author><author><keyname>Curri</keyname><forenames>Vittorio</forenames></author></authors><title>Observing the Effects of Legacy 10G on 100G Channels in Dispersion
  Managed Optical Systems</title><categories>eess.SP</categories><comments>3 pages conference paper, submitted to OFC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that 10G channels generate both amplitude and phase noise on 100G
channels. Amplitude noise can be managed as the ASE and NLI noise, while the
DSP robustness to the phase noise sets the guard-band.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03419</identifier>
 <datestamp>2019-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03419</id><created>2019-01-10</created><authors><author><keyname>Zhu</keyname><forenames>Jin</forenames></author><author><keyname>Yang</keyname><forenames>Guang</forenames></author><author><keyname>Lio</keyname><forenames>Pietro</forenames></author></authors><title>How Can We Make GAN Perform Better in Single Medical Image
  Super-Resolution? A Lesion Focused Multi-Scale Approach</title><categories>eess.IV cs.CV cs.LG</categories><comments>5 pages, 4 figure, 1 table. Accepted at 2019 IEEE International
  Symposium on Biomedical Imaging (ISBI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single image super-resolution (SISR) is of great importance as a low-level
computer vision task. The fast development of Generative Adversarial Network
(GAN) based deep learning architectures realises an efficient and effective
SISR to boost the spatial resolution of natural images captured by digital
cameras. However, the SISR for medical images is still a very challenging
problem. This is due to (1) compared to natural images, in general, medical
images have lower signal to noise ratios, (2) GAN based models pre-trained on
natural images may synthesise unrealistic patterns in medical images which
could affect the clinical interpretation and diagnosis, and (3) the vanilla GAN
architecture may suffer from unstable training and collapse mode that can also
affect the SISR results. In this paper, we propose a novel lesion focused SR
(LFSR) method, which incorporates GAN to achieve perceptually realistic SISR
results for brain tumour MRI images. More importantly, we test and make
comparison using recently developed GAN variations, e.g., Wasserstein GAN
(WGAN) and WGAN with Gradient Penalty (WGAN-GP), and propose a novel
multi-scale GAN (MS-GAN), to achieve a more stabilised and efficient training
and improved perceptual quality of the super-resolved results. Based on both
quantitative evaluations and our designed mean opinion score, the proposed LFSR
coupled with MS-GAN has performed better in terms of both perceptual quality
and efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03434</identifier>
 <datestamp>2019-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03434</id><created>2019-01-10</created><authors><author><keyname>Schmidt</keyname><forenames>Erick</forenames></author><author><keyname>Ruble</keyname><forenames>Zach A.</forenames></author><author><keyname>Akopian</keyname><forenames>David</forenames></author><author><keyname>Pack</keyname><forenames>Daniel J.</forenames></author></authors><title>Software-Defined Radio GNSS Instrumentation for Spoofing Mitigation: A
  Review and a Case Study</title><categories>eess.SP cs.CR cs.SY</categories><journal-ref>IEEE Trans. Instrum. Meas., pp. 1-17, Oct. 2018, doi:
  10.1109/TIM.2018.2869261</journal-ref><doi>10.1109/TIM.2018.2869261</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, several global navigation satellite systems (GNSS) emerged
following the transformative technology impact of the first GNSS: US Global
Positioning System (GPS). The power level of GNSS signals as measured at the
earths surface is below the noise floor and is consequently vulnerable against
interference. Spoofers are smart GNSS-like interferers, which mislead the
receivers into generating false position and time information. While many
spoofing mitigation techniques exist, spoofers are continually evolving,
producing a cycle of new spoofing attacks and counter-measures against them.
Thus, upgradability of receivers becomes an important advantage for maintaining
their immunity against spoofing. Software-defined radio (SDR) implementations
of a GPS receiver address such flexibility but are challenged by demanding
computational requirements of both GNSS signal processing and spoofing
mitigation. Therefore, this paper reviews reported SDRs in the context of
instrumentation capabilities for both conventional and spoofing mitigation
modes. This separation is necessitated by significantly increased computational
loads when in spoofing domain. This is demonstrated by a case study budget
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03435</identifier>
 <datestamp>2019-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03435</id><created>2019-01-10</created><authors><author><keyname>Mehrabi</keyname><forenames>Mehrtash</forenames></author><author><keyname>Mohammadkarimi</keyname><forenames>Mostafa</forenames></author><author><keyname>Ardakani</keyname><forenames>Masoud</forenames></author><author><keyname>Jing</keyname><forenames>Yindi</forenames></author></authors><title>Decision Directed Channel Estimation Based on Deep Neural Network k-step
  Predictor for MIMO Communications in 5G</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the use of deep neural network (DNN) to develop a
decision-directed (DD)-channel estimation (CE) algorithm for multiple-input
multiple-output (MIMO)-space-time block coded systems in highly dynamic
vehicular environments. We propose the use of DNN for k-step channel prediction
for space-time block code (STBC)s, and show that deep learning (DL)-based DD-CE
can removes the need for Doppler spread estimation in fast time-varying quasi
stationary channels, where the Doppler spread varies from one packet to
another. Doppler spread estimation in this kind of vehicular channels is
remarkably challenging and requires a large number of pilots and preambles,
leading to lower power and spectral efficiency. We train two DNNs which learn
real and imaginary parts of the MIMO fading channels over a wide range of
Doppler spreads. We demonstrate that by those DNNs, DD-CE can be realized with
only rough priori knowledge about Doppler spread range. For the proposed DD-CE
algorithm, we also analytically derive the maximum likelihood (ML) decoding
algorithm for STBC transmission. The proposed DL-based DD-CE is a promising
solution for reliable communication over the vehicular MIMO fading channels
without accurate mathematical models. This is because DNN can intelligently
learn the statistics of the fading channels. Our simulation results show that
the proposed DL-based DD-CE algorithm exhibits lower propagation error compared
to existing DD-CE algorithms while the latters require perfect knowledge of the
Doppler rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03437</identifier>
 <datestamp>2019-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03437</id><created>2019-01-10</created><authors><author><keyname>Weinberg</keyname><forenames>Graham V.</forenames></author></authors><title>Multipulse Order Statistic Constant False Alarm Rate Detector in Pareto
  Background</title><categories>eess.SP stat.AP</categories><comments>arXiv admin note: text overlap with arXiv:1901.00250</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent study, the extension of sliding window detectors from the single
to multipulse case has been considered. This short note continues the analysis
of such detectors, and specifies an order statistic variation. The probability
of false alarm is derived in a useful compact mathematical expression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03450</identifier>
 <datestamp>2019-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03450</id><created>2019-01-10</created><authors><author><keyname>Cai</keyname><forenames>Chao</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author><author><keyname>Hu</keyname><forenames>Menglan</forenames></author></authors><title>A survey on acoustic sensing</title><categories>cs.SD cs.HC cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rise of Internet-of-Things (IoT) has brought many new sensing mechanisms.
Among these mechanisms, acoustic sensing attracts much attention in recent
years. Acoustic sensing exploits acoustic sensors beyond their primary uses,
namely recording and playing, to enable interesting applications and new user
experience. In this paper, we present the first survey of recent advances in
acoustic sensing using commodity hardware. We propose a general framework that
categorizes main building blocks of acoustic sensing systems. This framework
consists of three layers, i.e., the physical layer, processing layer, and
application layer. We highlight different sensing approaches in the processing
layer and fundamental design considerations in the physical layer. Many
existing and potential applications including context-aware applications,
human-computer interface, and aerial acoustic communications are presented in
depth. Challenges and future research trends are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03454</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03454</id><created>2019-01-10</created><updated>2019-10-07</updated><authors><author><keyname>Ma</keyname><forenames>Genwei</forenames></author><author><keyname>Zhu</keyname><forenames>Yining</forenames></author><author><keyname>Zhao</keyname><forenames>Xing</forenames></author></authors><title>Learning image from projection: a full-automatic reconstruction (FAR)
  net for sparse-views computed tomography</title><categories>physics.med-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sparse-views x-ray computed tomography (CT) is essential for medical
diagnosis and industrial nondestructive testing. However, in particular, the
reconstructed image usually suffers from complex artifacts and noise, when the
sampling is insufficient. In order to deal such issue, a full-automatic
reconstruction (FAR) net is proposed for sparse-views CT reconstruction via
deep learning technique. Different with the usual network in deep learning
reconstruction, the proposed neural network is an End-to-End network by which
the image is predicted directly from projection data. The main challenge for
such a FAR net is the space complexity of the CT reconstruction in
full-connected (FC) network. For a CT image with the size $N \times N$ , a
typical requirement of memory space for the image reconstruction is $O(N^{4})$,
for which is unacceptable by conventional calculation device, e.g. GPU
workstation. In this paper, we utilize a series of smaller FC layers to replace
the huge based on the sparse nonnegative matrix factorization (SNMF) theory. By
applying such an approach, the FAR net is able to reconstruct sparse-views CT
images with the size $512\times 512$ on only one workstation. Furthermore, a
Res-Unet structure is composed in the FAR net for suppressing the artifacts and
noise caused by under-sampling data. The results of numerical experiments show
that the projection matrix and the FAR net is able to reconstruct the CT image
from sparse-views projection data with a superior quality than conventional
method such as FBP and optimization based approach. Meanwhile, the
factorization for the inverse projection matrix is validated in numerical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03543</identifier>
 <datestamp>2019-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03543</id><created>2019-01-11</created><authors><author><keyname>Rezgui</keyname><forenames>Gada</forenames></author><author><keyname>Belmega</keyname><forenames>E. Veronica</forenames></author><author><keyname>Chorti</keyname><forenames>Arsenia</forenames></author></authors><title>Mitigating Jamming Attacks Using Energy Harvesting</title><categories>cs.CR cs.GT cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of energy harvesting as a counter-jamming measure is investigated on
the premise that part of the harmful interference can be harvested to increase
the transmit power. We formulate the strategic interaction between a pair of
legitimate nodes and a malicious jammer as a zero-sum game. Our analysis
demonstrates that the legitimate nodes are able to neutralize the jammer.
However, this policy is not necessarily a Nash equilibrium and hence is
sub-optimal. Instead, harvesting the jamming interference can lead to relative
gains of up to 95%, on average, in terms of Shannon capacity, when the jamming
interference is high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03565</identifier>
 <datestamp>2019-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03565</id><created>2019-01-11</created><updated>2019-11-11</updated><authors><author><keyname>McCann</keyname><forenames>Michael T.</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>Biomedical Image Reconstruction: From the Foundations to Deep Neural
  Networks</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This tutorial covers biomedical image reconstruction, from the foundational
concepts of system modeling and direct reconstruction to modern sparsity and
learning-based approaches.
  Imaging is a critical tool in biological research and medicine, and most
imaging systems necessarily use an image-reconstruction algorithm to create an
image; the design of these algorithms has been a topic of research since at
least the 1960's. In the last few years, machine learning-based approaches have
shown impressive performance on image reconstruction problems, triggering a
wave of enthusiasm and creativity around the paradigm of learning. Our goal is
to unify this body of research, identifying common principles and reusable
building blocks across decades and among diverse imaging modalities.
  We first describe system modeling, emphasizing how a few building blocks can
be used to describe a broad range of imaging modalities. We then discuss
reconstruction algorithms, grouping them into three broad generations. The
first are the classical direct methods, including Tikhonov regularization; the
second are the variational methods based on sparsity and the theory of
compressive sensing; and the third are the learning-based (also called
data-driven) methods, especially those using deep convolutional neural
networks. There are strong links between these generations: classical
(first-generation) methods appear as modules inside the latter two, and the
former two are used to inspire new designs for learning-based
(third-generation) methods. As a result, a solid understanding of all of three
generations is necessary for the design of state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03669</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03669</id><created>2019-01-11</created><updated>2019-07-15</updated><authors><author><keyname>Ouyang</keyname><forenames>Chongjun</forenames></author><author><keyname>Yang</keyname><forenames>Hongwen</forenames></author></authors><title>Performance Analysis of Receive Antenna Selection in Multi-Antenna
  Systems under Finite Constellation Size</title><categories>eess.SP</categories><comments>There are several errors in this article and the results are not very
  convincing. Besides, I hope to polish this paper. Because of this, I want to
  withdrawl it</comments><msc-class>00-01</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Antenna selection (AS) is regarded as one of the most prospective
technologies to reduce hardware cost but keep relatively high spectral
efficiency in multi-antenna systems. By selecting a subset of antennas to
transceive messages, AS greatly alleviates the requirement on RF chains. This
paper studies receive antenna selection in single-input multiple-output (SIMO)
systems, namely the antenna-selection SIMO (AS-SIMO) systems, from the
perspective of digital modulation. The receiver, equipped with multiple
antennas, selects an optimal antenna subset to receive messages from the
single-antenna transmitter. By assuming independent and identical distributed
(i.i.d) flat fading Rayleigh channels, we first analyze the input-output mutual
information, also referred as symmetric capacity, of AS-SIMO systems when the
modulation style is BPSK/QPSK/16QAM. To reduce the computation complexity of
the capacity, closed-form approximated expressions of the symmetric capacity
based on asymptotic theory are given for the first time to approach the exact
results. Compared with the conventional derivations, our approximation holds
much lower computation complexity with the guarantee of high precision. Next,
this asymptotic approximation technique is extended to estimate the symbol
error rate (SER) of antenna-selection SIMO systems and approximated expressions
for SER are proposed which indicates much lower complexity. Finally, a special
scenario of single-antenna-selection is detailedly investigated and series
expressions of the symmetric capacity are formulated for the first time. Beside
analytical derivations, simulation results are provided to demonstrate the
approximation precision of the derived results. Experiment results show that
the asymptotic theory has a remarkable approximation effect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03684</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03684</id><created>2019-01-11</created><authors><author><keyname>Romero</keyname><forenames>Francisco Perdigon</forenames></author><author><keyname>Tang</keyname><forenames>An</forenames></author><author><keyname>Kadoury</keyname><forenames>Samuel</forenames></author></authors><title>Multi-Level Batch Normalization In Deep Networks For Invasive Ductal
  Carcinoma Cell Discrimination In Histopathology Images</title><categories>eess.IV cs.LG</categories><comments>4 pages, 5 figures</comments><doi>10.1109/ISBI.2019.8759410</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Breast cancer is the most diagnosed cancer and the most predominant cause of
death in women worldwide. Imaging techniques such as the breast cancer
pathology helps in the diagnosis and monitoring of the disease. However
identification of malignant cells can be challenging given the high
heterogeneity in tissue absorbotion from staining agents. In this work, we
present a novel approach for Invasive Ductal Carcinoma (IDC) cells
discrimination in histopathology slides. We propose a model derived from the
Inception architecture, proposing a multi-level batch normalization module
between each convolutional steps. This module was used as a base block for the
feature extraction in a CNN architecture. We used the open IDC dataset in which
we obtained a balanced accuracy of 0.89 and an F1 score of 0.90, thus
surpassing recent state of the art classification algorithms tested on this
public dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03807</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03807</id><created>2019-01-12</created><authors><author><keyname>Matthews</keyname><forenames>Richard</forenames></author><author><keyname>Sorell</keyname><forenames>Matthew</forenames></author><author><keyname>Falkner</keyname><forenames>Nickolas</forenames></author></authors><title>Reverse Engineering the Raspberry Pi Camera V2: A study of Pixel
  Non-Uniformity using a Scanning Electron Microscope</title><categories>eess.IV</categories><comments>16 pages, 8 figures, 2 tables, paper is part of a thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we reverse engineer the Sony IMX219PQ image sensor, otherwise
known as the Raspberry Pi Camera v2.0. We provide a visual reference for pixel
non-uniformity by analysing variations in transistor length, microlens optic
system and in the photodiode. We use these measurements to demonstrate
irregularities at the microscopic level and link this to the signal variation
measured as pixel non-uniformity used for unique identification of discrete
image sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03808</identifier>
 <datestamp>2020-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03808</id><created>2019-01-12</created><updated>2020-01-14</updated><authors><author><keyname>Chen</keyname><forenames>Huangxun</forenames></author><author><keyname>Huang</keyname><forenames>Chenyu</forenames></author><author><keyname>Huang</keyname><forenames>Qianyi</forenames></author><author><keyname>Zhang</keyname><forenames>Qian</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author></authors><title>ECGadv: Generating Adversarial Electrocardiogram to Misguide Arrhythmia
  Classification System</title><categories>cs.LG eess.SP stat.ML</categories><comments>Accepted by AAAI 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks (DNNs)-powered Electrocardiogram (ECG) diagnosis systems
recently achieve promising progress to take over tedious examinations by
cardiologists. However, their vulnerability to adversarial attacks still lack
comprehensive investigation. The existing attacks in image domain could not be
directly applicable due to the distinct properties of ECGs in visualization and
dynamic properties. Thus, this paper takes a step to thoroughly explore
adversarial attacks on the DNN-powered ECG diagnosis system. We analyze the
properties of ECGs to design effective attacks schemes under two attacks models
respectively. Our results demonstrate the blind spots of DNN-powered diagnosis
systems under adversarial attacks, which calls attention to adequate
countermeasures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03844</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03844</id><created>2019-01-12</created><authors><author><keyname>Li</keyname><forenames>Ang</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Multiplexing More Streams in the MU-MISO Downlink by Interference
  Exploitation Precoding</title><categories>eess.SP</categories><comments>6 pages, submitted to IEEE ICC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the interference exploitation precoding for the
scenario where the number of streams simultaneously transmitted by the base
station (BS) is larger than that of transmit antennas at the BS, and derive the
optimal precoding structure by employing the pseudo inverse. We show that the
optimal pre-scaling vector is equal to a linear combination of the right
singular vectors that correspond to zero singular values of the coefficient
matrix. By formulating the dual problem, the optimal precoding matrix can be
expressed as a function of the dual variables in a closed form, and an
equivalent quadratic programming (QP) formulation is further derived for
computational complexity reduction. Numerical results validate our analysis and
demonstrate significant performance improvements for interference exploitation
precoding for the considered scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03860</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03860</id><created>2019-01-12</created><authors><author><keyname>Seth</keyname><forenames>Harshita</forenames></author><author><keyname>Kumar</keyname><forenames>Pulkit</forenames></author><author><keyname>Srivastava</keyname><forenames>Muktabh Mayank</forenames></author></authors><title>Prototypical Metric Transfer Learning for Continuous Speech Keyword
  Spotting With Limited Training Data</title><categories>cs.SD cs.CL cs.LG eess.AS stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Continuous Speech Keyword Spotting (CSKS) is the problem of spotting keywords
in recorded conversations, when a small number of instances of keywords are
available in training data. Unlike the more common Keyword Spotting, where an
algorithm needs to detect lone keywords or short phrases like &quot;Alexa&quot;,
&quot;Cortana&quot;, &quot;Hi Alexa!&quot;, &quot;Whatsup Octavia?&quot; etc. in speech, CSKS needs to filter
out embedded words from a continuous flow of speech, ie. spot &quot;Anna&quot; and
&quot;github&quot; in &quot;I know a developer named Anna who can look into this github
issue.&quot; Apart from the issue of limited training data availability, CSKS is an
extremely imbalanced classification problem. We address the limitations of
simple keyword spotting baselines for both aforementioned challenges by using a
novel combination of loss functions (Prototypical networks' loss and metric
loss) and transfer learning. Our method improves F1 score by over 10%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03893</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03893</id><created>2019-01-12</created><updated>2019-02-07</updated><authors><author><keyname>Guo</keyname><forenames>Shuaishuai</forenames></author><author><keyname>Zhang</keyname><forenames>Haixia</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>MIMO Capacity with Reduced RF Chains</title><categories>eess.SP</categories><comments>MIMO Capacity, Reduced RF Chain, submitted to IEEE TCOM</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a remarkable advance for the understanding of MIMO
capacity limits with insufficient RF chains. The capacity is characterized by
the maximum mutual information given any vector inputs subject to not only an
average power constraint but also a sparsity constraint. It is proven that the
Gaussian mixture input distribution is capacity-achieving in the high
signal-to-noise-ratio (SNR) regime. The optimal mixture coefficients and the
covariance matrices of the Gaussian mixtures are derived and also the
corresponding achievable capacity. For the special case with a single RF chain,
the optimal mixture coefficients are shown to be approximately proportional to
channel gains. The capacity is approximately the maximum-ratio combining (MRC)
of multiple channels in the high SNR regime. We investigate the superiority of
capacity-achieving techniques: Non-Uniform Spatial Modulation (NUSM) and
Non-Uniform Beamspace Modulation (NUBM) by comparing them with the best
antenna/beamspace selection (BAS/BBS) and the uniform spatial/beamspace
modulation (USM/UBM). The comparison results reveal that the information-guided
NUSM/NUBM is optimal in the high SNR regime. Numerical results are presented to
validate our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03898</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03898</id><created>2019-01-12</created><authors><author><keyname>Mazidi</keyname><forenames>Hesam</forenames></author><author><keyname>King</keyname><forenames>Eshan S.</forenames></author><author><keyname>Zhang</keyname><forenames>Oumeng</forenames></author><author><keyname>Nehorai</keyname><forenames>Arye</forenames></author><author><keyname>Lew</keyname><forenames>Matthew D.</forenames></author></authors><title>Dense Super-Resolution Imaging of Molecular Orientation via Joint Sparse
  Basis Deconvolution and Spatial Pooling</title><categories>eess.IV physics.data-an physics.optics q-bio.QM</categories><comments>Copyright 2019 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</comments><journal-ref>2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI
  2019), 325 (2019)</journal-ref><doi>10.1109/isbi.2019.8759444</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In single-molecule super-resolution microscopy, engineered point-spread
functions (PSFs) are designed to efficiently encode new molecular properties,
such as 3D orientation, into complex spatial features captured by a camera. To
fully benefit from their optimality, algorithms must estimate multi-dimensional
parameters such as molecular position and orientation in the presence of PSF
overlap and model-experiment mismatches. Here, we present a novel joint sparse
deconvolution algorithm based on the decomposition of fluorescence images into
six basis images that characterize molecular orientation. The proposed
algorithm exploits a group-sparsity structure across these basis images and
applies a pooling strategy on corresponding spatial features for robust
simultaneous estimates of the number, brightness, 2D position, and 3D
orientation of fluorescent molecules. We demonstrate this method by imaging DNA
transiently labeled with the intercalating dye YOYO-1. Imaging the position and
orientation of each molecule reveals orientational order and disorder within
DNA with nanoscale spatial precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03906</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03906</id><created>2019-01-12</created><authors><author><keyname>Rakowski</keyname><forenames>Alexander G.</forenames><affiliation>University of Cambridge - Computer Laboratory</affiliation></author><author><keyname>Veli&#x10d;kovi&#x107;</keyname><forenames>Petar</forenames><affiliation>University of Cambridge - Computer Laboratory</affiliation></author><author><keyname>Dall'Ara</keyname><forenames>Enrico</forenames><affiliation>University of Sheffield - Department of Oncology &amp; Metabolism</affiliation></author><author><keyname>Li&#xf2;</keyname><forenames>Pietro</forenames><affiliation>University of Cambridge - Computer Laboratory</affiliation></author></authors><title>ChronoMID - Cross-Modal Neural Networks for 3-D Temporal Medical Imaging
  Data</title><categories>eess.IV cs.LG stat.ML</categories><comments>8 pages, 7 figures, 2 tables</comments><acm-class>J.3; I.4.0; I.2.6; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ChronoMID builds on the success of cross-modal convolutional neural networks
(X-CNNs), making the novel application of the technique to medical imaging
data. Specifically, this paper presents and compares alternative approaches -
timestamps and difference images - to incorporate temporal information for the
classification of bone disease in mice, applied to micro-CT scans of mouse
tibiae. Whilst much previous work on diseases and disease classification has
been based on mathematical models incorporating domain expertise and the
explicit encoding of assumptions, the approaches given here utilise the growing
availability of computing resources to analyse large datasets and uncover
subtle patterns in both space and time. After training on a balanced set of
over 75000 images, all models incorporating temporal features outperformed a
state-of-the-art CNN baseline on an unseen, balanced validation set comprising
over 20000 images. The top-performing model achieved 99.54% accuracy, compared
to 73.02% for the CNN baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03940</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03940</id><created>2019-01-13</created><updated>2019-06-03</updated><authors><author><keyname>Yonel</keyname><forenames>Bariscan</forenames></author><author><keyname>Yazici</keyname><forenames>Birsen</forenames></author></authors><title>A Generalization of Wirtinger Flow for Exact Interferometric Inversion</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to SIAM Journal on Imaging Sciences</comments><doi>10.1137/19M1238599</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interferometric inversion involves recovery of a signal from
cross-correlations of its linear transformations. A close relative of
interferometric inversion is the generalized phase retrieval problem, which
consists of recovering a signal from the auto-correlations of its linear
transformations. Recently, significant advancements have been made in phase
retrieval methods despite the ill-posed, and non-convex nature of the problem.
One such method is Wirtinger Flow (WF), a non-convex optimization framework
that provides high probability guarantees of exact recovery under certain
measurement models, such as coded diffraction patterns, and Gaussian sampling
vectors. In this paper, we develop a generalization of WF for interferometric
inversion, which we refer to as Generalized Wirtinger Flow (GWF). GWF theory
extends the probabilistic exact recovery results of WF to arbitrary measurement
models characterized in the equivalent lifted problem, hence covers a larger
class of measurement models. Our framework unifies the theory of low rank
matrix recovery (LRMR) and the non-convex optimization approach of WF, thereby
establishes theoretical advantages of the non-convex approach over LRMR. We
identify a new sufficient condition on the lifted forward model that directly
implies exact recovery conditions of standard WF. This condition is less
stringent than those of LRMR, which is the state of the art approach for exact
interferometric inversion. We establish our sufficient condition for the
cross-correlations of linear measurements collected by complex Gaussian
sampling vectors, and show that the exact recovery conditions of standard WF
imply our sufficient condition. As a result, the regularity condition of WF
becomes redundant in solving the interferometric inversion problem. Finally, we
demonstrate the effectiveness of GWF numerically in a deterministic
multi-static radar imaging scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.03953</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.03953</id><created>2019-01-13</created><authors><author><keyname>Kotaru</keyname><forenames>Manikanta</forenames></author><author><keyname>Satat</keyname><forenames>Guy</forenames></author><author><keyname>Raskar</keyname><forenames>Ramesh</forenames></author><author><keyname>Katti</keyname><forenames>Sachin</forenames></author></authors><title>Light-Field for RF</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most computer vision systems and computational photography systems are
visible light based which is a small fraction of the electromagnetic (EM)
spectrum. In recent years radio frequency (RF) hardware has become more widely
available, for example, many cars are equipped with a RADAR, and almost every
home has a WiFi device. In the context of imaging, RF spectrum holds many
advantages compared to visible light systems. In particular, in this regime, EM
energy effectively interacts in different ways with matter. This property
allows for many novel applications such as privacy preserving computer vision
and imaging through absorbing and scattering materials in visible light such as
walls. Here, we expand many of the concepts in computational photography in
visible light to RF cameras. The main limitation of imaging with RF is the
large wavelength that limits the imaging resolution when compared to visible
light. However, the output of RF cameras is usually processed by computer
vision and perception algorithms which would benefit from multi-modal sensing
of the environment, and from sensing in situations in which visible light
systems fail. To bridge the gap between computational photography and RF
imaging, we expand the concept of light-field to RF. This work paves the way to
novel computational sensing systems with RF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04058</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04058</id><created>2019-01-13</created><authors><author><keyname>Wei</keyname><forenames>Zhongxiang</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author><author><keyname>Kang</keyname><forenames>Xin</forenames></author></authors><title>Multi-Cell Interference Exploitation: A New Dimension in Cell
  Coordination</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a series of novel coordination schemes for
multi-cell downlink communication. Starting from full base station (BS)
coordination, we first propose a fully-coordinated scheme to exploit beneficial
effects of both inter-cell and intra-cell interference, based on sharing both
channel state information (CSI) and data among the BSs. To reduce the
coordination overhead, we then propose a partially-coordinated scheme where
only intra-cell interference is designed to be constructive while inter-cell is
jointly suppressed by the coordinated BSs. Accordingly, the coordination only
involves CSI exchange and the need for sharing data is eliminated. To further
reduce the coordination overhead, a third scheme is proposed, which only
requires the knowledge of statistical inter-cell channels, at the cost of a
slight increase on the transmission power. For all the proposed schemes,
imperfect CSI is considered. We minimize the total transmission power in terms
of probabilistic and deterministic optimizations. Explicitly, the former
statistically satisfies the users' signal-to-interference-plus-noise ratio
(SINR) while the latter guarantees the SINR requirements in the worst case CSI
uncertainties. Simulation verifies that our schemes consume much lower power
compared to the existing benchmarks, i.e., coordinated multi-point (CoMP) and
coordinated-beamforming (CBF) systems, opening a new dimension on multi-cell
coordination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04110</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04110</id><created>2019-01-13</created><authors><author><keyname>Crangle</keyname><forenames>Colleen E.</forenames></author><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Perreau-Guimaraes</keyname><forenames>Marcos</forenames></author><author><keyname>Nguyen</keyname><forenames>Michelle U.</forenames></author><author><keyname>Nguyen</keyname><forenames>Duc T.</forenames></author><author><keyname>Suppes</keyname><forenames>Patrick</forenames></author></authors><title>Machine learning for the recognition of emotion in the speech of couples
  in psychotherapy using the Stanford Suppes Brain Lab Psychotherapy Dataset</title><categories>cs.SD cs.HC eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The automatic recognition of emotion in speech can inform our understanding
of language, emotion, and the brain. It also has practical application to
human-machine interactive systems. This paper examines the recognition of
emotion in naturally occurring speech, where there are no constraints on what
is said or the emotions expressed. This task is more difficult than that using
data collected in scripted, experimentally controlled settings, and fewer
results are published. Our data come from couples in psychotherapy. Video and
audio recordings were made of three couples (A, B, C) over 18 hour-long therapy
sessions. This paper describes the method used to code the audio recordings for
the four emotions of Anger, Sadness, Joy and Tension, plus Neutral, also
covering our approach to managing the unbalanced samples that a naturally
occurring emotional speech dataset produces. Three groups of acoustic features
were used in our analysis: filter-bank, frequency, and voice-quality features.
The random forests model classified the features. Recognition rates are
reported for each individual, the result of the speaker-dependent models that
we built. In each case, the best recognition rates were achieved using the
filter-bank features alone. For Couple A, these rates were 90% for the female
and 87% for the male for the recognition of three emotions plus Neutral. For
Couple B, the rates were 84% for the female and 78% for the male for the
recognition of all four emotions plus Neutral. For Couple C, a rate of 88% was
achieved for the female for the recognition of the four emotions plus Neutral
and 95% for the male for three emotions plus Neutral. For pairwise recognition,
the rates ranged from 76% to 99% across the three couples. Our results show
that couple therapy is a rich context for the study of emotion in naturally
occurring speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04119</identifier>
 <datestamp>2019-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04119</id><created>2019-01-13</created><updated>2019-04-17</updated><authors><author><keyname>Huangfu</keyname><forenames>Yourui</forenames></author><author><keyname>Wang</keyname><forenames>Jian</forenames></author><author><keyname>Li</keyname><forenames>Rong</forenames></author><author><keyname>Xu</keyname><forenames>Chen</forenames></author><author><keyname>Wang</keyname><forenames>Xianbin</forenames></author><author><keyname>Zhang</keyname><forenames>Huazi</forenames></author><author><keyname>Wang</keyname><forenames>Jun</forenames></author></authors><title>Predicting the Mumble of Wireless Channel with Sequence-to-Sequence
  Models</title><categories>eess.SP cs.IT math.IT</categories><comments>7 pages, 7 figures, updated figure 6&amp;7, added references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate prediction of fading channel in the upcoming transmission frame is
essential to realize adaptive transmission for transmitters, and receivers with
the ability of channel prediction can also save some computations of channel
estimation. However, due to the rapid channel variation and channel estimation
error, reliable prediction is hard to realize. In this situation, an
appropriate channel model should be selected, which can cover both the
statistical model and small scale fading of channel, this reminds us the
natural languages, which also have statistical word frequency and specific
sentences. Accordingly, in this paper, we take wireless channel model as a
language model, and the time-varying channel as talking in this language, while
the realistic noisy estimated channel can be compared with mumbling.
Furthermore, in order to utilize as much as possible the information a channel
coefficient takes, we discard the conventional two features of absolute value
and phase, replacing with hundreds of features which will be learned by our
channel model, to do this, we use a vocabulary to map a complex channel
coefficient into an ID, which is represented by a vector of real numbers.
Recurrent neural networks technique is used as its good balance between
memorization and generalization, moreover, we creatively introduce
sequence-to-sequence (seq2seq) models in time series channel prediction, which
can translates past channel into future channel. The results show that
realistic channel prediction with superior performance relative to channel
estimation is attainable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04141</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04141</id><created>2019-01-14</created><authors><author><keyname>Teng</keyname><forenames>Jiajie</forenames></author><author><keyname>Guo</keyname><forenames>Qiang</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author><author><keyname>Yang</keyname><forenames>Sigang</forenames></author><author><keyname>Chen</keyname><forenames>Hongwei</forenames></author></authors><title>Time-encoded single-pixel 3D imaging</title><categories>physics.optics eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently three-dimensional (3D) imaging achieves tremendous success in
consumer and industrial manufacturing. However, current 3D imaging methods
rarely observe dynamical events happening in a short time interval due to the
imaging speed limitation. Here we propose a time-encoded single-pixel 3D
(TESP-3D) imaging method based on active infrared imaging with high-speed
structured illumination, which can acquire the 3D information of dynamic events
at an ultra-high frame rate. This method uses single-pixel photodetectors
instead of conventional CCD or CMOS devices as the imaging sensors to overcome
the image capturing speed limitation. As a proof of concept, we perform
continuous real-time 3D scanning imaging at a record 500,000 fps and acquire 3D
information of objects moving at a speed of up to 25 m/s. We anticipate that
this technology will have important applications in industrial on-line
inspection and high throughput 3D screening.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04157</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04157</id><created>2019-01-14</created><authors><author><keyname>Zhou</keyname><forenames>Mingyong</forenames></author></authors><title>A Spatio-temporal Spreading Communication Technique and its Applications</title><categories>eess.SP</categories><comments>Full paper was accepted into proceedings of 4th International
  Conference on Innovation in Computing System &amp; Engineering Technology (
  ICICSET 2018) in Zurich, Switzerland on August 14- 15, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address a fundamental question in communication, that is, in
the presence of various noise scenarios such as white/colored Gaussian noise
and impulsive -type noises, how to efficiently and accurately transmit a set of
various signals either they are speeches or images from one side into another
via a communication channel? We need to manipulate the various signals in a way
so that they are more robust to different types of noises while at the same
time the set of signals can be efficiently and accurately transmitted into
another side via a communication channel. In this paper we propose a
spatial-temporal spreading method for a set of signals and show its
applications in communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04249</identifier>
 <datestamp>2019-01-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04249</id><created>2019-01-14</created><updated>2019-01-18</updated><authors><author><keyname>Balti</keyname><forenames>Elyes</forenames></author><author><keyname>Johnson</keyname><forenames>Brian K.</forenames></author></authors><title>Asymmetric RF/FSO Relaying with HPA non-Linearities and Feedback Delay
  Constraints</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we investigate the performance of a dual-hop multiple relays
system consisting of mixed Radio-Frequency (RF)/Free Space Optical (FSO)
channels. The RF channels are subject to Rayleigh fading while the optical
links experience the Double Generalized Gamma including atmospheric turbulence,
path loss and the misalignment between the transmitter and the receiver
aperture (also known as the pointing error). The FSO model also takes into
account the receiver detection technique which could be either heterodyne or
intensity modulation and direct detection. Partial Relay Selection with
outdated Channel State Information is assumed based on the RF channels to
select a relay and we also consider fixed and variable Amplify-and-Forward
relaying schemes. In addition, we assume that the relays are affected by the
high power amplifier non-linearities and herein we discuss two power amplifiers
called Soft Envelope Limiter and Traveling Wave Tube Amplifier. Furthermore,
novel closed-forms and tight upper bounds of the outage probability, the bit
error probability, and the ergodic capacity are derived. Capitalizing on these
performance, we derive the high SNR asymptotic to get engineering insights
about the system gains such as the diversity and the coding gains. Finally, the
mathematical expressions are validated using the Monte Carlo simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04276</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04276</id><created>2019-01-14</created><authors><author><keyname>Tits</keyname><forenames>No&#xe9;</forenames></author><author><keyname>Haddad</keyname><forenames>Kevin El</forenames></author><author><keyname>Dutoit</keyname><forenames>Thierry</forenames></author></authors><title>Exploring Transfer Learning for Low Resource Emotional TTS</title><categories>cs.SD cs.CL eess.AS</categories><comments>Accepted at IntelliSys 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the last few years, spoken language technologies have known a big
improvement thanks to Deep Learning. However Deep Learning-based algorithms
require amounts of data that are often difficult and costly to gather.
Particularly, modeling the variability in speech of different speakers,
different styles or different emotions with few data remains challenging. In
this paper, we investigate how to leverage fine-tuning on a pre-trained Deep
Learning-based TTS model to synthesize speech with a small dataset of another
speaker. Then we investigate the possibility to adapt this model to have
emotional TTS by fine-tuning the neutral TTS model with a small emotional
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04295</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04295</id><created>2018-12-25</created><authors><author><keyname>Yang</keyname><forenames>Damao</forenames></author><author><keyname>Peng</keyname><forenames>Sihan</forenames></author><author><keyname>Huang</keyname><forenames>He</forenames></author><author><keyname>Xue</keyname><forenames>Hongliang</forenames></author></authors><title>On-Demand Video Dispatch Networks: A Scalable End-to-End Learning
  Approach</title><categories>cs.NI cs.LG cs.SY eess.IV stat.ML</categories><comments>12 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a dispatch system to improve the peak service quality of video on
demand (VOD). Our system predicts the hot videos during the peak hours of the
next day based on the historical requests, and dispatches to the content
delivery networks (CDNs) at the previous off-peak time. In order to scale to
billions of videos, we build the system with two neural networks, one for video
clustering and the other for dispatch policy developing. The clustering network
employs autoencoder layers and reduces the video number to a fixed value. The
policy network employs fully connected layers and ranks the clustered videos
with dispatch probabilities. The two networks are coupled with weight-sharing
temporal layers, which analyze the video request sequences with convolutional
and recurrent modules. Therefore, the clustering and dispatch tasks are trained
in an end-to-end mechanism. The real-world results show that our approach
achieves an average prediction accuracy of 17%, compared with 3% from the
present baseline method, for the same amount of dispatches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04327</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04327</id><created>2019-01-14</created><authors><author><keyname>Yao</keyname><forenames>Jun-Liang</forenames></author><author><keyname>Sun</keyname><forenames>Yu-Zhe</forenames></author><author><keyname>Ren</keyname><forenames>Hai-Peng</forenames></author><author><keyname>Grebogi</keyname><forenames>Celso</forenames></author></authors><title>Experimental Wireless Communication Using Chaotic Baseband Waveform</title><categories>eess.SP nlin.CD</categories><comments>15 pages, 17 figures</comments><journal-ref>IEEE Transactions on Vehicular Technology, PP(99):1-1, November
  2018</journal-ref><doi>10.1109/TVT.2018.2882422</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some new properties of the chaotic signal have been implemented in
communication system applications recently. However, due to the broadband
property of the chaotic signal, it is very difficult for a practical transducer
or antenna to convert such a broadband signal into a signal that would be
suitable for practical band-limited wireless channel. Thus, the use of chaos
property to improve the performance of conventional communication system
without changing the system configuration becomes a critical issue in
communication with chaos. In this paper, chaotic baseband waveform generated by
a chaotic shaping filter is used to show that this difficulty can be overcome.
The generated continuous-time chaotic waveform is proven to be topologically
conjugate to a symbolic sequence, allowing the encoding of arbitrary
information sequence into the chaotic waveform. A finite impulse response
filter is used to replace the impulse control in order to encode information
into the chaotic signal, simplifying the algorithm for high speed
communication. A wireless communication system is being proposed using the
chaotic signal as the baseband waveform, which is compatible with the general
wireless communication platform. The matched filter and decoding method, using
chaos properties, enhance the communication system performance. The Bit Error
Rate (BER) and computational complexity performances of the proposed wireless
communication system are analyzed and compared with the conventional wireless
systems. The results show that the proposed chaotic baseband waveform of our
wireless communication method has better BER performance in both the static and
time-varying wireless channels. The experimental results, based on the
commonly-used wireless open-access research platform, show that the BER of the
proposed method is superior to the conventional method under a practical
wireless multipath channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04420</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04420</id><created>2019-01-14</created><authors><author><keyname>Paschali</keyname><forenames>Magdalini</forenames></author><author><keyname>Simson</keyname><forenames>Walter</forenames></author><author><keyname>Roy</keyname><forenames>Abhijit Guha</forenames></author><author><keyname>Naeem</keyname><forenames>Muhammad Ferjad</forenames></author><author><keyname>G&#xf6;bl</keyname><forenames>R&#xfc;diger</forenames></author><author><keyname>Wachinger</keyname><forenames>Christian</forenames></author><author><keyname>Navab</keyname><forenames>Nassir</forenames></author></authors><title>Data Augmentation with Manifold Exploring Geometric Transformations for
  Increased Performance and Robustness</title><categories>cs.LG eess.IV stat.ML</categories><comments>Under Review for the 26th International Conference on Information
  Processing in Medical Imaging (IPMI) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a novel augmentation technique that improves not
only the performance of deep neural networks on clean test data, but also
significantly increases their robustness to random transformations, both affine
and projective. Inspired by ManiFool, the augmentation is performed by a
line-search manifold-exploration method that learns affine geometric
transformations that lead to the misclassification on an image, while ensuring
that it remains on the same manifold as the training data.
  This augmentation method populates any training dataset with images that lie
on the border of the manifolds between two-classes and maximizes the variance
the network is exposed to during training. Our method was thoroughly evaluated
on the challenging tasks of fine-grained skin lesion classification from
limited data, and breast tumor classification of mammograms. Compared with
traditional augmentation methods, and with images synthesized by Generative
Adversarial Networks our method not only achieves state-of-the-art performance
but also significantly improves the network's robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04555</identifier>
 <datestamp>2019-03-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04555</id><created>2019-01-14</created><updated>2019-03-14</updated><authors><author><keyname>Nasrullah</keyname><forenames>Zain</forenames></author><author><keyname>Zhao</keyname><forenames>Yue</forenames></author></authors><title>Music Artist Classification with Convolutional Recurrent Neural Networks</title><categories>cs.SD cs.LG cs.MM eess.AS stat.ML</categories><comments>Proceedings of the 2019 International Joint Conference on Neural
  Networks (IJCNN)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous attempts at music artist classification use frame level audio
features which summarize frequency content within short intervals of time.
Comparatively, more recent music information retrieval tasks take advantage of
temporal structure in audio spectrograms using deep convolutional and recurrent
models. This paper revisits artist classification with this new framework and
empirically explores the impacts of incorporating temporal structure in the
feature representation. To this end, an established classification
architecture, a Convolutional Recurrent Neural Network (CRNN), is applied to
the artist20 music artist identification dataset under a comprehensive set of
conditions. These include audio clip length, which is a novel contribution in
this work, and previously identified considerations such as dataset split and
feature level. Our results improve upon baseline works, verify the influence of
the producer effect on classification performance and demonstrate the
trade-offs between audio length and training set size. The best performing
model achieves an average F1 score of 0.937 across three independent trials
which is a substantial improvement over the corresponding baseline under
similar conditions. Additionally, to showcase the effectiveness of the CRNN's
feature extraction capabilities, we visualize audio samples at the model's
bottleneck layer demonstrating that learned representations segment into
clusters belonging to their respective artists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04618</identifier>
 <datestamp>2019-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04618</id><created>2019-01-14</created><authors><author><keyname>Wang</keyname><forenames>Zhengwei</forenames></author><author><keyname>Healy</keyname><forenames>Graham</forenames></author><author><keyname>Smeaton</keyname><forenames>Alan F.</forenames></author><author><keyname>Ward</keyname><forenames>Tomas E.</forenames></author></authors><title>Spatial Filtering Pipeline Evaluation of Cortically Coupled Computer
  Vision System for Rapid Serial Visual Presentation</title><categories>eess.IV cs.CV eess.SP</categories><doi>10.1080/2326263X.2019.1568821</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rapid Serial Visual Presentation (RSVP) is a paradigm that supports the
application of cortically coupled computer vision to rapid image search. In
RSVP, images are presented to participants in a rapid serial sequence which can
evoke Event-related Potentials (ERPs) detectable in their Electroencephalogram
(EEG). The contemporary approach to this problem involves supervised spatial
filtering techniques which are applied for the purposes of enhancing the
discriminative information in the EEG data. In this paper we make two primary
contributions to that field: 1) We propose a novel spatial filtering method
which we call the Multiple Time Window LDA Beamformer (MTWLB) method; 2) we
provide a comprehensive comparison of nine spatial filtering pipelines using
three spatial filtering schemes namely, MTWLB, xDAWN, Common Spatial Pattern
(CSP) and three linear classification methods Linear Discriminant Analysis
(LDA), Bayesian Linear Regression (BLR) and Logistic Regression (LR). Three
pipelines without spatial filtering are used as baseline comparison. The Area
Under Curve (AUC) is used as an evaluation metric in this paper. The results
reveal that MTWLB and xDAWN spatial filtering techniques enhance the
classification performance of the pipeline but CSP does not. The results also
support the conclusion that LR can be effective for RSVP based BCI if
discriminative features are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04690</identifier>
 <datestamp>2019-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04690</id><created>2019-01-15</created><authors><author><keyname>Choe</keyname><forenames>Soyeon</forenames></author><author><keyname>Chung</keyname><forenames>Soo-Whan</forenames></author><author><keyname>Ji</keyname><forenames>Youna</forenames></author><author><keyname>Kang</keyname><forenames>Hong-Goo</forenames></author></authors><title>Orthonormal Embedding-based Deep Clustering for Single-channel Speech
  Separation</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep clustering is a deep neural network-based speech separation algorithm
that first trains the mixed component of signals with high-dimensional
embeddings, and then uses a clustering algorithm to separate each mixture of
sources. In this paper, we extend the baseline criterion of deep clustering
with an additional regularization term to further improve the overall
performance. This term plays a role in assigning a condition to the embeddings
such that it gives less correlation to each embedding dimension, leading to
better decomposition of the spectral bins. The regularization term helps to
mitigate the unavoidable permutation problem in the conventional deep
clustering method, which enables to bring better clustering through the
formation of optimal embeddings. We evaluate the results by varying embedding
dimension, signal-to-interference ratio (SIR), and gender dependency. The
performance comparison with the source separation measurement metric, i.e.
signal-to-distortion ratio (SDR), confirms that the proposed method outperforms
the conventional deep clustering method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04696</identifier>
 <datestamp>2019-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04696</id><created>2019-01-15</created><authors><author><keyname>Malekzadeh</keyname><forenames>Saber</forenames></author><author><keyname>Samami</keyname><forenames>Maryam</forenames></author><author><keyname>RezazadehAzar</keyname><forenames>Shahla</forenames></author><author><keyname>Rayegan</keyname><forenames>Maryam</forenames></author></authors><title>Classical Music Generation in Distinct Dastgahs with AlimNet ACGAN</title><categories>cs.SD cs.LG eess.AS</categories><doi>10.13140/RG.2.2.32101.65765</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper AlimNet (With respect to great musician, Alim Qasimov) an
auxiliary generative adversarial deep neural network (ACGAN) for generating
music categorically, is used. This proposed network is a conditional ACGAN to
condition the generation process on music tracks which has a hybrid
architecture, composing of different kind of layers of neural networks. The
employed music dataset is MICM which contains 1137 music samples (506 violins
and 631 straw) with seven types of classical music Dastgah labels. To extract
both temporal and spectral features, Short-Time Fourier Transform (STFT) is
applied to convert input audio signals from time domain to time-frequency
domain. GANs are composed of a generator for generating new samples and a
discriminator to help generator making better samples. Samples in
time-frequency domain are used to train discriminator in fourteen classes
(seven Dastgahs and two instruments). The outputs of the conditional ACGAN are
also artificial music samples in those mentioned scales in time-frequency
domain. Then the output of the generator is transformed by Inverse STFT
(ISTFT). Finally, randomly ten generated music samples (five violin and five
straw samples) are given to ten musicians to rate how exact the samples are and
the overall result was 76.5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04699</identifier>
 <datestamp>2019-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04699</id><created>2019-01-15</created><authors><author><keyname>Malekzadeh</keyname><forenames>Saber</forenames></author></authors><title>Phoneme-Based Persian Speech Recognition</title><categories>cs.SD cs.LG eess.AS</categories><comments>in Farsi</comments><doi>10.13140/RG.2.2.32856.96007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Undoubtedly, one of the most important issues in computer science is
intelligent speech recognition. In these systems, computers try to detect and
respond to the speeches they are listening to, like humans. In this research,
presenting of a suitable method for the diagnosis of Persian phonemes by AI
using the signal processing and classification algorithms have tried. For this
purpose, the STFT algorithm has been used to process the audio signals, as well
as to detect and classify the signals processed by the deep artificial neural
network. At first, educational samples were provided as two phonological
phrases in Persian language and then signal processing operations were
performed on them. Then the results for the data training have been given to
the artificial deep neural network. At the final stage, the experiment was
conducted on new sounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04872</identifier>
 <datestamp>2019-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04872</id><created>2019-01-14</created><authors><author><keyname>Zhou</keyname><forenames>Mingyong</forenames></author></authors><title>Electrical Impedance Tomography based on Genetic Algorithm</title><categories>eess.IV cs.CV</categories><comments>Full paper was accepted into proceedings of 4th International
  Conference on Innovation in Computing System &amp; Engineering Technology (
  ICICSET 2018) in Zurich, Switzerland on August 14- 15, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we applies GA algorithm into Electrical Impedance Tomography
(EIT) application. We first outline the EIT problem as an optimization problem
and define a target optimization function. Then we show how the GA algorithm as
an alternative searching algorithm can be used for solving EIT inverse problem.
In this paper, we explore evolutionary methods such as GA algorithms combined
with various regularization operators to solve EIT inverse computing problem.
  Key words: Electrical Impedance Tomography (EIT), GA, Tikhonov operator ,
Mumford-Shah operator, Particle Swarm Optimization(PSO), Back Propagation(BP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04914</identifier>
 <datestamp>2019-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04914</id><created>2019-01-15</created><authors><author><keyname>Forouzesh</keyname><forenames>Moslem</forenames></author><author><keyname>Azmi</keyname><forenames>Paeiz</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Goeckel</keyname><forenames>Dennis</forenames></author></authors><title>Robust Power Allocation in Covert Communication: Imperfect CDI</title><categories>eess.SP</categories><comments>11 page, 5 figures, one table</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The study of the fundamental limits of covert communications, where a
transmitter Alice wants to send information to a desired recipient Bob without
detection of that transmission by an attentive and capable warden Willie, has
emerged recently as a topic of great research interest. Critical to these
analyses is a characterization of the detection problem that is presented to
Willie. Previous work has assumed that the channel distribution information
(CDI) is known to Alice, hence facilitating her characterization of Willie's
capabilities to detect the signal. However, in practice, Willie tends to be
passive and the environment heterogeneous, implying a lack of signaling
interchange between the transmitter and Willie makes it difficult if not
impossible for Alice to estimate the CDI exactly and provide covertness
guarantees. In this paper, we address this issue by developing covert
communication schemes for various assumptions on Alice's imperfect knowledge of
the CDI: 1) when the transmitter knows the channel distribution is within some
distance of a nominal channel distribution; 2) when only the mean and variance
of the channel distribution are available at Alice; 3) when Alice knows the
channel distribution is complex Gaussian but the variance is unknown. In each
case, we formulate new optimization problems to find the power allocations that
maximize covert rate subject to a covertness requirement under uncertain CDI.
Moreover, since Willie faces similar challenges as Alice in estimating the CDI,
we investigate two possible assumptions on the knowledge of the CDI at Willie:
1) CDI is known at Willie, 2) CDI is unknown at Willie. Numerical results are
presented to compare the proposed schemes from various aspects, in particular
the accuracy and efficiency of the proposed solutions for attaining desirable
covert system performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04986</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04986</id><created>2018-12-15</created><updated>2019-02-08</updated><authors><author><keyname>Ahmad</keyname><forenames>Hazoor</forenames></author><author><keyname>Tanvir</keyname><forenames>Muhammad</forenames></author><author><keyname>Hanif</keyname><forenames>Muhammad Abdullah</forenames></author><author><keyname>Javed</keyname><forenames>Muhammad Usama</forenames></author><author><keyname>Hafiz</keyname><forenames>Rehan</forenames></author><author><keyname>Shafique</keyname><forenames>Muhammad</forenames></author></authors><title>Systimator: A Design Space Exploration Methodology for Systolic Array
  based CNNs Acceleration on the FPGA-based Edge Nodes</title><categories>cs.DC cs.LG eess.IV</categories><comments>5 Pages, 3 Figures, work in progress</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of IoT based smart applications demand porting of artificial
intelligence algorithms to the edge computing devices. CNNs form a large part
of these AI algorithms. Systolic array based CNN acceleration is being widely
advocated due its ability to allow scalable architectures. However, CNNs are
inherently memory and compute intensive algorithms, and hence pose significant
challenges to be implemented on the resource-constrained edge computing
devices. Memory-constrained low-cost FPGA based devices form a substantial
fraction of these edge computing devices. Thus, when porting to such
edge-computing devices, the designer is left unguided as to how to select a
suitable systolic array configuration that could fit in the available hardware
resources. In this paper we propose Systimator, a design space exploration
based methodology that provides a set of design points that can be mapped
within the memory bounds of the target FPGA device. The methodology is based
upon an analytical model that is formulated to estimate the required resources
for systolic arrays, assuming multiple data reuse patterns. The methodology
further provides the performance estimates for each of the candidate design
points. We show that Systimator provides an in-depth analysis of
resource-requirement of systolic array based CNNs. We provide our resource
estimation results for porting of convolutional layers of TINY YOLO, a CNN
based object detector, on a Xilinx ARTIX 7 FPGA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04989</identifier>
 <datestamp>2019-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04989</id><created>2018-12-10</created><authors><author><keyname>J&#xfa;nior</keyname><forenames>Carlos E. B. S.</forenames></author><author><keyname>Torquato</keyname><forenames>Matheus F.</forenames></author><author><keyname>Fernandes</keyname><forenames>Marcelo A. C.</forenames></author></authors><title>Application-Specific System Processor for the SHA-1 Hash Algorithm</title><categories>cs.DC cs.AR cs.CR eess.SP</categories><comments>20 pages, 5 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes an Application-Specific System Processor (ASSP) hardware
for the Secure Hash Algorithm 1 (SHA-1) algorithm. The proposed hardware was
implemented in a Field Programmable Gate Array (FPGA) Xilinx Virtex 6
xc6vlx240t-1ff1156. The throughput and the occupied area were analyzed for
several implementations in parallel instances of the hash algorithm. The
results showed that the hardware proposed for the SHA-1 achieved a throughput
of 0.644 Gbps for a single instance and slightly more than 28 Gbps for 48
instances in a single FPGA. Various applications such as password recovery,
password validation, and high volume data integrity checking can be performed
efficiently and quickly with an ASSP for SHA1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.04990</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.04990</id><created>2019-01-15</created><updated>2019-10-27</updated><authors><author><keyname>Iqbal</keyname><forenames>Sheikh Muhammad Asher</forenames></author><author><keyname>Butt</keyname><forenames>Nauman Zaffar</forenames></author></authors><title>Design and Analysis of Microfluidic Cell Counter using Spice Simulation</title><categories>q-bio.CB eess.SP</categories><comments>18 pages,10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microfluidic cytometers based on coulter principle have recently shown a
great potential for point of care biosensors for medical diagnostics. In this
study, the design of coulter based microfluidic cytometer is investigated by
using electrical circuit simulations. We explore the effects of physical
dimensions of the microelectrodes, the measurement volume, size/morphology of
the targeted cells, electrical properties of the reagents in the measurement
volume, and, the impedance of external readout circuit, on the sensitivity of
the sensor. We show that the effect of microelectrode's surface area and the
dielectric properties of the suspension medium should be carefully considered
when characterizing the output response of the sensor. In particular, the area
of microelectrodes can have significant effect on cells electrical opacity( the
ratio of the cell impedance at high to low frequency) which is commonly used to
distinguish between sub-population of the target cells( e.g. lymphocytes vs
monocytes when counting white blood cells).Moreover, we highlight that the
opacity response vs frequency can significantly vary depending upon whether the
absolute cell impedance or the differential output impedance is used in the
calculation. These insights can provide valuable guidelines for the design and
characterization of coulter based microfluidic sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05044</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05044</id><created>2019-01-15</created><authors><author><keyname>Esterer</keyname><forenames>Nicholas</forenames></author><author><keyname>Depalle</keyname><forenames>Philippe</forenames></author></authors><title>A linear programming approach to the tracking of partials</title><categories>eess.AS cs.SD eess.SP</categories><comments>5 pages, 1 pdf figure</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  A new approach to the tracking of sinusoidal chirps using linear programming
is proposed. It is demonstrated that the classical algorithm of McAulay and
Quatieri is greedy and exhibits exponential complexity for long searches, while
approaches based on the Viterbi algorithm exhibit factorial complexity. A
linear programming (LP) formulation to find the best $L$ paths in a lattice is
described and its complexity is shown to be less than previous approaches.
Finally it is demonstrated that the new LP formulation outperforms the
classical algorithm in the tracking of sinusoidal chirps in high levels of
noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05049</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05049</id><created>2019-01-15</created><authors><author><keyname>de Prado</keyname><forenames>Miguel</forenames></author><author><keyname>Su</keyname><forenames>Jing</forenames></author><author><keyname>Dahyot</keyname><forenames>Rozenn</forenames></author><author><keyname>Saeed</keyname><forenames>Rabia</forenames></author><author><keyname>Keller</keyname><forenames>Lorenzo</forenames></author><author><keyname>Vallez</keyname><forenames>Noelia</forenames></author></authors><title>AI Pipeline - bringing AI to you. End-to-end integration of data,
  algorithms and deployment tools</title><categories>cs.LG cs.DC cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next generation of embedded Information and Communication Technology (ICT)
systems are interconnected collaborative intelligent systems able to perform
autonomous tasks. Training and deployment of such systems on Edge devices
however require a fine-grained integration of data and tools to achieve high
accuracy and overcome functional and non-functional requirements. In this work,
we present a modular AI pipeline as an integrating framework to bring data,
algorithms and deployment tools together. By these means, we are able to
interconnect the different entities or stages of particular systems and provide
an end-to-end development of AI products. We demonstrate the effectiveness of
the AI pipeline by solving an Automatic Speech Recognition challenge and we
show that all the steps leading to an end-to-end development for Key-word
Spotting tasks: importing, partitioning and pre-processing of speech data,
training of different neural network architectures and their deployment on
heterogeneous embedded platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05061</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05061</id><created>2019-01-15</created><updated>2019-06-26</updated><authors><author><keyname>Sahai</keyname><forenames>Abhimanyu</forenames></author><author><keyname>Weber</keyname><forenames>Romann</forenames></author><author><keyname>McWilliams</keyname><forenames>Brian</forenames></author></authors><title>Spectrogram Feature Losses for Music Source Separation</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>Accepted for presentation at the 27th European Signal Processing
  Conference (EUSIPCO 2019)</comments><msc-class>62, 68</msc-class><acm-class>I.2.6; H.5.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study deep learning-based music source separation, and
explore using an alternative loss to the standard spectrogram pixel-level L2
loss for model training. Our main contribution is in demonstrating that adding
a high-level feature loss term, extracted from the spectrograms using a VGG
net, can improve separation quality vis-a-vis a pure pixel-level loss. We show
this improvement in the context of the MMDenseNet, a State-of-the-Art deep
learning model for this task, for the extraction of drums and vocal sounds from
songs in the musdb18 database, covering a broad range of western music genres.
We believe that this finding can be generalized and applied to broader machine
learning-based systems in the audio domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05097</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05097</id><created>2019-01-15</created><authors><author><keyname>Balti</keyname><forenames>Elyes</forenames></author><author><keyname>Guizani</keyname><forenames>Mohsen</forenames></author><author><keyname>Hamdaoui</keyname><forenames>Bechir</forenames></author><author><keyname>Maalej</keyname><forenames>Yassine</forenames></author></authors><title>Partial Relay Selection For Hybrid RF/FSO Systems with Hardware
  Impairments</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the performance analysis of dual hop relaying
system consisting of asymmetric Radio Frequency (RF)/Free Optical Space (FSO)
links. The RF channels follow a Rayleigh distribution and the optical links are
subject to Gamma-Gamma fading. We also introduce impairments to our model and
we suggest Partial Relay Selection (PRS) protocol with Amplify-and-Forward (AF)
fixed gain relaying. The benefits of employing optical communication with RF,
is to increase the system transfer rate and thus improving the system
bandwidth. Many previous research attempts assuming ideal hardware (source,
relays, etc.) without impairments. In fact, this assumption is still valid for
low-rate systems. However, these hardware impairments can no longer be
neglected for high-rate systems in order to get consistent results. Novel
analytical expressions of outage probability and ergodic capacity of our model
are derived taking into account ideal and non-ideal hardware cases.
Furthermore, we study the dependence of the outage probability and the system
capacity considering, the effect of the correlation between the outdated CSI
(Channel State Information) and the current source-relay link, the number of
relays, the rank of the selected relay and the average optical Signal to Noise
Ratio (SNR) over weak and strong atmospheric turbulence. We also demonstrate
that for a non-ideal case, the end-to-end Signal to Noise plus Distortion Ratio
(SNDR) has a certain ceiling for high SNR range. However, the SNDR grows
infinitely for the ideal case and the ceiling caused by impairments no longer
exists. Finally, numerical and simulation results are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05107</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05107</id><created>2019-01-15</created><authors><author><keyname>Deb</keyname><forenames>Debayan</forenames></author><author><keyname>Ross</keyname><forenames>Arun</forenames></author><author><keyname>Jain</keyname><forenames>Anil K.</forenames></author><author><keyname>Prakah-Asante</keyname><forenames>Kwaku</forenames></author><author><keyname>Prasad</keyname><forenames>K. Venkatesh</forenames></author></authors><title>Actions Speak Louder Than (Pass)words: Passive Authentication of
  Smartphone Users via Deep Temporal Features</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prevailing user authentication schemes on smartphones rely on explicit user
interaction, where a user types in a passcode or presents a biometric cue such
as face, fingerprint, or iris. In addition to being cumbersome and obtrusive to
the users, such authentication mechanisms pose security and privacy concerns.
Passive authentication systems can tackle these challenges by frequently and
unobtrusively monitoring the user's interaction with the device. In this paper,
we propose a Siamese Long Short-Term Memory network architecture for passive
authentication, where users can be verified without requiring any explicit
authentication step. We acquired a dataset comprising of measurements from 30
smartphone sensor modalities for 37 users. We evaluate our approach on 8
dominant modalities, namely, keystroke dynamics, GPS location, accelerometer,
gyroscope, magnetometer, linear accelerometer, gravity, and rotation sensors.
Experimental results find that, within 3 seconds, a genuine user can be
correctly verified 97.15% of the time at a false accept rate of 0.1%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05109</identifier>
 <datestamp>2019-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05109</id><created>2019-01-15</created><authors><author><keyname>Huang</keyname><forenames>Xiaodong</forenames></author><author><keyname>Liao</keyname><forenames>Bin</forenames></author></authors><title>One-Bit MUSIC</title><categories>eess.SP</categories><comments>5 pages, 6 figures, submitted to IEEE Signal Processing Letters</comments><journal-ref>IEEE Signal Processing Letters, 2019</journal-ref><doi>10.1109/LSP.2019.2913452</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider the problem of direction-of-arrival (DOA)
estimation with one-bit quantized array measurements. With analysis, it is
shown that, under mild conditions the one-bit covariance matrix can be
approximated by the sum of a scaled unquantized covariance matrix and a scaled
identity matrix. Although the scaling parameters unknown because of the extreme
quantization, they do not affect the subspace-based DOA estimators.
Specifically, the signal and noise subspaces can be straightforwardly
determined through the eigendecomposition of the one-bit covariance matrix,
without pre-processing such as unquantized covariance matrix reconstruction.
With so-obtained subspaces, the most classical multiple signal classification
(MUSIC) technique can be applied to determine the signal DOAs. The resulting
method is thus termed as one-bit MUSIC. Thanks to the simplicity of this
method, it can be very easily implemented in practical applications, whereas
the DOA estimation performance is comparable to the case with unquantized
covariance matrix reconstruction, as demonstrated by various simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05122</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05122</id><created>2019-01-15</created><authors><author><keyname>Ma</keyname><forenames>Fei</forenames></author><author><keyname>Zhang</keyname><forenames>Wen</forenames></author><author><keyname>Abhayapala</keyname><forenames>Thushara D.</forenames></author></authors><title>Real-time separation of non-stationary sound fields on spheres</title><categories>eess.AS cs.SD</categories><comments>34 pages, 15 figures</comments><doi>10.1121/1.5114819</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sound field separation methods can separate the target field from the
interfering noises, facilitating the study of the acoustic characteristics of
the target source, which is placed in a noisy environment. However, most of the
existing sound field separation methods are derived in the frequency-domain,
thus are best suited for separating stationary sound fields. In this paper, a
time-domain sound field separation method is developed that can separate the
non-stationary sound field generated by the target source over a sphere in
real-time. A spherical array sets up a boundary between the target source and
the interfering sources, such that the outgoing field on the array is only
generated by the target source. The proposed method decomposes the pressure and
the radial particle velocity measured by the array into spherical harmonics
coefficients, and recoveries the target outgoing field based on the time-domain
relationship between the decomposition coefficients and the theoretically
derived spatial filter responses. Simulations show the proposed method can
separate non-stationary sound fields both in free field and room environments,
and over a longer duration with small errors. The proposed method could serve
as a foundation for developing future time-domain spatial sound field
manipulation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05254</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05254</id><created>2019-01-16</created><authors><author><keyname>Balti</keyname><forenames>Elyes</forenames></author><author><keyname>Johnson</keyname><forenames>Brian K.</forenames></author></authors><title>Sub-6 GHz Microstrip Antenna: Design and Radiation Modeling</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a global framework analysis of a microstrip antenna
design circularly polarized with an operating frequency of 5.80 GHz and a
bandwidth of at least 500 MHz. We evaluate the optimal antenna parameters to
design requirements. Capitalizing on these parameters, we simulate the
radiation model of this antenna using the Finite Difference Time Domain (FDTD)
technique assuming one, two, and three dimensions. The propagation medium is
assumed to be a free space bounded by absorbing boundaries, and perfect matched
layer (PML). The FDTD-1D is considered in free space while FDTD-2D and 3D are
considered both in free space and in a free space-medium containing either
dielectric sphere or cylinder in the center. In this case, we model the
incident and the scattered electromagnetic fields reflected back from hitting
the dielectric object. Moreover, the microstrip antenna radiates an
electromagnetic pulse either in the middle or at one end of the medium and the
sources considered are Gaussian pulse and plane wave. Finally, we provide the
analytic solutions of the propagation models to confirm the accuracy of the
FDTD simulation technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05260</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05260</id><created>2019-01-16</created><updated>2019-07-08</updated><authors><author><keyname>Wang</keyname><forenames>Jiangtao</forenames></author><author><keyname>Wang</keyname><forenames>Yongchao</forenames></author></authors><title>On the Design of Constant Modulus Probing Waveforms with Good
  Correlation Properties for MIMO Radar via Consensus-ADMM Approach</title><categories>eess.SP</categories><comments>16pages,6 figures. This work was presented in part at 2018
  International Conference on Acoustics, Speech and Signal Processing (ICASSP)
  in Calgary, Alberta, Canada</comments><doi>10.1109/TSP.2019.2928994</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we design constant modulus probing waveforms with good
correlation properties for collocated multi-input multi-output (MIMO) radar
systems. The main content is as follows: first, we formulate the design problem
as a fourth order polynomial minimization problem with constant modulus
constraints. Then, by exploiting introduced auxiliary variables and their
inherent structures, the polynomial optimization model is equivalent to a
non-convex consensus minimization problem. Second, a customized alternating
direction method of multipliers (ADMM) algorithm is proposed to solve the
non-convex problem approximately. In the algorithm, all the subproblems can be
solved analytically. Moreover, all subproblems except one subproblem can be
performed in parallel. Third, we prove that the customized ADMM algorithm is
theoretically-guaranteed convergent if proper parameters are chosen. Fourth,
two variant ADMM algorithms, based on stochastic block coordinate descent and
accelerated gradient descent, are proposed to reduce computational complexity
and speed up the convergence rate. Numerical examples show the effectiveness of
the proposed consensus-ADMM algorithm and its variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05275</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05275</id><created>2019-01-16</created><authors><author><keyname>Churchill</keyname><forenames>Victor</forenames></author><author><keyname>Gelb</keyname><forenames>Anne</forenames></author></authors><title>Edge-masked CT image reconstruction from limited data</title><categories>eess.IV</categories><msc-class>94A08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an iterative inversion algorithm for computed tomography
image reconstruction that performs well in terms of accuracy and speed using
limited data. The computational method combines an image domain technique and
statistical reconstruction by using an initial filtered back projection
reconstruction to create a binary edge mask, which is then used in an
l2-regularized reconstruction. Both theoretical and empirical results are
offered to support the algorithm. While in this paper a simple forward model is
used and physical edges are used as the sparse feature, the proposed method is
flexible and can accommodate any forward model and sparsifying transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05284</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05284</id><created>2018-12-04</created><authors><author><keyname>Ma</keyname><forenames>Xiaofu</forenames></author><author><keyname>Fang</keyname><forenames>Yu</forenames></author><author><keyname>Bai</keyname><forenames>Xingzhen</forenames></author></authors><title>A balanced energy consumption clustering algorithm for heterogeneous
  energy wireless sensor networks</title><categories>eess.SP</categories><comments>2010 IEEE International Conference on Wireless Communications,
  Networking and Information Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a balanced energy consumption clustering algorithm (BECC) is
proposed. This new scheme is a cluster-based algorithm designed for
heterogeneous energy wireless sensor networks. A polarized energy factor is
introduced to adjust the probability with which each node may become a cluster
head in the election of the new clustering scheme. Under the condition that the
expected number of cluster heads in the network preserves the theoretical
optimal number, BECC makes sure that nodes with higher residual energy will
become cluster heads with higher probabilities while nodes with lower residual
energy will not become cluster heads. Simulation results show that this new
scheme provides longer lifetime than the classical clustering algorithms
including LEACH and other improved algorithms in heterogeneous networks, and
BECC also reaches larger amount of messages received at the sink.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05285</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05285</id><created>2018-12-04</created><authors><author><keyname>Ma</keyname><forenames>Xiaofu</forenames></author><author><keyname>Guha</keyname><forenames>Sayantan</forenames></author><author><keyname>Choi</keyname><forenames>Junsung</forenames></author><author><keyname>Anderson</keyname><forenames>Christopher R.</forenames></author><author><keyname>Nealy</keyname><forenames>Randall</forenames></author><author><keyname>Withers</keyname><forenames>Jared</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey H.</forenames></author><author><keyname>Dietrich</keyname><forenames>Carl</forenames></author></authors><title>Prototypes of Using Directional Antenna for Railroad Crossing Safety
  Applications</title><categories>eess.SP</categories><comments>IEEE Annual Consumer Communications &amp; Networking Conference (CCNC),
  2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this demonstration proposal, we present a prototype of a rapidly
deployable and cost-effective railroad crossing early warning system integrated
with the railway system. Specifically, the proposed demonstration deal with the
safety applications based on dedicated short range communications (DSRC)
protocol and devices using our different antennas. We will demonstrate the
feasibility and advantages of our proposed system, including the antenna
design, system deployment, the over-the-air transmission, and the software
applications that we developed for the end users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05292</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05292</id><created>2019-01-10</created><authors><author><keyname>Hartono</keyname><forenames>Rommy</forenames></author><author><keyname>Hasbi</keyname><forenames>Wahyudi</forenames></author><author><keyname>Choiriyah</keyname><forenames>Isma</forenames></author><author><keyname>Yatim</keyname><forenames>Rakhmad</forenames></author></authors><title>Design of APRS Modem Using IC TCM3105 and ATMega2560 Microcontroller</title><categories>eess.SP</categories><comments>8 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  APRS technology is still exists and still developing among amateur radio.
However, in Indonesia there are still not many people who use and utilize APRS.
The high price of APRS modem and difficulties of getting APRS modems is one of
the factors affecting the public interest in APRS. In Indonesia, no one has
developed APRS modem, so that our paper will be discuss about design and
develop of APRS modem using cheap and easy components FSK modem IC TCM3105 and
ATmega2560 as microcontroller. The implementation of APRS standard protocol on
modem that has been made use C programming language on Arduino IDE and the
schematic design and printed circuit board layout use Proteus 8. IC TCM3105
selection is based on the specification of eligible components of APRS device
able to set the baud rate of 1200 bps with FSK modulation technique. The
ATmega2560 microcontroller is chosen as the information signal encoding
processor and calculate the CRC-16-X25 FCS (Frame Check Sequence) for the
information packet according to the standard AX.25 UI Frame APRS protocol.
AX.25 UI Frame APRS protocol consists of flag, destination address, source
address, digipeater address, control field, protocol ID, information field and
FCS. The result of this paper is APRS modem device that has been made can send
the APRS information packet very well. This is proved by APRS packet that has
been sent can be received and repeated by ground station of Pusteksat LAPAN
also connected on APRS international network in aprs.fi. In addition, the
information that has been sent from APRS modem can be decoded correctly by APRS
software decoder such as Soundmodem, AFSK1200, dan AX.25-SCS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05294</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05294</id><created>2018-12-24</created><updated>2020-02-16</updated><authors><author><keyname>Wei</keyname><forenames>Yiheng</forenames></author><author><keyname>Kang</keyname><forenames>Yu</forenames></author><author><keyname>Yin</keyname><forenames>Weidi</forenames></author><author><keyname>Wang</keyname><forenames>Yong</forenames></author></authors><title>Design of generalized fractional order gradient descent method</title><categories>eess.SP math.OC</categories><comments>8 pages, 16 figures</comments><msc-class>26A33, 90C25</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the convergence problem of the emerging fractional
order gradient descent method, and proposes three solutions to overcome the
problem. In fact, the general fractional gradient method cannot converge to the
real extreme point of the target function, which critically hampers the
application of this method. Because of the long memory characteristics of
fractional derivative, fixed memory principle is a prior choice. Apart from the
truncation of memory length, two new methods are developed to reach the
convergence. The one is the truncation of the infinite series, and the other is
the modification of the constant fractional order. Finally, six illustrative
examples are performed to illustrate the effectiveness and practicability of
proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05296</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05296</id><created>2019-01-12</created><updated>2019-02-26</updated><authors><author><keyname>Alaifari</keyname><forenames>Rima</forenames></author><author><keyname>Wellershoff</keyname><forenames>Matthias</forenames></author></authors><title>Stability estimates for phase retrieval from discrete Gabor measurements</title><categories>math.NA cs.IT eess.SP math.FA math.IT</categories><comments>21 pages, 6 figures; Restructured introduction, added references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phase retrieval refers to the problem of recovering some signal (which is
often modelled as an element of a Hilbert space) from phaseless measurements.
It has been shown that, in the deterministic setting, phase retrieval from
frame coefficients is always unstable in infinite dimensional Hilbert spaces
[7] and possibly severely ill-conditioned in finite dimensional Hilbert spaces
[7].
  Recently, it was also shown that phase retrieval from measurements induced by
the Gabor transform with Gaussian window function is stable when one is willing
to accept a more relaxed semi-global stability regime [1].
  We present first evidence that this semi-global stability regime allows one
to do phase retrieval from measurements induced by the discrete Gabor transform
in such a way that the corresponding stability constant only scales linearly in
the space dimension. To this end, we utilise well-known reconstruction formulae
which have been used repeatedly in recent years [6,12,18,20].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05301</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05301</id><created>2019-01-11</created><authors><author><keyname>Granstr&#xf6;m</keyname><forenames>Karl</forenames></author><author><keyname>Bramst&#xe5;ng</keyname><forenames>Jakob</forenames></author></authors><title>Bayesian Smoothing for the Extended Object Random Matrix Model</title><categories>eess.SP</categories><doi>10.1109/TSP.2019.2920471</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The random matrix model is popular in extended object tracking, due to its
relative simplicity and versatility. In this model, the extended object state
consists of a kinematic vector for the position and motion parameters
(velocity, etc), and an extent matrix. Two versions of the model can be found
in literature, one where the state density is modelled by a conditional
density, and one where the state density is modelled by a factorized density.
In this paper, we present closed form Bayesian smoothing expression for both
the conditional and the factorised model. In a simulation study, we compare the
performance of different versions of the smoother.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05302</identifier>
 <datestamp>2019-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05302</id><created>2019-01-10</created><updated>2019-01-17</updated><authors><author><keyname>Madarasingha</keyname><forenames>K. C. M.</forenames></author><author><keyname>Perera</keyname><forenames>W. N. D.</forenames></author><author><keyname>Rathnayaka</keyname><forenames>A. M. A. I.</forenames></author><author><keyname>Savindu</keyname><forenames>H. P.</forenames></author><author><keyname>Jayasinghe</keyname><forenames>S.</forenames></author><author><keyname>Kahaduwa</keyname><forenames>K. T. D.</forenames></author><author><keyname>De Silva</keyname><forenames>A. C.</forenames></author></authors><title>Development of a system to profile foot temperatures of the plantar and
  the periphery</title><categories>eess.SP</categories><comments>5 pages, 6 figures, In proceedings of 2018 IEEE Region 10 Conference
  (TENCON), pp. 1922-1926. Jeju, Korea</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Foot temperature profiling is of utmost importance is mitigating the adverse
effects due to foot complications especially due to diabetes. Contactless
temperature monitoring methods could be used effectively in large scale for
patient screening. Near-infrared thermography has proven to be convenient and
accurate for temperature profiling. The objective of this study is to develop a
diagnostic device using the said imaging technology to detect as well as
progress monitoring of foot complications. The device we have developed is
capable of scanning the foot plantar and the periphery and it is also
accompanied by a semi-supervised thermal image analysis algorithm which is
convenient to the clinician. Preliminary clinical testing conducted using 6
diabetic subjects out of which 2 had ulcers in either foot and 9 non-diabetic
subjects 2 of which had wounds on the plantar. The system was able to detect
the ulcerated areas and wounds with the algorithm developed specifically for
thermal image analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05303</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05303</id><created>2019-01-10</created><authors><author><keyname>Rathnayaka</keyname><forenames>A. M. A. I.</forenames></author><author><keyname>Perera</keyname><forenames>W. N. D.</forenames></author><author><keyname>Savindu</keyname><forenames>H. P.</forenames></author><author><keyname>Madarasingha</keyname><forenames>K. C. M.</forenames></author><author><keyname>Ranasinghe</keyname><forenames>S. P.</forenames></author><author><keyname>Thuduwage</keyname><forenames>H. G. T. V.</forenames></author><author><keyname>Kulathilaka</keyname><forenames>A. U.</forenames></author><author><keyname>Silva</keyname><forenames>P.</forenames></author><author><keyname>Jayasinghe</keyname><forenames>S.</forenames></author><author><keyname>Kahaduwa</keyname><forenames>K. T. D.</forenames></author><author><keyname>De Silva</keyname><forenames>A. C.</forenames></author></authors><title>A Customized System to Assess Foot Plantar Pressure: A Case Study on
  Calloused and Normal Feet</title><categories>eess.SP</categories><comments>5 pages, 7 figures, 2018 IEEE Region Ten Symposium (Tensymp), pp
  202-206 2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Foot plantar pressure monitoring is an important tool for biomechanical
assessment of posture, foot complications due to callus formation and wounds
and for sports applications. The pronounced cost associated with commercial
plantar pressure monitoring systems and inflexibility of custom analyzing data
in such systems prompted the development of a versatile system with minimized
cost. This study focuses on the development of such a system with high speed
data acquisition providing analysis tools for assessing plantar pressure
variations of diabetic patients with calloused feet. The new system is capable
of achieving a frame rate of 155 Hz which is ideal for pressure monitoring
during both standing and walking. The system was verified using 10 normal
subjects and 5 diabetic subjects with calluses on in their feet. Results
indicate significantly high mechanical stresses on skin beneath callus and
postural disorders during standing, in subjects with calluses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05305</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05305</id><created>2019-01-14</created><authors><author><keyname>Avcu</keyname><forenames>Mustafa Talha</forenames></author><author><keyname>Zhang</keyname><forenames>Zhuo</forenames></author><author><keyname>Chan</keyname><forenames>Derrick Wei Shih</forenames></author></authors><title>Seizure Detection using Least EEG Channels by Deep Convolutional Neural
  Network</title><categories>eess.SP cs.CV cs.LG</categories><doi>10.1109/ICASSP.2019.8683229</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This work aims to develop an end-to-end solution for seizure onset detection.
We design the SeizNet, a Convolutional Neural Network for seizure detection. To
compare SeizNet with traditional machine learning approach, a baseline
classifier is implemented using spectrum band power features with Support
Vector Machines (BPsvm). We explore the possibility to use the least number of
channels for accurate seizure detection by evaluating SeizNet and BPsvm
approaches using all channels and two channels settings respectively. EEG Data
is acquired from 29 pediatric patients admitted to KK Woman's and Children's
Hospital who were diagnosed as typical absence seizures. We conduct
leave-one-out cross validation for all subjects. Using full channel data, BPsvm
yields a sensitivity of 86.6\% and 0.84 false alarm (per hour) while SeizNet
yields overall sensitivity of 95.8 \% with 0.17 false alarm. More
interestingly, two channels seizNet outperforms full channel BPsvm with a
sensitivity of 93.3\% and 0.58 false alarm. We further investigate
interpretability of SeizNet by decoding the filters learned along convolutional
layers. Seizure-like characteristics can be clearly observed in the filters
from third and forth convolutional layers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05341</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05341</id><created>2019-01-14</created><authors><author><keyname>Li</keyname><forenames>Xiawen</forenames></author><author><keyname>Mishra</keyname><forenames>Chetan</forenames></author><author><keyname>De La Ree</keyname><forenames>Jaime</forenames></author></authors><title>Frequency Control of Decoupled Synchronous Machine Using Koopman
  Operator Based Model Predictive</title><categories>eess.SP</categories><comments>2019 IEEE PES General Meeting</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional generators have been retired or replaced by renewable energy
because of the utility long-standing goals. However, instead of decommissioning
the entire plant, the rotating mass can be utilized as a storage unit to
mitigate the frequency issues due to these changes in the grid. The goal is to
design a control utilizing the retired machine interfaced with the grid through
a back to back converter referred to as decoupled synchronous machine system
(DSMS) to damp frequency oscillations. However, in a practical setting, it is
often not possible for a utility to obtain access to the detailed state
equations of such devices from the vendor making the addition of another layer
of control a challenging problem. Therefore, a purely data driven approach to
nonlinear control design using Koopman operator based framework is proposed for
this application. The effectiveness of the proposed system is demonstrated in
the Kundur two-area system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05361</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05361</id><created>2019-01-15</created><updated>2019-01-24</updated><authors><author><keyname>Wang</keyname><forenames>Qingsong</forenames></author><author><keyname>Wang</keyname><forenames>Chengjing</forenames></author><author><keyname>Tang</keyname><forenames>Peipei</forenames></author><author><keyname>Niu</keyname><forenames>Dunbiao</forenames></author></authors><title>A Dual Alternating Direction Method of Multipliers for Image
  Decomposition and Restoration</title><categories>eess.IV math.NA</categories><comments>12 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a dual alternating direction method of multipliers
(ADMM) for an image decomposition model. In this model, an image is divided
into two meaningful components, i.e., a cartoon part and a texture part. The
optimization algorithm that we develop not only gives the cartoon part and the
texture part of an image but also gives the restored image (cartoon part +
texture part). We also present the global convergence and the local linear
convergence rate for the algorithm under some mild conditions. Numerical
experiments demonstrate the efficiency and robustness of the dual ADMM (dADMM).
Furthermore, we can obtain relatively higher signalto-noise ratio (SNR)
comparing to other algorithms. It shows that the choice of the algorithm is
also important even for the same model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05413</identifier>
 <datestamp>2019-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05413</id><created>2019-01-16</created><authors><author><keyname>Pan</keyname><forenames>Cunhua</forenames></author><author><keyname>Ren</keyname><forenames>Hong</forenames></author><author><keyname>Deng</keyname><forenames>Yansha</forenames></author><author><keyname>Elkashlan</keyname><forenames>Maged</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author></authors><title>Joint Blocklength and Location Optimization for URLLC-enabled UAV Relay
  Systems</title><categories>eess.SP</categories><comments>Submitted to one journal. keywords: UAV, URLLC, Short-packet
  transmission, Relay</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  This letter considers the unmanned aerial vehicle (UAV)-enabled relay system
to deliver command information under ultra-reliable and low-latency
communication (URLLC) requirements. We aim to jointly optimize the blocklength
allocation and the UAV's location to minimize the decoding error probability
subject to the latency requirement. The achievable data rate under finite
blocklength regime is adopted. A novel perturbation-based iterative algorithm
is proposed to solve this problem. Simulation results show that the proposed
algorithm can achieve the same performance as the exhaustive search method, and
significantly outperforms the existing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05420</identifier>
 <datestamp>2019-01-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05420</id><created>2019-01-16</created><updated>2019-01-17</updated><authors><author><keyname>Fang</keyname><forenames>Song</forenames></author><author><keyname>Johansson</keyname><forenames>Karl Henrik</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author><author><keyname>Sandberg</keyname><forenames>Henrik</forenames></author><author><keyname>Ishii</keyname><forenames>Hideaki</forenames></author></authors><title>Two-Way Coding in Control Systems Under Injection Attacks: From Attack
  Detection to Attack Correction</title><categories>cs.SY eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce the method of two-way coding, a concept
originating in communication theory characterizing coding schemes for two-way
channels, into (networked) feedback control systems under injection attacks. We
first show that the presence of two-way coding can distort the perspective of
the attacker on the control system. In general, the distorted viewpoint on the
attacker side as a consequence of two-way coding will facilitate detecting the
attacks, or restricting what the attacker can do, or even correcting the attack
effect. In the particular case of zero-dynamics attacks, if the attacks are to
be designed according to the original plant, then they will be easily detected;
while if the attacks are designed with respect to the equivalent plant as
viewed by the attacker, then under the additional assumption that the plant is
stabilizable by static output feedback, the attack effect may be corrected in
steady state.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05441</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05441</id><created>2019-01-15</created><authors><author><keyname>Gilman</keyname><forenames>Mikhail</forenames></author><author><keyname>Tsynkov</keyname><forenames>Semyon</forenames></author></authors><title>Detection of delayed target response in SAR</title><categories>eess.IV</categories><doi>10.1088/1361-6420/ab1c80</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delayed target response in synthetic aperture radar (SAR) imaging can be
obscured by the range-delay ambiguity and speckle. To analyze the range-delay
ambiguity, one extends the standard SAR formulation and allows both the target
reflectivity and the image to depend not only on the coordinates, but also on
the response delay. However, this still leaves the speckle unaccounted for. Yet
speckle is commonly found in SAR images of extended targets, and a statistical
approach is usually employed to describe it. We have developed a simple model
of a delayed scatterer by modifying the random function that describes a
homogeneous extended scatterer. Our model allows us to obtain a relation
between the deterministic parameters of the target model and statistical
moments of the SAR image. We assume a regular shape of the antenna trajectory,
and our model targets are localized in at least one space-time coordinate; this
permits analytical formulation for statistical moments of the image. The
problem of reconstruction of coordinate-delay reflectivity function is reduced
to that of discrimination between instantaneous and delayed scatterers; for the
latter problem, the maximum likelihood based image processing procedure has
been developed. We perform Monte-Carlo simulation and evaluate performance of
the classification procedure for a simple dependence of scatterer reflectivity
on the delay time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05452</identifier>
 <datestamp>2019-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05452</id><created>2019-01-16</created><authors><author><keyname>Ahrabian</keyname><forenames>Alireza</forenames></author></authors><title>Supplementary Notes: Segment Parameter Labelling in MCMC Change
  Detection</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1710.09657</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work addresses the problem of segmentation in time series data with
respect to a statistical parameter of interest in Bayesian models. It is common
to assume that the parameters are distinct within each segment. As such, many
Bayesian change point detection models do not exploit the segment parameter
patterns, which can improve performance. This work proposes a Bayesian change
point detection algorithm that makes use of repetition in segment parameters,
by introducing segment class labels that utilise a Dirichlet process prior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05494</identifier>
 <datestamp>2020-01-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05494</id><created>2019-01-10</created><updated>2020-01-09</updated><authors><author><keyname>Liu</keyname><forenames>Jianqing</forenames></author><author><keyname>Pang</keyname><forenames>Yawei</forenames></author><author><keyname>Ding</keyname><forenames>Haichuan</forenames></author><author><keyname>Cai</keyname><forenames>Ling</forenames></author><author><keyname>Zhang</keyname><forenames>Haixia</forenames></author><author><keyname>Fang</keyname><forenames>Yuguang</forenames></author></authors><title>Optimizing IoT Energy Efficiency on Edge (EEE): a Cross-layer Design in
  a Cognitive Mesh Network</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Battery-powered wireless IoT devices are now widely seen in many critical
applications. Given the limited battery capacity and inaccessibility to
external power recharge, optimizing energy efficiency (EE) plays a vital role
in prolonging the lifetime of these IoT devices. However, a sheer amount of
existing works only focus on the EE design at the infrastructure level such as
base stations (BSs) but with little attention to the EE design at the device
level. In this paper, we propose a novel idea that aims to shift energy
consumption to a grid-powered cognitive radio mesh network thus preserving
energy of battery-powered devices. Under this line of thinking, we cast the
design into a cross-layer optimization problem with an objective to maximize
devices' energy efficiency. To solve this problem, we propose a parametric
transformation technique to convert the original problem into a more tractable
one. A baseline scheme is used to demonstrate the advantage of our design. We
also carry out extensive simulations to exhibit the optimality of our proposed
algorithms and the network performance under various settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05498</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05498</id><created>2019-01-16</created><updated>2019-01-20</updated><authors><author><keyname>Roy</keyname><forenames>Yannick</forenames></author><author><keyname>Banville</keyname><forenames>Hubert</forenames></author><author><keyname>Albuquerque</keyname><forenames>Isabela</forenames></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames></author><author><keyname>Falk</keyname><forenames>Tiago H.</forenames></author><author><keyname>Faubert</keyname><forenames>Jocelyn</forenames></author></authors><title>Deep learning-based electroencephalography analysis: a systematic review</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electroencephalography (EEG) is a complex signal and can require several
years of training to be correctly interpreted. Recently, deep learning (DL) has
shown great promise in helping make sense of EEG signals due to its capacity to
learn good feature representations from raw data. Whether DL truly presents
advantages as compared to more traditional EEG processing approaches, however,
remains an open question. In this work, we review 156 papers that apply DL to
EEG, published between January 2010 and July 2018, and spanning different
application domains such as epilepsy, sleep, brain-computer interfacing, and
cognitive and affective monitoring. We extract trends and highlight interesting
approaches in order to inform future research and formulate recommendations.
Various data items were extracted for each study pertaining to 1) the data, 2)
the preprocessing methodology, 3) the DL design choices, 4) the results, and 5)
the reproducibility of the experiments. Our analysis reveals that the amount of
EEG data used across studies varies from less than ten minutes to thousands of
hours. As for the model, 40% of the studies used convolutional neural networks
(CNNs), while 14% used recurrent neural networks (RNNs), most often with a
total of 3 to 10 layers. Moreover, almost one-half of the studies trained their
models on raw or preprocessed EEG time series. Finally, the median gain in
accuracy of DL approaches over traditional baselines was 5.4% across all
relevant studies. More importantly, however, we noticed studies often suffer
from poor reproducibility: a majority of papers would be hard or impossible to
reproduce given the unavailability of their data and code. To help the field
progress, we provide a list of recommendations for future studies and we make
our summary table of DL and EEG papers available and invite the community to
contribute.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05529</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05529</id><created>2019-01-16</created><updated>2019-09-05</updated><authors><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Ibrahim</keyname><forenames>Shahana</forenames></author><author><keyname>Wai</keyname><forenames>Hoi-To</forenames></author><author><keyname>Gao</keyname><forenames>Cheng</forenames></author><author><keyname>Huang</keyname><forenames>Kejun</forenames></author></authors><title>Block-Randomized Stochastic Proximal Gradient for Low-Rank Tensor
  Factorization</title><categories>eess.SP cs.LG</categories><comments>single-column, 37 pages, revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers the problem of computing the canonical polyadic
decomposition (CPD) of large tensors. Prior works mostly leverage data sparsity
to handle this problem, which is not suitable for handling dense tensors that
often arise in applications such as medical imaging, computer vision, and
remote sensing. Stochastic optimization is known for its low memory cost and
per-iteration complexity when handling dense data. However, exisiting
stochastic CPD algorithms are not flexible enough to incorporate a variety of
constraints/regularizations that are of interest in signal and data analytics.
Convergence properties of many such algorithms are also unclear. In this work,
we propose a stochastic optimization framework for large-scale CPD with
constraints/regularizations. The framework works under a doubly randomized
fashion, and can be regarded as a judicious combination of randomized block
coordinate descent (BCD) and stochastic proximal gradient (SPG). The algorithm
enjoys lightweight updates and small memory footprint. In addition, this
framework entails considerable flexibility---many frequently used regularizers
and constraints can be readily handled under the proposed scheme. The approach
is also supported by convergence analysis. Numerical results on large-scale
dense tensors are employed to showcase the effectiveness of the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05542</identifier>
 <datestamp>2019-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05542</id><created>2019-01-16</created><updated>2019-05-23</updated><authors><author><keyname>Ahmed</keyname><forenames>Abdul Haseeb</forenames></author><author><keyname>Mohsin</keyname><forenames>Yasir</forenames></author><author><keyname>Zhou</keyname><forenames>Ruixi</forenames></author><author><keyname>Yang</keyname><forenames>Yang</forenames></author><author><keyname>Salerno</keyname><forenames>Michael</forenames></author><author><keyname>Nagpal</keyname><forenames>Prashant</forenames></author><author><keyname>Jacob</keyname><forenames>Mathews</forenames></author></authors><title>Free-breathing and ungated cardiac cine using navigator-less spiral
  SToRM</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To develop a free-breathing and ungated cardiac MRI scheme using an
iterative kernel low-rank algorithm and self-gated spiral sequence. Methods:
The data were acquired continuously over 8-16 seconds per slice without ECG
gating or breath holding using a golden-angle gradient echo spiral sequence.
The reconstruction scheme relies on the manifold structure of a dynamic data to
recover it from the highly undersampled measurements. An iterative kernel
low-rank algorithm is introduced to estimate the manifold structure of the
images, or equivalently the manifold Laplacian matrix, from the central k-space
regions. The iterative algorithm, coupled with the non-Cartesian acquisitions,
eliminates the need for dedicated navigators to estimate the manifold
Laplacian, unlike previous manifold methods, thus improving sampling
efficiency. Results: The proposed method is demonstrated in patients with
different breathing patterns and cardiac rates. The experiments show the
ability of our proposed iterative strategy to reduce spatial and temporal
blurring compared to state-of-the-art methods. Conclusion: The iterative SToRM
algorithm facilitates the extension of manifold regularization to
navigator-less spiral acquisitions, thus improving sampling efficiency. The
proposed scheme eliminates the need for breath-holding and ECG gating, while
facilitating the imaging of the cardiac function in different respiratory
phases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05593</identifier>
 <datestamp>2019-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05593</id><created>2019-01-16</created><updated>2019-10-30</updated><authors><author><keyname>Fan</keyname><forenames>Fenglei</forenames></author><author><keyname>Shan</keyname><forenames>Hongming</forenames></author><author><keyname>Kalra</keyname><forenames>Mannudeep K.</forenames></author><author><keyname>Singh</keyname><forenames>Ramandeep</forenames></author><author><keyname>Qian</keyname><forenames>Guhan</forenames></author><author><keyname>Getzin</keyname><forenames>Matthew</forenames></author><author><keyname>Teng</keyname><forenames>Yueyang</forenames></author><author><keyname>Hahn</keyname><forenames>Juergen</forenames></author><author><keyname>Wang</keyname><forenames>Ge</forenames></author></authors><title>Quadratic Autoencoder (Q-AE) for Low-dose CT Denoising</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by complexity and diversity of biological neurons, our group
proposed quadratic neurons by replacing the inner product in current artificial
neurons with a quadratic operation on input data, thereby enhancing the
capability of an individual neuron. Along this direction, we are motivated to
evaluate the power of quadratic neurons in popular network architectures,
simulating human-like learning in the form of quadratic-neuron-based deep
learning. Our prior theoretical studies have shown important merits of
quadratic neurons and networks in representation, efficiency, and
interpretability. In this paper, we use quadratic neurons to construct an
encoder-decoder structure, referred as the quadratic autoencoder, and apply it
to low-dose CT denoising. The experimental results on the Mayo low-dose CT
dataset demonstrate the utility of quadratic autoencoder in terms of image
denoising and model efficiency. To our best knowledge, this is the first time
that the deep learning approach is implemented with a new type of neurons and
demonstrates a significant potential in the medical imaging field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05760</identifier>
 <datestamp>2019-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05760</id><created>2019-01-17</created><updated>2019-04-08</updated><authors><author><keyname>Soleymani</keyname><forenames>Mohammad</forenames></author><author><keyname>Lameiro</keyname><forenames>Christian</forenames></author><author><keyname>Santamaria</keyname><forenames>Ignacio</forenames></author><author><keyname>Schreier</keyname><forenames>Peter J.</forenames></author></authors><title>Robust Improper Signaling for Two-user SISO Interference Channels</title><categories>eess.SP</categories><comments>IEEE Transactions on Communications (accepted)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown that improper Gaussian signaling (IGS) can improve the
performance of wireless interference-limited systems when perfect channel state
information (CSI) is available. In this paper, we investigate the robustness of
IGS against imperfect CSI on the transmitter side in a two-user single-input
single-output (SISO) interference channel (IC) as well as in a SISO Z-IC, when
interference is treated as noise. We assume that the true channel coefficients
belong to a known region around the channel estimates, which we call the
uncertainty region. Following a worst-case robustness approach, we study the
rate-region boundary of the IC for the worst channel in the uncertainty region.
For the two-user IC, we derive a robust design in closed-form, which is
independent of the phase of the channels by allowing only one of the users to
transmit IGS. For the Z-IC, we provide a closed-form design for the
transmission parameters by considering an enlarged uncertainty region and
allowing both users to employ IGS. In both cases, the IGS-based designs are
ensured to perform no worse than proper Gaussian signaling. Furthermore, we
show, through numerical examples, that the proposed robust designs
significantly outperform non-robust solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05811</identifier>
 <datestamp>2019-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05811</id><created>2019-01-17</created><authors><author><keyname>Kumar</keyname><forenames>Vinay</forenames></author><author><keyname>Bawa</keyname><forenames>Vivek Singh</forenames></author></authors><title>No reference image quality assessment metric based on regional mutual
  information among images</title><categories>cs.CV eess.IV</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the inclusion of camera in daily life, an automatic no reference image
quality evaluation index is required for automatic classification of images.
The present manuscripts proposes a new No Reference Regional Mutual Information
based technique for evaluating the quality of an image. We use regional mutual
information on subsets of the complete image. Proposed technique is tested on
four benchmark natural image databases, and one benchmark synthetic database. A
comparative analysis with classical and state-of-art methods indicate
superiority of the present technique for high quality images and comparable for
other images of the respective databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05821</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05821</id><created>2019-01-17</created><updated>2019-09-11</updated><authors><author><keyname>Soleymani</keyname><forenames>Mohammad</forenames></author><author><keyname>Lameiro</keyname><forenames>Christian</forenames></author><author><keyname>Santamaria</keyname><forenames>Ignacio</forenames></author><author><keyname>Schreier</keyname><forenames>Peter J.</forenames></author></authors><title>Improper Signaling for SISO Two-user Interference Channels with Additive
  Asymmetric Hardware Distortion</title><categories>eess.SP</categories><doi>10.1109/TCOMM.2019.2939310</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hardware non-idealities are among the main performance restrictions for
upcoming wireless communication systems. Asymmetric hardware distortions (HWD)
happen when the impairments of the I/Q branches are correlated or imbalanced,
which in turn generate improper additive interference at the receiver side.
When the interference is improper, as well as in other interference-limited
scenarios, improper Gaussian signaling (IGS) has been shown to provide rate
and/or power efficiency benefits. In this paper, we investigate the rate
benefits of IGS in a two-user interference channel (IC) with additive
asymmetric HWD when interference is treated as noise. We propose two iterative
algorithms to optimize the parameters of the improper transmit signals. We
first rewrite the rate region as an
pseudosignal-to-interference-plus-noise-ratio (PSINR) region and employ
majorization minimization and fractional programming to find a suboptimal
solution for the achievable user rates. Then, we propose a simplified algorithm
based on a separate optimization of the powers and complementary variances of
the users, which exhibits lower computational complexity. We show that IGS can
improve the performance of the two-user IC with additive HWD. Our proposed
algorithms outperform proper Gaussian signaling and competing IGS algorithms in
the literature that do not consider asymmetric HWD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05842</identifier>
 <datestamp>2019-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05842</id><created>2019-01-07</created><authors><author><keyname>Wang</keyname><forenames>Haihang</forenames></author><author><keyname>Xu</keyname><forenames>He</forenames></author><author><keyname>Gao</keyname><forenames>Xiaozhi</forenames></author><author><keyname>Zhao</keyname><forenames>Zitong</forenames></author><author><keyname>Huang</keyname><forenames>Jinwei</forenames></author></authors><title>Application of a Modified Harmony Search Algorithm in the Optimal
  Arrangement of a Novel Three Dimensional Multiphase Flow Imaging Device</title><categories>eess.IV</categories><comments>27 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gas-liquid two-phase flow is a typical flow, and bubble characteristic
measurement is of great importance to study the flow mechanism and guide the
practical fluid mechanical engineering. In this paper, a novel three
dimensional (3D) multiphase flow imaging device was designed to measure the
transparent object that has an opaque object in the center of the observed
area. Its mathematical model was built and the constraints were defined based
on the geometrical relationship and design requirements. A modified harmony
search (HS) algorithm was integrated and applied to optimize the arrangement of
the single-camera-multi-mirror device. As a case study, the 3D multiphase flow
imaging method was applied in the the 3D reconstruction of the cavitation
bubble cluster inside a water hydraulic valve. The statistics of the Pareto
data shows the good performance of the modified HS algorithm. And the
cavitation experimental results shows that the method is valid, and the
cavitation bubble cluster can be reconstructed with quite high precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05846</identifier>
 <datestamp>2019-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05846</id><created>2019-01-16</created><authors><author><keyname>He</keyname><forenames>Qian</forenames></author><author><keyname>Liu</keyname><forenames>Rong</forenames></author><author><keyname>Tan</keyname><forenames>Chengdan</forenames></author><author><keyname>Tang</keyname><forenames>Lijun</forenames></author><author><keyname>Shang</keyname><forenames>Xiongjun</forenames></author></authors><title>The detection of non-Gaussian vibrations with improved spatial
  resolution and signal-to-noise ratio in distributed sensing</title><categories>eess.SP</categories><comments>6 pages,9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In fiber-optic distributed sensing, vibration signals are mostly assumed to
follow Gaussian distribution for the simplicity of signal processing. However,
in real applications, vibration signals often behave as non-Gaussian processes,
which have rarely been highly considered. In this paper, a higher-order
cumulants algorithm based phase-sensitive optical time-domain reflectometry
(OTDR) is proposed to detect and analyze non-Gaussian vibration signals
accompanied with noises. When disturbances are applied on the sensing fiber,
the distribution probability of Rayleigh backscattering signals will deviate
from the ideal Gaussian distribution. The non-Gaussian vibration is then
extracted from Gaussian noises based on the probability density distribution.
Simulations and experiments are carried out. The experimental results show that
the demonstrated method can measure non-Gaussian vibrations with improved
signal-to-noise ratio and spatial resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05850</identifier>
 <datestamp>2019-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05850</id><created>2019-01-15</created><authors><author><keyname>Ramjee</keyname><forenames>Sharan</forenames></author><author><keyname>Ju</keyname><forenames>Shengtai</forenames></author><author><keyname>Yang</keyname><forenames>Diyu</forenames></author><author><keyname>Liu</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Gamal</keyname><forenames>Aly El</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Fast Deep Learning for Automatic Modulation Classification</title><categories>eess.SP cs.AI cs.LG stat.ML</categories><comments>29 pages, 30 figures, submitted to Journal on Selected Areas in
  Communications - Special Issue on Machine Learning in Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we investigate the feasibility and effectiveness of employing
deep learning algorithms for automatic recognition of the modulation type of
received wireless communication signals from subsampled data. Recent work
considered a GNU radio-based data set that mimics the imperfections in a real
wireless channel and uses 10 different modulation types. A Convolutional Neural
Network (CNN) architecture was then developed and shown to achieve performance
that exceeds that of expert-based approaches. Here, we continue this line of
work and investigate deep neural network architectures that deliver high
classification accuracy. We identify three architectures - namely, a
Convolutional Long Short-term Deep Neural Network (CLDNN), a Long Short-Term
Memory neural network (LSTM), and a deep Residual Network (ResNet) - that lead
to typical classification accuracy values around 90% at high SNR. We then study
algorithms to reduce the training time by minimizing the size of the training
data set, while incurring a minimal loss in classification accuracy. To this
end, we demonstrate the performance of Principal Component Analysis in
significantly reducing the training time, while maintaining good performance at
low SNR. We also investigate subsampling techniques that further reduce the
training time, and pave the way for online classification at high SNR. Finally,
we identify representative SNR values for training each of the candidate
architectures, and consequently, realize drastic reductions of the training
time, with negligible loss in classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05852</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05852</id><created>2019-01-17</created><updated>2019-10-27</updated><authors><author><keyname>Papayiannis</keyname><forenames>Constantinos</forenames></author><author><keyname>Evers</keyname><forenames>Christine</forenames></author><author><keyname>Naylor</keyname><forenames>Patrick A.</forenames></author></authors><title>Detecting Sound-Absorbing Materials in a Room from a Single Impulse
  Response using a CRNN</title><categories>eess.AS cs.SD</categories><comments>Submitted for review for IEEE ICASSP 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The materials of surfaces in a room play an important room in shaping the
auditory experience within them. Different materials absorb energy at different
levels. The level of absorption also varies across frequencies. This paper
investigates how cues from a measured impulse response in the room can be
exploited by machines to detect the materials present. With this motivation,
this paper proposes a method for estimating the probability of presence of 10
material categories, based on their frequency-dependent absorption
characteristics. The method is based on a CNN-RNN, trained as a multi-task
classifier. The network is trained using a priori knowledge about the
absorption characteristics of materials from the literature. In the experiments
shown, the network is tested on over 5,00 impulse responses and 167 materials.
The F1 score of the detections was 98%, with an even precision and recall. The
method finds direct applications in architectural acoustics and in creating
more parsimonious models for acoustic reflections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05857</identifier>
 <datestamp>2019-01-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05857</id><created>2019-01-17</created><authors><author><keyname>Gaffoglio</keyname><forenames>Rossella</forenames></author><author><keyname>Cagliero</keyname><forenames>Andrea</forenames></author><author><keyname>Vecchi</keyname><forenames>Giuseppe</forenames></author><author><keyname>Andriulli</keyname><forenames>Francesco P.</forenames></author></authors><title>Vortex Waves and Channel Capacity: Hopes and Reality</title><categories>physics.optics eess.SP</categories><comments>8 pages, 7 figures</comments><journal-ref>IEEE Access, vol. 6, pp. 19814-19822, 2018</journal-ref><doi>10.1109/ACCESS.2017.2786467</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several recent contributions have envisioned the possibility of increasing
currently exploitable maximum channel capacity of a free space link, both at
optical and radio frequencies, by using vortex waves, i.e. carrying Orbital
Angular Momentum (OAM). Our objective is to disprove these claims by showing
that they are in contradiction with very fundamental properties of Maxwellian
fields. We demonstrate that the Degrees of Freedom (DoF) of the field cannot be
increased by the helical phase structure of electromagnetic vortex waves beyond
what can be done without invoking this property. We also show that the
often-advocated over-quadratic power decay of OAM beams with distance does not
play any fundamental role in the determination of the channel DoF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05885</identifier>
 <datestamp>2019-01-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05885</id><created>2019-01-17</created><authors><author><keyname>Damavandi</keyname><forenames>Hamidreza Ghasemi</forenames></author><author><keyname>Shah</keyname><forenames>Reepal</forenames></author></authors><title>A Learning Framework for An Accurate Prediction of Rainfall Rates</title><categories>eess.SP stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work is aimed to examine the potential of advanced machine
learning strategies to predict the monthly rainfall (precipitation) for the
Indus Basin, using climatological variables such as air temperature,
geo-potential height, relative humidity and elevation. In this work, the focus
is on thirteen geographical locations, called index points, within the basin.
Arguably, not all of the hydrological components are relevant to the
precipitation rate, and therefore, need to be filtered out, leading to a
lower-dimensional feature space. Towards this goal, we adopted the gradient
boosting method to extract the most contributive features for precipitation
rate prediction. Five state-of-the-art machine learning methods have then been
trained where pearson correlation coefficient and mean absolute error have been
reported as the prediction performance criteria. The Random Forest regression
model outperformed the other regression models achieving the maximum pearson
correlation coefficient and minimum mean absolute error for most of the index
points. Our results suggest the relative humidity (for pressure levels of 300
mb and 150 mb, respectively), the u-direction wind (for pressure level of 700
mb), air temperature (for pressure levels of 150 mb and 10 mb, respectively) as
the top five influencing features for accurate forecasting the precipitation
rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.05914</identifier>
 <datestamp>2019-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.05914</id><created>2019-01-17</created><authors><author><keyname>Zheng</keyname><forenames>Tianhang</forenames></author><author><keyname>Sun</keyname><forenames>Zhi</forenames></author><author><keyname>Ren</keyname><forenames>Kui</forenames></author></authors><title>FID: Function Modeling-based Data-Independent and Channel-Robust
  Physical-Layer Identification</title><categories>cs.CR eess.SP</categories><comments>Accepted to INFOCOM2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trusted identification is critical to secure IoT devices. However, the
limited memory and computation power of low-end IoT devices prevent the direct
usage of conventional identification systems. RF fingerprinting is a promising
technique to identify low-end IoT devices since it only requires the RF signals
that most IoT devices can produce for communication. However, most existing RF
fingerprinting systems are data-dependent and/or not robust to impacts from
wireless channels. To address the above problems, we propose to exploit the
mathematical expression of the physical-layer process, regarded as a function
$\mathbf{\mathcal{F}(\cdot)}$, for device identification.
$\mathbf{\mathcal{F}(\cdot)}$ is not directly derivable, so we further propose
a model to learn it and employ this function model as the device fingerprint in
our system, namely $\mathcal{F}$ID. Our proposed function model characterizes
the unique physical-layer process of a device that is independent of the
transmitted data, and hence, our system $\mathcal{F}$ID is data-independent and
thus resilient against signal replay attacks. Modeling and further separating
channel effects from the function model makes $\mathcal{F}$ID channel-robust.
We evaluate $\mathcal{F}$ID on thousands of random signal packets from $33$
different devices in different environments and scenarios, and the overall
identification accuracy is over $99\%$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06011</identifier>
 <datestamp>2019-01-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06011</id><created>2019-01-17</created><authors><author><keyname>Rezvani</keyname><forenames>Mohammad Mehdi</forenames></author><author><keyname>Mehraeen</keyname><forenames>Shahab</forenames></author></authors><title>A New Approach for Steady-State Analysis of a Hybrid ac-dc Microgrid</title><categories>eess.SP cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dc grid became more popular, by emerging the distributed generations
(DGs). Despite this popularity, the dc grid is not yet widely used because the
majority of loads in a power system are ac, which means the ac grid is still
the dominant grid in the power system. Therefore, the concept of a hybrid ac-dc
microgrid was emerged because of this contradiction. Hybrid ac-dc microgrid was
introduced in order to exploit the benefits of both ac and dc microgrids.
However, the combination of both ac and dc microgrids will add more complexity
to the network. Because in all studies for hybrid ac-dc microgrid, such as
steady-state analysis or dynamic study, two sets of equations should be
considered and solved either separately or simultaneously, the solutions that
were presented before. These solutions increase the time of simulation and
operation. In this paper, a novel procedure for steady-state analysis of a
general hybrid ac-dc microgrid is proposed. In this technique, the dc
microgrids will be transferred to the ac side by proposing two lemmas and then
the whole grid will be analyzed as one ac network. It will be proved that not
only the new ac grid has the same power flow result with the initial topology
of the ac-dc microgrid, but also the simulation time of the proposed method is
less than the other existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06034</identifier>
 <datestamp>2019-01-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06034</id><created>2019-01-17</created><authors><author><keyname>Lu</keyname><forenames>Si</forenames></author></authors><title>High-speed Video from Asynchronous Camera Array</title><categories>cs.CV cs.GR eess.IV</categories><comments>10 pages, 82 figures, Published at IEEE WACV 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for capturing high-speed video using an
asynchronous camera array. Our method sequentially fires each sensor in a
camera array with a small time offset and assembles captured frames into a
high-speed video according to the time stamps. The resulting video, however,
suffers from parallax jittering caused by the viewpoint difference among
sensors in the camera array. To address this problem, we develop a dedicated
novel view synthesis algorithm that transforms the video frames as if they were
captured by a single reference sensor. Specifically, for any frame from a
non-reference sensor, we find the two temporally neighboring frames captured by
the reference sensor. Using these three frames, we render a new frame with the
same time stamp as the non-reference frame but from the viewpoint of the
reference sensor. Specifically, we segment these frames into super-pixels and
then apply local content-preserving warping to warp them to form the new frame.
We employ a multi-label Markov Random Field method to blend these warped
frames. Our experiments show that our method can produce high-quality and
high-speed video of a wide variety of scenes with large parallax, scene
dynamics, and camera motion and outperforms several baseline and
state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06046</identifier>
 <datestamp>2019-01-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06046</id><created>2019-01-17</created><authors><author><keyname>Lu</keyname><forenames>Si</forenames></author></authors><title>Good Similar Patches for Image Denoising</title><categories>cs.CV cs.GR eess.IV</categories><comments>10 pages, 13 figures, 6 tables, IEEE WACV 2019</comments><doi>10.1109/WACV.2019.00205</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Patch-based denoising algorithms like BM3D have achieved outstanding
performance. An important idea for the success of these methods is to exploit
the recurrence of similar patches in an input image to estimate the underlying
image structures. However, in these algorithms, the similar patches used for
denoising are obtained via Nearest Neighbour Search (NNS) and are sometimes not
optimal. First, due to the existence of noise, NNS can select similar patches
with similar noise patterns to the reference patch. Second, the unreliable
noisy pixels in digital images can bring a bias to the patch searching process
and result in a loss of color fidelity in the final denoising result. We
observe that given a set of good similar patches, their distribution is not
necessarily centered at the noisy reference patch and can be approximated by a
Gaussian component. Based on this observation, we present a patch searching
method that clusters similar patch candidates into patch groups using Gaussian
Mixture Model-based clustering, and selects the patch group that contains the
reference patch as the final patches for denoising. We also use an unreliable
pixel estimation algorithm to pre-process the input noisy images to further
improve the patch searching. Our experiments show that our approach can better
capture the underlying patch structures and can consistently enable the
state-of-the-art patch-based denoising algorithms, such as BM3D, LPCA and PLOW,
to better denoise images by providing them with patches found by our approach
while without modifying these algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06115</identifier>
 <datestamp>2019-01-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06115</id><created>2019-01-18</created><authors><author><keyname>Zhang</keyname><forenames>Yue</forenames></author><author><keyname>Wu</keyname><forenames>Jiong</forenames></author><author><keyname>Chen</keyname><forenames>Wanli</forenames></author><author><keyname>Chen</keyname><forenames>Yifan</forenames></author><author><keyname>Tang</keyname><forenames>Xiaoying</forenames></author></authors><title>Prostate segmentation using Z-net</title><categories>eess.IV</categories><comments>IEEE International Symposium on Biomedical Imaging, Venice Italy.
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we proposed a novel architecture of convolutional neural
network (CNN), namely Z-net, for segmenting prostate from magnetic resonance
images (MRIs). In the proposed Z-net, 5 pairs of Z-block and decoder Z-block
with different sizes and numbers of feature maps were assembled in a way
similar to that of U-net. The proposed architecture can capture more
multi-level features by using concatenation and dense connection. A total of 45
training images were used to train the proposed Z-net and the evaluations were
conducted qualitatively on 5 validation images and quantitatively on 30 testing
images. In addition, three approaches including pad and cut, 2D resize, and 3D
resize for uniforming the size of samples were evaluated and compared. The
experimental results demonstrated that the 2D resize is the most suitable
approach for the proposed Z-net. Compared to the other two classical CNN
architectures, the proposed method was observed with superior performance for
segmenting prostate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06134</identifier>
 <datestamp>2019-01-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06134</id><created>2019-01-18</created><authors><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Xiang</keyname><forenames>Chenlu</forenames></author><author><keyname>Cao</keyname><forenames>Shan</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author><author><keyname>Zhu</keyname><forenames>Jiang</forenames></author></authors><title>Dynamic Carrier and Power Amplifier Mapping for Energy Efficient
  Multi-Carrier Wireless Communications</title><categories>eess.SP cs.NI</categories><doi>10.1109/ICC.2018.8422875</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid increasing demand of wireless transmission has incurred mobile
broadband to continuously evolve through multiple frequency bands, massive
antennas and other multi-stream processing schemes. Together with the improved
data transmission rate, the power consumption for multi-carrier transmission
and processing is proportionally increasing, which contradicts with the energy
efficiency requirements of 5G wireless systems. To meet this challenge, multi
carrier power amplifier (MCPA) technology, e.g., to support multiple carriers
through a single power amplifier, is widely deployed in practical. With massive
carriers required for 5G communication and limited number of carriers supported
per MCPA, a natural question to ask is how to map those carriers into multiple
MCPAs and whether we shall dynamically adjust this mapping relation. In this
paper, we have theoretically formulated the dynamic carrier and MCPA mapping
problem to jointly optimize the traditional separated baseband and radio
frequency processing. On top of that, we have also proposed a low complexity
algorithm that can achieve most of the power saving with affordable
computational time, if compared with the optimal exhaustive search based
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06162</identifier>
 <datestamp>2019-01-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06162</id><created>2019-01-18</created><authors><author><keyname>Liu</keyname><forenames>Qian</forenames></author><author><keyname>He</keyname><forenames>Xingkang</forenames></author><author><keyname>Fang</keyname><forenames>Haitao</forenames></author></authors><title>Asymptotic Properties of Distributed Social Sampling Algorithm</title><categories>cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social sampling is a novel randomized message passing protocol inspired by
social communication for opinion formation in social networks. In a typical
social sampling algorithm, each agent holds a sample from the empirical
distribution of social opinions at initial time, and it collaborates with other
agents in a distributed manner to estimate the initial empirical distribution
by randomly sampling a message from current distribution estimate. In this
paper, we focus on analyzing the theoretical properties of the distributed
social sampling algorithm over random networks. Firstly, we provide a framework
based on stochastic approximation to study the asymptotic properties of the
algorithm. Then, under mild conditions, we prove that the estimates of all
agents converge to a common random distribution, which is composed of the
initial empirical distribution and the accumulation of quantized error.
Besides, by tuning algorithm parameters, we prove the strong consistency,
namely, the distribution estimates of agents almost surely converge to the
initial empirical distribution. Furthermore, the asymptotic normality of
estimation error generated by distributed social sampling algorithm is
addressed. Finally, we provide a numerical simulation to validate the
theoretical results of this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06254</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06254</id><created>2019-01-18</created><updated>2019-01-22</updated><authors><author><keyname>Seifert</keyname><forenames>Bastian</forenames></author></authors><title>FFT and orthogonal discrete transform on weight lattices of semi-simple
  Lie groups</title><categories>math.NA cs.IT eess.SP math.IT math.RT</categories><comments>37 pages, 12 figures</comments><msc-class>65T50, 15A23, 33F99, 68R01, 16G99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give two algebro-geometric inspired approaches to fast algorithms for
Fourier transforms in algebraic signal processing theory based on polynomial
algebras in several variables. One is based on module induction and one is
based on a decomposition property of certain polynomials. The Gauss-Jacobi
procedure for the derivation of orthogonal transforms is extended to the
multivariate setting. This extension relies on a multivariate
Christoffel-Darboux formula for orthogonal polynomials in several variables. As
a set of application examples a general scheme for the derivation of fast
transforms of weight lattices based on multivariate Chebyshev polynomials is
derived. A special case of such transforms is considered, where one can apply
the Gauss-Jacobi procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06396</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06396</id><created>2019-01-18</created><updated>2019-01-29</updated><authors><author><keyname>Zhu</keyname><forenames>Lijun</forenames></author><author><keyname>Peng</keyname><forenames>Zhigang</forenames></author><author><keyname>McClellan</keyname><forenames>James</forenames></author><author><keyname>Li</keyname><forenames>Chenyu</forenames></author><author><keyname>Yao</keyname><forenames>Dongdong</forenames></author><author><keyname>Li</keyname><forenames>Zefeng</forenames></author><author><keyname>Fang</keyname><forenames>Lihua</forenames></author></authors><title>Deep learning for seismic phase detection and picking in the aftershock
  zone of 2008 Mw7.9 Wenchuan earthquake</title><categories>physics.geo-ph cs.LG eess.SP</categories><doi>10.1016/j.pepi.2019.05.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing volume of seismic data from long-term continuous monitoring
motivates the development of algorithms based on convolutional neural network
(CNN) for faster and more reliable phase detection and picking. However, many
less studied regions lack a significant amount of labeled events needed for
traditional CNN approaches. In this paper, we present a CNN-based Phase-
Identification Classifier (CPIC) designed for phase detection and picking on
small to medium sized training datasets. When trained on 30,146 labeled phases
and applied to one-month of continuous recordings during the aftershock
sequences of the 2008 MW 7.9 Wenchuan Earthquake in Sichuan, China, CPIC
detects 97.5% of the manually picked phases in the standard catalog and
predicts their arrival times with a five-times improvement over the ObsPy AR
picker. In addition, unlike other CNN-based approaches that require millions of
training samples, when the off-line training set size of CPIC is reduced to
only a few thousand training samples the accuracy stays above 95%. The online
implementation of CPIC takes less than 12 hours to pick arrivals in 31-day
recordings on 14 stations. In addition to the catalog phases manually picked by
analysts, CPIC finds more phases for existing events and new events missed in
the catalog. Among those additional detections, some are confirmed by a matched
filter method while others require further investigation. Finally, when tested
on a small dataset from a different region (Oklahoma, US), CPIC achieves 97%
accuracy after fine tuning only the fully connected layer of the model. This
result suggests that the CPIC developed in this study can be used to identify
and pick P/S arrivals in other regions with no or minimum labeled phases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06453</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06453</id><created>2019-01-18</created><updated>2019-04-21</updated><authors><author><keyname>Barmherzig</keyname><forenames>David A.</forenames></author><author><keyname>Sun</keyname><forenames>Ju</forenames></author><author><keyname>Lane</keyname><forenames>T. J.</forenames></author><author><keyname>Li</keyname><forenames>Po-Nan</forenames></author><author><keyname>Cand&#xe8;s</keyname><forenames>Emmanuel J.</forenames></author></authors><title>Holographic Phase Retrieval and Reference Design</title><categories>cs.IT eess.SP math.IT math.NA math.OC</categories><comments>27 pages, 10 figures</comments><doi>10.1088/1361-6420/ab23d1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general mathematical framework and recovery algorithm is presented for the
holographic phase retrieval problem. In this problem, which arises in
holographic coherent diffraction imaging, a &quot;reference&quot; portion of the signal
to be recovered via phase retrieval is a priori known from experimental design.
A generic formula is also derived for the expected recovery error when the
measurement data is corrupted by Poisson shot noise. This facilitates an
optimization perspective towards reference design and analysis. We employ this
optimization perspective towards quantifying the performance of various
reference choices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06469</identifier>
 <datestamp>2019-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06469</id><created>2019-01-19</created><updated>2019-12-16</updated><authors><author><keyname>Zhang</keyname><forenames>Jing</forenames></author><author><keyname>Tian</keyname><forenames>Jing</forenames></author><author><keyname>Cao</keyname><forenames>Yang</forenames></author><author><keyname>Yang</keyname><forenames>Yuxiang</forenames></author><author><keyname>Xu</keyname><forenames>Xiaobin</forenames></author></authors><title>Deep Time-Frequency Representation and Progressive Decision Fusion for
  ECG Classification</title><categories>cs.LG eess.SP stat.ML</categories><comments>30 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early recognition of abnormal rhythms in ECG signals is crucial for
monitoring and diagnosing patients' cardiac conditions, increasing the success
rate of the treatment. Classifying abnormal rhythms into exact categories is
very challenging due to the broad taxonomy of rhythms, noises and lack of
large-scale real-world annotated data. Different from previous methods that
utilize hand-crafted features or learn features from the original signal
domain, we propose a novel ECG classification method by learning deep
time-frequency representation and progressive decision fusion at different
temporal scales in an end-to-end manner. First, the ECG wave signal is
transformed into the time-frequency domain by using the Short-Time Fourier
Transform. Next, several scale-specific deep convolutional neural networks are
trained on ECG samples of a specific length. Finally, a progressive online
decision fusion method is proposed to fuse decisions from the scale-specific
models into a more accurate and stable one. Extensive experiments on both
synthetic and real-world ECG datasets demonstrate the effectiveness and
efficiency of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06486</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06486</id><created>2019-01-19</created><authors><author><keyname>Bertero</keyname><forenames>Dario</forenames></author><author><keyname>Kampman</keyname><forenames>Onno</forenames></author><author><keyname>Fung</keyname><forenames>Pascale</forenames></author></authors><title>Towards Universal End-to-End Affect Recognition from Multilingual Speech
  by ConvNets</title><categories>cs.CL cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an end-to-end affect recognition approach using a Convolutional
Neural Network (CNN) that handles multiple languages, with applications to
emotion and personality recognition from speech. We lay the foundation of a
universal model that is trained on multiple languages at once. As affect is
shared across all languages, we are able to leverage shared information between
languages and improve the overall performance for each one. We obtained an
average improvement of 12.8% on emotion and 10.1% on personality when compared
with the same model trained on each language only. It is end-to-end because we
directly take narrow-band raw waveforms as input. This allows us to accept as
input audio recorded from any source and to avoid the overhead and information
loss of feature extraction. It outperforms a similar CNN using spectrograms as
input by 12.8% for emotion and 6.3% for personality, based on F-scores.
Analysis of the network parameters and layers activation shows that the network
learns and extracts significant features in the first layer, in particular
pitch, energy and contour variations. Subsequent convolutional layers instead
capture language-specific representations through the analysis of
supra-segmental features. Our model represents an important step for the
development of a fully universal affect recognizer, able to recognize
additional descriptors, such as stress, and for the future implementation into
affective interactive systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06528</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06528</id><created>2019-01-19</created><authors><author><keyname>Kumar</keyname><forenames>Vivek</forenames></author><author><keyname>Samadhiya</keyname><forenames>Atul</forenames></author></authors><title>Image De-Noising For Salt and Pepper Noise by Introducing New Enhanced
  Filter</title><categories>cs.CV cs.LG eess.IV</categories><comments>5 pages, 3 Figures, 2 Tables, International Conference on Innovations
  in Engineering and Technology (ICIET'2013) Dec. 25-26, 2013 Bangkok
  (Thailand)</comments><journal-ref>ICIET'2013 pp 53-57, 2013</journal-ref><doi>10.15242/IIE.E1213577</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When an image is formed, factors such as lighting (spectra, source, and
intensity) and camera characteristics (sensor response, lenses) affect the
appearance of the image. Therefore, the prime factor that reduces the quality
of the image is noise. It hides the important details and information of
images. In order to enhance the qualities of the image, the removal of noises
become imperative and that should not at the cost of any loss of image
information. Noise removal is one of the pre-processing stages of image
processing. In this paper a new method for the enhancement of grayscale images
is introduced, when images are corrupted by fixed valued impulse noise (salt
and pepper noise). The proposed methodology ensures a better output for the low
and medium density of fixed value impulse noise as compared to the other famous
filters like Standard Median Filter (SMF), Decision Based Median Filter (DBMF)
and Modified Decision Based Median Filter (MDBMF) etc. The main objective of
the proposed method was to improve peak signal to noise ratio (PSNR), visual
perception and reduction in the blurring of the image. The proposed algorithm
replaced the noisy pixel by trimmed mean value. When previous pixel values, 0s,
and 255s are present in the particular window and all the pixel values are 0s
and 255s then the remaining noisy pixels are replaced by mean value. The
gray-scale image of mandrill and Lena were tested via the proposed method. The
experimental result shows better peak signal to noise ratio (PSNR), mean square
error values with better visual and human perception.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06529</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06529</id><created>2019-01-19</created><authors><author><keyname>Kumar</keyname><forenames>Vivek</forenames></author><author><keyname>Samadhiya</keyname><forenames>Atul</forenames></author></authors><title>Comparative Performance Analysis of Image De-noising Techniques</title><categories>cs.CV cs.LG eess.IV</categories><comments>6 pages, 9 figures, 1 Table, International Conference on Innovations
  in Engineering and Technology (ICIET'2013) Dec. 25-26, 2013 Bangkok
  (Thailand)</comments><journal-ref>ICIET pages 47-52, 2013</journal-ref><doi>10.15242/IIE.E1213576</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noise is an important factor which when get added to an image reduces its
quality and appearance. So in order to enhance the image qualities, it has to
be removed with preserving the textural information and structural features of
image. There are different types of noises exist who corrupt the images.
Selection of the denoising algorithm is application dependent. Hence, it is
necessary to have knowledge about the noise present in the image so as to
select the appropriate denoising algorithm. Objective of this paper is to
present brief account on types of noises, its types and different noise removal
algorithms. In the first section types of noises on the basis of their additive
and multiplicative nature are being discussed. In second section a precise
classification and analysis of the different potential image denoising
algorithm is presented. At the end of paper, a comparative study of all these
algorithms in context of performance evaluation is done and concluded with
several promising directions for future research work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06537</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06537</id><created>2019-01-19</created><authors><author><keyname>Huang</keyname><forenames>Hongji</forenames></author><author><keyname>Song</keyname><forenames>Yiwei</forenames></author><author><keyname>Yang</keyname><forenames>Jie</forenames></author><author><keyname>Gui</keyname><forenames>Guan</forenames></author><author><keyname>Adachi</keyname><forenames>Fumiyuki</forenames></author></authors><title>Deep-Learning-based Millimeter-Wave Massive MIMO for Hybrid Precoding</title><categories>eess.SP</categories><comments>This paper has been accepted by the IEEE TVT</comments><doi>10.1109/TVT.2019.2893928</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) has
been regarded to be an emerging solution for the next generation of
communications, in which hybrid analog and digital precoding is an important
method for reducing the hardware complexity and energy consumption associated
with mixed signal components. However, the fundamental limitations of the
existing hybrid precoding schemes is that they have high computational
complexity and fail to fully exploit the spatial information. To overcome these
limitations, this paper proposes, a deep-learning-enabled mmWave massive MIMO
framework for effective hybrid precoding, in which each selection of the
precoders for obtaining the optimized decoder is regarded as a mapping relation
in the deep neural network (DNN). Specifically, the hybrid precoder is selected
through training based on the DNN for optimizing precoding process of the
mmWave massive MIMO. Additionally, we present extensive simulation results to
validate the excellent performance of the proposed scheme. The results exhibit
that the DNN-based approach is capable ofminimizing the bit error ratio (BER)
and enhancing spectrum efficiency of the mmWave massive MIMO, which achieves
better performance in hybrid precoding compared with conventional schemes while
substantially reducing the required computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06650</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06650</id><created>2019-01-20</created><authors><author><keyname>Hasanshahi</keyname><forenames>Zabihollah</forenames></author><author><keyname>Azmi</keyname><forenames>Paeiz</forenames></author><author><keyname>Khajezadeh</keyname><forenames>Mohammad</forenames></author></authors><title>Fading Model Deviation in The NLOS Communication Channel in Limited
  Reflection</title><categories>eess.SP</categories><comments>7 pages,10 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical models are employed to characterize the clutter in the radar and
the reflective signals of the telecommunication receivers. End to this,
Rayliegh distribution is the simplest fading models in NLOS channels possessing
low-accuracy in the high-resolution radars and distant telecommunication
receivers. At present, high accuracy models such as the m-type Nakagami and
hybrid GG distributions are utilized in order to model fading. However, despite
the Non-Rayliegh models have better precision in the NLOS relative to the
Rayliegh models, the accuracy of these models decreases when the radiation
angle in the transmitter and the reflection angle in the receiver are
different. In this paper, the K distribution function is analytically
introduced and deployed to model the fading using practical data. Although this
model was previously introduced to describe the clutter properties of the radar
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06776</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06776</id><created>2019-01-20</created><authors><author><keyname>Wu</keyname><forenames>Chunyu</forenames></author><author><keyname>Sun</keyname><forenames>Ze</forenames></author><author><keyname>Wang</keyname><forenames>Xu</forenames></author><author><keyname>Wang</keyname><forenames>Yansheng</forenames></author><author><keyname>Kim</keyname><forenames>Ben</forenames></author><author><keyname>Fan</keyname><forenames>Jun</forenames></author></authors><title>An Improved Dipole Extraction Method From Magnitude-Only
  Electromagnetic-Field Data</title><categories>eess.SP physics.class-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Infinitesimal electric and magnetic dipoles are widely used as an equivalent
radiating source model. In this paper, an improved method for dipole extraction
from magnitude-only electromagnetic-field data based on genetic algorithm and
back-and-forth iteration algorithm [1] is proposed. Compared with conventional
back-and-forth iteration algorithm, this method offers an automatic flow to
extract the equivalent dipoles without prior decision of the type, position,
orientation and number of dipoles. It can be easily applied to
electromagnetic-field data on arbitrarily shaped surfaces and minimize the
number of required dipoles. The extracted dipoles can be close to original
radiating structure, thus being physical. Compared with conventional genetic
algorithm based method, this method reduces the optimization time and will not
easily get trapped into local minima during optimization, thus being more
robust. This method is validated by both simulation data and measurement data
and its advantages are proved. The potential application of this method in
phase retrieval is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06791</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06791</id><created>2019-01-20</created><authors><author><keyname>Jeong</keyname><forenames>Min-Oh</forenames></author><author><keyname>Hong</keyname><forenames>Song-Nam</forenames></author></authors><title>SC-Fano Decoding of Polar Codes</title><categories>eess.SP cs.IT math.IT</categories><comments>5pages, 5figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel decoding algorithm of a polar code, named
SC-Fano decoding, by appropriately incorporating the Fano sequential decoding
into the standard successive-cancellation (SC) decoding. The proposed SC-Fano
decoding follows the basic procedures of SC decoding with an additional
operation to evaluate the reliability (or belief) of a current partial path.
Specifically, at every decoding stage, it decides whether to move forward along
a current path or move backward to find a more likelihood path. In this way,
SC-Fano decoding can address the inherent drawback of SC decoding such as one
wrong-decision will surely lead to a wrong codeword. Compared with the other
improvements of SC decoding as SC-List (SCL) and SC-Stack (SCS) decodings,
SC-Fano decoding has much lower memory requirement and thus is more suitable
for hardware implementations. Also, SC- Fano decoding can be viewed as an
efficient implementation of SC-Flip (SCF) decoding without the cost of
cyclic-redundancy-code (CRC). Simulation results show that the proposed SC-Fano
decoding significantly enhances the performance of SC decoding with a similar
complexity as well as achieves the performance of SCL decoding with a lower
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06817</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06817</id><created>2019-01-21</created><authors><author><keyname>Xu</keyname><forenames>Dongyang</forenames></author><author><keyname>Ren</keyname><forenames>Pinyi</forenames></author><author><keyname>Ritcey</keyname><forenames>James A.</forenames></author></authors><title>Hierarchical 2-D Feature Coding for Secure Pilot Authentication in
  Multi-User Multi-Antenna OFDM Systems: A Reliability Bound Contraction
  Perspective</title><categories>eess.SP cs.CR</categories><journal-ref>IEEE Trans. Inf. Forensics and Security, 2018, vol.14, no. 3, Mar.
  2019</journal-ref><doi>10.1109/TIFS.2018.2859585</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the publicly known and deterministic characteristic of pilot tones,
pilot authentication (PA) in multi-user multi-antenna orthogonal
frequency-division multiplexing systems is very susceptible to the
jamming/nulling/spoofing behaviors. To solve this, in this paper, we develop a
hierarchical 2-D feature (H2DF) coding theory that exploits the hidden pilot
signal features, i.e., the energy feature and independence feature, to secure
pilot information coding which is applied between legitimate parties through a
well-designed five-layer hierarchical coding model to achieve secure multiuser
PA (SMPA). The reliability of SMPA is characterized using the identification
error probability (IEP) of pilot encoding and decoding with the exact
closed-form upper and lower bounds. However, this phenomenon of non-tight
bounds brings about the risk of long-term instability in SMPA. Therefore, a
reliability bound contraction theory is developed to shrink the bound interval,
and practically, this is done by an easy-to-implement technique, namely,
codebook partition within the H2DF code. In this process, a tradeoff between
the upper and lower bounds of IEP is identified and a problem of optimal upper
and lower bound tradeoff is formulated, with the objective of optimizing the
cardinality of sub-codebooks such that the upper and lower bounds coincide.
Solving this, we finally derive an exact closed-form expression for IEP, which
realizes a stable and highly reliable SMPA. Numerical results validate the
stability and resilience of H2DF coding in SMPA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06836</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06836</id><created>2019-01-21</created><authors><author><keyname>Callebaut</keyname><forenames>Gilles</forenames></author><author><keyname>Ottoy</keyname><forenames>Geoffrey</forenames></author><author><keyname>Leenders</keyname><forenames>Guus</forenames></author><author><keyname>Thoen</keyname><forenames>Bart</forenames></author><author><keyname>De Strycker</keyname><forenames>Lieven</forenames></author><author><keyname>Van der Perre</keyname><forenames>Liesbet</forenames></author></authors><title>Remote IoT devices: sleepy strategies and signal processing to the
  rescue for a long battery life</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Long range wireless connectivity opens the door for new IoT applications. Low
energy consumption is essential to enable long autonomy of devices powered by
batteries or even relying on harvested energy. This paper introduces
technologies for long-distance interaction with energy-constraint embedded
devices. It proposes sleepy strategies for power management for the platform
and the transmission. Adequate signal processing on the remote modules is
demonstrated to play a crucial role to sustain the autonomy of these systems.
The presented open-source development platform invites the signal processing
community to a smooth validation of new algorithms and applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06878</identifier>
 <datestamp>2019-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06878</id><created>2019-01-21</created><updated>2019-06-05</updated><authors><author><keyname>Chen</keyname><forenames>Bin</forenames></author><author><keyname>Okonkwo</keyname><forenames>Chigo</forenames></author><author><keyname>Hafermann</keyname><forenames>Hartmut</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author></authors><title>Polarization-ring-switching for nonlinearity-tolerant
  geometrically-shaped four-dimensional formats maximizing generalized mutual
  information</title><categories>eess.SP cs.IT math.IT</categories><comments>12 pages, 12 figures</comments><journal-ref>Journal of Lightwave Technology, 2019</journal-ref><doi>10.1109/JLT.2019.2918072</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, a new four-dimensional 64-ary polarization ring switching
(4D-64PRS) modulation format with a spectral efficiency of 6 bit/4D-sym is
introduced. The format is designed by maximizing the generalized mutual
information (GMI) and by imposing a constant-modulus on the 4D structure. The
proposed format yields an improved performance with respect to state-of-the-art
geometrically shaped modulation formats for bit-interleaved coded modulation
systems at the same spectral efficiency. Unlike previously published results,
the coordinates of the constellation points and the binary labeling of the
constellation are jointly optimized. When compared with
polarization-multiplexed 8-ary quadrature-amplitude modulation (PM-8QAM), gains
of up to 0.7 dB in signal-to-noise ratio are observed in the additive white
Gaussian noise (AWGN) channel. For a long-haul nonlinear optical fiber system
of 8,000 km, gains of up to 0.27 bit/4D-sym (5.5% data capacity increase) are
observed. These gains translate into a reach increase of approximately 16%
(1,100 km). The proposed modulation format is also shown to be more tolerant to
nonlinearities than PM-8QAM. Results with LDPC codes are also presented, which
confirm the gains predicted by the GMI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.06904</identifier>
 <datestamp>2019-03-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.06904</id><created>2019-01-21</created><updated>2019-03-22</updated><authors><author><keyname>Strisciuglio</keyname><forenames>Nicola</forenames></author><author><keyname>Vento</keyname><forenames>Mario</forenames></author><author><keyname>Petkov</keyname><forenames>Nicolai</forenames></author></authors><title>Learning sound representations using trainable COPE feature extractors</title><categories>eess.AS cs.LG cs.SD</categories><comments>Accepted for publication in Pattern Recognition</comments><journal-ref>Pattern Recognition (2019)</journal-ref><doi>10.1016/j.patcog.2019.03.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sound analysis research has mainly been focused on speech and music
processing. The deployed methodologies are not suitable for analysis of sounds
with varying background noise, in many cases with very low signal-to-noise
ratio (SNR). In this paper, we present a method for the detection of patterns
of interest in audio signals. We propose novel trainable feature extractors,
which we call COPE (Combination of Peaks of Energy). The structure of a COPE
feature extractor is determined using a single prototype sound pattern in an
automatic configuration process, which is a type of representation learning. We
construct a set of COPE feature extractors, configured on a number of training
patterns. Then we take their responses to build feature vectors that we use in
combination with a classifier to detect and classify patterns of interest in
audio signals. We carried out experiments on four public data sets: MIVIA audio
events, MIVIA road events, ESC-10 and TU Dortmund data sets. The results that
we achieved (recognition rate equal to 91.71% on the MIVIA audio events, 94% on
the MIVIA road events, 81.25% on the ESC-10 and 94.27% on the TU Dortmund)
demonstrate the effectiveness of the proposed method and are higher than the
ones obtained by other existing approaches. The COPE feature extractors have
high robustness to variations of SNR. Real-time performance is achieved even
when the value of a large number of features is computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07031</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07031</id><created>2019-01-21</created><authors><author><keyname>Irvin</keyname><forenames>Jeremy</forenames></author><author><keyname>Rajpurkar</keyname><forenames>Pranav</forenames></author><author><keyname>Ko</keyname><forenames>Michael</forenames></author><author><keyname>Yu</keyname><forenames>Yifan</forenames></author><author><keyname>Ciurea-Ilcus</keyname><forenames>Silviana</forenames></author><author><keyname>Chute</keyname><forenames>Chris</forenames></author><author><keyname>Marklund</keyname><forenames>Henrik</forenames></author><author><keyname>Haghgoo</keyname><forenames>Behzad</forenames></author><author><keyname>Ball</keyname><forenames>Robyn</forenames></author><author><keyname>Shpanskaya</keyname><forenames>Katie</forenames></author><author><keyname>Seekins</keyname><forenames>Jayne</forenames></author><author><keyname>Mong</keyname><forenames>David A.</forenames></author><author><keyname>Halabi</keyname><forenames>Safwan S.</forenames></author><author><keyname>Sandberg</keyname><forenames>Jesse K.</forenames></author><author><keyname>Jones</keyname><forenames>Ricky</forenames></author><author><keyname>Larson</keyname><forenames>David B.</forenames></author><author><keyname>Langlotz</keyname><forenames>Curtis P.</forenames></author><author><keyname>Patel</keyname><forenames>Bhavik N.</forenames></author><author><keyname>Lungren</keyname><forenames>Matthew P.</forenames></author><author><keyname>Ng</keyname><forenames>Andrew Y.</forenames></author></authors><title>CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and
  Expert Comparison</title><categories>cs.CV cs.AI cs.LG eess.IV</categories><comments>Published in AAAI 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Large, labeled datasets have driven deep learning methods to achieve
expert-level performance on a variety of medical imaging tasks. We present
CheXpert, a large dataset that contains 224,316 chest radiographs of 65,240
patients. We design a labeler to automatically detect the presence of 14
observations in radiology reports, capturing uncertainties inherent in
radiograph interpretation. We investigate different approaches to using the
uncertainty labels for training convolutional neural networks that output the
probability of these observations given the available frontal and lateral
radiographs. On a validation set of 200 chest radiographic studies which were
manually annotated by 3 board-certified radiologists, we find that different
uncertainty approaches are useful for different pathologies. We then evaluate
our best model on a test set composed of 500 chest radiographic studies
annotated by a consensus of 5 board-certified radiologists, and compare the
performance of our model to that of 3 additional radiologists in the detection
of 5 selected pathologies. On Cardiomegaly, Edema, and Pleural Effusion, the
model ROC and PR curves lie above all 3 radiologist operating points. We
release the dataset to the public as a standard benchmark to evaluate
performance of chest radiograph interpretation models.
  The dataset is freely available at
https://stanfordmlgroup.github.io/competitions/chexpert .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07042</identifier>
 <datestamp>2019-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07042</id><created>2019-01-21</created><updated>2019-11-14</updated><authors><author><keyname>Johnson</keyname><forenames>Alistair E. W.</forenames></author><author><keyname>Pollard</keyname><forenames>Tom J.</forenames></author><author><keyname>Greenbaum</keyname><forenames>Nathaniel R.</forenames></author><author><keyname>Lungren</keyname><forenames>Matthew P.</forenames></author><author><keyname>Deng</keyname><forenames>Chih-ying</forenames></author><author><keyname>Peng</keyname><forenames>Yifan</forenames></author><author><keyname>Lu</keyname><forenames>Zhiyong</forenames></author><author><keyname>Mark</keyname><forenames>Roger G.</forenames></author><author><keyname>Berkowitz</keyname><forenames>Seth J.</forenames></author><author><keyname>Horng</keyname><forenames>Steven</forenames></author></authors><title>MIMIC-CXR-JPG, a large publicly available database of labeled chest
  radiographs</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chest radiography is an extremely powerful imaging modality, allowing for a
detailed inspection of a patient's thorax, but requiring specialized training
for proper interpretation. With the advent of high performance general purpose
computer vision algorithms, the accurate automated analysis of chest
radiographs is becoming increasingly of interest to researchers. However, a key
challenge in the development of these techniques is the lack of sufficient
data. Here we describe MIMIC-CXR-JPG v2.0.0, a large dataset of 377,110 chest
x-rays associated with 227,827 imaging studies sourced from the Beth Israel
Deaconess Medical Center between 2011 - 2016. Images are provided with 14
labels derived from two natural language processing tools applied to the
corresponding free-text radiology reports. MIMIC-CXR-JPG is derived entirely
from the MIMIC-CXR database, and aims to provide a convenient processed version
of MIMIC-CXR, as well as to provide a standard reference for data splits and
image labels. All images have been de-identified to protect patient privacy.
The dataset is made freely available to facilitate and encourage a wide range
of research in medical computer vision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07061</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07061</id><created>2019-01-21</created><authors><author><keyname>Tofighi</keyname><forenames>Mohammad</forenames></author><author><keyname>Guo</keyname><forenames>Tiantong</forenames></author><author><keyname>Vanamala</keyname><forenames>Jairam K. P.</forenames></author><author><keyname>Monga</keyname><forenames>Vishal</forenames></author></authors><title>Prior Information Guided Regularized Deep Learning for Cell Nucleus
  Detection</title><categories>eess.IV cs.LG stat.ML</categories><comments>Accepted for Publication</comments><journal-ref>IEEE Transactions on Medical Imaging, January 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cell nuclei detection is a challenging research topic because of limitations
in cellular image quality and diversity of nuclear morphology, i.e. varying
nuclei shapes, sizes, and overlaps between multiple cell nuclei. This has been
a topic of enduring interest with promising recent success shown by deep
learning methods. These methods train Convolutional Neural Networks (CNNs) with
a training set of input images and known, labeled nuclei locations. Many such
methods are supplemented by spatial or morphological processing. Using a set of
canonical cell nuclei shapes, prepared with the help of a domain expert, we
develop a new approach that we call Shape Priors with Convolutional Neural
Networks (SP-CNN). We further extend the network to introduce a shape prior
(SP) layer and then allowing it to become trainable (i.e. optimizable). We call
this network tunable SP-CNN (TSP-CNN). In summary, we present new network
structures that can incorporate 'expected behavior' of nucleus shapes via two
components: learnable layers that perform the nucleus detection and a fixed
processing part that guides the learning with prior information. Analytically,
we formulate two new regularization terms that are targeted at: 1) learning the
shapes, 2) reducing false positives while simultaneously encouraging detection
inside the cell nucleus boundary. Experimental results on two challenging
datasets reveal that the proposed SP-CNN and TSP-CNN can outperform
state-of-the-art alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07201</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07201</id><created>2019-01-22</created><authors><author><keyname>Cox</keyname><forenames>Mitchell A.</forenames></author><author><keyname>Toninelli</keyname><forenames>Ermes</forenames></author><author><keyname>Cheng</keyname><forenames>Ling</forenames></author><author><keyname>Padgett</keyname><forenames>Miles</forenames></author><author><keyname>Forbes</keyname><forenames>Andrew</forenames></author></authors><title>A high-speed, wavelength invariant, single-pixel wavefront sensor with a
  digital micromirror device</title><categories>physics.optics eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The wavefront measurement of a light beam is a complex task, which often
requires a series of spatially resolved intensity measurements. For instance, a
detector array may be used to measure the local phase gradient in the
transverse plane of the unknown laser beam. In most cases the resolution of the
reconstructed wavefront is determined by the resolution of the detector, which
in the infrared case is severely limited. Here we employ a Digital Micro-mirror
Device (DMD) and a single-pixel detector (i.e. with no spatial resolution) to
demonstrate the reconstruction of unknown wavefronts with excellent resolution.
Our approach exploits modal decomposition of the incoming field by the DMD,
enabling wavefront measurements at 4~kHz of both visible and infrared laser
beams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07239</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07239</id><created>2019-01-22</created><authors><author><keyname>Valentini-Botinhao</keyname><forenames>Cassia</forenames></author><author><keyname>Wester</keyname><forenames>Mirjam</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author><author><keyname>Toman</keyname><forenames>Markus</forenames></author><author><keyname>Pucher</keyname><forenames>Michael</forenames></author><author><keyname>Schabus</keyname><forenames>Dietmar</forenames></author></authors><title>Non linear time compression of clear and normal speech at high rates</title><categories>eess.AS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We compare a series of time compression methods applied to normal and clear
speech. First we evaluate a linear (uniform) method applied to these styles as
well as to naturally-produced fast speech. We found, in line with the
literature, that unprocessed fast speech was less intelligible than linearly
compressed normal speech. Fast speech was also less intelligible than
compressed clear speech but at the highest rate (three times faster than
normal) the advantage of clear over fast speech was lost. To test whether this
was due to shorter speech duration we evaluate, in our second experiments, a
range of methods that compress speech and silence at different rates. We found
that even when the overall duration of speech and silence is kept the same
across styles, compressed normal speech is still more intelligible than
compressed clear speech. Compressing silence twice as much as speech improved
results further for normal speech with very little additional computational
costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07368</identifier>
 <datestamp>2019-01-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07368</id><created>2019-01-13</created><authors><author><keyname>Lin</keyname><forenames>Yunfeng</forenames></author><author><keyname>Li</keyname><forenames>Jiangbei</forenames></author><author><keyname>Wang</keyname><forenames>Hanjing</forenames></author></authors><title>DCNN-GAN: Reconstructing Realistic Image from fMRI</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visualizing the perceptual content by analyzing human functional magnetic
resonance imaging (fMRI) has been an active research area. However, due to its
high dimensionality, complex dimensional structure, and small number of samples
available, reconstructing realistic images from fMRI remains challenging.
Recently with the development of convolutional neural network (CNN) and
generative adversarial network (GAN), mapping multi-voxel fMRI data to complex,
realistic images has been made possible. In this paper, we propose a model,
DCNN-GAN, by combining a reconstruction network and GAN. We utilize the CNN for
hierarchical feature extraction and the DCNN-GAN to reconstruct more realistic
images. Extensive experiments have been conducted, showing that our method
outperforms previous works, regarding reconstruction quality and computational
cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07375</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07375</id><created>2019-01-16</created><authors><author><keyname>Jung</keyname><forenames>Jay Hoon</forenames></author><author><keyname>Shin</keyname><forenames>Yousun</forenames></author><author><keyname>Kwon</keyname><forenames>YoungMin</forenames></author></authors><title>Extension of Convolutional Neural Network with General Image Processing
  Kernels</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>4 pages, 6 figures</comments><journal-ref>TENCON 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We applied pre-defined kernels also known as filters or masks developed for
image processing to convolution neural network. Instead of letting neural
networks find its own kernels, we used 41 different general-purpose kernels of
blurring, edge detecting, sharpening, discrete cosine transformation, etc. for
the first layer of the convolution neural networks. This architecture, thus
named as general filter convolutional neural network (GFNN), can reduce
training time by 30% with a better accuracy compared to the regular
convolutional neural network (CNN). GFNN also can be trained to achieve 90%
accuracy with only 500 samples. Furthermore, even though these kernels are not
specialized for the MNIST dataset, we achieved 99.56% accuracy without ensemble
nor any other special algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07384</identifier>
 <datestamp>2019-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07384</id><created>2019-01-22</created><updated>2019-10-29</updated><authors><author><keyname>Kawano</keyname><forenames>Yu</forenames></author><author><keyname>Cao</keyname><forenames>Ming</forenames></author></authors><title>Design of Differentially Private Dynamic Controllers</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a quantitative criterion for privacy of &quot;mechanisms&quot; in the form of
data-generating processes, the concept of differential privacy was first
proposed in computer science and has later been applied to linear dynamical
systems. However, differential privacy has not been studied in depth together
with other properties of dynamical systems, and it has not been fully utilized
for controller design. In this paper, first we clarify that a classical concept
in systems and control, input observability (sometimes referred to as left
invertibility) has a strong connection with differential privacy. In
particular, we show that the Gaussian mechanism can be made highly
differentially private by adding small noise if the corresponding system is
less input observable. Next, enabled by our new insight into privacy, we
develop a method to design dynamic controllers for a tracking problem while
addressing privacy concerns. We call the designed controller as such the
differentially private controller. The usage of such controllers is further
illustrated by solving a power supply problem in a DC microgrid with smart
meters where privacy issues are of concern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07429</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07429</id><created>2019-01-15</created><updated>2019-04-03</updated><authors><author><keyname>Aznan</keyname><forenames>Nik Khadijah Nik</forenames></author><author><keyname>Atapour-Abarghouei</keyname><forenames>Amir</forenames></author><author><keyname>Bonner</keyname><forenames>Stephen</forenames></author><author><keyname>Connolly</keyname><forenames>Jason</forenames></author><author><keyname>Moubayed</keyname><forenames>Noura Al</forenames></author><author><keyname>Breckon</keyname><forenames>Toby</forenames></author></authors><title>Simulating Brain Signals: Creating Synthetic EEG Data via Neural-Based
  Generative Models for Improved SSVEP Classification</title><categories>q-bio.QM eess.SP</categories><comments>Accepted as a full paper at International Joint Conference on Neural
  Network (IJCNN) 2019</comments><doi>10.1109/IJCNN.2019.8852227</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite significant recent progress in the area of Brain-Computer Interface
(BCI), there are numerous shortcomings associated with collecting
Electroencephalography (EEG) signals in real-world environments. These include,
but are not limited to, subject and session data variance, long and arduous
calibration processes and predictive generalisation issues across different
subjects or sessions. This implies that many downstream applications, including
Steady State Visual Evoked Potential (SSVEP) based classification systems, can
suffer from a shortage of reliable data. Generating meaningful and realistic
synthetic data can therefore be of significant value in circumventing this
problem. We explore the use of modern neural-based generative models trained on
a limited quantity of EEG data collected from different subjects to generate
supplementary synthetic EEG signal vectors, subsequently utilised to train an
SSVEP classifier. Extensive experimental analysis demonstrates the efficacy of
our generated data, leading to improvements across a variety of evaluations,
with the crucial task of cross-subject generalisation improving by over 35%
with the use of such synthetic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07441</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07441</id><created>2019-01-22</created><updated>2019-02-07</updated><authors><author><keyname>Bustos</keyname><forenames>Aurelia</forenames></author><author><keyname>Pertusa</keyname><forenames>Antonio</forenames></author><author><keyname>Salinas</keyname><forenames>Jose-Maria</forenames></author><author><keyname>de la Iglesia-Vay&#xe1;</keyname><forenames>Maria</forenames></author></authors><title>PadChest: A large chest x-ray image dataset with multi-label annotated
  reports</title><categories>eess.IV cs.CV</categories><msc-class>92B20, 92C50, 68T50, 92B10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a labeled large-scale, high resolution chest x-ray dataset for the
automated exploration of medical images along with their associated reports.
This dataset includes more than 160,000 images obtained from 67,000 patients
that were interpreted and reported by radiologists at Hospital San Juan
Hospital (Spain) from 2009 to 2017, covering six different position views and
additional information on image acquisition and patient demography. The reports
were labeled with 174 different radiographic findings, 19 differential
diagnoses and 104 anatomic locations organized as a hierarchical taxonomy and
mapped onto standard Unified Medical Language System (UMLS) terminology. Of
these reports, 27% were manually annotated by trained physicians and the
remaining set was labeled using a supervised method based on a recurrent neural
network with attention mechanisms. The labels generated were then validated in
an independent test set achieving a 0.93 Micro-F1 score. To the best of our
knowledge, this is one of the largest public chest x-ray database suitable for
training supervised models concerning radiographs, and the first to contain
radiographic reports in Spanish. The PadChest dataset can be downloaded from
http://bimcv.cipf.es/bimcv-projects/padchest/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07455</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07455</id><created>2019-01-14</created><authors><author><keyname>Zhou</keyname><forenames>Mingyong</forenames></author><author><keyname>Zhu</keyname><forenames>Hongyu</forenames></author></authors><title>A Discussion on the Algorithm Design of Electrical Impedance Tomography
  for Biomedical Applications</title><categories>eess.SP q-bio.QM</categories><comments>accepted for ICSI 2018(2018 International Conference on Sensing and
  Image), liuzhou, October 15, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a discussion on the algorithms design of Electrical
Impedance Tomography (EIT) for biomedical applications. Based on the Maxwell
differential equations and the derived the finite element(FE) linear equations,
we first investigate the possibility to estimate the matrix that contains the
impedance values based on Singular Value Decomposition(SVD) approximations.
Secondly based on the biomedical properties we further explore the possibility
to recover the impedance values uniquely by injecting various different types
of currents with multi-frequency. Injecting various types of multi-frequency
currents lead to a set of different measured voltages configurations, thus
enhance the possibility of uniquely recovering the impedance values in a stable
way under the assumption that the biological cells respond to the different
type of injecting currents in a different way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07457</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07457</id><created>2019-01-12</created><authors><author><keyname>Kumar</keyname><forenames>Satyam</forenames></author><author><keyname>Reddy</keyname><forenames>Tharun Kumar</forenames></author><author><keyname>Behera</keyname><forenames>Laxmidhar</forenames></author></authors><title>Divergence Framework for EEG based Multiclass Motor Imagery Brain
  Computer Interface</title><categories>q-bio.QM cs.HC eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similar to most of the real world data, the ubiquitous presence of
non-stationarities in the EEG signals significantly perturb the feature
distribution thus deteriorating the performance of Brain Computer Interface. In
this letter, a novel method is proposed based on Joint Approximate
Diagonalization (JAD) to optimize stationarity for multiclass motor imagery
Brain Computer Interface (BCI) in an information theoretic framework.
Specifically, in the proposed method, we estimate the subspace which optimizes
the discriminability between the classes and simultaneously preserve
stationarity within the motor imagery classes. We determine the subspace for
the proposed approach through optimization using gradient descent on an
orthogonal manifold. The performance of the proposed stationarity enforcing
algorithm is compared to that of baseline One-Versus-Rest (OVR)-CSP and JAD on
publicly available BCI competition IV dataset IIa. Results show that an
improvement in average classification accuracies across the subjects over the
baseline algorithms and thus essence of alleviating within session
non-stationarities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07543</identifier>
 <datestamp>2019-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07543</id><created>2019-01-21</created><updated>2019-11-11</updated><authors><author><keyname>Zhang</keyname><forenames>Yifu</forenames></author><author><keyname>Cortes</keyname><forenames>Jorge</forenames></author></authors><title>Model predictive control for transient frequency regulation of power
  networks</title><categories>eess.SY cs.SY</categories><comments>arXiv admin note: text overlap with arXiv:1809.05644</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a control strategy to simultaneously achieve asymptotic
stabilization and transient frequency regulation of power networks. The control
command is generated by iteratively solving an open-loop control cost
minimization problem with stability and transient frequency constraints. To
deal with the non-convexity of the stability constraint, we propose a
convexification strategy that uses a reference trajectory based on the system's
current state. We also detail how to employ network partitions to implement the
proposed control strategy in a distributed way, where each region only requires
system information from neighboring regions to execute its controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07604</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07604</id><created>2019-01-22</created><authors><author><keyname>Radfar</keyname><forenames>Martin H.</forenames></author><author><keyname>Dansereau</keyname><forenames>Richard M.</forenames></author><author><keyname>Wong</keyname><forenames>Willy</forenames></author></authors><title>Speech Separation Using Gain-Adapted Factorial Hidden Markov Models</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new probabilistic graphical model which generalizes factorial
hidden Markov models (FHMM) for the problem of single-channel speech separation
(SCSS) in which we wish to separate the two speech signals $X(t)$ and $V(t)$
from a single recording of their mixture $Y(t)=X(t)+V(t)$ using the trained
models of the speakers' speech signals. Current techniques assume the data used
in the training and test phases of the separation model have the same loudness.
In this paper, we introduce GFHMM, gain adapted FHMM, to extend SCSS to the
general case in which $Y(t)=g_xX(t)+g_vV(t)$, where $g_x$ and $g_v$ are unknown
gain factors. GFHMM consists of two independent-state HMMs and a hidden node
which model spectral patterns and gain difference, respectively. A novel
inference method is presented using the Viterbi algorithm and quadratic
optimization with minimal computational overhead. Experimental results,
conducted on 180 mixtures with gain differences from 0 to 15~dB, show that the
proposed technique significantly outperforms FHMM and its memoryless
counterpart, i.e., vector quantization (VQ)-based SCSS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07617</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07617</id><created>2019-01-22</created><authors><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author><author><keyname>D'Andrea</keyname><forenames>Carmen</forenames></author><author><keyname>Li</keyname><forenames>Dejian</forenames></author><author><keyname>Feng</keyname><forenames>Shulan</forenames></author></authors><title>MIMO-UFMC Transceiver Schemes for Millimeter Wave Wireless
  Communications</title><categories>eess.SP cs.IT math.IT</categories><journal-ref>IEEE Transactions on Communications, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The UFMC modulation is among the most considered solutions for the
realization of beyond-OFDM air interfaces for future wireless networks. This
paper focuses on the design and analysis of an UFMC transceiver equipped with
multiple antennas and operating at millimeter wave carrier frequencies. The
paper provides the full mathematical model of a MIMO-UFMC transceiver, taking
into account the presence of hybrid analog/digital beamformers at both ends of
the communication links. Then, several detection structures are proposed, both
for the case of single-packet isolated transmission, and for the case of
multiple-packet continuous transmission. In the latter situation, the paper
also considers the case in which no guard time among adjacent packets is
inserted, trading off an increased level of interference with higher values of
spectral efficiency. At the analysis stage, the several considered detection
structures and transmission schemes are compared in terms of bit-error-rate,
root-mean-square-error, and system throughput. The numerical results show that
the proposed transceiver algorithms are effective and that the linear MMSE data
detector is capable of well managing the increased interference brought by the
removal of guard times among consecutive packets, thus yielding throughput
gains of about 10 - 13 $\%$. The effect of phase noise at the receiver is also
numerically assessed, and it is shown that the recursive implementation of the
linear MMSE exhibits some degree of robustness against this disturbance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07659</identifier>
 <datestamp>2019-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07659</id><created>2019-01-12</created><updated>2019-04-10</updated><authors><author><keyname>Alaudah</keyname><forenames>Yazeed</forenames></author><author><keyname>Michalowicz</keyname><forenames>Patrycja</forenames></author><author><keyname>Alfarraj</keyname><forenames>Motaz</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>A Machine Learning Benchmark for Facies Classification</title><categories>eess.IV cs.CV physics.geo-ph</categories><comments>Submitted to the SEG Interpretation journal</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The recent interest in using deep learning for seismic interpretation tasks,
such as facies classification, has been facing a significant obstacle, namely
the absence of large publicly available annotated datasets for training and
testing models. As a result, researchers have often resorted to annotating
their own training and testing data. However, different researchers may
annotate different classes, or use different train and test splits. In
addition, it is common for papers that apply machine learning for facies
classification to not contain quantitative results, and rather rely solely on
visual inspection of the results. All of these practices have lead to
subjective results and have greatly hindered the ability to compare different
machine learning models against each other and understand the advantages and
disadvantages of each approach.
  To address these issues, we open-source a fully-annotated 3D geological model
of the Netherlands F3 Block. This model is based on the study of the 3D seismic
data in addition to 26 well logs, and is grounded on the careful study of the
geology of the region. Furthermore, we propose two baseline models for facies
classification based on a deconvolution network architecture and make their
codes publicly available. Finally, we propose a scheme for evaluating different
models on this dataset, and we share the results of our baseline models. In
addition to making the dataset and the code publicly available, this work helps
advance research in this area by creating an objective benchmark for comparing
the results of different machine learning approaches for facies classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07703</identifier>
 <datestamp>2019-04-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07703</id><created>2019-01-22</created><updated>2019-04-10</updated><authors><author><keyname>Ezuma</keyname><forenames>Martins</forenames></author><author><keyname>Erden</keyname><forenames>Fatih</forenames></author><author><keyname>Anjinappa</keyname><forenames>Chethan Kumar</forenames></author><author><keyname>Ozdemir</keyname><forenames>Ozgur</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Micro-UAV Detection and Classification from RF Fingerprints Using
  Machine Learning Techniques</title><categories>eess.SP</categories><comments>12 pages. To be presented in 2019 IEEE Aerospace Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the detection and classification of micro-unmanned
aerial vehicles (UAVs) using radio frequency (RF) fingerprints of the signals
transmitted from the controller to the micro-UAV. In the detection phase, raw
signals are split into frames and transformed into the wavelet domain. A Markov
models-based naive Bayes approach is used to check for the presence of a UAV in
each frame. In the classification phase, unlike the traditional approaches that
rely solely on time-domain signals and corresponding features, the proposed
technique uses the energy transient signal. This approach is more robust to
noise and can cope with different modulation techniques. First, the normalized
energy trajectory is generated from the energy-time-frequency distribution of
the raw control signal. Next, the start and end points of the energy transient
are detected by searching for the most abrupt changes in the mean of the energy
trajectory. Then, a set of statistical features is extracted from the energy
transient. Significant features are selected by performing neighborhood
component analysis (NCA) to keep the computational cost of the algorithm low.
Finally, selected features are fed to several machine learning algorithms for
classification. The algorithms are evaluated experimentally using a database
containing 100 RF signals from each of 14 different UAV controllers. The
signals are recorded wirelessly using a high-frequency oscilloscope. The data
set is randomly partitioned into training and test sets for validation with the
ratio 4:1. Ten Monte Carlo simulations are run and results are averaged to
assess the performance of the methods. All the micro-UAVs are detected
correctly and an average accuracy of 96.3% is achieved using the k-nearest
neighbor (kNN) classification. Proposed methods are also tested for different
signal-to-noise ratio (SNR) levels and results are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07716</identifier>
 <datestamp>2020-01-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07716</id><created>2019-01-22</created><updated>2020-01-09</updated><authors><author><keyname>Li</keyname><forenames>Zhuo</forenames></author><author><keyname>You</keyname><forenames>Keyou</forenames></author><author><keyname>Song</keyname><forenames>Shiji</forenames></author></authors><title>Cooperative Source Seeking via Networked Multi-vehicle Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the cooperative source seeking problem via a networked
multi-vehicle system. In contrast to existing literature, the multi-vehicle
system is controlled to the source position that maximizes aggregated multiple
unknown scalar fields and each sensor-enabled vehicle only samples measurements
of one scalar field. Thus, a single vehicle is unable to localize the source
and has to cooperate with its neighboring vehicles. By jointly exploiting the
ideas of the consensus algorithm and the stochastic extremum seeking (ES), this
paper proposes novel distributed stochastic ES controllers, which are
gradient-free and do not need any absolute information, such that the
multi-vehicle system simultaneously approaches the source position. The
effectiveness of the proposed controllers is proved for quadratic scalar
fields. Finally, illustrative examples are included to validate the theoretical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07800</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07800</id><created>2019-01-23</created><authors><author><keyname>G&#xf3;mez</keyname><forenames>Pedro A.</forenames></author><author><keyname>Molina-Romero</keyname><forenames>Miguel</forenames></author><author><keyname>Buonincontri</keyname><forenames>Guido</forenames></author><author><keyname>Menzel</keyname><forenames>Marion I.</forenames></author><author><keyname>Menze</keyname><forenames>Bjoern H.</forenames></author></authors><title>Designing contrasts for rapid, simultaneous parameter quantification and
  flow visualization with quantitative transient-state imaging</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance imaging (MRI) is a remarkably powerful diagnostic
technique: it generates wide-ranging information for the non-invasive study of
tissue anatomy and physiology. Complementary data is normally obtained in
separate measurements, either as contrast-weighted images, which are fast and
simple to acquire, or as quantitative parametric maps, which offer an absolute
quantification of underlying biophysical effects, such as relaxation times or
flow. Here, we demonstrate how to acquire and reconstruct data in a
transient-state with a dual purpose: 1 - to generate contrast-weighted images
that can be adjusted to emphasise clinically relevant image biomarkers;
exemplified with signal modulation according to flow to obtain angiography
information, and 2 - to simultaneously infer multiple quantitative parameters
with a single, highly accelerated acquisition. This is a achieved by
introducing three novel elements: a model that accounts for flowing blood, a
method for sequence design that incorporates both parameter encoding and signal
contrast, and the reconstruction of temporally resolved contrast-weighted
images. From these images we simultaneously obtain angiography projections and
multiple quantitative maps. By doing so, we increase the amount of clinically
relevant data without adding measurement time, creating new dimensions for
biomarker exploration and adding value to MR examinations for patients and
clinicians alike.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07822</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07822</id><created>2019-01-23</created><authors><author><keyname>Kollia</keyname><forenames>Ilianna</forenames></author><author><keyname>Stafylopatis</keyname><forenames>Andreas-Georgios</forenames></author><author><keyname>Kollias</keyname><forenames>Stefanos</forenames></author></authors><title>Predicting Parkinson's Disease using Latent Information extracted from
  Deep Neural Networks</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new method for medical diagnosis of neurodegenerative
diseases, such as Parkinson's, by extracting and using latent information from
trained Deep convolutional, or convolutional-recurrent Neural Networks (DNNs).
In particular, our approach adopts a combination of transfer learning, k-means
clustering and k-Nearest Neighbour classification of deep neural network
learned representations to provide enriched prediction of the disease based on
MRI and/or DaT Scan data. A new loss function is introduced and used in the
training of the DNNs, so as to perform adaptation of the generated learned
representations between data from different medical environments. Results are
presented using a recently published database of Parkinson's related
information, which was generated and evaluated in a hospital environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07887</identifier>
 <datestamp>2019-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07887</id><created>2019-01-19</created><updated>2019-04-25</updated><authors><author><keyname>Lyu</keyname><forenames>Jiangbin</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Network-Connected UAV: 3D System Modeling and Coverage Performance
  Analysis</title><categories>eess.SP</categories><comments>Double-column, 13 pages, 10 figures, accepted for publication in IEEE
  Internet of Things Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With growing popularity, unmanned aerial vehicles (UAVs) are pivotally
extending conventional terrestrial Internet of Things (IoT) into the sky. To
enable high-performance two-way communications of UAVs with their ground
pilots/users, cellular network-connected UAV has drawn significant interests
recently. Among others, an important issue is whether the existing cellular
network, designed mainly for terrestrial users, is also able to effectively
cover the new UAV users in the three-dimensional (3D) space for both uplink and
downlink communications. Such 3D coverage analysis is challenging due to the
unique air-ground channel characteristics, the resulted interference issue with
terrestrial communication, and the non-uniform 3D antenna gain pattern of
ground base station (GBS) in practice. Particularly, high-altitude UAV often
possesses a high probability of line-of-sight (LoS) channels with a large
number of GBSs, while their random binary (LoS/Non-LoS) channel states and
(on/off) activities give rise to exponentially large number of discrete UAV-GBS
association/interference states, rendering coverage analysis more difficult.
This paper presents a new 3D system model to incorporate UAV users and proposes
an analytical framework to characterize their uplink/downlink 3D coverage
performance. To tackle the above exponential complexity, we introduce a
generalized Poisson multinomial (GPM) distribution to model the discrete
interference states, and a novel lattice approximation (LA) technique to
approximate the non-lattice GPM variable and obtain the interference
distribution efficiently with high accuracy. The 3D coverage analysis is
validated by extensive numerical results, which also show effects of key system
parameters such as cell loading factor, GBS antenna downtilt, UAV altitude and
antenna beamwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07893</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07893</id><created>2019-01-22</created><authors><author><keyname>Xu</keyname><forenames>Liangyuan</forenames></author><author><keyname>Lu</keyname><forenames>Xintong</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Zhu</keyname><forenames>Yongxu</forenames></author></authors><title>On the Uplink Achievable Rate of Massive MIMO System With Low-Resolution
  ADC and RF Impairments</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 4 figures. Submitted to IEEE Communications Letters. Already
  accepted for publication by IEEE but not published yet</comments><journal-ref>IEEE Communications Letters 2019</journal-ref><doi>10.1109/LCOMM.2019.2895823</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers channel estimation and uplink achievable rate of the
coarsely quantized massive multiple-input multiple-output (MIMO) system with
radio frequency (RF) impairments. We utilize additive quantization noise model
(AQNM) and extended error vector magnitude (EEVM) model to analyze the impacts
of low-resolution analog-to-digital converters (ADCs) and RF impairments
respectively. We show that hardware impairments cause a nonzero floor on the
channel estimation error, which contraries to the conventional case with ideal
hardware. The maximal-ratio combining (MRC) technique is then used at the
receiver, and an approximate tractable expression for the uplink achievable
rate is derived. The simulation results illustrate the appreciable
compensations between ADCs' resolution and RF impairments. The proposed studies
support the feasibility of equipping economical coarse ADCs and economical
imperfect RF components in practical massive MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07896</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07896</id><created>2019-01-21</created><updated>2019-01-28</updated><authors><author><keyname>Khordad</keyname><forenames>Erfan</forenames></author><author><keyname>Khalili</keyname><forenames>Ata</forenames></author><author><keyname>Akhlaghi</keyname><forenames>Soroush</forenames></author></authors><title>Rate Balancing in Full-Duplex MIMO Two-Way Relay Networks</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximizing the minimum rate for a full-duplex multiple-input multiple-output
(MIMO) wireless network encompassing two sources and a two-way (TW) relay
operating in a two hop manner is investigated. To improve the overall
performance, using a zero-forcing approach at the relay to suppress the
residual self-interference arising from full-duplex (FD) operation, the
underlying max-min problem is cast as an optimization problem which is
non-convex. To circumvent this issue, semidefinite relaxation technique is
employed, leading to upper and lower bound solutions for the optimization
problem. Numerical results verify that the upper and lower bound solutions
closely follow each other, showing that the proposed approach results in a
close-to-optimal solution. In addition, the impact of residual
self-interference upon the overall performance of the network in terms of the
minimum rate is illustrated by numerical results, and for low residual
self-interference scenarios the superiority of the proposed method compared to
an analogous half-duplex (HD) counterpart is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07897</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07897</id><created>2019-01-21</created><authors><author><keyname>Xu</keyname><forenames>Dongyang</forenames></author><author><keyname>Ren</keyname><forenames>Pinyi</forenames></author><author><keyname>Ritcey</keyname><forenames>James A.</forenames></author></authors><title>Independence-Checking Coding for OFDM Channel Training Authentication:
  Protocol Design, Security, Stability, and Tradeoff Analysis</title><categories>eess.SP cs.CR</categories><comments>arXiv admin note: text overlap with arXiv:1803.02089</comments><journal-ref>IEEE Trans. Inf. Forensics and Security, 2018, vol.14, no. 2, Feb.
  2019</journal-ref><doi>10.1109/TIFS.2018.2850334</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless OFDM communications systems, pilot tones, due to their publicly
known and deterministic characteristic, suffer significant
jamming/nulling/spoofing risks. Thus, the convectional channel training
protocol using pilot tones could be attacked and paralyzed, which raises the
issue of anti-attack channel training authentication (CTA), i.e., verifying the
claims of identities of pilot tones and channel estimation samples. In this
paper, we consider one-ring scattering scenarios with large-scale uniform
linear arrays (ULA) and develop an independence-checking coding (ICC) theory to
build a secure and stable CTA protocol, namely, ICC-based CTA (ICC-CTA)
protocol. In this protocol, the pilot tones are not only merely randomized and
inserted into subcarriers but also encoded as diversified subcarrier activation
patterns (SAPs) simultaneously. Those encoded SAPs, though camouflaged by
malicious signals, can be identified and decoded into original pilots for
high-accuracy channel impulse response (CIR) estimation. The CTA security is
first characterized by the error probability of identifying legitimate CIR
estimation samples. The CTA instability is formulated as the function of
probability of stably estimating CIR against all available diversified SAPs. A
realistic tradeoff between the CTA security and instability under the
discretely distributed AoA is identified and an optimally stable tradeoff
problem is formulated, with the objective of optimizing the code rate to
maximize security while maintaining maximum stability for ever. Solving this,
we derive the closed-form expression of optimal code rate. Numerical results
finally validate the resilience of proposed ICC-CTA protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07915</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07915</id><created>2019-01-22</created><updated>2019-02-04</updated><authors><author><keyname>Pion-Tonachini</keyname><forenames>Luca</forenames></author><author><keyname>Kreutz-Delgado</keyname><forenames>Ken</forenames></author><author><keyname>Makeig</keyname><forenames>Scott</forenames></author></authors><title>ICLabel: An automated electroencephalographic independent component
  classifier, dataset, and website</title><categories>eess.SP cs.LG stat.ML</categories><comments>Intended for NeuroImage. Updated from version one with minor
  editorial and figure changes</comments><doi>10.1016/j.neuroimage.2019.05.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The electroencephalogram (EEG) provides a non-invasive, minimally
restrictive, and relatively low cost measure of mesoscale brain dynamics with
high temporal resolution. Although signals recorded in parallel by multiple,
near-adjacent EEG scalp electrode channels are highly-correlated and combine
signals from many different sources, biological and non-biological, independent
component analysis (ICA) has been shown to isolate the various source generator
processes underlying those recordings. Independent components (IC) found by ICA
decomposition can be manually inspected, selected, and interpreted, but doing
so requires both time and practice as ICs have no particular order or intrinsic
interpretations and therefore require further study of their properties.
Alternatively, sufficiently-accurate automated IC classifiers can be used to
classify ICs into broad source categories, speeding the analysis of EEG studies
with many subjects and enabling the use of ICA decomposition in near-real-time
applications. While many such classifiers have been proposed recently, this
work presents the ICLabel project comprised of (1) an IC dataset containing
spatiotemporal measures for over 200,000 ICs from more than 6,000 EEG
recordings, (2) a website for collecting crowdsourced IC labels and educating
EEG researchers and practitioners about IC interpretation, and (3) the
automated ICLabel classifier. The classifier improves upon existing methods in
two ways: by improving the accuracy of the computed label estimates and by
enhancing its computational efficiency. The ICLabel classifier outperforms or
performs comparably to the previous best publicly available method for all
measured IC categories while computing those labels ten times faster than that
classifier as shown in a rigorous comparison against all other publicly
available EEG IC classifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07923</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07923</id><created>2019-01-23</created><authors><author><keyname>de Oliveira</keyname><forenames>Lucas Giroto</forenames></author><author><keyname>Filomeno</keyname><forenames>Mateus de L.</forenames></author><author><keyname>Colla</keyname><forenames>Luiz Fernando</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Ribeiro</keyname><forenames>Mois&#xe9;s V.</forenames></author></authors><title>On the Suitability of PLC Pulses for Power Line Fault Sensing via
  Time-Domain Reflectometry</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work discusses the suitability of typical power line communication (PLC)
pulses for fault sensing in power lines via pulse-compression time-domain
reflectometry (TDR). For this purpose, we first carefully outline a TDR system
operating over a power distribution network, discussing its limitations and
ultimately resorting to the pulse compression procedure. Next, we present
closed-form expressions for pulses and their autocorrelation functions of
typical PLC modulation schemes, namely Hermitian symmetric orthogonal
frequency-division multiplexing (HS-OFDM), impulsive ultra-wideband (UWB), and
chirp spread spectrum (CSS). Furthermore, different metrics are used on the
provided expressions in order to evaluate the suitability of the considered PLC
pulses for providing proper TDR measurements, i.e., \textit{reflectograms}, in
terms of resolution, effectiveness of the pulse compression, distortion, and
range. Considering the scenarios of European underground low-voltage and US
overhead medium-voltage power distribution networks, we finally carry out a
comparative numerical analysis among the considered PLC pulses in terms of the
aforementioned metrics for frequency bands comprising narrowband- and
broadband-PLC, with a highlight on compliance to regulatory constraints. Based
on the achieved results, we show that the use of UWB pulses allows the
obtaining of a larger number of reflectograms in a given time interval, while
HS-OFDM and CSS pulses provide higher reflectogram quality and better
resolution for a given occupied frequency bandwidth. Also, we show that NB-PLC
pulses are suitable for most distribution network scenarios, being the use of
BB-PLC left for cases where very fine resolutions are desired.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07927</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07927</id><created>2019-01-23</created><updated>2019-10-21</updated><authors><author><keyname>Mandelli</keyname><forenames>Sara</forenames></author><author><keyname>Lipari</keyname><forenames>Vincenzo</forenames></author><author><keyname>Bestagini</keyname><forenames>Paolo</forenames></author><author><keyname>Tubaro</keyname><forenames>Stefano</forenames></author></authors><title>Interpolation and Denoising of Seismic Data using Convolutional Neural
  Networks</title><categories>cs.NE cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seismic data processing algorithms greatly benefit from regularly sampled and
reliable data. Therefore, interpolation and denoising play a fundamental role
as one of the starting steps of most seismic processing workflows. We exploit
convolutional neural networks for the joint tasks of interpolation and random
noise attenuation of 2D common shot gathers. Inspired by the great
contributions achieved in image processing and computer vision, we investigate
a particular architecture of convolutional neural network referred to as U-net,
which implements a convolutional autoencoder able to describe the complex
features of clean and regularly sampled data for reconstructing the corrupted
ones. In training phase we exploit part of the data for tailoring the network
to the specific tasks of interpolation, denoising and joint
denoising/interpolation, while during the system deployment we are able to
recover the remaining corrupted shot gathers in a computationally efficient
procedure. We consider a plurality of data corruptions in our numerical
experiments, including different noise models and different distributions of
missing traces. Several examples on synthetic and field data illustrate the
appealing features of the aforementioned strategy. Comparative examples show
improvements with respect to recently proposed solutions for joint denoising
and interpolation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07930</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07930</id><created>2019-01-23</created><authors><author><keyname>Cai</keyname><forenames>Xuesong</forenames></author><author><keyname>Rodr&#xed;guez-Pi&#xf1;eiro</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Yin</keyname><forenames>Xuefeng</forenames></author><author><keyname>Ai</keyname><forenames>Bo</forenames></author><author><keyname>Pedersen</keyname><forenames>Gert Fr&#xf8;lund</forenames></author><author><keyname>Yuste</keyname><forenames>Antonio P&#xe9;rez</forenames></author></authors><title>An Empirical Air-to-Ground Channel Model Based on Passive Measurements
  in LTE</title><categories>eess.SP</categories><comments>15 pages, submitted version to IEEE Transactions on Vehicular
  Technology. Current status: Early access</comments><doi>10.1109/TVT.2018.2886961</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a recently conducted measurement campaign for
unmanned-aerial-vehicle (UAV) channels is introduced. The downlink signals of
an in-service long-time-evolution (LTE) network which is deployed in a suburban
scenario were acquired. Five horizontal and five vertical flight routes were
considered. The channel impulse responses (CIRs) are extracted from the
received data by exploiting the cell specific signals (CRSs). Based on the
CIRs, the parameters of multipath components (MPCs) are estimated by using a
high-resolution algorithm derived according to the space-alternating
generalized expectation-maximization (SAGE) principle. Based on the SAGE
results, channel characteristics including the path loss, shadow fading, fast
fading, delay spread and Doppler frequency spread are thoroughly investigated
for different heights and horizontal distances, which constitute a stochastic
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07938</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07938</id><created>2019-01-23</created><authors><author><keyname>Sun</keyname><forenames>Jingcong</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author></authors><title>Energy Aware Trajectory Optimization for Aerial Base Stations</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By fully exploiting the mobility of unmanned aerial vehicles (UAVs),
UAV-based aerial base stations (BSs) can move closer to ground users to achieve
better communication conditions. In this paper, we consider a scenario where an
aerial BS is dispatched for covering a maximum number of ground users before
exhausting its on-board energy resources. The resulting trajectory optimization
problem is a mixed integer non-linear problem (MINLP) which is non-convex and
is challenging to solve. As such, we propose an iterative algorithm which
decomposes the problem into two sub-problems by applying both successive convex
optimization and block coordinate descent techniques to solve it. To be
specific, the trajectory of the aerial BS and the user scheduling and
association are alternately optimized within each iteration. In addition, to
achieve better coverage performance and speed up convergence, the problem of
designing the initial trajectory of the UAV is also considered. Finally, to
address the unavailability of accurate user location information (ULI) in
practice, two different robust techniques are proposed to compensate the
performance loss in the existence of inaccurate ULI. Simulation results show
both energy and coverage performance gains for the proposed schemes compared to
the benchmark techniques, with an up to 50% increase in coverage probability
and an up to 20% reduction in energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07953</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07953</id><created>2019-01-14</created><authors><author><keyname>Novikov-Borodin</keyname><forenames>Andrey V.</forenames></author></authors><title>Direct Reconstruction of Distorted Signals and Images Using Shifts
  Methods</title><categories>eess.SP</categories><comments>Submitted to IEEE Trans on Signal Processing, 14-Jan-2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematical methods of step-by-step and combined shifts are proposed for
experimental data processing to reconstruct the measuring system impulse
response distorted by shift-invariant blur. Proposed methods base on direct
non-blind deconvolution without using approximations and integral transforms.
Methods are fast and effective for accurate data reconstruction, which gives a
possibility of increasing the effective resolution of measuring systems by
mathematical methods up to physical limits without solving the expensive and
quite difficult scientific and technical problems. Step-by-step and combined
shifts methods supplement each other in data reconstruction at different
distortions of signals, noise levels and data volumes. Methods may be adapted
for reconstruction of multi-dimensional data. There are considered the
restorations of 2D images blurred by uniform motion and distorted by functions,
which may be factored, such as Gaussian-like functions. The comparative
analysis of step-by-step and combined shifts methods is presented.
Reconstruction inaccuracies are estimated. Examples of signal reconstructions
and image restorations at different distortions are considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07961</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07961</id><created>2019-01-18</created><authors><author><keyname>Chen</keyname><forenames>Jun</forenames></author><author><keyname>Qiao</keyname><forenames>Deli</forenames></author></authors><title>Outage Analysis of Heterogeneous mmWave Cellular Networks Employing JSDM</title><categories>eess.SP cs.IT math.IT</categories><comments>arXiv admin note: text overlap with arXiv:1806.09326</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the outage performance of a two-tier heterogeneous mmWave
cellular networks employing joint spatial division and multiplexing (JSDM) is
investigated. It is assumed that macro base stations (BSs) equipped with a
large number of antennas and pico BSs equipped with single antenna serve users
simultaneously. The two-tier BSs and users are distributed according to
independent Poisson point processes (PPPs). Theoretical analysis of the
signal-to-interference-plus-noise ratio (SINR) outage probability of the
typical user is first provided. The all SINR outage probability of the two
tiers is then derived. Simulation results in accordance with theoretical
analysis demonstrating the performance improvement of two-tier networks compare
with the single-tier network are provided. By using the noise-limited
assumption for mmWave networks, a simpler expression to analyze the outage
performance is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.07994</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.07994</id><created>2019-01-23</created><authors><author><keyname>Hosseini</keyname><forenames>Seyed MohammadReza</forenames></author><author><keyname>Isazadeh</keyname><forenames>Afshin</forenames></author><author><keyname>Noroozi</keyname><forenames>Ali</forenames></author><author><keyname>Sebt</keyname><forenames>Mohammad Ali</forenames></author></authors><title>Uncertainty Principle in Distributed MIMO Radars</title><categories>eess.SP stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radar uncertainty principle indicates that there is an inherent invariance in
the product of the time-delay and Doppler-shift measurement accuracy and
resolution which can be tuned by the waveform at transmitter. In this paper,
based on the radar uncertainty principle, a conceptual waveform design is
proposed for a distributed multiple-input multiple-output (MIMO) radar system
in order to improve the Cramer-Rao lower bound (CRLB) of the target position
and velocity. To this end, a non-convex band constrained optimization problem
is formulated, and a local and the global solution to the problem are obtained
by sequential quadratic programming (SQP) and particle swarm algorithms,
respectively. Numerical results are also included to illustrate the
effectiveness of the proposed mechanism on the CRLB of the target position and
velocity. By numerical results, it is also concluded that the global solution
to the optimization problem is obtained at a vertex of the bounding box.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08049</identifier>
 <datestamp>2019-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08049</id><created>2019-01-23</created><authors><author><keyname>Singh</keyname><forenames>Kanwar Bharat</forenames></author><author><keyname>Taheri</keyname><forenames>Saied</forenames></author></authors><title>Accelerometer Based Method for Tire Load and Slip Angle Estimation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tire mounted sensors are emerging as a promising technology, capable of
providing information about important tire states. This paper presents a survey
of the state-of-the-art in the field of smart tire technology, with a special
focus on the different signal processing techniques proposed by researchers to
estimate the tire load and slip angle using tire mounted accelerometers. Next,
details about the research activities undertaken as part of this study to
develop a smart tire are presented. Finally, novel algorithms for estimating
the tire load and slip angle are presented. Experimental results demonstrate
the effectiveness of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08096</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08096</id><created>2019-01-23</created><updated>2020-01-24</updated><authors><author><keyname>Lim</keyname><forenames>Bryan</forenames></author><author><keyname>Zohren</keyname><forenames>Stefan</forenames></author><author><keyname>Roberts</keyname><forenames>Stephen</forenames></author></authors><title>Recurrent Neural Filters: Learning Independent Bayesian Filtering Steps
  for Time Series Prediction</title><categories>stat.ML cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the recent popularity of deep generative state space models, few
comparisons have been made between network architectures and the inference
steps of the Bayesian filtering framework -- with most models simultaneously
approximating both state transition and update steps with a single recurrent
neural network (RNN). In this paper, we introduce the Recurrent Neural Filter
(RNF), a novel recurrent autoencoder architecture that learns distinct
representations for each Bayesian filtering step, captured by a series of
encoders and decoders. Testing this on three real-world time series datasets,
we demonstrate that the decoupled representations learnt not only improve the
accuracy of one-step-ahead forecasts while providing realistic uncertainty
estimates, but also facilitate multistep prediction through the separation of
encoder stages
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08109</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08109</id><created>2019-01-23</created><authors><author><keyname>Gomariz</keyname><forenames>Alvaro</forenames></author><author><keyname>Li</keyname><forenames>Weiye</forenames></author><author><keyname>Ozkan</keyname><forenames>Ece</forenames></author><author><keyname>Tanner</keyname><forenames>Christine</forenames></author><author><keyname>Goksel</keyname><forenames>Orcun</forenames></author></authors><title>Siamese Networks with Location Prior for Landmark Tracking in Liver
  Ultrasound Sequences</title><categories>cs.CV eess.IV</categories><comments>Accepted at the IEEE International Symposium on Biomedical Imaging
  (ISBI) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image-guided radiation therapy can benefit from accurate motion tracking by
ultrasound imaging, in order to minimize treatment margins and radiate moving
anatomical targets, e.g., due to breathing. One way to formulate this tracking
problem is the automatic localization of given tracked anatomical landmarks
throughout a temporal ultrasound sequence. For this, we herein propose a
fully-convolutional Siamese network that learns the similarity between pairs of
image regions containing the same landmark. Accordingly, it learns to localize
and thus track arbitrary image features, not only predefined anatomical
structures. We employ a temporal consistency model as a location prior, which
we combine with the network-predicted location probability map to track a
target iteratively in ultrasound sequences. We applied this method on the
dataset of the Challenge on Liver Ultrasound Tracking (CLUST) with competitive
results, where our work is the first to effectively apply CNNs on this tracking
problem, thanks to our temporal regularization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08118</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08118</id><created>2019-01-23</created><authors><author><keyname>Tan</keyname><forenames>Yixuan</forenames></author><author><keyname>Lei</keyname><forenames>Xin</forenames></author><author><keyname>Wang</keyname><forenames>Xingze</forenames></author><author><keyname>Fan</keyname><forenames>Shanhui</forenames></author><author><keyname>Yu</keyname><forenames>Zongfu</forenames></author></authors><title>Imaging-free object recognition enabled by optical coherence</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual object recognition is one of the most important perception functions
for a wide range of intelligent machines. A conventional recognition process
begins with forming a clear optical image of the object, followed by its
computer analysis. In contrast, it is possible to carry out recognition without
imaging by using coherent illumination and directly analyzing the optical
interference pattern of the scattered light as captured by an image sensor.
Here we show that such direct visual recognition can overcome traditional
limitations of imaging optics to realize excellent recognition without
focusing, beyond diffraction limit, or in the absence of direct line-of-sight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08134</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08134</id><created>2019-01-23</created><authors><author><keyname>Rodrigues</keyname><forenames>Victor Croisfelt</forenames></author><author><keyname>Marinello</keyname><forenames>Jose Carlos</forenames></author><author><keyname>Abrao</keyname><forenames>Taufik</forenames></author></authors><title>Exponential Spatial Correlation with Large-Scale Fading Variations in
  Massive MIMO Channel Estimation</title><categories>eess.SP</categories><comments>26 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To provide the vast exploitation of the large number of antennas on massive
multiple-input-multiple-output (M-MIMO), it is crucial to know as accurately as
possible the channel state information in the base station. This knowledge is
canonically acquired through channel estimation procedures conducted after a
pilot signaling phase, which adopts the widely accepted time-division duplex
scheme. However, the quality of channel estimation is very impacted either by
pilot contamination or by spatial correlation of the channels. There are
several models that strive to match the spatial correlation in M-MIMO channels,
the exponential correlation model being one of these. To observe how the
channel estimation and pilot contamination are affected by this correlated
fading model, this work proposes to investigate an M-MIMO scenario applying the
standard minimum mean square error channel estimation approach over uniform
linear arrays and uniform planar arrays (ULAs and UPAs, respectively) of
antennas. Moreover, the elements of the array are considered to contribute
unequally on the communication, owing to large-scale fading variations over the
array. Thus, it was perceived that the spatially correlated channels generated
by this combined model offer a reduction of pilot contamination, consequently
the estimation quality is improved. The UPA acquired better results regarding
pilot contamination since it has been demonstrated that this type of array
generates stronger levels of spatial correlation than the ULA. In contrast to
the favorable results in channel estimation, the channel hardening effect was
impaired by the spatially correlated channels, where the UPA imposes the worst
performance of this effect for the discussed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08142</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08142</id><created>2019-01-23</created><authors><author><keyname>Martins</keyname><forenames>Wallace Alves</forenames></author><author><keyname>Cruz-Rold&#xe1;n</keyname><forenames>Fernando</forenames></author><author><keyname>Moonen</keyname><forenames>Marc</forenames></author><author><keyname>Diniz</keyname><forenames>Paulo Sergio Ramirez</forenames></author></authors><title>Intersymbol and Intercarrier Interference in OFDM Transmissions through
  Highly Dispersive Channels</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work quantifies, for the first time, intersymbol and intercarrier
interferences induced by very dispersive channels in OFDM systems. The
resulting achievable data rate for \wam{suboptimal} OFDM transmissions is
derived based on the computation of signal-to-interference-plus-noise ratio for
arbitrary length finite duration channel impulse responses. Simulation results
point to significant differences between data rates obtained via conventional
formulations, for which interferences are supposed to be limited to two or
three blocks, versus the data rates considering the actual channel dispersion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08196</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08196</id><created>2019-01-23</created><authors><author><keyname>Xie</keyname><forenames>Liyan</forenames></author><author><keyname>Xie</keyname><forenames>Yao</forenames></author><author><keyname>Moustakides</keyname><forenames>George V.</forenames></author></authors><title>Asynchronous Multi-Sensor Change-Point Detection for Seismic Tremors</title><categories>stat.AP eess.SP</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the sequential change-point detection for asynchronous
multi-sensors, where each sensor observe a signal (due to change-point) at
different times. We propose an asynchronous Subspace-CUSUM procedure based on
jointly estimating the unknown signal waveform and the unknown relative delays
between the sensors. Using the estimated delays, we can align signals and use
the subspace to combine the multiple sensor observations. We derive the optimal
drift parameter for the proposed procedure, and characterize the relationship
between the expected detection delay, average run length (of false alarms), and
the energy of the time-varying signal. We demonstrate the good performance of
the proposed procedure using simulation and real data. We also demonstrate that
the proposed procedure outperforms the well-known `one-shot procedure' in
detecting weak and asynchronous signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08203</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08203</id><created>2019-01-23</created><authors><author><keyname>Chang</keyname><forenames>Sungkyun</forenames></author><author><keyname>Lee</keyname><forenames>Seungjin</forenames></author><author><keyname>Lee</keyname><forenames>Kyogu</forenames></author></authors><title>Sequential Skip Prediction with Few-shot in Streamed Music Contents</title><categories>cs.IR cs.LG cs.SD eess.AS</categories><comments>4 pages, (to appear in) WSDM Cup 2019 Workshop at ACM International
  Conference on Web Search and Data Mining(WSDM), February 2019, Melbourne,
  Austrailia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides an outline of the algorithms submitted for the WSDM Cup
2019 Spotify Sequential Skip Prediction Challenge (team name: mimbres). In the
challenge, complete information including acoustic features and user
interaction logs for the first half of a listening session is provided. Our
goal is to predict whether the individual tracks in the second half of the
session will be skipped or not, only given acoustic features. We proposed two
different kinds of algorithms that were based on metric learning and sequence
learning. The experimental results showed that the sequence learning approach
performed significantly better than the metric learning approach. Moreover, we
conducted additional experiments to find that significant performance gain can
be achieved using complete user log information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08352</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08352</id><created>2019-01-24</created><authors><author><keyname>Jain</keyname><forenames>Aditi</forenames></author><author><keyname>Sarvepalli</keyname><forenames>Pradeep</forenames></author><author><keyname>Bhashyam</keyname><forenames>Srikrishna</forenames></author><author><keyname>Kannu</keyname><forenames>Arun Pachai</forenames></author></authors><title>Change Detection with Sparse Signals using Quantum Designs</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the change detection problem where the pre-change observation
vectors are purely noise and the post-change observation vectors are
noise-corrupted compressive measurements of sparse signals with a common
support, measured using a sensing matrix. In general, post-change distribution
of the observations depends on parameters such as the support and variances of
the sparse signal. When these parameters are unknown, we propose two
approaches. In the first approach, we approximate the post-change pdf based on
the known parameters such as mutual coherence of the sensing matrix and bounds
on the signal variances. In the second approach, we parameterize the
post-change pdf with an unknown parameter and try to adaptively estimate this
parameter using a stochastic gradient descent method. In both these approaches,
we employ CUSUM algorithm with various decision statistics such as the energy
of the observations, correlation values with columns of the sensing matrix and
the maximum value of such correlations. We study the performance of these
approaches and offer insights on the relevance of different decision statistics
in different SNR regimes. We also address the problem of designing sensing
matrices with small coherence by using designs from quantum information theory.
One such design, called SIC POVM, also has an additional structure which allows
exact computation of the post-change pdfs of some decision statistics even when
the support set of the sparse signal is unknown. We apply our detection
algorithms with SIC POVM based sequences to a massive random access problem and
show their superior performance over conventional Gold codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08404</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08404</id><created>2019-01-24</created><authors><author><keyname>de Oliveira</keyname><forenames>Lucas Giroto</forenames></author><author><keyname>Filomeno</keyname><forenames>Mateus de L.</forenames></author><author><keyname>Ribeiro</keyname><forenames>Mois&#xe9;s V.</forenames></author></authors><title>HS-OFDM-based Time-Domain Reflectometry for Power Line Sensing:
  Characteristics and Limitations</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study discusses key characteristics and limitations of time-domain
reflectometry (TDR) systems based on the Hermitian symmetric orthogonal
frequency-division multiplexing (HS-OFDM) scheme for power line sensing. In
this sense, a system model with a power line modem injecting signals and
capturing raising reflections for sensing a power distribution network is
outlined. Next, pulse compression and channel estimation reflectogram
processing approaches are carefully described and the effects of system
parametrization and multiple access schemes on the HS-OFDM-based TDR system
performance are addressed. Finally, numerical results covering a comparison
between pulse compression and channel estimation, system limitations based on
parametrization considering typical European underground low-voltage and US
overhead medium-voltage (MV) scenarios and narrowband (NB) power line
communication (PLC) regulatory constraints, and comparison among multiple
access techniques in a Brazilian MV overhead scenario are presented for
supporting the carried out discussion. Based on the attained results, it is
shown that channel estimation outperforms the pulse compression in terms of
computational complexity and sidelobe level. Also, it is shown that the NB-PLC
frequency range provides fair range resolution and maximum unambiguous range
values. Finally, it is seen that the use of the frequency-division multiple
access multiple access schemes presents different
signal-to-interference-plus-noise ratio (SINR) performance among different
power line modems (PLMs) connected to a power distribution grid, while the use
of time-division multiple access and code-division multiple access schemes
results in fair SINR performance among the PLMs at the cost of obtaining less
reflectograms over time due to time multiplexing and spreading processes,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08449</identifier>
 <datestamp>2019-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08449</id><created>2019-01-24</created><authors><author><keyname>Zijlstra</keyname><forenames>Frank</forenames></author><author><keyname>Willemsen</keyname><forenames>Koen</forenames></author><author><keyname>Florkow</keyname><forenames>Mateusz C.</forenames></author><author><keyname>Sakkers</keyname><forenames>Ralph J. B.</forenames></author><author><keyname>Weinans</keyname><forenames>Harrie H.</forenames></author><author><keyname>van der Wal</keyname><forenames>Bart C. H.</forenames></author><author><keyname>van Stralen</keyname><forenames>Marijn</forenames></author><author><keyname>Seevinck</keyname><forenames>Peter R.</forenames></author></authors><title>CT synthesis from MR images for orthopedic applications in the lower arm
  using a conditional generative adversarial network</title><categories>cs.CV eess.IV</categories><comments>This work has been accepted at the SPIE Medical Imaging 2019, Image
  Processing conference, paper 10949-54</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To assess the feasibility of deep learning-based high resolution
synthetic CT generation from MRI scans of the lower arm for orthopedic
applications.
  Methods: A conditional Generative Adversarial Network was trained to
synthesize CT images from multi-echo MR images. A training set of MRI and CT
scans of 9 ex vivo lower arms was acquired and the CT images were registered to
the MRI images. Three-fold cross-validation was applied to generate independent
results for the entire dataset. The synthetic CT images were quantitatively
evaluated with the mean absolute error metric, and Dice similarity and surface
to surface distance on cortical bone segmentations.
  Results: The mean absolute error was 63.5 HU on the overall tissue volume and
144.2 HU on the cortical bone. The mean Dice similarity of the cortical bone
segmentations was 0.86. The average surface to surface distance between bone on
real and synthetic CT was 0.48 mm. Qualitatively, the synthetic CT images
corresponded well with the real CT scans and partially maintained high
resolution structures in the trabecular bone. The bone segmentations on
synthetic CT images showed some false positives on tendons, but the general
shape of the bone was accurately reconstructed.
  Conclusions: This study demonstrates that high quality synthetic CT can be
generated from MRI scans of the lower arm. The good correspondence of the bone
segmentations demonstrates that synthetic CT could be competitive with real CT
in applications that depend on such segmentations, such as planning of
orthopedic surgery and 3D printing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08539</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08539</id><created>2019-01-24</created><updated>2019-01-31</updated><authors><author><keyname>Alfarraj</keyname><forenames>Motaz</forenames></author><author><keyname>Alaudah</keyname><forenames>Yazeed</forenames></author><author><keyname>Long</keyname><forenames>Zhiling</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Multiresolution Analysis and Learning for Computational Seismic
  Interpretation</title><categories>eess.IV physics.geo-ph</categories><comments>Published in the The Leading Edge in June 2018</comments><journal-ref>The Leading Edge 37.6 (2018): 443-450</journal-ref><doi>10.1190/tle37060443.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the use of multiresolution analysis techniques as texture
attributes for seismic image characterization, especially in representing
subsurface structures in large migrated seismic data. Namely, we explore the
Gaussian pyramid, the discrete wavelet transform, Gabor filters, and the
curvelet transform. These techniques are examined in a seismic structure
labeling case study on the Netherlands offshore F3 block. In seismic structure
labeling, a seismic volume is automatically segmented and classified according
to the underlying subsurface structure using texture attributes. Our results
show that multiresolution attributes improved the labeling performance compared
to using seismic amplitude alone. Moreover, directional multiresolution
attributes, such as the curvelet transform, are more effective than the
non-directional attributes in distinguishing different subsurface structures in
large seismic datasets, and can greatly help the interpretation process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08577</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08577</id><created>2019-01-24</created><updated>2019-04-30</updated><authors><author><keyname>Arafa</keyname><forenames>Ahmed</forenames></author><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Using Erasure Feedback for Online Timely Updating with an Energy
  Harvesting Sensor</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>To appear in the 2019 IEEE International Symposium on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A real-time status updating system is considered, in which an energy
harvesting sensor is acquiring measurements regarding some physical phenomenon
and sending them to a destination through an erasure channel. The setting is
online, in which energy arrives in units according to a Poisson process with
unit rate, with arrival times being revealed causally over time. Energy is
saved in a unit-sized battery. The sensor is notified by the destination of
whether updates were erased via feedback. Updates need to reach the destination
successfully in a timely fashion, namely, such that the long term average age
of information, defined as the time elapsed since the latest successful update
has reached the destination, is minimized. First, it is shown that the optimal
status update policy has a renewal structure: successful update times should
constitute a renewal process. Then, threshold-greedy policies are investigated:
a new update is transmitted, following a successful one, only if the age of
information grows above a certain threshold; and if it is erased, then all
subsequent update attempts are greedily scheduled whenever energy is available.
The optimal threshold-greedy policy is then analytically derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08608</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08608</id><created>2019-01-24</created><authors><author><keyname>Li</keyname><forenames>Xinyu</forenames></author><author><keyname>Chebiyyam</keyname><forenames>Venkata</forenames></author><author><keyname>Kirchhoff</keyname><forenames>Katrin</forenames></author></authors><title>Multi-stream Network With Temporal Attention For Environmental Sound
  Classification</title><categories>cs.SD cs.MM eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Environmental sound classification systems often do not perform robustly
across different sound classification tasks and audio signals of varying
temporal structures. We introduce a multi-stream convolutional neural network
with temporal attention that addresses these problems. The network relies on
three input streams consisting of raw audio and spectral features and utilizes
a temporal attention function computed from energy changes over time. Training
and classification utilizes decision fusion and data augmentation techniques
that incorporate uncertainty. We evaluate this network on three commonly used
data sets for environmental sound and audio scene classification and achieve
new state-of-the-art performance without any changes in network architecture or
front-end preprocessing, thus demonstrating better generalizability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08660</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08660</id><created>2018-12-28</created><authors><author><keyname>Kumar</keyname><forenames>Jyant</forenames></author><author><keyname>Naskar</keyname><forenames>Tarun</forenames></author></authors><title>Multimodal phase velocity-frequency dispersion images using different
  MASW transformation techniques</title><categories>eess.SP math.NA</categories><comments>16 pages, 19 figures, 2 table, Submitted in Soils and Foundations</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Three different transformation techniques, namely, (i)w-c, (ii) w-k and (iii)
tau-p, has been employed for generating multimodal dispersion images on the
basis of multi-channel analysis of surface waves (MASW) data recorded in
distance-time domain; here w= circular frequency, c = phase velocity, tau =
time intercept, p = phase slowness (1/c) and k = wavenumber. All the three
methods have been first clearly described. The results from these three
different transforms have been examined by using synthetic as well as field
data obtained from field tests using 48 geophones. The effect of sensor spread
length (X) and geophone numbers (M) on multimodal dispersion images were
examined. The solutions from these three transforms were found to match
generally well with each other. The w-c transform has been noted to provide the
most clarity since it does not require either high sampling rate as normally
needed for the tau-p method or inclusion of the zero padding of the data in a
distance domain for the w-k approach. The paper will be useful since it not
only describes the methods, but it brings out simultaneously their merits in
implementation and for generating the dispersion images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08687</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08687</id><created>2019-01-24</created><authors><author><keyname>Chen</keyname><forenames>Shuyi</forenames></author><author><keyname>Liu</keyname><forenames>Xiqing</forenames></author><author><keyname>Zhao</keyname><forenames>Tianyu</forenames></author><author><keyname>Chen</keyname><forenames>Hsiao-Hwa</forenames></author><author><keyname>Meng</keyname><forenames>Weixiao</forenames></author></authors><title>Performance Analysis of Joint Transmission Schemes in Ultra-Dense
  Networks - An Unified Approach</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultra-dense network (UDN) is one of the enabling technologies to achieve
1000-fold capacity increase in 5G communication systems, and the application of
joint transmission (JT) is an effective method to deal with severe inter-cell
interferences in UDNs. However, most works done for performance analysis on JT
schemes in the literature were based largely on simulation results due to the
difficulties in quantitatively identifying the numbers of desired and
interfering transmitters. In this work, we are motivated to propose an
analytical approach to investigate the performance of JT schemes with a unified
approach based on stochastic geometry, which is in particular useful for
studying different JT methods and conventional transmission schemes without JT.
Using the proposed approach, we can unveil the statistic characteristics (i.e.,
expectation, moment generation function, variance) of desired signal and
interference powers of a given user equipment (UE), and thus system
performances, such as average signal-to-interference-plus-noise ratio (SINR),
and area spectral efficiency, can be evaluated analytically. The simulation
results are used to verify the effectiveness of the proposed unified approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08759</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08759</id><created>2019-01-25</created><authors><author><keyname>Palod</keyname><forenames>Priyank</forenames></author><author><keyname>Patwari</keyname><forenames>Ayush</forenames></author><author><keyname>Bahety</keyname><forenames>Sudhanshu</forenames></author><author><keyname>Bagchi</keyname><forenames>Saurabh</forenames></author><author><keyname>Goyal</keyname><forenames>Pawan</forenames></author></authors><title>Misleading Metadata Detection on YouTube</title><categories>cs.CL cs.CV eess.IV</categories><comments>Accepted at European Conference on Information Retrieval(ECIR) 2019.
  7 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  YouTube is the leading social media platform for sharing videos. As a result,
it is plagued with misleading content that includes staged videos presented as
real footages from an incident, videos with misrepresented context and videos
where audio/video content is morphed. We tackle the problem of detecting such
misleading videos as a supervised classification task. We develop UCNet - a
deep network to detect fake videos and perform our experiments on two datasets
- VAVD created by us and publicly available FVC [8]. We achieve a macro
averaged F-score of 0.82 while training and testing on a 70:30 split of FVC,
while the baseline model scores 0.36. We find that the proposed model
generalizes well when trained on one dataset and tested on the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08810</identifier>
 <datestamp>2019-09-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08810</id><created>2019-01-25</created><updated>2019-09-11</updated><authors><author><keyname>Chorowski</keyname><forenames>Jan</forenames></author><author><keyname>Weiss</keyname><forenames>Ron J.</forenames></author><author><keyname>Bengio</keyname><forenames>Samy</forenames></author><author><keyname>Oord</keyname><forenames>A&#xe4;ron van den</forenames></author></authors><title>Unsupervised speech representation learning using WaveNet autoencoders</title><categories>cs.LG eess.AS stat.ML</categories><comments>Accepted to IEEE TASLP, final version available at
  http://dx.doi.org/10.1109/TASLP.2019.2938863</comments><doi>10.1109/TASLP.2019.2938863</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the task of unsupervised extraction of meaningful latent
representations of speech by applying autoencoding neural networks to speech
waveforms. The goal is to learn a representation able to capture high level
semantic content from the signal, e.g.\ phoneme identities, while being
invariant to confounding low level details in the signal such as the underlying
pitch contour or background noise. Since the learned representation is tuned to
contain only phonetic content, we resort to using a high capacity WaveNet
decoder to infer information discarded by the encoder from previous samples.
Moreover, the behavior of autoencoder models depends on the kind of constraint
that is applied to the latent representation. We compare three variants: a
simple dimensionality reduction bottleneck, a Gaussian Variational Autoencoder
(VAE), and a discrete Vector Quantized VAE (VQ-VAE). We analyze the quality of
learned representations in terms of speaker independence, the ability to
predict phonetic content, and the ability to accurately reconstruct individual
spectrogram frames. Moreover, for discrete encodings extracted using the
VQ-VAE, we measure the ease of mapping them to phonemes. We introduce a
regularization scheme that forces the representations to focus on the phonetic
content of the utterance and report performance comparable with the top entries
in the ZeroSpeech 2017 unsupervised acoustic unit discovery task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08838</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08838</id><created>2019-01-25</created><authors><author><keyname>Noe</keyname><forenames>Reinhold</forenames></author><author><keyname>Koch</keyname><forenames>Benjamin</forenames></author></authors><title>Accuracy Limits of Polarization-Independent Optical Depolarizers Based
  on Rotating Waveplates</title><categories>eess.SP</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optical depolarizers for monochromatic waves which work independent of input
polarization can be built from cascaded electrooptic rotating waveplates. If
the waveplate retardations deviate from their desired values then the
worst-case residual degree-of-polarization DOPmax is larger than its desired
value 0. In a depolarizer consisting of one rotating halfwave and one rotating
quarterwave plate, DOPmax roughly equals the retardation error, which is &lt;&lt;1.
However, with just one rotating quarterwave plate more, DOPmax roughly equals
the square of the retardation error which is a much smaller value. Thereby
depolarizer accuracy is substantially improved. Waveplate sequence and rotation
frequency combinations suitable for fast depolarization are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08909</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08909</id><created>2019-01-22</created><authors><author><keyname>Gu</keyname><forenames>Xueping</forenames></author><author><keyname>Li</keyname><forenames>Yang</forenames></author></authors><title>Transient Stability Assessment of Power Systems Based on Local Learning
  Machine and Bacterial Colony Chemotaxis Algorithm</title><categories>eess.SP cs.SY</categories><journal-ref>Transactions of China Electrotechnical Society 28 (2013) 271-279</journal-ref><doi>10.19595/j.cnki.1000-6753.tces.2013.10.033</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to improve the classification accuracy of transient stability
assessment of power systems, a novel method based on local learning machine and
an improved bacterial colony chemotaxis (BCC) algorithm is proposed, where
local learning machine(LLM) is used to build a TSA model. Considering the
possible real-time information provided by PMU, a group of system-level
classification features extracted from the power system operation parameters
are employed as inputs, and the stability result is used as output of the LLM
model. The relation ship between input and output is trained and the ideal
model is obtained by applying the improved BCC combined with chaotic search
strategy to determine the optimal parameters of LLM automatically. The
effectiveness of the proposed method is shown by the simulation results on the
New England 10-unit-39-bus power system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08928</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08928</id><created>2019-01-23</created><authors><author><keyname>Liu</keyname><forenames>Caifeng</forenames></author><author><keyname>Feng</keyname><forenames>Lin</forenames></author><author><keyname>Liu</keyname><forenames>Guochao</forenames></author><author><keyname>Wang</keyname><forenames>Huibing</forenames></author><author><keyname>Liu</keyname><forenames>Shenglan</forenames></author></authors><title>Bottom-up Broadcast Neural Network For Music Genre Classification</title><categories>cs.SD cs.AI eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music genre recognition based on visual representation has been successfully
explored over the last years. Recently, there has been increasing interest in
attempting convolutional neural networks (CNNs) to achieve the task. However,
most of existing methods employ the mature CNN structures proposed in image
recognition without any modification, which results in the learning features
that are not adequate for music genre classification. Faced with the challenge
of this issue, we fully exploit the low-level information from spectrograms of
audios and develop a novel CNN architecture in this paper. The proposed CNN
architecture takes the long contextual information into considerations, which
transfers more suitable information for the decision-making layer. Various
experiments on several benchmark datasets, including GTZAN, Ballroom, and
Extended Ballroom, have verified the excellent performances of the proposed
neural network. Codes and model will be available at
&quot;ttps://github.com/CaifengLiu/music-genre-classification&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08970</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08970</id><created>2019-01-24</created><updated>2019-11-25</updated><authors><author><keyname>Sala</keyname><forenames>Simone</forenames></author><author><keyname>Daurer</keyname><forenames>Benedikt J.</forenames></author><author><keyname>Odstrcil</keyname><forenames>Michal</forenames></author><author><keyname>Capotondi</keyname><forenames>Flavio</forenames></author><author><keyname>Pedersoli</keyname><forenames>Emanuele</forenames></author><author><keyname>Hantke</keyname><forenames>Max F.</forenames></author><author><keyname>Manfredda</keyname><forenames>Michele</forenames></author><author><keyname>Loh</keyname><forenames>N. Duane</forenames></author><author><keyname>Thibault</keyname><forenames>Pierre</forenames></author><author><keyname>Maia</keyname><forenames>Filipe R. N. C.</forenames></author></authors><title>Pulse-to-pulse wavefront sensing at free-electron lasers using
  ptychography</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pressing need for the detailed wavefront properties of ultra-bright and
ultra-short pulses produced by free-electron lasers (FELs) has spurred the
development of several complementary characterization approaches. Here we
present a method based on ptychography that can retrieve full high-resolution
complex-valued wave functions of individual pulses. Our technique is
demonstrated within experimental conditions suited for diffraction experiments
in their native imaging state. This lensless technique, applicable to many
other short-pulse instruments, can achieve diffraction-limited resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08983</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08983</id><created>2019-01-25</created><authors><author><keyname>Qian</keyname><forenames>Xinyuan</forenames></author><author><keyname>Cavallaro</keyname><forenames>Andrea</forenames></author><author><keyname>Brutti</keyname><forenames>Alessio</forenames></author><author><keyname>Omologo</keyname><forenames>Maurizio</forenames></author></authors><title>LOCATA challenge: speaker localization with a planar array</title><categories>cs.SD eess.AS</categories><comments>In Proceedings of the LOCATA ChallengeWorkshop - a satellite event of
  IWAENC 2018 (arXiv:1811.08482 )</comments><report-no>LOCATAchallenge/2018/05</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes our submission to the 2018 LOCalization And TrAcking
(LOCATA) challenge (Tasks 1, 3, 5). We estimate the 3D position of a speaker
using the Global Coherence Field (GCF) computed from multiple microphone pairs
of a DICIT planar array. One of the main challenges when using such an array
with omnidirectional microphones is the front-back ambiguity, which is
particularly evident in Task 5. We address this challenge by post-processing
the peaks of the GCF and exploiting the attenuation introduced by the frame of
the array. Moreover, the intermittent nature of speech and the changing
orientation of the speaker make localization difficult. For Tasks 3 and 5, we
also employ a Particle Filter (PF) that favors the spatio-temporal continuity
of the localization results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.08993</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.08993</id><created>2019-01-25</created><authors><author><keyname>Uday</keyname><forenames>T.</forenames></author><author><keyname>Kumar</keyname><forenames>Abhinav</forenames></author><author><keyname>Natarajan</keyname><forenames>L.</forenames></author></authors><title>MIMO Codes for Uniform Illumination across Space and Time in VLC with
  Dimming Control</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indoor visible light communications (VLC) require simultaneous illumination
and communication. Hence, uniformity in the illumination is a key consideration
for user comfort and data transfer in VLC systems. Several run-length limited
codes have been proposed in the literature which mitigate flicker for single
input and single output VLC systems. Recently, codes have been proposed for
multiple input multiple output (MIMO) VLC systems. However, uniform
illumination along with dimming control has not been considered for MIMO VLC
systems. Hence, in this paper, we propose codes with generalized algorithms for
encoding and decoding that maintain consistency in the illumination across
space and time and achieve the desired dimming level. We present the
expressions for code rate, run-length, and Hamming distance for the proposed
codes. Through Monte Carlo simulations, we compare the codeword error rate
(CER) performance of the proposed codes with zero-forcing, minimum mean square
error, and maximum likelihood detectors for various number of transmit and
receive antennas. We also compare the mutual information of the proposed codes
for various number of transmit and receive antennas. The numerical results show
that the proposed codes exhibit good performance while satisfying the design
criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09088</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09088</id><created>2019-01-25</created><updated>2019-07-23</updated><authors><author><keyname>Zhang</keyname><forenames>Angela</forenames></author><author><keyname>Kao</keyname><forenames>Po-Yu</forenames></author><author><keyname>Sahyouni</keyname><forenames>Ronald</forenames></author><author><keyname>Shelat</keyname><forenames>Ashutosh</forenames></author><author><keyname>Chen</keyname><forenames>Jefferson</forenames></author><author><keyname>Manjunath</keyname><forenames>B. S.</forenames></author></authors><title>Automated Segmentation of CT Scans for Normal Pressure Hydrocephalus</title><categories>eess.IV cs.CV physics.med-ph</categories><msc-class>92-04</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Normal Pressure Hydrocephalus (NPH) is one of the few reversible forms of
dementia, Due to their low cost and versatility, Computed Tomography (CT) scans
have long been used as an aid to help diagnose intracerebral anomalies such as
NPH. However, no well-defined and effective protocol currently exists for the
analysis of CT scan-based ventricular, cerebral mass and subarachnoid space
volumes in the setting of NPH. The Evan's ratio, an approximation of the ratio
of ventricle to brain volume using only one 2D slice of the scan, has been
proposed but is not robust. Instead of manually measuring a 2-dimensional proxy
for the ratio of ventricle volume to brain volume, this study proposes an
automated method of calculating the brain volumes for better recognition of NPH
from a radiological standpoint. The method first aligns the subject CT volume
to a common space through an affine transformation, then uses a random forest
classifier to mask relevant tissue types. A 3D morphological segmentation
method is used to partition the brain volume, which in turn is used to train
machine learning methods to classify the subjects into non-NPH vs. NPH based on
volumetric information. The proposed algorithm has increased sensitivity
compared to the Evan's ratio thresholding method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09146</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09146</id><created>2019-01-25</created><updated>2019-01-30</updated><authors><author><keyname>Kim</keyname><forenames>Jaeyoung</forenames></author><author><keyname>El-Kharmy</keyname><forenames>Mostafa</forenames></author><author><keyname>Lee</keyname><forenames>Jungwon</forenames></author></authors><title>End-to-End Multi-Task Denoising for joint SDR and PESQ Optimization</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised learning based on a deep neural network recently has achieved
substantial improvement on speech enhancement. Denoising networks learn mapping
from noisy speech to clean one directly, or to a spectrum mask which is the
ratio between clean and noisy spectra. In either case, the network is optimized
by minimizing mean square error (MSE) between ground-truth labels and
time-domain or spectrum output. However, existing schemes have either of two
critical issues: spectrum and metric mismatches. The spectrum mismatch is a
well known issue that any spectrum modification after short-time Fourier
transform (STFT), in general, cannot be fully recovered after inverse
short-time Fourier transform (ISTFT). The metric mismatch is that a
conventional MSE metric is sub-optimal to maximize our target metrics,
signal-to-distortion ratio (SDR) and perceptual evaluation of speech quality
(PESQ). This paper presents a new end-to-end denoising framework with the goal
of joint SDR and PESQ optimization. First, the network optimization is
performed on the time-domain signals after ISTFT to avoid spectrum mismatch.
Second, two loss functions which have improved correlations with SDR and PESQ
metrics are proposed to minimize metric mismatch. The experimental result
showed that the proposed denoising scheme significantly improved both SDR and
PESQ performance over the existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09167</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09167</id><created>2019-01-26</created><authors><author><keyname>Aryasomayajula</keyname><forenames>Bharadwaj</forenames></author><author><keyname>Sil</keyname><forenames>Dibakar</forenames></author><author><keyname>Palit</keyname><forenames>Sarbani</forenames></author></authors><title>Fast Periodicity Estimation and Reconstruction of hidden components from
  noisy periodic signal</title><categories>eess.SP</categories><comments>10 pages, 29 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Periodicity estimation from an arbitrary length noisy signal is
computationally very costly. A recently developed Ramanujan Fat Dictionary is
one of the ways to find the hidden components from an arbitrary length (non
integral multiple of period) of the signal. This method suffers from high run
time due to the lack of information about the period and effect of noise on the
signal. We propose a new method that efficiently estimates the period of the
signal and finding the hidden components thus becomes easy from it. Our method
works well with significantly low SNR values and runs in O(n) time complexity,
n being length of the signal. Comparision of run time analysis between our
method for period estimation of a given signal and SVD method at various SNR
values has been made and the corresponding hidden components are there by
extracted by projecting onto the factor-Ramanujan Subspaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09189</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09189</id><created>2019-01-26</created><authors><author><keyname>Hakim</keyname><forenames>Patria Rachman</forenames></author><author><keyname>Syafrudin</keyname><forenames>A Hadi</forenames></author><author><keyname>Salaswati</keyname><forenames>Sartika</forenames></author><author><keyname>Utama</keyname><forenames>Satriya</forenames></author><author><keyname>Hasbi</keyname><forenames>Wahyudi</forenames></author></authors><title>Development of Systematic Image Preprocessing of LAPAN-A3/IPB
  Multispectral Images</title><categories>eess.IV astro-ph.IM</categories><comments>10 pages, 16 figures, journal</comments><journal-ref>International Journal of Advanced Studies in Computer Science and
  Engineering (IJASCSE), Volume 7 Issue 10, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As of any other satellite images, LAPAN-A3/IPB multispectral images suffered
from both geometric and radiometric distortions which need to be corrected.
LAPAN as satellite owner has developed image preprocessing algorithm to process
raw image into systematically corrected image. This research aims to evaluate
the performance of the developed algorithm, particularly the performance of
lens vignetting and band co-registration correction as well as the performance
of direct image georeferencing. Lens vignetting distortion occurs on image was
corrected by using pre-flight calibration data, while calculation of direct
georeferencing was done by using satellite metadata of satellite position and
attitude. Meanwhile, band co-registration correction was conducted based
entirely on the image being processed using image matching approach. Based on
several results and analysis which have been done, lens vignetting effects on
image can be suppressed significantly from about 40 percent down to 10 percent,
band coregistration error can be reduced to below 2-3 pixels in average, and
the calculated direct georeferencing has 3000 meter accuracy. The results show
that the developed image preprocessing algorithm has moderately good
performance to process LAPAN-A3/IPB multispectral images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09199</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09199</id><created>2019-01-26</created><authors><author><keyname>Du</keyname><forenames>Liutong</forenames></author><author><keyname>Li</keyname><forenames>Lihua</forenames></author><author><keyname>Zhang</keyname><forenames>Ping</forenames></author></authors><title>Robust Vector Perturbation Precoding Design for MIMO Broadcast Channel</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the vector perturbation (VP) precoder design for multiuser
multiple-input single output (MU-MISO) broadcast channel systems which is
robust to power scaling factor errors. VP precoding has so far been developed
and analyzed under the assumption that receivers could have known the power
scaling factor in advance of tranmission perfectly, which is hard to obtain due
to the large dynamic range and limited feedforward. However, as demonstrated in
our results the performance of VP precoding is quite sensitive to the accuracy
of power scaling factor and always encounter an error floor at mid to high
signal-to-noise ratio (SNR) regimes. Motivated by such observations, we propose
a robust VP precoder based on the minimum mean square error (MMSE) criterion.
Simulation results show that, the robust VP precoder outperforms conventional
VP precoding designs, as less sensitive to power scaling factor errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09212</identifier>
 <datestamp>2019-08-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09212</id><created>2019-01-26</created><updated>2019-08-23</updated><authors><author><keyname>Wei</keyname><forenames>Yiheng</forenames></author><author><keyname>Wang</keyname><forenames>Jiachang</forenames></author><author><keyname>Tse</keyname><forenames>Peter W</forenames></author><author><keyname>Wang</keyname><forenames>Yong</forenames></author></authors><title>Modelling and simulation of nabla fractional dynamic systems with
  nonzero initial conditions</title><categories>eess.SP</categories><journal-ref>Asian Journal of Control 2019</journal-ref><doi>10.1002/asjc.2232</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper focuses on the numerical approximation of nabla fractional order
systems with the conditions of nonzero initial instant and nonzero initial
state. First, the inverse nabla Laplace transform is developed and the
equivalent infinite dimensional frequency distributed models of discrete
fractional order system are introduced. Then, resorting the nabla Laplace
transform, the rationality of the finite dimensional frequency distributed
model approaching the infinite one is illuminated. Based on this, an original
algorithm to estimate the parameters of the approximate model is proposed with
the help of vector fitting method. Additionally, the applicable object is
extended from a sum operator to a general system. Three numerical examples are
performed to illustrate the applicability and flexibility of the introduced
methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09222</identifier>
 <datestamp>2019-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09222</id><created>2019-01-26</created><authors><author><keyname>Xia</keyname><forenames>ChenYang</forenames></author><author><keyname>Fan</keyname><forenames>YouZhe</forenames></author><author><keyname>Tsui</keyname><forenames>Chi-Ying</forenames></author></authors><title>A Two-staged Adaptive Successive Cancellation List Decoding for Polar
  Codes</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 7 figures, 1 table. Accepted by ISCAS 2019</comments><doi>10.1109/ISCAS.2019.8702103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes achieve outstanding error correction performance when using
successive cancellation list (SCL) decoding with cyclic redundancy check. A
larger list size brings better decoding performance and is essential for
practical applications such as 5G communication networks. However, the decoding
speed of SCL decreases with increased list size. Adaptive SCL (ASCL) decoding
can greatly enhance the decoding speed, but the decoding latency for each
codeword is different so A-SCL is not a good choice for hardware-based
applications. In this paper, a hardware-friendly two-staged adaptive SCL
(TA-SCL) decoding algorithm is proposed such that a constant input data rate is
supported even if the list size for each codeword is different. A mathematical
model based on Markov chain is derived to explore the bounds of its decoding
performance. Simulation results show that the throughput of TA-SCL is tripled
for good channel conditions with negligible performance degradation and
hardware overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09241</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09241</id><created>2019-01-26</created><authors><author><keyname>Marinello</keyname><forenames>Jose Carlos</forenames></author><author><keyname>Panazio</keyname><forenames>Cristiano</forenames></author><author><keyname>Abrao</keyname><forenames>Taufik</forenames></author><author><keyname>Tomasin</keyname><forenames>Stefano</forenames></author></authors><title>Total Energy Efficiency of TD- and FD-MRC Receivers for Massive MIMO
  Uplink</title><categories>eess.SP</categories><comments>27 pages, 03 tables, and 08 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a detailed investigation on the uplink (UL) performance
of massive multiple-input-multiple-output (maMIMO) systems employing
maximum-ratio combining at the receiver. While most papers in maMIMO literature
assume orthogonal frequency-division multiplexing (OFDM), current standards
like LTE employ single-carrier (SC) waveform in the UL due to several benefits.
We thus perform a systemic comparison between two fundamental schemes: the
time-reversal MRC (TRMRC) operating under SC, and the frequency-domain MRC
(FDMRC) employed with OFDM. It was recently shown that TRMRC outperforms FDMRC
in terms of achievable rates, since SC systems do not require the cyclic prefix
(CP) of OFDM. On the other hand, the computational complexity of TRMRC
algorithm is higher than that of FDMRC, even when efficient solutions are
employed (e.g., fast convolution with the overlap-and-add method). Hence, the
best scheme for the UL maMIMO systems still remains an open question. The main
contribution of this paper is the comparison of the total energy efficiency of
both TRMRC and FDMRC when used in the UL of maMIMO systems. Our results show
that, for current typical system parameters, FDMRC/OFDM achieves a higher total
energy efficiency than TRMRC/SC. However, if the cell radius is below 300m
and/or the computational efficiency increases by 30% regarding the current
processors, the TRMRC under SC waveform becomes more attractive for the UL of
maMIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09307</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09307</id><created>2019-01-26</created><authors><author><keyname>Wang</keyname><forenames>Pengfei</forenames></author><author><keyname>Zheng</keyname><forenames>Zijie</forenames></author><author><keyname>Di</keyname><forenames>Boya</forenames></author><author><keyname>Song</keyname><forenames>Lingyang</forenames></author></authors><title>HetMEC: Latency-optimal Task Assignment and Resource Allocation for
  Heterogeneous Mobile Edge Computing</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Driven by great demands on low-latency services of the edge devices (EDs),
mobile edge computing (MEC) has been proposed to enable the computing
capacities at the edge of the radio access network. However, conventional MEC
servers suffer disadvantages such as limited computing capacity, preventing the
computation-intensive tasks to be processed in time. To relief this issue, we
propose the heterogeneous MEC (HetMEC) where the data that cannot be timely
processed at the edge are allowed be offloaded to the upper-layer MEC servers,
and finally to the cloud center (CC) with more powerful computing capacity. We
design the latency minimization algorithm by jointly coordinating the task
assignment, computing and transmission resources among the EDs, multi-layer MEC
servers, and the CC. Simulation results indicate that our proposed algorithm
can achieve a lower latency and higher processing rate than the conventional
MEC scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09318</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09318</id><created>2019-01-27</created><authors><author><keyname>Guo</keyname><forenames>Shuaishuai</forenames></author><author><keyname>Zhang</keyname><forenames>Haixia</forenames></author><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Dang</keyname><forenames>Shuping</forenames></author><author><keyname>Cong</keyname><forenames>Liang</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Signal Shaping for Generalized Spatial Modulation and Generalized
  Quadrature Spatial Modulation</title><categories>eess.SP</categories><comments>Summited to IEEE TWC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates generic signal shaping methods for
multiple-data-stream generalized spatial modulation (GenSM) and generalized
quadrature spatial modulation (GenQSM) based on the maximizing the minimum
Euclidean distance (MMED) criterion. Three cases with different channel state
information at the transmitter (CSIT) are considered, including no CSIT,
statistical CSIT and perfect CSIT. A unified optimization problem is formulated
to find the optimal transmit vector set under size, power and sparsity
constraints. We propose an optimization-based signal shaping (OBSS) approach by
solving the formulated problem directly and a codebook-based signal shaping
(CBSS) approach by finding sub-optimal solutions in discrete space. In the OBSS
approach, we reformulate the original problem to optimize the signal
constellations used for each transmit antenna combination (TAC). Both the size
and entry of all signal constellations are optimized. Specifically, we suggest
the use of a recursive design for size optimization. The entry optimization is
formulated as a non-convex large-scale quadratically constrained quadratic
programming (QCQP) problem and can be solved by existing optimization
techniques with rather high complexity. To reduce the complexity, we propose
the CBSS approach using a codebook generated by quadrature amplitude modulation
(QAM) symbols and a low-complexity selection algorithm to choose the optimal
transmit vector set. Simulation results show that the OBSS approach exhibits
the optimal performance in comparison with existing benchmarks. However, the
OBSS approach is impractical for large-size signal shaping and adaptive signal
shaping with instantaneous CSIT due to the demand of high computational
complexity. As a low-complexity approach, CBSS shows comparable performance and
can be easily implemented in large-size systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09413</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09413</id><created>2019-01-27</created><authors><author><keyname>Xie</keyname><forenames>Hui</forenames></author><author><keyname>Yi</keyname><forenames>Jirong</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Mudumbai</keyname><forenames>Raghu</forenames></author></authors><title>An Information-Theoretic Explanation for the Adversarial Fragility of AI
  Classifiers</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple hypothesis about a compression property of artificial
intelligence (AI) classifiers and present theoretical arguments to show that
this hypothesis successfully accounts for the observed fragility of AI
classifiers to small adversarial perturbations. We also propose a new method
for detecting when small input perturbations cause classifier errors, and show
theoretical guarantees for the performance of this detection method. We present
experimental results with a voice recognition system to demonstrate this
method. The ideas in this paper are motivated by a simple analogy between AI
classifiers and the standard Shannon model of a communication system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09424</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09424</id><created>2019-01-27</created><authors><author><keyname>Topal</keyname><forenames>Ozan Alp</forenames></author><author><keyname>Gecgel</keyname><forenames>Selen</forenames></author><author><keyname>Eksioglu</keyname><forenames>Ender Mete</forenames></author><author><keyname>Kurt</keyname><forenames>Gunes Karabulut</forenames></author></authors><title>Identification of Smart Jammers: Learning based Approaches Using Wavelet
  Representation</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart jammer nodes can disrupt communication between a transmitter and a
receiver in a wireless network, and they leave traces that are undetectable to
classical jammer identification techniques, hidden in the time-frequency plane.
These traces cannot be effectively identified through the use of the classical
Fourier transform based time-frequency transformation (TFT) techniques with a
fixed resolution. Inspired by the adaptive resolution property provided by the
wavelet transforms, in this paper, we propose a jammer identification
methodology that includes a pre-processing step to obtain a multi-resolution
image, followed by the use of a classifier. Support vector machine (SVM) and
deep convolutional neural network (DCNN) architectures are investigated as
classifiers to automatically extract the features of the transformed signals
and to classify them. Three different jamming attacks are considered, the
barrage jamming that targets the complete transmission bandwidth, the
synchronization signal jamming attack that targets synchronization signals and
the reference signal jamming attack that targets the reference signals in an
LTE downlink transmission scenario. The performance of the proposed approach is
compared with the classical Fourier transform based TFT techniques,
demonstrating the efficacy of the proposed approach in the presence of smart
jammers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09462</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09462</id><created>2019-01-27</created><updated>2019-12-28</updated><authors><author><keyname>Karimi</keyname><forenames>Davood</forenames></author><author><keyname>Samei</keyname><forenames>Golnoosh</forenames></author><author><keyname>Shao</keyname><forenames>Yanan</forenames></author><author><keyname>Salcudean</keyname><forenames>Septimiu</forenames></author></authors><title>A deep learning-based method for prostate segmentation in T2-weighted
  magnetic resonance imaging</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel automatic method for accurate segmentation of the prostate
in T2-weighted magnetic resonance imaging (MRI). Our method is based on
convolutional neural networks (CNNs). Because of the large variability in the
shape, size, and appearance of the prostate and the scarcity of annotated
training data, we suggest training two separate CNNs. A global CNN will
determine a prostate bounding box, which is then resampled and sent to a local
CNN for accurate delineation of the prostate boundary. This way, the local CNN
can effectively learn to segment the fine details that distinguish the prostate
from the surrounding tissue using the small amount of available training data.
To fully exploit the training data, we synthesize additional data by deforming
the training images and segmentations using a learned shape model. We apply the
proposed method on the PROMISE12 challenge dataset and achieve state of the art
results. Our proposed method generates accurate, smooth, and artifact-free
segmentations. On the test images, we achieve an average Dice score of 90.6
with a small standard deviation of 2.2, which is superior to all previous
methods. Our two-step segmentation approach and data augmentation strategy may
be highly effective in segmentation of other organs from small amounts of
annotated medical images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09556</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09556</id><created>2019-01-28</created><authors><author><keyname>Saeed</keyname><forenames>Nasir</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author></authors><title>On Achievable Accuracy of Localization in Magnetic Induction-Based
  Internet of Underground Things for Oil and Gas Reservoirs</title><categories>eess.SP</categories><comments>Submitted to IEEE Internet of Things Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic Induction (MI) is an efficient wireless communication method to
deploy operational internet of underground things (IOUT) for oil and gas
reservoirs. The IOUT consists of underground things which are capable of
sensing the underground environment and communicating with the surface. The
MI-based IOUT enable many applications, such as monitoring of the oil rigs,
optimized fracturing, and optimized extraction. Most of these applications are
dependent on the location of the underground things and therefore require
accurate localization techniques. The existing localization techniques for
MI-based underground sensing networks are two-dimensional and do not
characterize the achievable accuracy of the developed methods which are both
crucial and challenging tasks. Therefore, this paper presents the expression of
the Cramer Rao lower bound (CRLB) for three-dimensional MI-based IOUT
localization which takes into account the channel parameters of the underground
magnetic-induction. The derived CRLB provide the suggestions for an MI-based
underground localization system by associating the system parameters with the
error trend. Numerical results demonstrate that localization accuracy is
affected by different channel and networks parameters such as the number of
anchors, noise variance, frequency, and the number of underground things.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09568</identifier>
 <datestamp>2019-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09568</id><created>2019-01-28</created><authors><author><keyname>Chamain</keyname><forenames>Lahiru D.</forenames></author><author><keyname>Dharmawansa</keyname><forenames>Prathapasinghe</forenames></author><author><keyname>Atapattu</keyname><forenames>Saman</forenames></author><author><keyname>Tellambura</keyname><forenames>Chintha</forenames></author></authors><title>Detection of a Signal in Colored Noise: A Random Matrix Theory Based
  Analysis</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to ISIT 2019</comments><msc-class>62E15, 15B52, 15B57, 15A18</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the classical statistical signal processing problem
of detecting a signal in the presence of colored noise with an unknown
covariance matrix. In particular, we consider a scenario where m-dimensional p
possible signal-plus-noise samples and m-dimensional n noise-only samples are
available at the detector. Then the presence of a signal can be detected using
the largest generalized eigenvalue (l.g.e.) of the so called whitened sample
covariance matrix. This amounts to statistically characterizing the maximum
eigenvalue of the deformed Jacobi unitary ensemble (JUE). To this end, we
employ the powerful orthogonal polynomial approach to determine a new finite
dimensional expression for the cumulative distribution function (c.d.f.) of the
l.g.e. of the deformed JUE. This new c.d.f. expression facilitates the further
analysis of the receiver operating characteristics (ROC) of the detector. It
turns out that, for m=n, when m and p increase such that m/p attains a fixed
value, there exists an optimal ROC profile corresponding to each fixed
signal-to-noise ratio (SNR). In this respect, we have established a tight
approximation for the corresponding optimal ROC profile.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09878</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09878</id><created>2019-01-28</created><updated>2019-05-24</updated><authors><author><keyname>Marchisio</keyname><forenames>Alberto</forenames></author><author><keyname>Nanfa</keyname><forenames>Giorgio</forenames></author><author><keyname>Khalid</keyname><forenames>Faiq</forenames></author><author><keyname>Hanif</keyname><forenames>Muhammad Abdullah</forenames></author><author><keyname>Martina</keyname><forenames>Maurizio</forenames></author><author><keyname>Shafique</keyname><forenames>Muhammad</forenames></author></authors><title>CapsAttacks: Robust and Imperceptible Adversarial Attacks on Capsule
  Networks</title><categories>cs.LG cs.CR cs.CV eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Capsule Networks preserve the hierarchical spatial relationships between
objects, and thereby bears a potential to surpass the performance of
traditional Convolutional Neural Networks (CNNs) in performing tasks like image
classification. A large body of work has explored adversarial examples for
CNNs, but their effectiveness on Capsule Networks has not yet been well
studied. In our work, we perform an analysis to study the vulnerabilities in
Capsule Networks to adversarial attacks. These perturbations, added to the test
inputs, are small and imperceptible to humans, but can fool the network to
mispredict. We propose a greedy algorithm to automatically generate targeted
imperceptible adversarial examples in a black-box attack scenario. We show that
this kind of attacks, when applied to the German Traffic Sign Recognition
Benchmark (GTSRB), mislead Capsule Networks. Moreover, we apply the same kind
of adversarial attacks to a 5-layer CNN and a 9-layer CNN, and analyze the
outcome, compared to the Capsule Networks to study differences in their
behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.09923</identifier>
 <datestamp>2019-12-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.09923</id><created>2019-01-28</created><authors><author><keyname>de Oliveira</keyname><forenames>Lucas Giroto</forenames></author><author><keyname>Filomeno</keyname><forenames>Mateus de L.</forenames></author><author><keyname>Ribeiro</keyname><forenames>Mois&#xe9;s V.</forenames></author></authors><title>Orthogonal Chirp Division Multiplexing for Power Line Sensing via
  Time-Domain Reflectometry</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1901.08404</comments><journal-ref>IEEE Sensors Journal (Early Access), pp. 1--10, August 2019</journal-ref><doi>10.1109/JSEN.2019.2932994</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, a time-domain reflectometry (TDR) system based on a baseband
version of the orthogonal chirp-division multiplexing (OCDM) scheme, which is
relies on a modified discrete Fresnel transform (DFnT), is proposed for power
line sensing. After a detailed description of the system model, a multiple
access scheme that exploits the contolution theorem of the modified DFnT for
enabling distributed reflectometric and transferometric sensing of the
monitored power line. Considering typical European underground low-voltage and
US overhead medium-voltage (MV) power distribution networks, range resolution
and maximum unambiguous range for the measurements are assessed for the
proposed scheme. Next, a comparison with multiple access schemes based on the
Hermitian symmetric orthogonal frequency-division multiplexing (HS-OFDM)
discussed in a previous work is performed considering a Brazilian MV overhead
scenario, being the number of measurements obtained over time, as well as
signal-to-interference-plus-noise ratio (SINR) used as performance metrics. The
attained results show that the proposed multiple access scheme results in the
same range resolution as the others. Also, the highest number of measurements
over time is obtained by the proposed scheme, which produces orthogonality
among signals transmitted by different power line modems (PLMs) neither and
time nor frequency domains, but rather in the Fresnel domain. Meanwhile,
although its yielded SINR values are fair among the PLMs consisting the
distributed sensing system, the proposed scheme is slightly outperformed by the
HS-OFDM based on code-division multiple access and by the HS-OFDM based on
frequency-division multiple access at some PLMs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10055</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10055</id><created>2019-01-22</created><updated>2019-02-19</updated><authors><author><keyname>Salazar</keyname><forenames>Julian</forenames></author><author><keyname>Kirchhoff</keyname><forenames>Katrin</forenames></author><author><keyname>Huang</keyname><forenames>Zhiheng</forenames></author></authors><title>Self-Attention Networks for Connectionist Temporal Classification in
  Speech Recognition</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>Accepted to ICASSP 2019</comments><doi>10.1109/ICASSP.2019.8682539</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The success of self-attention in NLP has led to recent applications in
end-to-end encoder-decoder architectures for speech recognition. Separately,
connectionist temporal classification (CTC) has matured as an alignment-free,
non-autoregressive approach to sequence transduction, either by itself or in
various multitask and decoding frameworks. We propose SAN-CTC, a deep, fully
self-attentional network for CTC, and show it is tractable and competitive for
end-to-end speech recognition. SAN-CTC trains quickly and outperforms existing
CTC models and most encoder-decoder models, with character error rates (CERs)
of 4.7% in 1 day on WSJ eval92 and 2.8% in 1 week on LibriSpeech test-clean,
with a fixed architecture and one GPU. Similar improvements hold for WERs after
LM decoding. We motivate the architecture for speech, evaluate position and
downsampling approaches, and explore how label alphabets (character, phoneme,
subword) affect attention heads and performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10076</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10076</id><created>2019-01-28</created><updated>2019-02-22</updated><authors><author><keyname>Tabaghi</keyname><forenames>Puoya</forenames></author><author><keyname>de Hoop</keyname><forenames>Maarten</forenames></author><author><keyname>Dokmani&#x107;</keyname><forenames>Ivan</forenames></author></authors><title>Learning Schatten--von Neumann Operators</title><categories>stat.ML cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the learnability of a class of compact operators known as
Schatten--von Neumann operators. These operators between infinite-dimensional
function spaces play a central role in a variety of applications in learning
theory and inverse problems. We address the question of sample complexity of
learning Schatten-von Neumann operators and provide an upper bound on the
number of measurements required for the empirical risk minimizer to generalize
with arbitrary precision and probability, as a function of class parameter $p$.
Our results give generalization guarantees for regression of
infinite-dimensional signals from infinite-dimensional data. Next, we adapt the
representer theorem of Abernethy \emph{et al.} to show that empirical risk
minimization over an a priori infinite-dimensional, non-compact set, can be
converted to a convex finite dimensional optimization problem over a compact
set. In summary, the class of $p$-Schatten--von Neumann operators is probably
approximately correct (PAC)-learnable via a practical convex program for any $p
&lt; \infty$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10121</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10121</id><created>2019-01-29</created><updated>2019-09-17</updated><authors><author><keyname>Ding</keyname><forenames>Tianben</forenames></author><author><keyname>Hirose</keyname><forenames>Akira</forenames></author></authors><title>Online regularization of complex-valued neural networks for structure
  optimization in wireless-communication channel prediction</title><categories>eess.SP</categories><comments>40 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes online-learning complex-valued neural networks (CVNNs) to
predict future channel states in fast-fading multipath mobile communications.
CVNN is suitable for dealing with a fading communication channel as a single
complex-valued entity. This framework makes it possible to realize accurate
channel prediction by utilizing its high generalization ability in the complex
domain. However, actual communication environments are marked by rapid and
irregular changes, thus causing fluctuation of communication channel states.
Hence, an empirically selected stationary network gives only limited prediction
accuracy. In this paper, we introduce regularization in the update of the CVNN
weights to develop online dynamics that can self-optimize its effective network
size by responding to such channel-state changes. It realizes online adaptive,
highly accurate and robust channel prediction with dynamical adjustment of the
network size. We demonstrate its online adaptability in simulations and real
wireless-propagation experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10231</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10231</id><created>2019-01-29</created><authors><author><keyname>Awate</keyname><forenames>GuruRaj</forenames></author></authors><title>Detection of Alzheimers Disease from MRI using Convolutional Neural
  Networks, Exploring Transfer Learning And BellCNN</title><categories>eess.IV cs.CV cs.LG</categories><comments>IEEE Conference, Intended for non-technical audiences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a need for automatic diagnosis of certain diseases from medical
images that could help medical practitioners for further assessment towards
treating the illness. Alzheimers disease is a good example of a disease that is
often misdiagnosed. Alzheimers disease (Hear after referred to as AD), is
caused by atrophy of certain brain regions and by brain cell death and is the
leading cause of dementia and memory loss [1]. MRI scans reveal this
information but atrophied regions are different for different individuals which
makes the diagnosis a bit more trickier and often gets misdiagnosed [1, 13]. We
believe that our approach to this particular problem would improve the
assessment quality by pre-flagging the images which are more likely to have AD.
We propose two solutions to this; one with transfer learning [9] and other by
BellCNN [14], a custom made Convolutional Neural Network (Hear after referred
to as CNN). Advantages and disadvantages of each approach will also be
discussed in their respective sections. The dataset used for this project is
provided by Open Access Series of Imaging Studies (Hear after referred to as
OASIS) [2, 3, 4], which contains over 400 subjects, 100 of whom have mild to
severe dementia. The dataset has labeled these subjects by two standards of
diagnosis; MiniMental State Examination (Hear after referred to as MMSE) and
Clinical Dementia Rating (Hear after referred to as CDR). These are some of the
general tools and concepts which are prerequisites to our solution; CNN [5, 6],
Neural Networks [10] (Hear after referred to as NN), Anaconda bundle for
python, Regression, Tensorflow [7]. Keywords: Alzheimers Disease, Convolutional
Neural Network, BellCNN, Image Recognition, Machine Learning, MRI, OASIS,
Tensorflow
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10236</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10236</id><created>2019-01-29</created><updated>2019-02-12</updated><authors><author><keyname>Cai</keyname><forenames>Xuesong</forenames></author><author><keyname>Fan</keyname><forenames>Wei</forenames></author></authors><title>A Complexity-Efficient High Resolution Propagation Parameter Estimation
  Algorithm for Ultra-Wideband Large-Scale Uniform Circular Array</title><categories>eess.SP</categories><comments>Single column, 28 pages. In review process with IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mm-wave) communication with large-scale antenna array
configuration is seen as the key enabler of the next generation communication
systems. Accurate knowledge of the mm-wave propagation channels is fundamental
and essential. In this contribution, a novel complexity-efficient high
resolution parameter estimation (HRPE) algorithm is proposed for the mm-wave
channel with large-scale uniform circular array (UCA) applied. The proposed
algorithm is able to obtain the high-resolution estimation results of the
spherical channel propagation parameters. The prior channel information in the
delay domain, i.e., the delay trajectories of individual propagation paths
observed across the array elements, is exploited, by combining the
high-resolution estimation principle and the phase mode excitation technique.
Fast initializations, effective interference cancellations and reduced
searching spaces achieved by the proposed schemes significantly decrease the
algorithm complexity. Furthermore, the channel spatial non-stationarity in path
gain across the array elements is considered for the first time in the
literature for propagation parameter estimation, which is beneficial to obtain
more realistic results as well as to decrease the complexity. A mm-wave
measurement campaign at the frequency band of 28-30 GHz using a large-scale UCA
is exploited to demonstrate and validate the proposed HRPE algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10239</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10239</id><created>2019-01-29</created><updated>2019-06-12</updated><authors><author><keyname>Singh</keyname><forenames>Prem</forenames></author><author><keyname>Mishra</keyname><forenames>Himanshu B.</forenames></author><author><keyname>Jagannatham</keyname><forenames>Aditya K.</forenames></author><author><keyname>Vasudevan</keyname><forenames>K.</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Uplink Sum-Rate and Power Scaling Laws for Multi-User Massive MIMO-FBMC
  Systems</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Communications , 29 October 2019</journal-ref><doi>10.1109/TCOMM.2019.2950216</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyses the performance of filter bank multicarrier (FBMC)
signaling in conjunction with offset quadrature amplitude modulation (OQAM) in
multi-user (MU) massive multiple-input multiple-output (MIMO) systems.
Initially, closed form expressions are derived for tight lower bounds
corresponding to the achievable uplink sum-rates for FBMC-based single-cell MU
massive MIMO systems relying on maximum ratio combining (MRC), zero forcing
(ZF) and minimum mean square error (MMSE) receiver processing with/without
perfect channel state information (CSI) at the base station (BS). This is
achieved by exploiting the statistical properties of the intrinsic interference
that is characteristic of FBMC systems. Analytical results are also developed
for power scaling in the uplink of MU massive MIMO-FBMC systems. The above
analysis of the achievable sum-rates and corresponding power scaling laws is
subsequently extended to multi-cell scenarios considering both perfect as well
as imperfect CSI, and the effect of pilot contamination. The
delay-spread-induced performance erosion imposed on the linear processing aided
BS receiver is numerically quantified by simulations. Numerical results are
presented to demonstrate the close match between our analysis and simulations,
and to illustrate and compare the performance of FBMC and traditional
orthogonal frequency division multiplexing (OFDM)-based MU massive MIMO
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10240</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10240</id><created>2019-01-29</created><authors><author><keyname>Huzaifah</keyname><forenames>M.</forenames></author><author><keyname>Wyse</keyname><forenames>L.</forenames></author></authors><title>Applying Visual Domain Style Transfer and Texture Synthesis Techniques
  to Audio - Insights and Challenges</title><categories>cs.SD eess.AS</categories><comments>Post-peer-review, pre-copyedit version of an article to be published
  in Neural Computing and Applications. 11 figures</comments><doi>10.1007/s00521-019-04053-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Style transfer is a technique for combining two images based on the
activations and feature statistics in a deep learning neural network
architecture. This paper studies the analogous task in the audio domain and
takes a critical look at the problems that arise when adapting the original
vision-based framework to handle spectrogram representations. We conclude that
CNN architectures with features based on 2D representations and convolutions
are better suited for visual images than for time-frequency representations of
audio. Despite the awkward fit, experiments show that the Gram matrix
determined &quot;style&quot; for audio is more closely aligned with timbral signatures
without temporal structure whereas network layer activity determining audio
&quot;content&quot; seems to capture more of the pitch and rhythmic structures. We shed
insight on several reasons for the domain differences with illustrative
examples. We motivate the use of several types of one-dimensional CNNs that
generate results that are better aligned with intuitive notions of audio
texture than those based on existing architectures built for images. These
ideas also prompt an exploration of audio texture synthesis with architectural
variants for extensions to infinite textures, multi-textures, parametric
control of receptive fields and the constant-Q transform as an alternative
frequency scaling for the spectrogram.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10300</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10300</id><created>2019-01-26</created><updated>2020-02-22</updated><authors><author><keyname>Liu</keyname><forenames>Xiaolei</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaosong</forenames></author><author><keyname>Wan</keyname><forenames>Kun</forenames></author><author><keyname>Zhu</keyname><forenames>Qingxin</forenames></author><author><keyname>Ding</keyname><forenames>Yufei</forenames></author></authors><title>Weighted-Sampling Audio Adversarial Example Attack</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies have highlighted audio adversarial examples as a ubiquitous
threat to state-of-the-art automatic speech recognition systems. Thorough
studies on how to effectively generate adversarial examples are essential to
prevent potential attacks. Despite many research on this, the efficiency and
the robustness of existing works are not yet satisfactory. In this paper, we
propose~\textit{weighted-sampling audio adversarial examples}, focusing on the
numbers and the weights of distortion to reinforce the attack. Further, we
apply a denoising method in the loss function to make the adversarial attack
more imperceptible. Experiments show that our method is the first in the field
to generate audio adversarial examples with low noise and high audio robustness
at the minute time-consuming level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10396</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10396</id><created>2019-01-29</created><authors><author><keyname>Romanov</keyname><forenames>Elad</forenames></author><author><keyname>Ordentlich</keyname><forenames>Or</forenames></author></authors><title>Blind Unwrapping of Modulo Reduced Gaussian Vectors: Recovering MSBs
  from LSBs</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of recovering $n$ i.i.d samples from a zero mean
multivariate Gaussian distribution with an unknown covariance matrix, from
their modulo wrapped measurements, i.e., measurement where each coordinate is
reduced modulo $\Delta$, for some $\Delta&gt;0$. For this setup, which is
motivated by quantization and analog-to-digital conversion, we develop a
low-complexity iterative decoding algorithm. We show that if a benchmark
informed decoder that knows the covariance matrix can recover each sample with
small error probability, and $n$ is large enough, the performance of the
proposed blind recovery algorithm closely follows that of the informed one. We
complement the analysis with numeric results that show that the algorithm
performs well even in non-asymptotic conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10472</identifier>
 <datestamp>2020-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10472</id><created>2019-01-29</created><updated>2020-01-15</updated><authors><author><keyname>Boutin</keyname><forenames>Mireille</forenames></author><author><keyname>Kemper</keyname><forenames>Gregor</forenames></author></authors><title>A Drone Can Hear the Shape of a Room</title><categories>math.AC eess.SP math.MG</categories><comments>Revised version: some clarifications and references added. The paper
  is accepted for publication in SIAM J. Appl. Algebra Geometry. 15 pages</comments><msc-class>51K99, 13P10, 13P25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that one can reconstruct the shape of a room with planar walls from
the first-order echoes received by four non-planar microphones placed on a
drone with generic position and orientation. Both the cases where the source is
located in the room and on the drone are considered. If the microphone
positions are picked at random, then with probability one, the location of any
wall is correctly reconstructed as long as it is heard by four microphones. Our
algorithm uses a simple echo sorting criterion to recover the wall assignments
for the echoes. We prove that, if the position and orientation of the drone on
which the microphones are mounted do not lie on a certain set of dimension at
most 5 in the 6-dimensional space of all drone positions and orientations, then
the wall assignment obtained through our echo sorting criterion must be the
right one and thus the reconstruction obtained through our algorithm is
correct. Our proof uses methods from computational commutative algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10503</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10503</id><created>2019-01-29</created><authors><author><keyname>Garnot</keyname><forenames>Vivien Sainte Fare</forenames></author><author><keyname>Landrieu</keyname><forenames>Loic</forenames></author><author><keyname>Giordano</keyname><forenames>Sebastien</forenames></author><author><keyname>Chehata</keyname><forenames>Nesrine</forenames></author></authors><title>Time-Space tradeoff in deep learning models for crop classification on
  satellite multi-spectral image time series</title><categories>eess.IV cs.CV cs.LG</categories><comments>Currently under review</comments><journal-ref>International Geoscience and Remote Sensing Symposium 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we investigate several structured deep learning models for
crop type classification on multi-spectral time series. In particular, our aim
is to assess the respective importance of spatial and temporal structures in
such data. With this objective, we consider several designs of convolutional,
recurrent, and hybrid neural networks, and assess their performance on a large
dataset of freely available Sentinel-2 imagery. We find that the
best-performing approaches are hybrid configurations for which most of the
parameters (up to 90%) are allocated to modeling the temporal structure of the
data. Our results thus constitute a set of guidelines for the design of bespoke
deep learning models for crop type classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10508</identifier>
 <datestamp>2019-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10508</id><created>2019-01-29</created><authors><author><keyname>Zhang</keyname><forenames>Fengchun</forenames></author><author><keyname>Fan</keyname><forenames>Wei</forenames></author></authors><title>Near-field Ultra-wideband mmWave Channel Characterization Using
  Successive Cancellation Beamspace UCA Algorithm</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Of the wide palette of 5G features, ultra-wide bandwidth and large-scale
antenna configuration are regarded as the essential enabling technology
components at millimeter wave (mmWave) communication. Accurate knowledge of
delay and angle information of multipath components is essential for many
applications in mmWave systems. There is a strong need for a low
computation-cost channel estimation algorithm for such systems, where typically
adopted far-field and narrowband assumptions might be violated. In this work, a
generic yet novel beamspace uniform circular array (UCA) beamforming algorithm
with successive cancellation scheme is proposed to jointly detect the impinging
angle and delay of the multipath components. The proposed algorithm is
computationally cheap and it works for ultra-wideband (UWB) systems in the
near-field conditions. Both numerical simulations and experimental validation
results are provided to demonstrate the effectiveness and robustness of the
proposed algorithm, compared to the state-of-art works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10533</identifier>
 <datestamp>2019-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10533</id><created>2019-01-29</created><authors><author><keyname>Rezvani</keyname><forenames>Mohammad Mehdi</forenames></author><author><keyname>Khoud</keyname><forenames>Reza</forenames></author></authors><title>Voltage Profile Improvement of Distribution Grid by Using a New Control
  Approach on Injected Reactive Power of Plug-in Electric Vehicle Parking Lots
  to Grid</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Establishing electrical parking lots will become more important by increasing
the use of electric vehicles (EVs). These parking lots not only can be seen as
high electrical power consumption loads which can cause the voltage drop at
feeders but also they can be used as electrical power plants that can help the
main power grid during the load peak hour or any congestion. Therefore, finding
an optimum place for the building of these lots, in which the deviation of the
voltage at the feeder, power loss in the grid, and cost be minimized, is
essential. In this paper, a new method of vehicle-to-grid reactive power
support (V2GQ) has been used to add the model of plug-in electric vehicle (PEV)
as one part of the objective function to find the optimum place of parking
lots. The non-sorting genetic algorithm II (NSGA2) is used here as an
optimization algorithm to find the optimum voltage profile based on the
location of parking lots. For validation of the purposed method, a 33-bus
standard distribution network has been studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10562</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10562</id><created>2019-01-29</created><authors><author><keyname>Schwarz</keyname><forenames>Robert T.</forenames></author><author><keyname>Delamotte</keyname><forenames>Thomas</forenames></author><author><keyname>Storek</keyname><forenames>Kai-Uwe</forenames></author><author><keyname>Knopp</keyname><forenames>Andreas</forenames></author></authors><title>MIMO Applications for Multibeam Satellites</title><categories>eess.SP</categories><comments>Accepted for publication in IEEE Transactions on Broadcasting</comments><doi>10.1109/TBC.2019.2898150</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High throughput satellites employing multibeam antennas and full frequency
reuse for broadband satellite services are considered in this paper. Such
architectures offer, for example, a cost-effective solution to optimize data
delivery and extend the coverage areas in future 5G networks. We propose the
application of the multiple-input-multiple-output (MIMO) technology in both the
feeder link and the multiuser downlink. Spatial multiplexing of different data
streams is performed in a common feeder beam. In the user links, MIMO with
multiple beams is exploited to simultaneously serve different users in the same
frequency channel. Under particular design constraints, effective spatial
separation of the multiple user signals is possible. To mitigate the
interstream interference in the MIMO feeder link as well as the multiuser
downlink, precoding of the transmit signals is applied. Simulation results
illustrate the performance gains in terms of sum throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10629</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10629</id><created>2019-01-27</created><updated>2019-02-28</updated><authors><author><keyname>Rashno</keyname><forenames>Elyas</forenames></author><author><keyname>Akbari</keyname><forenames>Ahmad</forenames></author><author><keyname>Nasersharif</keyname><forenames>Babak</forenames></author></authors><title>A Convolutional Neural Network model based on Neutrosophy for Noisy
  Speech Recognition</title><categories>eess.AS cs.LG cs.SD</categories><comments>International conference on Pattern Recognition and Image Analysis
  (IPRIA 2019)</comments><doi>10.1109/PRIA.2019.8786010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks are sensitive to unknown noisy condition in the
test phase and so their performance degrades for the noisy data classification
task including noisy speech recognition. In this research, a new convolutional
neural network (CNN) model with data uncertainty handling; referred as NCNN
(Neutrosophic Convolutional Neural Network); is proposed for classification
task. Here, speech signals are used as input data and their noise is modeled as
uncertainty. In this task, using speech spectrogram, a definition of
uncertainty is proposed in neutrosophic (NS) domain. Uncertainty is computed
for each Time-frequency point of speech spectrogram as like a pixel. Therefore,
uncertainty matrix with the same size of spectrogram is created in NS domain.
In the next step, a two parallel paths CNN classification model is proposed.
Speech spectrogram is used as input of the first path and uncertainty matrix
for the second path. The outputs of two paths are combined to compute the final
output of the classifier. To show the effectiveness of the proposed method, it
has been compared with conventional CNN on the isolated words of Aurora2
dataset. The proposed method achieves the average accuracy of 85.96 in noisy
train data. It is more robust against Car, Airport and Subway noises with
accuracies 90, 88 and 81 in test sets A, B and C, respectively. Results show
that the proposed method outperforms conventional CNN with the improvement of
6, 5 and 2 percentage in test set A, test set B and test sets C, respectively.
It means that the proposed method is more robust against noisy data and handle
these data effectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10647</identifier>
 <datestamp>2019-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10647</id><created>2019-01-29</created><authors><author><keyname>Truong</keyname><forenames>Lan V.</forenames></author><author><keyname>Scarlett</keyname><forenames>Jonathan</forenames></author></authors><title>Support Recovery in the Phase Retrieval Model: Information-Theoretic
  Fundamental Limits</title><categories>cs.IT eess.SP math.IT stat.ML</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The support recovery problem consists of determining a sparse subset of
variables that is relevant in generating a set of observations. In this paper,
we study the support recovery problem in the phase retrieval model consisting
of noisy phaseless measurements, which arises in a diverse range of settings
such as optical detection, X-ray crystallography, electron microscopy, and
coherent diffractive imaging. Our focus is on information-theoretic fundamental
limits under an approximate recovery criterion, considering both discrete and
Gaussian models for the sparse non-zero entries. In both cases, our bounds
provide sharp thresholds with near-matching constant factors in several scaling
regimes on the sparsity and signal-to-noise ratio. As a key step towards
obtaining these results, we develop new concentration bounds for the
conditional information content of log-concave random variables, which may be
of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10675</identifier>
 <datestamp>2019-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10675</id><created>2019-01-29</created><authors><author><keyname>Brahman</keyname><forenames>Azade</forenames></author><author><keyname>Novosad</keyname><forenames>Dilan</forenames></author><author><keyname>Tabrizi</keyname><forenames>Mehriar</forenames></author><author><keyname>Cook</keyname><forenames>Tim</forenames></author><author><keyname>Lee</keyname><forenames>Wei Jen</forenames></author></authors><title>Analytical Approach to Study the Impacts of Mutual Coupling on
  Transmission Lines Protection Systems</title><categories>eess.SP</categories><comments>Accepted in 2019 Texas Power and Energy Conference (TPEC 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While there are numerous literatures that have addressed the impact of mutual
coupling on the reliability and security of protection schemes and have
provided possible mitigation solutions, there has not been adequate research
and documentation presenting a comprehensive analytical approach to 1) estimate
the magnitude of mutual coupling and 2) quantify the adverse impact of mutual
coupling in real-life scenarios under several system faults across various
types of protective elements. This should be considered as the first stage of
any mutual coupling related study preceding the second stage in which the
mitigation against mutual coupling is to be developed. The proposed methodology
can be used to study the impact of mutual coupling on ground overcurrent
relays, ground and phase distance as well as pilot protection schemes. As part
of the proposed approach, EMT simulation is utilized to quantify the extent of
sub-transient overshoot and current reversal that may have adverse impact on
the performance of studied relays. A real-life case study within the ERCOT
network has been used to demonstrate the proposed study approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10700</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10700</id><created>2019-01-30</created><updated>2019-12-22</updated><authors><author><keyname>Yang</keyname><forenames>Tianye</forenames></author><author><keyname>Liu</keyname><forenames>Xuefeng</forenames></author><author><keyname>Tang</keyname><forenames>Shaojie</forenames></author><author><keyname>Niu</keyname><forenames>Jianwei</forenames></author><author><keyname>Guo</keyname><forenames>Peng</forenames></author></authors><title>A new PIR-based method for real-time tracking</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pyroelectric infrared (PIR) sensors are considered to be promising devices
for device-free localization due to its advantages of low cost, less intrusive,
and the immunity from multi-path fading. However, most of the existing
PIR-based localization systems only utilize the binary information of PIR
sensors and therefore require a large number of PIR sensors and a careful
deployment. A few works directly map the raw data of PIR sensors to one's
location using machine learning approaches. However, these approaches require
to collect abundant training data and suffer from environmental change. In this
paper, we propose a PIR-based device-free localization approach based on the
raw data of PIR sensors. The key of this approach is to extract a new type of
location information called as the azimuth change. The extraction of the
azimuth change relies on the physical properties of PIR sensors. Therefore, no
abundant training data are needed and the system is robust to environmental
change. Through experiments, we demonstrated that a device-free localization
system incorporating the information of azimuth change outperforms the
state-of-the-art approaches in terms of higher location accuracy. In addition,
the information of the azimuth change can be easily integrated with other
PIR-based localization systems to improve their localization accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10817</identifier>
 <datestamp>2019-08-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10817</id><created>2019-01-30</created><authors><author><keyname>Groll</keyname><forenames>Herbert</forenames></author><author><keyname>Z&#xf6;chmann</keyname><forenames>Erich</forenames></author><author><keyname>Pratschner</keyname><forenames>Stefan</forenames></author><author><keyname>Lerch</keyname><forenames>Martin</forenames></author><author><keyname>Sch&#xfc;tzenh&#xf6;fer</keyname><forenames>Daniel</forenames></author><author><keyname>Hofer</keyname><forenames>Markus</forenames></author><author><keyname>Blumenstein</keyname><forenames>Jiri</forenames></author><author><keyname>Sangodoyin</keyname><forenames>Seun</forenames></author><author><keyname>Zemen</keyname><forenames>Thomas</forenames></author><author><keyname>Prokes</keyname><forenames>Ales</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author><author><keyname>Caban</keyname><forenames>Sebastian</forenames></author></authors><title>Sparsity in the Delay-Doppler Domain for Measured 60 GHz
  Vehicle-to-Infrastructure Communication Channels</title><categories>eess.SP</categories><comments>submitted to IEEE International Conference on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report results from millimeter wave vehicle-to-infrastructure (V2I)
channel measurements conducted on Sept. 25, 2018 in an urban street
environment, down-town Vienna, Austria. Measurements of a frequency-division
multiplexed multiple-input single-output channel have been acquired with a
time-domain channel sounder at 60 GHz with a bandwidth of 100 MHz and a
frequency resolution of 5 MHz. Two horn antennas were used on a moving
transmitter vehicle: one horn emitted a beam towards the horizon and the second
horn emitted an elevated beam at 15-degrees up-tilt. This configuration was
chosen to assess the impact of beam elevation on V2I communication channel
characteristics: propagation loss and sparsity of the local scattering function
in the delay-Doppler domain. The measurement results within urban speed limits
show high sparsity in the delay-Doppler domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10826</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10826</id><created>2019-01-28</created><authors><author><keyname>Nunes</keyname><forenames>Jo&#xe3;o Ant&#xf4;nio Chagas</forenames></author><author><keyname>Mac&#xea;do</keyname><forenames>David</forenames></author><author><keyname>Zanchettin</keyname><forenames>Cleber</forenames></author></authors><title>Additive Margin SincNet for Speaker Recognition</title><categories>eess.AS cs.CL cs.LG cs.NE cs.SD stat.ML</categories><journal-ref>2019 International Joint Conference on Neural Networks (IJCNN)</journal-ref><doi>10.1109/IJCNN.2019.8852112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker Recognition is a challenging task with essential applications such as
authentication, automation, and security. The SincNet is a new deep learning
based model which has produced promising results to tackle the mentioned task.
To train deep learning systems, the loss function is essential to the network
performance. The Softmax loss function is a widely used function in deep
learning methods, but it is not the best choice for all kind of problems. For
distance-based problems, one new Softmax based loss function called Additive
Margin Softmax (AM-Softmax) is proving to be a better choice than the
traditional Softmax. The AM-Softmax introduces a margin of separation between
the classes that forces the samples from the same class to be closer to each
other and also maximizes the distance between classes. In this paper, we
propose a new approach for speaker recognition systems called AM-SincNet, which
is based on the SincNet but uses an improved AM-Softmax layer. The proposed
method is evaluated in the TIMIT dataset and obtained an improvement of
approximately 40% in the Frame Error Rate compared to SincNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10832</identifier>
 <datestamp>2019-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10832</id><created>2019-01-30</created><updated>2019-11-26</updated><authors><author><keyname>Huang</keyname><forenames>Hongji</forenames></author><author><keyname>Yang</keyname><forenames>Yuchun</forenames></author><author><keyname>Wang</keyname><forenames>Hong</forenames></author><author><keyname>Ding</keyname><forenames>Zhiguo</forenames></author><author><keyname>Sari</keyname><forenames>Hikmet</forenames></author><author><keyname>Adachi</keyname><forenames>Fumiyuki</forenames></author></authors><title>Deep Reinforcement Learning for UAV Navigation Through Massive MIMO
  Technique</title><categories>eess.SP</categories><comments>Accepted by IEEE Transactions on Vehicular Technology. doi:
  10.1109/TVT.2019.2952549</comments><journal-ref>IEEE Transactions on Vehicular Technology,Oct. 2019</journal-ref><doi>10.1109/TVT.2019.2952549.</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAVs) technique has been recognized as a promising
solution in future wireless connectivity from the sky, and UAV navigation is
one of the most significant open research problems, which has attracted wide
interest in the research community. However, the current UAV navigation schemes
are unable to capture the UAV motion and select the best UAV-ground links in
real time, and these weaknesses overwhelm the UAV navigation performance. To
tackle these fundamental limitations, in this paper, we merge the
state-of-theart deep reinforcement learning with the UAV navigation through
massive multiple-input-multiple-output (MIMO) technique. To be specific, we
carefully design a deep Q-network (DQN) for optimizing the UAV navigation by
selecting the optimal policy, and then we propose a learning mechanism for
processing the DQN. The DQN is trained so that the agent is capable of making
decisions based on the received signal strengths for navigating theUAVs with
the aid of the powerful Q-learning. Simulation results are provided to
corroborate the superiority of the proposed schemes in terms of the coverage
and convergence compared with those of the other schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10885</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.10885</id><created>2019-01-25</created><updated>2019-05-07</updated><authors><author><keyname>Li</keyname><forenames>Xiao Peng</forenames></author><author><keyname>Huang</keyname><forenames>Lei</forenames></author><author><keyname>So</keyname><forenames>Hing Cheung</forenames></author><author><keyname>Zhao</keyname><forenames>Bo</forenames></author></authors><title>A Survey on Matrix Completion: Perspective of Signal Processing</title><categories>eess.SP</categories><comments>12 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix completion (MC) is a promising technique which is able to recover an
intact matrix with low-rank property from sub-sampled/incomplete data. Its
application varies from computer vision, signal processing to wireless network,
and thereby receives much attention in the past several years. There are plenty
of works addressing the behaviors and applications of MC methodologies. This
work provides a comprehensive review for MC approaches from the perspective of
signal processing. In particular, the MC problem is first grouped into six
optimization problems to help readers understand MC algorithms. Next, four
representative types of optimization algorithms solving the MC problem are
reviewed. Ultimately, three different application fields of MC are described
and evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11074</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11074</id><created>2019-01-30</created><authors><author><keyname>Bazaga</keyname><forenames>Adri&#xe1;n</forenames></author><author><keyname>Rold&#xe1;n</keyname><forenames>M&#xf2;nica</forenames></author><author><keyname>Badosa</keyname><forenames>Carmen</forenames></author><author><keyname>Jim&#xe9;nez-Mallebrera</keyname><forenames>Cecilia</forenames></author><author><keyname>Porta</keyname><forenames>Josep M.</forenames></author></authors><title>A Convolutional Neural Network for the Automatic Diagnosis of Collagen
  VI related Muscular Dystrophies</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>Submitted for review to Expert Systems With Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of machine learning systems for the diagnosis of rare
diseases is challenging mainly due the lack of data to study them. Despite this
challenge, this paper proposes a system for the Computer Aided Diagnosis (CAD)
of low-prevalence, congenital muscular dystrophies from confocal microscopy
images. The proposed CAD system relies on a Convolutional Neural Network (CNN)
which performs an independent classification for non-overlapping patches tiling
the input image, and generates an overall decision summarizing the individual
decisions for the patches on the query image. This decision scheme points to
the possibly problematic areas in the input images and provides a global
quantitative evaluation of the state of the patients, which is fundamental for
diagnosis and to monitor the efficiency of therapies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11091</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11091</id><created>2019-01-30</created><authors><author><keyname>Badarneh</keyname><forenames>Osamah. S.</forenames></author><author><keyname>da Costa</keyname><forenames>Daniel B.</forenames></author><author><keyname>Sofotasios</keyname><forenames>Paschalis C.</forenames></author><author><keyname>Muhaidat</keyname><forenames>Sami</forenames></author><author><keyname>Cotton</keyname><forenames>Simon L.</forenames></author></authors><title>On the Sum of Fisher-Snedecor F Variates and its Application to
  Maximal-Ratio Combining</title><categories>eess.SP</categories><comments>5 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Capitalizing on the recently proposed Fisher-Snedecor F composite fading
model, in this letter, we investigate the sum of independent but not
identically distributed (i.n.i.d.) Fisher-Snedecor F variates. First, a novel
closed-form expression is derived for the moment generating function of the
instantaneous signal-to-noise ratio. Based on this, the corresponding
probability density function and cumulative distribution function of the sum of
i.n.i.d. Fisher- Snedecor F variates are derived, which are subsequently
employed in the analysis of multiple branch maximal-ratio combining (MRC).
Specifically, we investigate the impact of multipath and shadowed fading on the
outage probability and outage capacity of MRC based receivers. In addition, we
derive exact closed-form expressions for the average bit error rate of coherent
binary modulation schemes followed by an asymptotic analysis which provides
further insights into the effect of the system parameters on the overall
performance. Importantly, it is shown that the effect of multipath fading on
the system performance is more pronounced than that of shadowing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11139</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11139</id><created>2019-01-30</created><updated>2019-06-05</updated><authors><author><keyname>Kirchner</keyname><forenames>Matthew R.</forenames></author></authors><title>A Level Set Approach to Online Sensing and Trajectory Optimization with
  Time Delays</title><categories>cs.SY eess.SP math.OC</categories><comments>Updated formatting to comply with publications guidelines. Corrected
  some minor typos. To appear in the proceedings of the 10th IFAC Symposium on
  Intelligent Autonomous Vehicles</comments><journal-ref>IFAC PapersOnLine, volume 52, issue 8, pp. 301-306, 2019</journal-ref><doi>10.1016/j.ifacol.2019.08.087</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Presented is a method to compute certain classes of Hamilton-Jacobi equations
that result from optimal control and trajectory generation problems with time
delays. Many robotic control and trajectory problems have limited information
of the operating environment a priori and must continually perform online
trajectory optimization in real time after collecting measurements. The sensing
and optimization can induce a significant time delay, and must be accounted for
when computing the trajectory. This paper utilizes the generalized Hopf
formula, which avoids the exponential dimensional scaling typical of other
numerical methods for computing solutions to the Hamilton-Jacobi equation. We
present as an example a robot that incrementally predicts a communication
channel from measurements as it travels. As part of this example, we introduce
a seemingly new generalization of a non-parametric formulation of robotic
communication channel estimation. New communication measurements are used to
improve the channel estimate and online trajectory optimization with time-delay
compensation is performed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11220</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11220</id><created>2019-01-31</created><authors><author><keyname>Yan</keyname><forenames>Han</forenames></author><author><keyname>Cabric</keyname><forenames>Danijela</forenames></author></authors><title>Compressive Initial Access and Beamforming Training for Millimeter-Wave
  Cellular Systems</title><categories>eess.SP</categories><comments>14 pages, 7 figures, submitted to IEEE Journal of Selected Topics in
  Signal Processing</comments><doi>10.1109/JSTSP.2019.2931206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Initial access (IA) is a fundamental physical layer procedure in cellular
systems where user equipment (UE) detects nearby base station (BS) as well as
acquire synchronization. Due to the necessity of using antenna array in
millimeter-wave (mmW) IA, the channel spatial information can also be inferred.
The state-of-the-art directional IA (DIA) uses sector sounding beams with
limited angular resolution, and thus requires additional dedicated radio
resources, access latency and overhead for refined beam training. To remedy the
problem of access latency and overhead in DIA, this work proposes to use a
quasi-omni pseudorandom sounding beam for IA, and develops a novel algorithm
for joint initial access and fine resolution initial beam training without
requiring extra radio resources. We provide the analysis of the proposed
algorithm miss detection rate under synchronization error, and further derive
Cram\'er-Rao lower bound of angular estimation under frequency offset. Using
QuaDRiGa simulator with mmMAGIC model at 28 GHz, the numerical results show
that the proposed approach is advantageous to DIA with hierarchical beam
training. The proposed algorithm offers up to two order of magnitude access
latency saving compared to DIA, when the same discovery, post training SNR, and
overhead performance are targeted. This conclusion holds true in various
propagation environments and 3D locations of a mmW pico-cell with up to 140m
radius.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11240</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11240</id><created>2019-01-31</created><updated>2019-02-01</updated><authors><author><keyname>Atakan</keyname><forenames>Baris</forenames></author><author><keyname>Gulec</keyname><forenames>Fatih</forenames></author></authors><title>Signal reconstruction in diffusion-based molecular communication</title><categories>eess.SP cs.ET</categories><comments>This paper is submitted to Transactions on Emerging
  Telecommunications Technologies journal on 30th of January 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Molecular Communication (MC) is an important nanoscale communication
paradigm, which is employed for the interconnection of the nanomachines (NMs)
to form nanonetworks. A transmitter NM (TN) sends the information symbols by
emitting molecules into the transmission medium and a receiver NM (RN) receives
the information symbols by sensing the molecule concentration. In this paper, a
model of how a RN measures and reconstructs the molecular signal is proposed.
The signal around the RN is assumed to be a Gaussian random process instead of
deterministic approach in a more realistic way. After the reconstructed signal
is derived as a Doubly Stochastic Poisson Process (DSPP), the distortion
between the signal around the RN and the reconstructed signal is derived as a
new performance parameter in MC systems. The derived distortion which is a
function of system parameters such as RN radius, sampling period and the
diffusion coefficient of the channel, is shown to be valid by employing random
walk simulations. Then, it is shown that the original signal can be
satisfactorily reconstructed with a sufficiently low-level of distortion.
Finally, optimum RN design parameters, namely RN radius, sampling period and
sampling frequency, are derived by minimizing the signal distortion. The
simulation results reveal that there is a trade-off among the RN design
parameters which can be jointly set for a desired signal distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11291</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11291</id><created>2019-01-31</created><updated>2019-02-17</updated><authors><author><keyname>Le</keyname><forenames>Thanh-Ha</forenames></author><author><keyname>Gilberton</keyname><forenames>Philippe</forenames></author><author><keyname>Duong</keyname><forenames>Ngoc Q. K.</forenames></author></authors><title>Discriminate natural versus loudspeaker emitted speech</title><categories>cs.SD eess.AS</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we address a novel, but potentially emerging, problem of
discriminating the natural human voices and those played back by any kind of
audio devices in the context of interactions with in-house voice user
interface. The tackled problem may find relevant applications in (1) the
far-field voice interactions of vocal interfaces such as Amazon Echo, Google
Home, Facebook Portal, etc, and (2) the replay spoofing attack detection. The
detection of loudspeaker emitted speech will help avoid false wake-ups or
unintended interactions with the devices in the first application, while
eliminating attacks involve the replay of recordings collected from enrolled
speakers in the second one. At first we collect a real-world dataset under
well-controlled conditions containing two classes: recorded speeches directly
spoken by numerous people (considered as the natural speech), and recorded
speeches played back from various loudspeakers (considered as the loudspeaker
emitted speech). Then from this dataset, we build prediction models based on
Deep Neural Network (DNN) for which different combination of audio features
have been considered. Experiment results confirm the feasibility of the task
where the combination of audio embeddings extracted from SoundNet and VGGish
network yields the classification accuracy up to about 90%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11332</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11332</id><created>2019-01-31</created><updated>2019-04-30</updated><authors><author><keyname>Mingote</keyname><forenames>Victoria</forenames></author><author><keyname>Miguel</keyname><forenames>Antonio</forenames></author><author><keyname>Ortega</keyname><forenames>Alfonso</forenames></author><author><keyname>Lleida</keyname><forenames>Eduardo</forenames></author></authors><title>Optimization of the Area Under the ROC Curve using Neural Network
  Supervectors for Text-Dependent Speaker Verification</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores two techniques to improve the performance of
text-dependent speaker verification systems based on deep neural networks.
Firstly, we propose a general alignment mechanism to keep the temporal
structure of each phrase and obtain a supervector with the speaker and phrase
information, since both are relevant for a text-dependent verification. As we
show, it is possible to use different alignment techniques to replace the
global average pooling providing significant gains in performance. Moreover, we
also present a novel back-end approach to train a neural network for detection
tasks by optimizing the Area Under the Curve (AUC) as an alternative to the
usual triplet loss function, so the system is end-to-end, with a cost function
close to our desired measure of performance. As we can see in the experimental
section, this approach improves the system performance, since our triplet
neural network based on an approximation of the AUC (aAUC) learns how to
discriminate between pairs of examples from the same identity and pairs of
different identities. The different alignment techniques to produce
supervectors in addition to the new back-end approach were tested on the
RSR2015-Part I database for text-dependent speaker verification, providing
competitive results compared to similar size networks using the global average
pooling to extract supervectors and using a simple back-end or triplet loss
training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11368</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11368</id><created>2019-01-31</created><updated>2019-02-03</updated><authors><author><keyname>Mendis</keyname><forenames>Gihan</forenames></author><author><keyname>Wei</keyname><forenames>Jin</forenames></author><author><keyname>Madanayakey</keyname><forenames>Arjuna</forenames></author><author><keyname>Mandalz</keyname><forenames>Soumyajit</forenames></author></authors><title>Spectral Attention-Driven Intelligent Target Signal Identification on a
  Wideband Spectrum</title><categories>eess.SP</categories><comments>6 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a spectral attention-driven reinforcement learning based
intelligent method for effective and efficient detection of important signals
in a wideband spectrum. In the work presented in this paper, it is assumed that
the modulation technique used is available as a priori knowledge of the
targeted important signal. The proposed spectral attention-driven intelligent
method is consists of two main components, a spectral correlation function
(SCF) based spectral visualization scheme and a spectral attention-driven
reinforcement learning mechanism that adaptively selects the spectrum range and
implements the intelligent signal detection. Simulations illustrate that the
proposed method can achieve high accuracy of signal detection while observation
of spectrum is limited to few ranges via effectively selecting the spectrum
ranges to be observed. Furthermore, the proposed spectral attention-driven
machine learning method can lead to an efficient adaptive intelligent spectrum
sensor designs in cognitive radio (CR) receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11389</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11389</id><created>2019-01-22</created><authors><author><keyname>Tsianikas</keyname><forenames>Stamatis</forenames></author><author><keyname>Zhou</keyname><forenames>Jian</forenames></author><author><keyname>Yousefi</keyname><forenames>Nooshin</forenames></author><author><keyname>Coit</keyname><forenames>David W.</forenames></author></authors><title>Battery selection for optimal grid-outage resilient photovoltaic and
  battery systems</title><categories>eess.SP stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first and most important purpose of the current research work is to
investigate the effects that different battery types have on the optimal
configuration of photovoltaic (PV) and battery systems, from both economic and
resilience perspectives. Many industry reports, as well as research papers,
have already highlighted the crucial role that storage systems have in the
coming years in the electricity sector, especially when combined with renewable
energy systems (RES). Given the high cost of storage technologies, there is an
urgent need for optimizing such integrated energy systems. In this paper, a
simulation-based method is adopted and improved, in order to compare different
battery types based on their characteristics by considering projected trends in
the future. After the introduction of four different battery types, i.e.
lead-acid, sodium sulphur, vanadium redox and lithium-ion, the mathematical
model for the optimization problem is presented, along with the required
explanations. Subsequently, a case study is described and the numerical
assumptions are defined. Therein, our specific focus addresses the different
values that the four battery types possess in three critical parameters, i.e.
battery cost, efficiency and depth of discharge (DoD). Finally, results and
discussion are provided in an illustrative and informative way. This model
provides a useful guide for relevant future work in the area, and also serves
as a baseline for more comprehensive methodologies regarding optimal sizing of
photovoltaic and battery systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11395</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11395</id><created>2019-01-28</created><updated>2019-08-25</updated><authors><author><keyname>Kovach</keyname><forenames>Christopher K.</forenames></author><author><keyname>Howard</keyname><forenames>Matthew A.</forenames><suffix>III</suffix></author></authors><title>Decomposition of Higher-Order Spectra for Blind Multiple-Input
  Deconvolution, Pattern Identification and Separation</title><categories>eess.SP q-bio.QM stat.AP</categories><comments>published, open access version</comments><doi>10.1016/j.sigpro.2019.07.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Like the ordinary power spectrum, higher-order spectra (HOS) describe signal
properties that are invariant under translations in time. Unlike the power
spectrum, HOS retain phase information from which details of the signal
waveform can be recovered. Here we consider the problem of identifying multiple
unknown transient waveforms which recur within an ensemble of records at
mutually random delays. We develop a new technique for recovering filters from
HOS whose performance in waveform detection approaches that of an optimal
matched filter, requiring no prior information about the waveforms. Unlike
previous techniques of signal identification through HOS, the method applies
equally well to signals with deterministic and non-deterministic HOS. In the
non-deterministic case, it yields an additive decomposition, introducing a new
approach to the separation of component processes within non-Gaussian signals
having non-deterministic higher moments. We show a close relationship to
minimum-entropy blind deconvolution (MED), which the present technique improves
upon by avoiding the need for numerical optimization, while requiring only
numerically stable operations of time shift, element-wise multiplication and
averaging, making it particularly suited for real-time applications. The
application of HOS decomposition to real-world signals is demonstrated with
blind denoising, detection and classification of normal and abnormal heartbeats
in electrocardiograms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11404</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11404</id><created>2019-01-30</created><authors><author><keyname>Shehata</keyname><forenames>Mohamed</forenames><affiliation>INSA Rennes</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Maryline</forenames><affiliation>IETR</affiliation></author></authors><title>On the Theoretical Limits of Beam Steering in mmWave Massive MIMO
  Channels</title><categories>eess.SP</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analog Beamsteering (ABS) has emerged as a low complexity, power efficient
solution for MillimeterWave (mmWave) massive Multiple Input Multiple Output
(MIMO) systems. Moreover, driven by the low spatial correlation between the
User Terminals (UTs) with high number of transmit antennas (massive MIMO) at
the Base Station (BS), ABS can be used to support Multi User (MU) MIMO
scenarios instead of digital or Hybrid Beamforming (HBF). However, we show in
this paper, that even with high number of transmit antennas, the HBF can
achieve better Spectral Efficiency (SE) compared to the MU ABS even in pure
Line of Sight (LoS) channels. Moreover, we prove that the MU ABS saturates to a
constant SE at high transmit Signal to Noise Ratio (SNR) and we theoretically
derive an approximation to that saturation bound in this paper. On the other
hand, we highlight that the HBF's SE scales with the transmit SNR even in high
SNR regime. Finally, given the same power consumption and hardware complexity
as the MU ABS case, we show that HBF asymptotically achieves the optimal SE
(ideal non interference scenario) when increasing the number of transmit
antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11405</identifier>
 <datestamp>2019-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11405</id><created>2019-01-30</created><updated>2019-04-27</updated><authors><author><keyname>Wei</keyname><forenames>Zhuangkun</forenames></author><author><keyname>Li</keyname><forenames>Bin</forenames></author><author><keyname>Guo</keyname><forenames>Weisi</forenames></author></authors><title>Optimal Sampling for Dynamic Complex Networks with Graph-Bandlimited
  Initialization</title><categories>eess.SP</categories><comments>under review at IEEE (version 2.5)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many engineering, social, and biological complex systems consist of dynamical
elements connected via a large-scale network. Monitoring the network's dynamics
is essential for a variety of maintenance and scientific purposes. Whilst we
understand how to optimally sample a single dynamic element or a non-dynamic
graph, we do not possess a theory on how to optimally sample networked
dynamical elements. Here, we study nonlinear dynamic graph signals on a fixed
complex network. We define the necessary conditions for optimal sampling in the
combining time- and graph-domain to fully recover the networked dynamics. We
firstly interpret the networked dynamics into a linearized matrix. Then, we
prove that the dynamic signals can be sampled and fully recovered if the
networked dynamics is stable and their initialization is bandlimited in the
graph spectral domain. This new theory directly maps optimal sampling locations
and rates to the graph properties and governing nonlinear dynamics. This can
inform the optimal placement of experimental probes and sensors on dynamical
networks as well as inform the design of each sensor's optimal sampling rate.
We motivate the reader with two examples of recovering the networked dynamics
for: social population growth and networked protein biochemical interactions
with both bandlimited and arbitrary initialization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11417</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11417</id><created>2019-01-31</created><updated>2019-10-27</updated><authors><author><keyname>Michaelides</keyname><forenames>Michalis</forenames></author><author><keyname>Hillston</keyname><forenames>Jane</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Guido</forenames></author></authors><title>Geometric fluid approximation for general continuous-time Markov chains</title><categories>eess.SY cs.SY stat.ML</categories><journal-ref>Proc. R. Soc. A 475:2229 (2019)</journal-ref><doi>10.1098/rspa.2019.0100</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluid approximations have seen great success in approximating the macro-scale
behaviour of Markov systems with a large number of discrete states. However,
these methods rely on the continuous-time Markov chain (CTMC) having a
particular population structure which suggests a natural continuous state-space
endowed with a dynamics for the approximating process. We construct here a
general method based on spectral analysis of the transition matrix of the CTMC,
without the need for a population structure. Specifically, we use the popular
manifold learning method of diffusion maps to analyse the transition matrix as
the operator of a hidden continuous process. An embedding of states in a
continuous space is recovered, and the space is endowed with a drift vector
field inferred via Gaussian process regression. In this manner, we construct an
ODE whose solution approximates the evolution of the CTMC mean, mapped onto the
continuous space (known as the fluid limit).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11418</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11418</id><created>2019-01-31</created><authors><author><keyname>Wei</keyname><forenames>Zhuangkun</forenames></author><author><keyname>Li</keyname><forenames>Bin</forenames></author><author><keyname>Guo</keyname><forenames>Weisi</forenames></author><author><keyname>Hu</keyname><forenames>Wenxiu</forenames></author><author><keyname>Zhao</keyname><forenames>Chenglin</forenames></author></authors><title>Sequential Bayesian Detection of Spike Activities from Fluorescence
  Observations</title><categories>q-bio.NC cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extracting and detecting spike activities from the fluorescence observations
is an important step in understanding how neuron systems work. The main
challenge lies in that the combination of the ambient noise with dynamic
baseline fluctuation, often contaminates the observations, thereby
deteriorating the reliability of spike detection. This may be even worse in the
face of the nonlinear biological process, the coupling interactions between
spikes and baseline, and the unknown critical parameters of an underlying
physiological model, in which erroneous estimations of parameters will affect
the detection of spikes causing further error propagation. In this paper, we
propose a random finite set (RFS) based Bayesian approach. The dynamic
behaviors of spike sequence, fluctuated baseline and unknown parameters are
formulated as one RFS. This RFS state is capable of distinguishing the hidden
active/silent states induced by spike and non-spike activities respectively,
thereby \emph{negating the interaction role} played by spikes and other
factors. Then, premised on the RFS states, a Bayesian inference scheme is
designed to simultaneously estimate the model parameters, baseline, and crucial
spike activities. Our results demonstrate that the proposed scheme can gain an
extra $12\%$ detection accuracy in comparison with the state-of-the-art MLSpike
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11423</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11423</id><created>2019-01-31</created><authors><author><keyname>Meng</keyname><forenames>Xiangyu</forenames></author><author><keyname>Cassandras</keyname><forenames>Christos G.</forenames></author></authors><title>A Real-Time Optimal Eco-driving for Autonomous Vehicles Crossing
  Multiple Signalized Intersections</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops an optimal acceleration/speed profile for a single
autonomous vehicle crossing multiple signalized intersections without stopping
in free flow mode. The design objective is to produce both time and energy
efficient acceleration profiles of autonomous vehicles based on vehicle to
infrastructure communication. Our design approach differs from most existing
approaches based on numerical calculations: it begins with identifying the
structure of the optimal acceleration profile and then showing that it is
characterized by several parameters, which are used for design optimization.
Therefore, the infinite dimensional optimal control problem is transformed into
a finite dimensional parametric optimization problem, which enables a real-time
online analytical solution. The simulation results show quantitatively the
advantages of considering multiple intersections jointly rather than dealing
with them individually. Based on mild assumptions, the optimal eco-driving
algorithm is readily extended to include interfering traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11436</identifier>
 <datestamp>2019-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11436</id><created>2019-01-31</created><updated>2019-04-27</updated><authors><author><keyname>Wilkinson</keyname><forenames>William J.</forenames></author><author><keyname>Andersen</keyname><forenames>Michael Riis</forenames></author><author><keyname>Reiss</keyname><forenames>Joshua D.</forenames></author><author><keyname>Stowell</keyname><forenames>Dan</forenames></author><author><keyname>Solin</keyname><forenames>Arno</forenames></author></authors><title>End-to-End Probabilistic Inference for Nonstationary Audio Analysis</title><categories>stat.ML cs.LG cs.SD eess.AS eess.SP</categories><comments>Accepted to the Thirty-sixth International Conference on Machine
  Learning (ICML) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A typical audio signal processing pipeline includes multiple disjoint
analysis stages, including calculation of a time-frequency representation
followed by spectrogram-based feature analysis. We show how time-frequency
analysis and nonnegative matrix factorisation can be jointly formulated as a
spectral mixture Gaussian process model with nonstationary priors over the
amplitude variance parameters. Further, we formulate this nonlinear model's
state space representation, making it amenable to infinite-horizon Gaussian
process regression with approximate inference via expectation propagation,
which scales linearly in the number of time steps and quadratically in the
state dimensionality. By doing so, we are able to process audio signals with
hundreds of thousands of data points. We demonstrate, on various tasks with
empirical data, how this inference scheme outperforms more standard techniques
that rely on extended Kalman filtering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11452</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11452</id><created>2019-01-31</created><updated>2019-05-30</updated><authors><author><keyname>Leshem</keyname><forenames>Amir</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author></authors><title>The Interference Channel Revisited: Aligning Interference by Adjusting
  Receive Antenna Separation</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that a receiver equipped with two antennas may null an arbitrary
large number of spatial directions to any desired accuracy, while maintaining
the interference-free signal-to-noise ratio, by judiciously adjusting the
distance between the antenna elements. The main theoretical result builds on
ergodic theory. The practicality of the scheme in moderate signal-to-noise
systems is demonstrated for a scenario where each transmitter is equipped with
a single antenna and each receiver has two receive chains and where the desired
spacing between antenna elements is achieved by selecting the appropriate
antennas from a large linear antenna array. We further extend the proposed
scheme to show that interference can be eliminated also in specular multipath
channels as well as multiple-input multiple-output interference channels where
a single extra receiver suffices to align all interferers into a
one-dimensional subspace. To demonstrate the performance of the scheme, we show
significant gains for interference channels with four as well as six users, at
low to moderate signal-to-noise ratios (0-20 dB). The robustness of the
proposed technique to small channel estimation errors is also explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11474</identifier>
 <datestamp>2019-12-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11474</id><created>2019-01-31</created><authors><author><keyname>Hamza</keyname><forenames>Syed A.</forenames></author><author><keyname>Amin</keyname><forenames>Moeness G.</forenames></author></authors><title>Sparse Array DFT Beamformers for Wideband Sources</title><categories>eess.SP</categories><journal-ref>2019 IEEE Radar Conference (RadarConf)</journal-ref><doi>10.1109/RADAR.2019.8835749</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse arrays are popular for performance optimization while keeping the
hardware and computational costs down. In this paper, we consider sparse arrays
design method for wideband source operating in a wideband jamming environment.
Maximizing the signal-to-interference plus noise ratio (MaxSINR) is adopted as
an optimization objective for wideband beamforming. Sparse array design problem
is formulated in the DFT domain to process the source as parallel narrowband
sources. The problem is formulated as quadratically constraint quadratic
program (QCQP) alongside the weighted mixed $l_{1-\infty}$-norm squared
penalization of the beamformer weight vector. The semidefinite relaxation (SDR)
of QCQP promotes sparse solutions by iteratively re-weighting beamformer based
on previous iteration. It is shown that the DFT approach reduces the
computational cost considerably as compared to the delay line approach, while
efficiently utilizing the degrees of freedom to harness the maximum output SINR
offered by the given array aperture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.11502</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1901.11502</id><created>2019-01-31</created><updated>2019-02-02</updated><authors><author><keyname>Hoeher</keyname><forenames>Peter A.</forenames></author></authors><title>FSK-based Simultaneous Wireless Information and Power Transfer in
  Inductively Coupled Resonant Circuits Exploiting Frequency Splitting</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inductively coupled resonant circuits are affected by the so-called frequency
splitting phenomenon at short distances. In the area of power electronics,
tracking of one of the peak frequencies is state-of-the-art. In the data
transmission community, however, the frequency splitting effect is often
ignored. Particularly, modulation schemes have not yet been adapted to the
bifurcation phenomenon. We argue that binary frequency shift keying (2-ary FSK)
is a low-cost modulation scheme which well matches the double-peak voltage
transfer function $H(s)$, particularly when the quality factor $Q$ is large,
whereas most other modulation schemes suffer from the small bandwidths of the
peaks. Additionally we show that a rectified version of 2-ary FSK, coined
rectified FSK (RFSK), is even more attractive from output power and
implementation points of view. Analytical and numerical contributions include
the efficiency factor, the impulse response, and the bit error performance. A
low-cost incoherent receiver is proposed. Theoretical examinations are
supported by an experimental prototype.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00009</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00009</id><created>2019-01-31</created><updated>2019-11-15</updated><authors><author><keyname>Varga</keyname><forenames>Andreas</forenames></author></authors><title>Descriptor system techniques and software tools</title><categories>eess.SY cs.SY</categories><comments>11 pages. A shorter version of this article appeared in the
  Encyclopedia of Systems and Control (2019). arXiv admin note: text overlap
  with arXiv:1707.07140</comments><msc-class>34A09, 93C, 93B20, 93B40, 93C05, 93D20</msc-class><doi>10.1007/978-1-4471-5102-9_100054-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The role of the descriptor system representation as basis for reliable
numerical computations for system analysis and synthesis, and in particular,
for the manipulation of rational matrices, is discussed and available robust
numerical software tools are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00052</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00052</id><created>2018-12-21</created><authors><author><keyname>Alhilal</keyname><forenames>Ahmad</forenames></author><author><keyname>Dowaji</keyname><forenames>Salah</forenames></author></authors><title>Base Station Distance Adaptive LEACH</title><categories>cs.DC eess.SP</categories><comments>11 pages, in Arabic, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For some applications, we need to deploy a network of sensors in working
field to sense the environment and send collected data to a base station for
processing; these sensors depend on non-rechargeable batteries, so the routing
protocols for such network of sensors need to be efficient. LEACH is one of
these protocols which is a hierarchical routing protocol and helps in saving
energy in wireless sensor networks. Enhanced LEACH depends on a mathematical
model to calculate the estimated average energy in each round. consequently,
utilizing the node remaining energy to ensure rotating cluster head role over
all the nodes. It also depends on a mathematical model to calculate base
station distance from work field whereas LEACH does not take into its account
any consideration for remaining energy of node. In this paper, we enhance LEACH
(work efficiency in homogeneous networks) to adapt with base-station distance,
thus more energy saving for certain distances from base-station. The obtained
simulation results show that enhanced LEACH saves energy better than LEACH and
increase network stability and reliability when base-station is inside working
field and consume the same energy as LEACH when base-station is outside work
field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00061</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00061</id><created>2019-01-31</created><updated>2019-02-17</updated><authors><author><keyname>Francis</keyname><forenames>Bibin</forenames></author><author><keyname>Mathew</keyname><forenames>Manoj</forenames></author><author><keyname>Arigovindan</keyname><forenames>Muthuvel</forenames></author></authors><title>Image Reconstruction from Undersampled Confocal Microscopy Data using
  Multiresolution Based Maximum Entropy Regularization</title><categories>eess.IV</categories><doi>10.1088/1748-0221/14/07/P07015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of reconstructing 2D images from randomly
under-sampled confocal microscopy samples. The well known and widely celebrated
total variation regularization, which is the L1 norm of derivatives, turns out
to be unsuitable for this problem; it is unable to handle both noise and
under-sampling together. This issue is linked with the notion of phase
transition phenomenon observed in compressive sensing research, which is
essentially the break-down of total variation methods, when sampling density
gets lower than certain threshold. The severity of this breakdown is determined
by the so-called mutual incoherence between the derivative operators and
measurement operator. In our problem, the mutual incoherence is low, and hence
the total variation regularization gives serious artifacts in the presence of
noise even when the sampling density is not very low. There has been very few
attempts in developing regularization methods that perform better than total
variation regularization for this problem. We develop a multi-resolution based
regularization method that is adaptive to image structure. In our approach, the
desired reconstruction is formulated as a series of coarse-to-fine
multi-resolution reconstructions; for reconstruction at each level, the
regularization is constructed to be adaptive to the image structure, where the
information for adaption is obtained from the reconstruction obtained at
coarser resolution level. This adaptation is achieved by using maximum entropy
principle, where the required adaptive regularization is determined as the
maximizer of entropy subject to the information extracted from the coarse
reconstruction as constraints. We demonstrate the superiority of the proposed
regularization method over existing ones using several reconstruction examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00075</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00075</id><created>2019-01-31</created><authors><author><keyname>Srinivasa</keyname><forenames>Rakshith Sharma</forenames></author><author><keyname>Davenport</keyname><forenames>Mark A.</forenames></author><author><keyname>Romberg</keyname><forenames>Justin</forenames></author></authors><title>Trading beams for bandwidth: Imaging with randomized beamforming</title><categories>eess.SP eess.IV stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of actively imaging a range-limited far-field scene
using an antenna array. We describe how the range limit imposes structure in
the measurements across multiple wavelengths. This structure allows us to
introduce a novel trade-off: the number of spatial array measurements (i.e.,
beams that have to be formed) can be reduced significantly lower than the
number array elements if the scene is illuminated with a broadband source. To
take advantage of this trade-off, we use a small number of &quot;generic&quot; linear
combinations of the array outputs, instead of the phase offsets used in
conventional beamforming. We provide theoretical justification for the proposed
trade-off without making any strong structural assumptions on the target scene
(such as sparsity) except that it is range limited. In proving our theoretical
results, we take inspiration from the sketching literature. We also provide
simulation results to establish the merit of the proposed signal acquisition
strategy. Our proposed method results in a reduction in the number of required
spatial measurements in an array imaging system and hence can directly impact
their speed and cost of operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00092</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00092</id><created>2019-01-31</created><authors><author><keyname>Churchill</keyname><forenames>Victor</forenames></author><author><keyname>Gelb</keyname><forenames>Anne</forenames></author></authors><title>Image reconstruction enhancement via masked regularization</title><categories>eess.IV</categories><msc-class>94A08, 65F22, 68U10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image reconstruction based on an edge-sparsity assumption has become popular
in recent years. Many methods of this type are capable of reconstructing nearly
perfect edge-sparse images using limited data. In this paper, we present a
method to improve the accuracy of a suboptimal image resulting from an
edge-sparsity image reconstruction method when compressed sensing or empirical
data requirements are not met. The method begins with an edge detection from an
initial edge-sparsity based reconstruction. From this edge map, a mask matrix
is created which allows us to regularize exclusively in regions away from
edges. By accounting for the spatial distribution of the sparsity, our method
preserves edge information and and furthermore enhances suboptimal
reconstructions to be nearly perfect from fewer data than needed by the initial
method. We present results for two phantom images using a variety of initial
reconstruction methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00149</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00149</id><created>2019-01-31</created><authors><author><keyname>Shimly</keyname><forenames>Samiya M.</forenames></author><author><keyname>Smith</keyname><forenames>David B.</forenames></author></authors><title>Towards Smart Wireless Body-Centric Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the existence of 'long-memory' or long-range dependence (LRD)
of the wireless body-centric channels, e.g., on-body, body-to-body (B2B), with
real-life experimental dataset collected from 10 co-located wireless body area
networks or BANs (people fitted with wearable sensors). We examine two
different factors on that purpose such as: the pattern of the decaying
autocorrelation function (ACF) and the Hurst exponent. From the experimental
outcome, we show that, the ACF decay of the body-centric channels follows a
power-like decay and the channels have a Hurst exponent much greater than 0.5
on average. These results indicate that the body-centric channels can possess
long-memory or LRD characteristic which can be used for predictive analysis and
intelligent decision making to build futuristic wireless human-centered
networks that can sense and act autonomously. We also clarify whether the
presence of the LRD property is sufficient for reliable prediction of the
body-centric channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00166</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00166</id><created>2019-01-31</created><updated>2019-05-06</updated><authors><author><keyname>Wang</keyname><forenames>Jie</forenames></author><author><keyname>Batabyal</keyname><forenames>Tamal</forenames></author><author><keyname>Zhang</keyname><forenames>Mingxing</forenames></author><author><keyname>Zhang</keyname><forenames>Ji</forenames></author><author><keyname>Aziz</keyname><forenames>Arslan</forenames></author><author><keyname>Gahlmann</keyname><forenames>Andreas</forenames></author><author><keyname>Acton</keyname><forenames>Scott T.</forenames></author></authors><title>LCuts: Linear Clustering of Bacteria using Recursive Graph Cuts</title><categories>eess.IV</categories><comments>v1: Submitted to IEEE International Conference on Image Processing
  (ICIP) 2019; v2: Minor edits, updated reference and co-authors; v3: Accepted
  to be published in 2019 IEEE International Conference on Image Processing,
  Sep 22-25, 2019, Taipei. IEEE Copyright notice added. Minor changes for
  camera-ready version. (updated May. 6, 2019)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bacterial biofilm segmentation poses significant challenges due to lack of
apparent structure, poor imaging resolution, limited contrast between
conterminous cells and high density of cells that overlap. Although there exist
bacterial segmentation algorithms in the existing art, they fail to delineate
cells in dense biofilms, especially in 3D imaging scenarios in which the cells
are growing and subdividing in a complex manner. A graph-based data clustering
method, LCuts, is presented with the application on bacterial cell
segmentation. By constructing a weighted graph with node features in locations
and principal orientations, the proposed method can automatically classify and
detect differently oriented aggregations of linear structures (represent by
bacteria in the application). The method assists in the assessment of several
facets, such as bacterium tracking, cluster growth, and mapping of migration
patterns of bacterial biofilms. Quantitative and qualitative measures for 2D
data demonstrate the superiority of proposed method over the state of the art.
Preliminary 3D results exhibit reliable classification of the cells with 97%
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00226</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00226</id><created>2019-02-01</created><updated>2019-10-08</updated><authors><author><keyname>Li</keyname><forenames>Peng</forenames></author></authors><title>An Estimation Algorithm of Extended Kalman Filter based on improved
  Thevenin Model for the management of Lithium Battery System</title><categories>eess.SP nlin.AO</categories><comments>Because of the author's inexperience (the first time) when this
  article was uploaded, due to the problems of document management software,
  the contents of other authors in the reference were mistakenly uploaded to
  the article. Although no comments were received, the author still asked to
  withdraw this article and sincerely apologized</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We proposed a new estimation algorithm of extended Kalman filter (EKF) based
on improved Thevenin model; Experiments were carried out to verify the validity
with seven 4Ah lithium cobalt acid batteries in series. The experimental
results showed that when using the algorithm, the estimation error of SOC is in
the scope of error allowed, and the requirement of online SOC estimation can be
satisfied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00233</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00233</id><created>2019-02-01</created><authors><author><keyname>Ayesh</keyname><forenames>Mostafa</forenames></author><author><keyname>Ibrahim</keyname><forenames>Sameh</forenames></author><author><keyname>Aboudina</keyname><forenames>Mohamed M.</forenames></author></authors><title>A Low-Power 20-Gb/s Discrete-Time Analog Front-End for ADC-Based Serial
  Link Equalizers</title><categories>eess.SP</categories><comments>9 pages, Journal, 5 Tables, 19 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a discrete-time analog frontend for an analog-to-digital
(ADC) based equalizers. The frontend uses a discrete-time linear equalizer
(DTLE) and ultralow-power 4-bit time-interleaved charge-steering flash ADC. The
DTLE serves two functions; linear equalization and sampling and holding for the
following charge-steering ADC. The ADC uses fully differential low-power
clocked comparators. Low power in the comparators is achieved by embedding a
dynamic latch into the core of a charge-steering pre-amplifier. The 20-Gb/s
front-end is designed and simulated in 65-nm CMOS technology. The flash ADC
uses 4-stage interleaving and thus requires 4 DTLEs running at 5 Gb/s. A 5-Gb/s
DTLE consumes 0.57 mW from a 1.2-V supply and the ADC consumes 15.5 mW from a
1-V supply at 20 GS/s for a total power dissipation of 17.78 mW or 0.89 pJ/bit.
The ADC has an SNDR of 23.9 dB, an SFDR of 33.6 dB, and an effective number of
bits (ENOB) of 3.67 bits for a sinusoidal input of frequency 9.84 GHz and
amplitude 600 mVdiff .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00341</identifier>
 <datestamp>2019-04-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00341</id><created>2019-02-01</created><updated>2019-03-29</updated><authors><author><keyname>Parthasarathy</keyname><forenames>Gayatri</forenames></author><author><keyname>Abhilash</keyname><forenames>G.</forenames></author></authors><title>Entropy-Based Learning of Sensing Matrices</title><categories>eess.SP</categories><comments>This paper is a preprint of a paper submitted to IET Signal
  Processing. If accepted, the copy of record will be available at the IET
  Digital Library</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a learning method to construct an efficient sensing
(measurement) matrix, having orthogonal rows, for compressed sensing of a class
of signals. The learning scheme identifies the sensing matrix by maximizing the
entropy of measurement vectors. The bounds on the entropy of the measurement
vector necessary for the unique recovery of a signal are also proposed. A
comparison of the performance of the designed sensing matrix and the sensing
matrices constructed using other existing methods is also presented. The
simulation results on the recovery of synthetic, speech, and image signals,
compressively sensed using the sensing matrix identified, shows an improvement
in the accuracy of recovery. The reconstruction quality is better, using less
number of measurements, than those measured using sensing matrices identified
by other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00347</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00347</id><created>2019-02-01</created><updated>2019-08-05</updated><authors><author><keyname>Angermann</keyname><forenames>Christoph</forenames></author><author><keyname>Haltmeier</keyname><forenames>Markus</forenames></author><author><keyname>Steiger</keyname><forenames>Ruth</forenames></author><author><keyname>Pereverzyev</keyname><forenames>Sergiy</forenames><suffix>Jr</suffix></author><author><keyname>Gizewski</keyname><forenames>Elke</forenames></author></authors><title>Projection-Based 2.5D U-net Architecture for Fast Volumetric
  Segmentation</title><categories>cs.CV eess.IV</categories><comments>presented at the SAMPTA 2019 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks are state-of-the-art for various segmentation
tasks. While for 2D images these networks are also computationally efficient,
3D convolutions have huge storage requirements and require long training time.
To overcome this issue, we introduce a network structure for volumetric data
without 3D convolutional layers. The main idea is to include maximum intensity
projections from different directions to transform the volumetric data to a
sequence of images, where each image contains information of the full data. We
then apply 2D convolutions to these projection images and lift them again to
volumetric data using a trainable reconstruction algorithm.The proposed network
architecture has less storage requirements than network structures using 3D
convolutions. For a tested binary segmentation task, it even shows better
performance than the 3D U-net and can be trained much faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00364</identifier>
 <datestamp>2019-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00364</id><created>2019-01-31</created><updated>2019-02-27</updated><authors><author><keyname>Paganin</keyname><forenames>David M.</forenames></author><author><keyname>Pelliccia</keyname><forenames>Daniele</forenames></author></authors><title>Tutorials on X-ray Phase Contrast Imaging: Some Fundamentals and Some
  Conjectures on Future Developments</title><categories>eess.IV physics.optics</categories><comments>This tutorial was presented as three two-hour seminars, delivered to
  the European Synchrotron (ESRF) community, on May 31 - June 2, 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These tutorials introduce some basics of imaging with coherent X-rays,
focusing on phase contrast. We consider the transport-of-intensity equation, as
one particular method for X-ray phase contrast imaging among many, before
passing on to the inverse problem of phase retrieval. These ideas are applied
to two-dimensional and three-dimensional propagation-based phase-contrast
imaging using coherent X-rays. We then consider the role of partial coherence,
and sketch a generic means by which partially coherent X-ray imaging scenarios
may be modelled, using the space-frequency description of partial coherence.
Besides covering fundamental concepts in both theory and practice, we also give
opinions on future trends in X-ray phase contrast imaging including X-ray
tomography, and comparison of different phase contrast imaging methods. These
tutorials will be accessible to those with a basic background in optics (e.g.
wave equation, Maxwell equations, Fresnel and Fraunhofer diffraction, and the
basics of Fourier and vector analysis) and interactions of X-rays with matter
(e.g. attenuation mechanisms and complex refractive index).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00379</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00379</id><created>2019-01-31</created><updated>2019-07-29</updated><authors><author><keyname>Zhu</keyname><forenames>Lei</forenames></author><author><keyname>Wu</keyname><forenames>Yuxiang</forenames></author><author><keyname>Liu</keyname><forenames>Jietao</forenames></author><author><keyname>Wu</keyname><forenames>Tengfei</forenames></author><author><keyname>Liu</keyname><forenames>Lixian</forenames></author><author><keyname>Shao</keyname><forenames>Xiaopeng</forenames></author></authors><title>Color imaging through the scattering media based on phase retrieval with
  triple correlation</title><categories>eess.IV</categories><comments>4 pages,11 figures</comments><journal-ref>Optics and Lasers in Engineering 124 (2020) 105796</journal-ref><doi>10.1016/j.optlaseng.2019.105796</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Light passing through scattering media will be strongly scattered and
diffused into complex speckle pattern, which however contains almost all the
spatial information and color information of the objects. Although various
technologies have been proposed to realize color imaging through the scattering
media, current technologies are still complex with long sequence of measurement
for each imaging pixel or spectral point spread functions of optical system.
Here we theoretically prove the spatial averaging of triple correlation
technique can be used to retrieve the Fourier phase of object, and
experimentally demonstrate it can be applied in color imaging through
scattering media. Compared to other phase retrieval techniques, the phase
retrieval with triple correlation technique can retain the orientation
information of objects, and can composite color image without rotation
operation. Furthermore, our approach has the potential of realizing spectral
imaging through scattering media.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00386</identifier>
 <datestamp>2019-10-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00386</id><created>2019-02-01</created><updated>2019-10-18</updated><authors><author><keyname>Sanchez</keyname><forenames>Thomas</forenames></author><author><keyname>G&#xf6;zc&#xfc;</keyname><forenames>Baran</forenames></author><author><keyname>van Heeswijk</keyname><forenames>Ruud B.</forenames></author><author><keyname>Eftekhari</keyname><forenames>Armin</forenames></author><author><keyname>Il&#x131;cak</keyname><forenames>Efe</forenames></author><author><keyname>&#xc7;ukur</keyname><forenames>Tolga</forenames></author><author><keyname>Cevher</keyname><forenames>Volkan</forenames></author></authors><title>Scalable Learning-Based Sampling Optimization for Compressive Dynamic
  MRI</title><categories>eess.IV cs.CV</categories><comments>12 pages, Submitted to the session &quot;Learning and Optimization in
  Non-Convex Environments&quot; of ICASSP 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing applied to magnetic resonance imaging (MRI) allows to
reduce the scanning time by enabling images to be reconstructed from highly
undersampled data. In this paper, we tackle the problem of designing a sampling
mask for an arbitrary reconstruction method and a limited acquisition budget.
Namely, we look for an optimal probability distribution from which a mask with
a fixed cardinality is drawn. We demonstrate that this problem admits a
compactly supported solution, which leads to a deterministic optimal sampling
mask. We then propose a stochastic greedy algorithm that (i) provides an
approximate solution to this problem, and (ii) resolves the scaling issues of
[1,2]. We validate its performance on in vivo dynamic MRI with retrospective
undersampling, showing that our method preserves the performance of [1,2] while
reducing the computational burden by a factor close to 200.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00469</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00469</id><created>2019-02-01</created><authors><author><keyname>Bahou</keyname><forenames>Andrawes Al</forenames></author><author><keyname>Tanner</keyname><forenames>Christine</forenames></author><author><keyname>Goksel</keyname><forenames>Orcun</forenames></author></authors><title>SCATGAN for Reconstruction of Ultrasound Scatterers Using Generative
  Adversarial Networks</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational simulation of ultrasound (US) echography is essential for
training sonographers. Realistic simulation of US interaction with microscopic
tissue structures is often modeled by a tissue representation in the form of
point scatterers, convolved with a spatially varying point spread function.
This yields a realistic US B-mode speckle texture, given that a scatterer
representation for a particular tissue type is readily available. This is often
not the case and scatterers are nontrivial to determine. In this work we
propose to estimate scatterer maps from sample US B-mode images of a tissue, by
formulating this inverse mapping problem as image translation, where we learn
the mapping with Generative Adversarial Networks, using a US simulation
software for training. We demonstrate robust reconstruction results, invariant
to US viewing and imaging settings such as imaging direction and center
frequency. Our method is shown to generalize beyond the trained imaging
settings, demonstrated on in-vivo US data. Our inference runs orders of
magnitude faster than optimization-based techniques, enabling future extensions
for reconstructing 3D B-mode volumes with only linear computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00479</identifier>
 <datestamp>2019-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00479</id><created>2019-02-01</created><authors><author><keyname>Sluzewski</keyname><forenames>M. Filip</forenames></author><author><keyname>Tvrdik</keyname><forenames>Petr</forenames></author><author><keyname>Acton</keyname><forenames>Scott T.</forenames></author></authors><title>Segmentation of Cortical Spreading Depression Wavefronts Through Local
  Similarity Metric</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel region-based segmentation method for
cortical spreading depressions in 2-photon microscopy images. Fluorescent
microscopy has become an important tool in neuroscience, but segmentation
approaches are challenged by the opaque properties and structures of brain
tissue. These challenges are made more extreme when segmenting events such as
cortical spreading depressions, where low signal-to-noise ratios and intensity
inhomogeneity dominate images. The method we propose uses a local intensity
similarity measure that takes advantage of normalized Euclidean and geodesic
distance maps of the image. This method provides a smooth segmentation boundary
which is robust to the noise and inhomogeneity within cortical spreading
depression images. Experimental results yielded a DICE index of 0.9859, an
increase of 6% over the current state-of-the-art, and a reduction of root mean
square error by 79.9%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00539</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00539</id><created>2019-02-01</created><authors><author><keyname>Yu</keyname><forenames>Chin-Yun</forenames></author><author><keyname>Su</keyname><forenames>Li</forenames></author></authors><title>Multi-layered Cepstrum for Instantaneous Frequency Estimation</title><categories>eess.AS cs.SD eess.SP</categories><comments>In 2018 6th IEEE Global Conference on Signal and Information
  Processing</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We propose the multi-layered cepstrum (MLC) method to estimate multiple
fundamental frequencies (MF0) of a signal under challenging contamination such
as high-pass filter noise. Taking the operation of cepstrum (i.e., Fourier
transform, filtering, and nonlinear activation) recursively, MLC is shown as an
efficient method to enhance MF0 saliency in a step-by-step manner. Evaluation
on a real-world polyphonic music dataset under both normal and low-fidelity
conditions demonstrates the potential of MLC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00570</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00570</id><created>2019-02-01</created><authors><author><keyname>Norouzian</keyname><forenames>Atta</forenames></author><author><keyname>Mazoure</keyname><forenames>Bogdan</forenames></author><author><keyname>Connolly</keyname><forenames>Dermot</forenames></author><author><keyname>Willett</keyname><forenames>Daniel</forenames></author></authors><title>Exploring attention mechanism for acoustic-based classification of
  speech utterances into system-directed and non-system-directed</title><categories>cs.HC cs.CL eess.AS</categories><comments>Accpeted for presentation at ICASSP2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice controlled virtual assistants (VAs) are now available in smartphones,
cars, and standalone devices in homes. In most cases, the user needs to first
&quot;wake-up&quot; the VA by saying a particular word/phrase every time he or she wants
the VA to do something. Eliminating the need for saying the wake-up word for
every interaction could improve the user experience. This would require the VA
to have the capability to detect the speech that is being directed at it and
respond accordingly. In other words, the challenge is to distinguish between
system-directed and non-system-directed speech utterances. In this paper, we
present a number of neural network architectures for tackling this
classification problem based on using only acoustic features. These
architectures are based on using convolutional, recurrent and feed-forward
layers. In addition, we investigate the use of an attention mechanism applied
to the output of the convolutional and the recurrent layers. It is shown that
incorporating the proposed attention mechanism into the models always leads to
significant improvement in classification accuracy. The best model achieved
equal error rates of 16.25 and 15.62 percents on two distinct realistic
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00573</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00573</id><created>2019-02-01</created><authors><author><keyname>Alfarraj</keyname><forenames>Motaz</forenames></author><author><keyname>Di</keyname><forenames>Haibin</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Multiscale Fusion for Seismic Geometric Attribute Enhancement</title><categories>eess.IV physics.geo-ph</categories><comments>Published in SEG Technical Program Expanded Abstracts 2017</comments><doi>10.1190/segam2017-17750698.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this abstract, we propose a multiscale fusion technique to enhance seismic
geometric attributes, such as dip and curvature, which are very sensitive to
noise present in seismic data. For a give seismic section, first, we construct
a Gaussian pyramid that allows us to generate the seismic attribute at
different resolutions (scales). Then, all attributes at the different scales
are fused together to form the proposed multiscale enhanced attribute.
Applications to the 3D seismic dataset over the Great South Basin in New
Zealand demonstrate that the proposed method is capable of improving both the
resolution and noise robustness of the first-order dip and the second-order
curvature attributes, compared to existing methods and algorithm. Such
improvement indicates the great potential of our multiscale fusion technique
for enhancing the quality of more multitrace seismic attributes, such as
coherence, flexure, and GLCM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00608</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00608</id><created>2019-02-01</created><authors><author><keyname>Defazio</keyname><forenames>Aaron</forenames></author><author><keyname>Tygert</keyname><forenames>Mark</forenames></author></authors><title>Methods of interpreting error estimates for grayscale image
  reconstructions</title><categories>stat.CO eess.IV</categories><comments>23 pages, 16 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One representation of possible errors in a grayscale image reconstruction is
as another grayscale image estimating potentially worrisome differences between
the reconstruction and the actual &quot;ground-truth&quot; reality. Visualizations and
summary statistics can aid in the interpretation of such a representation of
error estimates. Visualizations include suitable colorizations of the
reconstruction, as well as the obvious &quot;correction&quot; of the reconstruction by
subtracting off the error estimates. The canonical summary statistic would be
the root-mean-square of the error estimates. Numerical examples involving
cranial magnetic-resonance imaging clarify the relative merits of the various
methods in the context of compressed sensing. Unfortunately, the colorizations
appear likely to be too distracting for actual clinical practice, and the
root-mean-square gets swamped by background noise in the error estimates.
Fortunately, straightforward displays of the error estimates and of the
&quot;corrected&quot; reconstruction are illuminating, and the root-mean-square improves
greatly after mild blurring of the error estimates; the blurring is barely
perceptible to the human eye yet smooths away background noise that would
otherwise overwhelm the root-mean-square.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00631</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00631</id><created>2019-02-01</created><authors><author><keyname>Shi</keyname><forenames>Ziqiang</forenames></author><author><keyname>Lin</keyname><forenames>Huibin</forenames></author><author><keyname>Liu</keyname><forenames>Liu</forenames></author><author><keyname>Liu</keyname><forenames>Rujie</forenames></author><author><keyname>Han</keyname><forenames>Jiqing</forenames></author></authors><title>Is CQT more suitable for monaural speech separation than STFT? an
  empirical study</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short-time Fourier transform (STFT) is used as the front end of many popular
successful monaural speech separation methods, such as deep clustering (DPCL),
permutation invariant training (PIT) and their various variants. Since the
frequency component of STFT is linear, while the frequency distribution of
human auditory system is nonlinear. In this work we propose and give an
empirical study to use an alternative front end called constant Q transform
(CQT) instead of STFT to achieve a better simulation of the frequency resolving
power of the human auditory system. The upper bound in signal-to-distortion
(SDR) of ideal speech separation based on CQT's ideal ration mask (IRM) is
higher than that based on STFT. In the same experimental setting on WSJ0-2mix
corpus, we examined the performance of CQT under different backends, including
the original DPCL, utterance level PIT, and some of their variants. It is found
that all CQT-based methods are better than STFT-based methods, and achieved on
average 0.4dB better performance than STFT based method in SDR improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00637</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00637</id><created>2019-02-01</created><authors><author><keyname>Tang</keyname><forenames>Kexin</forenames></author><author><keyname>Kan</keyname><forenames>Nuowen</forenames></author><author><keyname>Zou</keyname><forenames>Junni</forenames></author><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author><author><keyname>Xiong</keyname><forenames>Hongkai</forenames></author></authors><title>Multiuser Video Streaming Rate Adaptation: A Physical Layer
  Resource-Aware Deep Reinforcement Learning Approach</title><categories>cs.MM eess.SP</categories><comments>29 pages, 7 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-user video streaming service optimization problem over a
time-varying and mutually interfering multi-cell wireless network. The key
research challenge is to appropriately adapt each user's video streaming rate
according to the radio frequency environment (e.g., channel fading and
interference level) and service demands (e.g., play request), so that the
users' long-term experience for watching videos can be optimized. To address
the above challenge, we propose a novel two-level cross-layer optimization
framework for multiuser adaptive video streaming over wireless networks. The
key idea is to jointly design the physical layer optimization-based beamforming
scheme (performed at the base stations) and the application layer Deep
Reinforcement Learning (DRL)-based scheme (performed at the user terminals), so
that a highly complex multi-user, cross-layer, time-varying video streaming
problem can be decomposed into relatively simple problems and solved
effectively. Our strategy represents a significant departure for the existing
schemes where either short-term user experience optimization is considered, or
only single-user point-to-point long-term optimization is considered. Extensive
simulations based on real-data sets show that the proposed cross-layer design
is effective and promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00651</identifier>
 <datestamp>2019-03-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00651</id><created>2019-02-02</created><updated>2019-03-17</updated><authors><author><keyname>Shi</keyname><forenames>Ziqiang</forenames></author><author><keyname>Lin</keyname><forenames>Huibin</forenames></author><author><keyname>Liu</keyname><forenames>Liu</forenames></author><author><keyname>Liu</keyname><forenames>Rujie</forenames></author><author><keyname>Hayakawa</keyname><forenames>Shoji</forenames></author><author><keyname>Harada</keyname><forenames>Shouji</forenames></author><author><keyname>Han</keyname><forenames>Jiqing</forenames></author></authors><title>FurcaNet: An end-to-end deep gated convolutional, long short-term
  memory, deep neural networks for single channel speech separation</title><categories>cs.SD eess.AS</categories><comments>arXiv admin note: text overlap with arXiv:1902.00631</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep gated convolutional networks have been proved to be very effective in
single channel speech separation. However current state-of-the-art framework
often considers training the gated convolutional networks in time-frequency
(TF) domain. Such an approach will result in limited perceptual score, such as
signal-to-distortion ratio (SDR) upper bound of separated utterances and also
fail to exploit an end-to-end framework. In this paper we present an integrated
simple and effective end-to-end approach to monaural speech separation, which
consists of deep gated convolutional neural networks (GCNN) that takes the
mixed utterance of two speakers and maps it to two separated utterances, where
each utterance contains only one speaker's voice. In addition long short-term
memory (LSTM) is employed for long term temporal modeling. For the objective,
we propose to train the network by directly optimizing utterance level SDR in a
permutation invariant training (PIT) style. Our experiments on the public
WSJ0-2mix data corpus demonstrate that this new scheme can produce more
discriminative separated utterances and leading to performance improvement on
the speaker separation task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00694</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00694</id><created>2019-02-02</created><authors><author><keyname>Rafi</keyname><forenames>Abdul Muntakim</forenames></author><author><keyname>Tonmoy</keyname><forenames>Thamidul Islam</forenames></author><author><keyname>Kamal</keyname><forenames>Uday</forenames></author><author><keyname>Hoque</keyname><forenames>Rakibul</forenames></author><author><keyname>Hasan</keyname><forenames>Md. Kamrul</forenames></author></authors><title>RemNet: Remnant Convolutional Neural Network for Camera Model
  Identification</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Camera model identification has gained significant importance in image
forensics as digitally altered images are becoming increasingly commonplace. In
this paper, we present a solution to the problem of identifying the source
camera model of an image using a novel deep learning architecture called
Remnant Convolutional Neural Network (RemNet). RemNet is comprised of multiple
remnant blocks with intra-block skip connection and a classification block in
series. Unlike the conventional fixed filters used in image forensics for
preprocessing, our proposed novel remnant blocks are completely data driven. It
suppresses unnecessary image contents dynamically and generates a remnant of
the image from where the classification block can extract intrinsic camera
model-specific features for model identification. The whole architecture is
trained end-to-end. This network proves to be very robust for identifying the
source camera model, even if the original images are post-processed. The
network, trained and tested on 18 models from Dresden database, shows 100%
accuracy for 16 camera models with an overall accuracy of 97.59% where the test
dataset consisted of images from unseen devices. This result is better in
comparison to other state of the art methods. Our network also achieves an
overall accuracy of 95.01% on the IEEE Signal Processing (SP) Cup 2018 dataset,
which indicates the generalizability of our network. In addition, RemNet
achieves an overall accuracy of 99.53% in image manipulation detection which
implies that it can be used as a general purpose network for image forensic
tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00726</identifier>
 <datestamp>2019-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00726</id><created>2019-02-02</created><authors><author><keyname>Saberi</keyname><forenames>Amir</forenames></author><author><keyname>Farokhi</keyname><forenames>Farhad</forenames></author><author><keyname>Nair</keyname><forenames>Girish N.</forenames></author></authors><title>State Estimation over Worst-Case Erasure and Symmetric Channels with
  Memory</title><categories>eess.SP cs.IT cs.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Worst-case models of erasure and symmetric channels are investigated, in
which the number of channel errors occurring in each sliding window of a given
length is bounded. Upper and lower bounds on their zero-error capacities are
derived, with the lower bounds revealing a connection with the topological
entropy of the channel dynamics. Necessary and sufficient conditions for linear
state estimation with bounded estimation errors via such channels are then
obtained, by extending previous results for non-stochastic memoryless channels
to those with finite memory. These estimation conditions involve the
topological entropies of the linear system and the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00743</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00743</id><created>2019-02-02</created><authors><author><keyname>Song</keyname><forenames>Linghao</forenames></author><author><keyname>Chen</keyname><forenames>Fan</forenames></author><author><keyname>Young</keyname><forenames>Steven R.</forenames></author><author><keyname>Schuman</keyname><forenames>Catherine D.</forenames></author><author><keyname>Perdue</keyname><forenames>Gabriel</forenames></author><author><keyname>Potok</keyname><forenames>Thomas E.</forenames></author></authors><title>Deep Learning for Vertex Reconstruction of Neutrino-Nucleus Interaction
  Events with Combined Energy and Time Data</title><categories>cs.LG eess.SP physics.data-an stat.ML</categories><comments>To appear in 2019 International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a deep learning approach for vertex reconstruction of
neutrino-nucleus interaction events, a problem in the domain of high energy
physics. In this approach, we combine both energy and timing data that are
collected in the MINERvA detector to perform classification and regression
tasks. We show that the resulting network achieves higher accuracy than
previous results while requiring a smaller model size and less training time.
In particular, the proposed model outperforms the state-of-the-art by 4.00% on
classification accuracy. For the regression task, our model achieves 0.9919 on
the coefficient of determination, higher than the previous work (0.96).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00809</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00809</id><created>2019-02-02</created><updated>2019-07-29</updated><authors><author><keyname>Goyal</keyname><forenames>Manu</forenames></author><author><keyname>Oakley</keyname><forenames>Amanda</forenames></author><author><keyname>Bansal</keyname><forenames>Priyanka</forenames></author><author><keyname>Dancey</keyname><forenames>Darren</forenames></author><author><keyname>Yap</keyname><forenames>Moi Hoon</forenames></author></authors><title>Automatic Lesion Boundary Segmentation in Dermoscopic Images with
  Ensemble Deep Learning Methods</title><categories>eess.IV cs.CV</categories><comments>7 pages, 8 figures and 4 tables. arXiv admin note: text overlap with
  arXiv:1711.10449</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early detection of skin cancer, particularly melanoma, is crucial to enable
advanced treatment. Due to the rapid growth in the numbers of skin cancers,
there is a growing need of computerized analysis for skin lesions. The
state-of-the-art public available datasets for skin lesions are often
accompanied with very limited amount of segmentation ground truth labeling as
it is laborious and expensive. The lesion boundary segmentation is vital to
locate the lesion accurately in dermoscopic images and lesion diagnosis of
different skin lesion types. In this work, we propose the use of fully
automated deep learning ensemble methods for accurate lesion boundary
segmentation in dermoscopic images. We trained the Mask-RCNN and DeepLabv3+
methods on ISIC-2017 segmentation training set and evaluate the performance of
the ensemble networks on ISIC-2017 testing set. Our results showed that the
best proposed ensemble method segmented the skin lesions with Jaccard index of
79.58% for the ISIC-2017 testing set. The proposed ensemble method outperformed
FrCN, FCN, U-Net, and SegNet in Jaccard Index by 2.48%, 7.42%, 17.95%, and
9.96% respectively. Furthermore, the proposed ensemble method achieved an
accuracy of 95.6% for some representative clinically benign cases, 90.78% for
the melanoma cases, and 91.29% for the seborrheic keratosis cases on ISIC-2017
testing set, exhibiting better performance than FrCN, FCN, U-Net, and SegNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00816</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00816</id><created>2019-02-02</created><updated>2019-02-18</updated><authors><author><keyname>Imoto</keyname><forenames>Keisuke</forenames></author><author><keyname>Kyochi</keyname><forenames>Seisuke</forenames></author></authors><title>Sound Event Detection Using Graph Laplacian Regularization Based on
  Event Co-occurrence</title><categories>cs.SD eess.AS</categories><comments>Accepted to ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The types of sound events that occur in a situation are limited, and some
sound events are likely to co-occur; for instance, ``dishes'' and ``glass
jingling.'' In this paper, we propose a technique of sound event detection
utilizing graph Laplacian regularization taking the sound event co-occurrence
into account. In the proposed method, sound event occurrences are represented
as a graph whose nodes indicate the frequency of event occurrence and whose
edges indicate the co-occurrence of sound events. This graph representation is
then utilized for sound event modeling, which is optimized under an objective
function with a regularization term considering the graph structure.
Experimental results obtained using TUT Sound Events 2016 development, 2017
development, and TUT Acoustic Scenes 2016 development indicate that the
proposed method improves the detection performance of sound events by 7.9
percentage points compared to that of the conventional CNN-BiGRU-based method
in terms of the segment-based F1-score. Moreover, the results show that the
proposed method can detect co-occurring sound events more accurately than the
conventional method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00820</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00820</id><created>2019-02-02</created><authors><author><keyname>Farnoosh</keyname><forenames>Amirreza</forenames></author><author><keyname>Rezaei</keyname><forenames>Behnaz</forenames></author><author><keyname>Ostadabbas</keyname><forenames>Sarah</forenames></author></authors><title>DeepPBM: Deep Probabilistic Background Model Estimation from Video
  Sequences</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel unsupervised probabilistic model estimation of
visual background in video sequences using a variational autoencoder framework.
Due to the redundant nature of the backgrounds in surveillance videos, visual
information of the background can be compressed into a low-dimensional subspace
in the encoder part of the variational autoencoder, while the highly variant
information of its moving foreground gets filtered throughout its
encoding-decoding process. Our deep probabilistic background model (DeepPBM)
estimation approach is enabled by the power of deep neural networks in learning
compressed representations of video frames and reconstructing them back to the
original domain. We evaluated the performance of our DeepPBM in background
subtraction on 9 surveillance videos from the background model challenge
(BMC2012) dataset, and compared that with a standard subspace learning
technique, robust principle component analysis (RPCA), which similarly
estimates a deterministic low dimensional representation of the background in
videos and is widely used for this application. Our method outperforms RPCA on
BMC2012 dataset with 23% in average in F-measure score, emphasizing that
background subtraction using the trained model can be done in more than 10
times faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00837</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00837</id><created>2019-02-02</created><authors><author><keyname>Liu</keyname><forenames>Yajun</forenames></author><author><keyname>Zhu</keyname><forenames>Congxu</forenames></author><author><keyname>Deng</keyname><forenames>Xiaoheng</forenames></author><author><keyname>Guan</keyname><forenames>Peiyuan</forenames></author><author><keyname>Wan</keyname><forenames>Zhiwen</forenames></author><author><keyname>Luo</keyname><forenames>Jie</forenames></author><author><keyname>Liu</keyname><forenames>Enlu</forenames></author><author><keyname>Zhang</keyname><forenames>Honggang</forenames></author></authors><title>UAV-aided urban target tracking system based on edge computing</title><categories>eess.SP cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Target tracking is an important issue of social security. In order to track a
target, traditionally a large amount of surveillance video data need to be
uploaded into the cloud for processing and analysis, which put stremendous
bandwidth pressure on communication links in access networks and core networks.
At the same time, the long delay in wide area network is very likely to cause a
tracking system to lose its target. Often, unmanned aerial vehicle (UAV) has
been adopted for target tracking due to its flexibility, but its limited flight
time due to battery constraint and the blocking by various obstacles in the
field pose two major challenges to its target tracking task, which also very
likely results in the loss of target. A novel target tracking model that
coordinates the tracking by UAV and ground nodes in an edge computing
environment is proposed in this study. The model can effectively reduce the
communication cost and the long delay of the traditional surveillance camera
system that relies on cloud computing, and it can improve the probability of
finding a target again after an UAV loses the tracing of that target. It has
been demonstrated that the proposed system achieved a significantly better
performance in terms of low latency, high reliability, and optimal quality of
experience (QoE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00889</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00889</id><created>2019-02-03</created><updated>2019-09-19</updated><authors><author><keyname>Bai</keyname><forenames>Zhongxin</forenames></author><author><keyname>Zhang</keyname><forenames>Xiao-Lei</forenames></author><author><keyname>Chen</keyname><forenames>Jingdong</forenames></author></authors><title>Speaker Verification By Partial AUC Optimization</title><categories>eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker verification systems usually work at different working points of its
receiver operating characteristic (ROC) curve for different applications,
however, most research inclines to use equal error rate (EER) as the major
evaluation metric. As a result, the system that reaches the minimum EER may not
be the best at other working points. To optimize the performance at other
interested working points, we propose to optimize the parameters of a squared
Mahalanobis distance metric for maximizing the area under part of the ROC curve
where the working points locate (denoted as partial AUC or pAUC for short). To
improve the performance of the state-of-the-art speaker verification systems by
the proposed back-end, we further propose two feature preprocessing techniques
based on length-normalization and probabilistic linear discriminant analysis
respectively. We evaluated the proposed systems on the major languages of NIST
SRE16 and core tasks of SITW. Experimental results show that the proposed
systems outperform the state-of-the-art speaker verification systems by at
least over 10\% relative EER reduction and over 9\% relative pAUC improvement
and more than 20\% relative AUC improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.00956</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.00956</id><created>2019-02-03</created><authors><author><keyname>Wager</keyname><forenames>Sanna</forenames></author><author><keyname>Tzanetakis</keyname><forenames>George</forenames></author><author><keyname>Wang</keyname><forenames>Cheng-i</forenames></author><author><keyname>Guo</keyname><forenames>Lijiang</forenames></author><author><keyname>Sivaraman</keyname><forenames>Aswin</forenames></author><author><keyname>Kim</keyname><forenames>Minje</forenames></author></authors><title>Deep Autotuner: A Data-Driven Approach to Natural-Sounding Pitch
  Correction for Singing Voice in Karaoke Performances</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a machine-learning approach to pitch correcting a solo singing
performance in a karaoke setting, where the solo voice and accompaniment are on
separate tracks. The proposed approach addresses the situation where no musical
score of the vocals nor the accompaniment exists: It predicts the amount of
correction from the relationship between the spectral contents of the vocal and
accompaniment tracks. Hence, the pitch shift in cents suggested by the model
can be used to make the voice sound in tune with the accompaniment. This
approach differs from commercially used automatic pitch correction systems,
where notes in the vocal tracks are shifted to be centered around notes in a
user-defined score or mapped to the closest pitch among the twelve
equal-tempered scale degrees. We train the model using a dataset of 4,702
amateur karaoke performances selected for good intonation. We present a
Convolutional Gated Recurrent Unit (CGRU) model to accomplish this task. This
method can be extended into unsupervised pitch correction of a vocal
performance, popularly referred to as autotuning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01040</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01040</id><created>2019-02-04</created><authors><author><keyname>Shankaranarayana</keyname><forenames>Sharath M</forenames></author><author><keyname>Ram</keyname><forenames>Keerthi</forenames></author><author><keyname>Mitra</keyname><forenames>Kaushik</forenames></author><author><keyname>Sivaprakasam</keyname><forenames>Mohanasankar</forenames></author></authors><title>Fully Convolutional Networks for Monocular Retinal Depth Estimation and
  Optic Disc-Cup Segmentation</title><categories>eess.IV cs.LG stat.ML</categories><comments>Under review in IEEE JBHI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Glaucoma is a serious ocular disorder for which the screening and diagnosis
are carried out by the examination of the optic nerve head (ONH). The color
fundus image (CFI) is the most common modality used for ocular screening. In
CFI, the central r
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01053</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01053</id><created>2019-02-04</created><authors><author><keyname>B&#xe4;ckstr&#xf6;m</keyname><forenames>Tom</forenames></author></authors><title>Overlap-Add Windows with Maximum Energy Concentration for Speech and
  Audio Processing</title><categories>eess.AS</categories><comments>accepted to Proc. ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Processing of speech and audio signals with time-frequency representations
require windowing methods which allow perfect reconstruction of the original
signal and where processing artifacts have a predictable behavior. The most
common approach for this purpose is overlap-add windowing, where signal
segments are windowed before and after processing. Commonly used windows
include the half-sine and a Kaiser-Bessel derived window. The latter is an
approximation of the discrete prolate spherical sequence, and thus a maximum
energy concentration window, adapted for overlap-add. We demonstrate that
performance can be improved by including the overlap-add structure as a
constraint in optimization of the maximum energy concentration criteria. The
same approach can be used to find further special cases such as optimal
low-overlap windows. Our experiments demonstrate that the proposed windows
provide notable improvements in terms of reduction in side-lobe magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01147</identifier>
 <datestamp>2019-04-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01147</id><created>2019-02-04</created><authors><author><keyname>Marchisio</keyname><forenames>Alberto</forenames></author><author><keyname>Nanfa</keyname><forenames>Giorgio</forenames></author><author><keyname>Khalid</keyname><forenames>Faiq</forenames></author><author><keyname>Hanif</keyname><forenames>Muhammad Abdullah</forenames></author><author><keyname>Martina</keyname><forenames>Maurizio</forenames></author><author><keyname>Shafique</keyname><forenames>Muhammad</forenames></author></authors><title>SNN under Attack: are Spiking Deep Belief Networks vulnerable to
  Adversarial Examples?</title><categories>cs.LG cs.CR eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, many adversarial examples have emerged for Deep Neural Networks
(DNNs) causing misclassifications. However, in-depth work still needs to be
performed to demonstrate such attacks and security vulnerabilities for spiking
neural networks (SNNs), i.e. the 3rd generation NNs. This paper aims at
addressing the fundamental questions:&quot;Are SNNs vulnerable to the adversarial
attacks as well?&quot; and &quot;if yes, to what extent?&quot; Using a Spiking Deep Belief
Network (SDBN) for the MNIST database classification, we show that the SNN
accuracy decreases accordingly to the noise magnitude in data poisoning random
attacks applied to the test images. Moreover, SDBNs generalization capabilities
increase by applying noise to the training images. We develop a novel black box
attack methodology to automatically generate imperceptible and robust
adversarial examples through a greedy algorithm, which is first of its kind for
SNNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01178</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01178</id><created>2019-02-04</created><authors><author><keyname>Lei</keyname><forenames>Yi</forenames></author><author><keyname>Chen</keyname><forenames>Bin</forenames></author><author><keyname>Liga</keyname><forenames>Gabriele</forenames></author><author><keyname>Deng</keyname><forenames>Xiong</forenames></author><author><keyname>Cao</keyname><forenames>Zizheng</forenames></author><author><keyname>Li</keyname><forenames>Jianqiang</forenames></author><author><keyname>Xu</keyname><forenames>Kun</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author></authors><title>Improved Decoding of Staircase Codes: The Soft-aided Bit-marking (SABM)
  Algorithm</title><categories>eess.SP</categories><comments>10 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Staircase codes (SCCs) are typically decoded using iterative bounded-distance
decoding (BDD) and hard decisions. In this paper, a novel decoding algorithm is
proposed, which partially uses soft information from the channel. The proposed
algorithm is based on marking certain number of highly reliable and highly
unreliable bits. These marked bits are used to improve the
miscorrection-detection capability of the SCC decoder and the error-correcting
capability of BDD. For SCCs with $2$-error-correcting
Bose-Chaudhuri-Hocquenghem component codes, our algorithm improves upon
standard SCC decoding by up to $0.30$~dB at a bit-error rate (BER) of
$10^{-7}$. The proposed algorithm is shown to achieve almost half of the gain
achievable by an idealized decoder with this structure. A complexity analysis
based on the number of additional calls to the component BDD decoder shows that
the relative complexity increase is only around $4\%$ at a BER of $10^{-4}$.
This additional complexity is shown to decrease as the channel quality
improves. Our algorithm is also extended (with minor modifications) to product
codes. The simulation results show that in this case, the algorithm offers
gains of up to $0.44$~dB at a BER of $10^{-8}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01186</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01186</id><created>2019-02-04</created><authors><author><keyname>Santos</keyname><forenames>Irene</forenames></author><author><keyname>Murillo-Fuentes</keyname><forenames>Juan Jos&#xe9;</forenames></author><author><keyname>Arias-de-Reyna</keyname><forenames>Eva</forenames></author></authors><title>A double EP-based proposal for turbo equalization</title><categories>eess.SP</categories><doi>10.1109/LSP.2019.2959900</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter deals with the application of the expectation propagation (EP)
algorithm to turbo equalization. The EP has been successfully applied to obtain
either a better approximation at the output of the equalizer or at the output
of the channel decoder to better initialize the Gaussian prior used by the
equalizer. In this letter we combine both trends to propose a novel double
EP-based equalizer that is able to decrease the number of iterations needed,
reducing the computational complexity to twice that of the linear MMSE. This
novel equalizer is developed in three different implementations: a block design
that exploits the whole vector of observations, a Wiener filter-type approach
that just uses the observations within a predefined window and a Kalman
smoothing filter-type approach that emulates the BCJR behavior. Finally, we
include some experimental results to compare the three different
implementations and to detail their improvements with respect to other EP-based
proposals in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01198</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01198</id><created>2019-01-17</created><authors><author><keyname>Giacoumidis</keyname><forenames>Elias</forenames></author><author><keyname>Lin</keyname><forenames>Yi</forenames></author><author><keyname>Barry</keyname><forenames>Liam P.</forenames></author></authors><title>DBSCAN for nonlinear equalization in high-capacity multi-carrier optical
  communications</title><categories>eess.SP</categories><comments>This work will be presented at the 3rd International Conference &amp;
  Expo on Laser, Optics &amp; Photonics (Laser and Optics 2019) that will be held
  at London, UK on June 14-15, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coherent optical multi-carrier communications have recently dominated
metro-regional and long-haul optical communications. However, the major
obstacle of networks involving coherent multi-carrier signals such as coherent
optical orthogonal frequency-division multiplexing (CO-OFDM) is the
fiber-induced nonlinearity and the parametric noise amplification from cascaded
optical amplifiers which results in significant nonlinear distortion among
subcarriers. Here, we present the first nonlinear equalizer in optical
communications using the traditional Density-Based Spatial Clustering of
Applications with Noise (DBSCAN) algorithm and a novel modified version of
DBSCAN which combines K-means clustering on the noisy un-clustered symbols. For
a 24.72 Gbit/sec differential quaternary phase-shift keying (DQPSK) CO-OFDM
system, the modified DBSCAN can increase the signal quality-factor by up to
2.158 dB compared to linear equalization at 500 km of transmission. The
modified DBSCAN slightly outperforms the traditional DBSCAN, fuzzy-logic
C-means, hierarchical and conventional K-means clustering at high launched
optical powers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01201</identifier>
 <datestamp>2019-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01201</id><created>2019-01-28</created><updated>2019-02-13</updated><authors><author><keyname>Sheikh</keyname><forenames>Tasher Ali</forenames></author><author><keyname>Bora</keyname><forenames>Joyatri</forenames></author><author><keyname>Hussain</keyname><forenames>Md. Anwar</forenames></author></authors><title>Spectral Efficiency Analysis in Downlink Massive MIMO System for Perfect
  CSI with Precoding</title><categories>eess.SP</categories><comments>We are sorry to inform you that we want to withdraw this paper from
  the arXiv because of the following reason,1. There is a problem in
  section-III. The mathematical part is not correct in the uploaded version so
  we want to withdraw the paper;2. The language in the whole paper is not
  correct in present version of paper.So because of huge cretinism from the
  reader we want to withdraw this paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we first derived the mathematical expression for lower bound
spectral efficiency (SE) calculation for zero-force (ZF), and minimum mean
square error (MMSE). Secondly, we calculated the simulation SE with three
algorithms for ZF and MMSE precoding. We compared the simulation and
theoretical results and found that the theoretical results are 1 to 1.5 bits
less than the simulation values which implied that the theoretical lower bounds
are actually the lower bounds. To achieve the maximum spectral efficiency in
downlink massive MIMO systems we assumed perfect CSI, ZF and MMSE precoding in
this paper. We also considered that the channel has the characteristics of
small and large scale fading (SSF and LSF) as the model is like a practical. We
investigated the effect of different SNR, base station (M) and radius (R) of
the cell on spectral efficiency for simulation and theoretical results. We also
evaluated the performance of SE of each algorithms and precoding schemes for
different configurations. From the results we have observed that algorithms-1
and ZF outperform other algorithms and MMSE. From our investigation we noticed
that the LSF parameters are the most dominated factor in SE in massive MIMO
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01202</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01202</id><created>2019-01-31</created><authors><author><keyname>Sheng</keyname><forenames>Hao</forenames></author><author><keyname>Wang</keyname><forenames>Xiaozhe</forenames></author></authors><title>Probabilistic Power Flow Calculation using Non-intrusive Low-rank
  Approximation Method</title><categories>eess.SP</categories><comments>12 pages, 5 figures, Accepted by IEEE Transactions on Power Systems
  on January 27, 2019. arXiv admin note: text overlap with arXiv:1810.08156</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel non-intrusive probabilistic power flow (PPF) analysis
method based on the low-rank approximation (LRA) is proposed, which can
accurately and efficiently estimate the probabilistic characteristics (e.g.,
mean, variance, probability density function) of the PPF solutions. This method
aims at building up a statistically-equivalent surrogate for the PPF solutions
through a small number of power flow evaluations. By exploiting the retained
tensor-product form of the univariate polynomial basis, a sequential
correction-updating scheme is applied, making the total number of unknowns to
be linear rather than exponential to the number of random inputs. Consequently,
the LRA method is particularly promising for dealing with high-dimensional
problems with a large number of random inputs. Numerical studies on the IEEE
39-bus, 118-bus, and 1354-bus systems show that the proposed method can achieve
accurate probabilistic characteristics of the PPF solutions with much less
computational effort compared to the Monte Carlo simulations. Even compared to
the polynomial chaos expansion method, the LRA method can achieve comparable
accuracy, while the LRA method is more capable of handling higher-dimensional
problems. Moreover, numerical results reveal that the randomness brought about
by the renewable energy resources and loads may inevitably affect the
feasibility of dispatch/planning schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01223</identifier>
 <datestamp>2020-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01223</id><created>2019-02-01</created><updated>2020-02-11</updated><authors><author><keyname>Lavaei</keyname><forenames>Abolfazl</forenames></author><author><keyname>Soudjani</keyname><forenames>Sadegh</forenames></author><author><keyname>Zamani</keyname><forenames>Majid</forenames></author></authors><title>Compositional Abstraction of Large-Scale Stochastic Systems: A Relaxed
  Dissipativity Approach</title><categories>eess.SY cs.SY</categories><comments>This work is accepted at Nonlinear Analysis: Hybrid Systems. arXiv
  admin note: text overlap with arXiv:1712.07793</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a compositional approach for the construction of
finite abstractions (a.k.a. finite Markov decision processes (MDPs)) for
networks of discrete-time stochastic control subsystems that are not
necessarily stabilizable. The proposed approach leverages the interconnection
topology and a notion of finite-step stochastic storage functions, that
describes joint dissipativity-type properties of subsystems and their
abstractions, and establishes a finite-step stochastic simulation function as a
relation between the network and its abstraction. To this end, we first develop
a new type of compositionality conditions which is less conservative than the
existing ones. In particular, using a relaxation via a finite-step stochastic
simulation function, it is possible to construct finite abstractions such that
stabilizability of each subsystem is not necessarily required. We then propose
an approach to construct finite MDPs together with their corresponding
finite-step storage functions for general discrete-time stochastic control
systems satisfying an incremental passivablity property. We also construct
finite MDPs for a particular class of nonlinear stochastic control systems. To
demonstrate the effectiveness of the proposed results, we apply our results on
three different case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01299</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01299</id><created>2019-02-04</created><updated>2019-09-09</updated><authors><author><keyname>Haubner</keyname><forenames>Thomas</forenames></author><author><keyname>Schmidt</keyname><forenames>Alexander</forenames></author><author><keyname>Kellermann</keyname><forenames>Walter</forenames></author></authors><title>Active Acoustic Source Tracking Exploiting Particle Filtering and Monte
  Carlo Tree Search</title><categories>eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the task of active acoustic source tracking as part
of robotic path planning. It denotes the planning of sequences of robotic
movements to enhance tracking results of acoustic sources, e.g., talking
humans, by fusing observations from multiple positions. Essentially, two
strategies are possible: short-term planning, which results in greedy behavior,
and long-term planning, which considers a sequence of possible future movements
of the robot and the source. Here, we focus on the second method as it might
improve tracking performance compared to greedy behavior and propose a flexible
path planning algorithm which exploits Monte Carlo Tree Search (MCTS) and
particle filtering based on a reward motivated by information-theoretic
considerations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01306</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01306</id><created>2019-02-04</created><updated>2020-01-18</updated><authors><author><keyname>Duggal</keyname><forenames>Gaurav</forenames></author><author><keyname>Vishwakarma</keyname><forenames>Shelly</forenames></author><author><keyname>Mishra</keyname><forenames>Kumar Vijay</forenames></author><author><keyname>Ram</keyname><forenames>Shobha Sundar</forenames></author></authors><title>Doppler-Resilient 802.11ad-Based Ultra-Short Range Automotive Joint
  Radar-Communications System</title><categories>eess.SP</categories><comments>13 pages, 14 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an ultra-short range IEEE 802.11ad-based automotive joint
radar-communications (JRC) framework, wherein we improve the radar's Doppler
resilience by incorporating Prouhet-Thue-Morse sequences in the preamble. The
proposed processing reveals detailed micro-features of common automotive
objects verified through extended scattering center models of animated
pedestrian, bicycle, and car targets. Numerical experiments demonstrate $2.5$%
reduction in the probability-of-false-alarm at low signal-to-noise-ratios and
improvement in the peak-to-sidelobe level dynamic range up to Doppler
velocities of $\pm144$ km/hr over conventional 802.11ad JRC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01426</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01426</id><created>2019-02-04</created><updated>2019-08-19</updated><authors><author><keyname>Martin-del-Campo</keyname><forenames>Sergio</forenames></author><author><keyname>Sandin</keyname><forenames>Fredrik</forenames></author><author><keyname>Str&#xf6;mbergsson</keyname><forenames>Daniel</forenames></author></authors><title>Dictionary learning approach to monitoring of wind turbine drivetrain
  bearings</title><categories>eess.SP cs.LG stat.ML</categories><comments>22 pages, 10 figures, preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Condition monitoring is central to the efficient operation of wind farms due
to the challenging operating conditions, rapid technology development and large
number of aging wind turbines. In particular, predictive maintenance planning
requires the early detection of faults with few false positives. Achieving this
type of detection is a challenging problem due to the complex and weak
signatures of some faults, particularly the faults that occur in some of the
drivetrain bearings. Here, we investigate recently proposed condition
monitoring methods based on unsupervised dictionary learning using vibration
data recorded over 46 months under typical industrial operations. Thus, we
contribute novel test results and real world data that are made publicly
available. The results of former studies addressing condition monitoring tasks
using dictionary learning indicate that unsupervised feature learning is useful
for diagnosis and anomaly detection purposes. However, these studies are based
on small sets of labeled data from test rigs operating under controlled
conditions that focus on classification tasks, which are useful for
quantitative method comparisons but gives little insight into how useful these
approaches are in practice. In this study, dictionaries are learned from
gearbox vibrations in six different turbines, and the dictionaries are
subsequently propagated over a few years of monitoring data when faults are
known to occur. We perform the experiment using two different sparse coding
algorithms to investigate if the algorithm selected affects the features of
abnormal conditions. We calculate the dictionary distance between the initial
and propagated dictionaries and find the time periods of abnormal dictionary
adaptation starting six months before a drivetrain bearing replacement and one
year before the resulting gearbox replacement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01544</identifier>
 <datestamp>2019-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01544</id><created>2019-02-04</created><authors><author><keyname>Dey</keyname><forenames>Jayanta</forenames></author><author><keyname>Hossain</keyname><forenames>Md Sanzid Bin</forenames></author><author><keyname>Haque</keyname><forenames>Mohammad Ariful</forenames></author></authors><title>An Ensemble SVM-based Approach for Voice Activity Detection</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Voice activity detection (VAD), used as the front end of speech enhancement,
speech and speaker recognition algorithms, determines the overall accuracy and
efficiency of the algorithms. Therefore, a VAD with low complexity and high
accuracy is highly desirable for speech processing applications. In this paper,
we propose a novel training method on large dataset for supervised
learning-based VAD system using support vector machine (SVM). Despite of high
classification accuracy of support vector machines (SVM), trivial SVM is not
suitable for classification of large data sets needed for a good VAD system
because of high training complexity. To overcome this problem, a novel
ensemble-based approach using SVM has been proposed in this paper.The
performance of the proposed ensemble structure has been compared with a
feedforward neural network (NN). Although NN performs better than single
SVM-based VAD trained on a small portion of the training data, ensemble SVM
gives accuracy comparable to neural network-based VAD. Ensemble SVM and NN give
88.74% and 86.28% accuracy respectively whereas the stand-alone SVM shows
57.05% accuracy on average on the test dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01573</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01573</id><created>2019-02-05</created><updated>2019-07-09</updated><authors><author><keyname>Nizam</keyname><forenames>Navid Ibtehaj</forenames></author><author><keyname>Ara</keyname><forenames>Sharmin R.</forenames></author><author><keyname>Hasan</keyname><forenames>Md. Kamrul</forenames></author></authors><title>Classification of Breast Lesions Using Quantitative Ultrasound
  Biomarkers</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative ultrasound (QUS) based parameters like the effective scatterer
diameter (ESD) and mean scatterer spacing (MSS) are gaining attention recently
as non-invasive biomarkers for soft tissue characterization. In this work, we
propose a multiple QUS parameter based technique that employs ESD and MSS, for
binary classification of breast lesions. In order to produce improved ESD
estimates, we propose a modified frequency domain technique for ESD estimation
of breast tissues from the diffuse component of backscattered radio-frequency
(RF) data. Ensemble empirical mode decomposition (EEMD) is performed to
separate the diffuse component from the coherent component by decomposing the
RF data into their intrinsic mode functions (IMFs). A non-parametric
Kolmogorov-Smirnov (K-S) test is employed for automatic IMF selection along
with a multi-step system effect minimization process. The ESD is estimated
using a nearest neighborhood average regression line fitting algorithm.
Furthermore, we use an ameliorated EEMD domain autoregressive (AR) spectral
estimation technique for MSS estimation. On using the ESD for binary
classification of 159 lesions, we obtain high sensitivity, specificity,
accuracy values of 91.07%, 96.12%, and 94.34%, respectively, with an area under
the receiver operating characteristics (ROC) curve of 0.94. On combining ESD
with MSS we obtain even more improved sensitivity, specificity, and accuracy
values of 96.43%, 95.15%, and 95.60%, respectively, with an area under the ROC
of 0.96. Such a high classification performance highlights the potential of
these QUS parameters to be used as non-invasive biomarkers for breast cancer
detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01605</identifier>
 <datestamp>2019-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01605</id><created>2019-02-05</created><authors><author><keyname>Leglaive</keyname><forenames>Simon</forenames></author><author><keyname>Girin</keyname><forenames>Laurent</forenames></author><author><keyname>Horaud</keyname><forenames>Radu</forenames></author></authors><title>A variance modeling framework based on variational autoencoders for
  speech enhancement</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>6 pages, 3 figures</comments><report-no>hal-01832826v1</report-no><journal-ref>Proc. of the IEEE International Workshop on Machine Learning for
  Signal Processing (MLSP), Aalborg, Denmark, September 2018</journal-ref><doi>10.1109/MLSP.2018.8516711</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the problem of enhancing speech signals in noisy
mixtures using a source separation approach. We explore the use of neural
networks as an alternative to a popular speech variance model based on
supervised non-negative matrix factorization (NMF). More precisely, we use a
variational autoencoder as a speaker-independent supervised generative speech
model, highlighting the conceptual similarities that this approach shares with
its NMF-based counterpart. In order to be free of generalization issues
regarding the noisy recording environments, we follow the approach of having a
supervised model only for the target speech signal, the noise model being based
on unsupervised NMF. We develop a Monte Carlo expectation-maximization
algorithm for inferring the latent variables in the variational autoencoder and
estimating the unsupervised model parameters. Experiments show that the
proposed method outperforms a semi-supervised NMF baseline and a
state-of-the-art fully supervised deep learning approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01625</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01625</id><created>2019-02-05</created><updated>2019-09-19</updated><authors><author><keyname>Ishizaki</keyname><forenames>Takayuki</forenames></author><author><keyname>Sasahara</keyname><forenames>Hampei</forenames></author><author><keyname>Inoue</keyname><forenames>Masaki</forenames></author><author><keyname>Kawaguchi</keyname><forenames>Takahiro</forenames></author><author><keyname>Imura</keyname><forenames>Jun-ichi</forenames></author></authors><title>Modularity-in-Design of Dynamical Network Systems: Retrofit Control
  Approach</title><categories>eess.SY cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a modular design method of decentralized
controllers for linear dynamical network systems, where multiple subcontroller
designers aim at individually regulating their own control performance with
accessibility only to respective subsystem models. First, from the standpoint
of a single subcontroller designer who manages his own subsystem, we derive a
constrained version of the Youla parameterization that characterizes all
retrofit controllers, defined as an add-on type subcontroller such that the
resultant feedback system is kept robustly stable for any variation of
neighboring subsystems, other than the subsystem of interest, as long as the
original system before implementing retrofit control is stable. Then, we find
out a special internal structure of the retrofit controllers under the
supposition that the interaction input signal coming from neighboring
subsystems is measurable. We further show that the simultaneous implementation
of multiple retrofit controllers, designed by individual subcontroller
designers, can contribute to improving entire control performance in the sense
of an upper bound. Finally, its practical significance is demonstrated by an
illustrative example of frequency regulation with the IEEE 68-bus power system
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01655</identifier>
 <datestamp>2019-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01655</id><created>2019-02-05</created><authors><author><keyname>M.</keyname><forenames>Shree Prasad</forenames></author><author><keyname>Panigrahi</keyname><forenames>Trilochan</forenames></author><author><keyname>Hassan</keyname><forenames>Mahbub</forenames></author><author><keyname>Ding</keyname><forenames>Ming</forenames></author></authors><title>Sampling Free TDOA Localization in Millimeter Wave Networks</title><categories>eess.SP</categories><comments>6 Pages, 12 Figures, Camera Ready for IEEE WCNC 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Time difference of arrival (TDOA) is a widely used technique for localizing a
radio transmitter from the difference in signal arrival times at multiple
receivers. For TDOA to work, the individual receivers must estimate the
respective signal arrival times precisely, which requires sampling the signal
at least double the rate of its highest frequency content, commonly known as
the Nyquist rate. Such sampling is less practical for the millimeter wave band
comprising of frequencies in 30-300 GHz range. In this paper, we propose an
energy detection architecture for accurately estimating the time of arrival
from a single picosecond Gaussian pulse, which enables TDOA localization
without sampling at the receiver. We derive the closed form expression of the
estimated time of arrival and validate it via simulation. We demonstrate that
the proposed sampling-free TDOA can localize millimeter wave transmitters as
accurately as the conventional sampling-based TDOA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01707</identifier>
 <datestamp>2019-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01707</id><created>2019-02-02</created><authors><author><keyname>Rizk</keyname><forenames>Hamada</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>Increasing Coverage of Indoor Localization Systems for EEE112 Support</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among many techniques for indoor localization, fingerprinting has been shown
to provide a higher accuracy compared to the alternative techniques.
Fingerprinting techniques require an initial calibration phase during which
site surveyors visit virtually every location in the area of interest to
manually collect the fingerprint data. However, this process is labour
intensive, tedious, and needs to be repeated with any change in the
environment. In this work, we propose a technique for enhancing cellular-based
indoor localization fingerprinting systems by automatically increasing the
spatial density of the reference points. This can be achieved by generating
synthetic measurements for virtually all points in the environment to cover
inaccessible places.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01777</identifier>
 <datestamp>2019-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01777</id><created>2019-02-05</created><authors><author><keyname>Korn</keyname><forenames>Katharina</forenames></author><author><keyname>Seifert</keyname><forenames>Bastian</forenames></author><author><keyname>Uhl</keyname><forenames>Christian</forenames></author></authors><title>Dynamical Component Analysis (DyCA) and its application on epileptic EEG</title><categories>eess.SP cs.LG nlin.CD</categories><comments>5 pages, 4 figures, accepted for IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamical Component Analysis (DyCA) is a recently-proposed method to detect
projection vectors to reduce the dimensionality of multi-variate deterministic
datasets. It is based on the solution of a generalized eigenvalue problem and
therefore straight forward to implement. DyCA is introduced and applied to EEG
data of epileptic seizures. The obtained eigenvectors are used to project the
signal and the corresponding trajectories in phase space are compared with PCA
and ICA-projections. The eigenvalues of DyCA are utilized for seizure detection
and the obtained results in terms of specificity, false discovery rate and miss
rate are compared to other seizure detection algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01799</identifier>
 <datestamp>2019-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01799</id><created>2019-02-05</created><authors><author><keyname>Hosseini</keyname><forenames>Seyedroohollah</forenames></author><author><keyname>Guo</keyname><forenames>Xuan</forenames></author></authors><title>Deep Convolutional Neural Network for Automated Detection of Mind
  Wandering using EEG Signals</title><categories>cs.LG cs.HC eess.SP stat.ML</categories><comments>4 pages, 3 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mind wandering (MW) is a ubiquitous phenomenon which reflects a shift in
attention from task-related to task-unrelated thoughts. There is a need for
intelligent interfaces that can reorient attention when MW is detected due to
its detrimental effects on performance and productivity. In this paper, we
propose a deep learning model for MW detection using Electroencephalogram (EEG)
signals. Specifically, we develop a channel-wise deep convolutional neural
network (CNN) model to classify the features of focusing state and MW extracted
from EEG signals. This is the first study that employs CNN to automatically
detect MW using only EEG data. The experimental results on the collected
dataset demonstrate promising performance with 91.78% accuracy, 92.84%
sensitivity, and 90.73% specificity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01817</identifier>
 <datestamp>2019-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01817</id><created>2019-02-05</created><authors><author><keyname>Taricco</keyname><forenames>Giorgio</forenames></author></authors><title>MIMO Capacity with Average Total and Per-Antenna Power Constraints</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MIMO capacity with a joint total and per-antenna average power constraint is
considered in this work. The problem arises when, besides having a limited
available power at the transmitter, also the individual antennas cannot radiate
power beyond the limits of their corresponding RF chains. Closed-form results
are illustrated in specific cases and, in particular, in the unit-rank channel
matrix case. Lower-complexity optimization problems are derived for the other
cases. Numerical complexity is derived in terms of the number of equivalent
real variables for the optimization problem and a general formula is provided
depending on the channel matrix rank. Numerical results are included to
validate and illustrate the application of the proposed optimization algorithms
and also to evaluate the time complexity of its implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01875</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01875</id><created>2019-02-05</created><authors><author><keyname>Dorize</keyname><forenames>Christian</forenames></author><author><keyname>Awwad</keyname><forenames>Elie</forenames></author><author><keyname>Renaudier</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author></authors><title>High Sensitivity {\phi}-OTDR over Long Distance with Polarization
  Multiplexed Codes</title><categories>eess.SP</categories><doi>10.1109/LPT.2019.2942083</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Newly introduced polarization diversity probing codes are suggested to
enhance the sensitivity and bandwidth performance of differential
phase-sensitive distributed OTDR systems. This was recently demonstrated by
means of short-length specialized fibers with a backscattering induced by
equally spaced Fiber Bragg Gratings inserted in the fiber itself. The work
summarized in this letter aims to extend the polarization-diversity probing
technique to widely spread standard single mode fibers (SSMF) used for
telecommunications, by solely exploiting the Rayleigh backscattering.
Conditions to achieve perfect phase estimation along such fibers are first
detailed. An experimental validation highlights the ability to detect and
localize, over 25km of SSMF, multiple low-energy perturbations within a
475Hz-bandwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01951</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01951</id><created>2019-02-02</created><updated>2019-05-15</updated><authors><author><keyname>Nguyen</keyname><forenames>Thai-Son</forenames></author><author><keyname>Stueker</keyname><forenames>Sebastian</forenames></author><author><keyname>Waibel</keyname><forenames>Alex</forenames></author></authors><title>Using multi-task learning to improve the performance of acoustic-to-word
  and conventional hybrid models</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>submitted newer work which includes this paper results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic-to-word (A2W) models that allow direct mapping from acoustic signals
to word sequences are an appealing approach to end-to-end automatic speech
recognition due to their simplicity. However, prior works have shown that
modelling A2W typically encounters issues of data sparsity that prevent
training such a model directly. So far, pre-training initialization is the only
approach proposed to deal with this issue. In this work, we propose to build a
shared neural network and optimize A2W and conventional hybrid models in a
multi-task manner. Our results show that training an A2W model is much more
stable with our multi-task model without pre-training initialization, and
results in a significant improvement compared to a baseline model. Experiments
also reveal that the performance of a hybrid acoustic model can be further
improved when jointly training with a sequence-level optimization criterion
such as acoustic-to-word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01973</identifier>
 <datestamp>2019-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01973</id><created>2019-02-05</created><updated>2019-03-03</updated><authors><author><keyname>Kumar</keyname><forenames>Harish</forenames></author><author><keyname>Ravindran</keyname><forenames>Balaraman</forenames></author></authors><title>Polyphonic Music Composition with LSTM Neural Networks and Reinforcement
  Learning</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the domain of algorithmic music composition, machine learning-driven
systems eliminate the need for carefully hand-crafting rules for composition.
In particular, the capability of recurrent neural networks to learn complex
temporal patterns lends itself well to the musical domain. Promising results
have been observed across a number of recent attempts at music composition
using deep RNNs. These approaches generally aim at first training neural
networks to reproduce subsequences drawn from existing songs. Subsequently,
they are used to compose music either at the audio sample-level or at the
note-level. We designed a representation that divides polyphonic music into a
small number of monophonic streams. This representation greatly reduces the
complexity of the problem and eliminates an exponential number of probably poor
compositions. On top of our LSTM neural network that learnt musical sequences
in this representation, we built an RL agent that learnt to find combinations
of songs whose joint dominance produced pleasant compositions. We present
Amadeus, an algorithmic music composition system that composes music that
consists of intricate melodies, basic chords, and even occasional contrapuntal
sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.01977</identifier>
 <datestamp>2019-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.01977</id><created>2019-02-05</created><authors><author><keyname>Desai</keyname><forenames>Arjun D.</forenames></author><author><keyname>Gold</keyname><forenames>Garry E.</forenames></author><author><keyname>Hargreaves</keyname><forenames>Brian A.</forenames></author><author><keyname>Chaudhari</keyname><forenames>Akshay S.</forenames></author></authors><title>Technical Considerations for Semantic Segmentation in MRI using
  Convolutional Neural Networks</title><categories>eess.IV cs.CV</categories><comments>Submitted to Magnetic Resonance in Medicine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-fidelity semantic segmentation of magnetic resonance volumes is critical
for estimating tissue morphometry and relaxation parameters in both clinical
and research applications. While manual segmentation is accepted as the
gold-standard, recent advances in deep learning and convolutional neural
networks (CNNs) have shown promise for efficient automatic segmentation of soft
tissues. However, due to the stochastic nature of deep learning and the
multitude of hyperparameters in training networks, predicting network behavior
is challenging. In this paper, we quantify the impact of three factors
associated with CNN segmentation performance: network architecture, training
loss functions, and training data characteristics. We evaluate the impact of
these variations on the segmentation of femoral cartilage and propose potential
modifications to CNN architectures and training protocols to train these models
with confidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02059</identifier>
 <datestamp>2019-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02059</id><created>2019-02-06</created><authors><author><keyname>Rashno</keyname><forenames>Abdolreza</forenames></author><author><keyname>Rashno</keyname><forenames>Elyas</forenames></author></authors><title>Content-based image retrieval system with most relevant features among
  wavelet and color features</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Content-based image retrieval (CBIR) has become one of the most important
research directions in the domain of digital data management. In this paper, a
new feature extraction schema including the norm of low frequency components in
wavelet transformation and color features in RGB and HSV domains are proposed
as representative feature vector for images in database followed by appropriate
similarity measure for each feature type. In CBIR systems, retrieving results
are so sensitive to image features. We address this problem with selection of
most relevant features among complete feature set by ant colony optimization
(ACO)-based feature selection which minimize the number of features as well as
maximize F-measure in CBIR system. To evaluate the performance of our proposed
CBIR system, it has been compared with three older proposed systems. Results
show that the precision and recall of our proposed system are higher than older
ones for the majority of image categories in Corel database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02120</identifier>
 <datestamp>2019-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02120</id><created>2019-02-06</created><authors><author><keyname>ElShaer</keyname><forenames>Mohamed Ezzeldin A.</forenames></author><author><keyname>Wisdom</keyname><forenames>Scott</forenames></author><author><keyname>Mishra</keyname><forenames>Taniya</forenames></author></authors><title>Transfer Learning From Sound Representations For Anger Detection in
  Speech</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>5 pages, 2 tables, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we train fully convolutional networks to detect anger in
speech. Since training these deep architectures requires large amounts of data
and the size of emotion datasets is relatively small, we use transfer learning.
However, unlike previous approaches that use speech or emotion-based tasks for
the source model, we instead use SoundNet, a fully convolutional neural network
trained multimodally on a massive video dataset to classify audio, with
ground-truth labels provided by vision-based classifiers. As a result of
transfer learning from SoundNet, our trained anger detection model improves
performance and generalizes well on a variety of acted, elicited, and natural
emotional speech datasets. We also test the cross-lingual effectiveness of our
model by evaluating our English-trained model on Mandarin Chinese speech
emotion data. Furthermore, our proposed system has low latency suitable for
real-time applications, only requiring 1.2 seconds of audio to make a reliable
classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02263</identifier>
 <datestamp>2019-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02263</id><created>2019-02-06</created><authors><author><keyname>Nachmani</keyname><forenames>Eliya</forenames></author><author><keyname>Wolf</keyname><forenames>Lior</forenames></author></authors><title>Unsupervised Polyglot Text To Speech</title><categories>cs.LG cs.CL cs.SD eess.AS stat.ML</categories><comments>The paper will be presented at ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a TTS neural network that is able to produce speech in multiple
languages. The proposed network is able to transfer a voice, which was
presented as a sample in a source language, into one of several target
languages. Training is done without using matching or parallel data, i.e.,
without samples of the same speaker in multiple languages, making the method
much more applicable. The conversion is based on learning a polyglot network
that has multiple per-language sub-networks and adding loss terms that preserve
the speaker's identity in multiple languages. We evaluate the proposed polyglot
neural network for three languages with a total of more than 400 speakers and
demonstrate convincing conversion capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02267</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02267</id><created>2019-02-06</created><updated>2019-10-10</updated><authors><author><keyname>Zhou</keyname><forenames>Hao</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author><author><keyname>Honig</keyname><forenames>Michael L.</forenames></author></authors><title>Beam Acquisition and Training in Millimeter Wave Networks with
  Narrowband Pilots</title><categories>eess.SP</categories><comments>28 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies initial beam acquisition in a millimeter wave network
consisting of multiple access points (APs) and mobile devices. A training
protocol for joint estimation of transmit and receive beams is presented with a
general frame structure consisting of an initial access sub-frame followed by
data transmission sub-frames. During the initial subframe, APs and mobiles
sweep through a set of beams and determine the best transmit and receive beams
via a handshake. All pilot signals are narrowband (tones), and the mobiles are
distinguished by their assigned pilot frequencies. Both non-coherent and
coherent beam estimation methods based on, respectively, power detection and
maximum likelihood (ML) are presented. To avoid exchanging information about
beamforming vectors between APs and mobiles, a local maximum likelihood (LML)
algorithm is also presented. An efficient fast Fourier transform implementation
is proposed for ML and LML to achieve high-resolution. A system-level
optimization is performed in which the frame length, training time, and
training bandwidth are selected to maximize a rate objective taking into
account blockage and mobility. Simulation results based on a realistic network
topology are presented to compare the performance of different estimation
methods and training codebooks, and demonstrate the effectiveness of the
proposed protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02375</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02375</id><created>2019-02-06</created><authors><author><keyname>Wang</keyname><forenames>Jixuan</forenames></author><author><keyname>Wang</keyname><forenames>Kuan-Chieh</forenames></author><author><keyname>Law</keyname><forenames>Marc</forenames></author><author><keyname>Rudzicz</keyname><forenames>Frank</forenames></author><author><keyname>Brudno</keyname><forenames>Michael</forenames></author></authors><title>Centroid-based deep metric learning for speaker recognition</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>ICASSP 2019 (44th International Conference on Acoustics, Speech, and
  Signal Processing)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker embedding models that utilize neural networks to map utterances to a
space where distances reflect similarity between speakers have driven recent
progress in the speaker recognition task. However, there is still a significant
performance gap between recognizing speakers in the training set and unseen
speakers. The latter case corresponds to the few-shot learning task, where a
trained model is evaluated on unseen classes. Here, we optimize a speaker
embedding model with prototypical network loss (PNL), a state-of-the-art
approach for the few-shot image classification task. The resulting embedding
model outperforms the state-of-the-art triplet loss based models in both
speaker verification and identification tasks, for both seen and unseen
speakers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02383</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02383</id><created>2019-02-06</created><authors><author><keyname>Wang</keyname><forenames>Yiming</forenames></author><author><keyname>Fan</keyname><forenames>Xing</forenames></author><author><keyname>Chen</keyname><forenames>I-Fan</forenames></author><author><keyname>Liu</keyname><forenames>Yuzong</forenames></author><author><keyname>Chen</keyname><forenames>Tongfei</forenames></author><author><keyname>Hoffmeister</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>End-to-end Anchored Speech Recognition</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Accepted by ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice-controlled house-hold devices, like Amazon Echo or Google Home, face
the problem of performing speech recognition of device-directed speech in the
presence of interfering background speech, i.e., background noise and
interfering speech from another person or media device in proximity need to be
ignored. We propose two end-to-end models to tackle this problem with
information extracted from the &quot;anchored segment&quot;. The anchored segment refers
to the wake-up word part of an audio stream, which contains valuable speaker
information that can be used to suppress interfering speech and background
noise. The first method is called &quot;Multi-source Attention&quot; where the attention
mechanism takes both the speaker information and decoder state into
consideration. The second method directly learns a frame-level mask on top of
the encoder output. We also explore a multi-task learning setup where we use
the ground truth of the mask to guide the learner. Given that audio data with
interfering speech is rare in our training data set, we also propose a way to
synthesize &quot;noisy&quot; speech from &quot;clean&quot; speech to mitigate the mismatch between
training and test data. Our proposed methods show up to 15% relative reduction
in WER for Amazon Alexa live data with interfering background speech without
significantly degrading on clean speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02454</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02454</id><created>2019-02-06</created><authors><author><keyname>Pilanawithana</keyname><forenames>Bhathiya</forenames></author><author><keyname>Atapattu</keyname><forenames>Saman</forenames></author><author><keyname>Evans</keyname><forenames>Jamie</forenames></author></authors><title>Average Transmission Success Probability Bound for SWIPT Relay Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless energy transferring technology offers a constant and instantaneous
power for low-power applications such as Internet of Things (IoT) to become an
affordable reality. This paper considers simultaneous wireless information and
power transfer (SWIPT) over a dual-hop decode-and-forward (DF) relay network
with the power-splitting (PS) energy harvesting protocol at the relay. The
relay is equipped with a finite capacity battery. The system performance, which
is characterized by the average success probability of source to destination
transmission, is a function of the resource allocation policy that selects the
PS ratio and the transmit energy of the relay. We develop a mathematical
framework to find an upper bound for the maximum the average success
probability. The upper bound is formulated by a discrete state space Markov
decision problem (MDP) and make use of a policy iteration algorithm to
calculate it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02455</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02455</id><created>2019-02-06</created><updated>2019-07-17</updated><authors><author><keyname>Heo</keyname><forenames>Hee-Soo</forenames></author><author><keyname>Jung</keyname><forenames>Jee-weon</forenames></author><author><keyname>Yang</keyname><forenames>IL-Ho</forenames></author><author><keyname>Yoon</keyname><forenames>Sung-Hyun</forenames></author><author><keyname>Shim</keyname><forenames>Hye-jin</forenames></author><author><keyname>Yu</keyname><forenames>Ha-Jin</forenames></author></authors><title>End-to-end losses based on speaker basis vectors and all-speaker hard
  negative mining for speaker verification</title><categories>eess.AS cs.LG cs.SD</categories><comments>5 pages and 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, speaker verification has primarily performed using deep
neural networks that are trained to output embeddings from input features such
as spectrograms or Mel-filterbank energies. Studies that design various loss
functions, including metric learning have been widely explored. In this study,
we propose two end-to-end loss functions for speaker verification using the
concept of speaker bases, which are trainable parameters. One loss function is
designed to further increase the inter-speaker variation, and the other is
designed to conduct the identical concept with hard negative mining. Each
speaker basis is designed to represent the corresponding speaker in the process
of training deep neural networks. In contrast to the conventional loss
functions that can consider only a limited number of speakers included in a
mini-batch, the proposed loss functions can consider all the speakers in the
training set regardless of the mini-batch composition. In particular, the
proposed loss functions enable hard negative mining and calculations of
between-speaker variations with consideration of all speakers. Through
experiments on VoxCeleb1 and VoxCeleb2 datasets, we confirmed that the proposed
loss functions could supplement conventional softmax and center loss functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02461</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02461</id><created>2019-02-06</created><authors><author><keyname>Thudugalage</keyname><forenames>Amanthi</forenames></author><author><keyname>Atapattu</keyname><forenames>Saman</forenames></author><author><keyname>Evans</keyname><forenames>Jamie</forenames></author></authors><title>Opportunistic Wireless Energy Transfer in Point-to-Point Links</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider wireless energy transfer for a point-to-point link.
The energy transmitter sees a finite number of independent channel
realizations, and, armed with (causal) knowledge of the channels, must decide
how much energy to transmit in each time slot. The objective is to maximize the
expected energy transferred to the receiver at the end of the time period. We
show that the optimal energy allocation policy is binary: the transmitter sends
no energy or all energy in a slot with this decision based on a simple
threshold on the channel. As intuition demands, this threshold for transmission
decreases as we move closer to the last available time slot. The performance of
the optimal scheme is studied both analytically and numerically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02492</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02492</id><created>2019-02-07</created><updated>2019-06-25</updated><authors><author><keyname>Barmherzig</keyname><forenames>David A.</forenames></author><author><keyname>Sun</keyname><forenames>Ju</forenames></author><author><keyname>Cand&#xe8;s</keyname><forenames>Emmanuel J.</forenames></author><author><keyname>Lane</keyname><forenames>T. J.</forenames></author><author><keyname>Li</keyname><forenames>Po-Nan</forenames></author></authors><title>Dual-Reference Design for Holographic Coherent Diffraction Imaging</title><categories>eess.IV cs.LG cs.NA math.NA math.OC physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new reference design is introduced for holographic coherent diffraction
imaging. This consists in two references - &quot;block&quot; and &quot;pinhole&quot; shaped regions
- placed adjacent to the imaging specimen. An efficient recovery algorithm is
provided for the resulting holographic phase retrieval problem, which is based
on solving a structured, overdetermined linear system. Analysis of the expected
recovery error on noisy data, which is contaminated by Poisson shot noise,
shows that this simple modification synergizes the individual references and
hence leads to uniformly superior performance over single-reference schemes.
Numerical experiments on simulated data confirm the theoretical prediction, and
the proposed dual-reference scheme achieves a smaller recovery error than
leading single-reference schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02498</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02498</id><created>2019-02-07</created><authors><author><keyname>Thakur</keyname><forenames>Anshul</forenames></author><author><keyname>Sharma</keyname><forenames>Pulkit</forenames></author><author><keyname>Abrol</keyname><forenames>Vinayak</forenames></author><author><keyname>Rajan</keyname><forenames>Padmanabhan</forenames></author></authors><title>Conv-codes: Audio Hashing For Bird Species Classification</title><categories>eess.AS cs.LG cs.SD</categories><comments>Accepted for presentation at ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a supervised, convex representation based audio
hashing framework for bird species classification. The proposed framework
utilizes archetypal analysis, a matrix factorization technique, to obtain
convex-sparse representations of a bird vocalization. These convex
representations are hashed using Bloom filters with non-cryptographic hash
functions to obtain compact binary codes, designated as conv-codes. The
conv-codes extracted from the training examples are clustered using
class-specific k-medoids clustering with Jaccard coefficient as the similarity
metric. A hash table is populated using the cluster centers as keys while hash
values/slots are pointers to the species identification information. During
testing, the hash table is searched to find the species information
corresponding to a cluster center that exhibits maximum similarity with the
test conv-code. Hence, the proposed framework classifies a bird vocalization in
the conv-code space and requires no explicit classifier or reconstruction error
calculations. Apart from that, based on min-hash and direct addressing, we also
propose a variant of the proposed framework that provides faster and effective
classification. The performances of both these frameworks are compared with
existing bird species classification frameworks on the audio recordings of 50
different bird species.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02530</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02530</id><created>2019-02-07</created><authors><author><keyname>Joo</keyname><forenames>Sunghwan</forenames></author><author><keyname>Cha</keyname><forenames>Sungmin</forenames></author><author><keyname>Moon</keyname><forenames>Taesup</forenames></author></authors><title>DoPAMINE: Double-sided Masked CNN for Pixel Adaptive Multiplicative
  Noise Despeckling</title><categories>eess.IV cs.CV cs.LG</categories><comments>AAAI 2019 Camera Ready Version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose DoPAMINE, a new neural network based multiplicative noise
despeckling algorithm. Our algorithm is inspired by Neural AIDE (N-AIDE), which
is a recently proposed neural adaptive image denoiser. While the original
N-AIDE was designed for the additive noise case, we show that the same
framework, i.e., adaptively learning a network for pixel-wise affine denoisers
by minimizing an unbiased estimate of MSE, can be applied to the multiplicative
noise case as well. Moreover, we derive a double-sided masked CNN architecture
which can control the variance of the activation values in each layer and
converge fast to high denoising performance during supervised training. In the
experimental results, we show our DoPAMINE possesses high adaptivity via
fine-tuning the network parameters based on the given noisy image and achieves
significantly better despeckling results compared to SAR-DRN, a
state-of-the-art CNN-based algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02546</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02546</id><created>2019-02-07</created><authors><author><keyname>Rao</keyname><forenames>Wei</forenames></author><author><keyname>Xu</keyname><forenames>Chenglin</forenames></author><author><keyname>Chng</keyname><forenames>Eng Siong</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author></authors><title>Target Speaker Extraction for Overlapped Multi-Talker Speaker
  Verification</title><categories>eess.AS cs.SD</categories><comments>5 pages, 3 figures. This paper is submitted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of speaker verification degrades significantly when the test
speech is corrupted by interference speakers. Speaker diarization does well to
separate speakers if the speakers are temporally overlapped. However, if
multi-talkers speak at the same time, we need the technique to separate the
speech in the spectral domain. This paper proposes an overlapped multi-talker
speaker verification framework by using target speaker extraction methods.
Specifically, given the target speaker information, the target speaker's speech
is firstly extracted from the overlapped multi-talker speech by a target
speaker extraction module. Then, the extracted speech is passed to the speaker
verification system. Experimental results show that the proposed approach
significantly improves the performance of overlapped multi-talker speaker
verification and achieves 65.7% relative EER reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02597</identifier>
 <datestamp>2020-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02597</id><created>2019-02-07</created><updated>2020-02-13</updated><authors><author><keyname>Lagrange</keyname><forenames>Adrien</forenames></author><author><keyname>Fauvel</keyname><forenames>Mathieu</forenames></author><author><keyname>May</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Bioucas-Dias</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author></authors><title>Matrix Cofactorization for Joint Representation Learning and Supervised
  Classification -- Application to Hyperspectral Image Analysis</title><categories>cs.CV cs.LG eess.IV</categories><doi>10.1016/j.neucom.2019.12.068</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised classification and representation learning are two widely used
classes of methods to analyze multivariate images. Although complementary,
these methods have been scarcely considered jointly in a hierarchical modeling.
In this paper, a method coupling these two approaches is designed using a
matrix cofactorization formulation. Each task is modeled as a factorization
matrix problem and a term relating both coding matrices is then introduced to
drive an appropriate coupling. The link can be interpreted as a clustering
operation over a low-dimensional representation vectors. The attribution
vectors of the clustering are then used as features vectors for the
classification task, i.e., the coding vectors of the corresponding
factorization problem. A proximal gradient descent algorithm, ensuring
convergence to a critical point of the objective function, is then derived to
solve the resulting non-convex non-smooth optimization problem. An evaluation
of the proposed method is finally conducted both on synthetic and real data in
the specific context of hyperspectral image interpretation, unifying two
standard analysis techniques, namely unmixing and classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02627</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02627</id><created>2019-01-25</created><updated>2019-02-07</updated><authors><author><keyname>Nguyen</keyname><forenames>Thong</forenames></author><author><keyname>Lu</keyname><forenames>Tianjian</forenames></author><author><keyname>Wu</keyname><forenames>Ken</forenames></author><author><keyname>Schutt-Aine</keyname><forenames>Jose</forenames></author></authors><title>Fast Transient Simulation of High-Speed Channels Using Recurrent Neural
  Network</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generating eye diagrams by using a circuit simulator can be very
computationally intensive, especially in the presence of nonlinearities. It
often involves multiple Newton-like iterations at every time step when a
SPICE-like circuit simulator handles a nonlinear system in the transient
regime. In this paper, we leverage machine learning methods, to be specific,
the recurrent neural network (RNN), to generate black-box macromodels and
achieve significant reduction of computation time. Through the proposed
approach, an RNN model is first trained and then validated on a relatively
short sequence generated from a circuit simulator. Once the training completes,
the RNN can be used to make predictions on the remaining sequence in order to
generate an eye diagram. The training cost can also be amortized when the
trained RNN starts making predictions. Besides, the proposed approach requires
no complex circuit simulations nor substantial domain knowledge. We use two
high-speed link examples to demonstrate that the proposed approach provides
adequate accuracy while the computation time can be dramatically reduced. In
the high-speed link example with a PAM4 driver, the eye diagram generated by
RNN models shows good agreement with that obtained from a commercial circuit
simulator. This paper also investigates the impacts of various RNN topologies,
training schemes, and tunable parameters on both the accuracy and the
generalization capability of an RNN model. It is found out that the long
short-term memory (LSTM) network outperforms the vanilla RNN in terms of the
accuracy in predicting transient waveforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02629</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02629</id><created>2019-02-06</created><authors><author><keyname>Zusag</keyname><forenames>Mario</forenames></author><author><keyname>Desai</keyname><forenames>Sujal</forenames></author><author><keyname>Di Paolo</keyname><forenames>Marcello</forenames></author><author><keyname>Semple</keyname><forenames>Thomas</forenames></author><author><keyname>Shah</keyname><forenames>Anand</forenames></author><author><keyname>Angelini</keyname><forenames>Elsa</forenames></author></authors><title>SAPSAM - Sparsely Annotated Pathological Sign Activation Maps - A novel
  approach to train Convolutional Neural Networks on lung CT scans using binary
  labels only</title><categories>eess.IV cs.LG stat.ML</categories><comments>Accepted paper for ISBI2019</comments><journal-ref>https://biomedicalimaging.org/2019/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chronic Pulmonary Aspergillosis (CPA) is a complex lung disease caused by
infection with Aspergillus. Computed tomography (CT) images are frequently
requested in patients with suspected and established disease, but the
radiological signs on CT are difficult to quantify making accurate follow-up
challenging. We propose a novel method to train Convolutional Neural Networks
using only regional labels on the presence of pathological signs, to not only
detect CPA, but also spatially localize pathological signs. We use average
intensity projections within different ranges of Hounsfield-unit (HU) values,
transforming input 3D CT scans into 2D RGB-like images. CNN architectures are
trained for hierarchical tasks, leading to precise activation maps of
pathological patterns. Results on a cohort of 352 subjects demonstrate high
classification accuracy, localization precision and predictive power of 2 year
survival. Such tool opens the way to CPA patient stratification and
quantitative follow-up of CPA pathological signs, for patients under drug
therapy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02639</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02639</id><created>2019-02-02</created><updated>2019-02-22</updated><authors><author><keyname>Bhat</keyname><forenames>Ganapati</forenames></author><author><keyname>Bagewadi</keyname><forenames>Kunal</forenames></author><author><keyname>Lee</keyname><forenames>Hyung Gyu</forenames></author><author><keyname>Ogras</keyname><forenames>Umit Y.</forenames></author></authors><title>REAP: Runtime Energy-Accuracy Optimization for Energy Harvesting IoT
  Devices</title><categories>eess.SP cs.SY</categories><comments>To appear in Proceedings of DAC 2019. Datasets are available at
  https://github.com/gmbhat/human-activity-recognition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of wearable and mobile devices for health monitoring and activity
recognition applications is increasing rapidly. These devices need to maximize
their accuracy and active time under a tight energy budget imposed by battery
and small form-factor constraints. This paper considers energy harvesting
devices that run on a limited energy budget to recognize user activities over a
given period. We propose a technique to co-optimize the accuracy and active
time by utilizing multiple design points with different energy-accuracy
trade-offs. The proposed technique switches between these design points at
runtime to maximize a generalized objective function under tight harvested
energy budget constraints. We evaluate the proposed approach experimentally
using a custom hardware prototype and fourteen user studies. The proposed
approach achieves both 46% higher expected accuracy and 66% longer active time
compared to the highest performance design point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02647</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02647</id><created>2019-02-05</created><updated>2019-06-13</updated><authors><author><keyname>Zappone</keyname><forenames>Alessio</forenames></author><author><keyname>Di Renzo</keyname><forenames>Marco</forenames></author><author><keyname>Debbah</keyname><forenames>M&#xe9;rouane</forenames></author></authors><title>Wireless Networks Design in the Era of Deep Learning: Model-Based,
  AI-Based, or Both?</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted for publication in the IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work deals with the use of emerging deep learning techniques in future
wireless communication networks. It will be shown that data-driven approaches
should not replace, but rather complement traditional design techniques based
on mathematical models.
  Extensive motivation is given for why deep learning based on artificial
neural networks will be an indispensable tool for the design and operation of
future wireless communications networks, and our vision of how artificial
neural networks should be integrated into the architecture of future wireless
communication networks is presented.
  A thorough description of deep learning methodologies is provided, starting
with the general machine learning paradigm, followed by a more in-depth
discussion about deep learning and artificial neural networks, covering the
most widely-used artificial neural network architectures and their training
methods. Deep learning will also be connected to other major learning
frameworks such as reinforcement learning and transfer learning.
  A thorough survey of the literature on deep learning for wireless
communication networks is provided, followed by a detailed description of
several novel case-studies wherein the use of deep learning proves extremely
useful for network design. For each case-study, it will be shown how the use of
(even approximate) mathematical models can significantly reduce the amount of
live data that needs to be acquired/measured to implement data-driven
approaches. For each application, the merits of the proposed approaches will be
demonstrated by a numerical analysis in which the implementation and training
of the artificial neural network used to solve the problem is discussed.
  Finally, concluding remarks describe those that in our opinion are the major
directions for future research in this field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02649</identifier>
 <datestamp>2019-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02649</id><created>2019-02-05</created><authors><author><keyname>Prabakaran</keyname><forenames>Bharath Srinivas</forenames></author><author><keyname>Rehman</keyname><forenames>Semeen</forenames></author><author><keyname>Shafique</keyname><forenames>Muhammad</forenames></author></authors><title>XBioSiP: A Methodology for Approximate Bio-Signal Processing at the Edge</title><categories>eess.SP</categories><comments>Accepted for publication at the Design Automation Conference 2019
  (DAC'19), Las Vegas, Nevada, USA</comments><doi>10.1145/3316781.3317933</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bio-signals exhibit high redundancy, and the algorithms for their processing
are inherently error resilient. This property can be leveraged to improve the
energy-efficiency of IoT-Edge (wearables) through the emerging trend of
approximate computing. This paper presents XBioSiP, a novel methodology for
approximate bio-signal processing that employs two quality evaluation stages,
during the pre-processing and bio-signal processing stages, to determine the
approximation parameters. It thereby achieves high energy savings while
satisfying the user-determined quality constraint. Our methodology achieves, up
to 19x and 22x reduction in the energy consumption of a QRS peak detection
algorithm for 0% and &lt;1% loss in peak detection accuracy, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02654</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02654</id><created>2019-02-06</created><authors><author><keyname>Androvic</keyname><forenames>Bozidar</forenames></author><author><keyname>Kovac</keyname><forenames>Marko</forenames></author><author><keyname>Kandic</keyname><forenames>Andjela</forenames></author></authors><title>Instantaneous frequency estimation in compressive sensing scenario</title><categories>eess.SP</categories><comments>Student paper submitted to The 8th Mediterranean Conference on
  Embedded Computing - MECO'2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the instantaneous frequency estimation of nonstationary
signals is considered. The instantaneous frequency is estimated from the
timefrequency representation where certain percent of the coefficients is
missing. The time-frequency representation is considered as an image, whose
missing pixels are reconstructed by using compressive sensing recovery
algorithms. As a time-frequency representation, the S-method is considered. The
Compressive Sensing as a intensively growing novel approach for signal
acquisition, ensures accurate signal reconstruction from relatively small
percent of available information about the signal. The theory is verified by
experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02732</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02732</id><created>2019-02-07</created><updated>2019-02-19</updated><authors><author><keyname>Shastri</keyname><forenames>Saurav Kumaraswami</forenames></author><author><keyname>Rudresh</keyname><forenames>Sunil</forenames></author><author><keyname>Seelamantula</keyname><forenames>Chandra Sekhar</forenames></author></authors><title>Generalized Design of Sampling Kernels for 2-D FRI Signals</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the interesting problems in the finite-rate-of-innovation signal
sampling framework is the design of compactly supported sampling kernels. In
this paper, we present a generic framework for designing sampling kernels in
2-D. We consider both separable and nonseparable kernels. The design is carried
out in the frequency domain, where a set of alias cancellation conditions are
imposed on the kernel's frequency response. The Paley-Wiener theorem for 2-D
signals is invoked to arrive at admissible kernels with a compact support. As a
specific case, we show that a certain separable extension of the 1-D design
framework results in 2-D sum-of-modulated-spline (SMS) kernels. Similar to
their 1-D counterparts, the 2-D SMS kernels have the attractive feature of
reproducing a class of 2-D polynomial-modulated exponentials of a desired
order. Also, the support of the kernels is independent of the order. The design
framework is generic and also allows one to design nonseparable sampling
kernels. To this end, we demonstrate the design of a nonseparable kernel and
present simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02734</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02734</id><created>2019-02-07</created><authors><author><keyname>Zhao</keyname><forenames>Hui</forenames></author><author><keyname>Yang</keyname><forenames>Liang</forenames></author><author><keyname>Salem</keyname><forenames>Ahmed S.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Ergodic Capacity Under Power Adaption Over Fisher-Snedecor F Fading
  Channels</title><categories>eess.SP</categories><comments>4 pages, 3 figures</comments><doi>10.1109/LCOMM.2019.2894648</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider a communication scenario, where the transmitter
adopts different power adaption methods according to the instantaneous channel
state to enhance the ergodic capacity (EC) over Fisher-Snedecor F fading
channels. We derive closed-form expressions for the EC under different power
adaption methods, as well as the corresponding asymptotic EC formulas to get
some insights in the high signal-to-noise ratio region. In the numerical
results section, we compare the performance of different adaptive power
transmission strategies, and demonstrate the accuracy of our derived
expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02762</identifier>
 <datestamp>2019-02-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02762</id><created>2019-02-07</created><authors><author><keyname>Sarikaya</keyname><forenames>Yunus</forenames></author><author><keyname>Ercetin</keyname><forenames>Ozgur</forenames></author></authors><title>Self-sufficient Receiver with Wireless Energy Transfer in a Multi-access
  Network</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider the control of an energy self-sufficient receiver
in a multi-access network with simultaneous wireless information and energy
transfer. Multiple transmitters send data to a common receiver whose only
source of energy is a finite size battery which is recharged only from the
energy harvested from incoming RF signals. The nodes access the channel
randomly resulting in a packet collision when multiple transmitters
simultaneously access the channel. The receiver takes samples from the received
RF signal to calculate the probability of a collision. The objective is to
maximize the receiver goodput subject to the instantaneous availability of
receiver energy. We develop an asymptotically optimal dynamic control
algorithm, where the receiver makes an energy harvesting or decoding decision
according to the current channel measurements and battery level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02771</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02771</id><created>2019-01-21</created><updated>2019-11-19</updated><authors><author><keyname>Basha</keyname><forenames>S. H. Shabbeer</forenames></author><author><keyname>Dubey</keyname><forenames>Shiv Ram</forenames></author><author><keyname>Pulabaigari</keyname><forenames>Viswanath</forenames></author><author><keyname>Mukherjee</keyname><forenames>Snehasis</forenames></author></authors><title>Impact of Fully Connected Layers on Performance of Convolutional Neural
  Networks for Image Classification</title><categories>cs.CV cs.LG cs.NE eess.IV</categories><comments>This paper is accepted for publication in Neurocomputing Journal</comments><doi>10.1016/j.neucom.2019.10.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Convolutional Neural Networks (CNNs), in domains like computer vision,
mostly reduced the need for handcrafted features due to its ability to learn
the problem-specific features from the raw input data. However, the selection
of dataset-specific CNN architecture, which mostly performed by either
experience or expertise is a time-consuming and error-prone process. To
automate the process of learning a CNN architecture, this paper attempts at
finding the relationship between Fully Connected (FC) layers with some of the
characteristics of the datasets. The CNN architectures, and recently datasets
also, are categorized as deep, shallow, wide, etc. This paper tries to
formalize these terms along with answering the following questions. (i) What is
the impact of deeper/shallow architectures on the performance of the CNN w.r.t.
FC layers?, (ii) How the deeper/wider datasets influence the performance of CNN
w.r.t. FC layers?, and (iii) Which kind of architecture (deeper/ shallower) is
better suitable for which kind of (deeper/ wider) datasets. To address these
findings, we have performed experiments with three CNN architectures having
different depths. The experiments are conducted by varying the number of FC
layers. We used four widely used datasets including CIFAR-10, CIFAR-100, Tiny
ImageNet, and CRCHistoPhenotypes to justify our findings in the context of the
image classification problem. The source code of this research is available at
https://github.com/shabbeersh/Impact-of-FC-layers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02829</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02829</id><created>2019-02-07</created><authors><author><keyname>Yao</keyname><forenames>Houpu</forenames></author><author><keyname>Wen</keyname><forenames>Jingjing</forenames></author><author><keyname>Ren</keyname><forenames>Yi</forenames></author><author><keyname>Wu</keyname><forenames>Bin</forenames></author><author><keyname>Ji</keyname><forenames>Ze</forenames></author></authors><title>Low-cost Measurement of Industrial Shock Signals via Deep Learning
  Calibration</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Special high-end sensors with expensive hardware are usually needed to
measure shock signals with high accuracy. In this paper, we show that cheap
low-end sensors calibrated by deep neural networks are also capable to measure
high-g shocks accurately. Firstly we perform drop shock tests to collect a
dataset of shock signals measured by sensors of different fidelity. Secondly,
we propose a novel network to effectively learn both the signal peak and
overall shape. The results show that the proposed network is capable to map
low-end shock signals to its high-end counterparts with satisfactory accuracy.
To the best of our knowledge, this is the first work to apply deep learning
techniques to calibrate shock sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02882</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02882</id><created>2019-02-07</created><updated>2019-08-01</updated><authors><author><keyname>Song</keyname><forenames>Pingfan</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Mazor</keyname><forenames>Gal</forenames></author><author><keyname>Rodrigues</keyname><forenames>Miguel</forenames></author></authors><title>HYDRA: Hybrid Deep Magnetic Resonance Fingerprinting</title><categories>eess.IV</categories><doi>10.1002/mp.13727</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: Magnetic resonance fingerprinting (MRF) methods typically rely on
dictio-nary matching to map the temporal MRF signals to quantitative tissue
parameters. Such approaches suffer from inherent discretization errors, as well
as high computational complexity as the dictionary size grows. To alleviate
these issues, we propose a HYbrid Deep magnetic ResonAnce fingerprinting
approach, referred to as HYDRA.
  Methods: HYDRA involves two stages: a model-based signature restoration phase
and a learning-based parameter restoration phase. Signal restoration is
implemented using low-rank based de-aliasing techniques while parameter
restoration is performed using a deep nonlocal residual convolutional neural
network. The designed network is trained on synthesized MRF data simulated with
the Bloch equations and fast imaging with steady state precession (FISP)
sequences. In test mode, it takes a temporal MRF signal as input and produces
the corresponding tissue parameters.
  Results: We validated our approach on both synthetic data and anatomical data
generated from a healthy subject. The results demonstrate that, in contrast to
conventional dictionary-matching based MRF techniques, our approach
significantly improves inference speed by eliminating the time-consuming
dictionary matching operation, and alleviates discretization errors by
outputting continuous-valued parameters. We further avoid the need to store a
large dictionary, thus reducing memory requirements.
  Conclusions: Our approach demonstrates advantages in terms of inference
speed, accuracy and storage requirements over competing MRF methods
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.02980</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.02980</id><created>2019-02-08</created><authors><author><keyname>Esswie</keyname><forenames>Ali A.</forenames></author><author><keyname>Pedersen</keyname><forenames>Klaus I.</forenames></author></authors><title>Inter-Cell Radio Frame Coordination Scheme Based on Sliding Codebook for
  5G TDD Systems</title><categories>eess.SP</categories><journal-ref>2019 Ieee 89th Vehicular Technology Conference: Vtc2019-spring</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fifth generation (5G) of the wireless communication networks supports
wide diversity of service classes, leading to a highly dynamic uplink (UL) and
downlink (DL) traffic asymmetry. Thus, dynamic time division duplexing (TDD)
technology has become of a significant importance, due to its radio frame
flexibility. However, fully dynamic TDD systems suffer from potentially severe
inter-cell cross link interference (CLI). In this paper, we propose a novel
inter-cell radio frame coordination (RFC) scheme based on sliding codebook for
fully dynamic TDD 5G networks. Proposed coordination scheme simultaneously
addresses two optimization objectives of minimizing the average CLI while
reliably maximizing the achievable DL/UL capacity, by virtually extending the
RFC degrees of freedom through a sliding phase-offset RFC codebook design.
Compared to the state-of-the-art TDD studies, the proposed scheme shows
significantly improved ergodic capacity, i.e., at least 40% gain under both the
TCP and UDP protocols, and with much less signaling overhead, limited to B-bit.
The paper offers valuable insights about how to most efficiently pre-mitigate
potential CLI in Macro TDD systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03003</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03003</id><created>2019-02-08</created><authors><author><keyname>Yang</keyname><forenames>Zhaohui</forenames></author><author><keyname>Xu</keyname><forenames>Wei</forenames></author><author><keyname>Shikh-Bahaei</keyname><forenames>Mohammad</forenames></author></authors><title>Joint Time-Frequency Splitting for Multiuser SWIPT OFDM Networks</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we propose a joint time-frequency splitting (TFS) strategy for
a multiuser orthogonal frequency division multiplexing (OFDM) system with
simultaneous wireless information and power transfer (SWIPT). In TFS, the time
sharing factors for each user on different subcarriers are optimized via
maximizing the sum rate of users with both information and energy quality of
service (QoS) constraints. Though the original problem is nonconvex, we first
transform it into an equivalent convex problem through an appropriate variable
transformation. Then, we present an iterative algorithm based on semi closed
form with low complexity. Numerical results show that the proposed TFS
outperforms the conventional time-sharing and subcarrier-separation strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03078</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03078</id><created>2019-02-08</created><authors><author><keyname>Bi</keyname><forenames>Siguo</forenames></author><author><keyname>Fang</keyname><forenames>Zhaoxi</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaojun</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author></authors><title>Joint Base Station Activation and Coordinated Downlink Beamforming for
  HetNets: Efficient Optimal and Suboptimal Algorithms</title><categories>eess.SP</categories><comments>11 pages, 5 figures, this paper has been submitted to TVT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cellular heterogeneous networks (HetNets), a number of distributed base
stations cooperatively provide services to multiple mobile users. This paper
addresses joint base-station activation and coordinated beamforming design for
downlink transmission in HetNets. To this end, a mixed integer program is
formulated to optimize the total power consumption of a HetNet. A novel
approach based on Benders' decomposition is then put forth to obtain the
optimal solution for the problem of interest with guaranteed convergence.
Building on our new formulation, a dual-subgradient algorithm is also proposed
to find an approximate solution in polynomial time. The proposed approaches can
be generalized to more general setups, including robust beamforming designs
under channel uncertainty, and coordinated beamforming for multi-cell
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03083</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03083</id><created>2019-02-07</created><authors><author><keyname>Kreuk</keyname><forenames>Felix</forenames></author><author><keyname>Adi</keyname><forenames>Yossi</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author><author><keyname>Singh</keyname><forenames>Rita</forenames></author><author><keyname>Keshet</keyname><forenames>Joseph</forenames></author></authors><title>Hide and Speak: Deep Neural Networks for Speech Steganography</title><categories>cs.SD cs.CR cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Steganography is the science of hiding a secret message within an ordinary
public message, which referred to as Carrier. Traditionally, digital signal
processing techniques, such as least significant bit encoding, were used for
hiding messages. In this paper, we explore the use of deep neural networks as
steganographic functions for speech data. To this end, we propose to jointly
optimize two neural networks: the first network encodes the message inside a
carrier, while the second network decodes the message from the modified
carrier. We demonstrated the effectiveness of our method on several speech
data-sets and analyzed the results quantitatively and qualitatively. Moreover,
we showed that our approach could be applied to conceal multiple messages in a
single carrier using multiple decoders or a single conditional decoder.
Qualitative experiments suggest that modifications to the carrier are
unnoticeable by human listeners and that the decoded messages are highly
intelligible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03123</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03123</id><created>2019-02-07</created><authors><author><keyname>Darmanovic</keyname><forenames>Radoje</forenames></author><author><keyname>Bulatovic</keyname><forenames>Tamara</forenames></author><author><keyname>Salkovic</keyname><forenames>Seid</forenames></author></authors><title>Iris Image Processing in Compressive Sensing Scenario</title><categories>eess.IV cs.MM</categories><comments>Student paper submitted to The 8th Mediterranean Conference on
  Embedded Computing - MECO'2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper observes the application of the Compressive Sensing in
reconstruction of the under-sampled iris images. Iris recognition represents
form of biometric identification whose usage in real applications is growing.
Compressive Sensing represents a novel form of sparse signal acquisition and
recovering when small amount of data is a available. Different sparsity domains
are considered and compared using various number of available image pixels. The
theory is verified on iris images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03171</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03171</id><created>2019-02-02</created><authors><author><keyname>Mellah</keyname><forenames>Hacene</forenames></author><author><keyname>Hemsas</keyname><forenames>Kamel Eddoine</forenames></author><author><keyname>Taleb</keyname><forenames>Rachid</forenames></author><author><keyname>CECATI</keyname><forenames>carlo</forenames></author></authors><title>Estimation of speed, armature temperature and resistance in brushed DC
  machines using a CFNN based on BFGS BP</title><categories>eess.SP</categories><journal-ref>Turk J Elec Eng &amp; Comp Sci 26 (2018) 3181-3191</journal-ref><doi>10.3906/elk-1711-330</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, a sensorless speed and armature resistance and temperature
estimator for Brushed (B) DC machines is proposed, based on a Cascade-Forward
Neural Network (CFNN) and Quasi-Newton BFGS backpropagation (BP). Since we wish
to avoid the use of a thermal sensor, a thermal model is needed to estimate the
temperature of the BDC machine. Previous studies propose either non-intelligent
estimators which depend on the model, such as the Extended Kalman Filter (EKF)
and Luenberger's observer, or estimators which do not estimate the speed,
temperature and resistance simultaneously. The proposed method has been
verified both by simulation and by comparison with the simulation results
available in the literature
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03173</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03173</id><created>2019-01-15</created><authors><author><keyname>Balti</keyname><forenames>Elyes</forenames></author><author><keyname>Guizani</keyname><forenames>Mohsen</forenames></author><author><keyname>Hamdaoui</keyname><forenames>Bechir</forenames></author></authors><title>Hybrid Rayleigh and Double-Weibull over Impaired RF/FSO System with
  Outdated CSI</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present a global framework of a dual-hop RF/FSO system with
multiple relays operating at the mode of amplify-and-forward (AF) with fixed
gain. Partial relay selection (PRS) protocol with outdated channel state
information (CSI) is assumed since the channels of the first hop are
time-varying. The optical irradiance of the second hop are subject to the
Double-Weibull model while the RF channels of the first hop experience the
Rayleigh fading. The signal reception is achieved either by heterodyne or
intensity modulation and direct detection (IM/DD). In addition, we introduce an
aggregate model of hardware impairments to the source (S) and the relays since
they are not perfect nodes. In order to quantify the impairment impact on the
system, we derive closed-form, approximate, upper bound and high
signal-to-noise ratio (SNR) asymptotic of the outage probability (OP) and the
ergodic capacity (EC). Finally, analytical and numerical results are in
agreement using Monte Carlo simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03174</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03174</id><created>2019-01-15</created><authors><author><keyname>Balti</keyname><forenames>Elyes</forenames></author><author><keyname>Guizani</keyname><forenames>Mohsen</forenames></author></authors><title>Mixed RF/FSO Cooperative Relaying Systems with Co-Channel Interference</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide a global framework analysis of a dual-hop mixed
Radio Frequency (RF)/Free Space Optical (FSO) system with multiple
branches/relays wherein the first and second hops, respectively, consist of RF
and FSO channels. To cover various cases of fading, we propose generalized
channels' models for RF and FSO links that follow the Nakagami-m and the Double
Generalized Gamma (DGG) distributions, respectively. Moreover, we suggest
Channel State Information (CSI)-assisted relaying or variable relaying gain
based Amplifiy-and-Forward (AF) amplification. Partial relay selection with
outdated CSI is assumed as a relay selection protocol based on the knowledge of
the RF CSI. In order to derive the end-to-end Signal-to-Interference-plus-Noise
Ratio (SINR) statistics such as the Cumulative Distribution Function (CDF), the
Probability Density Function (PDF), the higher order moments, the amount of
fading and the Moment Generating Function (MGF), the numerical values of the
fading severity parameters are only valid for integer values. Based on these
statistics, we derive closed-forms of the outage probability, the bit error
probability, the ergodic capacity and the outage capacity in terms of Meijer-G,
univariate, bivariate and trivariate Fox-H functions. Capitalizing on these
expressions, we derive the asymptotic high SNR to unpack valuable engineering
insights of the system performance. Monte Carlo simulation is used to confirm
the analytical expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03176</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03176</id><created>2019-01-15</created><authors><author><keyname>Balti</keyname><forenames>Elyes</forenames></author><author><keyname>Guizani</keyname><forenames>Mohsen</forenames></author></authors><title>Impact of Non-Linear High-Power Amplifiers on Cooperative Relaying
  Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the impact of the high-power amplifier
non-linear distortion on multiple relay systems by introducing the soft
envelope limiter, traveling wave tube amplifier, and solid-state power
amplifier to the relays. The system employs amplify-and-forward either fixed or
variable gain relaying and uses the opportunistic relay selection with outdated
channel state information to select the best relay. The results show that the
performance loss is small at low rates; however, it is significant for high
rates. In particular, the outage probability and the bit error rate are
saturated by an irreducible floor at high rates. The same analysis is pursued
for the capacity and shows that it is saturated by a detrimental ceiling as the
average signal-to-noise ratio becomes higher. This result contrasts the case of
the ideal hardware where the capacity grows indefinitely. Moreover, the results
show that the capacity ceiling is proportional to the impairment's parameter
and for some special cases the impaired systems practically operate in
acceptable conditions. Closed-forms and high SNR asymptotes of the outage
probability, the bit error rate, and the capacity are derived. Finally,
analytical expressions are validated by the Monte Carlo simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03177</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03177</id><created>2019-01-15</created><authors><author><keyname>Balti</keyname><forenames>Elyes</forenames></author><author><keyname>Guizani</keyname><forenames>Mohsen</forenames></author><author><keyname>Hamdaoui</keyname><forenames>Bechir</forenames></author><author><keyname>Khalfi</keyname><forenames>Bassem</forenames></author></authors><title>Aggregate Hardware Impairments Over Mixed RF/FSO Relaying Systems With
  Outdated CSI</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a dual-hop RF (Radio-Frequency)/FSO (Free-Space
Optical) system with multiple relays employing the Decode-and-Forward (DF) and
Amplify-and-Forward (AF) with a Fixed Gain (FG) relaying scheme. The RF
channels are subject to a Rayleigh distribution while the optical links
experience a unified fading model emcopassing the atmospheric turbulence that
follows the M\'alaga distribution (or also called the
$\mathcal{M}$-distribution), the atmospheric path loss and the pointing error.
Partial relay selection (PRS) with outdated channel state information (CSI) is
proposed to select the candidate relay to forward the signal to the
destination. At the reception, the detection of the signal can be achieved
following either heterodyne or Intensity Modulation and Direct Detection
(IM/DD). Many previous attempts neglected the impact of the hardware
impairments and assumed ideal hardware. This assumption makes sense for low
data rate systems but it would no longer be valid for high data rate systems.
In this work, we propose a general model of hardware impairment to get insight
into quantifying its effects on the system performance. We will demonstrate
that the hardware impairments have small impact on the system performance for
low signal-to-noise ratio (SNR), but it can be destructive at high SNR values.
Furthermore analytical expressions and upper bounds are derived for the outage
probability and ergodic capacity while the symbol error probability is obtained
through the numerical integration method. Capitalizing on these metrics, we
also derive the high SNR asymptotes to get valuable insight into the system
gains such as the diversity and the coding gains. Finally, analytical and
numerical results are presented and validated by Monte Carlo simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03183</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03183</id><created>2019-02-06</created><authors><author><keyname>Delgado</keyname><forenames>Alberto</forenames></author></authors><title>Nonlinear LC Circuit with Josephson Junction</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper illustrates a unified approach, classical circuit and control
theories, to study a nonlinear LC circuit with a current dependent inductance
as model of the Josephson junction, the mathematical analysis is complemented
with simulations to visualize different dynamics under changes in parameters
and inputs. Currently, in quantum computing, superconducting circuits with
Josephson junctions are used as the building blocks of quantum bits or qubits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03190</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03190</id><created>2019-02-08</created><authors><author><keyname>Sun</keyname><forenames>Guangzhi</forenames></author><author><keyname>Zhang</keyname><forenames>Chao</forenames></author><author><keyname>Woodland</keyname><forenames>Phil</forenames></author></authors><title>Speaker diarisation using 2D self-attentive combination of embeddings</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker diarisation systems often cluster audio segments using speaker
embeddings such as i-vectors and d-vectors. Since different types of embeddings
are often complementary, this paper proposes a generic framework to improve
performance by combining them into a single embedding, referred to as a
c-vector. This combination uses a 2-dimensional (2D) self-attentive structure,
which extends the standard self-attentive layer by averaging not only across
time but also across different types of embeddings. Two types of 2D
self-attentive structure in this paper are the simultaneous combination and the
consecutive combination, adopting a single and multiple self-attentive layers
respectively. The penalty term in the original self-attentive layer which is
jointly minimised with the objective function to encourage diversity of
annotation vectors is also modified to obtain not only different local peaks
but also the overall trends in the multiple annotation vectors. Experiments on
the AMI meeting corpus show that our modified penalty term improves the d-
vector relative speaker error rate (SER) by 6% and 21% for d-vector systems,
and a 10% further relative SER reduction can be obtained using the c-vector
from our best 2D self-attentive structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03227</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03227</id><created>2019-02-08</created><authors><author><keyname>Srivastava</keyname><forenames>Sanjana</forenames></author><author><keyname>Ben-Yosef</keyname><forenames>Guy</forenames></author><author><keyname>Boix</keyname><forenames>Xavier</forenames></author></authors><title>Minimal Images in Deep Neural Networks: Fragile Object Recognition in
  Natural Images</title><categories>cs.CV eess.IV</categories><comments>International Conference on Learning Representations (ICLR) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The human ability to recognize objects is impaired when the object is not
shown in full. &quot;Minimal images&quot; are the smallest regions of an image that
remain recognizable for humans. Ullman et al. 2016 show that a slight
modification of the location and size of the visible region of the minimal
image produces a sharp drop in human recognition accuracy. In this paper, we
demonstrate that such drops in accuracy due to changes of the visible region
are a common phenomenon between humans and existing state-of-the-art deep
neural networks (DNNs), and are much more prominent in DNNs. We found many
cases where DNNs classified one region correctly and the other incorrectly,
though they only differed by one row or column of pixels, and were often bigger
than the average human minimal image size. We show that this phenomenon is
independent from previous works that have reported lack of invariance to minor
modifications in object location in DNNs. Our results thus reveal a new failure
mode of DNNs that also affects humans to a much lesser degree. They expose how
fragile DNN recognition ability is for natural images even without adversarial
patterns being introduced. Bringing the robustness of DNNs in natural images to
the human level remains an open challenge for the community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03283</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03283</id><created>2019-02-08</created><authors><author><keyname>Wundervald</keyname><forenames>Bruna D.</forenames></author><author><keyname>Zeviani</keyname><forenames>Walmes M.</forenames></author></authors><title>Machine learning and chord based feature engineering for genre
  prediction in popular Brazilian music</title><categories>cs.IR cs.LG cs.SD eess.AS stat.ML</categories><comments>10 pages, 10 figures, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music genre can be hard to describe: many factors are involved, such as
style, music technique, and historical context. Some genres even have
overlapping characteristics. Looking for a better understanding of how music
genres are related to musical harmonic structures, we gathered data about the
music chords for thousands of popular Brazilian songs. Here, 'popular' does not
only refer to the genre named MPB (Brazilian Popular Music) but to nine
different genres that were considered particular to the Brazilian case. The
main goals of the present work are to extract and engineer harmonically related
features from chords data and to use it to classify popular Brazilian music
genres towards establishing a connection between harmonic relationships and
Brazilian genres. We also emphasize the generalization of the method for
obtaining the data, allowing for the replication and direct extension of this
work. Our final model is a combination of multiple classification trees, also
known as the random forest model. We found that features extracted from
harmonic elements can satisfactorily predict music genre for the Brazilian
case, as well as features obtained from the Spotify API. The variables
considered in this work also give an intuition about how they relate to the
genres.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03375</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03375</id><created>2019-02-09</created><authors><author><keyname>Ahmed</keyname><forenames>I. Zakir</forenames></author><author><keyname>Sadjadpour</keyname><forenames>Hamid</forenames></author><author><keyname>Yousefi</keyname><forenames>Shahram</forenames></author></authors><title>Optimal Bit Allocation Variable-Resolution ADC for Massive MIMO</title><categories>eess.SP cs.IT math.IT</categories><comments>This work has been submitted to the IEEE for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we derive an optimal ADC bit-allocation (BA) condition for a
Single-User (SU) Millimeter wave (mmWave) Massive Multiple-Input
Multiple-Output (Ma-MIMO) receiver equipped with variable-resolution ADCs under
power constraint with the following criteria: (i) Minimizing the Mean Squared
Error (MSE) of the received, quantized and combined symbol vector and (ii)
Maximizing the capacity of the SU mmWave Ma-MIMO channel encompassing hybrid
precoder and combiner. Optimal BA under both criteria results the same. We
jointly design the hybrid combiner based on the SVD of the channel. We
demonstrate improvement of the proposed optimal BA over the BA based on
Minimization of the Mean Square Quantization Error (MSQE). Using Monte-Carlo
simulations, it is shown that the MSE and capacity performance of the proposed
BA is very close to that of the Exhaustive Search (ES). The computational
complexity of the proposed techniques are compared with ES and MQSE BA
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03389</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03389</id><created>2019-02-09</created><authors><author><keyname>Tamaru</keyname><forenames>Hiroki</forenames></author><author><keyname>Saito</keyname><forenames>Yuki</forenames></author><author><keyname>Takamichi</keyname><forenames>Shinnosuke</forenames></author><author><keyname>Koriyama</keyname><forenames>Tomoki</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author></authors><title>Generative Moment Matching Network-based Random Modulation Post-filter
  for DNN-based Singing Voice Synthesis and Neural Double-tracking</title><categories>cs.SD cs.AI cs.LG cs.MM cs.NE eess.AS</categories><comments>5 pages, to appear in IEEE ICASSP 2019 (Paper Code: SLP-P22.11,
  Session: Speech Synthesis III)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a generative moment matching network (GMMN)-based
post-filter that provides inter-utterance pitch variation for deep neural
network (DNN)-based singing voice synthesis. The natural pitch variation of a
human singing voice leads to a richer musical experience and is used in
double-tracking, a recording method in which two performances of the same
phrase are recorded and mixed to create a richer, layered sound. However,
singing voices synthesized using conventional DNN-based methods never vary
because the synthesis process is deterministic and only one waveform is
synthesized from one musical score. To address this problem, we use a GMMN to
model the variation of the modulation spectrum of the pitch contour of natural
singing voices and add a randomized inter-utterance variation to the pitch
contour generated by conventional DNN-based singing voice synthesis.
Experimental evaluations suggest that 1) our approach can provide perceptible
inter-utterance pitch variation while preserving speech quality. We extend our
approach to double-tracking, and the evaluation demonstrates that 2) GMMN-based
neural double-tracking is perceptually closer to natural double-tracking than
conventional signal processing-based artificial double-tracking is.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03427</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03427</id><created>2019-02-09</created><authors><author><keyname>Valenzuela</keyname><forenames>Cristobal</forenames></author><author><keyname>Tobar</keyname><forenames>Felipe</forenames></author></authors><title>Low-pass filtering as Bayesian inference</title><categories>stat.ML cs.LG eess.SP</categories><comments>Accepted at ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a Bayesian nonparametric method for low-pass filtering that can
naturally handle unevenly-sampled and noise-corrupted observations. The
proposed model is constructed as a latent-factor model for time series, where
the latent factors are Gaussian processes with non-overlapping spectra. With
this construction, the low-pass version of the time series can be identified as
the low-frequency latent component, and therefore it can be found by means of
Bayesian inference. We show that the model admits exact training and can be
implemented with minimal numerical approximations. Finally, the proposed model
is validated against standard linear filters on synthetic and real-world time
series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03459</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03459</id><created>2019-02-09</created><authors><author><keyname>Kopaczka</keyname><forenames>Marcin</forenames></author><author><keyname>Schock</keyname><forenames>Justus</forenames></author><author><keyname>Merhof</keyname><forenames>Dorit</forenames></author></authors><title>Super-realtime facial landmark detection and shape fitting by deep
  regression of shape model parameters</title><categories>cs.CV eess.IV</categories><comments>https://github.com/justusschock/shapenet</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for highly efficient landmark detection that combines
deep convolutional neural networks with well established model-based fitting
algorithms. Motivated by established model-based fitting methods such as active
shapes, we use a PCA of the landmark positions to allow generative modeling of
facial landmarks. Instead of computing the model parameters using iterative
optimization, the PCA is included in a deep neural network using a novel layer
type. The network predicts model parameters in a single forward pass, thereby
allowing facial landmark detection at several hundreds of frames per second.
Our architecture allows direct end-to-end training of a model-based landmark
detection method and shows that deep neural networks can be used to reliably
predict model parameters directly without the need for an iterative
optimization. The method is evaluated on different datasets for facial landmark
detection and medical image segmentation. PyTorch code is freely available at
https://github.com/justusschock/shapenet
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03489</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03489</id><created>2019-02-09</created><updated>2019-02-16</updated><authors><author><keyname>Habibi</keyname><forenames>Mohammad</forenames></author><author><keyname>Ayatollahi</keyname><forenames>Ahmad</forenames></author><author><keyname>Dallalazar</keyname><forenames>Niyoosha</forenames></author><author><keyname>Kermani</keyname><forenames>Ali</forenames></author></authors><title>Lumen boundary detection using neutrosophic c-means in IVOCT images</title><categories>eess.IV cs.LG</categories><comments>Accepted on knowledge_based engineering and innovation (KBEI 2019), 6
  pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel method for lumen boundary identification is proposed
using Neutrosophic c_means. This method clusters pixels of the intravascular
optical coherence tomography image into several clusters using indeterminacy
and Neutrosophic theory, which aims to detect the boundaries. Intravascular
optical coherence tomography images are cross-sectional and high-resolution
images which are taken from the coronary arterial wall. Coronary Artery Disease
cause a lot of death each year. The first step for diagnosing this kind of
diseases is to detect lumen boundary. Employing this approach, we obtained
0.972, 0.019, 0.076 mm2, 0.32 mm, and 0.985 as mean value for Jaccard measure
(JACC), the percentage of area difference (PAD), average distance (AD),
Hausdorff distance (HD), and dice index (DI), respectively. Based on our
results, this method enjoys high accuracy performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03492</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03492</id><created>2019-02-09</created><authors><author><keyname>Gupchup</keyname><forenames>Jayant</forenames></author><author><keyname>Sharma</keyname><forenames>Abhishek</forenames></author><author><keyname>Terzis</keyname><forenames>Andreas</forenames></author><author><keyname>Burns</keyname><forenames>Randal</forenames></author><author><keyname>Szalay</keyname><forenames>Alex</forenames></author></authors><title>The Perils of Detecting Measurement Faults in Environmental Monitoring
  Networks</title><categories>eess.SP</categories><journal-ref>Proceedings of the ProSense Special Session and International
  Workshop on Wireless Sensor Network Deployments (WiDeploy), held at DCOSS
  2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scientists deploy environmental monitoring net-works to discover previously
unobservable phenomena and quantify subtle spatial and temporal differences in
the physical quantities they measure. Our experience, shared by others, has
shown that measurements gathered by such networks are perturbed by sensor
faults. In response, multiple fault detection techniques have been proposed in
the literature. However, in this paper we argue that these techniques may
misclassify events (e.g. rain events for soil moisture measurements) as faults,
potentially discarding the most interesting measurements. We support this
argument by applying two commonly used fault detection techniques on data
collected from a soil monitoring network. Our results show that in this case,
up to 45% of the event measurements are misclassified as faults. Furthermore,
tuning the fault detection algorithms to avoid event misclassification, causes
them to miss the majority of actual faults. In addition to exposing the tension
between fault and event detection, our findings motivate the need to develop
novel fault detection mechanisms which incorporate knowledge of the underlying
events and are customized to the sensing modality they monitor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03493</identifier>
 <datestamp>2019-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03493</id><created>2019-02-09</created><updated>2019-05-29</updated><authors><author><keyname>Li</keyname><forenames>Yuelong</forenames></author><author><keyname>Tofighi</keyname><forenames>Mohammad</forenames></author><author><keyname>Geng</keyname><forenames>Junyi</forenames></author><author><keyname>Monga</keyname><forenames>Vishal</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Deep Algorithm Unrolling for Blind Image Deblurring</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind image deblurring remains a topic of enduring interest. Learning based
approaches, especially those that employ neural networks have emerged to
complement traditional model based methods and in many cases achieve vastly
enhanced performance. That said, neural network approaches are generally
empirically designed and the underlying structures are difficult to interpret.
In recent years, a promising technique called algorithm unrolling has been
developed that has helped connect iterative algorithms such as those for sparse
coding to neural network architectures. However, such connections have not been
made yet for blind image deblurring. In this paper, we propose a neural network
architecture based on this idea. We first present an iterative algorithm that
may be considered as a generalization of the traditional total-variation
regularization method in the gradient domain. We then unroll the algorithm to
construct a neural network for image deblurring which we refer to as Deep
Unrolling for Blind Deblurring (DUBLID). Key algorithm parameters are learned
with the help of training images. Our proposed deep network DUBLID achieves
significant practical performance gains while enjoying interpretability at the
same time. Extensive experimental results show that DUBLID outperforms many
state-of-the-art methods and in addition is computationally faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03558</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03558</id><created>2019-02-10</created><authors><author><keyname>Sahba</keyname><forenames>Farshid</forenames></author><author><keyname>Sahba</keyname><forenames>Amin</forenames></author><author><keyname>Sahba</keyname><forenames>Ramin</forenames></author></authors><title>Helping Blind People in Their Meeting Locations to Find Each Other Using
  RFID Technology</title><categories>eess.SP cs.CY</categories><comments>5 pages, 6 figures, Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>International Journal of Computer Science and Information Security
  (IJCSIS), Vol. 16, No. 12, December 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new specific system based on RFID technology to help
blind people find the other party in their meeting place. This system, uses a
device called Smart Director or SD, equipped with Active Tag and RFID Reader.
The blind person, the visitor, adjusts the SD with the identification number of
the other party who has shared it previously for example on a telephone call,
and takes the device to the meeting place. When the blind person arrives at the
location, the reader of the device receives signals from the active tag of the
other party's SD. It then identifies his/her position based on the intensity
and direction of the received signals and tell it to the blind person. In this
way, blind people can simply identify the position of the other party in
crowded places and find each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03569</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03569</id><created>2019-02-10</created><updated>2019-02-17</updated><authors><author><keyname>Bialer</keyname><forenames>Oded</forenames></author><author><keyname>Garnett</keyname><forenames>Noa</forenames></author><author><keyname>Tirer</keyname><forenames>Tom</forenames></author></authors><title>Performance Advantages of Deep Neural Networks for Angle of Arrival
  Estimation</title><categories>eess.SP cs.LG cs.SD eess.AS stat.ML</categories><comments>Accepted to ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of estimating the number of sources and their angles of arrival
from a single antenna array observation has been an active area of research in
the signal processing community for the last few decades. When the number of
sources is large, the maximum likelihood estimator is intractable due to its
very high complexity, and therefore alternative signal processing methods have
been developed with some performance loss. In this paper, we apply a deep
neural network (DNN) approach to the problem and analyze its advantages with
respect to signal processing algorithms. We show that an appropriate designed
network can attain the maximum likelihood performance with feasible complexity
and outperform other feasible signal processing estimation methods over various
signal to noise ratios and array response inaccuracies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03578</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03578</id><created>2019-02-10</created><authors><author><keyname>D'Andrea</keyname><forenames>Carmen</forenames></author><author><keyname>Garcia-Rodriguez</keyname><forenames>Adrian</forenames></author><author><keyname>Geraci</keyname><forenames>Giovanni</forenames></author><author><keyname>Giordano</keyname><forenames>Lorenzo Galati</forenames></author><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author></authors><title>Cell-free Massive MIMO for UAV Communications</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to 2019 ICC Workshop on &quot;Integrating UAVs into 5G and
  Beyond&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study support for unmanned aerial vehicle (UAV) communications through a
cell-free massive MIMO architecture. Under the general assumption that the
propagation channel between the mobile stations, either UAVs or ground users,
and the access points follows a Ricean distribution, we derive closed form
spectral efficiency lower bounds for uplink and downlink with linear minimum
mean square error (LMMSE) channel estimation. We also propose power allocation
and user scheduling strategies for such a system. Our numerical results reveal
that a cell-free massive MIMO architecture may provide better performance than
a traditional multicell massive MIMO network deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03582</identifier>
 <datestamp>2019-03-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03582</id><created>2019-02-10</created><updated>2019-03-09</updated><authors><author><keyname>Yue</keyname><forenames>Xingzhi</forenames></author><author><keyname>Dimitriou</keyname><forenames>Neofytos</forenames></author><author><keyname>Arandjelovic</keyname><forenames>Ognjen</forenames></author></authors><title>Colorectal Cancer Outcome Prediction from H&amp;E Whole Slide Images using
  Machine Learning and Automatically Inferred Phenotype Profiles</title><categories>eess.IV cs.CV</categories><comments>2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital pathology (DP) is a new research area which falls under the broad
umbrella of health informatics. Owing to its potential for major public health
impact, in recent years DP has been attracting much research attention.
Nevertheless, a wide breadth of significant conceptual and technical challenges
remain, few of them greater than those encountered in the field of oncology.
The automatic analysis of digital pathology slides of cancerous tissues is
particularly problematic due to the inherent heterogeneity of the disease,
extremely large images, amongst numerous others. In this paper we introduce a
novel machine learning based framework for the prediction of colorectal cancer
outcome from whole digitized haematoxylin &amp; eosin (H&amp;E) stained histopathology
slides. Using a real-world data set we demonstrate the effectiveness of the
method and present a detailed analysis of its different elements which
corroborate its ability to extract and learn salient, discriminative, and
clinically meaningful content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03705</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03705</id><created>2019-02-10</created><updated>2019-09-17</updated><authors><author><keyname>Tian</keyname><forenames>Xiaohai</forenames></author><author><keyname>Chng</keyname><forenames>Eng Siong</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author></authors><title>A Vocoder-free WaveNet Voice Conversion with Non-Parallel Data</title><categories>eess.AS cs.SD</categories><comments>5 pages, 4 figures, This paper is submitted to INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a typical voice conversion system, vocoder is commonly used for
speech-to-features analysis and features-to-speech synthesis. However, vocoder
can be a source of speech quality degradation. This paper presents a
vocoder-free voice conversion approach using WaveNet for non-parallel training
data. Instead of dealing with the intermediate features, the proposed approach
utilizes the WaveNet to map the Phonetic PosteriorGrams (PPGs) to the waveform
samples directly. In this way, we avoid the estimation errors caused by vocoder
and feature conversion. Additionally, as PPG is assumed to be speaker
independent, the proposed method also reduces the feature mismatch problem in
WaveNet vocoder based approaches. Experimental results conducted on the
CMU-ARCTIC database show that the proposed approach significantly outperforms
the baseline approaches in terms of speech quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03844</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03844</id><created>2019-02-11</created><updated>2019-08-26</updated><authors><author><keyname>Saeed</keyname><forenames>Nasir</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Towards the Internet of Underground Things: A Systematic Survey</title><categories>eess.SP cs.NI</categories><comments>IEEE Communication Surveys &amp; Tutorials</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides recent advances in the area of Internet of Underground
Things (IoUT) with emphasis on enabling communication technologies, networking
issues, and localization techniques. IoUT is enabled by underground things
(sensors), communication technology, and networking protocols. This new
paradigm of IoUT facilitates the integration of sensing and communication in
the underground environment for various industries such as oil and gas,
agriculture, seismic mapping, and border monitoring. These applications require
to gather relevant information from the deployed underground things. However,
the harsh underground propagation environment including sand, rock, and
watersheds do not allow the use of single communication technology for
information transfer between the surface and the underground things. Therefore,
various wireless and wired communication technologies are used for underground
communication. The wireless technologies are based on acoustic waves,
electromagnetic waves, magnetic induction and visible light communication while
the wired technologies use coaxial cable and optical fibers. In this paper,
state-of-art communication technologies are surveyed, and the respective
networking and localization techniques for IoUT are presented. Moreover, the
advances and applications of IoUT are also reported. Also, new research
challenges for the design and implementation of IoUT are identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03894</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03894</id><created>2019-01-15</created><authors><author><keyname>Balti</keyname><forenames>Elyes</forenames></author><author><keyname>Guizani</keyname><forenames>Mohsen</forenames></author><author><keyname>Hamdaoui</keyname><forenames>Bechir</forenames></author><author><keyname>Khalfi</keyname><forenames>Bassem</forenames></author></authors><title>Mixed RF/FSO Relaying Systems with Hardware Impairments</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1901.04249</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we provide a detailed analysis of a dual-hop fixed gain (FG)
amplify-and-forward relaying system, consisting of a hybrid radio frequency
(RF) and free-space optical (FSO) channels. We introduce an impairment model
which is the soft envelope limiter (SEL). Additionally, we propose the partial
relay selection (PRS) protocol with outdated channel state information (CSI)
based on the knowledge of the RF channels in order to select one relay for the
communication. Moreover, the RF channels of the first hop experience Rayleigh
fading while we propose a unified fading model for the FSO channels, called the
unified Gamma Gamma (GG), taking into account the atmospheric turbulence, the
path loss and the misalignment between the transmitter and the receiver
aperture also called the pointing error. Novel closed-forms of the outage
probability (OP), the bit error probability (BEP) and the average ergodic
capacity (EC) are derived in terms of Meijer-G and Fox-H functions.
Capitalizing on these metrics, we also derive the asymptotical high
signal-to-noise ratio (SNR) in order to get engineering insights into the
impacts of the hardware impairments and the system parameters as well. Finally,
using Monte Carlo simulations, we validate numerically the derived mathematical
formulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03906</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03906</id><created>2019-02-08</created><authors><author><keyname>Morsi</keyname><forenames>Rania</forenames></author></authors><title>Investigations on Increased Data rate Differential Space-Time Block
  Codes for Single Carrier Wireless Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>This Master thesis is done in Ulm University, Germany, in November
  2010. It includes 146 pages, 42 figures, and 10 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this thesis, we study differential modulation schemes which do not need
channel knowledge at the transmitter nor at the receiver. First, we consider
single-antenna systems and investigate the use of Differential Amplitude Phase
Shift Keying (DAPSK) modulation. We study the use of Multiple-Symbol
Differential Detection (MSDD) to bridge the performance gap between coherent
and non-coherent systems and remove the error floor associated with fast-fading
channels. Second, we consider multi-antenna systems to combat fading and
improve the transmission reliability. The resulting performance improvement
(known as diversity) does not require additional bandwidth nor power. Achieving
diversity using multiple antennas at the receiver (receive diversity) is proved
to be a much simpler task than using multiple antennas at the transmitter
(transmit diversity). However, in downlink mobile communications, mounting
multiple antennas on the receiving mobile handsets results in an increase in
the size and cost of mobiles. This motivates the need of transmit diversity,
which can be achieved by a technique known as Space-Time Coding (STC). In this
thesis, we investigate a class of ST codes known as Orthogonal Space-Time Block
Codes (OSTBC), which achieves a good performance with linear decoding
complexity. As an attempt to increase the data rate, the orthogonality
requirement of OSTBCs is relaxed leading to the so-called Quasi-Orthogonal
STBCs (QOSTBC). Recently a new class of QOSTBCs known as Minimum Decoding
Complexity QOSTBCs (MDC-QOSTBC) has proved to increase the data rate with the
same complexity requirement of OSTBCs. In this thesis, we propose the use of
MDC-QOSTBC in differential non-coherent systems and show that their performance
is remarkably better than that of differential OSTBCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03920</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03920</id><created>2019-02-08</created><updated>2019-05-21</updated><authors><author><keyname>Kandel</keyname><forenames>Saugat</forenames></author><author><keyname>Maddali</keyname><forenames>S.</forenames></author><author><keyname>Allain</keyname><forenames>Marc</forenames></author><author><keyname>Hruszkewycz</keyname><forenames>Stephan O.</forenames></author><author><keyname>Jacobsen</keyname><forenames>Chris</forenames></author><author><keyname>Nashed</keyname><forenames>Youssef S G</forenames></author></authors><title>Using Automatic Differentiation as a General Framework for Ptychographic
  Reconstruction</title><categories>eess.IV physics.optics</categories><comments>23 pages (including references and supplemental material), 19
  externally generated figure files</comments><doi>10.1364/OE.27.018653</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coherent diffraction imaging methods enable imaging beyond lens-imposed
resolution limits. In these methods, the object can be recovered by minimizing
an error metric that quantifies the difference between diffraction patterns as
observed, and those calculated from a present guess of the object. Efficient
minimization methods require analytical calculation of the derivatives of the
error metric, which is not always straightforward. This limits our ability to
explore variations of basic imaging approaches. In this paper, we propose to
substitute analytical derivative expressions with the automatic differentiation
method, whereby we can achieve object reconstruction by specifying only the
physics-based experimental forward model. We demonstrate the generality of the
proposed method through straightforward object reconstruction for a variety of
complex ptychographic experimental models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03926</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03926</id><created>2019-02-08</created><authors><author><keyname>Leglaive</keyname><forenames>Simon</forenames></author><author><keyname>Simsekli</keyname><forenames>Umut</forenames></author><author><keyname>Liutkus</keyname><forenames>Antoine</forenames></author><author><keyname>Girin</keyname><forenames>Laurent</forenames></author><author><keyname>Horaud</keyname><forenames>Radu</forenames></author></authors><title>Speech enhancement with variational autoencoders and alpha-stable
  distributions</title><categories>cs.SD eess.AS stat.ML</categories><comments>5 pages, 3 figures, audio examples and code available online :
  https://team.inria.fr/perception/research/icassp2019-asvae/. arXiv admin
  note: text overlap with arXiv:1811.06713</comments><report-no>hal-02005106</report-no><journal-ref>IEEE International Conference on Acoustics Speech and Signal
  Processing (ICASSP), Brighton, UK, May 2019, pp. 541-545</journal-ref><doi>10.1109/ICASSP.2019.8682546</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on single-channel semi-supervised speech enhancement. We
learn a speaker-independent deep generative speech model using the framework of
variational autoencoders. The noise model remains unsupervised because we do
not assume prior knowledge of the noisy recording environment. In this context,
our contribution is to propose a noise model based on alpha-stable
distributions, instead of the more conventional Gaussian non-negative matrix
factorization approach found in previous studies. We develop a Monte Carlo
expectation-maximization algorithm for estimating the model parameters at test
time. Experimental results show the superiority of the proposed approach both
in terms of perceptual quality and intelligibility of the enhanced speech
signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03927</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03927</id><created>2019-02-08</created><updated>2019-08-25</updated><authors><author><keyname>Baroudi</keyname><forenames>Uthman</forenames></author><author><keyname>Al-Roubaiey</keyname><forenames>Anas</forenames></author><author><keyname>Devendiran</keyname><forenames>Abdullah</forenames></author></authors><title>Pipeline Leak Detection Systems and Data Fusion: A Survey</title><categories>eess.SP</categories><journal-ref>in IEEE Access, vol. 7, pp. 97426-97439, 2019</journal-ref><doi>10.1109/ACCESS.2019.2928487</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pipeline leakage problem is a very challenging and critical issue.
Solving this problem will save the nation a lot of money, resources and more
importantly, it will save the environment. This paper discusses the
state-of-the-art of leak detection systems (LDSs) and data fusion approaches
that are applicable to pipeline monitoring. A comparison of LDSs is performed
based on well-defined criteria. We have classified and critically reviewed
these techniques. A thorough analysis and comparison of all the recent works
have been provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03956</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03956</id><created>2019-02-11</created><authors><author><keyname>Liu</keyname><forenames>Kae-An</forenames></author><author><keyname>Sarris</keyname><forenames>Costas D.</forenames></author></authors><title>Efficient Computation of High-Order Electromagnetic Field Derivatives
  for Multiple Design Parameters in FDTD</title><categories>eess.SP cs.CE</categories><doi>10.1109/TMTT.2019.2929046</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new computational framework to derive electromagnetic
field derivatives with respect to multiple design parameters up to any order
with the Finite-Difference Time-Domain (FDTD) technique. Specifically, only one
FDTD simulation is needed to compute the first-order field derivatives with
respect to N parameters, while two FDTD simulations are needed to compute the
field derivatives with respect to one parameter up to any order. The field
derivatives with respect to N parameters up to any order are computed with
(N+1) FDTD runs. In addition to its efficiency, this framework is based on a
subtractive cancellation error-free approach, providing guaranteed accuracy
toward the computation of field derivatives up to any order. With high-order
field derivatives available, sensitivity analysis, parametric modelling and
uncertainty quantification can be accurately performed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03978</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03978</id><created>2019-02-11</created><authors><author><keyname>Chen</keyname><forenames>Muyuan</forenames></author><author><keyname>Bell</keyname><forenames>James M.</forenames></author><author><keyname>Shi</keyname><forenames>Xiaodong</forenames></author><author><keyname>Sun</keyname><forenames>Stella Y.</forenames></author><author><keyname>Wang</keyname><forenames>Zhao</forenames></author><author><keyname>Ludtke</keyname><forenames>Steven J.</forenames></author></authors><title>A complete data processing workflow for CryoET and subtomogram averaging</title><categories>q-bio.QM eess.IV</categories><comments>21 pages, 4+2 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Electron cryotomography (CryoET) is currently the only method capable of
visualizing cells in 3D at nanometer resolutions. While modern instruments
produce massive amounts of tomography data containing extremely rich structural
information, the data processing is very labor intensive and results are often
limited by the skills of the personnel rather than the data. We present an
integrated workflow that covers the entire tomography data processing pipeline,
from automated tilt series alignment to subnanometer resolution subtomogram
averaging. This workflow greatly reduces human effort and increases throughput,
and is capable of determining protein structures at state-of-the-art
resolutions for both purified macromolecules and cells.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03988</identifier>
 <datestamp>2019-04-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03988</id><created>2019-02-08</created><updated>2019-03-30</updated><authors><author><keyname>Sadrizadeh</keyname><forenames>Sahar</forenames></author><author><keyname>Zarmehi</keyname><forenames>Nematollah</forenames></author><author><keyname>Asadi</keyname><forenames>Ehsan</forenames></author><author><keyname>Abin</keyname><forenames>Hamidreza</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>A Fast Iterative Method for Removing Impulsive Noise from Sparse Signals</title><categories>eess.SP cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new method to reconstruct a signal corrupted by
noise where both signal and noise are sparse but in different domains. The
problem investigated in this paper arises in different applications such as
impulsive noise removal from images, audios and videos, decomposition of
low-rank and sparse components of matrices, and separation of texts from
images. First, we provide a cost function for our problem and then present an
iterative method to find its local minimum. The analysis of the algorithm is
also provided. As an application of this problem, we apply our algorithm for
impulsive noise Salt-and-Pepper noise (SPN) and Random-Valued Impulsive Noise
(RVIN)) removal from images and compare our results with other notable
algorithms in the literature. Furthermore, we apply our algorithm for removing
clicks from audio signals. Simulation results show that our algorithms is
simple and fast, and it outperforms other state-of-the-art methods in terms of
reconstruction quality and/or complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03989</identifier>
 <datestamp>2019-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03989</id><created>2019-02-05</created><authors><author><keyname>Dumphart</keyname><forenames>Gregor</forenames></author><author><keyname>Bitachon</keyname><forenames>Bertold Ian</forenames></author><author><keyname>Wittneben</keyname><forenames>Armin</forenames></author></authors><title>Magneto-Inductive Powering and Uplink of In-Body Microsensors:
  Feasibility and High-Density Effects</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, to appear at IEEE WCNC 2019. This work has been submitted to
  the IEEE for possible publication. Copyright may be transferred without
  notice, after which this version may no longer be accessible</comments><doi>10.1109/WCNC.2019.8885956</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies magnetic induction for wireless powering and the data
uplink of microsensors, in particular for future medical in-body applications.
We consider an external massive coil array as power source (1 W) and data sink.
For sensor devices at 12 cm distance from the array, e.g. beneath the human
skin, we compute a minimum coil size of 150 um assuming 50 nW required chip
activation power and operation at 750 MHz. A 275 um coil at the sensor allows
for 1 Mbit/s uplink rate. Moreover, we study resonant sensor nodes in dense
swarms, a key aspect of envisioned biomedical applications. In particular, we
investigate the occurring passive relaying effect and cooperative transmit
beamforming in the uplink. We show that the frequency- and location-dependent
signal fluctuations in such swarms allow for significant performance gains when
utilized with adaptive matching, spectrally-aware signaling and node
cooperation. The work is based on a general magneto-inductive MIMO system
model, which is introduced first.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03990</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.03990</id><created>2019-02-11</created><authors><author><keyname>Aldalahmeh</keyname><forenames>Sami A.</forenames></author><author><keyname>Al-Jazzar</keyname><forenames>Saleh O.</forenames></author><author><keyname>McLernon</keyname><forenames>Des</forenames></author><author><keyname>Zaidi</keyname><forenames>Syed Ali Raza</forenames></author><author><keyname>Ghogho</keyname><forenames>Mounir</forenames></author></authors><title>Fusion Rules for Distributed Detection in Clustered Wireless Sensor
  Networks with Imperfect Channels</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper we investigate fusion rules for distributed detection in large
random clustered-wireless sensor networks (WSNs) with a three-tier hierarchy;
the sensor nodes (SNs), the cluster heads (CHs) and the fusion center (FC). The
CHs collect the SNs' local decisions and relay them to the FC that then fuses
them to reach the ultimate decision. The SN-CH and the CH-FC channels suffer
from additive white Gaussian noise (AWGN). In this context, we derive the
optimal log-likelihood ratio (LLR) fusion rule, which turns out to be
intractable. So, we develop a sub-optimal linear fusion rule (LFR) that weighs
the cluster's data according to both its local detection performance and the
quality of the communication channels. In order to implement it, we propose an
approximate maximum likelihood based LFR (LFR-aML), which estimates the
required parameters for the LFR. We also derive Gaussian-tail upper bounds for
the detection and false alarms probabilities for the LFR. Furthermore, an
optimal CH transmission power allocation strategy is developed by solving the
Karush-Kuhn-Tucker (KKT) conditions for the related optimization problem.
Extensive simulations show that the LFR attains a detection performance near to
that of the optimal LLR and confirms the validity of the proposed upper bounds.
Moreover, when compared to equal power allocation, simulations show that our
proposed power allocation strategy achieves a significant power saving at the
expense of a small reduction in the detection performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04062</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04062</id><created>2019-02-09</created><authors><author><keyname>Sun</keyname><forenames>Tao</forenames></author><author><keyname>Li</keyname><forenames>Dongsheng</forenames></author><author><keyname>Jiang</keyname><forenames>Hao</forenames></author><author><keyname>Quan</keyname><forenames>Zhe</forenames></author></authors><title>Iteratively reweighted penalty alternating minimization methods with
  continuation for image deblurring</title><categories>math.OC cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a class of nonconvex problems with linear
constraints appearing frequently in the area of image processing. We solve this
problem by the penalty method and propose the iteratively reweighted
alternating minimization algorithm. To speed up the algorithm, we also apply
the continuation strategy to the penalty parameter. A convergence result is
proved for the algorithm. Compared with the nonconvex ADMM, the proposed
algorithm enjoys both theoretical and computational advantages like weaker
convergence requirements and faster speed. Numerical results demonstrate the
efficiency of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04072</identifier>
 <datestamp>2019-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04072</id><created>2019-02-11</created><updated>2019-05-16</updated><authors><author><keyname>Marafioti</keyname><forenames>Andr&#xe9;s</forenames></author><author><keyname>Holighaus</keyname><forenames>Nicki</forenames></author><author><keyname>Perraudin</keyname><forenames>Nathana&#xeb;l</forenames></author><author><keyname>Majdak</keyname><forenames>Piotr</forenames></author></authors><title>Adversarial Generation of Time-Frequency Features with application in
  audio synthesis</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>Accepted for publication at ICML 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Time-frequency (TF) representations provide powerful and intuitive features
for the analysis of time series such as audio. But still, generative modeling
of audio in the TF domain is a subtle matter. Consequently, neural audio
synthesis widely relies on directly modeling the waveform and previous attempts
at unconditionally synthesizing audio from neurally generated invertible TF
features still struggle to produce audio at satisfying quality. In this
article, focusing on the short-time Fourier transform, we discuss the
challenges that arise in audio synthesis based on generated invertible TF
features and how to overcome them. We demonstrate the potential of deliberate
generative TF modeling by training a generative adversarial network (GAN) on
short-time Fourier features. We show that by applying our guidelines, our
TF-based network was able to outperform a state-of-the-art GAN generating
waveforms directly, despite the similar architecture in the two networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04149</identifier>
 <datestamp>2019-03-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04149</id><created>2019-02-11</created><updated>2019-03-07</updated><authors><author><keyname>Talreja</keyname><forenames>Veeru</forenames></author><author><keyname>Soleymani</keyname><forenames>Sobhan</forenames></author><author><keyname>Valenti</keyname><forenames>Matthew C.</forenames></author><author><keyname>Nasrabadi</keyname><forenames>Nasser M.</forenames></author></authors><title>Learning to Authenticate with Deep Multibiometric Hashing and Neural
  Network Decoding</title><categories>cs.CV cs.LG eess.IV</categories><comments>To be published in Proc. IEEE ICC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel multimodal deep hashing neural decoder
(MDHND) architecture, which integrates a deep hashing framework with a neural
network decoder (NND) to create an effective multibiometric authentication
system. The MDHND consists of two separate modules: a multimodal deep hashing
(MDH) module, which is used for feature-level fusion and binarization of
multiple biometrics, and a neural network decoder (NND) module, which is used
to refine the intermediate binary codes generated by the MDH and compensate for
the difference between enrollment and probe biometrics (variations in pose,
illumination, etc.). Use of NND helps to improve the performance of the overall
multimodal authentication system. The MDHND framework is trained in 3 steps
using joint optimization of the two modules. In Step 1, the MDH parameters are
trained and learned to generate a shared multimodal latent code; in Step 2, the
latent codes from Step 1 are passed through a conventional error-correcting
code (ECC) decoder to generate the ground truth to train a neural network
decoder (NND); in Step 3, the NND decoder is trained using the ground truth
from Step 2 and the MDH and NND are jointly optimized. Experimental results on
a standard multimodal dataset demonstrate the superiority of our method
relative to other current multimodal authentication systems
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04154</identifier>
 <datestamp>2019-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04154</id><created>2019-02-11</created><updated>2019-04-09</updated><authors><author><keyname>Jereminov</keyname><forenames>Marko</forenames></author><author><keyname>Hooi</keyname><forenames>Bryan</forenames></author><author><keyname>Pandey</keyname><forenames>Amritanshu</forenames></author><author><keyname>Song</keyname><forenames>Hyun-Ah</forenames></author><author><keyname>Faloutsos</keyname><forenames>Christos</forenames></author><author><keyname>Pileggi</keyname><forenames>Larry</forenames></author></authors><title>Impact of Load Models on Power Flow Optimization</title><categories>eess.SP cs.SY</categories><comments>Accepted for IEEE PES General Meeting, August 2019, Atlanta, GA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aggregated load models, such as PQ and ZIP, are used to represent the
approximated load demand at specific buses in grid simulation and optimization
problems. In this paper we examine the impact of model choice on the optimal
power flow solution and demonstrate that it is possible for different load
models to represent the same amount of real and reactive power at the optimal
solution yet correspond to completely different grid operating points. We
introduce the metric derived from the maximum power transfer theorem to
identify the behavior of an aggregated model in the OPF formulation to indicate
its possible limitations. A dataset from the Carnegie Mellon campus is used to
characterize three types of load models using a time-series machine learning
algorithm, from which the optimal power flow results demonstrate that the
choice of load model type has a significant impact on the solution set points.
For example, our results show that the PQ load accurately characterizes the CMU
data behavior correctly for only 16.7% of the cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04209</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04209</id><created>2019-02-11</created><authors><author><keyname>Wang</keyname><forenames>Kaixiang</forenames></author><author><keyname>Ruppert</keyname><forenames>Michael G.</forenames></author><author><keyname>Manzie</keyname><forenames>Chris</forenames></author><author><keyname>Nesic</keyname><forenames>Dragan</forenames></author><author><keyname>Yong</keyname><forenames>Yuen K.</forenames></author></authors><title>Adaptive Scan for Atomic Force Microscopy Based on Online Optimisation:
  Theory and Experiment</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major challenge in Atomic Force Microscopy (AFM) is to reduce the scan
duration while retaining the image quality. Conventionally, the scan rate is
restricted to a sufficiently small value in order to ensure a desirable image
quality as well as a safe tip-sample contact force. This usually results in a
conservative scan rate for samples that have a large variation in aspect ratio
and/or for scan patterns that have a varying linear velocity. In this paper, an
adaptive scan scheme is proposed to alleviate this problem. A scan line-based
performance metric balancing both imaging speed and accuracy is proposed, and
the scan rate is adapted such that the metric is optimised online in the
presence of aspect ratio and/or linear velocity variations. The online
optimisation is achieved using an extremum-seeking (ES) approach, and a
semi-global practical asymptotic stability (SGPAS) result is shown for the
overall system. Finally, the proposed scheme is demonstrated via both
simulation and experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04219</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04219</id><created>2019-02-11</created><authors><author><keyname>Atapattu</keyname><forenames>Saman</forenames></author><author><keyname>Inaltekin</keyname><forenames>Hazer</forenames></author><author><keyname>Evans</keyname><forenames>Jamie</forenames></author></authors><title>Location-Based Optimum Relay Selection in Random Spatial Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the location-based relay selection problem, where the
source node chooses its relay from a set of spatially deployed
decode-and-forward relays. The advantages of location-based relay selection are
the elimination of excessive relay switching rate and the feedback reduction
avoiding the requirement of having full channel state information at the source
node. For a homogeneous Poisson point process of candidate relays, we first
derive the distribution for the distance of the relay (relative to the source
and destination nodes) selected by the optimum location-based relay selection
policy. This result is independent of the functional form of the path-loss
function as long as it is a non-increasing function of the transmitter-receiver
separation. By utilizing the derived optimum relay distance distribution, we
then obtain analytical expressions for the average rate and outage probability
by considering the power-law decaying path-loss function for the no-fading and
Rayleigh fading communication scenarios. It is observed that the optimum relay
selection policy outperforms the other common selection strategies notably,
including the ones choosing the relay closest to the source, the relay closest
to the destination and the relay closest to the mid-point between source and
destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04236</identifier>
 <datestamp>2019-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04236</id><created>2019-02-11</created><updated>2019-02-20</updated><authors><author><keyname>Ravichandran</keyname><forenames>Vignesh</forenames></author><author><keyname>Murugesan</keyname><forenames>Balamurali</forenames></author><author><keyname>Balakarthikeyan</keyname><forenames>Vaishali</forenames></author><author><keyname>Shankaranarayana</keyname><forenames>Sharath M</forenames></author><author><keyname>Ram</keyname><forenames>Keerthi</forenames></author><author><keyname>P</keyname><forenames>Preejith S.</forenames></author><author><keyname>Joseph</keyname><forenames>Jayaraj</forenames></author><author><keyname>Sivaprakasam</keyname><forenames>Mohanasankar</forenames></author></authors><title>RespNet: A deep learning model for extraction of respiration from
  photoplethysmogram</title><categories>eess.SP cs.CV cs.LG</categories><comments>Under review at EMBC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Respiratory ailments afflict a wide range of people and manifests itself
through conditions like asthma and sleep apnea. Continuous monitoring of
chronic respiratory ailments is seldom used outside the intensive care ward due
to the large size and cost of the monitoring system. While Electrocardiogram
(ECG) based respiration extraction is a validated approach, its adoption is
limited by access to a suitable continuous ECG monitor. Recently, due to the
widespread adoption of wearable smartwatches with in-built Photoplethysmogram
(PPG) sensor, it is being considered as a viable candidate for continuous and
unobtrusive respiration monitoring. Research in this domain, however, has been
predominantly focussed on estimating respiration rate from PPG. In this work, a
novel end-to-end deep learning network called RespNet is proposed to perform
the task of extracting the respiration signal from a given input PPG as opposed
to extracting respiration rate. The proposed network was trained and tested on
two different datasets utilizing different modalities of reference respiration
signal recordings. Also, the similarity and performance of the proposed network
against two conventional signal processing approaches for extracting
respiration signal were studied. The proposed method was tested on two
independent datasets with a Mean Squared Error of 0.262 and 0.145. The
Cross-Correlation coefficient of the respective datasets were found to be 0.933
and 0.931. The reported errors and similarity was found to be better than
conventional approaches. The proposed approach would aid clinicians to provide
comprehensive evaluation of sleep-related respiratory conditions and chronic
respiratory ailments while being comfortable and inexpensive for the patient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04265</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04265</id><created>2019-02-12</created><updated>2019-02-16</updated><authors><author><keyname>Lin</keyname><forenames>Sijie</forenames></author><author><keyname>Xie</keyname><forenames>Xuan</forenames></author><author><keyname>Feng</keyname><forenames>Hui</forenames></author><author><keyname>Hu</keyname><forenames>Bo</forenames></author></authors><title>Active Sampling for Approximately Bandlimited Graph Signals</title><categories>eess.SP</categories><comments>ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the active sampling for estimation of approximately
bandlimited graph signals. With the assistance of a graph filter, an
approximately bandlimited graph signal can be formulated by a Gaussian random
field over the graph. In contrast to offline sampling set design methods which
usually rely on accurate prior knowledge about the model, unknown parameters in
signal and noise distribution are allowed in the proposed active sampling
algorithm. The active sampling process is divided into two alternating stages:
unknown parameters are first estimated by Expectation Maximization (EM), with
which the next node to sample is selected based on historical observations
according to predictive uncertainty. Validated by simulations compared with
related approaches, the proposed algorithm can reduce the sample size to reach
a certain estimation accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04350</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04350</id><created>2019-02-12</created><authors><author><keyname>Dumphart</keyname><forenames>Gregor</forenames></author><author><keyname>Kuhn</keyname><forenames>Marc</forenames></author><author><keyname>Wittneben</keyname><forenames>Armin</forenames></author><author><keyname>Tr&#xf6;sch</keyname><forenames>Florian</forenames></author></authors><title>Inter-Node Distance Estimation from Multipath Delay Differences of
  Channels to Observer Nodes</title><categories>eess.SP stat.AP</categories><comments>To appear at IEEE ICC 2019. This work has been submitted to the IEEE
  for possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible</comments><doi>10.1109/ICC.2019.8761943</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the estimation of distance d between two wireless nodes by means of
their wideband channels to a third node, called observer. The motivating
principle is that the channel impulse responses are similar for small d and
drift apart when d increases. Following this idea we propose specific distance
estimators based on the differences of path delays of the extractable multipath
components. In particular, we derive such estimators for rich multipath
environments and various important cases: with and without clock
synchronization as well as errors on the extracted path delays (e.g. due to
limited bandwidth). The estimators readily support (and benefit from) the
presence of multiple observers. We present an error analysis and, using ray
tracing in an exemplary indoor environment, show that the estimators perform
well in realistic conditions. We describe possible localization applications of
the proposed scheme and highlight its major advantages: it requires neither
precise synchronization nor line-of-sight connection. This could make wireless
user tracking feasible in dynamic indoor settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04383</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04383</id><created>2019-02-12</created><authors><author><keyname>Zhou</keyname><forenames>Qihao</forenames></author><author><keyname>Xing</keyname><forenames>Jinyu</forenames></author><author><keyname>Hou</keyname><forenames>Lu</forenames></author><author><keyname>Xu</keyname><forenames>Rongtao</forenames></author><author><keyname>Zheng</keyname><forenames>Kan</forenames></author></authors><title>A Novel Rate and Channel Control Scheme Based on Data Extraction Rate
  for LoRa Networks</title><categories>eess.SP</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Long Range (LoRa) has become one of the most popular Low Power Wide Area
(LPWA) technologies, which provides a desirable trade-off among communication
range, battery life, and deployment cost. In LoRa networks, several
transmission parameters can be allocated to ensure efficient and reliable
communication. For example, the configuration of the spreading factor allows
tuning the data rate and the transmission distance. However, how to dynamically
adjust the setting that minimizes the collision probability while meeting the
required communication performance is an open challenge. This paper proposes a
novel Data Rate and Channel Control (DRCC) scheme for LoRa networks so as to
improve wireless resource utilization and support a massive number of LoRa
nodes. The scheme estimates channel conditions based on the short-term Data
Extraction Rate (DER), and opportunistically adjusts the spreading factor to
adapt the variation of channel conditions. Furthermore, the channel control is
carried out to balance the link load of all available channels with the global
information of the channel usage, which is able to lower the access collisions
under dense deployments. Our experiments demonstrate that the proposed DRCC
performs well on improving the reliability and capacity compared with other
spreading factor allocation schemes in dense deployment scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04390</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04390</id><created>2019-02-12</created><authors><author><keyname>Kelz</keyname><forenames>Rainer</forenames></author><author><keyname>B&#xf6;ck</keyname><forenames>Sebastian</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Multitask Learning for Polyphonic Piano Transcription, a Case Study</title><categories>cs.SD eess.AS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Viewing polyphonic piano transcription as a multitask learning problem, where
we need to simultaneously predict onsets, intermediate frames and offsets of
notes, we investigate the performance impact of additional prediction targets,
using a variety of suitable convolutional neural network architectures. We
quantify performance differences of additional objectives on the large MAESTRO
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04415</identifier>
 <datestamp>2019-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04415</id><created>2019-02-12</created><updated>2019-02-13</updated><authors><author><keyname>Bandi</keyname><forenames>Ashok</forenames></author><author><keyname>R</keyname><forenames>Bhavani Shankar Mysore</forenames></author><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author><author><keyname>Ottersten</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>A Joint Solution for Scheduling and Precoding in Multiuser MISO Downlink
  Channels</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The long-term average performance of the MISO downlink channel, with a large
number of users compared to transmit antennas of the BS, depends on the
interference management which necessitates the joint design problem of
scheduling and precoding. Unlike the previous works which do not offer a truly
joint design, this paper focuses on formulating a problem amenable for the
joint update of scheduling and precoding. Novel optimization formulations are
investigated to reveal the hidden difference of convex/ concave structure for
three classical criteria (weighted sum rate, max-min SINR, and power
minimization) and associated constraints are considered. Thereafter, we propose
a convex-concave procedure framework based iterative algorithm where scheduling
and precoding variables are updated jointly in each iteration. Finally, we show
the superiority in performance of joint solution over the state-of-the-art
designs through Monte-Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04487</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04487</id><created>2019-02-12</created><updated>2019-07-29</updated><authors><author><keyname>Carmo</keyname><forenames>Diedre</forenames></author><author><keyname>Silva</keyname><forenames>Bruna</forenames></author><author><keyname>Yasuda</keyname><forenames>Clarissa</forenames></author><author><keyname>Rittner</keyname><forenames>Let&#xed;cia</forenames></author><author><keyname>Lotufo</keyname><forenames>Roberto</forenames></author></authors><title>Extended 2D Consensus Hippocampus Segmentation</title><categories>eess.IV cs.CV cs.LG</categories><comments>This was published as an extended abstract in MIDL 2019
  [arXiv:1907.08612]. An alpha version of the code is available at
  https://github.com/dscarmo/e2dhipseg. More experiments on improvements to the
  method and code are ongoing. Future updates are to be expected</comments><report-no>MIDL/2019/ExtendedAbstract/Sygx97DaKV</report-no><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Hippocampus segmentation plays a key role in diagnosing various brain
disorders such as Alzheimer's disease, epilepsy, multiple sclerosis, cancer,
depression and others. Nowadays, segmentation is still mainly performed
manually by specialists. Segmentation done by experts is considered to be a
gold-standard when evaluating automated methods, buts it is a time consuming
and arduos task, requiring specialized personnel. In recent years, efforts have
been made to achieve reliable automated segmentation. For years the best
performing authomatic methods were multi atlas based with around 80-85% Dice
coefficient and very time consuming, but machine learning methods are recently
rising with promising time and accuracy performance. A method for volumetric
hippocampus segmentation is presented, based on the consensus of tri-planar
U-Net inspired fully convolutional networks (FCNNs), with some modifications,
including residual connections, VGG weight transfers, batch normalization and a
patch extraction technique employing data from neighbor patches. A study on the
impact of our modifications to the classical U-Net architecture was performed.
Our method achieves cutting edge performance in our dataset, with around 96%
volumetric Dice accuracy in our test data. In a public validation dataset,
HARP, we achieve 87.48% DICE. GPU execution time is in the order of seconds per
volume, and source code is publicly available. Also, masks are shown to be
similar to other recent state-of-the-art hippocampus segmentation methods in a
third dataset, without manual annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04531</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04531</id><created>2019-02-12</created><updated>2019-02-21</updated><authors><author><keyname>Ndolo</keyname><forenames>Antony</forenames></author><author><keyname>Aldo&#x11f;an</keyname><forenames>K&#x131;v&#x131;lc&#x131;m Y&#xfc;ksel</forenames></author></authors><title>Bending Loss Sensor Using Fibre Loop Ring-Down Technique</title><categories>eess.SP</categories><comments>My co-author is against publication of this preprint. She has
  therefore requested me to withdraw it. It is therefore my desire that this
  paper be withdrawn as she had not given me permission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bending losses are very critical in many application hence should be
monitored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04682</identifier>
 <datestamp>2019-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04682</id><created>2019-02-12</created><authors><author><keyname>Akyildiz</keyname><forenames>Ian F.</forenames></author><author><keyname>Han</keyname><forenames>Chong</forenames></author><author><keyname>Nie</keyname><forenames>Shuai</forenames></author></authors><title>Combating the Distance Problem in the Millimeter Wave and Terahertz
  Frequency Bands</title><categories>eess.SP</categories><journal-ref>IEEE Communications Magazine, vol. 56, no. 6, pp. 102-108, June
  2018</journal-ref><doi>10.1109/MCOM.2018.1700928</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the millimeter wave (30-300 GHz) and Terahertz (0.1-10 THz) frequency
bands, high spreading loss and molecular absorption often limit the signal
transmission distance and coverage range. In this paper, four directions to
tackle the crucial problem of distance limitation are investigated, namely, a
physical layer distance-aware design, ultra-massive MIMO communication,
reflectarrays, and intelligent surfaces. Additionally, the potential joint
design of these technologies is proposed to combine the benefits and possibly
further extend the communication distance. Qualitative analyses and
quantitative simulations are provided to illustrate the benefits of the
proposed techniques and demonstrate the feasibility of mm-wave and THz band
communications up to 100 meters in both line-of-sight and non-line-of-sight
areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04684</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04684</id><created>2019-02-12</created><updated>2019-07-19</updated><authors><author><keyname>Mayer</keyname><forenames>Owen</forenames></author><author><keyname>Stamm</keyname><forenames>Matthew C.</forenames></author></authors><title>Forensic Similarity for Digital Images</title><categories>cs.CV eess.IV</categories><comments>16 pages, Accepted for publication with IEEE T-IFS (IEEE Transactions
  on Information Forensics and Security, 2019)</comments><doi>10.1109/TIFS.2019.2924552</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a new digital image forensics approach called
forensic similarity, which determines whether two image patches contain the
same forensic trace or different forensic traces. One benefit of this approach
is that prior knowledge, e.g. training samples, of a forensic trace are not
required to make a forensic similarity decision on it in the future. To do
this, we propose a two part deep-learning system composed of a CNN-based
feature extractor and a three-layer neural network, called the similarity
network. This system maps pairs of image patches to a score indicating whether
they contain the same or different forensic traces. We evaluated system
accuracy of determining whether two image patches were 1) captured by the same
or different camera model, 2) manipulated by the same or different editing
operation, and 3) manipulated by the same or different manipulation parameter,
given a particular editing operation. Experiments demonstrate applicability to
a variety of forensic traces, and importantly show efficacy on &quot;unknown&quot;
forensic traces that were not used to train the system. Experiments also show
that the proposed system significantly improves upon prior art, reducing error
rates by more than half. Furthermore, we demonstrated the utility of the
forensic similarity approach in two practical applications: forgery detection
and localization, and database consistency verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04721</identifier>
 <datestamp>2019-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04721</id><created>2019-02-12</created><authors><author><keyname>Rahmati</keyname><forenames>Ali</forenames></author><author><keyname>Yap&#x131;c&#x131;</keyname><forenames>Yavuz</forenames></author><author><keyname>Rupasinghe</keyname><forenames>Nadisanka</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author><author><keyname>Bhuyany</keyname><forenames>Arupjyoti</forenames></author></authors><title>Energy Efficiency of RSMA and NOMA in Cellular-Connected mmWave UAV
  Networks</title><categories>eess.SP</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular-connected unmanned aerial vehicles (UAVs) are recently getting
significant attention due to various practical use cases, e.g., surveillance,
data gathering, purchase delivery, among other applications. Since UAVs are low
power nodes, energy and spectral efficient communication is of paramount
importance. To that end, multiple access (MA) schemes can play an important
role in achieving high energy efficiency and spectral efficiency. In this work,
we introduce rate-splitting MA (RSMA) and non-orthogonal MA (NOMA) schemes in a
cellular-connected UAV network. In particular, we investigate the energy
efficiency of the RSMA and NOMA schemes in a millimeter wave (mmWave) downlink
transmission scenario. Furthermore, we optimize precoding vectors of both the
schemes by explicitly taking into account the 3GPP antenna propagation
patterns. The numerical results for this realistic transmission scheme indicate
that RSMA is superior to NOMA in terms of overall energy efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04762</identifier>
 <datestamp>2019-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04762</id><created>2019-02-13</created><authors><author><keyname>Chowdhury</keyname><forenames>Md Moin Uddin</forenames></author><author><keyname>Bulut</keyname><forenames>Eyuphan</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Trajectory Optimization in UAV-Assisted Cellular Networks under Mission
  Duration Constraint</title><categories>eess.SP</categories><comments>Accepted in IEEE Radio Wireless Week 2019, Orlando, FL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of finding the optimal trajectory for
an unmanned aerial vehicle (UAV) for improving the wireless coverage of a
terrestrial cellular network. In particular, we consider a UAV that is tasked
to travel from one point to another within a given time constraint, and it can
also simultaneously assist the cellular network by providing wireless coverage
during its mission. Considering an interference limited downlink of a cellular
network, we formulate an optimization problem for maximizing the
proportional-fair (PF) data rate of the cellular network and explore dynamic
programming (DP) technique for finding the optimum UAV trajectory. We also
explore the optimal UAV trajectories associated with maximum sum-rate and 5th
percentile spectral efficiency (5pSE) rate and compare the capacity and
coverage performance of the three approaches. Numerical simulations show that
the maximum sum-rate trajectory provides the best per user capacity whereas,
the optimal PF trajectory yields higher coverage probability than the other two
trajectories. The optimal trajectories are generally infeasible to follow
exactly as the UAVs can not take sharp turns due to kinematic constraints.
Hence, we generate smooth trajectories using Bezier curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04763</identifier>
 <datestamp>2019-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04763</id><created>2019-02-13</created><authors><author><keyname>Xu</keyname><forenames>Yue</forenames></author><author><keyname>Yin</keyname><forenames>Feng</forenames></author><author><keyname>Xu</keyname><forenames>Wenjun</forenames></author><author><keyname>Lin</keyname><forenames>Jiaru</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Wireless Traffic Prediction with Scalable Gaussian Process: Framework,
  Algorithms, and Verification</title><categories>cs.LG cs.NI eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cloud radio access network (C-RAN) is a promising paradigm to meet the
stringent requirements of the fifth generation (5G) wireless systems.
Meanwhile, wireless traffic prediction is a key enabler for C-RANs to improve
both the spectrum efficiency and energy efficiency through load-aware network
managements. This paper proposes a scalable Gaussian process (GP) framework as
a promising solution to achieve large-scale wireless traffic prediction in a
cost-efficient manner. Our contribution is three-fold. First, to the best of
our knowledge, this paper is the first to empower GP regression with the
alternating direction method of multipliers (ADMM) for parallel hyper-parameter
optimization in the training phase, where such a scalable training framework
well balances the local estimation in baseband units (BBUs) and information
consensus among BBUs in a principled way for large-scale executions. Second, in
the prediction phase, we fuse local predictions obtained from the BBUs via a
cross-validation based optimal strategy, which demonstrates itself to be
reliable and robust for general regression tasks. Moreover, such a
cross-validation based optimal fusion strategy is built upon a well
acknowledged probabilistic model to retain the valuable closed-form GP
inference properties. Third, we propose a C-RAN based scalable wireless
prediction architecture, where the prediction accuracy and the time consumption
can be balanced by tuning the number of the BBUs according to the real-time
system demands. Experimental results show that our proposed scalable GP model
can outperform the state-of-the-art approaches considerably, in terms of
wireless traffic prediction performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04775</identifier>
 <datestamp>2020-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04775</id><created>2019-02-13</created><updated>2019-11-21</updated><authors><author><keyname>Kumari</keyname><forenames>Vineeta</forenames></author><author><keyname>Ahmed</keyname><forenames>Aijaz</forenames></author><author><keyname>Sheoran</keyname><forenames>Gyanendra</forenames></author><author><keyname>Kanumuri</keyname><forenames>Tirupathiraju</forenames></author><author><keyname>shakher</keyname><forenames>Chandra</forenames></author></authors><title>Indirect Microwave Holography with Resolution Enhancement in Metallic
  Imaging</title><categories>eess.IV physics.app-ph</categories><comments>14 pages, 14 figures</comments><journal-ref>Int J RF Microw Comput Aided Eng. 2020;e22185</journal-ref><doi>10.1002/mmce.22185</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of compact indirect microwave holographic set-up by the
implementation of low cost, specifically designed directive antennae as
transmitter and receiver is proposed. Microwave holograms are recorded by 2D
scanning over a plane using motorized translation stage. The recorded
interference pattern i.e. holograms are then processed numerically to
reconstruct the amplitude and phase information employing the angular spectrum
diffraction method. The quality of the reconstructed amplitude image is further
enhanced through the deep neural network, in order to combat with the low
resolution of reconstructed images. The qualitative experimental results
exploit the possibility of developing the miniaturized, and low cost indirect
microwave holographic system for near field applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04845</identifier>
 <datestamp>2019-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04845</id><created>2019-02-13</created><authors><author><keyname>Ahmed</keyname><forenames>Tamim</forenames></author><author><keyname>Hasan</keyname><forenames>Md. Kamrul</forenames></author></authors><title>SHEAR-net: An End-to-End Deep Learning Approach for Single Push
  Ultrasound Shear Wave Elasticity Imaging</title><categories>eess.IV physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasound Shear Wave Elastography (USWE) with conventional B-mode imaging
demonstrates better performance in lesion segmentation and classification
problems. In this article, we propose SHEAR-net, an end-to-end deep neural
network, to reconstruct USWE images from tracked tissue displacement data at
different time instants induced by a single acoustic radiation force (ARF) with
100% or 50% of the energy in conventional use. The SHEAR-net consists of a
localizer called the S-net to first localize the lesion location and then uses
recurrent layers to extract temporal correlations from wave patterns using
different time frames, and finally, with an estimator, it reconstructs the
shear modulus image from the concatenated outputs of S-net and recurrent
layers. The network is trained with 800 simulation and a limited number of CIRS
tissue mimicking phantom data and is optimized using a multi-task learning loss
function where the tasks are: inclusion localization and modulus estimation.
The efficacy of the proposed SHEAR-net is extensively evaluated both
qualitatively and quantitatively on 125 test set of motion data obtained from
simulation and CIRS phantoms. We show that the proposed approach consistently
outperforms the current state-of-the-art method and achieves overall 4-5 dB
improvement in PSNR and SNR. In addition, an average gain of 0.15 in DSC and
SSIM values indicate that the SHEAR-net has a better inclusion coverage area
and structural similarity of the two approaches. The proposed real-time deep
learning based technique can accurately estimate shear modulus for a minimum
tissue displacement of 0.5$\mu$m and image multiple inclusions with a single
push ARF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04891</identifier>
 <datestamp>2019-04-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04891</id><created>2019-02-12</created><updated>2019-04-18</updated><authors><author><keyname>Shi</keyname><forenames>Ziqiang</forenames></author><author><keyname>Lin</keyname><forenames>Huibin</forenames></author><author><keyname>Liu</keyname><forenames>Liu</forenames></author><author><keyname>Liu</keyname><forenames>Rujie</forenames></author><author><keyname>Han</keyname><forenames>Jiqing</forenames></author><author><keyname>Shi</keyname><forenames>Anyan</forenames></author></authors><title>FurcaNeXt: End-to-end monaural speech separation with dynamic gated
  dilated temporal convolutional networks</title><categories>cs.SD eess.AS</categories><comments>Arxiv only allows figures with a small resolution. If you need to see
  large resolution figures, please contact us or check it at
  https://github.com/ShiZiqiang/furcanext_paper/blob/master/furcanext_arxiv.pdf.
  You can also check the samples generated by furcanext at
  https://github.com/ShiZiqiang/furcanext-samples/blob/master/samples_generated_by_furcanext.rar.
  arXiv admin note: substantial text overlap with arXiv:1902.00651</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep dilated temporal convolutional networks (TCN) have been proved to be
very effective in sequence modeling. In this paper we propose several
improvements of TCN for end-to-end approach to monaural speech separation,
which consists of 1) multi-scale dynamic weighted gated dilated convolutional
pyramids network (FurcaPy), 2) gated TCN with intra-parallel convolutional
components (FurcaPa), 3) weight-shared multi-scale gated TCN (FurcaSh), 4)
dilated TCN with gated difference-convolutional component (FurcaSu), that all
these networks take the mixed utterance of two speakers and maps it to two
separated utterances, where each utterance contains only one speaker's voice.
For the objective, we propose to train the network by directly optimizing
utterance level signal-to-distortion ratio (SDR) in a permutation invariant
training (PIT) style. Our experiments on the the public WSJ0-2mix data corpus
results in 18.4dB SDR improvement, which shows our proposed networks can leads
to performance improvement on the speaker separation task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04892</identifier>
 <datestamp>2019-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04892</id><created>2019-02-12</created><authors><author><keyname>Hou</keyname><forenames>Jie</forenames></author><author><keyname>Sun</keyname><forenames>Yuan</forenames></author><author><keyname>Yang</keyname><forenames>Wanqing</forenames></author><author><keyname>Lv</keyname><forenames>Ting</forenames></author><author><keyname>Wang</keyname><forenames>Xiaoqian</forenames></author></authors><title>Improvements of computational ghost imaging by using Special-Hadamard
  patterns</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduced a new kind of patterns named Special-Hadamard patterns, which
could be used as structured illuminations of computational ghost imaging.
Special-Hadamard patterns can get a better image quality than Hadamard patterns
in a noisy environment. We can completely reconstruct the original object in a
noiseless environment by using Special-Hadamard patterns, and the size of
object also can be adjusted arbitrarily, these advantages cannot be achieved by
other common patterns. We also performed simulations to compare the results of
Special Hadamard patterns with the results of Hadamard patterns. We found
Special Hadamard patterns can greatly improve the image quality of
computational ghost imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04980</identifier>
 <datestamp>2019-04-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04980</id><created>2019-02-13</created><authors><author><keyname>Nguyen</keyname><forenames>Duong</forenames></author><author><keyname>Kirsebom</keyname><forenames>Oliver S.</forenames></author><author><keyname>Fraz&#xe3;o</keyname><forenames>F&#xe1;bio</forenames></author><author><keyname>Fablet</keyname><forenames>Ronan</forenames></author><author><keyname>Matwin</keyname><forenames>Stan</forenames></author></authors><title>Recurrent Neural Networks with Stochastic Layers for Acoustic Novelty
  Detection</title><categories>eess.AS cs.LG cs.SD</categories><comments>Accepted to ICASSP 2019</comments><doi>10.1109/ICASSP.2019.8682901</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we adapt Recurrent Neural Networks with Stochastic Layers,
which are the state-of-the-art for generating text, music and speech, to the
problem of acoustic novelty detection. By integrating uncertainty into the
hidden states, this type of network is able to learn the distribution of
complex sequences. Because the learned distribution can be calculated
explicitly in terms of probability, we can evaluate how likely an observation
is then detect low-probability events as novel. The model is robust, highly
unsupervised, end-to-end and requires minimum preprocessing, feature
engineering or hyperparameter tuning. An experiment on a benchmark dataset
shows that our model outperforms the state-of-the-art acoustic novelty
detectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.04985</identifier>
 <datestamp>2019-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.04985</id><created>2019-02-13</created><authors><author><keyname>Abdulkareem</keyname><forenames>H. A.</forenames></author><author><keyname>Tekanyi</keyname><forenames>A. M. S.</forenames></author><author><keyname>Yau</keyname><forenames>I.</forenames></author><author><keyname>Sadiq</keyname><forenames>B. O.</forenames></author></authors><title>Development of Video Frame Enhancement Technique Using Pixel Intensity
  Analysis</title><categories>cs.MM eess.IV</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper developed a brightness enhancement technique for video frame pixel
intensity improvement. Frames extracted from the six sample video data used in
this work were stored in the form of images in a buffer. Noise was added to the
extracted image frames to vary the intensity of their pixels so that the pixel
values of the noisy images differ from their true values in order to determine
the efficiency of the developed technique. Simulation results showed that, the
developed technique was efficient with an improved pixel intensity and
histogram distribution. The Peak to Signal Noise Ratio evaluation showed that
the efficiency of the developed technique for both grayscale and coloured video
frames were improved by PSNR of 12.45%, 16.32%, 27.57% and 19.83% over the grey
level colour (black and white) for the NAELS1.avi, NAELS2.avi, NTA1.avi and
NTA2.avi respectively. Also, a percentage improvement of 28.93% and 31.68% were
obtained for the coloured image over the grey level image for Akiyo.avi and
Forman.avi benchmark video frame, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05028</identifier>
 <datestamp>2019-08-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05028</id><created>2019-02-13</created><updated>2019-08-07</updated><authors><author><keyname>Fijani</keyname><forenames>Ramin Faraji</forenames></author><author><keyname>Azimian</keyname><forenames>Behrouz</forenames></author><author><keyname>Ghotbi</keyname><forenames>Ehsan</forenames></author><author><keyname>Wang</keyname><forenames>Xingwu</forenames></author></authors><title>Game Theory Approach on Modeling of Residential Electricity Market by
  Considering the Uncertainty due to the Battery Electric Vehicles (BEVs)</title><categories>eess.SP</categories><comments>6 pages, 12 figs, PMAPS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid progression of sophisticated advance metering infrastructure (AMI),
allows us to have a better understanding and data from demand-response (DR)
solutions. There are vast amounts of research on the internet of things and its
application on the smart grids has been examined to find the most optimized
bill for the user; however, we propose a novel approach of house loads,
combined with owning a battery electric vehicle (BEV) equipped with the BEV
communication controllers and vehicle-to-grid (V2G) technology. In this paper
we use the Stackelberg game approach to achieve an efficient and effective
optimized algorithm for the users (followers) based on time dependent pricing.
We also assumed an electricity retailer company (leader) and a two-way
bilateral communication procedure. The usage-based side of the game has been
studied together with demand side management (DSM). Real-time pricing (RTP)
from time-of-use (TOU) companies has been used for better results, and Monte
Carlo simulation (MCS) handles the uncertain behavior of BEV drivers. Numerical
results compared to those from the simulation show that with this method we can
reshape the customer's demand for the best efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05069</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05069</id><created>2019-02-13</created><authors><author><keyname>Jain</keyname><forenames>Royal</forenames></author></authors><title>Improving performance and inference on audio classification tasks using
  capsule networks</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Classification of audio samples is an important part of many auditory
systems. Deep learning models based on the Convolutional and the Recurrent
layers are state-of-the-art in many such tasks. In this paper, we approach
audio classification tasks using capsule networks trained by recently proposed
dynamic routing-by-agreement mechanism. We propose an architecture for capsule
networks fit for audio classification tasks and study the impact of various
parameters on classification accuracy. Further, we suggest modifications for
regularization and multi-label classification. We also develop insights into
the data using capsule outputs and show the utility of the learned network for
transfer learning. We perform experiments on 7 datasets of different domains
and sizes and show significant improvements in performance compared to strong
baseline models. To the best of our knowledge, this is the first detailed study
about the application of capsule networks in the audio domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05072</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05072</id><created>2019-02-13</created><authors><author><keyname>Llorens-Quintana</keyname><forenames>Clara</forenames></author><author><keyname>Iskander</keyname><forenames>D. Robert</forenames></author></authors><title>Assessment of tear film using videokeratoscopy based on fractal
  dimension</title><categories>physics.med-ph eess.IV</categories><journal-ref>Optom Vis Sci. 2018 Jan;95(1):32-42</journal-ref><doi>10.1097/OPX.0000000000001159.</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To develop and test a new method for characterizing tear film
surface quality with high speed videokeratoscopy utilizing a fractal dimension
approach. Methods: The regularity of the reflected pattern in high speed
videokeratoscopy (E300, Medmont) depends on tear film stability. Thus
determining tear film stability can be addressed by estimating the fractal
dimension of the reflected pattern. The method is tested on 39 normal subjects.
The results of the fractal dimension approach are compared with those obtained
using previously proposed automated method, based on a gray level co-occurrence
matrix approach, and with subjective results obtained by two operators which
were assessing the video recordings in ideal conditions. Results: fractal
dimension method was less affected by eye movements and changes in the
videokeratoscopic image background than gray level co-occurrence matrix method.
Median difference of the non-invasive break-up time between manual and
automated methods was 0.03 s (IQR = 4.47 s.) and 0.0 s (IQR = 2.22 s.) for gray
level co-occurrence matrix and fractal dimension approaches, respectively.
Correlation coefficient with manual non-invasive break-up time was r2 = 0.86 (p
&lt; 0.001) for gray level co-occurrence matrix approach, and r2 = 0.82 (p &lt;
0.001) for fractal dimension approach. Significant statistical difference was
found between non-invasive break-up measurements of manual and gray level
co-occurrence matrix method (p = 0.008). Conclusions: The proposed method has
the potential to characterize tear film dynamics in more detail compared to
previous methods based on high speed videokeratoscopy. It showed good
correlation with manual assessment of tear film.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05097</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05097</id><created>2019-02-13</created><authors><author><keyname>Mao</keyname><forenames>Xinhua</forenames></author><author><keyname>Ding</keyname><forenames>Lan</forenames></author><author><keyname>Zhang</keyname><forenames>Yudong</forenames></author><author><keyname>Zhan</keyname><forenames>Ronghui</forenames></author><author><keyname>Li</keyname><forenames>Shan</forenames></author></authors><title>Knowledge-aided Two-dimensional Autofocus for Spotlight SAR Filtered
  Backprojection Imagery</title><categories>eess.SP</categories><comments>14 pages, 24 figures</comments><doi>10.1109/TGRS.2019.2924221</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Filtered backprojection (FBP) algorithm is a popular choice for complicated
trajectory SAR image formation processing due to its inherent nonlinear motion
compensation capability. However, how to efficiently autofocus the defocused
FBP imagery when the motion measurement is not accurate enough is still a
challenging problem. In this paper, a new interpretation of the FBP derivation
is presented from the Fourier transform point of view. Based on this new
viewpoint, the property of the residual 2-D phase error in FBP imagery is
analyzed in detail. Then, by incorporating the derived a priori knowledge on
the 2-D phase error, an accurate and efficient 2-D autofocus approach is
proposed. The new approach performs the parameter estimation in a
dimension-reduced parameter subspace by exploiting the a priori analytical
structure of the 2-D phase error, therefore possesses much higher accuracy and
efficiency than conventional blind methods. Finally, experimental results
clearly demonstrate the effectiveness and robustness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05124</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05124</id><created>2019-01-28</created><authors><author><keyname>Rahman</keyname><forenames>Ehsanur</forenames></author><author><keyname>Nojeh</keyname><forenames>Alireza</forenames></author></authors><title>Adsorbate-enhanced field-emission from single-walled carbon nanotubes: a
  comparative first-principles study</title><categories>cond-mat.mtrl-sci eess.SP</categories><comments>10 pages, 5 figure</comments><doi>10.1088/1361-6528/aaff94</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We report a comparative ab-initio study of different types of adsorbates and
their adsorption mechanism on the field-emission performance of single-walled
carbon nanotubes by analyzing electrical properties and transport
characteristics and considering the thermal stability of the adsorbed
structure. Adsorbates were found to reduce the work function by up to 1.3 eV,
enhance tunneling near the carbon nanotube tip, and increase the field-emission
current by as much as two orders of magnitude. A significant localization of
the electron cloud was also observed near the adsorbates under a high applied
electric field .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05168</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05168</id><created>2019-02-13</created><authors><author><keyname>Moeller</keyname><forenames>Lothar</forenames></author></authors><title>Nonlinear Depolarization of Light in Optical Communication Fiber</title><categories>eess.SP physics.optics</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report the experimental observation of a novel transmission phenomenon in
optical long-haul communication systems. Un-polarized ASE depolarizes via
nonlinear fiber interactions a cw laser light during their co-propagation which
leads to small but measurable ultra-fast polarization state fluctuations at the
fiber output. We provide a phenomenological approach and a theory that
qualitatively corroborates our experimental results. One of our major findings
suggests that the applicability of the often used Manakov equation needs to be
scrutinized for highly accurate studies of nonlinear polarization state
evolutions in noisy environments. The described phenomenon leads to a
qualitatively different microscopic understanding of nonlinear light
propagation in fiber and can contribute towards an explanation for todays
commonly perceived gap between simulated and experimentally obtained system
performance in optical data transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05347</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05347</id><created>2019-02-14</created><authors><author><keyname>Simonetta</keyname><forenames>Federico</forenames></author><author><keyname>Ntalampiras</keyname><forenames>Stavros</forenames></author><author><keyname>Avanzini</keyname><forenames>Federico</forenames></author></authors><title>Multimodal music information processing and retrieval: survey and future
  challenges</title><categories>cs.MM cs.IR cs.SD eess.AS</categories><acm-class>H.5.5; H.3.3</acm-class><journal-ref>in 2019 International Workshop on Multilayer Music Representation
  and Processing, Milano, IEEE 2019</journal-ref><doi>10.1109/MMRP.2019.00012</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Towards improving the performance in various music information processing
tasks, recent studies exploit different modalities able to capture diverse
aspects of music. Such modalities include audio recordings, symbolic music
scores, mid-level representations, motion, and gestural data, video recordings,
editorial or cultural tags, lyrics and album cover arts. This paper critically
reviews the various approaches adopted in Music Information Processing and
Retrieval and highlights how multimodal algorithms can help Music Computing
applications. First, we categorize the related literature based on the
application they address. Subsequently, we analyze existing information fusion
approaches, and we conclude with the set of challenges that Music Information
Retrieval and Sound and Music Computing research communities should focus in
the next years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05358</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05358</id><created>2019-02-14</created><authors><author><keyname>Dlamini</keyname><forenames>Thembelihle</forenames></author><author><keyname>Gambin</keyname><forenames>Angel Fernandez</forenames></author><author><keyname>Munaretto</keyname><forenames>Daniele</forenames></author><author><keyname>Rossi</keyname><forenames>Michele</forenames></author></authors><title>Online Supervisory Control and Resource Management for Energy Harvesting
  BS Sites Empowered with Computation Capabilities</title><categories>eess.SP</categories><comments>Journal on Wireless Communication and Mobile Computing</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The convergence of communication and computing has lead to the emergence of
Multi-access Edge Computing (MEC), where computing resources (supported by
Virtual Machines (VMs)) are distributed at the edge of the Mobile Network (MN),
i.e., in Base Stations (BSs), with the aim of ensuring reliable and ultra-low
latency services. Moreover, BSs equipped with Energy Harvesting (EH) systems
can decrease the amount of energy drained from the power grid resulting in
energetically self-sufficient MNs. The combination of these paradigms is
considered here. Specifically, we propose an online optimization algorithm,
called ENergy Aware and Adaptive Management (ENAAM), based on foresighted
control policies exploiting (short-term) traffic load and harvested energy
forecasts, where BSs and VMs are dynamically switched on/off towards energy
savings and QoS provisioning. Our numerical results reveal that ENAAM achieves
energy savings with respect to the case where no energy management is applied,
ranging from 57% and 69%. Moreover, the extension of ENAAM within a cluster of
BSs provides a further gain ranging from 9% to 16% in energy savings with
respect to the optimization performed in isolation for each BS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05362</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05362</id><created>2019-02-14</created><updated>2019-12-31</updated><authors><author><keyname>O'Shaughnessy</keyname><forenames>Matthew R.</forenames></author><author><keyname>Davenport</keyname><forenames>Mark A.</forenames></author><author><keyname>Rozell</keyname><forenames>Christopher J.</forenames></author></authors><title>Sparse Bayesian Learning with Dynamic Filtering for Inference of
  Time-Varying Sparse Signals</title><categories>eess.SP</categories><comments>25 pages, 10 figures</comments><journal-ref>IEEE Transactions on Signal Processing, Dec. 2019</journal-ref><doi>10.1109/TSP.2019.2961229</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many signal processing applications require estimation of time-varying sparse
signals, potentially with the knowledge of an imperfect dynamics model. In this
paper, we propose an algorithm for dynamic filtering of time-varying sparse
signals based on the sparse Bayesian learning (SBL) framework. The key idea
underlying the algorithm, termed SBL-DF, is the incorporation of a signal
prediction generated from a dynamics model and estimates of previous time steps
into the hyperpriors of the SBL probability model. The proposed algorithm is
robust to imperfect dynamics models (due to the propagation of dynamics
information through higher-order statistics), robust to certain undesirable
dictionary properties such as coherence (due to properties of the SBL
framework), allows the use of arbitrary dynamics models, and requires the
tuning of fewer parameters than many other dynamic filtering algorithms do. We
also extend the fast marginal likelihood SBL inference procedure to the
informative hyperprior setting to create a particularly efficient version of
the SBL-DF algorithm. Numerical simulations show that SBL-DF converges much
faster and to more accurate solutions than standard SBL and other dynamical
filtering algorithms. In particular, we show that SBL-DF outperforms state of
the art algorithms when the dictionary contains challenging structure such as
coherence and column scaling, as is found in many practical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05382</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05382</id><created>2019-01-29</created><authors><author><keyname>Ozbayoglu</keyname><forenames>A. Murat</forenames></author><author><keyname>Durlu</keyname><forenames>Nuri</forenames></author><author><keyname>Caliskan</keyname><forenames>N. Kaan</forenames></author></authors><title>Automated Image Analysis and Contiguity Estimation for Liquid Phase
  Sintered Tungsten Heavy Alloys</title><categories>eess.IV cond-mat.mtrl-sci</categories><msc-class>74A99, 68U10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study an automated software model using digital image processing
techniques is proposed for extracting the image characteristics and contiguity
of liquid phase sintered tungsten heavy alloys. The developed model takes a
typical image as input and processes it with no human intervention and provides
the corresponding image characteristics and contiguity value. The image
processing algorithm includes segmentation, binding point extraction, phase
connection, particle count and contiguity estimation stages. For the output,
microstructural parameters such as tungsten particle size, amount of tungsten
phase and contiguity are determined. The model is implemented by using 6
different scanning electron microscope images of liquid phase sintered
90W-7Ni-3Fe and 93W-4.9Ni-2.1Fe allloys. The results indicate that relative to
the manual measurements, the automated model can correctly estimate the
contiguity with an error in the vicinity of 5.6% - 2.9% for these two alloys.
The developed software can easily be adapted to be used for other
microstructures. It is also provided as open-source and available for other
researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05386</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05386</id><created>2019-02-07</created><authors><author><keyname>Jokic</keyname><forenames>Andrej</forenames></author><author><keyname>Vukovic</keyname><forenames>Nikola</forenames></author></authors><title>License Plate Recognition with Compressive Sensing Based Feature
  Extraction</title><categories>cs.CV cs.MM eess.SP</categories><comments>Student paper submitted to The 8th Mediterranean Conference on
  Embedded Computing - MECO'2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  License plate recognition is the key component to many automatic traffic
control systems. It enables the automatic identification of vehicles in many
applications. Such systems must be able to identify vehicles from images taken
in various conditions including low light, rain, snow, etc. In order to reduce
the complexity and cost of the hardware required for such devices, the
algorithm should be as efficient as possible. This paper proposes a license
plate recognition system which uses a new approach based on compressive sensing
techniques for dimensionality reduction and feature extraction. Dimensionality
reduction will enable precise classification with less training data while
demanding less computational power. Based on the extracted features, character
recognition and classification is done by a Support Vector Machine classifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05446</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05446</id><created>2019-02-13</created><authors><author><keyname>Jorge</keyname></author><author><keyname>Davila-Chacon</keyname></author><author><keyname>Jindong</keyname></author><author><keyname>Liu</keyname></author><author><keyname>Stefan</keyname></author><author><keyname>Wermter</keyname></author></authors><title>Enhanced Robot Speech Recognition Using Biomimetic Binaural Sound Source
  Localization</title><categories>cs.SD cs.HC cs.LG cs.NE eess.AS</categories><journal-ref>IEEE Transactions on Neural Networks and Learning Systems (Volume:
  30, Issue: 1, Jan. 2019)</journal-ref><doi>10.1109/TNNLS.2018.2830119</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by the behavior of humans talking in noisy environments, we propose
an embodied embedded cognition approach to improve automatic speech recognition
(ASR) systems for robots in challenging environments, such as with ego noise,
using binaural sound source localization (SSL). The approach is verified by
measuring the impact of SSL with a humanoid robot head on the performance of an
ASR system. More specifically, a robot orients itself toward the angle where
the signal-to-noise ratio (SNR) of speech is maximized for one microphone
before doing an ASR task. First, a spiking neural network inspired by the
midbrain auditory system based on our previous work is applied to calculate the
sound signal angle. Then, a feedforward neural network is used to handle high
levels of ego noise and reverberation in the signal. Finally, the sound signal
is fed into an ASR system. For ASR, we use a system developed by our group and
compare its performance with and without the support from SSL. We test our SSL
and ASR systems on two humanoid platforms with different structural and
material properties. With our approach we halve the sentence error rate with
respect to the common downmixing of both channels. Surprisingly, the ASR
performance is more than two times better when the angle between the humanoid
head and the sound source allows sound waves to be reflected most intensely
from the pinna to the ear microphone, rather than when sound waves arrive
perpendicularly to the membrane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05483</identifier>
 <datestamp>2019-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05483</id><created>2019-02-14</created><authors><author><keyname>Ezuma</keyname><forenames>Martins</forenames></author><author><keyname>Ozdemir</keyname><forenames>Ozgur</forenames></author><author><keyname>Anjinappa</keyname><forenames>Chethan Kumar</forenames></author><author><keyname>Gulzar</keyname><forenames>Wahab Ali</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Micro-UAV Detection with a Low-Grazing Angle Millimeter Wave Radar</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave radars are popularly used in last-mile radar-based defense
systems. Detection of low-altitude airborne target using these radars at
low-grazing angles is an important problem in the field of electronic warfare,
which becomes challenging due to the significant effects of clutters in the
terrain. This paper provides both experimental and analytical investigation of
micro unmanned aerial vehicle (UAV) detection in a rocky terrain using a low
grazing angle, surface-sited 24 GHz dual polarized frequency modulated
continuous wave (FMCW) radar. The radar backscatter signal from the UAV is
polluted by land clutters which is modeled using a uniform Weibull
distribution. A constant false alarm rate (CFAR) detector which employs
adaptive thresholding is designed to detect the UAV in the rich clutter
background. In order to further enhance the discrimination of the UAV from the
clutter, the micro-Doppler signature of the rotating propellers and bulk
trajectory of the UAV are extracted and plotted in the time-frequency domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05495</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05495</id><created>2019-02-14</created><authors><author><keyname>Dlamini</keyname><forenames>Thembelihle</forenames></author><author><keyname>Gambin</keyname><forenames>Angel Fernandez</forenames></author><author><keyname>Munaretto</keyname><forenames>Daniele</forenames></author><author><keyname>Rossi</keyname><forenames>Michele</forenames></author></authors><title>Online Resource Management in Energy Harvesting BS Sites through
  Prediction and Soft-Scaling of Computing Resources</title><categories>eess.SP cs.NI</categories><comments>arXiv admin note: substantial text overlap with arXiv:1902.05358</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Multi-Access Edge Computing (MEC) is a paradigm for handling delay sensitive
services that require ultra-low latency at the access network. With it,
computing and communications are performed within one Base Station (BS) site,
where the computation resources are in the form of Virtual Machines (VMs)
(computer emulators) in the MEC server. MEC and Energy Harvesting (EH) BSs,
i.e., BSs equipped with EH equipments, are foreseen as a key towards
next-generation mobile networks. In fact, EH systems are expected to decrease
the energy drained from the electricity grid and facilitate the deployment of
BSs in remote places, extending network coverage and making energy
self-sufficiency possible in remote/rural sites. In this paper, we propose an
online optimization algorithm called ENergy Aware and Adaptive Management
(ENAAM), for managing remote BS sites through foresighted control policies
exploiting (short-term) traffic load and harvested energy forecasts. Our
numerical results reveal that ENAAM achieves energy savings with respect to the
case where no energy management is applied, ranging from 56% to 66% through the
scaling of computing resources, and keeps the server utilization factor between
30% and 96% over time (with an average of 75%). Notable benefits are also found
against heuristic energy management techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05576</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05576</id><created>2019-02-14</created><authors><author><keyname>Winterauer</keyname><forenames>Dominik J.</forenames><affiliation>Renishaw plc</affiliation><affiliation>Institut des Mat&#xe9;riaux Jean Rouxel Nantes</affiliation></author><author><keyname>Funes-Hernando</keyname><forenames>Daniel</forenames><affiliation>Institut des Mat&#xe9;riaux Jean Rouxel Nantes</affiliation></author><author><keyname>Duvail</keyname><forenames>Jean-Luc</forenames><affiliation>Institut des Mat&#xe9;riaux Jean Rouxel Nantes</affiliation></author><author><keyname>Moussaoui</keyname><forenames>Sa&#xef;d</forenames><affiliation>Laboratoire des Sciences du Num&#xe9;rique de Nantes</affiliation></author><author><keyname>Batten</keyname><forenames>Tim</forenames><affiliation>Renishaw plc</affiliation></author><author><keyname>Humbert</keyname><forenames>Bernard</forenames><affiliation>Institut des Mat&#xe9;riaux Jean Rouxel Nantes</affiliation></author></authors><title>Sub-micron spatial resolution in far-field Raman imaging via positivity
  constrained super-resolution</title><categories>physics.optics eess.IV</categories><comments>21 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Raman microscopy is a valuable tool for detecting physical and chemical
properties of a sample material. When probing nanomaterials or nanocomposites
the spatial resolution of Raman microscopy is not always adequate as it is
limited by the optical diffraction limit. Numerical post-processing with
super-resolution algorithms provides a means to enhance resolution and can be
straightforwardly applied. The aim of this work is to present interior-point
least squares (IPLS) as a powerful tool for super-resolution in Raman imaging
through constrained optimisation. IPLS's potential for super-resolution is
illustrated on numerically generated test images. Its resolving power is
demonstrated on Raman spectroscopic data of a polymer nanowire sample.
Comparison to AFM data of the same sample substantiates that the presented
method is a promising technique for analysing nanomaterial samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05581</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05581</id><created>2019-02-14</created><authors><author><keyname>Xu</keyname><forenames>Wenju</forenames></author><author><keyname>Keshmiri</keyname><forenames>Shawn</forenames></author><author><keyname>Wang</keyname><forenames>Guanghui</forenames></author></authors><title>Adversarially Approximated Autoencoder for Image Generation and
  Manipulation</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regularized autoencoders learn the latent codes, a structure with the
regularization under the distribution, which enables them the capability to
infer the latent codes given observations and generate new samples given the
codes. However, they are sometimes ambiguous as they tend to produce
reconstructions that are not necessarily faithful reproduction of the inputs.
The main reason is to enforce the learned latent code distribution to match a
prior distribution while the true distribution remains unknown. To improve the
reconstruction quality and learn the latent space a manifold structure, this
work present a novel approach using the adversarially approximated autoencoder
(AAAE) to investigate the latent codes with adversarial approximation. Instead
of regularizing the latent codes by penalizing on the distance between the
distributions of the model and the target, AAAE learns the autoencoder flexibly
and approximates the latent space with a simpler generator. The ratio is
estimated using generative adversarial network (GAN) to enforce the similarity
of the distributions. Additionally, the image space is regularized with an
additional adversarial regularizer. The proposed approach unifies two deep
generative models for both latent space inference and diverse generation. The
learning scheme is realized without regularization on the latent codes, which
also encourages faithful reconstruction. Extensive validation experiments on
four real-world datasets demonstrate the superior performance of AAAE. In
comparison to the state-of-the-art approaches, AAAE generates samples with
better quality and shares the properties of regularized autoencoder with a nice
latent manifold structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05646</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05646</id><created>2019-02-14</created><authors><author><keyname>Schmidt</keyname><forenames>Erick</forenames></author><author><keyname>Mohammed</keyname><forenames>Misbahuddin A.</forenames></author><author><keyname>Akopian</keyname><forenames>David</forenames></author></authors><title>A Performance Study of a Fast-Rate WLAN Fingerprint Measurement
  Collection Method</title><categories>eess.SP cs.NI</categories><journal-ref>IEEE Trans. Instrum. Meas., vol. 67, no. 10, pp. 2273-2281, Oct.
  2018</journal-ref><doi>10.1109/TIM.2018.2819378</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indoor positioning systems exploiting WLAN signal measurements such as
Received Signal Strength (RSS) are gaining popularity due to high accuracy of
the results. Sets of RSS and other measurements at designated locations from
available WLAN access points (APs) are conventionally called fingerprints and
retrieved from network cards at typically one Hz rate. Such measurement
collection is needed for offline radio-map surveying stage which assigns
fingerprints to locations, and for online navigation stage, when collected
measurements are associated with the radio-map for positioning. As WLAN network
is not originally designed for localization, the network cards occasionally
miss the fingerprints, measurement fluctuations necessitate statistical signal
processing, and surveying process is very time consuming. This paper describes
a fast measurement collection approach that addresses the mentioned problems:
higher probability of measurement acquisition, more data for statistical
processing and faster surveying. The approach is further analyzed for practical
setting applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05647</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05647</id><created>2019-02-14</created><authors><author><keyname>Chang</keyname><forenames>Huibin</forenames></author><author><keyname>Enfedaque</keyname><forenames>Pablo</forenames></author><author><keyname>Marchesini</keyname><forenames>Stefano</forenames></author></authors><title>Iterative Joint Ptychography-Tomography with Total Variation
  Regularization</title><categories>eess.IV</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to determine the 3D structure of a thick sample, researchers have
recently combined ptychography (for high resolution) and tomography (for 3D
imaging) in a single experiment. 2-step methods are usually adopted for
reconstruction, where the ptychography and tomography problems are often solved
independently. In this paper, we provide a novel model and ADMM-based algorithm
to jointly solve the ptychography-tomography problem iteratively, also
employing total variation regularization. The proposed method permits large
scan stepsizes for the ptychography experiment, requiring less measurements and
being more robust to noise with respect to other strategies, while achieving
higher reconstruction quality results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05683</identifier>
 <datestamp>2019-03-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05683</id><created>2019-02-14</created><authors><author><keyname>Mao</keyname><forenames>Daijiafan</forenames></author><author><keyname>Meyer</keyname><forenames>Danielle</forenames></author><author><keyname>Wang</keyname><forenames>Jiankang</forenames></author></authors><title>Evaluating PEV Impact on Long-Term Cost of Grid Assets</title><categories>eess.SP</categories><journal-ref>International Journal of Electrical Power &amp; Energy Systems Volume
  105, February 2019, Pages 793-802</journal-ref><doi>10.1016/j.ijepes.2018.09.028</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With increasing penetration and improving fast charging technologies, Plug-in
Electric Vehicles (PEV) exert a disruptive influence on power delivery systems.
The impulsive and high power-density characteristics of PEV make conventional
assessment methods of load impact unsuitable. This paper proposes an integrated
method to investigate the long-term impact of PEV charging on temporal response
and depreciation of grid assets in sub-transmission and distribution grid
levels (below 69kV). Compared to conventional methods, the proposed method
embeds dynamical system models of grid assets in Time-Series (TS) analysis and
captures stochastic charging behavior through Monte-Carlo simulation, promising
more robust and accurate assessment. Under the proposed method, the Total Cost
of Ownership (TCO) of grid assets formulation is re-established. The results of
this paper will enable utilities to quantify the capital and operation cost of
grid assets induced under various PEV penetration level and during any time
span of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05693</identifier>
 <datestamp>2019-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05693</id><created>2019-02-15</created><authors><author><keyname>Mao</keyname><forenames>Daijiafan</forenames></author><author><keyname>Potty</keyname><forenames>Karun</forenames></author><author><keyname>Wang</keyname><forenames>Jiankang</forenames></author></authors><title>The Impact of Power-Electronics-Based Load Dynamics on Large-disturbance
  Voltage Stability</title><categories>eess.SP math.DS</categories><doi>10.1109/PESGM.2018.8586221</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper establishes a new context where the power-electronics-based
(PE-based) load, represented by Plug-in Electric Vehicles, dominates the total
load composition in power systems. The inherent fast dynamics of PE-based load
make conventional approaches of voltage stability analysis unsuitable. Under
the new context, the mechanism and impacts of voltage instability under large
disturbances have been analytically revealed. The Region of Attraction (ROA) of
the stable equilibrium point has been estimated through nonlinear dynamical
system theories, which implies a critical clearing time post grid disturbance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05714</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05714</id><created>2019-02-15</created><updated>2019-09-11</updated><authors><author><keyname>Myers</keyname><forenames>Nitin Jonathan</forenames></author><author><keyname>Mezghani</keyname><forenames>Amine</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>FALP: Fast beam alignment in mmWave systems with low-resolution phase
  shifters</title><categories>eess.SP</categories><comments>15 pages, to appear in IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) systems can enable high data rates if the link
between the transmitting and receiving radios is configured properly. Fast
configuration of mmWave links, however, is challenging due to the use of large
antenna arrays and hardware constraints. For example, a large amount of
training overhead is incurred by exhaustive search-based beam alignment in
typical mmWave phased arrays. In this paper, we present a framework called FALP
for Fast beam Alignment with Low-resolution Phase shifters. FALP uses an
efficient set of antenna weight vectors to acquire channel measurements, and
allows faster beam alignment when compared to exhaustive scan. The antenna
weight vectors in FALP can be realized in ultra-low power phase shifters whose
resolution can be as low as one-bit. From a compressed sensing (CS)
perspective, the CS matrix designed in FALP satisfies the restricted isometry
property and allows CS algorithms to exploit the fast Fourier transform. The
proposed framework also establishes a new connection between channel
acquisition in phased arrays and magnetic resonance imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05730</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05730</id><created>2019-02-15</created><authors><author><keyname>M&#xfc;ller</keyname><forenames>Tobias</forenames></author><author><keyname>Marquardt</keyname><forenames>Pascal</forenames></author><author><keyname>Br&#xfc;ggenwirth</keyname><forenames>Stefan</forenames></author></authors><title>A Load Balancing Surveillance Algorithm For Multifunctional Radar
  Resource Management</title><categories>eess.SP</categories><comments>6 pages, 5 figures, this paper is a preprint of a paper accepted by
  International Radar Symposium (IRS) 2019</comments><msc-class>49M25</msc-class><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For all multifunctional radar systems the allocation of resources plays an
outstanding role. Many radars have low priority on surveillance tasks. In
challenging situations this leads to neglecting of surveillance beams in
directions where many other tasks are done. This document presents a technique
that enables multifunctional radar systems to keep on scanning overloaded
surveillance sectors under the condition that all sectors have a similar
revisit time. Since radar resource management depends on the used system, two
general configurations are considered in this paper. The focus lies on systems
with a rotating antenna.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05732</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05732</id><created>2019-02-15</created><authors><author><keyname>Al-Obiedollah</keyname><forenames>Haitham</forenames></author><author><keyname>Cumanan</keyname><forenames>Kanapathippillai</forenames></author><author><keyname>Thiyagalingam</keyname><forenames>Jeyarajan</forenames></author><author><keyname>Burr</keyname><forenames>Alister G.</forenames></author><author><keyname>Ding</keyname><forenames>Zhiguo</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author></authors><title>Energy Efficiency Fairness Beamforming Designs for MISO NOMA Systems</title><categories>eess.SP</categories><comments>IEEE WCNC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose two beamforming designs for a multiple-input
single-output non-orthogonal multiple access system considering the energy
efficiency (EE) fairness between users. In particular, two quantitative
fairness-based designs are developed to maintain fairness between the users in
terms of achieved EE: max-min energy efficiency (MMEE) and proportional
fairness (PF) designs. While the MMEE-based design aims to maximize the minimum
EE of the users in the system, the PF-based design aims to seek a good balance
between the global energy efficiency of the system and the EE fairness between
the users. Detailed simulation results indicate that our proposed designs offer
many-fold EE improvements over the existing energy-efficient beamforming
designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05735</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05735</id><created>2019-02-15</created><authors><author><keyname>Al-Obiedollah</keyname><forenames>Haitham</forenames></author><author><keyname>Cumanan</keyname><forenames>Kanapathippillai</forenames></author><author><keyname>Thiyagalingam</keyname><forenames>Jeyarajan</forenames></author><author><keyname>Burr</keyname><forenames>Alister G.</forenames></author><author><keyname>Ding</keyname><forenames>Zhiguo</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author></authors><title>Sum Rate Fairness Trade-off-based Resource Allocation Technique for MISO
  NOMA Systems</title><categories>eess.SP</categories><comments>IEEE WCNC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a beamforming design that jointly considers two
conflicting performance metrics, namely the sum rate and fairness, for a
multiple-input single-output non-orthogonal multiple access system. Unlike the
conventional rate-aware beamforming designs, the proposed approach has the
flexibility to assign different weights to the objectives (i.e., sum rate and
fairness) according to the network requirements and the channel conditions. In
particular, the proposed design is first formulated as a multi-objective
optimization problem, and subsequently mapped to a single objective
optimization (SOO) problem by exploiting the weighted sum approach combined
with a prior articulation method. As the resulting SOO problem is non-convex,
we use the sequential convex approximation technique, which introduces multiple
slack variables, to solve the overall problem. Simulation results are provided
to demonstrate the performance and the effectiveness of the proposed approach
along with detailed comparisons with conventional rate-aware-based beamforming
designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05761</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05761</id><created>2019-02-15</created><updated>2019-02-19</updated><authors><author><keyname>Ribas</keyname><forenames>Dayana</forenames><affiliation>MULTISPEECH</affiliation></author><author><keyname>Vincent</keyname><forenames>Emmanuel</forenames><affiliation>MULTISPEECH</affiliation></author></authors><title>An improved uncertainty propagation method for robust i-vector based
  speaker recognition</title><categories>cs.SD cs.AI eess.AS</categories><proxy>ccsd</proxy><journal-ref>44th International Conference on Acoustics, Speech, and Signal
  Processing (ICASSP 2019), May 2019, Brighton, United Kingdom</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of automatic speaker recognition systems degrades when facing
distorted speech data containing additive noise and/or reverberation.
Statistical uncertainty propagation has been introduced as a promising paradigm
to address this challenge. So far, different uncertainty propagation methods
have been proposed to compensate noise and reverberation in i-vectors in the
context of speaker recognition. They have achieved promising results on small
datasets such as YOHO and Wall Street Journal, but little or no improvement on
the larger, highly variable NIST Speaker Recognition Evaluation (SRE) corpus.
In this paper, we propose a complete uncertainty propagation method, whereby we
model the effect of uncertainty both in the computation of unbiased Baum-Welch
statistics and in the derivation of the posterior expectation of the i-vector.
We conduct experiments on the NIST-SRE corpus mixed with real domestic noise
and reverberation from the CHiME-2 corpus and preprocessed by multichannel
speech enhancement. The proposed method improves the equal error rate (EER) by
4% relative compared to a conventional i-vector based speaker verification
baseline. This is to be compared with previous methods which degrade
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05849</identifier>
 <datestamp>2019-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05849</id><created>2019-02-15</created><authors><author><keyname>Al-Obiedollah</keyname><forenames>Haitham</forenames></author><author><keyname>Cumanan</keyname><forenames>Kanapathippillai</forenames></author><author><keyname>Thiyagalingam</keyname><forenames>Jeyarajan</forenames></author><author><keyname>Burr</keyname><forenames>Alister G.</forenames></author><author><keyname>Ding</keyname><forenames>Zhiguo</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author></authors><title>Energy Efficient Beamforming Design for MISO Non-Orthogonal Multiple
  Access Systems</title><categories>eess.SP</categories><comments>Accepted at IEEE Transaction on Communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When considering the future generation wireless networks, non-orthogonal
multiple access (NOMA) represents a viable multiple access technique for
improving the spectral efficiency. The basic performance of NOMA is often
enhanced using downlink beamforming and power allocation techniques. Although
downlink beamforming has been previously studied with different performance
criteria, such as sum-rate and max-min rate, it has not been studied in the
multiuser, multiple-input single-output (MISO) case, particularly with the
energy efficiency criteria. In this paper, we investigate the design of an
energy efficient beamforming technique for downlink transmission in the context
of a multiuser MISO-NOMA system. In particular, this beamforming design is
formulated as a global energy efficiency (GEE) maximization problem with
minimum user rate requirements and transmit power constraints. By using the
sequential convex approximation (SCA) technique and the Dinkelbach's algorithm
to handle the non-convex nature of the GEE-Max problem, we propose two novel
algorithms for solving the downlink beamforming problem for the MISO-NOMA
system. Our evaluation of the proposed algorithms shows that they offer similar
optimal designs and are effective in offering substantial energy efficiencies
compared to the designs based on conventional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05948</identifier>
 <datestamp>2019-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05948</id><created>2019-02-14</created><authors><author><keyname>Dean-Ben</keyname><forenames>Xose Luis</forenames></author><author><keyname>Ozbek</keyname><forenames>Ali</forenames></author><author><keyname>Lopez-Schier</keyname><forenames>Hernan</forenames></author><author><keyname>Razansky</keyname><forenames>Daniel</forenames></author></authors><title>Acoustic scattering mediated single detector optoacoustic tomography</title><categories>physics.bio-ph eess.IV</categories><comments>4 pages, 3 figures</comments><journal-ref>Phys. Rev. Lett. 123, 174301 (2019)</journal-ref><doi>10.1103/PhysRevLett.123.174301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optoacoustic image formation is conventionally based upon ultrasound
time-of-flight readings from multiple detection positions. Herein, we exploit
acoustic scattering to physically encode the position of optical absorbers in
the acquired signals, thus reduce the amount of data required to reconstruct an
image from a single waveform. This concept is experimentally tested by
including a random distribution of scatterers between the sample and an
ultrasound detector array. Ultrasound transmission through a randomized
scattering medium was calibrated by raster scanning a light-absorbing
microparticle across a Cartesian grid. Image reconstruction from a single
time-resolved signal was then enabled with a regularized model-based iterative
algorithm relying on the calibration signals. The signal compression efficiency
is facilitated by the relatively short acquisition time window needed to
capture the entire scattered wavefield. The demonstrated feasibility to form an
image using a single recorded optoacoustic waveform paves a way to the
development of faster and affordable optoacoustic imaging systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05982</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05982</id><created>2019-01-16</created><authors><author><keyname>Liu</keyname><forenames>Binbin</forenames></author><author><keyname>Zheng</keyname><forenames>Qilong</forenames></author></authors><title>Realize special instructions on clustering VLIW DSP:
  multiplication-accumulation instruction</title><categories>cs.OH eess.SP</categories><comments>7 pages, in Chinese, 4 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BWDSP is a 32bit static scalar digital signal processor with VLIW and SIMD
features, which is designed for high-performance computing. Associated special
instructions are designed for its special architecture and application
scenarios. However, the existing compilation framework doesn't meet these
special instructions. Therefore, in the context of traditional Open64 compiler,
proposed a special instruction algorithm. Through this algorithm implements the
multiplication-accumulation operation with BWDSP structure, to improve the
performance of algorithms with multiply-accumulate requirements. Experimental
results show that the algorithm, which can make an maximum of 8.85 speedup on
BWDSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05985</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05985</id><created>2019-02-05</created><authors><author><keyname>Mayasari</keyname><forenames>Rini</forenames></author><author><keyname>Heryana</keyname><forenames>Nono</forenames></author></authors><title>Reduce Noise in Computed Tomography Image using Adaptive Gaussian Filter</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One image processing application that is very helpful for humans is to
improve image quality, poor image quality makes the image more difficult to
interpret because the information conveyed by the image is reduced. In the
process of the acquisition of medical images, the resulting image has decreased
quality (degraded) due to external factors and medical equipment used. For this
reason, it is necessary to have an image processing process to improve the
quality of medical images, so that later it is expected to help facilitate
medical personnel in analyzing and translating medical images, which will lead
to an improvement in the quality of diagnosis. In this study, an analysis will
be carried out to improve the quality of medical images with noise reduction
with the Gaussian Filter Method. Next, it is carried out, and tested against
medical images, in this case, the lung photo image. The test image is given
noise in the form of impulse salt &amp; pepper and adaptive Gaussian then analyzed
its performance qualitatively by comparing the output filter image, noise
image, and the original image by naked eye.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05990</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05990</id><created>2019-02-15</created><authors><author><keyname>Demir</keyname><forenames>Ali Fatih</forenames></author><author><keyname>Abbasi</keyname><forenames>Q. H.</forenames></author><author><keyname>Ankarali</keyname><forenames>Z. E.</forenames></author><author><keyname>Alomainy</keyname><forenames>A.</forenames></author><author><keyname>Qaraqe</keyname><forenames>K.</forenames></author><author><keyname>Serpedin</keyname><forenames>E.</forenames></author><author><keyname>Arslan</keyname><forenames>H.</forenames></author></authors><title>Anatomical Region-Specific In Vivo Wireless Communication Channel
  Characterization</title><categories>eess.SP</categories><comments>9 pages, 12 figures, 6 tables; accepted version (The URL for the
  final version:
  http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7593228&amp;isnumber=8023990
  )</comments><journal-ref>IEEE Journal of Biomedical and Health Informatics, vol. 21, no. 5,
  pp. 1254-1262, Sept. 2017</journal-ref><doi>10.1109/JBHI.2016.2618890</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In vivo wireless body area networks (WBANs) and their associated technologies
are shaping the future of healthcare by providing continuous health monitoring
and noninvasive surgical capabilities, in addition to remote diagnostic and
treatment of diseases. To fully exploit the potential of such devices, it is
necessary to characterize the communication channel which will help to build
reliable and high-performance communication systems. This paper presents an in
vivo wireless communication channel characterization for male torso both
numerically and experimentally (on a human cadaver) considering various organs
at 915 MHz and 2.4 GHz. A statistical path loss (PL) model is introduced, and
the anatomical region-specific parameters are provided. It is found that the
mean PL in dB scale exhibits a linear decaying characteristic rather than an
exponential decaying profile inside the body, and the power decay rate is
approximately twice at 2.4 GHz as compared to 915 MHz. Moreover, the variance
of shadowing increases significantly as the in vivo antenna is placed deeper
inside the body since the main scatterers are present in the vicinity of the
antenna. Multipath propagation characteristics are also investigated to
facilitate proper waveform designs in the future wireless healthcare systems,
and a root-mean-square (RMS) delay spread of 2.76 ns is observed at 5 cm depth.
Results show that the in vivo channel exhibit different characteristics than
the classical communication channels, and location dependency is very critical
for accurate, reliable, and energy-efficient link budget calculations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05999</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.05999</id><created>2019-02-15</created><authors><author><keyname>Demir</keyname><forenames>Ali Fatih</forenames></author><author><keyname>Elkourdi</keyname><forenames>M.</forenames></author><author><keyname>Ibrahim</keyname><forenames>M.</forenames></author><author><keyname>Arslan</keyname><forenames>H.</forenames></author></authors><title>Waveform Design for 5G and Beyond</title><categories>eess.SP</categories><comments>22 pages, 21 figures, 2 tables; accepted version (The URL for the
  final version:
  https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119333142.ch2)</comments><journal-ref>5G Networks: Fundamental Requirements, Enabling Technologies, and
  Operations Management, John Wiley &amp; Sons, Inc., Sept. 2018, ch. 2, pp. 51-76</journal-ref><doi>10.1002/9781119333142.ch2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G is envisioned to improve major key performance indicators (KPIs), such as
peak data rate, spectral efficiency, power consumption, complexity, connection
density, latency, and mobility. This chapter aims to provide a complete picture
of the ongoing 5G waveform discussions and overviews the major candidates. It
provides a brief description of the waveform and reveals the 5G use cases and
waveform design requirements. The chapter presents the main features of cyclic
prefix-orthogonal frequency-division multiplexing (CP-OFDM) that is deployed in
4G LTE systems. CP-OFDM is the baseline of the 5G waveform discussions since
the performance of a new waveform is usually compared with it. The chapter
examines the essential characteristics of the major waveform candidates along
with the related advantages and disadvantages. It summarizes and compares the
key features of different waveforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06003</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06003</id><created>2019-02-15</created><authors><author><keyname>Calliari</keyname><forenames>Felipe</forenames></author><author><keyname>Amaral</keyname><forenames>Gustavo C.</forenames></author><author><keyname>Lunglmayr</keyname><forenames>Michael</forenames></author></authors><title>FPGA-Embedded Linearized Bregman Iterations Algorithm for Trend Break
  Detection</title><categories>eess.SP</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection of level shifts in a noisy signal, or trend break detection, is a
problem that appears in several research fields, from biophysics to optics and
economics. Although many algorithms have been developed to deal with such
problem, accurate and low-complexity trend break detection is still an active
topic of research. The linearized Bregman Iterations have been recently
presented as a low-complexity and computationally-efficient algorithm to tackle
this problem, with a formidable structure that could benefit immensely from
hardware implementation. In this work, a hardware architecture of the
Linearized Bregman Iterations algorithm is presented and tested on a Field
Programmable Gate Array (FPGA). The hardware is synthesized in different sized
FPGAs and the percentage of used hardware as well as the maximum frequency
enabled by the design indicate that an approximately 100 gain factor in
processing time, with respect to the software implementation, can be achieved.
This represents a tremendous advantage in using a dedicated unit for trend
break detection applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06010</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06010</id><created>2019-02-15</created><authors><author><keyname>Demir</keyname><forenames>Ali Fatih</forenames></author><author><keyname>Arslan</keyname><forenames>Huseyin</forenames></author></authors><title>The impact of adaptive guards for 5G and beyond</title><categories>eess.SP</categories><comments>5 pages, 6 figures, 5 tables; accepted version (The URL for the final
  version:
  http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8292413&amp;isnumber=8292162)</comments><journal-ref>2017 IEEE 28th Annual International Symposium on Personal, Indoor,
  and Mobile Radio Communications (PIMRC), Montreal, QC, Oct. 2017, pp. 1-5</journal-ref><doi>10.1109/PIMRC.2017.8292413</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The next generation communication systems are evolving towards an increased
flexibility in different aspects. Enhanced flexibility is the key in order to
address diverse requirements. This paper presents the significance of adaptive
guards considering a windowed-OFDM system which supports a variety of services
operating asynchronously under the same network. The windowing approach
requires a guard duration to suppress the out-of-band emissions (OOBE), and the
guard band is required to handle the adjacent channel interference (ACI) along
with the windowing. The guards in both time and frequency domains are optimized
with respect to the use case and power offset between the users. To fully
exploit and further increase the potential of adaptive guards, an
interference-based scheduling algorithm is proposed as well. The results show
that the precise design that facilitates such flexibility reduce the guards
significantly and boost the spectral efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06013</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06013</id><created>2019-02-15</created><authors><author><keyname>Ibrahim</keyname><forenames>Mostafa</forenames></author><author><keyname>Demir</keyname><forenames>Ali Fatih</forenames></author><author><keyname>Arslan</keyname><forenames>Huseyin</forenames></author></authors><title>Time-Frequency Warped Waveforms</title><categories>eess.SP</categories><comments>4 pages, 5 figures; accepted version (The URL for the final version:
  http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8540914&amp;isnumber=8605392)</comments><journal-ref>IEEE Communications Letters, vol. 23, no. 1, pp. 36-39, Jan. 2019</journal-ref><doi>10.1109/LCOMM.2018.2882498</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The forthcoming communication systems are advancing towards improved
flexibility in various aspects. Improved flexibility is crucial to cater
diverse service requirements. This letter proposes a novel waveform design
scheme that exploits axis warping to enable peaceful coexistence of different
pulse shapes. A warping transform manipulates the lattice samples non-uniformly
and provides flexibility to handle the time-frequency occupancy of a signal.
The proposed approach enables the utilization of flexible pulse shapes in a
quasi-orthogonal manner and increases the spectral efficiency. In addition, the
rectangular resource block structure, which assists an efficient resource
allocation, is preserved with the warped waveform design as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06085</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06085</id><created>2019-02-16</created><updated>2019-05-18</updated><authors><author><keyname>Li</keyname><forenames>Meiyu</forenames></author><author><keyname>Tang</keyname><forenames>Hailiang</forenames></author><author><keyname>Chan</keyname><forenames>Michael D.</forenames></author><author><keyname>Zhou</keyname><forenames>Xiaobo</forenames></author><author><keyname>Qian</keyname><forenames>Xiaohua</forenames></author></authors><title>DC-AL GAN: Pseudoprogression and True Tumor Progression of Glioblastoma
  Multiform Image Classification Based on DCGAN and AlexNet</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pseudoprogression (PsP) occurs in 20-30% of patients with glioblastoma
multiforme (GBM) after receiving the standard treatment. In the course of
post-treatment magnetic resonance imaging (MRI), PsP exhibits similarities in
shape and intensity to the true tumor progression (TTP) of GBM. So, these
similarities pose challenges on the differentiation of these types of
progression and hence the selection of the appropriate clinical treatment
strategy. In this paper, we introduce DC-AL GAN, a novel feature learning
method based on deep convolutional generative adversarial network (DCGAN) and
AlexNet, to discriminate between PsP and TTP in MRI images. Due to the
adversarial relationship between the generator and the discriminator of DCGAN,
high-level discriminative features of PsP and TTP can be derived for the
discriminator with AlexNet. Also, a feature fusion scheme is used to combine
higher-layer features with lower-layer information, leading to more powerful
features that are used for effectively discriminating between PsP and TTP. The
experimental results show that DC-AL GAN achieves desirable PsP and TTP
classification performance that is superior to other state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06126</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06126</id><created>2019-02-16</created><authors><author><keyname>Aksenov</keyname><forenames>Alexandre</forenames></author><author><keyname>Amblard</keyname><forenames>Pierre-Olivier</forenames></author><author><keyname>Michel</keyname><forenames>Olivier</forenames></author><author><keyname>Jutten</keyname><forenames>Christian</forenames></author></authors><title>Optimal Measurement Times for a Small Number of Measures of a Brownian
  Motion over a Finite Period</title><categories>eess.SP</categories><comments>12 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The measure timetable plays a critical role for the accuracy of the
estimator. This article deals with the optimization of the schedule of measures
for observing a random process in time using a Kalman filter, when the length
of the process is finite and fixed, and a fixed number of measures are
available. The measuring devices are allowed to differ. The mean variance of
the estimator is chosen as criterion for optimality. The cases of $1$ or $2$
measures are studied in detail, and analytical formulas are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06130</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06130</id><created>2019-02-16</created><authors><author><keyname>Genest</keyname><forenames>Diane</forenames><affiliation>LIGM</affiliation></author><author><keyname>L&#xe9;onard</keyname><forenames>Marc</forenames><affiliation>LIGM</affiliation></author><author><keyname>Cousty</keyname><forenames>Jean</forenames><affiliation>LIGM</affiliation></author><author><keyname>De Croz&#xe9;</keyname><forenames>No&#xe9;mie</forenames><affiliation>RCO</affiliation></author><author><keyname>Talbot</keyname><forenames>Hugues</forenames><affiliation>LIGM</affiliation></author></authors><title>Atlas-based automated detection of swim bladder in Medaka embryo</title><categories>cs.CV eess.IV q-bio.TO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fish embryo models are increasingly being used both for the assessment of
chemicals efficacy and potential toxicity. This article proposes a methodology
to automatically detect the swim bladder on 2D images of Medaka fish embryos
seen either in dorsal view or in lateral view. After embryo segmentation and
for each studied orientation, the method builds an atlas of a healthy embryo.
This atlas is then used to define the region of interest and to guide the swim
bladder segmentation with a discrete globally optimal active contour.
Descriptors are subsequently designed from this segmentation. An automated
random forest clas-sifier is built from these descriptors in order to classify
embryos with and without a swim bladder. The proposed method is assessed on a
dataset of 261 images, containing 202 embryos with a swim bladder (where 196
are in dorsal view and 6 are in lateral view) and 59 without (where 43 are in
dorsal view and 16 are in lateral view). We obtain an average precision rate of
95% in the total dataset following 5-fold cross-validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06131</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06131</id><created>2019-02-16</created><authors><author><keyname>Cho</keyname><forenames>Jang Ik</forenames></author><author><keyname>Wang</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Xu</keyname><forenames>Yifan</forenames></author><author><keyname>Sun</keyname><forenames>Jiayang</forenames></author></authors><title>LISA: a MATLAB package for Longitudinal Image Sequence Analysis</title><categories>stat.CO cs.CV eess.IV</categories><comments>18 pages, 17 figures made from 35 png files</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large sequences of images (or movies) can now be obtained on an unprecedented
scale, which poses fundamental challenges to the existing image analysis
techniques. The challenges include heterogeneity, (automatic) alignment,
multiple comparisons, potential artifacts, and hidden noises. This paper
introduces our MATLAB package, Longitudinal Image Sequence Analysis (LISA), as
a one-stop ensemble of image processing and analysis tool for comparing a
general class of images from either different times, sessions, or subjects.
Given two contrasting sequences of images, the image processing in LISA starts
with selecting a region of interest in two representative images, followed by
automatic or manual segmentation and registration. Automatic segmentation
de-noises an image using a mixture of Gaussian distributions of the pixel
intensity values, while manual segmentation applies a user-chosen intensity
cut-off value to filter out noises. Automatic registration aligns the
contrasting images based on a mid-line regression whereas manual registration
lines up the images along a reference line formed by two user-selected points.
The processed images are then rendered for simultaneous statistical comparisons
to generate D, S, T, and P-maps. The D map represents a curated difference of
contrasting images, the S map is the non-parametrically smoothed differences,
the T map presents the variance-adjusted, smoothed differences, and the P-map
provides multiplicity-controlled p-values. These maps reveal the regions with
significant differences due to either longitudinal, subject-specific, or
treatment changes. A user can skip the image processing step to dive directly
into the statistical analysis step if the images have already been processed.
Hence, LISA offers flexibility in applying other image pre-processing tools.
LISA also has a parallel computing option for high definition images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06222</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06222</id><created>2019-02-17</created><authors><author><keyname>Quan</keyname><forenames>Weize</forenames></author><author><keyname>Yan</keyname><forenames>Dong-Ming</forenames></author><author><keyname>Wang</keyname><forenames>Kai</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaopeng</forenames></author><author><keyname>Pellerin</keyname><forenames>Denis</forenames></author></authors><title>Detecting Colorized Images via Convolutional Neural Networks: Toward
  High Accuracy and Good Generalization</title><categories>cs.CV cs.LG eess.IV</categories><comments>13 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image colorization achieves more and more realistic results with the
increasing computation power of recent deep learning techniques. It becomes
more difficult to identify the fake colorized images by human eyes. In this
work, we propose a novel forensic method to distinguish between natural images
(NIs) and colorized images (CIs) based on convolutional neural network (CNN).
Our method is able to achieve high classification accuracy and cope with the
challenging scenario of blind detection, i.e., no training sample is available
from &quot;unknown&quot; colorization algorithm that we may encounter during the testing
phase. This blind detection performance can be regarded as a generalization
performance. First, we design and implement a base network, which can attain
better performance in terms of classification accuracy and generalization (in
most cases) compared with state-of-the-art methods. Furthermore, we design a
new branch, which analyzes smaller regions of extracted features, and insert it
into the above base network. Consequently, our network can not only improve the
classification accuracy, but also enhance the generalization in the vast
majority of cases. To further improve the performance of blind detection, we
propose to automatically construct negative samples through linear
interpolation of paired natural and colorized images. Then, we progressively
insert these negative samples into the original training dataset and continue
to train the network. Experimental results demonstrate that our method can
achieve stable and high generalization performance when tested against
different state-of-the-art colorization algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06226</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06226</id><created>2019-02-17</created><authors><author><keyname>Xiang</keyname><forenames>Chenlu</forenames></author><author><keyname>Zhang</keyname><forenames>Zhichao</forenames></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author><author><keyname>Cao</keyname><forenames>Shan</forenames></author><author><keyname>LAU</keyname><forenames>Vincent</forenames></author></authors><title>Robust Sub-meter Level Indoor Localization - A Logistic Regression
  Approach</title><categories>eess.SP</categories><comments>6 pages, 5 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indoor localization becomes a raising demand in our daily lives. Due to the
massive deployment in the indoor environment nowadays, WiFi systems have been
applied to high accurate localization recently. Although the traditional model
based localization scheme can achieve sub-meter level accuracy by fusing
multiple channel state information (CSI) observations, the corresponding
computational overhead is significant. To address this issue, the model-free
localization approach using deep learning framework has been proposed and the
classification based technique is applied. In this paper, instead of using
classification based mechanism, we propose to use a logistic regression based
scheme under the deep learning framework, which is able to achieve sub-meter
level accuracy (97.2cm medium distance error) in the standard laboratory
environment and maintain reasonable online prediction overhead under the single
WiFi AP settings. We hope the proposed logistic regression based scheme can
shed some light on the model-free localization technique and pave the way for
the practical deployment of deep learning based WiFi localization systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06267</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06267</id><created>2019-02-17</created><authors><author><keyname>Yang</keyname><forenames>Fangshu</forenames></author><author><keyname>Ma</keyname><forenames>Jianwei</forenames></author></authors><title>Deep-learning inversion: a next generation seismic velocity-model
  building method</title><categories>physics.geo-ph cs.LG eess.SP</categories><comments>62 pages, 23 figures, 5 tables, revised version (Geophysics)</comments><msc-class>86A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seismic velocity is one of the most important parameters used in seismic
exploration. Accurate velocity models are key prerequisites for reverse-time
migration and other high-resolution seismic imaging techniques. Such velocity
information has traditionally been derived by tomography or full-waveform
inversion (FWI), which are time consuming and computationally expensive, and
they rely heavily on human interaction and quality control. We investigate a
novel method based on the supervised deep fully convolutional neural network
(FCN) for velocity-model building (VMB) directly from raw seismograms. Unlike
the conventional inversion method based on physical models, the supervised
deep-learning methods are based on big-data training rather than
prior-knowledge assumptions. During the training stage, the network establishes
a nonlinear projection from the multi-shot seismic data to the corresponding
velocity models. During the prediction stage, the trained network can be used
to estimate the velocity models from the new input seismic data. One key
characteristic of the deep-learning method is that it can automatically extract
multi-layer useful features without the need for human-curated activities and
initial velocity setup. The data-driven method usually requires more time
during the training stage, and actual predictions take less time, with only
seconds needed. Therefore, the computational time of geophysical inversions,
including real-time inversions, can be dramatically reduced once a good
generalized network is built. By using numerical experiments on synthetic
models, the promising performances of our proposed method are shown in
comparison with conventional FWI even when the input data are in more realistic
scenarios. Discussions on the deep-learning methods, training dataset, lack of
low frequencies, and advantages and disadvantages of the new method are also
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06297</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06297</id><created>2019-02-17</created><authors><author><keyname>Park</keyname><forenames>Sungwoo</forenames></author><author><keyname>Ali</keyname><forenames>Anum</forenames></author><author><keyname>Gonz&#xe1;lez-Prelcic</keyname><forenames>Nuria</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Spatial Channel Covariance Estimation for Hybrid Architectures Based on
  Tensor Decompositions</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial channel covariance information can replace full instantaneous channel
state information for the analog precoder design in hybrid analog/digital
architectures. Obtaining spatial channel covariance estimation, however, is
challenging in the hybrid structure due to the use of fewer radio frequency
(RF) chains than the number of antennas. In this paper, we propose a spatial
channel covariance estimation method based on higher-order tensor decomposition
for spatially sparse time-varying frequency-selective channels. The proposed
method leverages the fact that the channel can be represented as a low-rank
higher-order tensor. We also derive the Cram\'er-Rao lower bound on the
estimation accuracy of the proposed method. Numerical results and theoretical
analysis show that the proposed tensor-based approach achieves higher
estimation accuracy in comparison with prior compressive-sensing-based
approaches or conventional angle-of-arrival estimation approaches. Simulation
results reveal that the proposed approach becomes more beneficial at low
signal-to-noise (SNR) region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06323</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06323</id><created>2019-02-17</created><authors><author><keyname>Alkhimova</keyname><forenames>Svitlana M</forenames></author></authors><title>Automated Detection of Regions of Interest for Brain Perfusion MR Images</title><categories>eess.IV cs.CV</categories><journal-ref>Research Bulletin of the National Technical University of Ukraine&quot;
  Kyiv Politechnic Institute&quot; 5 (2018): 14-21</journal-ref><doi>10.20535/1810-0546.2018.5.146185</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Images with abnormal brain anatomy produce problems for automatic
segmentation techniques, and as a result poor ROI detection affects both
quantitative measurements and visual assessment of perfusion data. This paper
presents a new approach for fully automated and relatively accurate ROI
detection from dynamic susceptibility contrast perfusion magnetic resonance and
can therefore be applied excellently in the perfusion analysis. In the proposed
approach the segmentation output is a binary mask of perfusion ROI that has
zero values for air pixels, pixels that represent non-brain tissues, and
cerebrospinal fluid pixels. The process of binary mask producing starts with
extracting low intensity pixels by thresholding. Optimal low-threshold value is
solved by obtaining intensity pixels information from the approximate
anatomical brain location. Holes filling algorithm and binary region growing
algorithm are used to remove falsely detected regions and produce region of
only brain tissues. Further, CSF pixels extraction is provided by thresholding
of high intensity pixels from region of only brain tissues. Each time-point
image of the perfusion sequence is used for adjustment of CSF pixels location.
The segmentation results were compared with the manual segmentation performed
by experienced radiologists, considered as the reference standard for
evaluation of proposed approach. On average of 120 images the segmentation
results have a good agreement with the reference standard. All detected
perfusion ROIs were deemed by two experienced radiologists as satisfactory
enough for clinical use. The results show that proposed approach is suitable to
be used for perfusion ROI detection from DSC head scans. Segmentation tool
based on the proposed approach can be implemented as a part of any automatic
brain image processing system for clinical use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06334</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06334</id><created>2019-02-17</created><authors><author><keyname>Prabhushankar</keyname><forenames>Mohit</forenames></author><author><keyname>Kwon</keyname><forenames>Gukyeong</forenames></author><author><keyname>Temel</keyname><forenames>Dogancan</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Semantically Interpretable and Controllable Filter Sets</title><categories>cs.CV eess.IV</categories><comments>5 pages, 5 figures, 1 table</comments><acm-class>I.2; I.4; I.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we generate and control semantically interpretable filters
that are directly learned from natural images in an unsupervised fashion. Each
semantic filter learns a visually interpretable local structure in conjunction
with other filters. The significance of learning these interpretable filter
sets is demonstrated on two contrasting applications. The first application is
image recognition under progressive decolorization, in which recognition
algorithms should be color-insensitive to achieve a robust performance. The
second application is image quality assessment where objective methods should
be sensitive to color degradations. In the proposed work, the sensitivity and
lack thereof are controlled by weighing the semantic filters based on the local
structures they represent. To validate the proposed approach, we utilize the
CURE-TSR dataset for image recognition and the TID 2013 dataset for image
quality assessment. We show that the proposed semantic filter set achieves
state-of-the-art performances in both datasets while maintaining its robustness
across progressive distortions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06347</identifier>
 <datestamp>2019-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06347</id><created>2019-02-17</created><updated>2019-02-20</updated><authors><author><keyname>Pereira</keyname><forenames>Pedro M. M.</forenames></author><author><keyname>Fonseca-Pinto</keyname><forenames>Rui</forenames></author><author><keyname>Paiva</keyname><forenames>Rui Pedro</forenames></author><author><keyname>Tavora</keyname><forenames>Luis M. N.</forenames></author><author><keyname>Assuncao</keyname><forenames>Pedro A. A.</forenames></author><author><keyname>de Faria</keyname><forenames>Sergio M. M.</forenames></author></authors><title>Accurate Segmentation of Dermoscopic Images based on Local Binary
  Pattern Clustering</title><categories>cs.CV eess.SP</categories><comments>submitted to MIPRO DC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmentation is a key stage in dermoscopic image processing, where the
accuracy of the border line that defines skin lesions is of utmost importance
for subsequent algorithms (e.g., classification) and computer-aided early
diagnosis of serious medical conditions. This paper proposes a novel
segmentation method based on Local Binary Patterns (LBP), where LBP and K-Means
clustering are combined to achieve a detailed delineation in dermoscopic
images. In comparison with usual dermatologist-like segmentation (i.e., the
available ground-truth), the proposed method is capable of finding more
realistic borders of skin lesions, i.e., with much more detail. The results
also exhibit reduced variability amongst different performance measures and
they are consistent across different images. The proposed method can be applied
for cell-based like segmentation adapted to the lesion border growing
specificities. Hence, the method is suitable to follow the growth dynamics
associated with the lesion border geometry in skin melanocytic images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06353</identifier>
 <datestamp>2019-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06353</id><created>2019-02-17</created><updated>2019-02-18</updated><authors><author><keyname>Zafaruddin</keyname><forenames>S. M.</forenames></author><author><keyname>Bistritz</keyname><forenames>Ilai</forenames></author><author><keyname>Leshem</keyname><forenames>Amir</forenames></author><author><keyname>Niyato</keyname><forenames>Dusit</forenames></author></authors><title>Distributed Learning for Channel Allocation Over a Shared Spectrum</title><categories>cs.IT cs.LG eess.SP math.IT</categories><journal-ref>IEEE Journal on Selected Areas in Communications Year: 2019 |
  Volume: 37, Issue: 10, Publisher: IEEE</journal-ref><doi>10.1109/JSAC.2019.2933966</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel allocation is the task of assigning channels to users such that some
objective (e.g., sum-rate) is maximized. In centralized networks such as
cellular networks, this task is carried by the base station which gathers the
channel state information (CSI) from the users and computes the optimal
solution. In distributed networks such as ad-hoc and device-to-device (D2D)
networks, no base station exists and conveying global CSI between users is
costly or simply impractical. When the CSI is time varying and unknown to the
users, the users face the challenge of both learning the channel statistics
online and converge to a good channel allocation. This introduces a multi-armed
bandit (MAB) scenario with multiple decision makers. If two users or more
choose the same channel, a collision occurs and they all receive zero reward.
We propose a distributed channel allocation algorithm that each user runs and
converges to the optimal allocation while achieving an order optimal regret of
O\left(\log T\right). The algorithm is based on a carrier sensing multiple
access (CSMA) implementation of the distributed auction algorithm. It does not
require any exchange of information between users. Users need only to observe a
single channel at a time and sense if there is a transmission on that channel,
without decoding the transmissions or identifying the transmitting users. We
demonstrate the performance of our algorithm using simulated LTE and 5G
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06383</identifier>
 <datestamp>2019-03-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06383</id><created>2019-02-17</created><updated>2019-03-19</updated><authors><author><keyname>Tiong</keyname><forenames>Leslie Ching Ow</forenames></author><author><keyname>Teoh</keyname><forenames>Andrew Beng Jin</forenames></author><author><keyname>Lee</keyname><forenames>Yunli</forenames></author></authors><title>Periocular Recognition in the Wild with Orthogonal Combination of Local
  Binary Coded Pattern in Dual-stream Convolutional Neural Network</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted in International Conference On Biometrics 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In spite of the advancements made in the periocular recognition, the dataset
and periocular recognition in the wild remains a challenge. In this paper, we
propose a multilayer fusion approach by means of a pair of shared parameters
(dual-stream) convolutional neural network where each network accepts RGB data
and a novel colour-based texture descriptor, namely Orthogonal
Combination-Local Binary Coded Pattern (OC-LBCP) for periocular recognition in
the wild. Specifically, two distinct late-fusion layers are introduced in the
dual-stream network to aggregate the RGB data and OC-LBCP. Thus, the network
beneficial from this new feature of the late-fusion layers for accuracy
performance gain. We also introduce and share a new dataset for periocular in
the wild, namely Ethnic-ocular dataset for benchmarking. The proposed network
has also been assessed on one publicly available dataset, namely UBIPr. The
proposed network outperforms several competing approaches on these datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06435</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06435</id><created>2019-02-18</created><authors><author><keyname>Alkhateeb</keyname><forenames>Ahmed</forenames></author></authors><title>DeepMIMO: A Generic Deep Learning Dataset for Millimeter Wave and
  Massive MIMO Applications</title><categories>cs.IT eess.SP math.IT</categories><comments>to appear in Proc. of Information Theory and Applications Workshop
  (ITA), Feb., 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning tools are finding interesting applications in millimeter
wave (mmWave) and massive MIMO systems. This is mainly thanks to their powerful
capabilities in learning unknown models and tackling hard optimization
problems. To advance the machine learning research in mmWave/massive MIMO,
however, there is a need for a common dataset. This dataset can be used to
evaluate the developed algorithms, reproduce the results, set benchmarks, and
compare the different solutions. In this work, we introduce the DeepMIMO
dataset, which is a generic dataset for mmWave/massive MIMO channels. The
DeepMIMO dataset generation framework has two important features. First, the
DeepMIMO channels are constructed based on accurate ray-tracing data obtained
from Remcom Wireless InSite. The DeepMIMO channels, therefore, capture the
dependence on the environment geometry/materials and transmitter/receiver
locations, which is essential for several machine learning applications.
Second, the DeepMIMO dataset is generic/parameterized as the researcher can
adjust a set of system and channel parameters to tailor the generated DeepMIMO
dataset for the target machine learning application. The DeepMIMO dataset can
then be completely defined by the (i) the adopted ray-tracing scenario and (ii)
the set of parameters, which enables the accurate definition and reproduction
of the dataset. In this paper, an example DeepMIMO dataset is described based
on an outdoor ray-tracing scenario of 18 base stations and more than one
million users. The paper also shows how this dataset can be used in an example
deep learning application of mmWave beam prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06450</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06450</id><created>2019-02-18</created><authors><author><keyname>Dong</keyname><forenames>Linhao</forenames></author><author><keyname>Wang</keyname><forenames>Feng</forenames></author><author><keyname>Xu</keyname><forenames>Bo</forenames></author></authors><title>Self-Attention Aligner: A Latency-Control End-to-End Model for ASR Using
  Self-Attention Network and Chunk-Hopping</title><categories>cs.CL cs.SD eess.AS</categories><comments>To appear at ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-attention network, an attention-based feedforward neural network, has
recently shown the potential to replace recurrent neural networks (RNNs) in a
variety of NLP tasks. However, it is not clear if the self-attention network
could be a good alternative of RNNs in automatic speech recognition (ASR),
which processes the longer speech sequences and may have online recognition
requirements. In this paper, we present a RNN-free end-to-end model:
self-attention aligner (SAA), which applies the self-attention networks to a
simplified recurrent neural aligner (RNA) framework. We also propose a
chunk-hopping mechanism, which enables the SAA model to encode on segmented
frame chunks one after another to support online recognition. Experiments on
two Mandarin ASR datasets show the replacement of RNNs by the self-attention
networks yields a 8.4%-10.2% relative character error rate (CER) reduction. In
addition, the chunk-hopping mechanism allows the SAA to have only a 2.5%
relative CER degradation with a 320ms latency. After jointly training with a
self-attention network language model, our SAA model obtains further error rate
reduction on multiple datasets. Especially, it achieves 24.12% CER on the
Mandarin ASR benchmark (HKUST), exceeding the best end-to-end model by over 2%
absolute CER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06562</identifier>
 <datestamp>2019-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06562</id><created>2019-02-18</created><authors><author><keyname>Back</keyname><forenames>Seunghyeok</forenames></author><author><keyname>Lee</keyname><forenames>Seongju</forenames></author><author><keyname>Seo</keyname><forenames>Hogeon</forenames></author><author><keyname>Park</keyname><forenames>Deokhwan</forenames></author><author><keyname>Kim</keyname><forenames>Tae</forenames></author><author><keyname>Lee</keyname><forenames>Kyoobin</forenames></author></authors><title>Intra- and Inter-epoch Temporal Context Network (IITNet) for Automatic
  Sleep Stage Scoring</title><categories>cs.LG eess.SP stat.ML</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study proposes a novel deep learning model, called IITNet, to learn
intra- and inter-epoch temporal contexts from a raw single channel
electroencephalogram (EEG) for automatic sleep stage scoring. When sleep
experts identify the sleep stage of a 30-second PSG data called an epoch, they
investigate the sleep-related events such as sleep spindles, K-complex, and
frequency components from local segments of an epoch (sub-epoch) and consider
the relations between sleep-related events of successive epochs to follow the
transition rules. Inspired by this, IITNet learns how to encode sub-epoch into
representative feature via a deep residual network, then captures contextual
information in the sequence of representative features via BiLSTM. Thus, IITNet
can extract features in sub-epoch level and consider temporal context not only
between epochs but also in an epoch. IITNet is an end-to-end architecture and
does not need any preprocessing, handcrafted feature design, balanced sampling,
pre-training, or fine-tuning. Our model was trained and evaluated in Sleep-EDF
and MASS datasets and outperformed other state-of-the-art results on both the
datasets with the overall accuracy (ACC) of 84.0% and 86.6%, macro F1-score
(MF1) of 77.7 and 80.8, and Cohen's kappa of 0.78 and 0.80 in Sleep-EDF and
MASS, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06585</identifier>
 <datestamp>2019-05-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06585</id><created>2019-02-18</created><updated>2019-05-06</updated><authors><author><keyname>Temel</keyname><forenames>Dogancan</forenames></author><author><keyname>Lee</keyname><forenames>Jinsol</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Object Recognition under Multifarious Conditions: A Reliability Analysis
  and A Feature Similarity-based Performance Estimation</title><categories>cs.CV eess.IV</categories><comments>5 pages, 3 figures, 1 table</comments><acm-class>I.2; I.4; I.5</acm-class><journal-ref>IEEE International Conference on Image Processing, Taipei, Taiwan,
  2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the reliability of online recognition
platforms, Amazon Rekognition and Microsoft Azure, with respect to changes in
background, acquisition device, and object orientation. We focus on platforms
that are commonly used by the public to better understand their real-world
performances. To assess the variation in recognition performance, we perform a
controlled experiment by changing the acquisition conditions one at a time. We
use three smartphones, one DSLR, and one webcam to capture side views and
overhead views of objects in a living room, an office, and photo studio setups.
Moreover, we introduce a framework to estimate the recognition performance with
respect to backgrounds and orientations. In this framework, we utilize both
handcrafted features based on color, texture, and shape characteristics and
data-driven features obtained from deep neural networks. Experimental results
show that deep learning-based image representations can estimate the
recognition performance variation with a Spearman's rank-order correlation of
0.94 under multifarious acquisition conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06659</identifier>
 <datestamp>2019-03-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06659</id><created>2019-02-14</created><authors><author><keyname>Cazau</keyname><forenames>D.</forenames><affiliation>for the OSmOSE team</affiliation></author></authors><title>Theory-plus-code documentation of the DEPAM workflow for soundscape
  description</title><categories>eess.AS astro-ph.IM cs.SD</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In the Big Data era, the community of PAM faces strong challenges, including
the need for more standardized processing tools accross its different
applications in oceanography, and for more scalable and high-performance
computing systems to process more efficiently the everly growing datasets. In
this work we address conjointly both issues by first proposing a detailed
theory-plus-code document of a classical analysis workflow to describe the
content of PAM data, which hopefully will be reviewed and adopted by a maximum
of PAM experts to make it standardized. Second, we transposed this workflow
into the Scala language within the Spark/Hadoop frameworks so it can be
directly scaled out on several node cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06687</identifier>
 <datestamp>2019-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06687</id><created>2019-02-18</created><updated>2019-04-09</updated><authors><author><keyname>Coleman</keyname><forenames>Benjamin</forenames></author><author><keyname>Shrivastava</keyname><forenames>Anshumali</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>RACE: Sub-Linear Memory Sketches for Approximate Near-Neighbor Search on
  Streaming Data</title><categories>cs.DS cs.CG cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first sublinear memory sketch which can be queried to find the
$v$ nearest neighbors in a dataset. Our online sketching algorithm can compress
an $N$-element dataset to a sketch of size $O(N^b \log^3{N})$ in $O(N^{b+1}
\log^3{N})$ time, where $b &lt; 1$ when the query satisfies a data-dependent
near-neighbor stability condition.
  We achieve data-dependent sublinear space by combining recent advances in
locality sensitive hashing (LSH)-based estimators with compressed sensing. Our
results shed new light on the memory-accuracy tradeoff for near-neighbor
search. The techniques presented reveal a deep connection between the
fundamental compressed sensing (or heavy hitters) recovery problem and
near-neighbor search, leading to new insight for geometric search problems and
implications for sketching algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06782</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06782</id><created>2019-02-18</created><authors><author><keyname>Malik</keyname><forenames>Hafiz</forenames></author></authors><title>Securing Voice-driven Interfaces against Fake (Cloned) Audio Attacks</title><categories>eess.AS cs.SD</categories><comments>6 pages, The 2nd IEEE International Workshop on &quot;Fake MultiMedia&quot;
  (FakeMM'19) March 28-30, 2019, San Jose, CA, USA</comments><msc-class>92C55</msc-class><acm-class>I.2.1; I.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice cloning technologies have found applications in a variety of areas
ranging from personalized speech interfaces to advertisement, robotics, and so
on. Existing voice cloning systems are capable of learning speaker
characteristics and use trained models to synthesize a person's voice from only
a few audio samples. Advances in cloned speech generation technologies are
capable of generating perceptually indistinguishable speech from a bona-fide
speech. These advances pose new security and privacy threats to voice-driven
interfaces and speech-based access control systems. The state-of-the-art speech
synthesis technologies use trained or tuned generative models for cloned speech
generation. Trained generative models rely on linear operations, learned
weights, and excitation source for cloned speech synthesis. These systems leave
characteristic artifacts in the synthesized speech. Higher-order spectral
analysis is used to capture differentiating attributes between bona-fide and
cloned audios. Specifically, quadrature phase coupling (QPC) in the estimated
bicoherence, Gaussianity test statistics, and linearity test statistics are
used to capture generative model artifacts. Performance of the proposed method
is evaluated on cloned audios generated using speaker adaptation- and speaker
encoding-based approaches. Experimental results for a dataset consisting of 126
cloned speech and 8 bona-fide speech samples indicate that the proposed method
is capable of detecting bona-fide and cloned audios with close to a perfect
detection rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06797</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06797</id><created>2019-02-18</created><authors><author><keyname>Stoller</keyname><forenames>Daniel</forenames></author><author><keyname>Durand</keyname><forenames>Simon</forenames></author><author><keyname>Ewert</keyname><forenames>Sebastian</forenames></author></authors><title>End-to-end Lyrics Alignment for Polyphonic Music Using an
  Audio-to-Character Recognition Model</title><categories>cs.SD cs.LG eess.AS</categories><comments>5 pages (1 for references), 2 figures, 2 tables. Camera-ready
  version, accepted at the International Conference on Acoustics, Speech, and
  Signal Processing 2019 (ICASSP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time-aligned lyrics can enrich the music listening experience by enabling
karaoke, text-based song retrieval and intra-song navigation, and other
applications. Compared to text-to-speech alignment, lyrics alignment remains
highly challenging, despite many attempts to combine numerous sub-modules
including vocal separation and detection in an effort to break down the
problem. Furthermore, training required fine-grained annotations to be
available in some form. Here, we present a novel system based on a modified
Wave-U-Net architecture, which predicts character probabilities directly from
raw audio using learnt multi-scale representations of the various signal
components. There are no sub-modules whose interdependencies need to be
optimized. Our training procedure is designed to work with weak, line-level
annotations available in the real world. With a mean alignment error of 0.35s
on a standard dataset our system outperforms the state-of-the-art by an order
of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06798</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06798</id><created>2019-02-18</created><authors><author><keyname>Zhang</keyname><forenames>Yaguang</forenames></author><author><keyname>Anderson</keyname><forenames>Christopher R.</forenames></author><author><keyname>Michelusi</keyname><forenames>Nicolo</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author><author><keyname>Baker</keyname><forenames>Kenneth R.</forenames></author><author><keyname>Krogmeier</keyname><forenames>James V.</forenames></author></authors><title>Propagation Modeling Through Foliage in a Coniferous Forest at 28 GHz</title><categories>eess.SP</categories><comments>4 pages, 5 figures, IEEE Wireless Communications Letters</comments><doi>10.1109/LWC.2019.2899299</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this article is to investigate the propagation behavior of 28-GHz
millimeter wave in coniferous forests and model its basic transmission loss.
Field measurements were conducted with a custom-designed sliding correlator
sounder. Relevant foliage regions were extracted from high-resolution LiDAR
data and satellite images. Our results show that traditional foliage analysis
models for lower-frequency wireless communications fail to consistently output
correct path loss predictions. Novel fully automated site-specific models are
proposed to resolve this issue, yielding 0.9 dB overall improvement and up to
20 dB regional improvement in root mean square errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06833</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06833</id><created>2019-02-18</created><authors><author><keyname>Palaskar</keyname><forenames>Shruti</forenames></author><author><keyname>Raunak</keyname><forenames>Vikas</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author></authors><title>Learned In Speech Recognition: Contextual Acoustic Word Embeddings</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted at ICASSP 2019, 5 pages, 1 figure, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end acoustic-to-word speech recognition models have recently gained
popularity because they are easy to train, scale well to large amounts of
training data, and do not require a lexicon. In addition, word models may also
be easier to integrate with downstream tasks such as spoken language
understanding, because inference (search) is much simplified compared to
phoneme, character or any other sort of sub-word units. In this paper, we
describe methods to construct contextual acoustic word embeddings directly from
a supervised sequence-to-sequence acoustic-to-word speech recognition model
using the learned attention distribution. On a suite of 16 standard sentence
evaluation tasks, our embeddings show competitive performance against a
word2vec model trained on the speech transcriptions. In addition, we evaluate
these embeddings on a spoken language understanding task, and observe that our
embeddings match the performance of text-based embeddings in a pipeline of
first performing speech recognition and then constructing word embeddings from
transcriptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06857</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06857</id><created>2019-02-18</created><updated>2019-08-28</updated><authors><author><keyname>Temel</keyname><forenames>Dogancan</forenames></author><author><keyname>Alshawi</keyname><forenames>Tariq</forenames></author><author><keyname>Chen</keyname><forenames>Min-Hung</forenames></author><author><keyname>AlRegib</keyname><forenames>Ghassan</forenames></author></authors><title>Challenging Environments for Traffic Sign Detection: Reliability
  Assessment under Inclement Conditions</title><categories>cs.CV eess.IV</categories><comments>26 pages, 22 figures, 7 tables</comments><acm-class>I.2; I.4; I.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art algorithms successfully localize and recognize traffic signs
over existing datasets, which are limited in terms of challenging condition
type and severity. Therefore, it is not possible to estimate the performance of
traffic sign detection algorithms under overlooked challenging conditions.
Another shortcoming of existing datasets is the limited utilization of temporal
information and the unavailability of consecutive frames and annotations. To
overcome these shortcomings, we generated the CURE-TSD video dataset and hosted
the first IEEE Video and Image Processing (VIP) Cup within the IEEE Signal
Processing Society. In this paper, we provide a detailed description of the
CURE-TSD dataset, analyze the characteristics of the top performing algorithms,
and provide a performance benchmark. Moreover, we investigate the robustness of
the benchmarked algorithms with respect to sign size, challenge type and
severity. Benchmarked algorithms are based on state-of-the-art and custom
convolutional neural networks that achieved a precision of 0.55 and a recall of
0.32, F0.5 score of 0.48 and F2 score of 0.35. Experimental results show that
benchmarked algorithms are highly sensitive to tested challenging conditions,
which result in an average performance drop of 0.17 in terms of precision and a
performance drop of 0.28 in recall under severe conditions. The dataset is
publicly available at https://github.com/olivesgatech/CURE-TSD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06860</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06860</id><created>2019-02-18</created><authors><author><keyname>Demir</keyname><forenames>Ali Fatih</forenames></author><author><keyname>Ankarali</keyname><forenames>Z. Esat</forenames></author><author><keyname>Abbasi</keyname><forenames>Qammer H.</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Qaraqe</keyname><forenames>Khalid</forenames></author><author><keyname>Serpedin</keyname><forenames>Erchin</forenames></author><author><keyname>Arslan</keyname><forenames>Huseyin</forenames></author><author><keyname>Gitlin</keyname><forenames>Richard D.</forenames></author></authors><title>In Vivo Communications: Steps Toward the Next Generation of Implantable
  Devices</title><categories>eess.SP</categories><comments>8 pages, 6 figures, 3 tables; accepted version (The URL for the final
  version:
  https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7476008&amp;isnumber=7474023)</comments><journal-ref>IEEE Vehicular Technology Magazine, vol. 11, no. 2, pp. 32-42,
  June 2016</journal-ref><doi>10.1109/MVT.2016.2520492</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In vivo wireless medical devices have the potential to play a vital role in
future healthcare technologies by improving the quality of human life. In order
to fully exploit the capabilities of such devices, it is necessary to
characterize and model the in vivo wireless communication channel. Utilization
of this model will have a significant role in improving the communication
performance of embedded medical devices in terms of power, reliability and
spectral efficiency. In this paper, the state of the art in this field is
presented to provide a comprehensive understanding of current models. Such
knowledge will be used to optimize the design and selection of various in vivo
wireless communication methods, operational frequencies, and antenna design.
Finally, open research areas are discussed for future studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06880</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06880</id><created>2019-02-18</created><authors><author><keyname>Rungta</keyname><forenames>Atul</forenames></author><author><keyname>Rewkowski</keyname><forenames>Nicholas</forenames></author><author><keyname>Klatzky</keyname><forenames>Roberta</forenames></author><author><keyname>Manocha</keyname><forenames>Dinesh</forenames></author></authors><title>P-Reverb: Perceptual Characterization of Early and Late Reflections for
  Auditory Displays</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel, perceptually derived metric (P-Reverb) that relates the
just-noticeable difference (JND) of the early sound field(also called early
reflections) to the late sound field (known as late reflections or
reverberation). Early and late reflections are crucial components of the sound
field and provide multiple perceptual cues for auditory displays. We conduct
two extensive user evaluations that relate the JNDs of early reflections and
late reverberation in terms of the mean-free path of the environment and
present a novel P-Reverb metric. Our metric is used to estimate dynamic
reverberation characteristics efficiently in terms of important parameters like
reverberation time (RT60). We show the numerical accuracy of our P-Reverb
metric in estimating RT60. Finally, we use our metric to design an interactive
sound propagation algorithm and demonstrate its effectiveness on various
benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06899</identifier>
 <datestamp>2019-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06899</id><created>2019-02-19</created><updated>2019-03-27</updated><authors><author><keyname>Tran</keyname><forenames>Julian</forenames></author><author><keyname>Farokhi</keyname><forenames>Farhad</forenames></author><author><keyname>Cantoni</keyname><forenames>Michael</forenames></author><author><keyname>Shames</keyname><forenames>Iman</forenames></author></authors><title>Implementing Homomorphic Encryption Based Secure Feedback Control for
  Physical Systems</title><categories>cs.CR cs.SY eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is about an encryption based approach to the secure implementation
of feedback controllers for physical systems. Specifically, Paillier's
homomorphic encryption is used to digitally implement a class of linear dynamic
controllers, which includes the commonplace static gain and PID type feedback
control laws as special cases. The developed implementation is amenable to
Field Programmable Gate Array (FPGA) realization. Experimental results,
including timing analysis and resource usage characteristics for different
encryption key lengths, are presented for the realization of an inverted
pendulum controller; as this is an unstable plant, the control is necessarily
fast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.06935</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.06935</id><created>2019-02-19</created><updated>2019-02-25</updated><authors><author><keyname>Kord</keyname><forenames>Ahmed</forenames></author><author><keyname>Tymchenko</keyname><forenames>Mykhailo</forenames></author><author><keyname>Sounas</keyname><forenames>Dimitrios</forenames></author><author><keyname>Krishnaswamy</keyname><forenames>Harish</forenames></author><author><keyname>Al&#xf9;</keyname><forenames>Andrea</forenames></author></authors><title>CMOS Integrated Magnetless Circulators Based on Spatiotemporal
  Modulation Angular-Momentum Biasing</title><categories>eess.SP</categories><doi>10.1109/TMTT.2019.2915074</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce the first integrated circuit (IC) implementation
of spatiotemporally modulated angular-momentum (STM-AM) biased magnetless
circulators. The design is based on a modified current-mode topology which is
less sensitive to parasitics and relies on switched capacitors rather than
varactors to achieve the desired modulation, thus reducing the circuit
complexity and easing its chip-scale realization. We analyze the presented
circuit and study its performance in the presence of inevitable non-idealities
using an in-house so-called composite Floquet scattering matrix (CFSM)
numerical method. We also validate the analysis with simulated and measured
results using a standard 180 nm CMOS technology, showing good performance.
Compared to previous discrete implementations of STM-AM circulators, the
presented CMOS chip reduces the form factor by at least an order of magnitude
and occupies a total area of only 36 mm2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07031</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07031</id><created>2019-02-19</created><authors><author><keyname>Magoarou</keyname><forenames>Luc Le</forenames><affiliation>IRT b-com</affiliation></author><author><keyname>Paquelet</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRT b-com</affiliation></author></authors><title>Performance of MIMO channel estimation with a physical model</title><categories>eess.SP cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel estimation is challenging in multi-antenna communication systems,
because of the large number of parameters to estimate. One way of facilitating
this task is to use a physical model describing the multiple paths constituting
the channel, in the hope of reducing the number of unknowns in the problem. The
achievable performance of estimation using this kind of physical model is
studied theoretically. It is found that adjusting the number of estimated paths
leads to a bias-variance tradeoff which is characterized. Moreover, computing
the Fisher information matrix of the model allows to identify orthogonal
parameters, ultimately leading to fast and asymptotically optimal algorithms as
a byproduct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07033</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07033</id><created>2019-02-19</created><authors><author><keyname>Wang</keyname><forenames>Shanshan</forenames></author><author><keyname>Naithani</keyname><forenames>Gaurav</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Low-Latency Deep Clustering For Speech Separation</title><categories>cs.SD eess.AS</categories><comments>To appear in ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a low algorithmic latency adaptation of the deep
clustering approach to speaker-independent speech separation. It consists of
three parts: a) the usage of long-short-term-memory (LSTM) networks instead of
their bidirectional variant used in the original work, b) using a short
synthesis window (here 8 ms) required for low-latency operation, and, c) using
a buffer in the beginning of audio mixture to estimate cluster centres
corresponding to constituent speakers which are then utilized to separate
speakers within the rest of the signal. The buffer duration would serve as an
initialization phase after which the system is capable of operating with 8 ms
algorithmic latency. We evaluate our proposed approach on two-speaker mixtures
from the Wall Street Journal (WSJ0) corpus. We observe that the use of LSTM
yields around one dB lower SDR as compared to the baseline bidirectional LSTM
in terms of source to distortion ratio (SDR). Moreover, using an 8 ms synthesis
window instead of 32 ms degrades the separation performance by around 2.1 dB as
compared to the baseline. Finally, we also report separation performance with
different buffer durations noting that separation can be achieved even for
buffer duration as low as 300ms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07095</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07095</id><created>2019-02-14</created><authors><author><keyname>Schmidt</keyname><forenames>Erick</forenames></author><author><keyname>Akopian</keyname><forenames>David</forenames></author><author><keyname>Pack</keyname><forenames>Daniel J.</forenames></author></authors><title>Development of a Real-Time Software-Defined Radio GPS Receiver
  Exploiting a LabVIEW-based Instrumentation Environment</title><categories>eess.SP cs.PF</categories><journal-ref>IEEE Trans. Instrum. Meas., vol. 67, no. 9, pp. 2082-2096, Sep.
  2018</journal-ref><doi>10.1109/TIM.2018.2811446</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ubiquitousness of location based services (LBS) has proven effective for
many applications such as commercial, military, and emergency responders.
Software-defined radio (SDR) has emerged as an adequate framework for
development and testing of global navigational satellite systems (GNSS) such as
the Global Position System (GPS). SDR receivers are constantly developing in
terms of acceleration factors and accurate algorithms for precise user
navigation. However, many SDR options for GPS receivers currently lack
real-time operation or could be costly. This paper presents a LabVIEW (LV) and
C/C++ based GPS L1 receiver platform with real-time capabilities. The system
relies on LV acceleration factors as well as other C/C++ techniques such as
dynamic link library (DLL) integration into LV and parallelizable loop
structures, and single input multiple data (SIMD) methods which leverage host
PC multi-purpose processors. A hardware testbed is presented for compactness
and mobility, as well as software functionality and data flow handling inherent
in LV environment. Benchmarks and other real-time results are presented as well
as compared against other state-of-the-art open-source GPS receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07178</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07178</id><created>2019-02-19</created><authors><author><keyname>Guo</keyname><forenames>Jinxi</forenames></author><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Weiss</keyname><forenames>Ron J.</forenames></author></authors><title>A spelling correction model for end-to-end speech recognition</title><categories>eess.AS cs.AI cs.CL cs.LG cs.SD</categories><comments>Accepted to ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attention-based sequence-to-sequence models for speech recognition jointly
train an acoustic model, language model (LM), and alignment mechanism using a
single neural network and require only parallel audio-text pairs. Thus, the
language model component of the end-to-end model is only trained on transcribed
audio-text pairs, which leads to performance degradation especially on rare
words. While there have been a variety of work that look at incorporating an
external LM trained on text-only data into the end-to-end framework, none of
them have taken into account the characteristic error distribution made by the
model. In this paper, we propose a novel approach to utilizing text-only data,
by training a spelling correction (SC) model to explicitly correct those
errors. On the LibriSpeech dataset, we demonstrate that the proposed model
results in an 18.6% relative improvement in WER over the baseline model when
directly correcting top ASR hypothesis, and a 29.0% relative improvement when
further rescoring an expanded n-best list using an external LM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07182</identifier>
 <datestamp>2019-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07182</id><created>2019-02-19</created><authors><author><keyname>Holmes</keyname><forenames>Daniel G.</forenames></author><author><keyname>Cheng</keyname><forenames>Ling</forenames></author><author><keyname>Shimaponda-Nawa</keyname><forenames>Mulundumina</forenames></author><author><keyname>Familua</keyname><forenames>Ayokunle D.</forenames></author><author><keyname>Abu-Mahfouz</keyname><forenames>Adnan M.</forenames></author></authors><title>Modelling Noise and Pulse Width Modulation Interference in Indoor
  Visible Light Communication Channels</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible light communication (VLC) has the potential to supplement the growing
demand for wireless connectivity. In order to realise the full potential of
VLC, channel models are required Discrete channel models based on semi-hidden
Markov models (Fritchman model) for indoor VLC using low data rate LEDs are
presented. Each channel considered includes background noise and differing
types of interference from fluorescent lights and pulse-width modulated (PWM)
LEDs, which could be part of an indoor smart lighting system. Models were
developed based on experimental error sequences from a VLC system using an
on-off keying (OOK) modulation scheme. The error sequences were input into the
Baum-Welch algorithm to determine the model parameters by expectation
maximisation. Simulated error sequences generated by the models are compared to
and, in most cases, perform better than simpler models with a single bit error
rate. The models closely approximate the experimental errors sequences in terms
of error distribution. The models performed better in channels where there is
less interference. It was also found that periodic errors were introduced as a
results of the PWM modulated smart lighting LEDs. These models have use for
designing error control codes and simulating indoor VLC environments with
different types of interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07213</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07213</id><created>2019-02-19</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Li</keyname><forenames>Jing</forenames></author><author><keyname>Qi</keyname><forenames>Junjian</forenames></author><author><keyname>Chen</keyname><forenames>Liang</forenames></author></authors><title>Robust Cubature Kalman Filter for Dynamic State Estimation of
  Synchronous Machines under Unknown Measurement Noise Statistics</title><categories>cs.SY eess.SP</categories><comments>Accepted by IEEE Access</comments><doi>10.1109/ACCESS.2019.2900228</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kalman-type filtering techniques including cubature Kalman filter (CKF) does
not work well in non-Gaussian environments, especially in the presence of
outliers. To solve this problem, Huber's M-estimation based robust CKF (RCKF)
is proposed for synchronous machines by combining the Huber's M-estimation
theory with the classical CKF, which is capable of coping with the
deterioration in performance and discretization of tracking curves when
measurement noise statistics deviatefrom the prior noise statistics. The
proposed RCKF algorithm has good adaptability to unknown measurement noise
statistics characteristics including non-Gaussian measurement noise and
outliers. The simulation results on the WSCC 3-machine 9-bus system and New
England 16-machine 68-bus system verify the effectiveness of the proposed
method and its advantage over the classical CKF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07238</identifier>
 <datestamp>2019-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07238</id><created>2019-02-19</created><authors><author><keyname>Kiranyaz</keyname><forenames>Serkan</forenames></author><author><keyname>Zabihi</keyname><forenames>Morteza</forenames></author><author><keyname>Rad</keyname><forenames>Ali Bahrami</forenames></author><author><keyname>Tahir</keyname><forenames>Anas</forenames></author><author><keyname>Ince</keyname><forenames>Turker</forenames></author><author><keyname>Hamila</keyname><forenames>Ridha</forenames></author><author><keyname>Gabbouj</keyname><forenames>Moncef</forenames></author></authors><title>Real-time PCG Anomaly Detection by Adaptive 1D Convolutional Neural
  Networks</title><categories>eess.SP</categories><comments>11 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The heart sound signals (Phonocardiogram - PCG) enable the earliest
monitoring to detect a potential cardiovascular pathology and have recently
become a crucial tool as a diagnostic test in outpatient monitoring to assess
heart hemodynamic status. The need for an automated and accurate anomaly
detection method for PCG has thus become imminent. To determine the
state-of-the-art PCG classification algorithm, 48 international teams competed
in the PhysioNet (CinC) Challenge at 2016 over the largest benchmark dataset
with 3126 records with the classification outputs, normal (N), abnormal (A) and
unsure - too noisy (U). In this study, our aim is to push this frontier
further; however, we focus deliberately on the anomaly detection problem while
assuming a reasonably high Signal-to-Noise Ratio (SNR) on the records. By using
1D Convolutional Neural Networks trained with a novel data purification
approach, we aim to achieve the highest detection performance and a real-time
processing ability with significantly lower delay and computational complexity.
The experimental results over the high-quality subset of the same benchmark
dataset shows that the proposed approach achieves both objectives. Furthermore,
our findings reveal the fact that further improvements indeed require a
personalized (patient-specific) approach to avoid major drawbacks of a global
PCG classification approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07292</identifier>
 <datestamp>2019-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07292</id><created>2019-02-19</created><authors><author><keyname>Blaauw</keyname><forenames>Merlijn</forenames></author><author><keyname>Bonada</keyname><forenames>Jordi</forenames></author><author><keyname>Daido</keyname><forenames>Ryunosuke</forenames></author></authors><title>Data Efficient Voice Cloning for Neural Singing Synthesis</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted to ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many use cases in singing synthesis where creating voices from
small amounts of data is desirable. In text-to-speech there have been several
promising results that apply voice cloning techniques to modern deep learning
based models. In this work, we adapt one such technique to the case of singing
synthesis. By leveraging data from many speakers to first create a multispeaker
model, small amounts of target data can then efficiently adapt the model to new
unseen voices. We evaluate the system using listening tests across a number of
different use cases, languages and kinds of data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07308</identifier>
 <datestamp>2019-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07308</id><created>2019-02-01</created><authors><author><keyname>Raptis</keyname><forenames>T. E.</forenames></author></authors><title>Hybrid Analog Signal-Based Models of Computation</title><categories>eess.SP</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work attempts both a review of previous methods for transferring
digital and symbolic computations in an analog or optical substrate and also to
offer certain alternatives not yet fully explored. The essential difference
from previous cases lies in the merging of general signal processing and
computational theory with some emphasis on the foundations of computations and
its logico-mathematical background and possible connections with fundamental
physical processes. The technologies proposed could among other things be used
to turn a standard RF network into a complete, autonomous holographic or
distributed computational medium. Some applications for Multi-Agent Systems are
also examined near the end.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07309</identifier>
 <datestamp>2019-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07309</id><created>2019-02-05</created><authors><author><keyname>Resetar</keyname><forenames>Milan</forenames></author><author><keyname>Ratkovic</keyname><forenames>Gojko</forenames></author><author><keyname>Zecevic</keyname><forenames>Svetlana</forenames></author></authors><title>Comparison of some commonly used algorithms for sparse signal
  reconstruction</title><categories>eess.SP cs.IT math.IT</categories><comments>submitted to The 8th Mediterranean Conference on Embedded Computing -
  MECO'2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to excessive need for faster propagations of signals and necessity to
reduce number of measurements and rapidly increase efficiency, new sensing
theories have been proposed. Conventional sampling approaches that follow
Shannon-Nyquist theorem require the sampling rate to be at least twice the
maximum frequency of the signal. This has triggered scientists to examine the
possibilities of creating a new path for recovering signals using much less
samples and therefore speeding up the process and satisfying the need for
faster realization. As a result the compressive sensing approach has emerged.
This breakthrough makes signal processing and reconstruction much easier, not
to mention that is has a vast variety of applications. In this paper some of
the commonly used algorithms for sparse signal recovery are compared. The
reconstruction accuracy, mean squared error and the execution time are
compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07316</identifier>
 <datestamp>2019-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07316</id><created>2019-02-17</created><updated>2019-04-15</updated><authors><author><keyname>Abbasloo</keyname><forenames>Amin</forenames></author><author><keyname>Salari</keyname><forenames>Alan</forenames></author></authors><title>Deep Modulation Embedding</title><categories>eess.SP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural network has recently shown very promising applications in
different research directions and attracted the industry attention as well.
Although the idea was introduced in the past but just recently the main
limitation of using this class of algorithms is solved by enabling parallel
computing on GPU hardware. Opening the possibility of hardware prototyping with
proven superiority of this class of algorithm, trigger several research
directions in communication system too. Among them cognitive radio, modulation
recognition, learning based receiver and transceiver are already given very
interesting result in simulation and real experimental evaluation implemented
on software defined radio. Specifically, modulation recognition is mostly
approached as a classification problem which is a supervised learning
framework. But it is here addressed as an unsupervised problem with introducing
new features for training, a new loss function and investigating the robustness
of the pipeline against several mismatch conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07318</identifier>
 <datestamp>2019-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07318</id><created>2019-02-18</created><authors><author><keyname>Zhou</keyname><forenames>Hailong</forenames></author><author><keyname>Zhao</keyname><forenames>Yuhe</forenames></author><author><keyname>Wang</keyname><forenames>Xu</forenames></author><author><keyname>Gao</keyname><forenames>Dingshan</forenames></author><author><keyname>Dong</keyname><forenames>Jianji</forenames></author><author><keyname>Zhang</keyname><forenames>Xinliang</forenames></author></authors><title>Self-learning photonic signal processor with an optical neural network
  chip</title><categories>eess.SP physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photonic signal processing is essential in the optical communication and
optical computing. Numerous photonic signal processors have been proposed, but
most of them exhibit limited reconfigurability and automaticity. A feature of
fully automatic implementation and intelligent response is highly desirable for
the multipurpose photonic signal processors. Here, we report and experimentally
demonstrate a fully self-learning and reconfigurable photonic signal processor
based on an optical neural network chip. The proposed photonic signal processor
is capable of performing various functions including multichannel optical
switching, optical multiple-input-multiple-output descrambler and tunable
optical filter. All the functions are achieved by complete self-learning. Our
demonstration suggests great potential for chip-scale fully programmable
optical signal processing with artificial intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07374</identifier>
 <datestamp>2019-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07374</id><created>2019-02-19</created><authors><author><keyname>Cai</keyname><forenames>Weicheng</forenames></author><author><keyname>Cai</keyname><forenames>Danwei</forenames></author><author><keyname>Huang</keyname><forenames>Shen</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>Utterance-level end-to-end language identification using attention-based
  CNN-BLSTM</title><categories>eess.AS cs.LG cs.SD</categories><comments>Accepted for ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an end-to-end language identification framework,
the attention-based Convolutional Neural Network-Bidirectional Long-short Term
Memory (CNN-BLSTM). The model is performed on the utterance level, which means
the utterance-level decision can be directly obtained from the output of the
neural network. To handle speech utterances with entire arbitrary and
potentially long duration, we combine CNN-BLSTM model with a self-attentive
pooling layer together. The front-end CNN-BLSTM module plays a role as local
pattern extractor for the variable-length inputs, and the following
self-attentive pooling layer is built on top to get the fixed-dimensional
utterance-level representation. We conducted experiments on NIST LRE07
closed-set task, and the results reveal that the proposed attention-based
CNN-BLSTM model achieves comparable error reduction with other state-of-the-art
utterance-level neural network approaches for all 3 seconds, 10 seconds, 30
seconds duration tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07383</identifier>
 <datestamp>2019-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07383</id><created>2019-02-19</created><updated>2019-02-20</updated><authors><author><keyname>Liu</keyname><forenames>Haojie</forenames></author><author><keyname>Chen</keyname><forenames>Tong</forenames></author><author><keyname>Lu</keyname><forenames>Ming</forenames></author><author><keyname>Shen</keyname><forenames>Qiu</forenames></author><author><keyname>Ma</keyname><forenames>Zhan</forenames></author></authors><title>Neural Video Compression using Spatio-Temporal Priors</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pursuit of higher compression efficiency continuously drives the advances
of video coding technologies. Fundamentally, we wish to find better
&quot;predictions&quot; or &quot;priors&quot; that are reconstructed previously to remove the
signal dependency efficiently and to accurately model the signal distribution
for entropy coding. In this work, we propose a neural video compression
framework, leveraging the spatial and temporal priors, independently and
jointly to exploit the correlations in intra texture, optical flow based
temporal motion and residuals. Spatial priors are generated using downscaled
low-resolution features, while temporal priors (from previous reference frames
and residuals) are captured using a convolutional neural network based
long-short term memory (ConvLSTM) structure in a temporal recurrent fashion.
All of these parts are connected and trained jointly towards the optimal
rate-distortion performance. Compared with the High-Efficiency Video Coding
(HEVC) Main Profile (MP), our method has demonstrated averaged 38%
Bjontegaard-Delta Rate (BD-Rate) improvement using standard common test
sequences, where the distortion is multi-scale structural similarity (MS-SSIM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07466</identifier>
 <datestamp>2019-04-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07466</id><created>2019-02-20</created><updated>2019-04-01</updated><authors><author><keyname>G&#xf6;kceli</keyname><forenames>Selahattin</forenames></author><author><keyname>Levanen</keyname><forenames>Toni</forenames></author><author><keyname>Riihonen</keyname><forenames>Taneli</forenames></author><author><keyname>Renfors</keyname><forenames>Markku</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>Frequency-Selective PAPR Reduction for OFDM</title><categories>eess.SP</categories><comments>Accepted for publication as a Correspondence in the IEEE Transactions
  on Vehicular Technology in March 2019. This is the revised version of
  original manuscript, and it is in press at the moment</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the peak-to-average power ratio (PAPR) problem in orthogonal
frequency-division multiplexing (OFDM) systems. In conventional clipping and
filtering based PAPR reduction techniques, clipping noise is allowed to spread
over the whole active passband, thus degrading the transmit signal quality
similarly at all active subcarriers. However, since modern radio networks
support frequency-multiplexing of users and services with highly different
quality-of-service expectations, clipping noise from PAPR reduction should be
distributed unequally over the corresponding physical resource blocks (PRBs).
To facilitate this, we present an efficient PAPR reduction technique, where
clipping noise can be flexibly controlled and filtered inside the transmitter
passband, allowing to control the transmitted signal quality per PRB. Numerical
results are provided in 5G New Radio (NR) mobile network context, demonstrating
the flexibility and efficiency of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07503</identifier>
 <datestamp>2019-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07503</id><created>2019-02-20</created><authors><author><keyname>Femenias</keyname><forenames>Guillem</forenames></author><author><keyname>Riera-Palou</keyname><forenames>Felip</forenames></author></authors><title>Cell-Free Millimeter-Wave Massive MIMO Systems with Limited Fronthaul
  Capacity</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network densification, massive multiple-input multiple-output (MIMO) and
millimeter-wave (mmWave) bands have recently emerged as some of the physical
layer enablers for the future generations of wireless communication networks
(5G and beyond). Grounded on prior work on sub-6~GHz cell-free massive MIMO
architectures, a novel framework for cell-free mmWave massive MIMO systems is
introduced that considers the use of low-complexity hybrid precoders/decoders
while factors in the impact of using capacity-constrained fronthaul links. A
suboptimal pilot allocation strategy is proposed that is grounded on the idea
of clustering by dissimilarity. Furthermore, based on mathematically tractable
expressions for the per-user achievable rates and the fronthaul capacity
consumption, max-min power allocation and fronthaul quantization optimization
algorithms are proposed that, combining the use of block coordinate descent
methods with sequential linear optimization programs, ensure a uniformly good
quality of service over the whole coverage area of the network. Simulation
results show that the proposed pilot allocation strategy eludes the
computational burden of the optimal small-scale CSI-based scheme while clearly
outperforming the classical random pilot allocation approaches. Moreover, they
also reveal the various existing trade-offs among the achievable max-min
per-user rate, the fronthaul requirements and the optimal hardware complexity
(i.e., number of antennas, number of RF chains).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07521</identifier>
 <datestamp>2019-11-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07521</id><created>2019-02-20</created><updated>2019-11-22</updated><authors><author><keyname>Schmitzer</keyname><forenames>Bernhard</forenames></author><author><keyname>Sch&#xe4;fers</keyname><forenames>Klaus P.</forenames></author><author><keyname>Wirth</keyname><forenames>Benedikt</forenames></author></authors><title>Dynamic Cell Imaging in PET with Optimal Transport Regularization</title><categories>cs.CV eess.IV math.OC</categories><comments>Revised version, to appear in IEEE Trans Med Imaging. Supplementary
  material attached as last page</comments><doi>10.1109/TMI.2019.2953773</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel dynamic image reconstruction method from PET listmode data
that could be particularly suited to tracking single or small numbers of cells.
In contrast to conventional PET reconstruction our method combines the
information from all detected events not only to reconstruct the dynamic
evolution of the radionuclide distribution, but also to improve the
reconstruction at each single time point by enforcing temporal consistency.
This is achieved via optimal transport regularization where in principle, among
all possible temporally evolving radionuclide distributions consistent with the
PET measurement, the one is chosen with least kinetic motion energy. The
reconstruction is found by convex optimization so that there is no dependence
on the initialization of the method. We study its behaviour on simulated data
of a human PET system and demonstrate its robustness even in settings with very
low radioactivity. In contrast to previously reported cell tracking algorithms,
our technique is oblivious to the number of tracked cells. Without any
additional complexity one or multiple cells can be reconstructed, and the model
automatically determines the number of particles. For instance, four
radiolabelled cells moving at a velocity of 3.1 mm/s and a PET recorded count
rate of 1.1 cps (for each cell) could be simultaneously tracked with a tracking
accuracy of 5.3 mm inside a simulated human body.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07542</identifier>
 <datestamp>2019-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07542</id><created>2019-02-20</created><updated>2019-03-06</updated><authors><author><keyname>Cheng</keyname><forenames>Wenchi</forenames></author><author><keyname>Li</keyname><forenames>Zan</forenames></author><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Liang</keyname><forenames>Liping</forenames></author><author><keyname>Zhang</keyname><forenames>Hailin</forenames></author></authors><title>Mode Hopping for Anti-Jamming in Cognitive Radio Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequency hopping (FH) is an effective anti-jamming technology in cognitive
radio networks (CRNs). However, it is difficult to significantly increase the
anti-jamming results because of the growing crowded spectrum in wireless
communications. Orbital momentum angular (OAM) provides a new mode dimension
for anti-jamming without consuming extra power and frequency resources in CRNs.
In this paper, we propose the mode-frequency hopping (MFH) scheme, which
jointly uses the mode hopping and the traditional FH scheme for anti-jamming to
significantly increase the capacity of secondary users (SUs). We derive the
false alarm probability and transmission outage probability for CRNs under our
proposed MFH scheme. Then, based on the two derived probabilities, we calculate
the capacity of SUs under the MFH scheme. Numerical results show that our
developed MFH scheme can achieve better anti-jamming results as compared with
the traditional FH scheme in CRNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07619</identifier>
 <datestamp>2019-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07619</id><created>2019-02-20</created><authors><author><keyname>Yangzhang</keyname><forenames>Xianhe</forenames></author><author><keyname>Aref</keyname><forenames>Vahid</forenames></author><author><keyname>Le</keyname><forenames>Son Thai</forenames></author><author><keyname>Buelow</keyname><forenames>Henning</forenames></author><author><keyname>Lavery</keyname><forenames>Domanic</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>Dual-polarisation Non-linear Frequency-division Multiplexed Transmission
  with b-Modulation</title><categories>eess.SP</categories><comments>submitted to Journal of Lightwave Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been much interest in the non-linear frequency-division
multiplexing (NFDM) transmission scheme in the optical fibre communication
system. Up to date, most of the demonstrated NFDM schemes have employed only
single polarisation for data transmission. Employing both polarisations can
potentially double the data rate of NFDM systems. We investigate in simulation
a dual-polarisation NFDM transmission with data modulation on the
$b$-coefficient. First, a transformation that facilitates the dual-polarisation
$b$-modulation was built upon an existing transformation. Second, the $q_c$-
and $b$-modulation for dual-polarisation were compared in terms of Q-factor,
spectral efficiency (SE), and correlation of sub-carriers. The correlation is
quantified via information theoretic metrics, joint and individual entropy. The
polarisation-multiplexed $b$-modulation system shows 1 dB Q-factor improvement
over $q_c$-modulation system due to a weaker correlation of sub-carriers and
less effective noise. Finally, the $b$-modulation system was optimised for high
data rate, achieving a record net data rate of 400 Gbps (SE of 7.2 bit/s/Hz)
over $12\times 80$ km of standard single-mode fibre (SSMF) with erbium-doped
fibre amplifiers (EDFAs). Based on the above simulation results, we further
point out the drawbacks of our current system and quantify the error introduced
by the transceiver algorithms and non-integrability of the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07678</identifier>
 <datestamp>2019-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07678</id><created>2019-02-11</created><updated>2019-06-12</updated><authors><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Marzetta</keyname><forenames>Thomas L.</forenames></author></authors><title>Massive MIMO is a Reality -- What is Next? Five Promising Research
  Directions for Antenna Arrays</title><categories>eess.SP cs.IT math.IT</categories><comments>20 pages, 9 figures, submitted to Digital Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive MIMO (multiple-input multiple-output) is no longer a &quot;wild&quot; or
&quot;promising&quot; concept for future cellular networks - in 2018 it became a reality.
Base stations (BSs) with 64 fully digital transceiver chains were commercially
deployed in several countries, the key ingredients of Massive MIMO have made it
into the 5G standard, the signal processing methods required to achieve
unprecedented spectral efficiency have been developed, and the limitation due
to pilot contamination has been resolved. Even the development of fully digital
Massive MIMO arrays for mmWave frequencies - once viewed prohibitively
complicated and costly - is well underway. In a few years, Massive MIMO with
fully digital transceivers will be a mainstream feature at both sub-6 GHz and
mmWave frequencies. In this paper, we explain how the first chapter of the
Massive MIMO research saga has come to an end, while the story has just begun.
The coming wide-scale deployment of BSs with massive antenna arrays opens the
door to a brand new world where spatial processing capabilities are
omnipresent. In addition to mobile broadband services, the antennas can be used
for other communication applications, such as low-power machine-type or
ultra-reliable communications, as well as non-communication applications such
as radar, sensing and positioning. We outline five new Massive MIMO related
research directions: Extremely large aperture arrays, Holographic Massive MIMO,
Six-dimensional positioning, Large-scale MIMO radar, and Intelligent Massive
MIMO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07817</identifier>
 <datestamp>2019-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07817</id><created>2019-02-20</created><authors><author><keyname>Haque</keyname><forenames>Albert</forenames></author><author><keyname>Guo</keyname><forenames>Michelle</forenames></author><author><keyname>Verma</keyname><forenames>Prateek</forenames></author><author><keyname>Fei-Fei</keyname><forenames>Li</forenames></author></authors><title>Audio-Linguistic Embeddings for Spoken Sentences</title><categories>cs.SD cs.CL eess.AS</categories><comments>International Conference on Acoustics, Speech, and Signal Processing
  (ICASSP) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose spoken sentence embeddings which capture both acoustic and
linguistic content. While existing works operate at the character, phoneme, or
word level, our method learns long-term dependencies by modeling speech at the
sentence level. Formulated as an audio-linguistic multitask learning problem,
our encoder-decoder model simultaneously reconstructs acoustic and natural
language features from audio. Our results show that spoken sentence embeddings
outperform phoneme and word-level baselines on speech recognition and emotion
recognition tasks. Ablation studies show that our embeddings can better model
high-level acoustic concepts while retaining linguistic content. Overall, our
work illustrates the viability of generic, multi-modal sentence embeddings for
spoken language understanding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07821</identifier>
 <datestamp>2019-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07821</id><created>2019-02-20</created><authors><author><keyname>Tang</keyname><forenames>Yun</forenames></author><author><keyname>Ding</keyname><forenames>Guohong</forenames></author><author><keyname>Huang</keyname><forenames>Jing</forenames></author><author><keyname>He</keyname><forenames>Xiaodong</forenames></author><author><keyname>Zhou</keyname><forenames>Bowen</forenames></author></authors><title>Deep Speaker Embedding Learning with Multi-Level Pooling for
  Text-Independent Speaker Verification</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted by ICASSP2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to improve the widely used deep speaker embedding x-vector
model. We propose the following improvements: (1) a hybrid neural network
structure using both time delay neural network (TDNN) and long short-term
memory neural networks (LSTM) to generate complementary speaker information at
different levels; (2) a multi-level pooling strategy to collect speaker
information from both TDNN and LSTM layers; (3) a regularization scheme on the
speaker embedding extraction layer to make the extracted embeddings suitable
for the following fusion step. The synergy of these improvements are shown on
the NIST SRE 2016 eval test (with a 19% EER reduction) and SRE 2018 dev test
(with a 9% EER reduction), as well as more than 10% DCF scores reduction on
these two test sets over the x-vector baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07859</identifier>
 <datestamp>2019-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07859</id><created>2019-02-20</created><authors><author><keyname>Wang</keyname><forenames>Fangfei</forenames></author><author><keyname>Guan</keyname><forenames>Dong</forenames></author><author><keyname>Zhao</keyname><forenames>Long</forenames></author><author><keyname>Zheng</keyname><forenames>Kan</forenames></author></authors><title>Cooperative V2X for High Definition Map Transmission Based on Vehicle
  Mobility</title><categories>eess.SP</categories><comments>5 pages, 4 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-definition (HD) map transmission is considered as a key technology for
automatic driving, which enables vehicles to obtain the precise road and
surrounding environment information for further localization and navigation.
Guaranteeing the huge requirement of HD map data, the objective of this paper
is to reduce the power consumption of vehicular networks. By leveraging the
mobile rule of vehicles, a collaborative vehicle to everything (V2X)
transmission scheme is proposed for the HD map transmission. Numerical results
indicate that the proposed scheme can satisfy the transmission rate requirement
of HD map with low power consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07881</identifier>
 <datestamp>2019-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07881</id><created>2019-02-21</created><authors><author><keyname>von Neumann</keyname><forenames>Thilo</forenames></author><author><keyname>Kinoshita</keyname><forenames>Keisuke</forenames></author><author><keyname>Delcroix</keyname><forenames>Marc</forenames></author><author><keyname>Araki</keyname><forenames>Shoko</forenames></author><author><keyname>Nakatani</keyname><forenames>Tomohiro</forenames></author><author><keyname>Haeb-Umbach</keyname><forenames>Reinhold</forenames></author></authors><title>All-neural online source separation, counting, and diarization for
  meeting analysis</title><categories>eess.AS cs.LG cs.SD</categories><comments>5 pages, to appear in ICASSP2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic meeting analysis comprises the tasks of speaker counting, speaker
diarization, and the separation of overlapped speech, followed by automatic
speech recognition. This all has to be carried out on arbitrarily long sessions
and, ideally, in an online or block-online manner. While significant progress
has been made on individual tasks, this paper presents for the first time an
all-neural approach to simultaneous speaker counting, diarization and source
separation. The NN-based estimator operates in a block-online fashion and
tracks speakers even if they remain silent for a number of time blocks, thus
learning a stable output order for the separated sources. The neural network is
recurrent over time as well as over the number of sources. The simulation
experiments show that state of the art separation performance is achieved,
while at the same time delivering good diarization and source counting results.
It even generalizes well to an unseen large number of blocks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07935</identifier>
 <datestamp>2019-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07935</id><created>2019-02-21</created><authors><author><keyname>Augustin</keyname><forenames>Sven</forenames></author><author><keyname>Jung</keyname><forenames>Peter</forenames></author><author><keyname>Frohmann</keyname><forenames>Sven</forenames></author><author><keyname>Huebers</keyname><forenames>Heinz-Wilhelm</forenames></author></authors><title>Terahertz dynamic aperture imaging at stand-off distances using a
  Compressed Sensing protocol</title><categories>physics.ins-det eess.IV</categories><comments>9 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this text, results of a 0.35 terahertz (THz) dynamic aperture imaging
approach are presented. The experiments use an optical modulation approach and
a single pixel detector at a stand-off imaging distance of approx 1 meter. The
optical modulation creates dynamic apertures of 5cm diameter with approx 2000
individually controllable elements. An optical modulation approach is used here
for the first time at a large far-field distance, for the investigation of
various test targets in a field-of-view of 8 x 8 cm. The results highlight the
versatility of this modulation technique and show that this imaging paradigm is
applicable even at large far-field distances. It proves the feasibility of this
imaging approach for potential applications like stand-off security imaging or
far field THz microscopy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07985</identifier>
 <datestamp>2020-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.07985</id><created>2019-02-21</created><updated>2020-02-10</updated><authors><author><keyname>Gao</keyname><forenames>Yang</forenames></author><author><keyname>Jiao</keyname><forenames>Shuming</forenames></author><author><keyname>Fang</keyname><forenames>Juncheng</forenames></author><author><keyname>Lei</keyname><forenames>Ting</forenames></author><author><keyname>Xie</keyname><forenames>Zhenwei</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaocong</forenames></author></authors><title>Multiple-image encryption and hiding with an optical diffractive neural
  network</title><categories>cs.CV eess.IV</categories><doi>10.1016/j.optcom.2020.125476</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cascaded phase-only mask architecture (or an optical diffractive neural
network) can be employed for different optical information processing tasks
such as pattern recognition, orbital angular momentum (OAM) mode conversion,
image salience detection and image encryption. However, for optical encryption
and watermarking applications, such a system usually cannot process multiple
pairs of input images and output images simultaneously. In our proposed scheme,
multiple input images can be simultaneously fed to an optical diffractive
neural network (DNN) system and each corresponding output image will be
displayed in a non-overlap sub-region in the output imaging plane. Each input
image undergoes a different optical transform in an independent channel within
the same system. The multiple cascaded phase masks in the system can be
effectively optimized by a wavefront matching algorithm. Similar to recent
optical pattern recognition and mode conversion works, the orthogonality
property is employed to design a multiplexed DNN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08034</identifier>
 <datestamp>2019-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08034</id><created>2019-02-16</created><authors><author><keyname>Kokalj-Filipovic</keyname><forenames>Silvija</forenames></author><author><keyname>Miller</keyname><forenames>Rob</forenames></author><author><keyname>Chang</keyname><forenames>Nicholas</forenames></author><author><keyname>Lau</keyname><forenames>Chi Leung</forenames></author></authors><title>Mitigation of Adversarial Examples in RF Deep Classifiers Utilizing
  AutoEncoder Pre-training</title><categories>eess.SP cs.LG stat.ML</categories><comments>arXiv admin note: substantial text overlap with arXiv:1902.06044</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial examples in machine learning for images are widely publicized and
explored. Illustrations of misclassifications caused by slightly perturbed
inputs are abundant and commonly known (e.g., a picture of panda imperceptibly
perturbed to fool the classifier into incorrectly labeling it as a gibbon).
Similar attacks on deep learning (DL) for radio frequency (RF) signals and
their mitigation strategies are scarcely addressed in the published work. Yet,
RF adversarial examples (AdExs) with minimal waveform perturbations can cause
drastic, targeted misclassification results, particularly against spectrum
sensing/survey applications (e.g. BPSK is mistaken for 8-PSK). Our research on
deep learning AdExs and proposed defense mechanisms are RF-centric, and
incorporate physical world, over-the-air (OTA) effects. We herein present
defense mechanisms based on pre-training the target classifier using an
autoencoder. Our results validate this approach as a viable mitigation method
to subvert adversarial attacks against deep learning-based communications and
radar sensing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08051</identifier>
 <datestamp>2019-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08051</id><created>2019-02-21</created><authors><author><keyname>Dawalatabad</keyname><forenames>Nauman</forenames></author><author><keyname>Madikeri</keyname><forenames>Srikanth</forenames></author><author><keyname>Sekhar</keyname><forenames>C Chandra</forenames></author><author><keyname>Murthy</keyname><forenames>Hema A</forenames></author></authors><title>Incremental Transfer Learning in Two-pass Information Bottleneck based
  Speaker Diarization System for Meetings</title><categories>eess.AS cs.SD</categories><comments>5 pages, 2 figures, To appear in Proc. ICASSP 2019, May 12-17, 2019,
  Brighton, UK</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The two-pass information bottleneck (TPIB) based speaker diarization system
operates independently on different conversational recordings. TPIB system does
not consider previously learned speaker discriminative information while
diarizing new conversations. Hence, the real time factor (RTF) of TPIB system
is high owing to the training time required for the artificial neural network
(ANN). This paper attempts to improve the RTF of the TPIB system using an
incremental transfer learning approach where the parameters learned by the ANN
from other conversations are updated using current conversation rather than
learning parameters from scratch. This reduces the RTF significantly. The
effectiveness of the proposed approach compared to the baseline IB and the TPIB
systems is demonstrated on standard NIST and AMI conversational meeting
datasets. With a minor degradation in performance, the proposed system shows a
significant improvement of 33.07% and 24.45% in RTF with respect to TPIB system
on the NIST RT-04Eval and AMI-1 datasets, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08072</identifier>
 <datestamp>2019-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08072</id><created>2019-02-21</created><authors><author><keyname>Hu</keyname><forenames>Zhinan</forenames></author><author><keyname>Zhang</keyname><forenames>Weile</forenames></author></authors><title>Radiation Efficiency Aware High-Mobility Massive MIMO with Antenna
  Selection</title><categories>eess.SP</categories><comments>4 pages, 4 figures, correspondence</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-mobility wireless communications have received a lot of attentions in
the past few years. In this paper, we consider angle-domain Doppler shifts
compensation scheme to reduce the channel time variation for the high-mobility
uplink from a high-speed terminal (HST) to a base station (BS). We propose to
minimize Doppler spread by antenna weighting under the constraint of
maintaining radiation efficiency. The sequential parametric convex
approximation (SPCA) algorithm is exploited to solve the above non-convex
problem. Moreover, in order to save the RF chains, we further exploit the idea
of antenna selection for high-mobility wireless communications. Simulations
verify the effectiveness of the proposed studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08167</identifier>
 <datestamp>2019-02-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08167</id><created>2019-02-21</created><authors><author><keyname>Wang</keyname><forenames>Xinan</forenames></author><author><keyname>Wang</keyname><forenames>Yishen</forenames></author><author><keyname>Shi</keyname><forenames>Di</forenames></author><author><keyname>Wang</keyname><forenames>Jianhui</forenames></author></authors><title>A Stacked Autoencoder Application for Residential Load Curve Forecast
  and Peak Shaving</title><categories>eess.SP</categories><comments>Accepted by IEEE PESGM 2019, Atlanta, GA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the last ten years, utilities have observed on-going transitions on
consumers' load curves. The previously flat load curves have more frequently
turned into duck-shape. This is jointly caused by the increasing household
loads as well as the popularity of rooftop solar photovoltaic. Such load curve
transition challenges the operational flexibility of the existing systems and
greatly increases the per-MWh energy costs. Peak shaving, in this context,
becomes a critical task to demand-side management. Owing to the development of
Battery Energy Storage Systems (BESS), numerous peak shaving strategies have
been developed and implemented. In this paper, by applying a stacked
autoencoder (SAE)-based residential peak load curve forecasting technology, we
further lift the peaking shaving capabilities of BESSs to a new level. The
proposed strategy takes into account the welfares of both generation-side and
demand-side and reaches an optimal balance. A comprehensive case study using
smart meter data demonstrates the effectiveness of the proposed method in peak
shaving application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08199</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08199</id><created>2019-02-21</created><authors><author><keyname>Demir</keyname><forenames>Ali Fatih</forenames></author><author><keyname>Ankarali</keyname><forenames>Z. Esat</forenames></author><author><keyname>Liu</keyname><forenames>Y.</forenames></author><author><keyname>Abbasi</keyname><forenames>Q. H.</forenames></author><author><keyname>Qaraqe</keyname><forenames>K.</forenames></author><author><keyname>Serpedin</keyname><forenames>E.</forenames></author><author><keyname>Arslan</keyname><forenames>Huseyin</forenames></author><author><keyname>Gitlin</keyname><forenames>R. D.</forenames></author></authors><title>In Vivo Wireless Channel Modeling</title><categories>eess.SP</categories><comments>25 pages, 17 figures, 7 tables, URL of the final version:
  https://digital-library.theiet.org/content/books/10.1049/pbte065e_ch7 . arXiv
  admin note: substantial text overlap with arXiv:1902.06860</comments><journal-ref>Advances in Body-Centric Wireless Communication: Applications and
  state-of-the-art, Inst. Eng. Technol. (IET), Jun. 2016, ch. 7, pp. 187-211</journal-ref><doi>10.1049/pbte065e_ch7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter, the state of the art of in vivo wireless channel
characterization has been presented. Various studies described in the
literature are dedicated to the in vivo communication channel, and they
consider different parameters in studying various anatomical regions.
Furthermore, the location-dependent characteristics of in vivo wireless
communication at 915 MHz are analyzed in detail via numerical and experimental
investigations. A complete model for the in vivo channel is not available and
remains an open research problem. However, considering the expected future
growth of implanted technologies and their potential use for the detection and
diagnosis of various health-related issues in the human body, the channel
modeling studies should be further extended to develop better and more
efficient communications systems for future in vivo systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08213</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08213</id><created>2019-02-21</created><authors><author><keyname>Harwath</keyname><forenames>David</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Towards Visually Grounded Sub-Word Speech Unit Discovery</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Accepted to ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the manner in which interpretable sub-word
speech units emerge within a convolutional neural network model trained to
associate raw speech waveforms with semantically related natural image scenes.
We show how diphone boundaries can be superficially extracted from the
activation patterns of intermediate layers of the model, suggesting that the
model may be leveraging these events for the purpose of word recognition. We
present a series of experiments investigating the information encoded by these
events.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08222</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08222</id><created>2019-02-21</created><authors><author><keyname>Sun</keyname><forenames>Ke</forenames></author><author><keyname>Esnaola</keyname><forenames>I&#xf1;aki</forenames></author><author><keyname>Tulino</keyname><forenames>Antonia M.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Learning requirements for stealth attacks</title><categories>cs.IT cs.SY eess.SP math.IT</categories><comments>International Conference on Acoustics, Speech, and Signal Processing
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The learning data requirements are analyzed for the construction of stealth
attacks in state estimation. In particular, the training data set is used to
compute a sample covariance matrix that results in a random matrix with a
Wishart distribution. The ergodic attack performance is defined as the average
attack performance obtained by taking the expectation with respect to the
distribution of the training data set. The impact of the training data size on
the ergodic attack performance is characterized by proposing an upper bound for
the performance. Simulations on the IEEE 30-Bus test system show that the
proposed bound is tight in practical settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08307</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08307</id><created>2019-02-19</created><authors><author><keyname>Nunes</keyname><forenames>Anderson Santos</forenames></author><author><keyname>Schwanz</keyname><forenames>Allan</forenames></author><author><keyname>Postali</keyname><forenames>Eduardo</forenames></author><author><keyname>Kruger</keyname><forenames>Marcelo</forenames></author></authors><title>An\'alise t\'ermica\-fluidodin\^amica de um transformador de energia a
  seco atrav\'es da din\^amica dos fluidos computacional</title><categories>eess.SP</categories><comments>in Portuguese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cooling system is a key factor in power transformer designs. The frequent
need for optimized projects further increases the importance of development
through of increasingly developed tools. This work aims to evaluate a
transformer design, in which the refrigeration is performed through of exhaust
fans and heat exchangers installed on the lower side of the transformer. The
model is elaborated applying a symmetry, reducing the model to be analyzed. In
order to evaluate the best configuration in terms of positioning, flow rate and
quantity of understand the main thermal and fluid dynamics characteristics of
the flow inside the transformer, the Computational Fluid Dynamics tool is used.
The methodology employed is to solve the numerically, through the ANSYS CFX
computational package, the flow and energy equations inside the transformer
tank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08308</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08308</id><created>2019-02-19</created><authors><author><keyname>Dai</keyname><forenames>Renchang</forenames></author><author><keyname>Zhang</keyname><forenames>Xiang</forenames></author><author><keyname>Shi</keyname><forenames>Junjie</forenames></author><author><keyname>Liu</keyname><forenames>Guangyi</forenames></author><author><keyname>Yuan</keyname><forenames>Chen</forenames></author><author><keyname>Wang</keyname><forenames>Zhiwei</forenames></author></authors><title>Simplify Power Flow Calculation Using Terminal Circuit and PMU
  Measurements</title><categories>eess.SP</categories><comments>5 pages, 5 figures, 4 tables, 2019 IEEE Power &amp; Energy Society
  General Meeting</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power flow calculation methods have been developed in decades using power
injections and Newton-Raphson method. The nonlinear characteristics of the
power flow to the bus voltage require Jacobian matrix reformation and
refactorization in each iteration. Power network is composed by resistors,
reactors, and capacitors which is a linear circuit when investigating the node
voltages with the node current injections. To take the advantage of the
linearity, this paper proposed to use terminal circuit model and PMU voltage
phase angle measurements to simplify power flow calculation. When updating
current injections at the righthand side of power flow equations and using PMU
voltage phase angle measurements representing PV buses voltage phase angle, the
Jacobian matrix is constant during the iteration. The simplification reduces
the computational efforts and improves the computation efficiency. The proposed
method is tested on the IEEE 14-bus and IEEE 118-bus standard systems. The
results are validated by traditional power flow solution and the computation
efficiency is demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08314</identifier>
 <datestamp>2020-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08314</id><created>2019-02-21</created><updated>2020-01-01</updated><authors><author><keyname>Trowitzsch</keyname><forenames>Ivo</forenames></author><author><keyname>Taghia</keyname><forenames>Jalil</forenames></author><author><keyname>Kashef</keyname><forenames>Youssef</forenames></author><author><keyname>Obermayer</keyname><forenames>Klaus</forenames></author></authors><title>The NIGENS General Sound Events Database</title><categories>cs.SD cs.LG cs.MM eess.AS</categories><comments>update to v4: added classification rate table, corrections, updates</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational auditory scene analysis is gaining interest in the last years.
Trailing behind the more mature field of speech recognition, it is particularly
general sound event detection that is attracting increasing attention. Crucial
for training and testing reasonable models is having available enough suitable
data -- until recently, general sound event databases were hardly found. We
release and present a database with 714 wav files containing isolated high
quality sound events of 14 different types, plus 303 `general' wav files of
anything else but these 14 types. All sound events are strongly labeled with
perceptual on- and offset times, paying attention to omitting in-between
silences. The amount of isolated sound events, the quality of annotations, and
the particular general sound class distinguish NIGENS from other databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08391</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08391</id><created>2019-02-22</created><authors><author><keyname>Sadeghi</keyname><forenames>Meysam</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Physical Adversarial Attacks Against End-to-End Autoencoder
  Communication Systems</title><categories>cs.IT cs.CR cs.LG eess.SP math.IT</categories><comments>to appear at IEEE Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that end-to-end learning of communication systems through deep neural
network (DNN) autoencoders can be extremely vulnerable to physical adversarial
attacks. Specifically, we elaborate how an attacker can craft effective
physical black-box adversarial attacks. Due to the openness (broadcast nature)
of the wireless channel, an adversary transmitter can increase the
block-error-rate of a communication system by orders of magnitude by
transmitting a well-designed perturbation signal over the channel. We reveal
that the adversarial attacks are more destructive than jamming attacks. We also
show that classical coding schemes are more robust than autoencoders against
both adversarial and jamming attacks. The codes are available at [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08431</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08431</id><created>2019-02-22</created><authors><author><keyname>Rosario</keyname><forenames>Vanderson Martins do</forenames></author><author><keyname>Borin</keyname><forenames>Edson</forenames></author><author><keyname>Breternitz</keyname><forenames>Mauricio</forenames><suffix>Jr</suffix></author></authors><title>The Multi-Lane Capsule Network (MLCN)</title><categories>cs.CV cs.LG eess.IV</categories><doi>10.1109/LSP.2019.2915661</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce Multi-Lane Capsule Networks (MLCN), which are a separable and
resource efficient organization of Capsule Networks (CapsNet) that allows
parallel processing, while achieving high accuracy at reduced cost. A MLCN is
composed of a number of (distinct) parallel lanes, each contributing to a
dimension of the result, trained using the routing-by-agreement organization of
CapsNet. Our results indicate similar accuracy with a much reduced cost in
number of parameters for the Fashion-MNIST and Cifar10 datsets. They also
indicate that the MLCN outperforms the original CapsNet when using a proposed
novel configuration for the lanes. MLCN also has faster training and inference
times, being more than two-fold faster than the original CapsNet in the same
accelerator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08463</identifier>
 <datestamp>2019-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08463</id><created>2019-02-22</created><updated>2019-04-16</updated><authors><author><keyname>Basar</keyname><forenames>Ertugrul</forenames></author></authors><title>Transmission Through Large Intelligent Surfaces: A New Frontier in
  Wireless Communications</title><categories>eess.SP cs.IT math.IT</categories><comments>2019 European Conference on Networks and Communications (EuCNC) (to
  appear)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, transmission through large intelligent surfaces (LIS) that
intentionally modify the phases of incident waves to improve the signal quality
at the receiver, is put forward as a promising candidate for future wireless
communication systems and standards. For the considered LIS-assisted system, a
general mathematical framework is presented for the calculation of symbol error
probability (SEP) by deriving the distribution of the received signal-to-noise
ratio (SNR). Next, the new concept of using the LIS itself as an access point
(AP) is proposed. Extensive computer simulation results are provided to assess
the potential of LIS-based transmission, in which the LIS acts either as an
intelligent reflector or an AP with or without the knowledge of channel phases.
Our findings reveal that LIS-based communications can become a game-changing
paradigm for future wireless systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08556</identifier>
 <datestamp>2019-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08556</id><created>2019-02-22</created><authors><author><keyname>Fehenberger</keyname><forenames>Tobias</forenames></author><author><keyname>Millar</keyname><forenames>David S.</forenames></author><author><keyname>Koike-Akino</keyname><forenames>Toshiaki</forenames></author><author><keyname>Kojima</keyname><forenames>Keisuke</forenames></author><author><keyname>Parsons</keyname><forenames>Kieran</forenames></author></authors><title>Parallel-Amplitude Architecture and Subset Ranking for Fast Distribution
  Matching</title><categories>eess.SP</categories><comments>10 pages, 6 figures/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distribution matcher (DM) maps a binary input sequence into a block of
nonuniformly distributed symbols. To facilitate the implementation of shaped
signaling, fast DM solutions with high throughput and low serialism are
required. We propose a novel DM architecture with parallel amplitudes (PADM)
for which m component DMs, each with a different binary output alphabet, are
operated in parallel in order to generate a shaped sequence with m amplitudes.
With negligible rate loss compared to a single nonbinary DM, PA-DM has a
parallelization factor that grows linearly with m, and the component DMs have
reduced output lengths. For such binary-output DMs, a novel
constant-composition DM (CCDM) algorithm based on subset ranking (SR) is
proposed. We present SR-CCDM algorithms that are serial in the minimum number
of occurrences of either binary symbol for mapping and fully parallel in
demapping. For distributions that are optimized for the additive white Gaussian
noise (AWGN) channel, we numerically show that PA-DM combined with SR-CCDM can
reduce the number of sequential processing steps by more than an order of
magnitude, while having a rate loss that is comparable to conventional
nonbinary CCDM with arithmetic coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08665</identifier>
 <datestamp>2019-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08665</id><created>2019-02-22</created><authors><author><keyname>Mishra</keyname><forenames>M.</forenames></author><author><keyname>Mattingly</keyname><forenames>J.</forenames></author><author><keyname>Kolbas</keyname><forenames>R. M.</forenames></author></authors><title>Application of deconvolution to recover frequency-domain multiplexed
  detector pulses</title><categories>eess.SP physics.ins-det</categories><journal-ref>Nucl. Instrum. Meth. A 929 (2019) 57-65</journal-ref><doi>10.1016/j.nima.2019.03.043</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiplexing of radiation detectors reduces the number of readout channels,
which in turn reduces the number of digitizer input channels for data
acquisition. We recently demonstrated frequency domain multiplexing (FDM) of
pulse mode radiation detectors using a resonator that converts the detector
signal into a damped sinusoid by convolution. The detectors were given unique
&quot;tags&quot; by the oscillation frequency of each resonator. The charge collected and
the time-of-arrival of the detector pulse were estimated from the corresponding
resonator output in the frequency domain.
  In this paper, we demonstrate a new method to recover the detector pulse from
the damped sinusoidal output by deconvolution. Deconvolution converts the
frequency-encoded detector signal back to the original detector pulse. We have
developed a new prototype FDM system to multiplex organic scintillators based
on convolution and deconvolution. Using the new prototype, the charge collected
under the anode pulse can be estimated from the recovered pulse with an
uncertainty of about 4.4 keVee (keV electron equivalent). The time-of-arrival
can be estimated from the recovered pulse with an uncertainty of about 102 ps.
We also used a CeBr3 inorganic scintillator to measure the Cs-137 gamma
spectrum using the recovered pulses and found a standard deviation of 13.8 keV
at 662 keV compared to a standard deviation of 13.5 keV when the original
pulses were used. Coincidence measurements with Na-22 using the deconvolved
pulses resulted in a timing uncertainty of 617 ps compared to an uncertainty of
603 ps using the original pulses. Pulse shape discrimination was also performed
using Cf-252 source and EJ-309 organic scintillator pulses recovered by
deconvolution. A figure of merit value of 1.08 was observed when the recovered
pulses were used compared to 1.2 for the original pulses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08670</identifier>
 <datestamp>2019-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08670</id><created>2019-02-22</created><updated>2019-02-27</updated><authors><author><keyname>Li</keyname><forenames>Xingyu</forenames></author><author><keyname>Radulovic</keyname><forenames>Marko</forenames></author><author><keyname>Kanjer</keyname><forenames>Ksenija</forenames></author><author><keyname>Plataniotis</keyname><forenames>Konstantinos N.</forenames></author></authors><title>Discriminative Pattern Mining for Breast Cancer Histopathology Image
  Classification via Fully Convolutional Autoencoder</title><categories>cs.CV cs.LG eess.IV q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate diagnosis of breast cancer in histopathology images is challenging
due to the heterogeneity of cancer cell growth as well as of a variety of
benign breast tissue proliferative lesions. In this paper, we propose a
practical and self-interpretable invasive cancer diagnosis solution. With
minimum annotation information, the proposed method mines contrast patterns
between normal and malignant images in unsupervised manner and generates a
probability map of abnormalities to verify its reasoning. Particularly, a fully
convolutional autoencoder is used to learn the dominant structural patterns
among normal image patches. Patches that do not share the characteristics of
this normal population are detected and analyzed by one-class support vector
machine and 1-layer neural network. We apply the proposed method to a public
breast cancer image set. Our results, in consultation with a senior
pathologist, demonstrate that the proposed method outperforms existing methods.
The obtained probability map could benefit the pathology practice by providing
visualized verification data and potentially leads to a better understanding of
data-driven diagnosis solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08676</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08676</id><created>2019-02-22</created><authors><author><keyname>Zheng</keyname><forenames>Le</forenames></author><author><keyname>Lops</keyname><forenames>Marco</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Radar and Communication Co-existence: an Overview</title><categories>eess.SP cs.SY</categories><comments>Submitted to IEEE Signal Processing Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increased amounts of bandwidth are required to guarantee both
high-quality/high-rate wireless services (4G and 5G) and reliable sensing
capabilities such as automotive radar, air traffic control, earth geophysical
monitoring and security applications. Therefore, co-existence between radar and
communication systems using overlapping bandwidths has been a primary
investigation field in recent years. Various signal processing techniques such
as interference mitigation, pre-coding or spatial separation, and waveform
design allow both radar and communications to share the spectrum. This article
reviews recent work on co-existence between radar and communication systems,
including signal models, waveform design and signal processing techniques. Our
goal is to survey contributions in this area in order to provide a primary
starting point for new researchers interested in these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08710</identifier>
 <datestamp>2019-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08710</id><created>2019-02-22</created><updated>2019-04-14</updated><authors><author><keyname>Engel</keyname><forenames>Jesse</forenames></author><author><keyname>Agrawal</keyname><forenames>Kumar Krishna</forenames></author><author><keyname>Chen</keyname><forenames>Shuo</forenames></author><author><keyname>Gulrajani</keyname><forenames>Ishaan</forenames></author><author><keyname>Donahue</keyname><forenames>Chris</forenames></author><author><keyname>Roberts</keyname><forenames>Adam</forenames></author></authors><title>GANSynth: Adversarial Neural Audio Synthesis</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>Colab Notebook: http://goo.gl/magenta/gansynth-demo</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient audio synthesis is an inherently difficult machine learning task,
as human perception is sensitive to both global structure and fine-scale
waveform coherence. Autoregressive models, such as WaveNet, model local
structure at the expense of global latent structure and slow iterative
sampling, while Generative Adversarial Networks (GANs), have global latent
conditioning and efficient parallel sampling, but struggle to generate
locally-coherent audio waveforms. Herein, we demonstrate that GANs can in fact
generate high-fidelity and locally-coherent audio by modeling log magnitudes
and instantaneous frequencies with sufficient frequency resolution in the
spectral domain. Through extensive empirical investigations on the NSynth
dataset, we demonstrate that GANs are able to outperform strong WaveNet
baselines on automated and human evaluation metrics, and efficiently generate
audio several orders of magnitude faster than their autoregressive
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08736</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08736</id><created>2019-02-23</created><updated>2019-06-18</updated><authors><author><keyname>Harell</keyname><forenames>Alon</forenames></author><author><keyname>Makonin</keyname><forenames>Stephen</forenames></author><author><keyname>Baji&#x107;</keyname><forenames>Ivan V.</forenames></author></authors><title>Wavenilm: A causal neural network for power disaggregation from the
  complex power signal</title><categories>eess.SP</categories><comments>44th International Conference on Acoustics, Speech, and Signal
  Processing (ICASSP 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-intrusive load monitoring (NILM) helps meet energy conservation goals by
estimating individual appliance power usage from a single aggregate
measurement. Deep neural networks have become increasingly popular in
attempting to solve NILM problems; however, many of them are not causal which
is important for real-time application. We present a causal 1-D convolutional
neural network inspired by WaveNet for NILM on low-frequency data. We also
study using various components of the complex power signal for NILM, and
demonstrate that using all four components available in a popular NILM dataset
(current, active power, reactive power, and apparent power) we achieve faster
convergence and higher performance than state-of-the-art results for the same
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08954</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08954</id><created>2019-02-24</created><authors><author><keyname>Dorostkar</keyname><forenames>Ali</forenames></author></authors><title>Complementary Fractional Dimensional Order of Nyquist Sinc Sequences for
  Time Division Multiplexing</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High speed data transmission is enabled by time and wavelength division
multiplexing. Here is introduced fractional dimension order of Nyquist pulses
sequences for orthogonal time division multiplexing. Firstly, with a
representation of the Nyquist sinc sequence by a cosine Fourier series, in one
side it is introduced the complementary Nyquist sinc sequences as a better
option for data transmission. On the other side, a possibility of optical time
delay by an electrical phase shifter for optical time division multiplexing is
theoretically demonstrated. In continue, the fractional dimensional order of
signal is defined to open a new window for data transmission. Moving of
function in fractional dimension can be realized as a new freedom for a signal
processing. In other words, dimension itself is a dimension. In this regard,
dimensional transformation is introduced to give a mapping of the function in
dimensional domain or variations of function in fractional dimension. This
mapping gives more information about signal in different point of view like
Fourier transformation. Then, the complementary fractional dimensional order of
Nyquist sinc sequences is defined to reach higher data rate. It has not a
unique solution, however; the best set of solutions for data transmission must
be taken in to accounted. Furthermore, the trajectory of fractional dimension
can be found by a numerical iterative algorithm which will be explained in the
appendix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08956</identifier>
 <datestamp>2019-10-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08956</id><created>2019-02-24</created><updated>2019-10-25</updated><authors><author><keyname>Lestyan</keyname><forenames>Szilvia</forenames></author><author><keyname>Acs</keyname><forenames>Gergely</forenames></author><author><keyname>Biczok</keyname><forenames>Gergely</forenames></author><author><keyname>Szalay</keyname><forenames>Zsolt</forenames></author></authors><title>Extracting vehicle sensor signals from CAN logs for driver
  re-identification</title><categories>cs.CR eess.SP</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data is the new oil for the car industry. Cars generate data about how they
are used and who's behind the wheel which gives rise to a novel way of
profiling individuals. Several prior works have successfully demonstrated the
feasibility of driver re-identification using the in-vehicle network data
captured on the vehicle's CAN (Controller Area Network) bus. However, all of
them used signals (e.g., velocity, brake pedal or accelerator position) that
have already been extracted from the CAN log which is itself not a
straightforward process. Indeed, car manufacturers intentionally do not reveal
the exact signal location within CAN logs. Nevertheless, we show that signals
can be efficiently extracted from CAN logs using machine learning techniques.
We exploit that signals have several distinguishing statistical features which
can be learnt and effectively used to identify them across different vehicles,
that is, to quasi &quot;reverse-engineer&quot; the CAN protocol. We also demonstrate that
the extracted signals can be successfully used to re-identify individuals in a
dataset of 33 drivers. Therefore, not revealing signal locations in CAN logs
per se does not prevent them to be regarded as personal data of drivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08992</identifier>
 <datestamp>2019-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.08992</id><created>2019-02-24</created><authors><author><keyname>Aldababsa</keyname><forenames>Mahmoud</forenames></author><author><keyname>Toka</keyname><forenames>Mesut</forenames></author><author><keyname>Gokceli</keyname><forenames>Selahattin</forenames></author><author><keyname>Kurt</keyname><forenames>Gunes Karabulut</forenames></author><author><keyname>Kucur</keyname><forenames>Oguz</forenames></author></authors><title>A Tutorial on Nonorthogonal Multiple Access for 5G and Beyond</title><categories>eess.SP</categories><comments>25 pages, 10 figures</comments><msc-class>pdf</msc-class><doi>10.1155/2018/9713450</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's wireless networks allocate radio resources to users based on the
orthogonal multiple access (OMA) principle. However, as the number of users
increases, OMA based approaches may not meet the stringent emerging
requirements including very high spectral efficiency, very low latency, and
massive device connectivity. Nonorthogonal multiple access (NOMA) principle
emerges as a solution to improve the spectral efficiency while allowing some
degree of multiple access interference at receivers. In this tutorial style
paper, we target providing a unified model for NOMA, including uplink and
downlink transmissions, along with the extensions tomultiple inputmultiple
output and cooperative communication scenarios. Through numerical examples, we
compare the performances of OMA and NOMA networks. Implementation aspects and
open issues are also detailed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09044</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09044</id><created>2019-02-24</created><authors><author><keyname>Fridovich-Keil</keyname><forenames>Sara</forenames></author><author><keyname>Ramadge</keyname><forenames>Peter J.</forenames></author></authors><title>Contact Surface Area: A Novel Signal for Heart Rate Estimation in
  Smartphone Videos</title><categories>physics.med-ph eess.IV</categories><journal-ref>IEEE Global Conference on Signal and Information Processing
  (GlobalSIP) (2018)</journal-ref><doi>10.1109/GlobalSIP.2018.8646391</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of smartphone video-based heart rate estimation,
which typically relies on measuring the green color intensity of the user's
skin. We describe a novel signal in fingertip videos used for smartphone-based
heart rate estimation: fingertip contact surface area. We propose a model
relating contact surface area to pressure, and validate it on a dataset of 786
videos from 62 participants by demonstrating a statistical correlation between
contact surface area and green color intensity. We estimate heart rate on our
dataset with two algorithms, a baseline using the green signal only and a novel
algorithm based on both color and area. We demonstrate lower rates of
substantial errors (&gt;10 beats per minute) using the novel algorithm (4.1%),
compared both to the baseline algorithm (6.4%) and to published results using
commercial color-based applications (&gt;6%).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09063</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09063</id><created>2019-02-24</created><authors><author><keyname>Simpson</keyname><forenames>Amber L.</forenames></author><author><keyname>Antonelli</keyname><forenames>Michela</forenames></author><author><keyname>Bakas</keyname><forenames>Spyridon</forenames></author><author><keyname>Bilello</keyname><forenames>Michel</forenames></author><author><keyname>Farahani</keyname><forenames>Keyvan</forenames></author><author><keyname>van Ginneken</keyname><forenames>Bram</forenames></author><author><keyname>Kopp-Schneider</keyname><forenames>Annette</forenames></author><author><keyname>Landman</keyname><forenames>Bennett A.</forenames></author><author><keyname>Litjens</keyname><forenames>Geert</forenames></author><author><keyname>Menze</keyname><forenames>Bjoern</forenames></author><author><keyname>Ronneberger</keyname><forenames>Olaf</forenames></author><author><keyname>Summers</keyname><forenames>Ronald M.</forenames></author><author><keyname>Bilic</keyname><forenames>Patrick</forenames></author><author><keyname>Christ</keyname><forenames>Patrick F.</forenames></author><author><keyname>Do</keyname><forenames>Richard K. G.</forenames></author><author><keyname>Gollub</keyname><forenames>Marc</forenames></author><author><keyname>Golia-Pernicka</keyname><forenames>Jennifer</forenames></author><author><keyname>Heckers</keyname><forenames>Stephan H.</forenames></author><author><keyname>Jarnagin</keyname><forenames>William R.</forenames></author><author><keyname>McHugo</keyname><forenames>Maureen K.</forenames></author><author><keyname>Napel</keyname><forenames>Sandy</forenames></author><author><keyname>Vorontsov</keyname><forenames>Eugene</forenames></author><author><keyname>Maier-Hein</keyname><forenames>Lena</forenames></author><author><keyname>Cardoso</keyname><forenames>M. Jorge</forenames></author></authors><title>A large annotated medical image dataset for the development and
  evaluation of segmentation algorithms</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic segmentation of medical images aims to associate a pixel with a
label in a medical image without human initialization. The success of semantic
segmentation algorithms is contingent on the availability of high-quality
imaging data with corresponding labels provided by experts. We sought to create
a large collection of annotated medical image datasets of various clinically
relevant anatomies available under open source license to facilitate the
development of semantic segmentation algorithms. Such a resource would allow:
1) objective assessment of general-purpose segmentation methods through
comprehensive benchmarking and 2) open and free access to medical image data
for any researcher interested in the problem domain. Through a
multi-institutional effort, we generated a large, curated dataset
representative of several highly variable segmentation tasks that was used in a
crowd-sourced challenge - the Medical Segmentation Decathlon held during the
2018 Medical Image Computing and Computer Aided Interventions Conference in
Granada, Spain. Here, we describe these ten labeled image datasets so that
these data may be effectively reused by the research community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09069</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09069</id><created>2019-02-24</created><authors><author><keyname>Bjorck</keyname><forenames>Johan</forenames></author><author><keyname>Rappazzo</keyname><forenames>Brendan H.</forenames></author><author><keyname>Chen</keyname><forenames>Di</forenames></author><author><keyname>Bernstein</keyname><forenames>Richard</forenames></author><author><keyname>Wrege</keyname><forenames>Peter H.</forenames></author><author><keyname>Gomes</keyname><forenames>Carla P.</forenames></author></authors><title>Automatic Detection and Compression for Passive Acoustic Monitoring of
  the African Forest Elephant</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider applying machine learning to the analysis and
compression of audio signals in the context of monitoring elephants in
sub-Saharan Africa. Earth's biodiversity is increasingly under threat by
sources of anthropogenic change (e.g. resource extraction, land use change, and
climate change) and surveying animal populations is critical for developing
conservation strategies. However, manually monitoring tropical forests or deep
oceans is intractable. For species that communicate acoustically, researchers
have argued for placing audio recorders in the habitats as a cost-effective and
non-invasive method, a strategy known as passive acoustic monitoring (PAM). In
collaboration with conservation efforts, we construct a large labeled dataset
of passive acoustic recordings of the African Forest Elephant via
crowdsourcing, compromising thousands of hours of recordings in the wild. Using
state-of-the-art techniques in artificial intelligence we improve upon
previously proposed methods for passive acoustic monitoring for classification
and segmentation. In real-time detection of elephant calls, network bandwidth
quickly becomes a bottleneck and efficient ways to compress the data are
needed. Most audio compression schemes are aimed at human listeners and are
unsuitable for low-frequency elephant calls. To remedy this, we provide a novel
end-to-end differentiable method for compression of audio signals that can be
adapted to acoustic monitoring of any species and dramatically improves over
naive coding strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09074</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09074</id><created>2019-02-24</created><authors><author><keyname>Fang</keyname><forenames>Xin</forenames></author><author><keyname>Zou</keyname><forenames>Liang</forenames></author><author><keyname>Li</keyname><forenames>Jin</forenames></author><author><keyname>Sun</keyname><forenames>Lei</forenames></author><author><keyname>Ling</keyname><forenames>Zhen-Hua</forenames></author></authors><title>Channel adversarial training for cross-channel text-independent speaker
  recognition</title><categories>eess.AS cs.SD</categories><comments>5 pages, 2 figures, 2 tabels</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conventional speaker recognition frameworks (e.g., the i-vector and
CNN-based approach) have been successfully applied to various tasks when the
channel of the enrolment dataset is similar to that of the test dataset.
However, in real-world applications, mismatch always exists between these two
datasets, which may severely deteriorate the recognition performance.
Previously, a few channel compensation algorithms have been proposed, such as
Linear Discriminant Analysis (LDA) and Probabilistic LDA. However, these
methods always require the collections of different channels from a specific
speaker, which is unrealistic to be satisfied in real scenarios. Inspired by
domain adaptation, we propose a novel deep-learning based speaker recognition
framework to learn the channel-invariant and speaker-discriminative speech
representations via channel adversarial training. Specifically, we first employ
a gradient reversal layer to remove variations across different channels. Then,
the compressed information is projected into the same subspace by adversarial
training. Experiments on test datasets with 54,133 speakers demonstrate that
the proposed method is not only effective at alleviating the channel mismatch
problem, but also outperforms state-of-the-art speaker recognition methods.
Compared with the i-vector-based method and the CNN-based method, our proposed
method achieves significant relative improvement of 44.7% and 22.6%
respectively in terms of the Top1 recall.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09101</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09101</id><created>2019-02-25</created><authors><author><keyname>Jiang</keyname><forenames>Jing</forenames></author><author><keyname>Wang</keyname><forenames>Xiaojing</forenames></author><author><keyname>Sidhu</keyname><forenames>Guftaar Ahmad Sardar</forenames></author><author><keyname>Zhen</keyname><forenames>Li</forenames></author><author><keyname>Gao</keyname><forenames>Runchen</forenames></author></authors><title>Clustering-Based Codebook Design for MIMO Communication System</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Codebook design is one of the core technologies in limited feedback
multi-input multi-output (MIMO) communication systems. However, the
conventional codebook designs usually assume MIMO vectors are uniformly
distributed or isotropic. Motivated by the excellent classfication and analysis
ability of clustering algorithms, we propose a K-means clustering based
codebook design. First, large amounts of channel state information (CSI) is
stored as the input data of the clustering, and finally divided into N clusters
according to the minimal distance. The clustering centroids are used as the
statistic channel information of the codebook construction which the sum
distance is minimal to the real channel information. Simulation results consist
with theoretical analysis in terms of the achievable rate, and demonstrate that
the proposed codebook design outperforms conventional schemes, especially in
the non-uniform distribution of channel scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09108</identifier>
 <datestamp>2019-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09108</id><created>2019-02-25</created><updated>2019-03-04</updated><authors><author><keyname>Shi</keyname><forenames>Qi</forenames></author><author><keyname>Liu</keyname><forenames>Yangyu</forenames></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author><author><keyname>Cao</keyname><forenames>Shan</forenames></author><author><keyname>LAU</keyname><forenames>Vincent</forenames></author></authors><title>Channel Estimation for WiFi Prototype Systems with Super-Resolution
  Image Recovery</title><categories>eess.SP</categories><comments>7 pages, 7 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel estimation is crucial for modern WiFi system and becomes more and
more challenging with the growth of user throughput in multiple input multiple
output configuration. Plenty of literature spends great efforts in improving
the estimation accuracy, while the interpolation schemes are overlooked. To
deal with this challenge, we exploit the super-resolution image recovery scheme
to model the non-linear interpolation mechanisms without pre-assumed channel
characteristics in this paper. To make it more practical, we offline generate
numerical channel coefficients according to the statistical channel models to
train the neural networks, and directly apply them in some practical WiFi
prototype systems. As shown in this paper, the proposed super-resolution based
channel estimation scheme can outperform the conventional approaches in both
LOS and NLOS scenarios, which we believe can significantly change the current
channel estimation method in the near future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09135</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09135</id><created>2019-02-25</created><authors><author><keyname>Ren</keyname><forenames>Longfei</forenames></author><author><keyname>Wang</keyname><forenames>Chengjing</forenames></author><author><keyname>Tang</keyname><forenames>Peipei</forenames></author><author><keyname>Ma</keyname><forenames>Zheng</forenames></author></authors><title>A Dual Symmetric Gauss-Seidel Alternating Direction Method of
  Multipliers for Hyperspectral Sparse Unmixing</title><categories>cs.NA cs.CV eess.IV math.NA</categories><comments>15 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since sparse unmixing has emerged as a promising approach to hyperspectral
unmixing, some spatial-contextual information in the hyperspectral images has
been exploited to improve the performance of the unmixing recently. The total
variation (TV) has been widely used to promote the spatial homogeneity as well
as the smoothness between adjacent pixels. However, the computation task for
hyperspectral sparse unmixing with a TV regularization term is heavy. Besides,
the convergences of the traditional sparse unmixing algorithms which are
special cases of the primal alternating direction method of multipliers (pADMM)
have not been explained in details. In this paper, we design an efficient and
convergent dual symmetric Gauss-Seidel ADMM (sGS-ADMM) for hyperspectral sparse
unmixing with a TV regularization term. We also present the global convergence
and local linear convergence rate analysis for the traditional sparse unmixing
algorithm and our algorithm. As demonstrated in numerical experiments, our
algorithm can obviously improve the efficiency of the unmixing compared with
the state-of-the-art algorithm. More importantly, we can obtain images with
higher quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09151</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09151</id><created>2019-02-25</created><updated>2019-02-26</updated><authors><author><keyname>Paris</keyname><forenames>Antoine</forenames></author><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author></authors><title>Identifiability Conditions for Multi-channel Blind Deconvolution with
  Short Filters</title><categories>eess.SP</categories><comments>10 pages, 4 figures, accepted at EUROCON 2019 as part of the IEEE
  Region 8 Student Paper Contest</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers the multi-channel blind deconvolution problem under the
assumption that the channels are short. First, we investigate the ill-posedness
issues inherent to blind deconvolution problems and sufficient and necessary
conditions on the channels that guarantee well-posedness are derived. Following
previous work on blind deconvolution, the problem is then reformulated as a
low-rank matrix recovery problem and solved by nuclear norm minimization.
Numerical experiments show the effectiveness of this algorithm under a certain
generative model for the input signal and the channels, both in the noiseless
and in the noisy case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09173</identifier>
 <datestamp>2020-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09173</id><created>2019-02-25</created><updated>2020-01-16</updated><authors><author><keyname>Ji</keyname><forenames>Feng</forenames></author><author><keyname>Yang</keyname><forenames>Jielong</forenames></author><author><keyname>Zhang</keyname><forenames>Qiang</forenames></author><author><keyname>Tay</keyname><forenames>Wee Peng</forenames></author></authors><title>GFCN: A New Graph Convolutional Network Based on Parallel Flows</title><categories>cs.LG cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In view of the huge success of convolution neural networks (CNN) for image
classification and object recognition, there have been attempts to generalize
the method to general graph-structured data. One major direction is based on
spectral graph theory and graph signal processing. In this paper, we study the
problem from a completely different perspective, by introducing parallel flow
decomposition of graphs. The essential idea is to decompose a graph into
families of non-intersecting one dimensional (1D) paths, after which, we may
apply a 1D CNN along each family of paths. We demonstrate that the our method,
which we call GraphFlow, is able to transfer CNN architectures to general
graphs. To show the effectiveness of our approach, we test our method on the
classical MNIST dataset, synthetic datasets on network information propagation
and a news article classification dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09177</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09177</id><created>2019-02-25</created><authors><author><keyname>Xu</keyname><forenames>Yicheng</forenames><affiliation>National Mobile Communication Research Laboratory, Southeast University, Nanjing, China</affiliation><affiliation>Wireless Energy and Information Transmission Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China</affiliation></author><author><keyname>Chu</keyname><forenames>Hongyun</forenames><affiliation>Wireless Energy and Information Transmission Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China</affiliation><affiliation>Department of Electrical Engineering, Columbia University, New York, USA</affiliation></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames><affiliation>Department of Electrical Engineering, Columbia University, New York, USA</affiliation></author></authors><title>Joint Timing Offset and Channel Estimation for Multi-user UFMC Uplink</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Universal filtered multi-carrier (UFMC), which groups and filters subcarriers
before transmission, is a potential multi-carrier modulation technique
investigated for the emerging Machine-Type Communications (MTC). Considering
the relaxed timing synchronization requirement of UFMC, we design a novel joint
timing synchronization and channel estimation method for multi-user UFMC uplink
transmission. Aiming at reducing overhead for higher system performance, the
joint estimation problem is formulated using atomic norm minimization that
enhances the sparsity of timing offset in the continuous frequency domain.
Simulation results show that the proposed method can achieve considerable
performance gain, as compared with its counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09179</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09179</id><created>2019-02-25</created><authors><author><keyname>An</keyname><forenames>Inkyu</forenames></author><author><keyname>Lee</keyname><forenames>Doheon</forenames></author><author><keyname>Jo</keyname><forenames>Byeongho</forenames></author><author><keyname>Choi</keyname><forenames>Jung-Woo</forenames></author><author><keyname>Yoon</keyname><forenames>Sung-Eui</forenames></author></authors><title>Robust Sound Source Localization considering Similarity of
  Back-Propagation Signals</title><categories>cs.SD cs.RO eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel, robust sound source localization algorithm considering
back-propagation signals. Sound propagation paths are estimated by generating
direct and reflection acoustic rays based on ray tracing in a backward manner.
We then compute the back-propagation signals by designing and using the impulse
response of the backward sound propagation based on the acoustic ray paths. For
identifying the 3D source position, we suggest a localization method based on
the Monte Carlo localization algorithm. Candidates for a source position is
determined by identifying the convergence regions of acoustic ray paths. This
candidate is validated by measuring similarities between back-propagation
signals, under the assumption that the back-propagation signals of different
acoustic ray paths should be similar near the sound source position. Thanks to
considering similarities of back-propagation signals, our approach can localize
a source position with an averaged error of 0.51 m in a room of 7 m by 7 m area
with 3 m height in tested environments. We also observe 65 % to 220 %
improvement in accuracy over the stateof-the-art method. This improvement is
achieved in environments containing a moving source, an obstacle, and noises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09254</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09254</id><created>2019-02-25</created><updated>2019-05-30</updated><authors><author><keyname>Wu</keyname><forenames>Mengyue</forenames></author><author><keyname>Dinkel</keyname><forenames>Heinrich</forenames></author><author><keyname>Yu</keyname><forenames>Kai</forenames></author></authors><title>Audio Caption: Listen and Tell</title><categories>cs.SD cs.CL eess.AS</categories><comments>accepted by ICASSP2019</comments><doi>10.1109/ICASSP.2019.8682377</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasing amount of research has shed light on machine perception of audio
events, most of which concerns detection and classification tasks. However,
human-like perception of audio scenes involves not only detecting and
classifying audio sounds, but also summarizing the relationship between
different audio events. Comparable research such as image caption has been
conducted, yet the audio field is still quite barren. This paper introduces a
manually-annotated dataset for audio caption. The purpose is to automatically
generate natural sentences for audio scene description and to bridge the gap
between machine perception of audio and image. The whole dataset is labelled in
Mandarin and we also include translated English annotations. A baseline
encoder-decoder model is provided for both English and Mandarin. Similar BLEU
scores are derived for both languages: our model can generate understandable
and data-related captions based on the dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09330</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09330</id><created>2019-02-21</created><authors><author><keyname>Yang</keyname><forenames>Zekun</forenames></author><author><keyname>Chen</keyname><forenames>Yu</forenames></author><author><keyname>Zhou</keyname><forenames>Ning</forenames></author><author><keyname>Tong</keyname><forenames>Shiqiong</forenames></author></authors><title>PReS: Power Peak Reduction by Real-time Scheduling for Urban Railway
  Transit</title><categories>eess.SP</categories><comments>Submitted to the 2019 IEEE Sustainability through ICT Summit (StICT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Railway transportation is one of the most popular options for Urban Massive
Transportation Systems (UMTS) because of many attractive features. A robust
electric power supply is essential to enable normal operation. However, the
power peaks appearing at the start time of the vehicles put heavy pressure on
the power grid. Reduction of the power peak is a key issue in improving urban
railway transit's power efficiency. Researchers have tried to address this
problem by making a delicate timetable, but this method often failed to serve
the purpose because of the punctuality problem. In this work, taking advantage
of real-time estimation of the single train's power consumption, an online
Power peak Reduction by real-time Scheduling (PReS) solution for trains'
departure is proposed. Particularly, a Binary Integer Programming (BIP) model
is introduced that is able to avoid power consumption peak caused by multiple
trains departure simultaneously. The simulation result verified that the
proposed real-time scheduling approach can effectively reduce the occurrences
of power peak without bringing in additional train travel delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09344</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09344</id><created>2019-02-22</created><authors><author><keyname>Guo</keyname><forenames>Hui</forenames></author><author><keyname>Wang</keyname><forenames>Le</forenames></author><author><keyname>Zhao</keyname><forenames>Shengmei</forenames></author></authors><title>Compressed ghost edge imaging</title><categories>eess.IV</categories><doi>10.3788/COL201917.071101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an advanced framework of ghost edge imaging, named
compressed ghost edge imaging (CGEI). In the scheme, a set of structured
speckle patterns with pixel shifting are illuminated on an unknown object, and
the output is collected by a bucket detector without any spatial resolution. By
using compressed sensing algorithm, we obtain the horizontal and vertical edge
information of the unknown object with the bucket detector detection results
and the known structured speckle patterns. The edge is finally constructed by
the two-dimentional edge information. The experimental and numerical
simulations results show that the proposed scheme has a higher quality and
reduces the number of measurements, in comparison with the existed edge
detection schemes based on ghost imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09426</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09426</id><created>2019-02-22</created><authors><author><keyname>Takeuchi</keyname><forenames>Shun</forenames></author><author><keyname>Nishino</keyname><forenames>Takuya</forenames></author><author><keyname>Saito</keyname><forenames>Takahiro</forenames></author><author><keyname>Watanabe</keyname><forenames>Isamu</forenames></author></authors><title>Semi-supervised Approach to Soft Sensor Modeling for Fault Detection in
  Industrial Systems with Multiple Operation Modes</title><categories>eess.SP cs.LG cs.SY stat.ML</categories><comments>7 pages, 1 figure</comments><journal-ref>International Conference on Advanced Intelligent Systems and
  Informatics 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In industrial systems, certain process variables that need to be monitored
for detecting faults are often difficult or impossible to measure. Soft sensor
techniques are widely used to estimate such difficult-to-measure process
variables from easy-to-measure ones. Soft sensor modeling requires training
datasets including the information of various states such as operation modes,
but the fault dataset with the target variable is insufficient as the training
dataset. This paper describes a semi-supervised approach to soft sensor
modeling to incorporate an incomplete dataset without the target variable in
the training dataset. To incorporate the incomplete dataset, we consider the
properties of processes at transition points between operation modes in the
system. The regression coefficients of the operation modes are estimated under
constraint conditions obtained from the information on the mode transitions. In
a case study, this constrained soft sensor modeling was used to predict
refrigerant leaks in air-conditioning systems with heating and cooling
operation modes. The results show that this modeling method is promising for
soft sensors in a system with multiple operation modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09427</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09427</id><created>2019-02-22</created><authors><author><keyname>Takeuchi</keyname><forenames>Shun</forenames></author><author><keyname>Saito</keyname><forenames>Takahiro</forenames></author></authors><title>Fault Diagnosis Method Based on Scaling Law for On-line Refrigerant Leak
  Detection</title><categories>eess.SP cs.LG cs.SY stat.ML</categories><comments>8 pages, 6 figures</comments><journal-ref>2018 17th IEEE International Conference on Machine Learning and
  Applications (ICMLA)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early fault detection using instrumented sensor data is one of the promising
application areas of machine learning in industrial facilities. However, it is
difficult to improve the generalization performance of the trained
fault-detection model because of the complex system configuration in the target
diagnostic system and insufficient fault data. It is not trivial to apply the
trained model to other systems. Here we propose a fault diagnosis method for
refrigerant leak detection considering the physical modeling and control
mechanism of an air-conditioning system. We derive a useful scaling law related
to refrigerant leak. If the control mechanism is the same, the model can be
applied to other air-conditioning systems irrespective of the system
configuration. Small-scale off-line fault test data obtained in a laboratory
are applied to estimate the scaling exponent. We evaluate the proposed scaling
law by using real-world data. Based on a statistical hypothesis test of the
interaction between two groups, we show that the scaling exponents of different
air-conditioning systems are equivalent. In addition, we estimated the time
series of the degree of leakage of real process data based on the scaling law
and confirmed that the proposed method is promising for early leak detection
through comparison with assessment by experts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09429</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09429</id><created>2019-02-22</created><authors><author><keyname>Eroglu</keyname><forenames>Yusuf Said</forenames></author><author><keyname>Anjinappa</keyname><forenames>Chethan Kumar</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Pala</keyname><forenames>Nezih</forenames></author></authors><title>Slow Beam Steering and NOMA for Indoor Multi-User Visible Light
  Communications</title><categories>eess.SP</categories><comments>Submitted to IEEE TCOM on Jan 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible light communication (VLC) is an emerging technology that enables
broadband data rates using the visible spectrum. In this paper, considering
slow beam steering where VLC beam directions are assumed to be fixed during a
transmission frame, we find the steering angles that simultaneously serve
multiple users within the frame duration and maximize the data rates. This is
achieved by solving a non-convex optimization problem using a grid-based search
and majorization-minimization (MM) procedure. Subsequently, we consider
multiple steerable beams with a larger number of users in the network and
propose an algorithm to cluster users and serve each cluster with a separate
beam. We optimize the transmit power of each beam to maximize the data rates.
Finally, we propose a non-orthogonal multiple access (NOMA) scheme for the beam
steering and user clustering scenario, to further increase the data rates of
the users. The simulation results show that the proposed beam steering method
can efficiently serve a high number of users, and with power optimization, a
data rate gain up to ten times is possible. The simulation results for NOMA
suggests an additional 10 Mbps sum rate gain for each NOMA user pair.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09444</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09444</id><created>2019-02-06</created><authors><author><keyname>Moltafet</keyname><forenames>Mohammad.</forenames></author><author><keyname>Parsaeefard</keyname><forenames>Saeedeh.</forenames></author><author><keyname>Javan</keyname><forenames>Mohammad R.</forenames></author><author><keyname>Mokari</keyname><forenames>Nader.</forenames></author></authors><title>Robust Radio Resource Allocation in MISO-SCMA Assisted C-RAN in 5G
  Networks</title><categories>cs.NI eess.SP</categories><comments>11 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, by considering multiple slices, a downlink transmission of a
sparse code multiple access (SCMA) based cloud-radio access network (C-RAN) is
investigated. In this regard, by supposing multiple input and single output
(MISO) transmission technology, a novel robust radio resource allocation is
proposed where considering uncertain channel state information (CSI), the worst
case approach is applied. The main goal of the proposed radio resource
allocation is to, maximize the system sum rate with maximum available power at
radio remote head (RRH), minimum rate requirement of each slice, maximum
frounthaul capacity of each RRH, user association, and SCMA constraints. To
solve the proposed optimization problem in an efficient manner, an iterative
method is deployed where in each iteration, beamforming and joint codebook
allocation and user association subproblem are solved separately. By
introducing some auxiliary variables, the joint codebook allocation and user
association subproblem is transformed into an integer linear programming, and
to solve the beamforming optimization problem, minorization-maximization
algorithm (MMA) is applied. Via numerical results, the performance of the
proposed system model versus different system parameters and for different
channel models are investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09447</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09447</id><created>2019-02-12</created><updated>2019-09-08</updated><authors><author><keyname>Pinilla</keyname><forenames>Samuel</forenames></author><author><keyname>Bendory</keyname><forenames>Tamir</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Arguello</keyname><forenames>Henry</forenames></author></authors><title>Frequency-Resolved Optical Gating Recovery via Smoothing Gradient</title><categories>eess.SP</categories><comments>Simulations and comparisons are being added</comments><doi>10.1109/TSP.2019.2951192</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequency-resolved optical gating (FROG) is a popular technique for complete
characterization of ultrashort laser pulses. The acquired data in FROG, called
FROG trace, is the Fourier magnitude of the product of the unknown pulse with a
time-shifted version of itself, for several different shifts. To estimate the
pulse from the FROG trace, we propose an algorithm that minimizes a smoothed
non-convex least-squares objective function. The method consists of two steps.
First, we approximate the pulse by an iterative spectral algorithm. Then, the
attained initialization is refined based upon a sequence of block stochastic
gradient iterations. The algorithm is theoretically simple, numerically
scalable, and easy-to-implement. Empirically, our approach outperforms the
state-of-the-art when the FROG trace is incomplete, that is, when only few
shifts are recorded. Simulations also suggest that the proposed algorithm
exhibits similar computational cost compared to a state-of-the-art technique
for both complete and incomplete data. In addition, we prove that in the
vicinity of the true solution, the algorithm converges to a critical point. A
Matlab implementation is publicly available at
https://github.com/samuelpinilla/FROG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09454</identifier>
 <datestamp>2019-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09454</id><created>2019-02-15</created><updated>2019-03-11</updated><authors><author><keyname>Mao</keyname><forenames>Daijiafan</forenames></author><author><keyname>Gao</keyname><forenames>Ziran</forenames></author><author><keyname>Wang</keyname><forenames>Jiankang</forenames></author></authors><title>An integrated algorithm for evaluating plug-in electric vehicle impact
  on the state of power grid assets</title><categories>eess.SP math.NA</categories><comments>20 pages, 9 figures. arXiv admin note: text overlap with
  arXiv:1902.05683</comments><journal-ref>International Journal of Electrical Power &amp; Energy Systems, 2019,
  105, pp.793-802</journal-ref><doi>10.1016/j.ijepes.2018.09.028</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Plug-in Electric Vehicles (PEV) exert an increasingly disruptive influence on
power delivery systems with penetration surge in the past decade. Therefore,
accurately assessing their impact plays a crucial role in managing grid assets
and maintaining power grids reliability. However, PEV loads are stochastic and
impulsive, which means they are of high power density and vary in a fast and
discrete manner. These load characteristics make conventional assessment
methods unsuitable. This paper proposes an algorithm, which captures the
inter-temporal response of grid assets and allows fast assessment through an
integrated interface. To realize these advantageous features, we establish
analytical models for two generic classes of grid assets (continuous and
discrete operating assets) and recast their cost functions in the statistical
settings of PEV charging. Distinct from simulation-based methods, the proposed
method is analytical, and thus greatly reduce the computation resources and
data required for accurate assessment. The effectiveness of the proposed
algorithm has been demonstrated on a set of power distribution networks in
Columbus metropolitan area, in comparison with the conventional assessment
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09467</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09467</id><created>2019-01-24</created><authors><author><keyname>Ceran</keyname><forenames>Elif Tu&#x11f;&#xe7;e</forenames></author><author><keyname>G&#xfc;nd&#xfc;z</keyname><forenames>Deniz</forenames></author><author><keyname>Gy&#xf6;rgy</keyname><forenames>Andr&#xe1;s</forenames></author></authors><title>Reinforcement Learning to Minimize Age of Information with an Energy
  Harvesting Sensor with HARQ and Sensing Cost</title><categories>eess.SP cs.IT cs.NI cs.SI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The time average expected age of information (AoI) is studied for status
updates sent from an energy-harvesting transmitter with a finite-capacity
battery. The optimal scheduling policy is first studied under different
feedback mechanisms when the channel and energy harvesting statistics are
known. For the case of unknown environments, an average-cost reinforcement
learning algorithm is proposed that learns the system parameters and the status
update policy in real time. The effectiveness of the proposed methods is
verified through numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09474</identifier>
 <datestamp>2020-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09474</id><created>2019-02-25</created><updated>2020-02-12</updated><authors><author><keyname>Leeb</keyname><forenames>William</forenames></author></authors><title>Matrix denoising for weighted loss functions and heterogeneous signals</title><categories>math.ST eess.SP stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of estimating a low-rank matrix from a noisy observed
matrix. Previous work has shown that the optimal method depends crucially on
the choice of loss function. In this paper, we use a family of weighted loss
functions, which arise naturally in many settings such as heteroscedastic
noise, missing data, and submatrix denoising. However, weighted loss functions
are challenging to analyze because they are not orthogonally-invariant. We
derive optimal spectral denoisers for these weighted loss functions. By
combining different weights, we then use these optimal denoisers to construct a
new denoiser that exploits heterogeneity in the signal matrix to boost
estimation with unweighted loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09477</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09477</id><created>2019-02-15</created><authors><author><keyname>Geissler</keyname><forenames>Florian</forenames></author><author><keyname>Kohnert</keyname><forenames>S&#xf6;ren</forenames></author><author><keyname>Stolle</keyname><forenames>Reinhard</forenames></author></authors><title>Designing a Roadside Sensor Infrastructure to Support Automated Driving</title><categories>eess.SP</categories><comments>6 pages, 5 figures</comments><journal-ref>2018 21st International Conference on Intelligent Transportation
  Systems (ITSC)</journal-ref><doi>10.1109/ITSC.2018.8569016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automation of complex traffic scenarios is expected to rely on input from a
roadside infrastructure to complement the vehicles' environment perception. We
here explore design requirements for a prototypical setup of virtual vision or
RADAR sensors along one roadside. Explicitly, we analyze the road coverage and
the probability of vehicle occlusions, with the objective of evaluating the
completeness of information that is captured by the sensor field. Simulation
case studies are performed based on real traffic data acquired at the German
Autobahn 9 near Munich. Our findings indicate how the sensor network should be
designed in terms of sensor range, orientation and opening angle, in order to
enable effective traffic detection. The achieved degree of completeness
suggests that such a setup could be used to support automated vehicles to a
substantial extent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09499</identifier>
 <datestamp>2019-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09499</id><created>2019-02-25</created><updated>2019-12-04</updated><authors><author><keyname>H&#xfc;ser</keyname><forenames>Matthias</forenames></author><author><keyname>K&#xfc;ndig</keyname><forenames>Adrian</forenames></author><author><keyname>Karlen</keyname><forenames>Walter</forenames></author><author><keyname>De Luca</keyname><forenames>Valeria</forenames></author><author><keyname>Jaggi</keyname><forenames>Martin</forenames></author></authors><title>Forecasting intracranial hypertension using multi-scale waveform metrics</title><categories>eess.SP cs.LG</categories><comments>11 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: Acute intracranial hypertension is an important risk factor of
secondary brain damage after traumatic brain injury. Hypertensive episodes are
often diagnosed reactively, leading to late detection and lost time for
intervention planning. A pro-active approach that predicts critical events
several hours ahead of time could assist in directing attention to patients at
risk. Approach: We developed a prediction framework that forecasts onsets of
acute intracranial hypertension in the next 8 hours. It jointly uses cerebral
auto-regulation indices, spectral energies and morphological pulse metrics to
describe the neurological state of the patient. One-minute base windows were
compressed by computing signal metrics, and then stored in a multi-scale
history, from which physiological features were derived. Main results: Our
model predicted events up to 8 hours in advance with alarm recall rates of 90%
at a precision of 30.3% in the MIMIC-III waveform database, improving upon two
baselines from the literature. We found that features derived from
high-frequency waveforms substantially improved the prediction performance over
simple statistical summaries of low-frequency time series, and each of the
three feature classes contributed to the performance gain. The inclusion of
long-term history up to 8 hours was especially important. Significance: Our
results highlight the importance of information contained in high-frequency
waveforms in the neurological intensive care unit. They could motivate future
studies on pre-hypertensive patterns and the design of new alarm algorithms for
critical events in the injured brain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09511</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09511</id><created>2019-02-25</created><authors><author><keyname>Karacora</keyname><forenames>Yasemin</forenames></author><author><keyname>Kariminezhad</keyname><forenames>Ali</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>Hybrid Beamforming: Where Should the Analog Power Amplifiers be Placed?</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 2 figures, accepted for presentation at ICASSP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the spectral efficiency (SE) of a point-to-point
massive multiple-input multiple-output system (P2P-massive MIMO) with limited
radio frequency (RF) chains, i.e., analog-to-digital/ digital-to-analog
(D2A/A2D) modules, at the transceivers. The resulting architecture is known as
hybrid beamforming, where the joint analog and digital beamforming optimization
maximizes the SE. We analyze the SE of the system by keeping the number of
RF-chains low, but placing analog amplifiers at different paths. Conventional
hybrid beamforming architecture uses the amplifiers right after the D2A
modules. However, placing them at the phase shifters or at the antennas can
effect the SE of hybrid beamforming. We study the optimal placement of the
analog amplifiers and pinpoint the amount of loss in case of misplaced
amplifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09541</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09541</id><created>2019-02-25</created><authors><author><keyname>Fortunati</keyname><forenames>Stefano</forenames></author><author><keyname>Gini</keyname><forenames>Fulvio</forenames></author><author><keyname>Greco</keyname><forenames>Maria</forenames></author><author><keyname>Zoubir</keyname><forenames>Abdelhak</forenames></author><author><keyname>Rangaswamy</keyname><forenames>Muralidhar</forenames></author></authors><title>Semiparametric CRB and Slepian-Bangs formulas for Complex Elliptically
  Symmetric Distributions</title><categories>eess.SP</categories><comments>Submitted to IEEE Transactions on Signal Processing. arXiv admin
  note: substantial text overlap with arXiv:1807.08505, arXiv:1807.08936</comments><doi>10.1109/TSP.2019.2939084</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main aim of this paper is to extend the semiparametric inference
methodology, recently investigated for Real Elliptically Symmetric (RES)
distributions, to Complex Elliptically Symmetric (CES) distributions. The
generalization to the complex field is of fundamental importance in all
practical applications that exploit the complex representation of the acquired
data. Moreover, the CES distributions has been widely recognized as a valuable
and general model to statistically describe the non-Gaussian behaviour of
datasets originated from a wide variety of physical measurement processes. The
paper is divided in two parts. In the first part, a closed form expression of
the constrained Semiparametric Cram\'{e}r-Rao Bound (CSCRB) for the joint
estimation of complex mean vector and complex scatter matrix of a set of
CES-distributed random vectors is obtained by exploiting the so-called
\textit{Wirtinger} or $\mathbb{C}\mathbb{R}$-\textit{calculus}. The second part
deals with the derivation of the semiparametric version of the Slepian-Bangs
formula in the context of the CES model. Specifically, the proposed
Semiparametric Slepian-Bangs (SSB) formula provides us with a useful and
ready-to-use expression of the Semiparametric Fisher Information Matrix (SFIM)
for the estimation of a parameter vector parametrizing the complex mean and the
complex scatter matrix of a CES-distributed vector in the presence of unknown,
nuisance, density generator. Furthermore, we show how to exploit the derived
SSB formula to obtain the semiparametric counterpart of the Stochastic CRB for
Direction of Arrival (DOA) estimation under a random signal model assumption.
Simulation results are also provided to clarify the theoretical findings and to
demonstrate their usefulness in common array processing applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09603</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09603</id><created>2019-02-25</created><authors><author><keyname>D'Andrea</keyname><forenames>Carmen</forenames></author><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author><author><keyname>Lops</keyname><forenames>Marco</forenames></author></authors><title>Communications and Radar Coexistence in the Massive MIMO Regime: Uplink
  Analysis</title><categories>cs.IT eess.SP math.IT</categories><comments>Journal Paper submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the uplink of a massive MIMO communication system using
5G New Radio-compliant multiple access, which is to co-exist with a radar
system using the same frequency band. A system model taking into account the
reverberation (clutter) produced by the radar system onto the massive MIMO
receiver is proposed. In this scenario, several receivers for uplink channel
estimation and data detection are proposed, ranging from the simple
channel-matched beamformer to the zero-forcing and linear minimum mean square
error receivers for clutter disturbance rejection, under the two opposite
situations of perfectly known ad completely unknown clutter covariance. A
theoretical analysis is also given, deriving a lower bound on the achievable
uplink spectral efficiency and the mutual information between the input
Gaussian-encoded symbols and the observables available at the communication
receiver of the cellular massive MIMO system: regarding the latter, in
particular, we show that, in the large antenna number regime, the radar clutter
effects at the base station is suppressed and single-user capacity is restored.
Numerical results, illustrating the performance of the proposed detection
schemes, confirm the findings of the theoretical analysis, and permit
quantifying the system robustness to clutter effect for increasing number of
antennas at the base station.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09652</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09652</id><created>2019-02-25</created><authors><author><keyname>Tadayon</keyname><forenames>Navid</forenames></author><author><keyname>Rahman</keyname><forenames>Muhammed T.</forenames></author><author><keyname>Han</keyname><forenames>Shuo</forenames></author><author><keyname>Valaee</keyname><forenames>Shahrokh</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author></authors><title>Decimeter Ranging with Channel State Information</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims at the problem of time-of-flight (ToF) estimation using
channel state information (CSI) obtainable from commercialized MIMO-OFDM WLAN
receivers. It was often claimed that the CSI phase is contaminated with errors
of known and unknown natures rendering ToF-based positioning difficult. To
search for an answer, we take a bottom-up approach by first understanding CSI,
its constituent building blocks, and the sources of error that contaminate it.
We then model these effects mathematically. The correctness of these models is
corroborated based on the CSI collected in extensive measurement campaign
including radiated, conducted and chamber tests. Knowing the nature of
contamination in CSI phase and amplitude, we proceed with introducing
pre-processing methods to clean CSI from those errors and make it usable for
range estimation. To check the validity of proposed algorithms, the MUSIC
super-resolution algorithm is applied to post-processed CSI to perform range
estimates. Results substantiate that median accuracy of 0.6m, 0.8m, and 0.9m is
achievable in highly multipath line-of-sight environment where transmitter and
receiver are 5m, 10m, and 15m apart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09656</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09656</id><created>2019-02-25</created><authors><author><keyname>Stip&#x10d;evi&#x107;</keyname><forenames>Mario</forenames></author></authors><title>A circuit for precise random frequency synthesis via a frequency locked
  loop</title><categories>eess.SP</categories><comments>9 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequency synthesis (FS) is a technique vital for all kinds of radio
frequency (RF) communications, such as: mobile phones, Bluetooth, Wi-Fi, radio,
TV and satellite, and in other equipment requiring periodic signals of stable
and programmable frequency. In this work, we present a generalization of the FS
technique to random, non-periodic signals, whose main use is in the new area of
stochastic neuromorphic computing and, information security and
instrumentation. Since conventional FS circuits cannot work with random
signals, we introduce a novel random frequency ratio detector, that works both
with random and periodic signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09698</identifier>
 <datestamp>2019-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09698</id><created>2019-02-25</created><updated>2019-10-23</updated><authors><author><keyname>Raj</keyname><forenames>Ankit</forenames></author><author><keyname>Li</keyname><forenames>Yuqi</forenames></author><author><keyname>Bresler</keyname><forenames>Yoram</forenames></author></authors><title>GAN-based Projector for Faster Recovery with Convergence Guarantees in
  Linear Inverse Problems</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Generative Adversarial Network (GAN) with generator $G$ trained to model
the prior of images has been shown to perform better than sparsity-based
regularizers in ill-posed inverse problems. Here, we propose a new method of
deploying a GAN-based prior to solve linear inverse problems using projected
gradient descent (PGD). Our method learns a network-based projector for use in
the PGD algorithm, eliminating expensive computation of the Jacobian of $G$.
Experiments show that our approach provides a speed-up of $60\text{-}80\times$
over earlier GAN-based recovery methods along with better accuracy. Our main
theoretical result is that if the measurement matrix is moderately conditioned
on the manifold range($G$) and the projector is $\delta$-approximate, then the
algorithm is guaranteed to reach $O(\delta)$ reconstruction error in
$O(log(1/\delta))$ steps in the low noise regime. Additionally, we propose a
fast method to design such measurement matrices for a given $G$. Extensive
experiments demonstrate the efficacy of this method by requiring
$5\text{-}10\times$ fewer measurements than random Gaussian measurement
matrices for comparable recovery performance. Because the learning of the GAN
and projector is decoupled from the measurement operator, our GAN-based
projector and recovery algorithm are applicable without retraining to all
linear inverse problems, as confirmed by experiments on compressed sensing,
super-resolution, and inpainting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09765</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09765</id><created>2019-02-26</created><authors><author><keyname>Thakur</keyname><forenames>Anshul</forenames></author><author><keyname>Rajan</keyname><forenames>Padmanabhan</forenames></author></authors><title>Directional Embedding Based Semi-supervised Framework For Bird
  Vocalization Segmentation</title><categories>eess.AS cs.LG cs.SD</categories><comments>Accepted for publication in Applied Acoustics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a data-efficient, semi-supervised, two-pass framework for
segmenting bird vocalizations. The framework utilizes a binary classification
model to categorize frames of an input audio recording into the background or
bird vocalization. The first pass of the framework automatically generates
training labels from the input recording itself, while model training and
classification is done during the second pass. The proposed framework utilizes
a reference directional model for obtaining a feature representation called
directional embeddings (DE). This reference directional model acts as an
acoustic model for bird vocalizations and is obtained using the mixtures of
Von-Mises Fisher distribution (moVMF). The proposed DE space only contains
information about bird vocalizations, while no information about the background
disturbances is reflected. The framework employs supervised information only
for obtaining the reference directional model and avoids the background
modeling. Hence, it can be regarded as semi-supervised in nature. The proposed
framework is tested on approximately 79000 vocalizations of seven different
bird species. The performance of the framework is also analyzed in the presence
of noise at different SNRs. Experimental results convey that the proposed
framework performs better than the existing bird vocalization segmentation
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09778</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09778</id><created>2019-02-26</created><authors><author><keyname>Rezaei</keyname><forenames>Omid</forenames></author><author><keyname>Naghsh</keyname><forenames>Mohammad Mahdi</forenames></author><author><keyname>Rezaei</keyname><forenames>Zahra</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Throughput Optimization for Wireless Powered Interference Channels</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a general multi-user wireless powered interference channel
(IFC) under the harvest-then-transmit protocol, where the communication in
channel coherence time consists of two phases, namely wireless energy transfer
(WET) and wireless information transfer (WIT). In the first phase, all energy
transmitters (ETs) transmit energy signals to information transmitters (ITs)
via collaborative waveform design, while in the second phase, each IT transmits
an information signal to its intended ET using the harvested energy in the
previous phase. The aim is to jointly design the WET-WIT time allocation, the
(deterministic) transmit signal at the first phase, and the transmit power of
ITs in the second phase to optimize the network throughput. The design problems
are non-convex and hence difficult to solve globally. To deal with them, we
propose efficient iterative algorithms based on alternating projections; then,
the majorization-minimization technique is used to tackle the nonconvex
sub-problems in each iteration. We also extend the devised design methodology
by considering imperfect channel state information (CSI) and non-linearity in
energy harvesting circuit. The proposed algorithms are locally convergent and
can provide high-quality suboptimal solutions to the design problems.
Simulation results show the effectiveness of the proposed algorithms under
various setups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09821</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09821</id><created>2019-02-26</created><authors><author><keyname>Ionescu</keyname><forenames>Maria</forenames></author><author><keyname>Lavery</keyname><forenames>Domanic</forenames></author><author><keyname>Edwards</keyname><forenames>Adrian</forenames></author><author><keyname>Sillekens</keyname><forenames>Eric</forenames></author><author><keyname>Galdino</keyname><forenames>Lidia</forenames></author><author><keyname>Semrau</keyname><forenames>Daniel</forenames></author><author><keyname>Killey</keyname><forenames>Robert</forenames></author><author><keyname>Pelouch</keyname><forenames>Wayne</forenames></author><author><keyname>Barnes</keyname><forenames>Stuart</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>74.38 Tb/s Transmission Over 6300 km Single Mode Fiber with Hybrid
  EDFA/Raman Amplifiers</title><categories>eess.SP physics.app-ph</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Transmission of 306x35 GBd, dual polarization, 64-ary geometrically shaped
channels over 90x70 km of SMF was demonstrated, achieving a net throughput of
74.38 Tb/s. A combination of hybrid fiber spans and EDFA/Raman amplifiers
enabled a continuous gain bandwidth of 10.8 THz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09823</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09823</id><created>2019-02-26</created><authors><author><keyname>de Almeida</keyname><forenames>Ivo Bizon Franco</forenames></author><author><keyname>Mendes</keyname><forenames>Luciano Leonel</forenames></author></authors><title>Linear GFDM: A Low Out-of-band Emission Configuration for 5G Air
  Interface</title><categories>eess.SP</categories><comments>2018 IEEE 5G World Forum (5GWF)</comments><doi>10.1109/5GWF.2018.8516993</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the flexibility of generalized frequency division
multiplexing (GFDM) for achieving the same performance as filter bank
multicarrier (FBMC). We present a GFDM configuration where the good spectral
containment of FBMC is also achieved through a modification in the GFDM
transmission scheme. For evaluating the scheme's performance, we estimate the
bit error ratio (BER) under three channel models: i) pure additive Gaussian
AWGN; ii) time-invariant frequency-selective; iii) time-variant
frequency-selective (doubly dispersive). The spectral containment is measured
through the power spectral density. Furthermore, the complementary cumulative
distribution function (CCDF) of the peak-to-average power ratio (PAPR) is also
estimated. The Linear GFDM waveform shows identical performance when compared
to FBMC in the above test scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09879</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09879</id><created>2019-02-26</created><updated>2019-09-19</updated><authors><author><keyname>Rezaei</keyname><forenames>Atefeh</forenames></author><author><keyname>Azmi</keyname><forenames>Paeiz</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Javan</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Robust Resource Allocation for PD-NOMA-Based MISO Heterogeneous Networks
  with CoMP Technology</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a hybrid scheme of coordinated multi-point (CoMP)
technology in MISO heterogeneous communication networks based on power domain
non-orthogonal multiple access (PD-NOMA). We propose a novel method based on
matching game with externalities to realize the hybrid scheme where the number
of the cooperative nodes are variable. Moreover, we propose a new matching
utility function to manage the interference caused by CoMP and NOMA techniques.
  We also devise robust beamforming to cope with the channel uncertainty. In
this regard, we focus on both no CSI and partial CSI cases to increase the
achievable data rate.
  We provide the complexity analysis of both schemes which shows that the
complexity of the partial CSI approach is more than that of the no CSI method.
  Results evaluate the performance of proposed CoMP scheme and the sensibility
of our methods, Index Terms, CoMP technology, hybrid scheme, matching game with
externalities, PD-NOMA, robust beamforming, probabilistic constraint, no CSI,
partial CSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09943</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09943</id><created>2019-02-26</created><authors><author><keyname>Lin</keyname><forenames>Tian</forenames></author><author><keyname>Cong</keyname><forenames>Jiaqi</forenames></author><author><keyname>Zhu</keyname><forenames>Yu</forenames></author></authors><title>Hybrid beamforming for single carrier mmWave MIMO systems</title><categories>eess.SP</categories><comments>IEEE GlobalSIP2018, Feb. 2019</comments><doi>10.1109/GlobalSIP.2018.8646693</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid analog and digital beamforming (HBF) has been recognized as an
attractive technique offering a tradeoff between hardware implementation
limitation and system performance for future broadband millimeter wave (mmWave)
communications. In contrast to most current works focusing on the HBF design
for orthogonal frequency division multiplexing based mmWave systems, this paper
investigates the HBF design for single carrier (SC) systems due to the
advantage of low peak-to-average power ratio in transmissions. By applying the
alternating minimization method, we propose an efficient HBF scheme based on
the minimum mean square error criterion. Simulation results show that the
proposed scheme outperforms the conventional HBF scheme for SC systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09952</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09952</id><created>2019-02-17</created><authors><author><keyname>No</keyname><forenames>Heekwon</forenames><affiliation>SIGNAV</affiliation></author><author><keyname>Vezinet</keyname><forenames>J&#xe9;r&#xe9;my</forenames><affiliation>TELECOM</affiliation></author><author><keyname>Milner</keyname><forenames>Carl</forenames><affiliation>TELECOM</affiliation></author></authors><title>Diagnostics of GNSS-based Virtual Balise in Railway Using Embedded
  Odometry and Track Geometry</title><categories>eess.SP</categories><proxy>ccsd</proxy><journal-ref>Institute of Navigation International Technical Meeting 2019, Jan
  2019, Reston, VA, United States</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of GNSS in the railway sector has been postulated on the notion of a
Virtual Balise (VB). The VB-based positioning system works by setting a VB
point on the railway track and determining the passage of the VB point using
the position solution from the GNSS receiver. Although augmentation systems
such as SBAS or GBAS are able to satisfy the integrity requirements of the
aviation standards down to the 10-7 level, it is difficult to satisfy the high
integrity requirements of the railway sector because firstly the railway users
located on the ground are affected by the ground environment such as terrain,
buildings and tunnels and secondly because the stringency of the railway sector
requirements extends below the 10-9 level. This paper proposes a method to
detect faults in the GNSS solution due to satellite failure or local effects.
Firstly, requirements for the monitoring performance are carefully derived
accounting for the specificities of GNSS, namely that the possibility of
consecutive VB faults cannot be discounted. The second contribution of the
paper is the proposed detection using both odometry and track geometry of the
onboard system. This enables to monitor all three-dimensional solution error so
that higher sensitivity for the fault detection can be achieved. Simulations
have been performed with both single and dual (GPS, GALILEO) solutions. It has
been found that the combinations of metrics are able to achieve very small
missed detection probabilities for mean failure rates from 5.0m/s down to
0.03m/s for most dual constellation geometries. The detection performance of
the odometer implementation varied according to the heading of the train. On
the other hand, when odometry and track geometry are used together, all the
three-directional monitors can obtain stable results regardless of the heading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09955</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09955</id><created>2019-02-21</created><authors><author><keyname>Roohi</keyname><forenames>Milad</forenames></author><author><keyname>Hernandez</keyname><forenames>Eric M.</forenames></author><author><keyname>Rosowsky</keyname><forenames>David</forenames></author></authors><title>Seismic Damage Assessment of Instrumented Wood-frame Buildings: A
  Case-study of NEESWood Full-scale Shake Table Tests</title><categories>cs.SY eess.SP</categories><comments>This paper is an extended version of the paper titled
  &quot;Element-by-element seismic damage diagnosis and prognosis in minimally
  instrumented wood-frame buildings&quot; presented at Engineering Mechanics
  Institute Conference 2018 (MS23-Advanced deep learning based SHM) and
  participated in the EMI SHM and Control Committee Student Paper Competition
  at MIT, Boston, MA, May 29-June 1, 2018</comments><journal-ref>Presented at Engineering Mechanics Institute Conference 2018 (MS
  23-Advanced deep learning based SHM) and in the EMI SHM and Control Committee
  Student Paper Competition at MIT, Boston, MA, May 29-June 1, 2018</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The authors propose a methodology to perform seismic damage assessment of
instrumented wood-frame buildings using response measurements. The proposed
methodology employs a nonlinear model-based state observer that combines sparse
acceleration measurements and a nonlinear structural model of a building to
estimate the complete seismic response including displacements, velocity,
acceleration and internal forces in all structural members. From the estimated
seismic response and structural characteristics of each shear wall of the
building, element-by-element seismic damage indices are computed and remaining
useful life (pertaining to seismic effects) is predicted. The methodology is
illustrated using measured data from the 2009 NEESWood Capstone full-scale
shake table tests at the E-Defense facility in Japan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09959</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09959</id><created>2019-02-19</created><authors><author><keyname>Krekovic</keyname><forenames>Miranda</forenames></author><author><keyname>Dokmanic</keyname><forenames>Ivan</forenames></author><author><keyname>Vetterli</keyname><forenames>Martin</forenames></author></authors><title>Shapes from Echoes: Uniqueness from Point-to-Plane Distance Matrices</title><categories>cs.CG cs.SD eess.AS eess.SP</categories><comments>13 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of localizing a configuration of points and planes from
the collection of point-to-plane distances. This problem models simultaneous
localization and mapping from acoustic echoes as well as the notable &quot;structure
from sound&quot; approach to microphone localization with unknown sources. In our
earlier work we proposed computational methods for localization from
point-to-plane distances and noted that such localization suffers from various
ambiguities beyond the usual rigid body motions; in this paper we provide a
complete characterization of uniqueness. We enumerate equivalence classes of
configurations which lead to the same distance measurements as a function of
the number of planes and points, and algebraically characterize the related
transformations in both 2D and 3D. Here we only discuss uniqueness;
computational tools and heuristics for practical localization from
point-to-plane distances using sound will be addressed in a companion paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09977</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09977</id><created>2019-02-26</created><authors><author><keyname>Seifert</keyname><forenames>Ann-Kathrin</forenames></author><author><keyname>Zoubir</keyname><forenames>Abdelhak M.</forenames></author><author><keyname>Amin</keyname><forenames>Moeness G.</forenames></author></authors><title>Detection of Gait Asymmetry Using Indoor Doppler Radar</title><categories>eess.SP</categories><comments>6 pages, 5 figures, 4 tables; accepted at the IEEE Radar Conference
  2019, Boston, MA, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Doppler radar systems enable unobtrusive and privacy-preserving long-term
monitoring of human motions indoors. In particular, a person's gait can provide
important information about their state of health. Utilizing micro-Doppler
signatures, we show that radar is capable of detecting small differences
between the step motions of the two legs, which results in asymmetric gait.
Image-based and physical features are extracted from the radar return signals
of several individuals, including four persons with different diagnosed gait
disorders. It is shown that gait asymmetry is correctly detected with high
probability, irrespective of the underlying pathology, for at least one motion
direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.09981</identifier>
 <datestamp>2020-02-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.09981</id><created>2019-02-24</created><updated>2020-02-21</updated><authors><author><keyname>Jin</keyname><forenames>Guozheng</forenames></author></authors><title>Vehicle Classification Based on Seismic Signatures with Weighted
  Intrinsic Mode Functions</title><categories>eess.SP</categories><comments>more tests need to be done</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seismic signal is used for vehicle classification widely. However, this task
becomes difficult as a result of various noises. To solve the problem, this
paper proposes a novel de-noising algorithm which evolves from a nonparametric
adaptive tool named empirical mode decomposition (EMD). EMD can decompose
signals into a set of zero-mean modes called intrinsic mode functions (IMFs)
that can be used to denoise a signal. Unlike other EMD-based de-noising
techniques, selecting the noise-free modes to denoise signals, this paper
assigns appropriate weights to the modes. In addition, considering the
similarities between speech recognition and seismic vehicle classification, an
algorithm scheme, consisting of improved Mel frequency cepstral coefficient
(MFCC) and artificial neural network, is applied to recognize seismic signals
for vehicle targets. The data from DARPA's SensIt project, which contains
various seismic signatures from two different vehicle types, is used to
evaluate the method. Through experiments, results demonstrate the efficacy of
proposed algorithm as compared to traditional MFCC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10043</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10043</id><created>2019-01-18</created><authors><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author></authors><title>An optimization problem on the performance of FSO communication system</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance of Free Space Optical (FSO) communication system is affected by
atmospheric turbulences and pointing errors. These effects can easily be
mitigated by adapting natural system parameters such as wavelength. In this
paper, considering effects of pointing error and atmospheric turbulence, two
optimization models are presented on FSO communication system. In Model 1, the
normalized transmitter power is objective function, Bit Error Rate (BER) is
equality subjective. In Model 2 normalized transmitter power is equality
subjective, the BER is objective function. In both of them the normalized
wavelength is variable parameter. These models were previously investigated
using numerical methods; in the sense that they were solved asymptotically.
From this point of view, this paper regenerated these models and solved them by
a completely different analytical method, and derived a new exact solution.
Comparing exact and asymptotic methods shows some interesting results; the
asymptotic method achieves BER=10^(-9), but the presented new exact method
achieves BER=10^(-13), which is a significant difference. It means that even at
the worst case scenario such as pointing error, it is possible to have a very
good performance by only the transmitting wavelength a bit. Proposed models are
practical and obtained results show that this system is cost and power
effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10063</identifier>
 <datestamp>2019-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10063</id><created>2019-02-26</created><updated>2019-04-03</updated><authors><author><keyname>Zhang</keyname><forenames>Liwen</forenames></author><author><keyname>Han</keyname><forenames>Jiqing</forenames></author></authors><title>Acoustic scene classification using multi-layer temporal pooling based
  on convolutional neural network</title><categories>cs.SD eess.AS</categories><comments>(0) the title for this version is inappropriate; (1) the introduction
  part about the discusses about the handcrafted methods are not precise; (2)
  the Fig. 1 in section 2 is not correct; (3) the experiments about the CNN
  part are insufficient</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of an Acoustic Scene Classification (ASC) system is highly
depending on the latent temporal dynamics of the audio signal. In this paper,
we proposed a multiple layers temporal pooling method using CNN feature
sequence as in-put, which can effectively capture the temporal dynamics for an
entire audio signal with arbitrary duration by building direct connections
between the sequence and its time indexes. We applied our novel framework on
DCASE 2018 task 1, ASC. For evaluation, we trained a Support Vector Machine
(SVM) with the proposed Multi-Layered Temporal Pooling (MLTP) learned features.
Experimental results on the development dataset, usage of the MLTP features
significantly improved the ASC performance. The best performance with 75.28%
accuracy was achieved by using the optimal setting found in our experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10071</identifier>
 <datestamp>2019-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10071</id><created>2019-01-28</created><authors><author><keyname>De Donno</keyname><forenames>Michele</forenames></author><author><keyname>Kavaja</keyname><forenames>Juxhino</forenames></author><author><keyname>Dragoni</keyname><forenames>Nicola</forenames></author><author><keyname>Bucchiarone</keyname><forenames>Antonio</forenames></author><author><keyname>Mazzara</keyname><forenames>Manuel</forenames></author></authors><title>Cyber-Storms Come from Clouds: Security of Cloud Computing in the IoT
  Era</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet of Things (IoT) is rapidly changing our society to a world where
every &quot;thing&quot; is connected to the Internet, making computing pervasive like
never before. This tsunami of connectivity and data collection relies more and
more on the Cloud, where data analytics and intelligence actually reside. Cloud
computing has indeed revolutionized the way computational resources and
services can be used and accessed, implementing the concept of utility
computing whose advantages are undeniable for every business. However, despite
the benefits in terms of flexibility, economic savings, and support of new
services, its widespread adoption is hindered by the security issues arising
with its usage. From a security perspective, the technological revolution
introduced by IoT and Cloud computing can represent a disaster, as each object
might become inherently remotely hackable and, as a consequence, controllable
by malicious actors. While the literature mostly focuses on security of IoT and
Cloud computing as separate entities, in this article we provide an up-to-date
and well-structured survey of the security issues of Cloud computing in the IoT
era. We give a clear picture of where security issues occur and what their
potential impact is. As a result, we claim that it is not enough to secure IoT
devices, as cyber-storms come from Clouds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10107</identifier>
 <datestamp>2019-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10107</id><created>2019-02-26</created><updated>2019-05-17</updated><authors><author><keyname>Xie</keyname><forenames>Weidi</forenames></author><author><keyname>Nagrani</keyname><forenames>Arsha</forenames></author><author><keyname>Chung</keyname><forenames>Joon Son</forenames></author><author><keyname>Zisserman</keyname><forenames>Andrew</forenames></author></authors><title>Utterance-level Aggregation For Speaker Recognition In The Wild</title><categories>eess.AS cs.LG cs.MM cs.SD</categories><comments>To appear in: International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP), 2019. (Oral Presentation)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The objective of this paper is speaker recognition &quot;in the wild&quot;-where
utterances may be of variable length and also contain irrelevant signals.
Crucial elements in the design of deep networks for this task are the type of
trunk (frame level) network, and the method of temporal aggregation. We propose
a powerful speaker recognition deep network, using a &quot;thin-ResNet&quot; trunk
architecture, and a dictionary-based NetVLAD or GhostVLAD layer to aggregate
features across time, that can be trained end-to-end. We show that our network
achieves state of the art performance by a significant margin on the VoxCeleb1
test set for speaker recognition, whilst requiring fewer parameters than
previous methods. We also investigate the effect of utterance length on
performance, and conclude that for &quot;in the wild&quot; data, a longer length is
beneficial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10127</identifier>
 <datestamp>2019-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10127</id><created>2019-02-25</created><authors><author><keyname>Gholizadeh-Ansari</keyname><forenames>Maryam</forenames></author><author><keyname>Alirezaie</keyname><forenames>Javad</forenames></author><author><keyname>Babyn</keyname><forenames>Paul</forenames></author></authors><title>Deep Learning for Low-Dose CT Denoising</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-dose CT denoising is a challenging task that has been studied by many
researchers. Some studies have used deep neural networks to improve the quality
of low-dose CT images and achieved fruitful results. In this paper, we propose
a deep neural network that uses dilated convolutions with different dilation
rates instead of standard convolution helping to capture more contextual
information in fewer layers. Also, we have employed residual learning by
creating shortcut connections to transmit image information from the early
layers to later ones. To further improve the performance of the network, we
have introduced a non-trainable edge detection layer that extracts edges in
horizontal, vertical, and diagonal directions. Finally, we demonstrate that
optimizing the network by a combination of mean-square error loss and
perceptual loss preserves many structural details in the CT image. This
objective function does not suffer from over smoothing and blurring effects
caused by per-pixel loss and grid-like artifacts resulting from perceptual
loss. The experiments show that each modification to the network improves the
outcome while only minimally changing the complexity of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10190</identifier>
 <datestamp>2019-04-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10190</id><created>2019-02-26</created><updated>2019-04-23</updated><authors><author><keyname>Ingle</keyname><forenames>Atul</forenames></author><author><keyname>Velten</keyname><forenames>Andreas</forenames></author><author><keyname>Gupta</keyname><forenames>Mohit</forenames></author></authors><title>High Flux Passive Imaging with Single-Photon Sensors</title><categories>eess.IV cs.CV physics.ins-det</categories><comments>28 pages, 15 figures, addressed reviewers's comments, fixed some
  errors and typos, official peer reviewed version to appear in IEEE CVPR 2019</comments><acm-class>I.3.3; I.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-photon avalanche diodes (SPADs) are an emerging technology with a
unique capability of capturing individual photons with high timing precision.
SPADs are being used in several active imaging systems (e.g., fluorescence
lifetime microscopy and LiDAR), albeit mostly limited to low photon flux
settings. We propose passive free-running SPAD (PF-SPAD) imaging, an imaging
modality that uses SPADs for capturing 2D intensity images with unprecedented
dynamic range under ambient lighting, without any active light source. Our key
observation is that the precise inter-photon timing measured by a SPAD can be
used for estimating scene brightness under ambient lighting conditions, even
for very bright scenes. We develop a theoretical model for PF-SPAD imaging, and
derive a scene brightness estimator based on the average time of darkness
between successive photons detected by a PF-SPAD pixel. Our key insight is that
due to the stochastic nature of photon arrivals, this estimator does not suffer
from a hard saturation limit. Coupled with high sensitivity at low flux, this
enables a PF-SPAD pixel to measure a wide range of scene brightness, from very
low to very high, thereby achieving extreme dynamic range. We demonstrate an
improvement of over 2 orders of magnitude over conventional sensors by imaging
scenes spanning a dynamic range of 1,000,000:1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10196</identifier>
 <datestamp>2019-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10196</id><created>2019-02-26</created><authors><author><keyname>Zhang</keyname><forenames>Han</forenames></author><author><keyname>Yang</keyname><forenames>Jun</forenames></author></authors><title>Transmission of Video Image in Underwater Acoustic Communication</title><categories>eess.SP physics.app-ph</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic communication is currently considered as the best way to transmit
information over long distances under water, since acoustic waves have lower
attenuation in water than the other information transmission media. However,
current information transmission rates of the underwater acoustic communication
is usually limited by low-frequency bandwidth due to the large attenuation
which characterized in high-frequency sound waves in water. Spiral acoustic
beams with helical wavefront dislocations carrying orbital angular momentum
have been applied to acoustic levitation and capture. Recently, harnessing the
orthogonality and the infinite dimension of Hilbert space in underwater
acoustic communication has been considered promising. Here, we construct a
real-time underwater acoustic communication system to transmit video image. The
system multiplexes eight orbital angular momentum topology charges ranging from
+1 to +8 and encoded with on-off keying modulation format, achieving a spectral
efficiency of 8 (bit/s)/Hz. This demonstration suggests that multiplexed
information-carrying orbital angular momentum acoustic beams presents
tremendous potential for increasing the capacity of underwater communication
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10226</identifier>
 <datestamp>2019-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10226</id><created>2019-02-26</created><authors><author><keyname>Rambhatla</keyname><forenames>Sirisha</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nikos D.</forenames></author><author><keyname>Haupt</keyname><forenames>Jarvis</forenames></author></authors><title>TensorMap: Lidar-Based Topological Mapping and Localization via Tensor
  Decompositions</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>5 pages; Index Terms - Topological maps, Lidar, Localization of
  Autonomous Vehicles, Orthogonal Tucker Decomposition, and Scan-matching</comments><journal-ref>2018 IEEE Global Conference on Signal and Information Processing
  (GlobalSIP)</journal-ref><doi>10.1109/GlobalSIP.2018.8646665</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a technique to develop (and localize in) topological maps from
light detection and ranging (Lidar) data. Localizing an autonomous vehicle with
respect to a reference map in real-time is crucial for its safe operation.
Owing to the rich information provided by Lidar sensors, these are emerging as
a promising choice for this task. However, since a Lidar outputs a large amount
of data every fraction of a second, it is progressively harder to process the
information in real-time. Consequently, current systems have migrated towards
faster alternatives at the expense of accuracy. To overcome this inherent
trade-off between latency and accuracy, we propose a technique to develop
topological maps from Lidar data using the orthogonal Tucker3 tensor
decomposition. Our experimental evaluations demonstrate that in addition to
achieving a high compression ratio as compared to full data, the proposed
technique, $\textit{TensorMap}$, also accurately detects the position of the
vehicle in a graph-based representation of a map. We also analyze the
robustness of the proposed technique to Gaussian and translational noise, thus
initiating explorations into potential applications of tensor decompositions in
Lidar data analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10280</identifier>
 <datestamp>2019-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10280</id><created>2019-02-26</created><authors><author><keyname>Jalali</keyname><forenames>Amin</forenames></author><author><keyname>Ding</keyname><forenames>Zhi</forenames></author></authors><title>A New Algorithm for Improved Blind Detection of Polar Coded PDCCH in 5G
  New Radio</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent release of the new cellular standard known as 5G New Radio (5G-NR),
the physical downlink control channel (PDCCH) has adopted polar codes for error
protection. Similar to 4G-LTE, each active user equipment (UE) must blindly
detect its own PDCCH in the downlink search space. This work investigates new
ways to improve the accuracy of PDCCH blind detection in 5G-NR. We develop a
novel design of joint detection and decoding receiver for 5G multiple-input
multiple-output (MIMO) transceivers. We aim to achieve robustness against
practical obstacles including channel state information (CSI) errors, noise,
co-channel interferences, and pilot contamination. To optimize the overall
receiver performance in PDCCH blind detection, we incorporate the polar code
information during the signal detection stage by relaxing and transforming the
Galois field code constraints into the complex signal field. Specifically, we
develop a novel joint linear programming (LP) formulation that takes into
consideration the transformed polar code constraints. Our proposed joint LP
formulation can also be integrated with polar decoders to deliver superior
receiver performance at low cost. We further introduce a metric that can be
used to eliminate most of wrong PDCCH candidates to improve the computational
efficiency of PDCCH blind detection for 5G-NR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10291</identifier>
 <datestamp>2019-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10291</id><created>2019-02-26</created><authors><author><keyname>Zhang</keyname><forenames>Sen</forenames></author><author><keyname>Ma</keyname><forenames>Xin</forenames></author><author><keyname>Lu</keyname><forenames>Hongwang</forenames></author><author><keyname>He</keyname><forenames>Weikai</forenames></author><author><keyname>Zhou</keyname><forenames>Weidong</forenames></author></authors><title>Accurate Target Localization by using Artificial Pinnae of brown
  long-eared bat</title><categories>eess.SP cs.SD eess.AS q-bio.NC</categories><comments>22 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Echolocating bats locate the targets by echolocation. Many theoretical
frameworks have been suggested the abilities of bats are related to the shapes
of bats ears, but few artificial bat-like ears have been made to mimic the
abilities, the difficulty of which lies in the determination of the elevation
angle of the target. In this study, we present a device with artificial bat
pinnae modeling by the ears of brown long-eared bat (Plecotus auritus) which
can accurately estimate the elevation angle of the aerial target by virtue of
active sonar. An artificial neural-network with the labeled data obtained from
echoes as the trained and tested data is used and optimized by a tenfold
cross-validation technique. A decision method we named sliding window averaging
algorithm is designed for getting the estimation results of elevation. At last,
a right-angle pinnae construction is designed for determining direction of the
target. The results show a higher accuracy for the direction determination of
the single target. The results also demonstrate that for the Plecotus auritus
bat, not only the binaural shapes, but the binaural relative orientations also
play important roles in the target localization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10379</identifier>
 <datestamp>2019-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10379</id><created>2019-02-27</created><updated>2019-04-17</updated><authors><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Yang</keyname><forenames>Xiuyan</forenames></author><author><keyname>Ma</keyname><forenames>Jianwei</forenames></author></authors><title>Can learning from natural image denoising be used for seismic data
  interpolation?</title><categories>physics.geo-ph cs.LG eess.SP</categories><comments>26 pages, 7 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a convolutional neural network (CNN) denoising based method for
seismic data interpolation. It provides a simple and efficient way to break
though the lack problem of geophysical training labels that are often required
by deep learning methods. The new method consists of two steps: (1) Train a set
of CNN denoisers from natural image clean-noisy pairs to learn denoising; (2)
Integrate the trained CNN denoisers into project onto convex set (POCS)
framework to perform seismic data interpolation. The method alleviates the
demanding of seismic big data with similar features as applications of
end-to-end deep learning on seismic data interpolation. Additionally, the
proposed method is flexible for many cases of traces missing because missing
cases are not involved in the training step, and thus it is of plug-and-play
nature. These indicate the high generalizability of our approach and the
reduction of the need of the problem-specific training. Primary results on
synthetic and field data show promising interpolation performances of the
presented CNN-POCS method in terms of signal-to-noise ratio, de-aliasing and
weak-feature reconstruction, in comparison with traditional $f$-$x$ prediction
filtering and curvelet transform based POCS methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10403</identifier>
 <datestamp>2019-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10403</id><created>2019-02-27</created><authors><author><keyname>Liu</keyname><forenames>Yingting</forenames></author><author><keyname>Ye</keyname><forenames>Yinghui</forenames></author><author><keyname>Ding</keyname><forenames>Haiyang</forenames></author><author><keyname>Shen</keyname><forenames>Jianmei</forenames></author><author><keyname>Yang</keyname><forenames>Hongwu</forenames></author></authors><title>Performance Analysis in DF Based Cooperative SWIPT Networks with Direct
  Link</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter proposes a dynamic power splitting scheme (DPSS) for
decode-and-forward (DF) based cooperative simultaneous wireless information and
power transfer (SWIPT) networks with direct link. The relay node adopts an
optimal dynamic power splitting factor determined by instantaneous channel
state information (CSI) to harvest energy and process information. The
expressions for the optimal dynamic power splitting factor, outage probability
and ergodic capacity of the proposed network are derived. Numerical results
show that the proposed scheme is better than or the same as the existing PS
schemes in terms of outage probability, while it achieves higher ergodic
capacity compared to the existing PS schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10480</identifier>
 <datestamp>2019-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10480</id><created>2019-02-27</created><authors><author><keyname>Liu</keyname><forenames>Haojie</forenames></author><author><keyname>Chen</keyname><forenames>Tong</forenames></author><author><keyname>Guo</keyname><forenames>Peiyao</forenames></author><author><keyname>Shen</keyname><forenames>Qiu</forenames></author><author><keyname>Ma</keyname><forenames>Zhan</forenames></author></authors><title>Gated Context Model with Embedded Priors for Deep Image Compression</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A deep image compression scheme is proposed in this paper, offering the
state-of-the-art compression efficiency, against the traditional JPEG,
JPEG2000, BPG and those popular learning based methodologies. This is achieved
by a novel conditional probably model with embedded priors which can accurately
approximate the entropy rate for rate-distortion optimization. It utilizes
three separable stacks to eliminate the blind spots in the receptive field for
better probability prediction and computation reduction. Those embedded priors
can be further used to help the image reconstruction when fused with latent
features, after passing through the proposed information compensation network
(ICN). Residual learning with generalized divisive normalization (GDN) based
activation is used in our encoder and decoder with fast convergence rate and
efficient performance. We have evaluated our model and other methods using
rate-distortion criteria, where distortion is measured by multi-scale
structural similarity (MS-SSIM). We have also discussed the impacts of various
distortion metrics on the reconstructed image quality. Besides, a field study
on perceptual quality is also given via a dedicated subjective assessment, to
compare the efficiency of our proposed methods and other conventional image
compression methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10823</identifier>
 <datestamp>2019-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10823</id><created>2019-02-27</created><authors><author><keyname>Song</keyname><forenames>Hao</forenames></author><author><keyname>Chen</keyname><forenames>Yu</forenames></author><author><keyname>Zhou</keyname><forenames>Ning</forenames></author><author><keyname>Chen</keyname><forenames>Genshe</forenames></author></authors><title>Electricity Consumption Forecasting for Smart Grid using the
  Multi-Factor Back-Propagation Neural Network</title><categories>eess.SP</categories><comments>Submitted to the 2019 SPIE Defense + Commercial Sensing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the development of modern information technology (IT), a smart grid has
become one of the major components of smart cities. To take full advantage of
the smart grid, the capability of intelligent scheduling and planning of
electricity delivery is essential. In practice, many factors have an impact on
electricity consumption, which necessitates information fusion technologies for
a thorough understanding. For this purpose, researchers have investigated
methodologies for collecting electricity consumption related information and
variant multi-factor power consumption forecasting models. In addition,
conducting a comprehensive analysis and obtaining an accurate evaluation of
power consumption are the premise and basis for a more robust and efficient
power grid design and transformation. Therefore, it is meaningful to explore
forecasting models that are able to reflect the power consumption changes and
internal relations within fusional information effectively. Making electricity
consumption forecasting based on the neural network has been a popular research
topic in recent years, and the back-propagation neural network (BPNN) algorithm
has been recognized as a mature and effective method. In this paper, BPNN is
adopted to forecast the electricity consumption using Pecan Street, a community
with a relatively large-scale smart grid, as a case study, and takes multiple
factors into account, such as weather condition, weekend and holidays. The
influences of each factor have been evaluated for a deeper insight. We hope
this work will inspire more discussion and further study to guide the design of
future smart grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.10825</identifier>
 <datestamp>2019-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1902.10825</id><created>2019-02-27</created><authors><author><keyname>Azami</keyname><forenames>Hamed</forenames></author><author><keyname>Arnold</keyname><forenames>Steven E.</forenames></author><author><keyname>Sanei</keyname><forenames>Saeid</forenames></author><author><keyname>Chang</keyname><forenames>Zhuoqing</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author><author><keyname>Escudero</keyname><forenames>Javier</forenames></author><author><keyname>Gupta</keyname><forenames>Anoopum S.</forenames></author></authors><title>Multiscale Fluctuation-based Dispersion Entropy and its Applications to
  Neurological Diseases</title><categories>q-bio.NC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluctuation-based dispersion entropy (FDispEn) is a new approach to estimate
the dynamical variability of the fluctuations of signals. It is based on
Shannon entropy and fluctuation-based dispersion patterns. To quantify the
physiological dynamics over multiple time scales, multiscale FDispEn (MFDE) is
developed in this article. MFDE is robust to the presence of baseline wanders,
or trends, in the data. We evaluate MFDE, compared with popular multiscale
sample entropy (MSE), and the recently introduced multiscale dispersion entropy
(MDE), on selected synthetic data and five neurological diseases' datasets: 1)
focal and non-focal electroencephalograms (EEGs); 2) walking stride interval
signals for young, elderly, and Parkinson's subjects; 3) stride interval
fluctuations for Huntington's disease and amyotrophic lateral sclerosis; 4)
EEGs for controls and Alzheimer's disease patients; and 5) eye movement data
for Parkinson's disease and ataxia. MFDE dealt with the problem of undefined
MSE values and, compared with MDE, led to more stable entropy values over the
scale factors for pink noise. Overall, MFDE was the fastest and most consistent
method for the discrimination of different states of neurological data,
especially where the mean value of a time series considerably changes along the
signal (e.g., eye movement data). This study shows that MFDE is a relevant new
metric to gain further insights into the dynamics of neurological diseases
recordings.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="4000" completeListSize="16166">4250076|5001</resumptionToken>
</ListRecords>
</OAI-PMH>
