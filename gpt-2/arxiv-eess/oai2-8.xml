<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2020-03-01T07:01:51Z</responseDate>
<request verb="ListRecords" resumptionToken="4250076|7001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07299</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07299</id><created>2019-06-17</created><authors><author><keyname>Novoa</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Fredes</keyname><forenames>Josu&#xe9;</forenames></author><author><keyname>Wuth</keyname><forenames>Jorge</forenames></author><author><keyname>Huenup&#xe1;n</keyname><forenames>Fernando</forenames></author><author><keyname>Stern</keyname><forenames>Richard M.</forenames></author><author><keyname>Yoma</keyname><forenames>Nestor Becerra</forenames></author></authors><title>On combining features for single-channel robust speech recognition in
  reverberant environments</title><categories>eess.AS cs.SD</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper addresses the combination of complementary parallel speech
recognition systems to reduce the error rate of speech recognition systems
operating in real highly-reverberant environments. First, the testing
environment consists of recordings of speech in a calibrated real room with
reverberation times from 0.47 to 1.77 seconds and speaker-to-microphone
distances of 0.16 to 2.56 meters. We combined systems both at the level of the
DNN outputs and at the level of the final ASR outputs. Second, recognition
experiments with the reverb challenge are also reported. The results presented
here show that the combination of features can lead to WER improvements between
7% and 18% with speech recorded in real reverberant environments. Also, the
combination at DNN-output level is much more effective than at the
system-output level. However, cascading both schemes can still lead to smaller
reductions in WER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07307</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07307</id><created>2019-06-17</created><authors><author><keyname>Fang</keyname><forenames>Wei</forenames></author><author><keyname>Chung</keyname><forenames>Yu-An</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Towards Transfer Learning for End-to-End Speech Synthesis from Deep
  Pre-Trained Language Models</title><categories>cs.CL cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern text-to-speech (TTS) systems are able to generate audio that sounds
almost as natural as human speech. However, the bar of developing high-quality
TTS systems remains high since a sizable set of studio-quality &lt;text, audio&gt;
pairs is usually required. Compared to commercial data used to develop
state-of-the-art systems, publicly available data are usually worse in terms of
both quality and size. Audio generated by TTS systems trained on publicly
available data tends to not only sound less natural, but also exhibits more
background noise. In this work, we aim to lower TTS systems' reliance on
high-quality data by providing them the textual knowledge extracted by deep
pre-trained language models during training. In particular, we investigate the
use of BERT to assist the training of Tacotron-2, a state of the art TTS
consisting of an encoder and an attention-based decoder. BERT representations
learned from large amounts of unlabeled text data are shown to contain very
rich semantic and syntactic information about the input text, and have
potential to be leveraged by a TTS system to compensate the lack of
high-quality data. We incorporate BERT as a parallel branch to the Tacotron-2
encoder with its own attention head. For an input text, it is simultaneously
passed into BERT and the Tacotron-2 encoder. The representations extracted by
the two branches are concatenated and then fed to the decoder. As a preliminary
study, although we have not found incorporating BERT into Tacotron-2 generates
more natural or cleaner speech at a human-perceivable level, we observe
improvements in other aspects such as the model is being significantly better
at knowing when to stop decoding such that there is much less babbling at the
end of the synthesized audio and faster convergence during training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07316</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07316</id><created>2019-06-17</created><authors><author><keyname>Flynn</keyname><forenames>John</forenames></author><author><keyname>Broxton</keyname><forenames>Michael</forenames></author><author><keyname>Debevec</keyname><forenames>Paul</forenames></author><author><keyname>DuVall</keyname><forenames>Matthew</forenames></author><author><keyname>Fyffe</keyname><forenames>Graham</forenames></author><author><keyname>Overbeck</keyname><forenames>Ryan</forenames></author><author><keyname>Snavely</keyname><forenames>Noah</forenames></author><author><keyname>Tucker</keyname><forenames>Richard</forenames></author></authors><title>DeepView: View Synthesis with Learned Gradient Descent</title><categories>cs.CV cs.GR cs.LG eess.IV</categories><comments>See https://augmentedperception.github.io/deepview/ for more results,
  video and an interactive viewer</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to view synthesis using multiplane images (MPIs).
Building on recent advances in learned gradient descent, our algorithm
generates an MPI from a set of sparse camera viewpoints. The resulting method
incorporates occlusion reasoning, improving performance on challenging scene
features such as object boundaries, lighting reflections, thin structures, and
scenes with high depth complexity. We show that our method achieves
high-quality, state-of-the-art results on two datasets: the Kalantari light
field dataset, and a new camera array dataset, Spaces, which we make publicly
available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07317</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07317</id><created>2019-06-17</created><authors><author><keyname>Xiang</keyname><forenames>Xu</forenames></author><author><keyname>Wang</keyname><forenames>Shuai</forenames></author><author><keyname>Huang</keyname><forenames>Houjun</forenames></author><author><keyname>Qian</keyname><forenames>Yanmin</forenames></author><author><keyname>Yu</keyname><forenames>Kai</forenames></author></authors><title>Margin Matters: Towards More Discriminative Deep Neural Network
  Embeddings for Speaker Recognition</title><categories>eess.AS cs.CL cs.SD</categories><comments>not accepted by INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, speaker embeddings extracted from a speaker discriminative deep
neural network (DNN) yield better performance than the conventional methods
such as i-vector. In most cases, the DNN speaker classifier is trained using
cross entropy loss with softmax. However, this kind of loss function does not
explicitly encourage inter-class separability and intra-class compactness. As a
result, the embeddings are not optimal for speaker recognition tasks. In this
paper, to address this issue, three different margin based losses which not
only separate classes but also demand a fixed margin between classes are
introduced to deep speaker embedding learning. It could be demonstrated that
the margin is the key to obtain more discriminative speaker embeddings.
Experiments are conducted on two public text independent tasks: VoxCeleb1 and
Speaker in The Wild (SITW). The proposed approach can achieve the
state-of-the-art performance, with 25% ~ 30% equal error rate (EER) reduction
on both tasks when compared to strong baselines using cross entropy loss with
softmax, obtaining 2.238% EER on VoxCeleb1 test set and 2.761% EER on SITW
core-core test set, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07319</identifier>
 <datestamp>2020-01-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07319</id><created>2019-06-17</created><updated>2020-01-27</updated><authors><author><keyname>Nicolson</keyname><forenames>Aaron</forenames></author><author><keyname>Paliwal</keyname><forenames>Kuldip K.</forenames></author></authors><title>Deep Xi as a Front-End for Robust Automatic Speech Recognition</title><categories>eess.AS cs.SD eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current front-ends for robust automatic speech recognition(ASR) include
masking- and mapping-based deep learning approaches to speech enhancement. A
recently proposed deep learning approach toa prioriSNR estimation, called
DeepXi, was able to produce enhanced speech at a higher quality and
intelligibility than current masking- and mapping-based approaches. Motivated
by this, we investigate Deep Xi as a front-end for robust ASR. Deep Xi is
evaluated using real-world non-stationary and coloured noise sources at
multiple SNR levels. Our experimental investigation shows that DeepXi as a
front-end is able to produce a lower word error rate than recent masking- and
mapping-based deep learning front-ends. The results presented in this work show
that Deep Xi is a viable front-end, and is able to significantly increase the
robustness of an ASR system. Availability: Deep Xi is available
at:https://github.com/anicolson/DeepXi
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07330</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07330</id><created>2019-06-17</created><authors><author><keyname>Cha</keyname><forenames>Eunju</forenames></author><author><keyname>Jang</keyname><forenames>Jaeduck</forenames></author><author><keyname>Lee</keyname><forenames>Junho</forenames></author><author><keyname>Lee</keyname><forenames>Eunha</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>Boosting CNN beyond Label in Inverse Problems</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNN) have been extensively used for inverse
problems. However, their prediction error for unseen test data is difficult to
estimate a priori since the neural networks are trained using only selected
data and their architecture are largely considered a blackbox. This poses a
fundamental challenge to neural networks for unsupervised learning or
improvement beyond the label. In this paper, we show that the recent
unsupervised learning methods such as Noise2Noise, Stein's unbiased risk
estimator (SURE)-based denoiser, and Noise2Void are closely related to each
other in their formulation of an unbiased estimator of the prediction error,
but each of them are associated with its own limitations. Based on these
observations, we provide a novel boosting estimator for the prediction error.
In particular, by employing combinatorial convolutional frame representation of
encoder-decoder CNN and synergistically combining it with the batch
normalization, we provide a close form formulation for the unbiased estimator
of the prediction error that can be minimized for neural network training
beyond the label. Experimental results show that the resulting algorithm, what
we call Noise2Boosting, provides consistent improvement in various inverse
problems under both supervised and unsupervised learning setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07334</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07334</id><created>2019-06-17</created><authors><author><keyname>Zhang</keyname><forenames>Xinglong</forenames></author><author><keyname>Jiang</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Zhizhong</forenames></author><author><keyname>Xu</keyname><forenames>Xin</forenames></author></authors><title>A Dual-level Model Predictive Control Scheme for Multi-timescale
  Dynamical Systems</title><categories>eess.SY cs.SY</categories><comments>13 pages, 9 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a dual-level model predictive control (MPC) scheme for
two-timescale dynamical systems subject to input and state constraints, with
the scope to enforce closed-loop separable dynamics. A novel dual-level MPC
(i.e., D-MPC) algorithm is initially presented. At the high level of the
control structure, a stabilizing MPC regulator minimizes the deviation of the
output and its setpoint at a slow time scale. A shrinking horizon MPC is
designed at the low level to refine the computed control actions in the basic
time scale so as to generate satisfactory short-term transient of the output
associated with the &quot;fast&quot; dynamics. To further improve the closed-loop control
performance, an incremental D-MPC algorithm is also proposed, via introducing
at the high level of the D-MPC an integral action and an explicit design of the
&quot;fast&quot; output reference. The proposed algorithms are not only suitable for
systems characterized by different dynamics, but also capable of imposing
separable closed-loop performance for dynamics that are non-separable and
strongly coupled. The recursive feasibility and convergence properties of the
D-MPC and incremental D-MPC closed-loop control systems are proven. The
simulation results concerning the use of the proposed approaches for the
control of a Boiler Turbine (BT) system, including the comparisons with a
decentralized PID controller and a multirate MPC, are reported to show the
effectiveness of the proposed algorithms in imposing closed-loop separable
dynamics and the advantages in generating satisfactory control performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07347</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07347</id><created>2019-06-17</created><updated>2019-06-25</updated><authors><author><keyname>Yue</keyname><forenames>Qian</forenames></author><author><keyname>Luo</keyname><forenames>Xinzhe</forenames></author><author><keyname>Ye</keyname><forenames>Qing</forenames></author><author><keyname>Xu</keyname><forenames>Lingchao</forenames></author><author><keyname>Zhuang</keyname><forenames>Xiahai</forenames></author></authors><title>Cardiac Segmentation from LGE MRI Using Deep Neural Network
  Incorporating Shape and Spatial Priors</title><categories>eess.IV cs.CV</categories><comments>Accepted for publication in MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cardiac segmentation from late gadolinium enhancement MRI is an important
task in clinics to identify and evaluate the infarction of myocardium. The
automatic segmentation is however still challenging, due to the heterogeneous
intensity distributions and indistinct boundaries in the images. In this paper,
we propose a new method, based on deep neural networks (DNN), for fully
automatic segmentation. The proposed network, referred to as SRSCN, comprises a
shape reconstruction neural network (SRNN) and a spatial constraint network
(SCN). SRNN aims to maintain a realistic shape of the resulting segmentation.
It can be pre-trained by a set of label images, and then be embedded into a
unified loss function as a regularization term. Hence, no manually designed
feature is needed. Furthermore, SCN incorporates the spatial information of the
2D slices. It is formulated and trained with the segmentation network via the
multi-task learning strategy. We evaluated the proposed method using 45
patients and compared with two state-of-the-art regularization schemes, i.e.,
the anatomically constraint neural network and the adversarial neural network.
The results show that the proposed SRSCN outperformed the conventional schemes,
and obtained a Dice score of 0.758(std=0.227) for myocardial segmentation,
which compares with 0.757(std=0.083) from the inter-observer variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07357</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07357</id><created>2019-06-17</created><authors><author><keyname>Zhu</keyname><forenames>Wentao</forenames></author><author><keyname>Huang</keyname><forenames>Yufang</forenames></author><author><keyname>Vannan</keyname><forenames>Mani A</forenames></author><author><keyname>Liu</keyname><forenames>Shizhen</forenames></author><author><keyname>Xu</keyname><forenames>Daguang</forenames></author><author><keyname>Fan</keyname><forenames>Wei</forenames></author><author><keyname>Qian</keyname><forenames>Zhen</forenames></author><author><keyname>Xie</keyname><forenames>Xiaohui</forenames></author></authors><title>Neural Multi-Scale Self-Supervised Registration for Echocardiogram Dense
  Tracking</title><categories>cs.CV cs.LG cs.NE eess.IV</categories><comments>Blood tracking video: https://youtu.be/pEA6ZmtTNuQ Muscle tracking
  video: https://youtu.be/NvLrCaqCiAE</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Echocardiography has become routinely used in the diagnosis of cardiomyopathy
and abnormal cardiac blood flow. However, manually measuring myocardial motion
and cardiac blood flow from echocardiogram is time-consuming and error-prone.
Computer algorithms that can automatically track and quantify myocardial motion
and cardiac blood flow are highly sought after, but have not been very
successful due to noise and high variability of echocardiography. In this work,
we propose a neural multi-scale self-supervised registration (NMSR) method for
automated myocardial and cardiac blood flow dense tracking. NMSR incorporates
two novel components: 1) utilizing a deep neural net to parameterize the
velocity field between two image frames, and 2) optimizing the parameters of
the neural net in a sequential multi-scale fashion to account for large
variations within the velocity field. Experiments demonstrate that NMSR yields
significantly better registration accuracy than state-of-the-art methods, such
as advanced normalization tools (ANTs) and VoxelMorph, for both myocardial and
cardiac blood flow dense tracking. Our approach promises to provide a fully
automated method for fast and accurate analyses of echocardiograms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07361</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07361</id><created>2019-06-17</created><authors><author><keyname>Tan</keyname><forenames>Chunyu</forenames></author><author><keyname>Zhang</keyname><forenames>Liming</forenames></author><author><keyname>Wu</keyname><forenames>Hau-tieng</forenames></author><author><keyname>Qian</keyname><forenames>Tao</forenames></author></authors><title>A Novel Feature Representation for Single-Channel Heartbeat
  Classification based on Adaptive Fourier Decomposition</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel approach for heartbeat classification from
single-lead electrocardiogram (ECG) signals based on the novel adaptive Fourier
decomposition (AFD). AFD is a recently developed signal processing tool that
provides useful morphological features, referred to as AFD-derived
instantaneous frequency (IF) features, that are different from those provided
by traditional tools. A support vector machine (SVM) classifier is trained with
the AFD-derived IF features, ECG landmark features, and RR interval features.
To evaluate the performance of the trained classifier, the Association for the
Advancement of Medical Instrumentation (AAMI) standard is applied to the
publicly available benchmark databases, including MIT-BIH arrhythmia database
and MIT-BIH supraventricular arrhythmia database, to classify heartbeats from
single-lead ECG. The overall performance in terms of sensitivities and positive
predictive values is comparable to the state-of-the-art automatic heartbeat
classification algorithms based on two-leads ECG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07367</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07367</id><created>2019-06-18</created><authors><author><keyname>Zhang</keyname><forenames>Zhenxi</forenames></author><author><keyname>Li</keyname><forenames>Jie</forenames></author><author><keyname>Zhong</keyname><forenames>Zhusi</forenames></author><author><keyname>Jiao</keyname><forenames>Zhicheng</forenames></author><author><keyname>Gao</keyname><forenames>Xinbo</forenames></author></authors><title>A sparse annotation strategy based on attention-guided active learning
  for 3D medical image segmentation</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3D image segmentation is one of the most important and ubiquitous problems in
medical image processing. It provides detailed quantitative analysis for
accurate disease diagnosis, abnormal detection, and classification. Currently
deep learning algorithms are widely used in medical image segmentation, most
algorithms trained models with full annotated datasets. However, obtaining
medical image datasets is very difficult and expensive, and full annotation of
3D medical image is a monotonous and time-consuming work. Partially labelling
informative slices in 3D images will be a great relief of manual annotation.
Sample selection strategies based on active learning have been proposed in the
field of 2D image, but few strategies focus on 3D images. In this paper, we
propose a sparse annotation strategy based on attention-guided active learning
for 3D medical image segmentation. Attention mechanism is used to improve
segmentation accuracy and estimate the segmentation accuracy of each slice. The
comparative experiments with three different strategies using datasets from the
developing human connectome project (dHCP) show that, our strategy only needs
15% to 20% annotated slices in brain extraction task and 30% to 35% annotated
slices in tissue segmentation task to achieve comparative results as full
annotation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07373</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07373</id><created>2019-06-18</created><authors><author><keyname>Zhang</keyname><forenames>Ling</forenames></author><author><keyname>Zhang</keyname><forenames>Baosen</forenames></author></authors><title>Scenario Forecasting of Residential Load Profiles</title><categories>eess.SY cs.SY eess.SP</categories><comments>12 pages, 11 figures; Submitted to JSAC-Communications and Data
  Analytics in Smart Grid; Code available at
  https://github.com/zhhhling/June2019/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Load forecasting is an integral part of power system operations and planning.
Due to the increasing penetration of rooftop PV, electric vehicles and demand
response applications, forecasting the load of individual and a small group of
households is becoming increasingly important. Forecasting the load accurately,
however, is considerable more difficult when only a few households are
included. A way to mitigate this challenge is to provide a set of scenarios
instead of one point forecast, so an operator or utility can consider a range
of behaviors. This paper proposes a novel scenario forecasting approach for
residential load using flow-based conditional generative models. Compared to
existing scenario forecasting methods, our approach can generate scenarios that
are not only able to infer possible future realizations of residential load
from the observed historical data but also realistic enough to cover a wide
range of behaviors. Particularly, the flow-based models utilize a flow of
reversible transformations to maximize the value of conditional density
function of future load given the past observations. In order to better capture
the complex temporal dependency of the forecasted future load on the condition,
we extend the structure design for the reversible transformations in flow-based
conditional generative models by strengthening the coupling between the output
and the conditional input in the transformations. The simulation results show
the flow-based designs outperform existing methods in scenario forecasting for
residential load by both providing more accurate and more diverse scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07383</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07383</id><created>2019-06-18</created><authors><author><keyname>Jayadevan</keyname><forenames>Vijai T.</forenames></author><author><keyname>Rodriguez</keyname><forenames>Jeffrey J.</forenames></author><author><keyname>Cronin</keyname><forenames>Alexander D.</forenames></author></authors><title>A Conditional Random Field Model for Context Aware Cloud Detection in
  Sky Images</title><categories>eess.IV cs.CV cs.LG</categories><comments>This was part of Vijai Jayadevan's MS thesis which was completed in
  Dec 2013. This particular chapter remained unpublished till now</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A conditional random field (CRF) model for cloud detection in ground based
sky images is presented. We show that very high cloud detection accuracy can be
achieved by combining a discriminative classifier and a higher order clique
potential in a CRF framework. The image is first divided into homogeneous
regions using a mean shift clustering algorithm and then a CRF model is defined
over these regions. The various parameters involved are estimated using
training data and the inference is performed using Iterated Conditional Modes
(ICM) algorithm. We demonstrate how taking spatial context into account can
boost the accuracy. We present qualitative and quantitative results to prove
the superior performance of this framework in comparison with other state of
the art methods applied for cloud detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07414</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07414</id><created>2019-06-18</created><updated>2019-10-07</updated><authors><author><keyname>Luong</keyname><forenames>Hieu-Thi</forenames></author><author><keyname>Yamagishi</keyname><forenames>Junichi</forenames></author></authors><title>A Unified Speaker Adaptation Method for Speech Synthesis using
  Transcribed and Untranscribed Speech with Backpropagation</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>14 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By representing speaker characteristic as a single fixed-length vector
extracted solely from speech, we can train a neural multi-speaker speech
synthesis model by conditioning the model on those vectors. This model can also
be adapted to unseen speakers regardless of whether the transcript of
adaptation data is available or not. However, this setup restricts the speaker
component to just a single bias vector, which in turn limits the performance of
adaptation process. In this study, we propose a novel speech synthesis model,
which can be adapted to unseen speakers by fine-tuning part of or all of the
network using either transcribed or untranscribed speech. Our methodology
essentially consists of two steps: first, we split the conventional acoustic
model into a speaker-independent (SI) linguistic encoder and a speaker-adaptive
(SA) acoustic decoder; second, we train an auxiliary acoustic encoder that can
be used as a substitute for the linguistic encoder whenever linguistic features
are unobtainable. The results of objective and subjective evaluations show that
adaptation using either transcribed or untranscribed speech with our
methodology achieved a reasonable level of performance with an extremely
limited amount of data and greatly improved performance with more data.
Surprisingly, adaptation with untranscribed speech surpassed the transcribed
counterpart in the subjective test, which reveals the limitations of the
conventional acoustic model and hints at potential directions for improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07416</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07416</id><created>2019-06-18</created><authors><author><keyname>Dong</keyname><forenames>Fei</forenames></author><author><keyname>You</keyname><forenames>Keyou</forenames></author><author><keyname>Song</keyname><forenames>Shiji</forenames></author></authors><title>Target Encirclement with any Smooth Pattern Using Range-only
  Measurements</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a coordinate-free controller to drive a mobile robot to
encircle a target at unknown position by only using range measurements.
Different from the existing works, a backstepping based controller is proposed
to encircle the target with zero steady-state error for any desired smooth
pattern. Moreover, we show its asymptotic exponential convergence under a fixed
set of control parameters, which are independent of the initial distance to the
target. The effectiveness and advantages of the proposed controller are
validated via simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07435</identifier>
 <datestamp>2020-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07435</id><created>2019-06-18</created><updated>2019-07-30</updated><authors><author><keyname>Escribano</keyname><forenames>Francisco J.</forenames></author><author><keyname>Wagemakers</keyname><forenames>Alexandre</forenames></author></authors><title>Performance Analysis of QAM-MPPM in Turbulence-Free FSO Channels:
  Accurate Derivations and Practical Approximations</title><categories>eess.SP cs.IT math.IT</categories><comments>10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following the trends of index modulated (IM) techniques for optical
communications, in the last few years several new waveform proposals have been
made, aiming at conveying a higher density of information by driving different
signal properties. One of these proposals mixes multi-pulse pulse-position
modulation (MPPM) and quadrature amplitude modulation (QAM) in a system called
QAM-MPPM. We present here a new way to demodulate its compound waveform, and,
for the non-turbulent free space optical (FSO) channel, we provide accurate
analytical expressions for its error probabilities, both in the case of the
traditional and the new detector. Based on these analytical derivations, we
also provide simplified expressions for the estimation of the error
probabilities. We show that the new detector offers a gain of some tenths of dB
in signal-to-noise ratio with respect to the previously defined one without an
increase in complexity, and that our error probability estimations are more
accurate than previously published results. To the best of our knowledge, this
work is the first to provide simulation results validating the study of the
error probability performance of QAM-MPPM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07460</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07460</id><created>2019-06-18</created><authors><author><keyname>Sultangazin</keyname><forenames>Alimzhan</forenames></author><author><keyname>Tabuada</keyname><forenames>Paulo</forenames></author></authors><title>Symmetries and isomorphisms for privacy in control over the cloud</title><categories>math.OC cs.CR cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing platforms are being increasingly used for closing feedback
control loops, especially when computationally expensive algorithms, such as
model-predictive control, are used to optimize performance. Outsourcing of
control algorithms entails an exchange of data between the control system and
the cloud, and, naturally, raises concerns about the privacy of the control
system's data (e.g., state trajectory, control objective). Moreover, any
attempt at enforcing privacy needs to add minimal computational overhead to
avoid degrading control performance. In this paper, we propose several
transformation-based methods for enforcing data privacy. We also quantify the
amount of provided privacy and discuss how much privacy is lost when the
adversary has access to side knowledge. We address three different scenarios:
a) the cloud has no knowledge about the system being controlled; b) the cloud
knows what sensors and actuators the system employs but not the system
dynamics; c) the cloud knows the system dynamics, its sensors, and actuators.
In all of these three scenarios, the proposed methods allow for the control
over the cloud without compromising private information (which information is
considered private depends on the considered scenario).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07480</identifier>
 <datestamp>2020-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07480</id><created>2019-06-18</created><updated>2020-02-27</updated><authors><author><keyname>Grard</keyname><forenames>Matthieu</forenames><affiliation>imagine</affiliation></author><author><keyname>Dellandr&#xe9;a</keyname><forenames>Emmanuel</forenames><affiliation>imagine</affiliation></author><author><keyname>Chen</keyname><forenames>Liming</forenames><affiliation>imagine</affiliation></author></authors><title>Deep Multicameral Decoding for Localizing Unoccluded Object Instances
  from a Single RGB Image</title><categories>cs.CV cs.LG eess.IV</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Occlusion-aware instance-sensitive segmentation is a complex task generally
split into region-based segmentations, by approximating instances as their
bounding box. We address the showcase scenario of dense homogeneous layouts in
which this approximation does not hold. In this scenario, outlining unoccluded
instances by decoding a deep encoder becomes difficult, due to the translation
invariance of convolutional layers and the lack of complexity in the decoder.
We therefore propose a multicameral design composed of subtask-specific
lightweight decoder and encoder-decoder units, coupled in cascade to encourage
subtask-specific feature reuse and enforce a learning path within the decoding
process. Furthermore, the state-of-the-art datasets for occlusion-aware
instance segmentation contain real images with few instances and occlusions
mostly due to objects occluding the background, unlike dense object layouts. We
thus also introduce a synthetic dataset of dense homogeneous object layouts,
namely Mikado, which extensibly contains more instances and inter-instance
occlusions per image than these public datasets. Our extensive experiments on
Mikado and public datasets show that ordinal multiscale units within the
decoding process prove more effective than state-of-the-art design patterns for
capturing position-sensitive representations. We also show that Mikado is
plausible with respect to real-world problems, in the sense that it enables the
learning of performance-enhancing representations transferable to real images,
while drastically reducing the need of hand-made annotations for finetuning.
The proposed dataset will be made publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07493</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07493</id><created>2019-06-18</created><authors><author><keyname>Dietzen</keyname><forenames>T.</forenames></author><author><keyname>Doclo</keyname><forenames>S.</forenames></author><author><keyname>Moonen</keyname><forenames>M.</forenames></author><author><keyname>van Waterschoot</keyname><forenames>T.</forenames></author></authors><title>Square root-based multi-source early PSD estimation and recursive RETF
  update in reverberant environments by means of the orthogonal Procrustes
  problem</title><categories>eess.AS cs.SD</categories><report-no>ESAT-STADIUS Tech. Rep. TR 19-69, KU Leuven, Belgium, submitted for
  publication, June 2019</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-channel short-time Fourier transform (STFT) domain-based processing of
reverberant microphone signals commonly relies on power-spectral-density (PSD)
estimates of early source images, where early refers to reflections contained
within the same STFT frame. State-of-the-art approaches to multi-source early
PSD estimation, given an estimate of the associated relative early transfer
functions (RETFs), conventionally minimize the approximation error defined with
respect to the early correlation matrix, requiring non-negative inequality
constraints on the PSDs. Instead, we here propose to factorize the early
correlation matrix and minimize the approximation error defined with respect to
the early-correlation-matrix square root. The proposed minimization problem --
constituting a generalization of the so-called orthogonal Procrustes problem --
seeks a unitary matrix and the square roots of the early PSDs up to an
arbitrary complex argument, making non-negative inequality constraints
redundant. A solution is obtained iteratively, requiring one singular value
decomposition (SVD) per iteration. The estimated unitary matrix and early PSD
square roots further allow to recursively update the RETF estimate, which is
not inherently possible in the conventional approach. An estimate of the said
early-correlation-matrix square root itself is obtained by means of the
generalized eigenvalue decomposition (GEVD), where we further propose to
restore non-stationarities by desmoothing the generalized eigenvalues in order
to compensate for inevitable recursive averaging. Simulation results indicate
fast convergence of the proposed multi-source early PSD estimation approach in
only one iteration if initialized appropriately, and better performance as
compared to the conventional approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07496</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07496</id><created>2019-06-18</created><authors><author><keyname>Manescu</keyname><forenames>Petru</forenames></author><author><keyname>Zajiczek</keyname><forenames>Lydia Neary-</forenames></author><author><keyname>Shaw</keyname><forenames>Michael J.</forenames></author><author><keyname>Elmi</keyname><forenames>Muna</forenames></author><author><keyname>Claveau</keyname><forenames>Remy</forenames></author><author><keyname>Pawar</keyname><forenames>Vijay</forenames></author><author><keyname>Shawe-Taylor</keyname><forenames>John</forenames></author><author><keyname>Kokkinos</keyname><forenames>Iasonas</forenames></author><author><keyname>Srinivasan</keyname><forenames>Mandayam A.</forenames></author><author><keyname>Lagunju</keyname><forenames>Ikeoluwa</forenames></author><author><keyname>Sodeinde</keyname><forenames>Olugbemiro</forenames></author><author><keyname>Brown</keyname><forenames>Biobele J.</forenames></author><author><keyname>Fernandez-Reyes</keyname><forenames>Delmiro</forenames></author></authors><title>Deep Learning Enhanced Extended Depth-of-Field for Thick Blood-Film
  Malaria High-Throughput Microscopy</title><categories>eess.IV cs.CV</categories><comments>10 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast accurate diagnosis of malaria is still a global health challenge for
which automated digital-pathology approaches could provide scalable solutions
amenable to be deployed in low-to-middle income countries. Here we address the
problem of Extended Depth-of-Field (EDoF) in thick blood film microscopy for
rapid automated malaria diagnosis. High magnification oil-objectives (100x)
with large numerical aperture are usually preferred to resolve the fine
structural details that help separate true parasites from distractors. However,
such objectives have a very limited depth-of-field requiring the acquisition of
a series of images at different focal planes per field of view (FOV). Current
EDoF techniques based on multi-scale decompositions are time consuming and
therefore not suited for high-throughput analysis of specimens. To overcome
this challenge, we developed a new deep learning method based on Convolutional
Neural Networks (EDoF-CNN) that is able to rapidly perform the extended
depth-of-field while also enhancing the spatial resolution of the resulting
fused image. We evaluated our approach using simulated low-resolution z-stacks
from Giemsa-stained thick blood smears from patients presenting with Plasmodium
falciparum malaria. The EDoF-CNN allows speed-up of our digital-pathology
acquisition platform and significantly improves the quality of the EDoF
compared to the traditional multi-scaled approaches when applied to lower
resolution stacks corresponding to acquisitions with fewer focal planes, large
camera pixel binning or lower magnification objectives (larger FOV). We use the
parasite detection accuracy of a deep learning model on the EDoFs as a
concrete, task-specific measure of performance of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07499</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07499</id><created>2019-06-18</created><authors><author><keyname>Boink</keyname><forenames>Yoeri E.</forenames></author><author><keyname>Manohar</keyname><forenames>Srirang</forenames></author><author><keyname>Brune</keyname><forenames>Christoph</forenames></author></authors><title>A Partially Learned Algorithm for Joint Photoacoustic Reconstruction and
  Segmentation</title><categories>eess.IV math.OC</categories><comments>&quot;copyright 2019 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works.&quot;</comments><doi>10.1109/TMI.2019.2922026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an inhomogeneously illuminated photoacoustic image, important information
like vascular geometry is not readily available when only the initial pressure
is reconstructed. To obtain the desired information, algorithms for image
segmentation are often applied as a post-processing step. In this work, we
propose to jointly acquire the photoacoustic reconstruction and segmentation,
by modifying a recently developed partially learned algorithm based on a
convolutional neural network. We investigate the stability of the algorithm
against changes in initial pressures and photoacoustic system settings. These
insights are used to develop an algorithm that is robust to input and system
settings. Our approach can easily be applied to other imaging modalities and
can be modified to perform other high-level tasks different from segmentation.
The method is validated on challenging synthetic and experimental photoacoustic
tomography data in limited angle and limited view scenarios. It is
computationally less expensive than classical iterative methods and enables
higher quality reconstructions and segmentations than state-of-the-art learned
and non-learned methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07509</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07509</id><created>2019-06-18</created><updated>2019-08-14</updated><authors><author><keyname>Netti</keyname><forenames>Alessio</forenames></author><author><keyname>Mueller</keyname><forenames>Micha</forenames></author><author><keyname>Auweter</keyname><forenames>Axel</forenames></author><author><keyname>Guillen</keyname><forenames>Carla</forenames></author><author><keyname>Ott</keyname><forenames>Michael</forenames></author><author><keyname>Tafani</keyname><forenames>Daniele</forenames></author><author><keyname>Schulz</keyname><forenames>Martin</forenames></author></authors><title>From Facility to Application Sensor Data: Modular, Continuous and
  Holistic Monitoring with DCDB</title><categories>cs.DC cs.SY eess.SY</categories><comments>Accepted at the The International Conference for High Performance
  Computing, Networking, Storage, and Analysis (SC) 2019</comments><doi>10.1145/3295500.3356191</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's HPC installations are highly-complex systems, and their complexity
will only increase as we move to exascale and beyond. At each layer, from
facilities to systems, from runtimes to applications, a wide range of tuning
decisions must be made in order to achieve efficient operation. This, however,
requires systematic and continuous monitoring of system and user data. While
many insular solutions exist, a system for holistic and facility-wide
monitoring is still lacking in the current HPC ecosystem. In this paper we
introduce DCDB, a comprehensive monitoring system capable of integrating data
from all system levels. It is designed as a modular and highly-scalable
framework based on a plugin infrastructure. All monitored data is aggregated at
a distributed noSQL data store for analysis and cross-system correlation. We
demonstrate the performance and scalability of DCDB, and describe two use cases
in the area of energy management and characterization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07512</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07512</id><created>2019-06-18</created><authors><author><keyname>Dietzen</keyname><forenames>T.</forenames></author><author><keyname>Doclo</keyname><forenames>S.</forenames></author><author><keyname>Moonen</keyname><forenames>M.</forenames></author><author><keyname>van Waterschoot</keyname><forenames>T.</forenames></author></authors><title>Integrated sidelobe cancellation and linear prediction Kalman filter for
  joint multi-microphone speech dereverberation, interfering speech
  cancellation, and noise reduction</title><categories>eess.AS cs.SD</categories><report-no>ESAT-STADIUS Tech. Rep. TR 19-70, KU Leuven, Belgium, submitted for
  publication, June 2019</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multi-microphone speech enhancement, reverberation as well as additive
noise and/or interfering speech are commonly suppressed by deconvolution and
spatial filtering, e.g., using multi-channel linear prediction (MCLP) on the
one hand and beamforming, e.g., a generalized sidelobe canceler (GSC), on the
other hand. In this paper, we consider several reverberant speech components,
whereof some are to be dereverberated and others to be canceled, as well as a
diffuse (e.g., babble) noise component to be suppressed. In order to perform
both deconvolution and spatial filtering, we integrate MCLP and the GSC into a
novel architecture referred to as integrated sidelobe cancellation and linear
prediction (ISCLP), where the sidelobe-cancellation (SC) filter and the linear
prediction (LP) filter operate in parallel, but on different microphone signal
frames. Within ISCLP, we estimate both filters jointly by means of a single
Kalman filter. We further propose a spectral Wiener gain post-processor, which
is shown to relate to the Kalman filter's posterior state estimate. The
presented ISCLP Kalman filter is benchmarked against two state-of-the-art
approaches, namely first a pair of alternating Kalman filters respectively
performing dereverberation and noise reduction, and second an MCLP+GSC Kalman
filter cascade. While the ISCLP Kalman filter is roughly $M^2$ times less
expensive than both reference algorithms, where $M$ denotes the number of
microphones, it is shown to perform similarly as compared to the former, and to
outperform the latter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07523</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07523</id><created>2019-06-18</created><updated>2019-06-28</updated><authors><author><keyname>Y&#x131;lmaz</keyname><forenames>Emre</forenames></author><author><keyname>Cohen</keyname><forenames>Samuel</forenames></author><author><keyname>Yue</keyname><forenames>Xianghu</forenames></author><author><keyname>van Leeuwen</keyname><forenames>David</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author></authors><title>Multi-Graph Decoding for Code-Switching ASR</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted for publication at Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the FAME! Project, a code-switching (CS) automatic speech recognition
(ASR) system for Frisian-Dutch speech is developed that can accurately
transcribe the local broadcaster's bilingual archives with CS speech. This
archive contains recordings with monolingual Frisian and Dutch speech segments
as well as Frisian-Dutch CS speech, hence the recognition performance on
monolingual segments is also vital for accurate transcriptions. In this work,
we propose a multi-graph decoding and rescoring strategy using bilingual and
monolingual graphs together with a unified acoustic model for CS ASR. The
proposed decoding scheme gives the freedom to design and employ alternative
search spaces for each (monolingual or bilingual) recognition task and enables
the effective use of monolingual resources of the high-resourced mixed language
in low-resourced CS scenarios. In our scenario, Dutch is the high-resourced and
Frisian is the low-resourced language. We therefore use additional monolingual
Dutch text resources to improve the Dutch language model (LM) and compare the
performance of single- and multi-graph CS ASR systems on Dutch segments using
larger Dutch LMs. The ASR results show that the proposed approach outperforms
baseline single-graph CS ASR systems, providing better performance on the
monolingual Dutch segments without any accuracy loss on monolingual Frisian and
code-mixed segments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07545</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07545</id><created>2019-06-16</created><authors><author><keyname>Phillips</keyname><forenames>Caleb</forenames></author><author><keyname>Liaqat</keyname><forenames>Daniyal</forenames></author><author><keyname>Gabel</keyname><forenames>Moshe</forenames></author><author><keyname>de Lara</keyname><forenames>Eyal</forenames></author></authors><title>Wrist02 -- Reliable Peripheral Oxygen Saturation Readings from
  Wrist-Worn Pulse Oximeters</title><categories>cs.CY eess.SP</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peripheral blood oxygen saturation Sp02 is a vital measure in healthcare.
Modern off-the-shelf wrist-worn devices, such as the Apple Watch, FitBit, and
Samsung Gear, have an onboard sensor called a pulse oximeter. While pulse
oximeters are capable of measuring both Sp02 and heart rate, current wrist-worn
devices use them only to determine heart rate, as Sp02 measurements collected
from the wrist are believed to be inaccurate. Enabling oxygen saturation
monitoring on wearable devices would make these devices tremendously more
useful for health monitoring and open up new avenues of research. To the best
of our knowledge, we present the first study of the reliability of Sp02 sensing
from the wrist. Using a custom-built wrist-worn pulse oximeter, we find that
existing algorithms designed for fingertip sensing are a poor match for this
setting, and can lead to over 90% of readings being inaccurate and unusable. We
further show that sensor placement and skin tone have a substantial effect on
the measurement error, and must be considered when designing wrist-worn Sp02
sensors and measurement algorithms. Based on our findings, we propose
\codename, an alternative approach for reliable Sp02 sensing. By selectively
pruning data, \codename achieves an order of magnitude reduction in error
compared to existing algorithms, while still providing sufficiently frequent
readings for continuous health monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07547</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07547</id><created>2019-06-12</created><authors><author><keyname>Islam</keyname><forenames>Md Atiqul</forenames></author><author><keyname>Smida</keyname><forenames>Besma</forenames></author></authors><title>A Comprehensive Self-interference Model for Single-antenna Full-duplex
  Communication Systems</title><categories>eess.SP</categories><comments>7 pages, 3 figures. To appear in the Proceedings of the IEEE
  International Conference on Communications (ICC), 20-24 May 2019, Shanghai,
  China</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Single-antenna full-duplex communication technology has the potential to
substantially increase spectral efficiency. However, limited propagation domain
cancellation of single-antenna system results in a higher impact of receiver
chain nonlinearities on the residual self-interference (SI) signal. In this
paper, we offer a comprehensive SI model for single-antenna full-duplex systems
based on direct-conversion transceiver structure considering nonlinearities of
all the transceiver radio frequency (RF) components, in-phase/quadrature (IQ)
imbalances, phase noise effect, and receiver noise figure. To validate our
model, we also propose a more appropriate digital SI cancellation approach
considering receiver chain RF and baseband nonlinearities. The proposed
technique employs orthogonalization of the design matrix using QR decomposition
to alleviate the estimation and cancellation error. Finally, through
circuit-level waveform simulation, the performance of the digital cancellation
strategy is investigated, which achieves 20 dB more cancellation compared to
existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07549</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07549</id><created>2019-06-17</created><authors><author><keyname>Zhong</keyname><forenames>Zhusi</forenames></author><author><keyname>Li</keyname><forenames>Jie</forenames></author><author><keyname>Zhang</keyname><forenames>Zhenxi</forenames></author><author><keyname>Jiao</keyname><forenames>Zhicheng</forenames></author><author><keyname>Gao</keyname><forenames>Xinbo</forenames></author></authors><title>An Attention-Guided Deep Regression Model for Landmark Detection in
  Cephalograms</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cephalometric tracing method is usually used in orthodontic diagnosis and
treat-ment planning. In this paper, we propose a deep learning based framework
to au-tomatically detect anatomical landmarks in cephalometric X-ray images. We
train the deep encoder-decoder for landmark detection, and combine global
landmark configuration with local high-resolution feature responses. The
proposed frame-work is based on 2-stage u-net, regressing the multi-channel
heatmaps for land-mark detection. In this framework, we embed attention
mechanism with global stage heatmaps, guiding the local stage inferring, to
regress the local heatmap patches in a high resolution. Besides, the Expansive
Exploration strategy im-proves robustness while inferring, expanding the
searching scope without in-creasing model complexity. We have evaluated our
framework in the most wide-ly-used public dataset of landmark detection in
cephalometric X-ray images. With less computation and manually tuning, our
framework achieves state-of-the-art results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07550</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07550</id><created>2019-06-14</created><updated>2019-10-17</updated><authors><author><keyname>Mahdizadeh</keyname><forenames>Amin</forenames></author><author><keyname>Schmid</keyname><forenames>Robert</forenames></author><author><keyname>Oetomo</keyname><forenames>Denny</forenames></author></authors><title>LIDAR-Assisted Exact Output Regulation for Load Mitigation in Wind
  Turbines</title><categories>eess.SY cs.SY</categories><comments>32 pages, provisionally accepted for IEEE Transactions on Control
  Systems Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimising wind turbine performance involves maximising energy harvesting
while seeking to minimise load fatigues on the tower structure, blades and
rotor. To improve turbine control performance, wind preview measurement
technologies such as Light Detection And Ranging (LIDAR) have been a point of
interest for researchers in recent years. In this paper, we explore the
application of a classical control methodology known as Exact Output Regulation
(EOR) for improving the control performance of a LIDAR-enhanced wind turbine.
The EOR controller is designed to achieve the rejection of known input
disturbances, while also ensuring the system output tracks a desired reference
signal. The controller is comprised of a state feedback controller together
with a feedforward gain. The LIDAR wind preview information is used to obtain a
low-order exosystem for modeling wind dynamics. This wind exosystem is used to
obtain the feedforward gain matrix that enables the EOR controller to
effectively reject the input disturbance and achieve the desired reference
tracking. Extensive simulations of the EOR controller with a broad range of
wind speeds in both partial load and full load operating regions are performed
on the full nonlinear aero-elastic model of the National Renewable Energy
Laboratory (NREL) 5 MW reference wind turbine. For performance comparisons, we
also implement a baseline torque controller and a commonly used feedforward
control method known as Disturbance Accommodation Control (DAC). The results
show that, in comparison with a baseline and DAC controller, the EOR controller
can provide substantially improved reduction of fatigue loads and smoother
power output, without compromising energy production levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07552</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07552</id><created>2019-06-14</created><authors><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Wang</keyname><forenames>Wenwu</forenames></author><author><keyname>Jackson</keyname><forenames>Philip J. B.</forenames></author><author><keyname>Plumbley</keyname><forenames>Mark D.</forenames></author></authors><title>Single-Channel Signal Separation and Deconvolution with Generative
  Adversarial Networks</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>7 pages. Accepted by IJCAI 2019</comments><journal-ref>International Joint Conference on Artificial Intelligence (IJCAI),
  2019, pp. 2747-2753</journal-ref><doi>10.24963/ijcai.2019/381</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-channel signal separation and deconvolution aims to separate and
deconvolve individual sources from a single-channel mixture and is a
challenging problem in which no prior knowledge of the mixing filters is
available. Both individual sources and mixing filters need to be estimated. In
addition, a mixture may contain non-stationary noise which is unseen in the
training set. We propose a synthesizing-decomposition (S-D) approach to solve
the single-channel separation and deconvolution problem. In synthesizing, a
generative model for sources is built using a generative adversarial network
(GAN). In decomposition, both mixing filters and sources are optimized to
minimize the reconstruction error of the mixture. The proposed S-D approach
achieves a peak-to-noise-ratio (PSNR) of 18.9 dB and 15.4 dB in image
inpainting and completion, outperforming a baseline convolutional neural
network PSNR of 15.3 dB and 12.2 dB, respectively and achieves a PSNR of 13.2
dB in source separation together with deconvolution, outperforming a
convolutive non-negative matrix factorization (NMF) baseline of 10.1 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07563</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07563</id><created>2019-06-15</created><authors><author><keyname>Hou</keyname><forenames>Weizhen</forenames></author><author><keyname>Mao</keyname><forenames>Yilan</forenames></author><author><keyname>Xu</keyname><forenames>Chi</forenames></author><author><keyname>Li</keyname><forenames>Zhengqiang</forenames></author><author><keyname>Li</keyname><forenames>Donghui</forenames></author><author><keyname>Ma</keyname><forenames>Yan</forenames></author><author><keyname>Xu</keyname><forenames>Hua</forenames></author></authors><title>Study on the spectral reconstruction of typical surface types based on
  spectral library and principal component analysis</title><categories>eess.IV</categories><comments>10 pages, 7 figures</comments><journal-ref>Proceedings of SPIE, 2019</journal-ref><doi>10.1117/12.2521743</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To meet the demanding of spectral reconstruction in the visible and
near-infrared wavelength, the spectral reconstruction method for typical
surface types is discussed based on the USGS /ASTER spectral library and
principal component analysis (PCA). A new spectral reconstructed model is
proposed by the information of several typical bands instead of all of the
wavelength bands, and a linear combination spectral reconstruction model is
also discussed. By selecting 4 typical spectral datasets including green
vegetation, bare soil, rangeland and concrete in the spectral range of 400-900
nm, the PCA results show that 6 principal components could characterized the
spectral dataset, and the relative reconstructed errors are smaller than 2%. If
only 6-7 selected typical bands are employed to spectral reconstruction for all
the surface reflectance in 400-900 nm, except that the reconstructed error of
green vegetation is about 3.3%, the relative errors of other 3 datasets are all
smaller than 1.6%. The correlation coefficients of those 4 datasets are all
larger than 0.99, which can effectively satisfy the needs of spectral
reconstruction. In addition, based on the spectral library and the linear
combination model of 4 common used bands of satellite remote sensing such as
490, 555, 670 and 865 nm, the reconstructed errors are smaller than 8.5% in
high reflectance region and smaller than 1.5% in low reflectance region
respectively, which basically meet the needs of spectral reconstruction. This
study can provide a reference value for the surface reflectance processing and
spectral reconstruction in satellite remote sensing research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07569</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07569</id><created>2019-06-14</created><updated>2019-09-02</updated><authors><author><keyname>Winter</keyname><forenames>Hanno</forenames></author><author><keyname>Willert</keyname><forenames>Volker</forenames></author><author><keyname>Adamy</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Train-borne Localization Exploiting Track-Geometry Constraints -- A
  Practical Evaluation</title><categories>eess.SP</categories><doi>10.25534/tuprints-00011296</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's railway signalling system heavily relies on trackside infrastructure
such as axle counters and track balises. This system has proven itself to be
reliable, however, it is not very efficient and, moreover, very costly. Thus,
it is not suited to overcome the future challenges in railway transportation.
For this reason, signalling systems based on train-borne sensors have gained
interest recently. In this context, train-borne localization is one of the main
research challenges. So far there is no sensor set-up which meets the demanding
requirements for a localization system, both in the sense of accuracy as well
as safety. To help overcome these issues in the near future we present our
latest research results here. Earlier we published a localization algorithm
which is characterized by an increased accuracy in cross-track direction
compared to a standard Kalman filter (KF) approach, as has been shown in
simulations [1]. To verify these results practically, we recorded data from a
Global Navigation Satellite System (GNSS) and an inertial measurement unit
(IMU) on a test drive. The localization accuracy is evaluated with the help of
OpenStreetMap (OSM) data and site plans. Furthermore, we evaluate the quality
of the estimated geometric track-map, which is additionally provided in the
process of the localization algorithm [2]. We conclude with some remarks on the
research challenges towards train-borne localization and suggest further steps
to overcome them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07571</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07571</id><created>2019-06-14</created><authors><author><keyname>Waqar</keyname><forenames>Ahsan</forenames></author><author><keyname>Hussain</keyname><forenames>Babar</forenames></author><author><keyname>Ahmad</keyname><forenames>Salman</forenames></author><author><keyname>Yahya</keyname><forenames>Talha</forenames></author><author><keyname>Sarwar</keyname><forenames>Muhammad</forenames></author></authors><title>A Communication-less Protection Strategy to Ensure Protection
  Coordination of Distribution Networks with Embedded DG</title><categories>eess.SP</categories><comments>6 pages, 11 figures, 12 tables, published in a conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed Generation (DG) has emerged as best alternative to conventional
energy sources in recent times. Decentralization of power generation,
improvement in voltage profile and reduction of system losses are some of key
benefits of DG integration into the grid. However, introduction of DG changes
the radial nature of a distribution network (DN) and may affect both magnitude
and direction of fault currents. This phenomenon may have severe repercussions
for the reliability and safety of a DN including protection coordination
failure. This paper investigates the impact of DG on protection coordination of
a typical DN and proposes a scheme to restore the protection coordination in
presence of DG. Moreover, impact of different DG sizes and locations on DN's
voltage profile and losses has also been analyzed. The sample DN with embedded
DG is modelled in ETAP environment and the simulation results presented show
the effectiveness of the proposed protection strategy in restoring relay
coordination of the network in both isolated and DG connected modes of
operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07582</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07582</id><created>2019-06-18</created><updated>2019-06-20</updated><authors><author><keyname>Ullrich</keyname><forenames>Karen</forenames></author><author><keyname>Berg</keyname><forenames>Rianne van den</forenames></author><author><keyname>Brubaker</keyname><forenames>Marcus</forenames></author><author><keyname>Fleet</keyname><forenames>David</forenames></author><author><keyname>Welling</keyname><forenames>Max</forenames></author></authors><title>Differentiable probabilistic models of scientific imaging with the
  Fourier slice theorem</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>accepted to UAI 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Scientific imaging techniques such as optical and electron microscopy and
computed tomography (CT) scanning are used to study the 3D structure of an
object through 2D observations. These observations are related to the original
3D object through orthogonal integral projections. For common 3D reconstruction
algorithms, computational efficiency requires the modeling of the 3D structures
to take place in Fourier space by applying the Fourier slice theorem. At
present, it is unclear how to differentiate through the projection operator,
and hence current learning algorithms can not rely on gradient based methods to
optimize 3D structure models. In this paper we show how back-propagation
through the projection operator in Fourier space can be achieved. We
demonstrate the validity of the approach with experiments on 3D reconstruction
of proteins. We further extend our approach to learning probabilistic models of
3D objects. This allows us to predict regions of low sampling rates or estimate
noise. A higher sample efficiency can be reached by utilizing the learned
uncertainties of the 3D structure as an unsupervised estimate of the model fit.
Finally, we demonstrate how the reconstruction algorithm can be extended with
an amortized inference scheme on unknown attributes such as object pose.
Through empirical studies we show that joint inference of the 3D structure and
the object pose becomes more difficult when the ground truth object contains
more symmetries. Due to the presence of for instance (approximate) rotational
symmetries, the pose estimation can easily get stuck in local optima,
inhibiting a fine-grained high-quality estimate of the 3D structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07601</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07601</id><created>2019-06-18</created><authors><author><keyname>Caubri&#xe8;re</keyname><forenames>Antoine</forenames></author><author><keyname>Tomashenko</keyname><forenames>Natalia</forenames></author><author><keyname>Laurent</keyname><forenames>Antoine</forenames></author><author><keyname>Morin</keyname><forenames>Emmanuel</forenames></author><author><keyname>Camelin</keyname><forenames>Nathalie</forenames></author><author><keyname>Est&#xe8;ve</keyname><forenames>Yannick</forenames></author></authors><title>Curriculum-based transfer learning for an effective end-to-end spoken
  language understanding and domain portability</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted to the INTERSPEECH 2019 conference. Submitted on March 29,
  2019 (Paper submission deadline)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an end-to-end approach to extract semantic concepts directly from
the speech audio signal. To overcome the lack of data available for this spoken
language understanding approach, we investigate the use of a transfer learning
strategy based on the principles of curriculum learning. This approach allows
us to exploit out-of-domain data that can help to prepare a fully neural
architecture. Experiments are carried out on the French MEDIA and PORTMEDIA
corpora and show that this end-to-end SLU approach reaches the best results
ever published on this task. We compare our approach to a classical pipeline
approach that uses ASR, POS tagging, lemmatizer, chunker... and other NLP tools
that aim to enrich ASR outputs that feed an SLU text to concepts system. Last,
we explore the promising capacity of our end-to-end SLU approach to address the
problem of domain portability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07644</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07644</id><created>2019-06-18</created><updated>2019-08-22</updated><authors><author><keyname>Biedenkapp</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Bozkurt</keyname><forenames>H. Furkan</forenames></author><author><keyname>Hutter</keyname><forenames>Frank</forenames></author><author><keyname>Lindauer</keyname><forenames>Marius</forenames></author></authors><title>Towards White-box Benchmarks for Algorithm Control</title><categories>cs.LG cs.AI cs.SY eess.SY stat.ML</categories><comments>8 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of many algorithms in the fields of hard combinatorial
problem solving, machine learning or AI in general depends on tuned
hyperparameter configurations. Automated methods have been proposed to
alleviate users from the tedious and error-prone task of manually searching for
performance-optimized configurations across a set of problem instances. However
there is still a lot of untapped potential through adjusting an algorithm's
hyperparameters online since different hyperparameters are potentially optimal
at different stages of the algorithm. We formulate the problem of adjusting an
algorithm's hyperparameters for a given instance on the fly as a contextual
MDP, making reinforcement learning (RL) the prime candidate to solve the
resulting algorithm control problem in a data-driven way. Furthermore, inspired
by applications of algorithm configuration, we introduce new white-box
benchmarks suitable to study algorithm control. We show that on short
sequences, algorithm configuration is a valid choice, but that with increasing
sequence length a black-box view on the problem quickly becomes infeasible and
RL performs better.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07679</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07679</id><created>2019-06-18</created><updated>2019-07-24</updated><authors><author><keyname>Asgari</keyname><forenames>Rhona</forenames></author><author><keyname>Orlando</keyname><forenames>Jos&#xe9; Ignacio</forenames></author><author><keyname>Waldstein</keyname><forenames>Sebastian</forenames></author><author><keyname>Schlanitz</keyname><forenames>Ferdinand</forenames></author><author><keyname>Baratsits</keyname><forenames>Magdalena</forenames></author><author><keyname>Schmidt-Erfurth</keyname><forenames>Ursula</forenames></author><author><keyname>Bogunovi&#x107;</keyname><forenames>Hrvoje</forenames></author></authors><title>Multiclass segmentation as multitask learning for drusen segmentation in
  retinal optical coherence tomography</title><categories>eess.IV cs.CV</categories><comments>Accepted for publication in MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated drusen segmentation in retinal optical coherence tomography (OCT)
scans is relevant for understanding age-related macular degeneration (AMD) risk
and progression. This task is usually performed by segmenting the top/bottom
anatomical interfaces that define drusen, the outer boundary of the retinal
pigment epithelium (OBRPE) and the Bruch's membrane (BM), respectively. In this
paper we propose a novel multi-decoder architecture that tackles drusen
segmentation as a multitask problem. Instead of training a multiclass model for
OBRPE/BM segmentation, we use one decoder per target class and an extra one
aiming for the area between the layers. We also introduce connections between
each class-specific branch and the additional decoder to increase the
regularization effect of this surrogate task. We validated our approach on
private/public data sets with 166 early/intermediate AMD Spectralis, and 200
AMD and control Bioptigen OCT volumes, respectively. Our method consistently
outperformed several baselines in both layer and drusen segmentation
evaluations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07719</identifier>
 <datestamp>2019-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07719</id><created>2019-06-19</created><updated>2019-10-30</updated><authors><author><keyname>Mashayekhi</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Harati</keyname><forenames>Mojtaba</forenames></author><author><keyname>Estekanchi</keyname><forenames>Homayoon E.</forenames></author></authors><title>On the optimal parameters of a PSO-based algorithm for simulation of
  Endurance Time Excitation Functions</title><categories>eess.SP</categories><comments>It is fully published in the journal of Engineering Reports (Oct
  issue, 2019)</comments><journal-ref>Engineering Reports (2019)</journal-ref><doi>10.1002/eng2.12048</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a particle swarm optimizer for production of endurance
time excitation functions. These excitations are intensifying acceleration time
histories that are used as input motions in endurance time method. The accuracy
of the endurance time methods heavily depends on the accuracy of endurance time
excitations. Unconstrained nonlinear optimization is employed to simulate these
excitations. Particle swarm optimization method as an evolutionary algorithm is
examined in this paper to achieve a more accurate endurance time excitation
function, where optimal parameters of the particle swarm optimization are first
determined using a parametric study on the involved variables. The proposed
method is verified and compared with the trust-region reflective method as a
classical optimization method and imperialist competitive algorithm as a
recently developed evolutionary method. Results show that the proposed method
leads to more accurate endurance time excitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07769</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07769</id><created>2019-06-18</created><updated>2019-09-13</updated><authors><author><keyname>Zhen</keyname><forenames>Kai</forenames></author><author><keyname>Sung</keyname><forenames>Jongmo</forenames></author><author><keyname>Lee</keyname><forenames>Mi Suk</forenames></author><author><keyname>Beack</keyname><forenames>Seungkwon</forenames></author><author><keyname>Kim</keyname><forenames>Minje</forenames></author></authors><title>Cascaded Cross-Module Residual Learning towards Lightweight End-to-End
  Speech Coding</title><categories>eess.AS cs.LG cs.SD</categories><comments>Accepted for publication in INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech codecs learn compact representations of speech signals to facilitate
data transmission. Many recent deep neural network (DNN) based end-to-end
speech codecs achieve low bitrates and high perceptual quality at the cost of
model complexity. We propose a cross-module residual learning (CMRL) pipeline
as a module carrier with each module reconstructing the residual from its
preceding modules. CMRL differs from other DNN-based speech codecs, in that
rather than modeling speech compression problem in a single large neural
network, it optimizes a series of less-complicated modules in a two-phase
training scheme. The proposed method shows better objective performance than
AMR-WB and the state-of-the-art DNN-based speech codec with a similar network
architecture. As an end-to-end model, it takes raw PCM signals as an input, but
is also compatible with linear predictive coding (LPC), showing better
subjective quality at high bitrates than AMR-WB and OPUS. The gain is achieved
by using only 0.9 million trainable parameters, a significantly less complex
architecture than the other DNN-based codecs in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07802</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07802</id><created>2019-06-18</created><updated>2019-07-23</updated><authors><author><keyname>Izadi</keyname><forenames>Saeed</forenames></author><author><keyname>Sutton</keyname><forenames>Darren</forenames></author><author><keyname>Hamarneh</keyname><forenames>Ghassan</forenames></author></authors><title>Image Super Resolution via Bilinear Pooling: Application to Confocal
  Endomicroscopy</title><categories>eess.IV cs.CV</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent developments in image acquisition literature have miniaturized the
confocal laser endomicroscopes to improve usability and flexibility of the
apparatus in actual clinical settings. However, miniaturized devices collect
less light and have fewer optical components, resulting in pixelation artifacts
and low resolution images. Owing to the strength of deep networks, many
supervised methods known as super resolution have achieved considerable success
in restoring low resolution images by generating the missing high frequency
details. In this work, we propose a novel attention mechanism that, for the
first time, combines 1st- and 2nd-order statistics for pooling operation, in
the spatial and channel-wise dimensions. We compare the efficacy of our method
to 11 other existing single image super resolution techniques that compensate
for the reduction in image quality caused by the necessity of endomicroscope
miniaturization. All evaluations are carried out on three publicly available
datasets. Experimental results show that our method can produce competitive
results against state-of-the-art in terms of PSNR, SSIM, and IFC metrics.
Additionally, our proposed method contains small number of parameters, which
makes it lightweight and fast for real-time applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07839</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07839</id><created>2019-06-18</created><authors><author><keyname>Ryant</keyname><forenames>Neville</forenames></author><author><keyname>Church</keyname><forenames>Kenneth</forenames></author><author><keyname>Cieri</keyname><forenames>Christopher</forenames></author><author><keyname>Cristia</keyname><forenames>Alejandrina</forenames></author><author><keyname>Du</keyname><forenames>Jun</forenames></author><author><keyname>Ganapathy</keyname><forenames>Sriram</forenames></author><author><keyname>Liberman</keyname><forenames>Mark</forenames></author></authors><title>The Second DIHARD Diarization Challenge: Dataset, task, and baselines</title><categories>eess.AS cs.CL</categories><comments>Accepted by Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the second DIHARD challenge, the second in a series of
speaker diarization challenges intended to improve the robustness of
diarization systems to variation in recording equipment, noise conditions, and
conversational domain. The challenge comprises four tracks evaluating
diarization performance under two input conditions (single channel vs.
multi-channel) and two segmentation conditions (diarization from a reference
speech segmentation vs. diarization from scratch). In order to prevent
participants from overtuning to a particular combination of recording
conditions and conversational domain, recordings are drawn from a variety of
sources ranging from read audiobooks to meeting speech, to child language
acquisition recordings, to dinner parties, to web video. We describe the task
and metrics, challenge design, datasets, and baseline systems for speech
enhancement, speech activity detection, and diarization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07849</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07849</id><created>2019-06-18</created><authors><author><keyname>Arvinte</keyname><forenames>Marius</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author><author><keyname>Tewfik</keyname><forenames>Ahmed H.</forenames></author></authors><title>Deep Learning-Based Quantization of L-Values for Gray-Coded Modulation</title><categories>cs.LG eess.SP stat.ML</categories><comments>Submitted to IEEE Globecom 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a deep learning-based quantization scheme for log-likelihood
ratio (L-value) storage is introduced. We analyze the dependency between the
average magnitude of different L-values from the same quadrature amplitude
modulation (QAM) symbol and show they follow a consistent ordering. Based on
this we design a deep autoencoder that jointly compresses and separately
reconstructs each L-value, allowing the use of a weighted loss function that
aims to more accurately reconstructs low magnitude inputs. Our method is shown
to be competitive with state-of-the-art maximum mutual information quantization
schemes, reducing the required memory footprint by a ratio of up to two and a
loss of performance smaller than 0.1 dB with less than two effective bits per
L-value or smaller than 0.04 dB with 2.25 effective bits. We experimentally
show that our proposed method is a universal compression scheme in the sense
that after training on an LDPC-coded Rayleigh fading scenario we can reuse the
same network without further training on other channel models and codes while
preserving the same performance benefits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07851</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07851</id><created>2019-06-18</created><updated>2019-07-26</updated><authors><author><keyname>Cho</keyname><forenames>Donghyeon</forenames></author><author><keyname>Hong</keyname><forenames>Sungeun</forenames></author><author><keyname>Kang</keyname><forenames>Sungil</forenames></author><author><keyname>Kim</keyname><forenames>Jiwon</forenames></author></authors><title>Key Instance Selection for Unsupervised Video Object Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><comments>Ranked 3rd in 'Unsupervised DAVIS Challenge' (CVPR 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes key instance selection based on video saliency covering
objectness and dynamics for unsupervised video object segmentation (UVOS). Our
method takes frames sequentially and extracts object proposals with
corresponding masks for each frame. We link objects according to their
similarity until the M-th frame and then assign them unique IDs (i.e.,
instances). Similarity measure takes into account multiple properties such as
ReID descriptor, expected trajectory, and semantic co-segmentation result.
After M-th frame, we select K IDs based on video saliency and frequency of
appearance; then only these key IDs are tracked through the remaining frames.
Thanks to these technical contributions, our results are ranked third on the
leaderboard of UVOS DAVIS challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07860</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07860</id><created>2019-06-18</created><authors><author><keyname>Lei</keyname><forenames>Lei</forenames></author><author><keyname>Xu</keyname><forenames>Huijuan</forenames></author><author><keyname>Xiong</keyname><forenames>Xiong</forenames></author><author><keyname>Zheng</keyname><forenames>Kan</forenames></author><author><keyname>Xiang</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Xianbin</forenames></author></authors><title>Multi-user Resource Control with Deep Reinforcement Learning in IoT Edge
  Computing</title><categories>eess.SP cs.LG cs.NI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By leveraging the concept of mobile edge computing (MEC), massive amount of
data generated by a large number of Internet of Things (IoT) devices could be
offloaded to MEC server at the edge of wireless network for further
computational intensive processing. However, due to the resource constraint of
IoT devices and wireless network, both the communications and computation
resources need to be allocated and scheduled efficiently for better system
performance. In this paper, we propose a joint computation offloading and
multi-user scheduling algorithm for IoT edge computing system to minimize the
long-term average weighted sum of delay and power consumption under stochastic
traffic arrival. We formulate the dynamic optimization problem as an
infinite-horizon average-reward continuous-time Markov decision process (CTMDP)
model. One critical challenge in solving this MDP problem for the multi-user
resource control is the curse-of-dimensionality problem, where the state space
of the MDP model and the computation complexity increase exponentially with the
growing number of users or IoT devices. In order to overcome this challenge, we
use the deep reinforcement learning (RL) techniques and propose a neural
network architecture to approximate the value functions for the post-decision
system states. The designed algorithm to solve the CTMDP problem supports
semi-distributed auction-based implementation, where the IoT devices submit
bids to the BS to make the resource control decisions centrally. Simulation
results show that the proposed algorithm provides significant performance
improvement over the baseline algorithms, and also outperforms the RL
algorithms based on other neural network architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07861</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07861</id><created>2019-06-18</created><updated>2019-06-27</updated><authors><author><keyname>Wan</keyname><forenames>Dan</forenames></author><author><keyname>Zhan</keyname><forenames>Hao</forenames></author></authors><title>Controllable Planning, Responsibility, and Information in Automatic
  Driving Technology</title><categories>cs.CY cs.SY eess.SY</categories><comments>The 7th International Symposium on Project Management (ISPM2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  People hope automated driving technology should be always in a stable and
controllable state, accurately, which can be divided into controllable
planning, responsibility, and information. Otherwise, it would bring about the
problems of tram dilemma, responsibility attribution, information leakage, and
security. This article discusses these three types of issues separately and
clarifies some misunderstandings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07862</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07862</id><created>2019-06-18</created><authors><author><keyname>Yu</keyname><forenames>Yanan</forenames></author><author><keyname>Guan</keyname><forenames>Yongpei</forenames></author><author><keyname>Chen</keyname><forenames>Yonghong</forenames></author></authors><title>An Integral Formulation and Convex Hull Pricing for Unit Commitment</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reducing uplift payments has been a challenging problem for most wholesale
markets in US. The main difficulty comes from the unit commitment discrete
decision makings. Recently convex hull pricing has shown promises to reduce the
uplift payments. However, it has been intractable to obtain the optimal convex
hull price. In this paper, we describe an innovative approach to decide the
optimal convex hull price by simply solving a linear program. We also provide
an example to illustrate the calculation process. The final computational
experiments on a revised IEEE-118 bus system verify the cost effectiveness by
utilizing our proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07887</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07887</id><created>2019-06-18</created><authors><author><keyname>Tatwawadi</keyname><forenames>Kedar</forenames></author><author><keyname>Chandak</keyname><forenames>Shubham</forenames></author></authors><title>Tutorial on algebraic deletion correction codes</title><categories>cs.DS cs.IT eess.SP math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The deletion channel is known to be a notoriously diffcult channel to design
error-correction codes for. In spite of this difficulty, there are some
beautiful code constructions which give some intuition about the channel and
about what good deletion codes look like. In this tutorial we will take a look
at some of them. This document is a transcript of my talk at the coding theory
reading group on some interesting works on deletion channel. It is not intended
to be an exhaustive survey of works on deletion channel, but more as a tutorial
to some of the important and cute ideas in this area. For a comprehensive
survey, we refer the reader to the cited sources and surveys.
  We also provide an implementation of VT codes that correct single
insertion/deletion errors for general alphabets at
https://github.com/shubhamchandak94/VT_codes/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07899</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07899</id><created>2019-06-18</created><authors><author><keyname>Rutkowski</keyname><forenames>Tomasz M.</forenames></author><author><keyname>Koculak</keyname><forenames>Marcin</forenames></author><author><keyname>Abe</keyname><forenames>Masato S.</forenames></author><author><keyname>Otake-Matsuura</keyname><forenames>Mihoko</forenames></author></authors><title>Brain correlates of task-load and dementia elucidation with tensor
  machine learning using oddball BCI paradigm</title><categories>q-bio.NC cs.LG eess.SP</categories><comments>In ICASSP 2019 - 2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), pp. 8578-8582, May 2019</comments><doi>10.1109/ICASSP.2019.8682387</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Dementia in the elderly has recently become the most usual cause of cognitive
decline. The proliferation of dementia cases in aging societies creates a
remarkable economic as well as medical problems in many communities worldwide.
A recently published report by The World Health Organization (WHO) estimates
that about 47 million people are suffering from dementia-related neurocognitive
declines worldwide. The number of dementia cases is predicted by 2050 to
triple, which requires the creation of an AI-based technology application to
support interventions with early screening for subsequent mental wellbeing
checking as well as preservation with digital-pharma (the so-called beyond a
pill) therapeutical approaches. We present an attempt and exploratory results
of brain signal (EEG) classification to establish digital biomarkers for
dementia stage elucidation. We discuss a comparison of various machine learning
approaches for automatic event-related potentials (ERPs) classification of a
high and low task-load sound stimulus recognition. These ERPs are similar to
those in dementia. The proposed winning method using tensor-based machine
learning in a deep fully connected neural network setting is a step forward to
develop AI-based approaches for a subsequent application for subjective- and
mild-cognitive impairment (SCI and MCI) diagnostics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07921</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07921</id><created>2019-06-19</created><authors><author><keyname>Akerman</keyname><forenames>Sefi</forenames></author><author><keyname>Habler</keyname><forenames>Edan</forenames></author><author><keyname>Shabtai</keyname><forenames>Asaf</forenames></author></authors><title>VizADS-B: Analyzing Sequences of ADS-B Images Using Explainable
  Convolutional LSTM Encoder-Decoder to Detect Cyber Attacks</title><categories>cs.CR eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of the automatic dependent surveillance broadcast (ADS-B)
technology is to serve as a replacement for the current radar-based, air
traffic control systems. Despite the considerable time and resources devoted to
designing and developing the system, the ADS-B is well known for its lack of
security mechanisms. Attempts to address these security vulnerabilities have
been made in previous studies by modifying the protocol's current architecture
or by using additional hardware components. These solutions, however, are
considered impractical because of 1) the complex regulatory process involving
avionic systems, 2) the high costs of using hardware components, and 3) the
fact that the ADS-B system itself is already deployed in most aircraft and
ground stations around the world. In this paper, we propose VizADS-B, an
alternative software-based security solution for detecting anomalous ADS-B
messages, which does not require any alteration of the current ADS-B
architecture or the addition of sensors. According to the proposed method, the
information obtained from all aircraft within a specific geographical area is
aggregated and represented as a stream of images. Then, a convolutional LSTM
encoder-decoder model is used for analyzing and detecting anomalies in the
sequences of images. In addition, we propose an explainability technique,
designed specifically for convolutional LSTM encoder-decoder models, which is
used for providing operative information to the pilot as a visual indicator of
a detected anomaly, thus allowing the pilot to make relevant decisions. We
evaluated our proposed method on five datasets by injecting and subsequently
identifying five different attacks. Our experiments demonstrate that most of
the attacks can be detected based on spatio-temporal anomaly detection
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07927</identifier>
 <datestamp>2019-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07927</id><created>2019-06-19</created><updated>2019-12-04</updated><authors><author><keyname>Qiu</keyname><forenames>Haonan</forenames></author><author><keyname>Xiao</keyname><forenames>Chaowei</forenames></author><author><keyname>Yang</keyname><forenames>Lei</forenames></author><author><keyname>Yan</keyname><forenames>Xinchen</forenames></author><author><keyname>Lee</keyname><forenames>Honglak</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author></authors><title>SemanticAdv: Generating Adversarial Examples via Attribute-conditional
  Image Editing</title><categories>cs.LG cs.CR cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks (DNNs) have achieved great success in various
applications due to their strong expressive power. However, recent studies have
shown that DNNs are vulnerable to adversarial examples which are manipulated
instances targeting to mislead DNNs to make incorrect predictions. Currently,
most such adversarial examples try to guarantee &quot;subtle perturbation&quot; by
limiting the $L_p$ norm of the perturbation. In this paper, we aim to explore
the impact of semantic manipulation on DNNs predictions by manipulating the
semantic attributes of images and generate &quot;unrestricted adversarial examples&quot;.
  In particular, we propose an algorithm \emph{SemanticAdv} which leverages
disentangled semantic factors to generate adversarial perturbation by altering
controlled semantic attributes to fool the learner towards various
&quot;adversarial&quot; targets. We conduct extensive experiments to show that the
semantic based adversarial examples can not only fool different learning tasks
such as face verification and landmark detection, but also achieve high
targeted attack success rate against \emph{real-world black-box} services such
as Azure face verification service based on transferability.
  To further demonstrate the applicability of \emph{SemanticAdv} beyond face
recognition domain, we also generate semantic perturbations on street-view
images. Such adversarial examples with controlled semantic manipulation can
shed light on further understanding about vulnerabilities of DNNs as well as
potential defensive approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07955</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07955</id><created>2019-06-19</created><updated>2019-06-28</updated><authors><author><keyname>Y&#x131;lmaz</keyname><forenames>Emre</forenames></author><author><keyname>Derinel</keyname><forenames>Adem</forenames></author><author><keyname>Kun</keyname><forenames>Zhou</forenames></author><author><keyname>Heuvel</keyname><forenames>Henk van den</forenames></author><author><keyname>Brummer</keyname><forenames>Niko</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author><author><keyname>van Leeuwen</keyname><forenames>David A.</forenames></author></authors><title>Large-Scale Speaker Diarization of Radio Broadcast Archives</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted for publication at Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes our initial efforts to build a large-scale speaker
diarization (SD) and identification system on a recently digitized radio
broadcast archive from the Netherlands which has more than 6500 audio tapes
with 3000 hours of Frisian-Dutch speech recorded between 1950-2016. The
employed large-scale diarization scheme involves two stages: (1) tape-level
speaker diarization providing pseudo-speaker identities and (2) speaker linking
to relate pseudo-speakers appearing in multiple tapes. Having access to the
speaker models of several frequently appearing speakers from the previously
collected FAME! speech corpus, we further perform speaker identification by
linking these known speakers to the pseudo-speakers identified at the first
stage. In this work, we present a recently created longitudinal and
multilingual SD corpus designed for large-scale SD research and evaluate the
performance of a new speaker linking system using x-vectors with PLDA to
quantify cross-tape speaker similarity on this corpus. The performance of this
speaker linking system is evaluated on a small subset of the archive which is
manually annotated with speaker information. The speaker linking performance
reported on this subset (53 hours) and the whole archive (3000 hours) is
compared to quantify the impact of scaling up in the amount of speech data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07961</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07961</id><created>2019-06-19</created><authors><author><keyname>Hall</keyname><forenames>Georgina</forenames></author></authors><title>Engineering and Business Applications of Sum of Squares Polynomials</title><categories>math.OC cs.SY eess.SY stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimizing over the cone of nonnegative polynomials, and its dual
counterpart, optimizing over the space of moments that admit a representing
measure, are fundamental problems that appear in many different applications
from engineering and computational mathematics to business. In this paper, we
review a number of these applications. These include, but are not limited to,
problems in control (e.g., formal safety verification), finance (e.g., option
pricing), statistics and machine learning (e.g., shape-constrained regression
and optimal design), and game theory (e.g., Nash equilibria computation in
polynomial games). We then show how sum of squares techniques can be used to
tackle these problems, which are hard to solve in general. We conclude by
highlighting some directions that could be pursued to further disseminate sum
of squares techniques within more applied fields. Among other things, we
briefly address the current challenge that scalability represents for
optimization problems that involve sum of squares polynomials and discuss
recent trends in software development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07970</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07970</id><created>2019-06-19</created><authors><author><keyname>Lan</keyname><forenames>Yu</forenames></author><author><keyname>Zhu</keyname><forenames>Hao</forenames></author><author><keyname>Guan</keyname><forenames>Xiaohong</forenames></author></authors><title>Fast Nonconvex SDP Solvers for Large-scale Power System State Estimation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast power system state estimation (SE) solution is of paramount importance
for achieving real-time decision making in power grid operations. Semidefinite
programming (SDP) reformulation has been shown effective to obtain the global
optimum for the nonlinear SE problem, while suffering from high computational
complexity. Thus, we leverage the recent advances in nonconvex SDP approach
that allows for the simple first-order gradient-descent (GD) updates. Using the
power system model, we can verify that the SE objective function enjoys nice
properties (strongly convex, smoothness) which in turn guarantee a linear
convergence rate of the proposed GD-based SE method. To further accelerate the
convergence speed, we consider the accelerated gradient descent (AGD)
extension, as well as their robust versions under outlier data and a hybrid
GD-based SE approach with additional synchrophasor measurements. Numerical
tests on the IEEE 118-bus, 300-bus and the synthetic ACTIVSg2000-bus systems
have demonstrated that FGD-SE and AGD-SE, can approach the near-optimal
performance of the SDP-SE solution at significantly improved computational
efficiency, especially so for AGD-SE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07991</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07991</id><created>2019-06-19</created><authors><author><keyname>Yi</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Suqi</forenames></author><author><keyname>Wang</keyname><forenames>Bailu</forenames></author><author><keyname>Hoseinnezhad</keyname><forenames>Reza</forenames></author><author><keyname>Kong</keyname><forenames>Lingjiang</forenames></author></authors><title>Computationally Efficient Distributed Multi-sensor Fusion with
  Multi-Bernoulli Filter</title><categories>eess.SY cs.SY</categories><comments>16 pages, 11 figures; Under review for IEEE Transactions on Signal
  processing</comments><doi>10.1109/TSP.2019.2957638</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a computationally efficient algorithm for distributed
fusion in a sensor network in which multi-Bernoulli (MB) filters are locally
running in every sensor node for multi-target tracking. The generalized
Covariance Intersection (GCI) fusion rule is employed to fuse multiple MB
random finite set densities. The fused density comprises a set of fusion
hypotheses that grow exponentially with the number of Bernoulli components.
Thus, GCI fusion with MB filters can become computationally intractable in
practical applications that involve tracking of even a moderate number of
objects. In order to accelerate the multi-sensor fusion procedure, we derive a
theoretically sound approximation to the fused density. The number of fusion
hypotheses in the resulting density is significantly smaller than the original
fused density. It also has a parallelizable structure that allows multiple
clusters of Bernoulli components to be fused independently. By carefully
clustering Bernoulli components into isolated clusters using the GCI divergence
as the distance metric, we propose an alternative to build exactly the
approximated density without exhaustively computing all the fusion hypotheses.
The combination of the proposed approximation technique and the fast clustering
algorithm can enable a novel and fast GCIMB fusion implementation. Our analysis
shows that the proposed fusion method can dramatically reduce the computational
and memory requirements with small bounded L1-error. The Gaussian mixture
implementation of the proposed method is also presented. In various numerical
experiments, including a challenging scenario with up to forty objects, the
efficacy of the proposed fusion method is demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.07997</identifier>
 <datestamp>2020-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.07997</id><created>2019-06-19</created><updated>2020-01-09</updated><authors><author><keyname>Goodman</keyname><forenames>Dou</forenames></author><author><keyname>Wei</keyname><forenames>Tao</forenames></author></authors><title>Cloud-based Image Classification Service Is Not Robust To Simple
  Transformations: A Forgotten Battlefield</title><categories>cs.CV cs.CR cs.LG eess.IV</categories><comments>arXiv admin note: text overlap with arXiv:1901.01223,
  arXiv:1704.05051, arXiv:1801.02612 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many recent works demonstrated that Deep Learning models are vulnerable to
adversarial examples.Fortunately, generating adversarial examples usually
requires white-box access to the victim model, and the attacker can only access
the APIs opened by cloud platforms. Thus, keeping models in the cloud can
usually give a (false) sense of security.Unfortunately, cloud-based image
classification service is not robust to simple transformations such as Gaussian
Noise, Salt-and-Pepper Noise, Rotation and Monochromatization. In this
paper,(1) we propose one novel attack method called Image Fusion(IF) attack,
which achieve a high bypass rate,can be implemented only with OpenCV and is
difficult to defend; and (2) we make the first attempt to conduct an extensive
empirical study of Simple Transformation (ST) attacks against real-world
cloud-based classification services. Through evaluations on four popular cloud
platforms including Amazon, Google, Microsoft, Clarifai, we demonstrate that ST
attack has a success rate of approximately 100% except Amazon approximately
50%, IF attack have a success rate over 98% among different classification
services. (3) We discuss the possible defenses to address these security
challenges.Experiments show that our defense technology can effectively defend
known ST attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08003</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08003</id><created>2019-06-19</created><authors><author><keyname>Wang</keyname><forenames>Qinyi</forenames></author><author><keyname>Y&#x131;lmaz</keyname><forenames>Emre</forenames></author><author><keyname>Derinel</keyname><forenames>Adem</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author></authors><title>Code-Switching Detection Using ASR-Generated Language Posteriors</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted for publication at Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Code-switching (CS) detection refers to the automatic detection of language
switches in code-mixed utterances. This task can be achieved by using a CS
automatic speech recognition (ASR) system that can handle such language
switches. In our previous work, we have investigated the code-switching
detection performance of the Frisian-Dutch CS ASR system by using the time
alignment of the most likely hypothesis and found that this technique suffers
from over-switching due to numerous very short spurious language switches. In
this paper, we propose a novel method for CS detection aiming to remedy this
shortcoming by using the language posteriors which are the sum of the
frame-level posteriors of phones belonging to the same language. The CS
ASR-generated language posteriors contain more complete language-specific
information on frame level compared to the time alignment of the ASR output.
Hence, it is expected to yield more accurate and robust CS detection. The CS
detection experiments demonstrate that the proposed language posterior-based
approach provides higher detection accuracy than the baseline system in terms
of equal error rate. Moreover, a detailed CS detection error analysis reveals
that using language posteriors reduces the false alarms and results in more
robust CS detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08024</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08024</id><created>2019-06-19</created><authors><author><keyname>Faqir</keyname><forenames>Omar J.</forenames></author><author><keyname>Kerrigan</keyname><forenames>Eric C.</forenames></author><author><keyname>G&#xfc;nd&#xfc;z</keyname><forenames>Deniz</forenames></author><author><keyname>Nie</keyname><forenames>Yuanbo</forenames></author></authors><title>Joint Optimization of Transmission and Propulsion in UAV-Assisted
  Communication Networks</title><categories>eess.SY cs.IT cs.NI cs.SY eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The communication energy in a wireless network of mobile autonomous agents
should be defined to include the propulsion energy as well as the transmission
energy used to facilitate information transfer. We therefore develop
communicationtheoretic and Newtonian dynamic models of the communication and
locomotion expenditures of an unmanned aerial vehicle (UAV). These models are
used to formulate a novel nonlinear optimal control problem (OCP) for arbitrary
networks of autonomous agents. This is the first work to consider mobility as a
decision variable in UAV networks with multiple access channels. Where
possible, we compare our results with known analytic solutions for particular
single-hop network configurations. The OCP is then applied to a multiple-node
UAV network for which previous results cannot be readily extended. Numerical
results demonstrate increased network capacity and communication energy savings
upwards of 70% when compared to more naive communication policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08041</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08041</id><created>2019-06-17</created><updated>2019-10-18</updated><authors><author><keyname>Li</keyname><forenames>Ruizhi</forenames></author><author><keyname>Wang</keyname><forenames>Xiaofei</forenames></author><author><keyname>Mallidi</keyname><forenames>Sri Harish</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author><author><keyname>Hori</keyname><forenames>Takaaki</forenames></author><author><keyname>Hermansky</keyname><forenames>Hynek</forenames></author></authors><title>Multi-Stream End-to-End Speech Recognition</title><categories>eess.AS cs.CL cs.SD</categories><comments>submitted to IEEE TASLP (In review). arXiv admin note: substantial
  text overlap with arXiv:1811.04897, arXiv:1811.04903</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attention-based methods and Connectionist Temporal Classification (CTC)
network have been promising research directions for end-to-end (E2E) Automatic
Speech Recognition (ASR). The joint CTC/Attention model has achieved great
success by utilizing both architectures during multi-task training and joint
decoding. In this work, we present a multi-stream framework based on joint
CTC/Attention E2E ASR with parallel streams represented by separate encoders
aiming to capture diverse information. On top of the regular attention
networks, the Hierarchical Attention Network (HAN) is introduced to steer the
decoder toward the most informative encoders. A separate CTC network is
assigned to each stream to force monotonic alignments. Two representative
framework have been proposed and discussed, which are Multi-Encoder
Multi-Resolution (MEM-Res) framework and Multi-Encoder Multi-Array (MEM-Array)
framework, respectively. In MEM-Res framework, two heterogeneous encoders with
different architectures, temporal resolutions and separate CTC networks work in
parallel to extract complimentary information from same acoustics. Experiments
are conducted on Wall Street Journal (WSJ) and CHiME-4, resulting in relative
Word Error Rate (WER) reduction of 18.0-32.1% and the best WER of 3.6% in the
WSJ eval92 test set. The MEM-Array framework aims at improving the far-field
ASR robustness using multiple microphone arrays which are activated by separate
encoders. Compared with the best single-array results, the proposed framework
has achieved relative WER reduction of 3.7% and 9.7% in AMI and DIRHA
multi-array corpora, respectively, which also outperforms conventional fusion
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08043</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08043</id><created>2019-06-17</created><authors><author><keyname>Parcollet</keyname><forenames>Titouan</forenames></author><author><keyname>Morchid</keyname><forenames>Mohamed</forenames></author><author><keyname>Linar&#xe8;s</keyname><forenames>Georges</forenames></author><author><keyname>De Mori</keyname><forenames>Renato</forenames></author></authors><title>Real to H-space Encoder for Speech Recognition</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted at INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks (DNNs) and more precisely recurrent neural networks
(RNNs) are at the core of modern automatic speech recognition systems, due to
their efficiency to process input sequences. Recently, it has been shown that
different input representations, based on multidimensional algebras, such as
complex and quaternion numbers, are able to bring to neural networks a more
natural, compressive and powerful representation of the input signal by
outperforming common real-valued NNs. Indeed, quaternion-valued neural networks
(QNNs) better learn both internal dependencies, such as the relation between
the Mel-filter-bank value of a specific time frame and its time derivatives,
and global dependencies, describing the relations that exist between time
frames. Nonetheless, QNNs are limited to quaternion-valued input signals, and
it is difficult to benefit from this powerful representation with real-valued
input data. This paper proposes to tackle this weakness by introducing a
real-to-quaternion encoder that allows QNNs to process any one dimensional
input features, such as traditional Mel-filter-banks for automatic speech
recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08044</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08044</id><created>2019-06-17</created><updated>2019-11-13</updated><authors><author><keyname>Han</keyname><forenames>Yan</forenames></author><author><keyname>Krishna</keyname><forenames>Gautam</forenames></author><author><keyname>Tran</keyname><forenames>Co</forenames></author><author><keyname>Carnahan</keyname><forenames>Mason</forenames></author><author><keyname>Tewfik</keyname><forenames>Ahmed H</forenames></author></authors><title>Robust End-to-End Speaker Verification Using EEG</title><categories>eess.AS cs.LG cs.SD eess.SP stat.ML</categories><comments>To be submitted to ICASSP 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we demonstrate that performance of a speaker verification
system can be improved by concatenating electroencephalography (EEG) signal
features with speech signal. We use state of art end to end deep learning model
for performing speaker verification and we demonstrate our results for noisy
speech. Our results indicate that EEG signals can improve the robustness of
speaker verification systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08045</identifier>
 <datestamp>2019-11-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08045</id><created>2019-06-17</created><updated>2019-11-13</updated><authors><author><keyname>Krishna</keyname><forenames>Gautam</forenames></author><author><keyname>Tran</keyname><forenames>Co</forenames></author><author><keyname>Han</keyname><forenames>Yan</forenames></author><author><keyname>Carnahan</keyname><forenames>Mason</forenames></author><author><keyname>Tewfik</keyname><forenames>Ahmed H</forenames></author></authors><title>Speech Recognition With No Speech Or With Noisy Speech Beyond English</title><categories>eess.AS cs.LG cs.SD eess.SP stat.ML</categories><comments>To be submitted to ICASSP 2020. arXiv admin note: substantial text
  overlap with arXiv:1906.08871, arXiv:1908.05743</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we demonstrate continuous noisy speech recognition using
connectionist temporal classification (CTC) model on limited Chinese vocabulary
using electroencephalography (EEG) features with no speech signal as input and
we further demonstrate single CTC model based continuous noisy speech
recognition on limited joint English and Chinese vocabulary using EEG features
with no speech signal as input. We demonstrate our results using various EEG
feature sets recently introduced in [1] as well as we propose a new deep
learning architecture in this paper which can perform continuous speech
recognition using raw EEG signals on limited joint English and Chinese
vocabulary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08059</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08059</id><created>2019-06-18</created><authors><author><keyname>You</keyname><forenames>Jia</forenames></author><author><keyname>Yu</keyname><forenames>Philip L. H.</forenames></author><author><keyname>Tsang</keyname><forenames>Anderson C. O.</forenames></author><author><keyname>Tsui</keyname><forenames>Eva L. H.</forenames></author><author><keyname>Woo</keyname><forenames>Pauline P. S.</forenames></author><author><keyname>Leung</keyname><forenames>Gilberto K. K.</forenames></author></authors><title>Automated Computer Evaluation of Acute Ischemic Stroke and Large Vessel
  Occlusion</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large vessel occlusion (LVO) plays an important role in the diagnosis of
acute ischemic stroke. Identifying LVO of patients in the early stage on
admission would significantly lower the probabilities of suffering from severe
effects due to stroke or even save their lives. In this paper, we utilized both
structural and imaging data from all recorded acute ischemic stroke patients in
Hong Kong. Total 300 patients (200 training and 100 testing) are used in this
study. We established three hierarchical models based on demographic data,
clinical data and features obtained from computerized tomography (CT) scans.
The first two stages of modeling are merely based on demographic and clinical
data. Besides, the third model utilized extra CT imaging features obtained from
deep learning model. The optimal cutoff is determined at the maximal Youden
index based on 10-fold cross-validation. With both clinical and imaging
features, the Level-3 model achieved the best performance on testing data. The
sensitivity, specificity, Youden index, accuracy and area under the curve (AUC)
are 0.930, 0.684, 0.614, 0.790 and 0.850 respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08095</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08095</id><created>2019-06-19</created><authors><author><keyname>Zhai</keyname><forenames>Guangyao</forenames></author><author><keyname>Liu</keyname><forenames>Liang</forenames></author><author><keyname>Zhang</keyname><forenames>Linjian</forenames></author><author><keyname>Liu</keyname><forenames>Yong</forenames></author></authors><title>PoseConvGRU: A Monocular Approach for Visual Ego-motion Estimation by
  Learning</title><categories>cs.CV cs.LG eess.IV</categories><comments>33 pages,12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While many visual ego-motion algorithm variants have been proposed in the
past decade, learning based ego-motion estimation methods have seen an
increasing attention because of its desirable properties of robustness to image
noise and camera calibration independence. In this work, we propose a
data-driven approach of fully trainable visual ego-motion estimation for a
monocular camera. We use an end-to-end learning approach in allowing the model
to map directly from input image pairs to an estimate of ego-motion
(parameterized as 6-DoF transformation matrices). We introduce a novel
two-module Long-term Recurrent Convolutional Neural Networks called
PoseConvGRU, with an explicit sequence pose estimation loss to achieve this.
The feature-encoding module encodes the short-term motion feature in an image
pair, while the memory-propagating module captures the long-term motion feature
in the consecutive image pairs. The visual memory is implemented with
convolutional gated recurrent units, which allows propagating information over
time. At each time step, two consecutive RGB images are stacked together to
form a 6 channels tensor for module-1 to learn how to extract motion
information and estimate poses. The sequence of output maps is then passed
through a stacked ConvGRU module to generate the relative transformation pose
of each image pair. We also augment the training data by randomly skipping
frames to simulate the velocity variation which results in a better performance
in turning and high-velocity situations. We evaluate the performance of our
proposed approach on the KITTI Visual Odometry benchmark. The experiments show
a competitive performance of the proposed method to the geometric method and
encourage further exploration of learning based methods for the purpose of
estimating camera ego-motion even though geometrical methods demonstrate
promising results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08143</identifier>
 <datestamp>2019-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08143</id><created>2019-06-19</created><updated>2019-09-05</updated><authors><author><keyname>Cheng</keyname><forenames>Jing</forenames></author><author><keyname>Wang</keyname><forenames>Haifeng</forenames></author><author><keyname>Zhu</keyname><forenames>Yanjie</forenames></author><author><keyname>Liu</keyname><forenames>Qiegen</forenames></author><author><keyname>Zhang</keyname><forenames>Qiyang</forenames></author><author><keyname>Su</keyname><forenames>Ting</forenames></author><author><keyname>Chen</keyname><forenames>Jianwei</forenames></author><author><keyname>Ge</keyname><forenames>Yongshuai</forenames></author><author><keyname>Hu</keyname><forenames>Zhanli</forenames></author><author><keyname>Liu</keyname><forenames>Xin</forenames></author><author><keyname>Zheng</keyname><forenames>Hairong</forenames></author><author><keyname>Ying</keyname><forenames>Leslie</forenames></author><author><keyname>Liang</keyname><forenames>Dong</forenames></author></authors><title>Model-based Deep Medical Imaging: the roadmap of generalizing iterative
  reconstruction model using deep learning</title><categories>cs.CV eess.SP math.OC physics.med-ph stat.ML</categories><comments>part of the preliminary work will be presented at MICCAI2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical imaging is playing a more and more important role in clinics.
However, there are several issues in different imaging modalities such as slow
imaging speed in MRI, radiation injury in CT and PET. Therefore, accelerating
MRI, reducing radiation dose in CT and PET have been ongoing research topics
since their invention. Usually, acquiring less data is a direct but important
strategy to address these issues. However, less acquisition usually results in
aliasing artifacts in reconstructions. Recently, deep learning (DL) has been
introduced in medical image reconstruction and shown potential on significantly
speeding up MR reconstruction and reducing radiation dose. In this paper, we
propose a general framework on combining the reconstruction model with deep
learning to maximize the potential of deep learning and model-based
reconstruction, and give the examples to demonstrate the performance and
requirements of unrolling different algorithms using deep learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08152</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08152</id><created>2019-06-19</created><updated>2019-06-29</updated><authors><author><keyname>Luo</keyname><forenames>Yin-Jyun</forenames></author><author><keyname>Agres</keyname><forenames>Kat</forenames></author><author><keyname>Herremans</keyname><forenames>Dorien</forenames></author></authors><title>Learning Disentangled Representations of Timbre and Pitch for Musical
  Instrument Sounds Using Gaussian Mixture Variational Autoencoders</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>20th Conference of the International Society for Music Information
  Retrieval</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we learn disentangled representations of timbre and pitch for
musical instrument sounds. We adapt a framework based on variational
autoencoders with Gaussian mixture latent distributions. Specifically, we use
two separate encoders to learn distinct latent spaces for timbre and pitch,
which form Gaussian mixture components representing instrument identity and
pitch, respectively. For reconstruction, latent variables of timbre and pitch
are sampled from corresponding mixture components, and are concatenated as the
input to a decoder. We show the model efficacy by latent space visualization,
and a quantitative analysis indicates the discriminability of these spaces,
even with a limited number of instrument labels for training. The model allows
for controllable synthesis of selected instrument sounds by sampling from the
latent spaces. To evaluate this, we trained instrument and pitch classifiers
using original labeled data. These classifiers achieve high accuracy when
tested on our synthesized sounds, which verifies the model performance of
controllable realistic timbre and pitch synthesis. Our model also enables
timbre transfer between multiple instruments, with a single autoencoder
architecture, which is evaluated by measuring the shift in posterior of
instrument classification. Our in depth evaluation confirms the model ability
to successfully disentangle timbre and pitch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08156</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08156</id><created>2019-06-19</created><updated>2019-11-18</updated><authors><author><keyname>Schoen</keyname><forenames>Scott</forenames><suffix>Jr</suffix></author><author><keyname>Arvanitis</keyname><forenames>Costas D.</forenames></author></authors><title>Heterogeneous Angular Spectrum Approach for Trans-skull Imaging and
  Focusing</title><categories>eess.SP</categories><comments>18 pages, 7 figures</comments><doi>10.1121/1.5136742</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasound, alone or in concert with circulating microbubble contrast agents,
has emerged as a promising modality for therapy and imaging of brain diseases.
While this has become possible due to advancements in aberration correction
methods, a range of applications, including adaptive focusing and tracking of
the microbubble dynamics through the human skull, may benefit from even more
computationally efficient methods to account for skull aberrations. Here, we
derive a general method for the angular spectrum approach (ASA) in a
heterogeneous medium, based on a numerical marching scheme to approximate the
full implicit solution. We then demonstrate its functionality with simulations
for (human) skull-related aberration correction and trans-skull passive
acoustic mapping. Our simulations show that the general solution provides
accurate trans-skull focusing as compared to the uncorrected case for
clinically relevant frequencies, apertures, and targets, with the effects of
skull attenuation and amplitude shading included. In the case of source
localization, our method leads to an average of 75 % error reduction and 40 to
60 % increase in peak intensity, evaluated over the range of frequencies as
compared to the homogeneous medium ASA. Overall, total computation times for
both focusing and point source localization of the order milliseconds can be
attained with this approach. Collectively our findings indicate that the
proposed phase correction method based on the ASA could provide a
computationally efficient and accurate method for trans-skull transmit focusing
and imaging of point scatterers, potentially opening new possibilities for
treatment and diagnosis of brain diseases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08171</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08171</id><created>2019-06-11</created><authors><author><keyname>Rizk</keyname><forenames>Hamada</forenames></author><author><keyname>Shokry</keyname><forenames>Ahmed</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>Effectiveness of Data Augmentation in Cellular-based Localization Using
  Deep Learning</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, deep learning-based positioning systems have gained attention due
to their higher performance relative to traditional methods. However, obtaining
the expected performance of deep learning-based systems requires large amounts
of data to train model. Obtaining this data is usually a tedious process which
hinders the utilization of such deep learning approaches. In this paper, we
introduce a number of techniques for addressing the data collection problem for
deep learning-based cellular localization systems. The basic idea is to
generate synthetic data that reflects the typical pattern of the wireless data
as observed from a small collected dataset. Evaluation of the proposed data
augmentation techniques using different Android phones in a cellular
localization case study shows that we can enhance the performance of the
localization systems in both indoor and outdoor scenarios by 157% and 50.5%,
respectively. This highlights the promise of the proposed techniques for
enabling deep learning-based localization systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08180</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08180</id><created>2019-06-19</created><updated>2019-08-28</updated><authors><author><keyname>Reid</keyname><forenames>Tyler G. R.</forenames></author><author><keyname>Pervez</keyname><forenames>Nahid</forenames></author><author><keyname>Ibrahim</keyname><forenames>Umair</forenames></author><author><keyname>Houts</keyname><forenames>Sarah E.</forenames></author><author><keyname>Pandey</keyname><forenames>Gaurav</forenames></author><author><keyname>Alla</keyname><forenames>Naveen K. R.</forenames></author><author><keyname>Hsia</keyname><forenames>Andy</forenames></author></authors><title>Standalone and RTK GNSS on 30,000 km of North American Highways</title><categories>cs.RO cs.SY eess.SP</categories><comments>Accepted for the 32nd International Technical Meeting of the
  Satellite Division of The Institute of Navigation (ION GNSS+ 2019), Miami,
  Florida, September 2019</comments><journal-ref>Proceedings of the 32nd International Technical Meeting of the
  Satellite Division of The Institute of Navigation (ION GNSS+ 2019), Miami,
  Florida, September 2019, pp. 2135-2158</journal-ref><doi>10.33012/2019.16914</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a growing need for vehicle positioning information to support
Advanced Driver Assistance Systems (ADAS), Connectivity (V2X), and Automated
Driving (AD) features. These range from a need for road determination (&lt;5
meters), lane determination (&lt;1.5 meters), and determining where the vehicle is
within the lane (&lt;0.3 meters). This work examines the performance of Global
Navigation Satellite Systems (GNSS) on 30,000 km of North American highways to
better understand the automotive positioning needs it meets today and what
might be possible in the near future with wide area GNSS correction services
and multi-frequency receivers. This includes data from a representative
automotive production GNSS used primarily for turn-by-turn navigation as well
as an Inertial Navigation System which couples two survey grade GNSS receivers
with a tactical grade Inertial Measurement Unit (IMU) to act as ground truth.
The latter utilized networked Real-Time Kinematic (RTK) GNSS corrections
delivered over a cellular modem in real-time. We assess on-road GNSS accuracy,
availability, and continuity. Availability and continuity are broken down in
terms of satellite visibility, satellite geometry, position type (RTK fixed,
RTK float, or standard positioning), and RTK correction latency over the
network. Results show that current automotive solutions are best suited to meet
road determination requirements at 98% availability but are less suitable for
lane determination at 57%. Multi-frequency receivers with RTK corrections were
found more capable with road determination at 99.5%, lane determination at 98%,
and highway-level lane departure protection at 91%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08182</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08182</id><created>2019-06-18</created><updated>2019-09-11</updated><authors><author><keyname>Pilori</keyname><forenames>Dario</forenames></author><author><keyname>Cantono</keyname><forenames>Mattia</forenames></author><author><keyname>Ferrari</keyname><forenames>Alessio</forenames></author><author><keyname>Carena</keyname><forenames>Andrea</forenames></author><author><keyname>Curri</keyname><forenames>Vittorio</forenames></author></authors><title>Observing the Effect of Polarization Mode Dispersion on Nonlinear
  Interference Generation in Wide-Band Optical Links</title><categories>eess.SP</categories><journal-ref>OSA Continuum 2 (10), 2856-2863 (2019)</journal-ref><doi>10.1364/OSAC.2.002856</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the extension of the spectral exploitation of optical fibers beyond the
C-band, accurate modeling and simulation of nonlinear interference (NLI)
generation is of the utmost performance. Models and numerical simulation tools
rely on the widely used Manakov equation (ME): however, this approach when
considering also the effect of polarization mode dispersion (PMD) is formally
valid only over a narrow optical bandwidth. In order to analyze the range of
validity of the ME and its applicability to future wide-band systems, we
present numerical simulations, showing the interplay between NLI generation and
PMD over long dispersion-uncompensated optical links, using coherent
polarization division multiplexing (PDM) quadrature amplitude modulation (QAM)
formats. Using a Monte-Carlo analysis of different PMD realizations based on
the coupled nonlinear Schr\&quot;{o}dinger equations, we show that PMD has a
negligible effect on NLI generation, independently from the total system
bandwidth. Based on this, we give strong numerical evidence that the ME can be
safely used to estimate NLI generation well beyond its bandwidth of validity
that is limited to the PMD coherence bandwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08192</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08192</id><created>2019-06-19</created><authors><author><keyname>Schrumpf</keyname><forenames>Fabian</forenames></author><author><keyname>Moench</keyname><forenames>Christoph</forenames></author><author><keyname>Bausch</keyname><forenames>Gerold</forenames></author><author><keyname>Fuchs</keyname><forenames>Mirco</forenames></author></authors><title>Exploiting Weak Head Movements for Camera-based Respiration Detection</title><categories>eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, considerable progress has been made in the non-contact based
detection of the respiration rate from video sequences. Common techniques
either directly assess the movement of the chest due to breathing or are based
on analyzing subtle color changes that occur as a result of hemodynamic
properties of the skin tissue by means of remote photoplethysmography (rPPG).
However, extracting hemodynamic parameters from rPPG is often difficult
especially if the skin is not visible to the camera. In contrast, extracting
respiratory signals from chest movements turned out to be a robust method.
However, the detectability of chest regions cannot be guaranteed in any
application scenario, for instance if the camera setting is optimized to
provide close-up images of the head. In such a case an alternative method for
respiration detection is required.
  It is reasonable to assume that the mechanical coupling between chest and
head induces minor movements of the head which, like in rPPG, can be detected
from subtle color changes as well. Although the strength of these movements is
expected to be much smaller in scale, sensing these intensity variations could
provide a reasonably suited respiration signal for subsequent respiratory rate
analysis.
  In order to investigate this coupling we conducted an experimental study with
12 subjects and applied motion- and rPPG-based methods to estimate the
respiratory frequency from both head regions and chest. Our results show that
it is possible to derive signals correlated to chest movement from facial
regions. The method is a feasible alternative to rPPG-based respiratory rate
estimations when rPPG-signals cannot be derived reliably and chest movement
detection cannot be applied as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08195</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08195</id><created>2019-06-19</created><authors><author><keyname>Benjamin</keyname><forenames>Arnold Julian Vinoj</forenames></author><author><keyname>Gomez</keyname><forenames>Pedro A.</forenames></author><author><keyname>Golbabaee</keyname><forenames>Mohammad</forenames></author><author><keyname>Mahbub</keyname><forenames>Zaid</forenames></author><author><keyname>Sprenger</keyname><forenames>Tim</forenames></author><author><keyname>Davies</keyname><forenames>Marion I. Menzel Michael</forenames></author><author><keyname>Marshall</keyname><forenames>Ian</forenames></author></authors><title>Multi-shot Echo Planar Imaging for accelerated Cartesian MR
  Fingerprinting: an alternative to conventional spiral MR Fingerprinting</title><categories>physics.med-ph eess.IV</categories><comments>12 pages, 11 main figures, 2 supplementry figures, preprint of
  accepted abstract</comments><doi>10.1016/j.mri.2019.04.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To develop an accelerated Cartesian MRF implementation using a
multi-shot EPI sequence for rapid simultaneous quantification of T1 and T2
parameters. Methods: The proposed Cartesian MRF method involved the acquisition
of highly subsampled MR images using a 16-shot EPI readout. A linearly varying
flip angle train was used for rapid, simultaneous T1 and T2 quantification. The
accuracy of parametric map estimations were improved by using an iterative
projection algorithm. The results were compared to a conventional spiral MRF
implementation. The acquisition time per slice was 8s and this method was
validated on a phantom and a healthy volunteer brain in vivo. Results: Joint T1
and T2 estimations using the 16-shot EPI readout are in good agreement with the
spiral implementation using the same acquisition parameters (deviation less
than 3% for T1 and less than 4% for T2) for the healthy volunteer brain. The T1
and T2 values also agree with the conventional values previously reported in
the literature. The visual quality of the multi-parametric maps generated by
the multi-shot EPI-MRF and spiral-MRF implementations were comparable.
Conclusion: The multi-shot EPI-MRF method generated accurate quantitative
multi-parametric maps similar to conventional Spiral - MRF. This multi-shot
approach achieved provides an alternative for performing MRF using an
accelerated Cartesian readout, thereby increasing the potential usability of
MRF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08208</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08208</id><created>2019-06-19</created><updated>2019-10-22</updated><authors><author><keyname>Pla</keyname><forenames>Pol del Aguila</forenames></author><author><keyname>Pellaco</keyname><forenames>Lissy</forenames></author><author><keyname>Dwivedi</keyname><forenames>Satyam</forenames></author><author><keyname>H&#xe4;ndel</keyname><forenames>Peter</forenames></author><author><keyname>Jald&#xe9;n</keyname><forenames>Joakim</forenames></author></authors><title>Clock synchronization over networks -- Identifiability of the sawtooth
  model</title><categories>eess.SY cs.SY eess.SP math.ST stat.TH</categories><comments>13 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the two-node joint clock synchronization and
ranging problem. We focus on the case of nodes that employ time-to-digital
converters to determine the range between them precisely. This specific design
choice leads to a sawtooth model for the captured signal, which has not been
studied before from an estimation theoretic standpoint. In the study of this
model, we recover the basic conclusion of a well-known article by Freris,
Graham, and Kumar in clock synchronization. More importantly, we discover a
surprising identifiability result on the sawtooth signal model: noise improves
the theoretical condition of the estimation of the phase and offset parameters.
To complete our study, we provide performance references for joint clock
synchronization and ranging using the sawtooth signal model by presenting an
exhaustive simulation study on basic estimation strategies under different
realistic conditions. With our contributions in this paper, we enable further
research in the estimation of sawtooth signal models and pave the path towards
their industrial use for clock synchronization and ranging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08211</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08211</id><created>2019-06-19</created><updated>2019-10-15</updated><authors><author><keyname>Alsulami</keyname><forenames>Osama Zwaid</forenames></author><author><keyname>Alresheedi</keyname><forenames>Mohammed T.</forenames></author><author><keyname>Elmirghani</keyname><forenames>Jaafar M. H.</forenames></author></authors><title>Optical Wireless cabin communication system</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Offering a high data rate to users inside the cabin is attractive for the
aircraft building companies. This paper presents an optical wireless system
that uses visible light for transmitting data. The reading light for each seat
is used as a transmitter in this work to offer high data rates. Red, yellow,
green, and blue (RYGB) laser diode (LD) are utilised in each reading light to
obtain a high modulation bandwidth. Two types of reading lights based on angle
diversity transmitter (ADT) units are utilised in this paper for illumination
and communication. Additionally, two kinds of optical receivers are used: four
branches angle diversity receiver (ADR) and 25 pixels imaging receiver (ImR).
The delay spread and the signal to interference and noise ratio (SINR) are
evaluated. The proposed system can offer high data rates up to 22.8 Gbps for
each user by using simple on-off-keying (OOK) modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08212</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08212</id><created>2019-06-19</created><updated>2019-10-15</updated><authors><author><keyname>Alsulami</keyname><forenames>Osama Zwaid</forenames></author><author><keyname>Musa</keyname><forenames>Mohamed O. I.</forenames></author><author><keyname>Alresheedi</keyname><forenames>Mohammed T.</forenames></author><author><keyname>Elmirghani</keyname><forenames>Jaafar M. H.</forenames></author></authors><title>Co-existence of Micro, Pico and Atto Cells in Optical Wireless
  Communication</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference between cells or users can have a significant impact on the
quality of optical wireless communication (OWC) links. This paper studies the
co-existence of infrared based Micro cells with Visible light communication
based Pico and Atto Cells for downlink communication. The signal to noise ratio
(SNR) of each cell and the signal to interference and noise ratio (SINR)
between cells are evaluated when an angle diversity receiver and an imaging
receiver are used. The results show that Atto cell systems provide higher SNR
and data rates compared to the Pico cell systems which provide higher SNR and
data rates compared to Micro cell systems. The Micro cell systems however
provide mobility as they provide a larger coverage area, followed by the Pico
cell systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08254</identifier>
 <datestamp>2019-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08254</id><created>2019-06-19</created><authors><author><keyname>Usevitch</keyname><forenames>James</forenames></author><author><keyname>Panagou</keyname><forenames>Dimitra</forenames></author></authors><title>Resilient Leader-Follower Consensus with Time-Varying Leaders in
  Discrete-Time Systems</title><categories>eess.SY cs.SY</categories><comments>Submitted to 58th IEEE Conference on Decision and Control, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of consensus in the presence of adversarially behaving agents has
been studied extensively in the literature. The proposed algorithms typically
guarantee that the consensus value lies within the convex hull of initial
normal agents' states. In leader-follower consensus problems however, the
objective for normally behaving agents is to track a time-varying reference
state that may take on values outside of this convex hull. In this paper we
present a method for agents with discrete-time dynamics to resiliently track a
set of leaders' common time-varying reference state despite a bounded subset of
the leaders and followers behaving adversarially. The efficacy of our results
are demonstrated through simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08257</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08257</id><created>2019-06-19</created><authors><author><keyname>Zhang</keyname><forenames>Xiaojing</forenames></author><author><keyname>Bujarbaruah</keyname><forenames>Monimoy</forenames></author><author><keyname>Borrelli</keyname><forenames>Francesco</forenames></author></authors><title>Safe and Near-Optimal Policy Learning for Model Predictive Control using
  Primal-Dual Neural Networks</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><comments>IEEE American Control Conference (ACC) 2019, July 9-12, Philadelphia,
  PA, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel framework for approximating the explicit
MPC law for linear parameter-varying systems using supervised learning. In
contrast to most existing approaches, we not only learn the control policy, but
also a &quot;certificate policy&quot;, that allows us to estimate the sub-optimality of
the learned control policy online, during execution-time. We learn both these
policies from data using supervised learning techniques, and also provide a
randomized method that allows us to guarantee the quality of each learned
policy, measured in terms of feasibility and optimality. This in turn allows us
to bound the probability of the learned control policy of being infeasible or
suboptimal, where the check is performed by the certificate policy. Since our
algorithm does not require the solution of an optimization problem during
run-time, it can be deployed even on resource-constrained systems. We
illustrate the efficacy of the proposed framework on a vehicle dynamics control
problem where we demonstrate a speedup of up to two orders of magnitude
compared to online optimization with minimal performance degradation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08311</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08311</id><created>2019-06-19</created><authors><author><keyname>Pierrou</keyname><forenames>Georgia</forenames></author><author><keyname>Wang</keyname><forenames>Xiaozhe</forenames></author></authors><title>The Effect of the Uncertainty of Load and Renewable Generation on the
  Dynamic Voltage Stability Margin</title><categories>eess.SY cs.SY eess.SP</categories><comments>Accepted in 2019 IEEE PES Innovative Smart Grid Technologies Europe
  (ISGT-Europe)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the impact of stochastic load and renewable generation
uncertainty on the dynamic voltage stability margin is studied. Stochastic
trajectories describing the uncertainty of load, wind and solar generation have
been incorporated in the power system model as a set of Stochastic
Differential-Algebraic Equations (SDAEs). A systematic study of Monte Carlo
dynamic simulations on the IEEE 39-Bus system has been conducted to compute the
stochastic load margin with all dynamic components active. Numerical results
show that the uncertainty of both demand and generation may lead to a decrease
on the size of the dynamic voltage stability margin, yet the variability of
renewable generators may play a more significant role. Given that the
integration of renewable energy will continue growing, it is of paramount
importance to apply stochastic and dynamic approaches in the voltage stability
study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08330</identifier>
 <datestamp>2019-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08330</id><created>2019-06-19</created><updated>2019-12-10</updated><authors><author><keyname>Shirazi</keyname><forenames>Mojtaba</forenames></author><author><keyname>Vosoughi</keyname><forenames>Azadeh</forenames></author></authors><title>On Distributed Estimation in Hierarchical Power Constrained Wireless
  Sensor Networks</title><categories>eess.SP</categories><comments>Some parts of the paper need to be changed, for example the Bayesian
  CRB in section III-C, Convergence analysis in section VII, and Fig. 9 in
  section VIII. We will upload the updated version as soon as it is ready</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider distributed estimation of a random source in a hierarchical power
constrained wireless sensor network. Sensors within each cluster send their
measurements to a cluster head (CH). CHs optimally fuse the received signals
and transmit to the fusion center (FC) over orthogonal fading channels. To
enable channel estimation at the FC, CHs send pilots, prior to data
transmission. We derive the mean square error (MSE) corresponding to the linear
minimum mean square error (LMMSE) estimator of the source at the FC, and derive
the Bayesian Cramer-Rao bound (CRB). Our goal is to find (i) the optimal
training power, (ii) the optimal power that sensors in a cluster spend to
transmit their amplified measurements to their CH, and (iii) the optimal weight
vector employed by each CH for its linear signal fusion, such that the MSE is
minimized, subject to a network power constraint. To untangle the performance
gain that optimizing each set of these variables provide, we also analyze three
special cases of the original problem, where in each special case, only two
sets of variables are optimized across clusters. We define three factors that
allow us to quantify the effectiveness of each power allocation scheme in
achieving an MSE-power tradeoff that is close to that of the Bayesian CRB.
Combining the information gained from the factors and Bayesian CRB with our
computational complexity analysis provides the system designer with
quantitative complexity-versus-MSE improvement tradeoffs offered by different
power allocation schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08331</identifier>
 <datestamp>2019-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08331</id><created>2019-06-19</created><updated>2019-10-29</updated><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Liu</keyname><forenames>Yamei</forenames></author><author><keyname>Zhang</keyname><forenames>Shengping</forenames></author><author><keyname>Poppe</keyname><forenames>Ronald</forenames></author><author><keyname>Wang</keyname><forenames>Meng</forenames></author></authors><title>Light Field Saliency Detection with Deep Convolutional Networks</title><categories>cs.CV eess.IV</categories><comments>14 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Light field imaging presents an attractive alternative to RGB imaging because
of the recording of the direction of the incoming light. The detection of
salient regions in a light field image benefits from the additional modeling of
angular patterns. For RGB imaging, methods using CNNs have achieved excellent
results on a range of tasks, including saliency detection. However, it is not
trivial to use CNN-based methods for saliency detection on light field images
because these methods are not specifically designed for processing light field
inputs. In addition, current light field datasets are not sufficiently large to
train CNNs. To overcome these issues, we present a new Lytro Illum dataset,
which contains 640 light fields and their corresponding ground-truth saliency
maps. Compared to current light field saliency datasets [1], [2], our new
dataset is larger, of higher quality, contains more variation and more types of
light field inputs. This makes our dataset suitable for training deeper
networks and benchmarking. Furthermore, we propose a novel end-to-end CNN-based
framework for light field saliency detection. Specifically, we propose three
novel MAC (Model Angular Changes) blocks to process light field micro-lens
images. We systematically study the impact of different architecture variants
and compare light field saliency with regular 2D saliency. Our extensive
comparisons indicate that our novel network significantly outperforms
state-of-the-art methods on the proposed dataset and has desired generalization
abilities on other existing datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08333</identifier>
 <datestamp>2019-12-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08333</id><created>2019-06-19</created><authors><author><keyname>Jung</keyname><forenames>Youngmoon</forenames></author><author><keyname>Kim</keyname><forenames>Younggwan</forenames></author><author><keyname>Lim</keyname><forenames>Hyungjun</forenames></author><author><keyname>Choi</keyname><forenames>Yeunju</forenames></author><author><keyname>Kim</keyname><forenames>Hoirin</forenames></author></authors><title>Spatial Pyramid Encoding with Convex Length Normalization for
  Text-Independent Speaker Verification</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>5 pages, 2 figures, Interspeech 2019</comments><journal-ref>Proc. of Interspeech 2019, 2019, pp. 4030-4034</journal-ref><doi>10.21437/Interspeech.2019-2177</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new pooling method called spatial pyramid
encoding (SPE) to generate speaker embeddings for text-independent speaker
verification. We first partition the output feature maps from a deep residual
network (ResNet) into increasingly fine sub-regions and extract speaker
embeddings from each sub-region through a learnable dictionary encoding layer.
These embeddings are concatenated to obtain the final speaker representation.
The SPE layer not only generates a fixed-dimensional speaker embedding for a
variable-length speech segment, but also aggregates the information of feature
distribution from multi-level temporal bins. Furthermore, we apply deep length
normalization by augmenting the loss function with ring loss. By applying ring
loss, the network gradually learns to normalize the speaker embeddings using
model weights themselves while preserving convexity, leading to more robust
speaker embeddings. Experiments on the VoxCeleb1 dataset show that the proposed
system using the SPE layer and ring loss-based deep length normalization
outperforms both i-vector and d-vector baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08365</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08365</id><created>2019-06-19</created><updated>2019-06-27</updated><authors><author><keyname>Sahoo</keyname><forenames>Dushyant</forenames></author><author><keyname>Bassett</keyname><forenames>Danielle</forenames></author><author><keyname>Davatzikos</keyname><forenames>Christos</forenames></author></authors><title>Extraction of hierarchical functional connectivity components in human
  brain using resting-state fMRI</title><categories>q-bio.NC cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of hierarchy in networks of the human brain has been of significant
interest among the researchers as numerous studies have pointed out towards a
functional hierarchical organization of the human brain. This paper provides a
novel method for the extraction of hierarchical connectivity components in the
human brain using resting-state fMRI. The method builds upon prior work of
Sparse Connectivity Patterns (SCPs) by introducing a hierarchy of sparse
overlapping patterns. The components are estimated by deep factorization of
correlation matrices generated from fMRI. The goal of the paper is to extract
interpretable hierarchical patterns using correlation matrices where a low rank
decomposition is formed by a linear combination of a high rank decomposition.
We formulate the decomposition as a non-convex optimization problem and solve
it using gradient descent algorithms with adaptive step size. We also provide a
method for the warm start of the gradient descent using singular value
decomposition. We demonstrate the effectiveness of the developed method on two
different real-world datasets by showing that multi-scale hierarchical SCPs are
reproducible between sub-samples and are more reproducible as compared to
single scale patterns. We also compare our method with existing hierarchical
community detection approaches. Our method also provides novel insight into the
functional organization of the human brain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08374</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08374</id><created>2019-06-19</created><authors><author><keyname>Mokhtar</keyname><forenames>Maizura</forenames></author><author><keyname>Robu</keyname><forenames>Valentin</forenames></author><author><keyname>Flynn</keyname><forenames>David</forenames></author><author><keyname>Higgins</keyname><forenames>Ciaran</forenames></author><author><keyname>Whyte</keyname><forenames>Jim</forenames></author><author><keyname>Loughran</keyname><forenames>Caroline</forenames></author><author><keyname>Fulton</keyname><forenames>Fiona</forenames></author></authors><title>Predicting the Voltage Distribution for Low Voltage Networks using Deep
  Learning</title><categories>cs.LG eess.SP</categories><comments>9th IEEE International Conference on Innovative Smart Grid
  Technologies (IEEE ISGT Europe 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The energy landscape for the Low-Voltage (LV) networks are beginning to
change; changes resulted from the increase penetration of renewables and/or the
predicted increase of electric vehicles charging at home. The previously
passive `fit-and-forget' approach to LV network management will be inefficient
to ensure its effective operations. A more adaptive approach is required that
includes the prediction of risk and capacity of the circuits. Many of the
proposed methods require full observability of the networks, motivating the
installations of smart meters and advance metering infrastructure in many
countries. However, the expectation of `perfect data' is unrealistic in
operational reality. Smart meter (SM) roll-out can have its issues, which may
resulted in low-likelihood of full SM coverage for all LV networks. This,
together with privacy requirements that limit the availability of high
granularity demand power data have resulted in the low uptake of many of the
presented methods. To address this issue, Deep Learning Neural Network is
proposed to predict the voltage distribution with partial SM coverage. The
results show that SM measurements from key locations are sufficient for
effective prediction of voltage distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08383</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08383</id><created>2019-06-19</created><updated>2019-09-17</updated><authors><author><keyname>Zhang</keyname><forenames>Kaiqing</forenames></author><author><keyname>Koppel</keyname><forenames>Alec</forenames></author><author><keyname>Zhu</keyname><forenames>Hao</forenames></author><author><keyname>Ba&#x15f;ar</keyname><forenames>Tamer</forenames></author></authors><title>Global Convergence of Policy Gradient Methods to (Almost) Locally
  Optimal Policies</title><categories>math.OC cs.LG cs.SY eess.SY math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Policy gradient (PG) methods are a widely used reinforcement learning
methodology in many applications such as video games, autonomous driving, and
robotics. In spite of its empirical success, a rigorous understanding of the
global convergence of PG methods is lacking in the literature. In this work, we
close the gap by viewing PG methods from a nonconvex optimization perspective.
In particular, we propose a new variant of PG methods for infinite-horizon
problems that uses a random rollout horizon for the Monte-Carlo estimation of
the policy gradient. This method then yields an unbiased estimate of the policy
gradient with bounded variance, which enables the tools from nonconvex
optimization to be applied to establish global convergence. Employing this
perspective, we first recover the convergence results with rates to the
stationary-point policies in the literature. More interestingly, motivated by
advances in nonconvex optimization, we modify the proposed PG method by
introducing periodically enlarged stepsizes. The modified algorithm is shown to
escape saddle points under mild assumptions on the reward and the policy
parameterization. Under a further strict saddle points assumption, this result
establishes convergence to essentially locally-optimal policies of the
underlying problem, and thus bridges the gap in existing literature on the
convergence of PG methods. Results from experiments on the inverted pendulum
are then provided to corroborate our theory, namely, by slightly reshaping the
reward function to satisfy our assumption, unfavorable saddle points can be
avoided and better limit points can be attained. Intriguingly, this empirical
finding justifies the benefit of reward-reshaping from a nonconvex optimization
perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08407</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08407</id><created>2019-06-19</created><authors><author><keyname>Hwang</keyname><forenames>Min-Jae</forenames></author><author><keyname>Kang</keyname><forenames>Hong-Goo</forenames></author></authors><title>Parameter Enhancement for MELP Speech Codec in Noisy Communication
  Environment</title><categories>eess.AS cs.SD eess.SP</categories><comments>Accepted to the conference of INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a deep learning (DL)-based parameter enhancement
method for a mixed excitation linear prediction (MELP) speech codec in noisy
communication environment. Unlike conventional speech enhancement modules that
are designed to obtain clean speech signal by removing noise components before
speech codec processing, the proposed method directly enhances codec parameters
on either the encoder or decoder side. As the proposed method has been
implemented by a small network without any additional processes required in
conventional enhancement systems, e.g., time-frequency (T-F) analysis/synthesis
modules, its computational complexity is very low. By enhancing the
noise-corrupted codec parameters with the proposed DL framework, we achieved an
enhancement system that is much simpler and faster than conventional T-F
mask-based speech enhancement methods, while the quality of its performance
remains similar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08411</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08411</id><created>2019-06-19</created><updated>2019-10-27</updated><authors><author><keyname>Gui</keyname><forenames>Qiang</forenames></author><author><keyname>Su</keyname><forenames>Hao</forenames></author><author><keyname>Feng</keyname><forenames>Donghan</forenames></author><author><keyname>Zhou</keyname><forenames>Yun</forenames></author><author><keyname>Xu</keyname><forenames>Ran</forenames></author><author><keyname>Lei</keyname><forenames>Ting</forenames></author></authors><title>A novel linear battery energy storage system (BESS) life loss
  calculation model for BESS-integrated wind farm in scheduled power tracking</title><categories>eess.SP cs.SY eess.SY math.OC</categories><comments>This article has been accepted in the 2019 International Conference
  on Renewable Power Generation (RPG 2019), Shanghai, China, October 24-25,
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, rapid development of battery technology makes it feasible to
integrate renewable generations with battery energy storage system (BESS). The
consideration of BESS life loss for different BESS application scenarios is
economic imperative. In this paper, a novel linear BESS life loss calculation
model for BESS-integrated wind farm in scheduled power tracking is proposed.
Firstly, based on the life cycle times-depth of discharge (DOD) relation-curve,
the BESS life loss coefficient for unit throughput energy with different state
of charge (SOC) can be determined from the life cycle times-DOD relation-curve
fitting function directly. Secondly, as unidirectional variation of SOC in a
single time step, the BESS life loss can be calculated through integration of
the life loss coefficient-SOC relation function. A linear BESS life loss
calculation model is established through self-optimal piecewise linearization
of the primitive function of the life loss coefficient-SOC relation function.
Thirdly, the proposed life loss calculation model is incorporated in the
BESS-integrated wind farm scheduled power tracking optimization. Case studies
demonstrate that with the proposed method, the BESS life loss item can be
incorporated in the optimization model effectively, and the scheduled power
tracking cost of the BESS-integrated wind farm can be determined and optimized
more comprehensively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08415</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08415</id><created>2019-06-19</created><authors><author><keyname>Gu</keyname><forenames>Yue</forenames></author><author><keyname>Du</keyname><forenames>Zhihao</forenames></author><author><keyname>Zhang</keyname><forenames>Hui</forenames></author><author><keyname>Zhang</keyname><forenames>Xueliang</forenames></author></authors><title>A Monaural Speech Enhancement Method for Robust Small-Footprint Keyword
  Spotting</title><categories>cs.SD cs.LG cs.MM eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robustness against noise is critical for keyword spotting (KWS) in real-world
environments. To improve the robustness, a speech enhancement front-end is
involved. Instead of treating the speech enhancement as a separated
preprocessing before the KWS system, in this study, a pre-trained speech
enhancement front-end and a convolutional neural networks (CNNs) based KWS
system are concatenated, where a feature transformation block is used to
transform the output from the enhancement front-end into the KWS system's
input. The whole model is trained jointly, thus the linguistic and other useful
information from the KWS system can be back-propagated to the enhancement
front-end to improve its performance. To fit the small-footprint device, a
novel convolution recurrent network is proposed, which needs fewer parameters
and computation and does not degrade performance. Furthermore, by changing the
input features from the power spectrogram to Mel-spectrogram, less computation
and better performance are obtained. our experimental results demonstrate that
the proposed method significantly improves the KWS system with respect to noise
robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08418</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08418</id><created>2019-06-19</created><authors><author><keyname>Zhu</keyname><forenames>Jiang</forenames></author><author><keyname>Zhang</keyname><forenames>Qi</forenames></author><author><keyname>Jin</keyname><forenames>Benzhou</forenames></author><author><keyname>Xu</keyname><forenames>Zhiwei</forenames></author></authors><title>Gridless Variational Line Spectral Estimation with Multiple Measurement
  Vector from Quantized Samples</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Utilizing multisnapshot quantized data in line spectral estimation (LSE) for
improving the estimation accuracy is of vital importance in signal processing,
e.g., channel estimation in energy efficient massive MIMO systems and direction
of arrival estimation. Recently, gridless variational line spectral estimation
(VALSE) treating frequencies as random variables has been proposed. VALSE has
the advantage of low computation complexity, high accuracy, automatically
estimating the model order and noise variance. In this paper, we utilize
expectation propagation (EP) to develop multi snapshot VALSE-EP (MVALSE-EP) to
deal with the LSE from multisnapshot quantized data. The basic idea of
MVALSE-EP is to iteratively approximate the quantized model as a sequence of
simple multiple pseudo unquantized models sharing the same frequency profile,
where the noise in each pseudo linear model is i.i.d. and heteroscedastic
(different components having different variance). Moreover, the Cram\'{e}r Rao
bound (CRB) is derived as a benchmark performance of the proposed algorithm.
Finally, numerical results demonstrate the effectiveness of MVALSE-EP, in
particular for the application of direction of arrival (DOA) problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08438</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08438</id><created>2019-06-20</created><authors><author><keyname>Zhou</keyname><forenames>Xiaobo</forenames></author><author><keyname>Yan</keyname><forenames>Shihao</forenames></author><author><keyname>Shu</keyname><forenames>Feng</forenames></author><author><keyname>Chen</keyname><forenames>Riqing</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author></authors><title>UAV-Enabled Covert Wireless Data Collection</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers unmanned aerial vehicle (UAV) networks for collecting
data covertly from ground users. The full-duplex UAV intends to gather critical
information from a scheduled user (SU) through wireless communication and
generate artificial noise (AN) with random transmit power in order to ensure a
negligible probability of the SU's transmission being detected by the
unscheduled users (USUs). To enhance the system performance, we jointly design
the UAV's trajectory and its maximum AN transmit power together with the user
scheduling strategy subject to practical constraints, e.g., a covertness
constraint, which is explicitly determined by analyzing each USU's detection
performance, and a binary constraint induced by user scheduling. The formulated
design problem is a mixed-integer non-convex optimization problem, which is
challenging to solve directly, but tackled by our developed penalty successive
convex approximation (P-SCA) scheme. An efficient UAV trajectory initialization
is also presented based on the Successive Hover-and-Fly (SHAF) trajectory,
which also serves as a benchmark scheme. Our examination shows the developed
P-SCA scheme significantly outperforms the benchmark scheme in terms of
achieving a higher max-min average transmission rate from all the SUs to the
UAV.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08451</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08451</id><created>2019-06-20</created><authors><author><keyname>Das</keyname><forenames>Proloy</forenames></author><author><keyname>Babadi</keyname><forenames>Behtash</forenames></author></authors><title>Multitaper Spectral Analysis of Neuronal Spiking Activity Driven by
  Latent Stationary Processes</title><categories>eess.SP cs.IT math.IT q-bio.NC stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Investigating the spectral properties of the neural covariates that underlie
spiking activity is an important problem in systems neuroscience, as it allows
to study the role of brain rhythms in cognitive functions. While the spectral
estimation of continuous time-series is a well-established domain, computing
the spectral representation of these neural covariates from spiking data sets
forth various challenges due to the intrinsic non-linearities involved. In this
paper, we address this problem by proposing a variant of the multitaper method
specifically tailored for point process data. To this end, we construct
auxiliary spiking statistics from which the eigen-spectra of the underlying
latent process can be directly inferred using maximum likelihood estimation,
and thereby the multitaper estimate can be efficiently computed. Comparison of
our proposed technique to existing methods using simulated data reveals
significant gains in terms of the bias-variance trade-off.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08464</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08464</id><created>2019-06-20</created><authors><author><keyname>Moghadam</keyname><forenames>Majid</forenames></author><author><keyname>Elkaim</keyname><forenames>Gabriel Hugh</forenames></author></authors><title>A Hierarchical Architecture for Sequential Decision-Making in Autonomous
  Driving using Deep Reinforcement Learning</title><categories>cs.RO cs.AI cs.LG cs.SY eess.SY</categories><comments>Appears in ICML 2019 workshop on Real-world Sequential Decision
  Making: Reinforcement Learning and Beyond. Source code available in:
  https://github.com/MajidMoghadam2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tactical decision making is a critical feature for advanced driving systems,
that incorporates several challenges such as complexity of the uncertain
environment and reliability of the autonomous system. In this work, we develop
a multi-modal architecture that includes the environmental modeling of ego
surrounding and train a deep reinforcement learning (DRL) agent that yields
consistent performance in stochastic highway driving scenarios. To this end, we
feed the occupancy grid of the ego surrounding into the DRL agent and obtain
the high-level sequential commands (i.e. lane change) to send them to
lower-level controllers. We will show that dividing the autonomous driving
problem into a multi-layer control architecture enables us to leverage the AI
power to solve each layer separately and achieve an admissible reliability
score. Comparing with end-to-end approaches, this architecture enables us to
end up with a more reliable system which can be implemented in actual
self-driving cars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08469</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08469</id><created>2019-06-20</created><authors><author><keyname>Chou</keyname><forenames>Fang-Chieh</forenames></author><author><keyname>Lin</keyname><forenames>Tsung-Han</forenames></author><author><keyname>Cui</keyname><forenames>Henggang</forenames></author><author><keyname>Radosavljevic</keyname><forenames>Vladan</forenames></author><author><keyname>Nguyen</keyname><forenames>Thi</forenames></author><author><keyname>Huang</keyname><forenames>Tzu-Kuo</forenames></author><author><keyname>Niedoba</keyname><forenames>Matthew</forenames></author><author><keyname>Schneider</keyname><forenames>Jeff</forenames></author><author><keyname>Djuric</keyname><forenames>Nemanja</forenames></author></authors><title>Predicting Motion of Vulnerable Road Users using High-Definition Maps
  and Efficient ConvNets</title><categories>cs.RO cs.CV cs.LG eess.IV</categories><comments>Shortened version accepted at the workshop on 'Machine Learning for
  Intelligent Transportation Systems' at Conference on Neural Information
  Processing Systems (MLITS), Montreal, Canada, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following detection and tracking of traffic actors, prediction of their
future motion is the next critical component of a self-driving vehicle (SDV)
technology, allowing the SDV to operate safely and efficiently in its
environment. This is particularly important when it comes to vulnerable road
users (VRUs), such as pedestrians and bicyclists. These actors need to be
handled with special care due to an increased risk of injury, as well as the
fact that their behavior is less predictable than that of motorized actors. To
address this issue, in this paper we present a deep learning-based method for
predicting VRU movement, where we rasterize high-definition maps and actor's
surroundings into bird's-eye view image used as an input to deep convolutional
networks. In addition, we propose a fast architecture suitable for real-time
inference, and present a detailed ablation study of various rasterization
choices. The results strongly indicate benefits of using the proposed approach
for motion prediction of VRUs, both in terms of accuracy and latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08497</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08497</id><created>2019-06-20</created><authors><author><keyname>Upadhaya</keyname><forenames>Bishal</forenames></author><author><keyname>Feng</keyname><forenames>Donghan</forenames></author><author><keyname>Zhou</keyname><forenames>Yun</forenames></author><author><keyname>Gui</keyname><forenames>Qiang</forenames></author><author><keyname>Zhao</keyname><forenames>Xiaojin</forenames></author><author><keyname>Wu</keyname><forenames>Dan</forenames></author></authors><title>Optimal Decision Making Model of Battery Energy Storage-Assisted
  Electric Vehicle Charging Station Considering Incentive Demand Response</title><categories>eess.SY cs.SY eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering large scale implementation of electric vehicles (EVs), public EV
charging stations are served as fuel tanks for EVs to meet the need of longer
travelling distance and overcome the shortage of private charging piles. The
allocation of local battery energy storage (BES) can enhance the flexibility of
the EV charging station. This paper proposes an optimal decision making model
of the BES-assisted EV charging station considering the incentive demand
response. Firstly, the detailed models of the BES-assisted EV charging station
are presented. Secondly, as a representative incentive demand response, the
emergency demand response (EDR) model is introduced. Thirdly, based on the
charging load forecast data, an optimal decision making model of the
BES-assisted EV charging station considering the EDR to maximize the charging
station's operating profit is established. Finally, the feasibility of the
proposed method is verified through case studies. The conclusions of this paper
are as follows: 1) Through the optimal decision making model, correct and
profitable EDR participation decision can be determined for the BES-assisted EV
charging station effectively. 2) Local BES in the EV charging station can
improve the charging station's ability to participate in the EDR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08501</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08501</id><created>2019-06-20</created><authors><author><keyname>Shi</keyname><forenames>Chengzhi</forenames></author><author><keyname>Liu</keyname><forenames>Jihong</forenames></author><author><keyname>Chen</keyname><forenames>Dali</forenames></author></authors><title>A Segmentation-Oriented Inter-Class Transfer Method: Application to
  Retinal Vessel Segmentation</title><categories>eess.IV cs.CV</categories><msc-class>68-06</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Retinal vessel segmentation, as a principal nonintrusive diagnose method for
ophthalmology diseases or diabetics, suffers from data scarcity due to
requiring pixel-wise labels. In this paper, we proposed a convenient
patch-based two-stage transfer method. First, based on the information
bottleneck theory, we insert one dimensionality-reduced layer for task-specific
feature space. Next, the semi-supervised clustering is conducted to select
instances, from different sources databases, possessing similarities in the
feature space. Surprisingly, we empirically demonstrate that images from
different classes possessing similarities contribute to better performance than
some same-class instances. The proposed framework achieved an accuracy of 97%,
96.8%, and 96.77% on DRIVE, STARE, and HRF respectively, outperforming current
methods and independent human observers (DRIVE (96.37%) and STARE (93.39%)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08512</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08512</id><created>2019-06-20</created><authors><author><keyname>Kim</keyname><forenames>Jong Wook</forenames></author><author><keyname>Bello</keyname><forenames>Juan Pablo</forenames></author></authors><title>Adversarial Learning for Improved Onsets and Frames Music Transcription</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic music transcription is considered to be one of the hardest problems
in music information retrieval, yet recent deep learning approaches have
achieved substantial improvements on transcription performance. These
approaches commonly employ supervised learning models that predict various
time-frequency representations, by minimizing element-wise losses such as the
cross entropy function. However, applying the loss in this manner assumes
conditional independence of each label given the input, and thus cannot
accurately express inter-label dependencies. To address this issue, we
introduce an adversarial training scheme that operates directly on the
time-frequency representations and makes the output distribution closer to the
ground-truth. Through adversarial learning, we achieve a consistent improvement
in both frame-level and note-level metrics over Onsets and Frames, a
state-of-the-art music transcription model. Our results show that adversarial
learning can significantly reduce the error rate while increasing the
confidence of the model estimations. Our approach is generic and applicable to
any transcription model based on multi-label predictions, which are very common
in music signal analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08546</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08546</id><created>2019-06-20</created><authors><author><keyname>Paulen</keyname><forenames>Radoslav</forenames></author><author><keyname>Fikar</keyname><forenames>Miroslav</forenames></author></authors><title>Dual-control based approach to batch process operation under uncertainty
  based on optimality-conditions parameterization</title><categories>eess.SY cs.SY math.OC</categories><doi>10.1021/acs.iecr.9b00638</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a scheme for dual robust control of batch processes under
parametric uncertainty. The dual-control paradigm arises in the context of
adaptive control. A trade-off should be decided between the control actions
that (robustly) optimize the plant performance and between those that excite
the plant such that unknown plant model parameters can be learned precisely
enough to increase the robust performance of the plant. Some recently proposed
approaches can be used to tackle this problem, however, this will be done at
the price of conservativeness or significant computational burden. In order to
increase computational efficiency, we propose a scheme that uses parameterized
conditions of optimality in the adaptive predictive-control fashion. The dual
features of the controller are incorporated through scenario-based
(multi-stage) approach, which allows for modeling of the adaptive robust
decision problem and for projecting this decision into predictions of the
controller. The proposed approach is illustrated on a case study from batch
membrane filtration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08556</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08556</id><created>2019-06-20</created><authors><author><keyname>Vestman</keyname><forenames>Ville</forenames></author><author><keyname>Lee</keyname><forenames>Kong Aik</forenames></author><author><keyname>Kinnunen</keyname><forenames>Tomi H.</forenames></author><author><keyname>Koshinaka</keyname><forenames>Takafumi</forenames></author></authors><title>Unleashing the Unused Potential of I-Vectors Enabled by GPU Acceleration</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>Accepted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker embeddings are continuous-value vector representations that allow
easy comparison between voices of speakers with simple geometric operations.
Among others, i-vector and x-vector have emerged as the mainstream methods for
speaker embedding. In this paper, we illustrate the use of modern computation
platform to harness the benefit of GPU acceleration for i-vector extraction. In
particular, we achieve an acceleration of 3000 times in frame posterior
computation compared to real time and 25 times in training the i-vector
extractor compared to the CPU baseline from Kaldi toolkit. This significant
speed-up allows the exploration of ideas that were hitherto impossible. In
particular, we show that it is beneficial to update the universal background
model (UBM) and re-compute frame alignments while training the i-vector
extractor. Additionally, we are able to study different variations of i-vector
extractors more rigorously than before. In this process, we reveal some
undocumented details of Kaldi's i-vector extractor and show that it outperforms
the standard formulation by a margin of 1 to 2% when tested with VoxCeleb
speaker verification protocol. All of our findings are asserted by ensemble
averaging the results from multiple runs with random start.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08575</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08575</id><created>2019-06-20</created><authors><author><keyname>Zou</keyname><forenames>Junni</forenames></author><author><keyname>Li</keyname><forenames>Chenglin</forenames></author><author><keyname>Liu</keyname><forenames>Chengming</forenames></author><author><keyname>Yang</keyname><forenames>Qin</forenames></author><author><keyname>Xiong</keyname><forenames>Hongkai</forenames></author><author><keyname>Steinbach</keyname><forenames>Eckehard</forenames></author></authors><title>Probabilistic Tile Visibility-Based Server-Side Rate Adaptation for
  Adaptive 360-Degree Video Streaming</title><categories>cs.MM eess.IV</categories><comments>33 pages (single column and double space) with 15 figures, submitted
  to IEEE Journal of Selected Topics in Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the server-side rate adaptation problem for streaming
tile-based adaptive 360-degree videos to multiple users who are competing for
transmission resources at the network bottleneck. Specifically, we develop a
convolutional neural network (CNN)-based viewpoint prediction model to capture
the nonlinear relationship between the future and historical viewpoints. A
Laplace distribution model is utilized to characterize the probability
distribution of the prediction error. Given the predicted viewpoint, we then
map the viewport in the spherical space into its corresponding planar
projection in the 2-D plane, and further derive the visibility probability of
each tile based on the planar projection and the prediction error probability.
According to the visibility probability, tiles are classified as viewport,
marginal and invisible tiles. The server-side tile rate allocation problem for
multiple users is then formulated as a non-linear discrete optimization problem
to minimize the overall received video distortion of all users and the quality
difference between the viewport and marginal tiles of each user, subject to the
transmission capacity constraints and users' specific viewport requirements. We
develop a steepest descent algorithm to solve this non-linear discrete
optimization problem, by initializing the feasible starting point in accordance
with the optimal solution of its continuous relaxation. Extensive experimental
results show that the proposed algorithm can achieve a near-optimal solution,
and outperforms the existing rate adaptation schemes for tile-based adaptive
360-video streaming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08585</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08585</id><created>2019-06-20</created><authors><author><keyname>King</keyname><forenames>D.</forenames></author><author><keyname>Farrel</keyname><forenames>A.</forenames></author><author><keyname>Nishida-King</keyname><forenames>Emiko</forenames></author><author><keyname>Casellas</keyname><forenames>R.</forenames></author><author><keyname>Velasco</keyname><forenames>L.</forenames></author><author><keyname>Nejabati</keyname><forenames>R.</forenames></author><author><keyname>Lord</keyname><forenames>A.</forenames></author></authors><title>The dichotomy of distributed and centralized control: METRO-HAUL, when
  control planes collide for 5G networks</title><categories>eess.SP cs.NI</categories><journal-ref>Optical Switching and Networking, Volume 33, July 2019, Pages
  49-55</journal-ref><doi>10.1016/j.osn.2018.11.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automating the provisioning of 5G services, deployed over a heterogeneous
infrastructure (in terms of domains, technologies, and management platforms),
remains a complex task, yet driven by the constant need to provide end-to-end
connections at network slices at reducing costs and service deployment time. At
the same time, such services are increasingly conceived around interconnected
functions and require allocation of computing, storage, and networking
resources.
  The METRO-HAUL 5G research initiative acknowledges the need for automation
and strives to develop an orchestration platform for services and resources
that extends, integrates, and builds on top of existing approaches,
macroscopically adopting Transport Software Defined Networking principles, and
leveraging the programmability and open control of Transport SDN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08598</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08598</id><created>2019-06-04</created><authors><author><keyname>wang</keyname><forenames>Bo</forenames></author><author><keyname>Hu</keyname><forenames>Hao</forenames></author><author><keyname>Zhang</keyname><forenames>Caixia</forenames></author></authors><title>Companion Surface of Danger Cylinder and its Role in Solution Variation
  of P3P Problem</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally the danger cylinder is intimately related to the solution
stability in P3P problem. In this work, we show that the danger cylinder is
also closely related to the multiple-solution phenomenon. More specifically, we
show when the optical center lies on the danger cylinder, of the 3 possible P3P
solutions, i.e., one double solution, and two other solutions, the optical
center of the double solution still lies on the danger cylinder, but the
optical centers of the other two solutions no longer lie on the danger
cylinder. And when the optical center moves on the danger cylinder, accordingly
the optical centers of the two other solutions of the corresponding P3P problem
form a new surface, characterized by a polynomial equation of degree 12 in the
optical center coordinates, called the Companion Surface of Danger Cylinder
(CSDC). That means the danger cylinder always has a companion surface. For the
significance of CSDC, we show that when the optical center passes through the
CSDC, the number of solutions of P3P problem must change by 2. That means CSDC
acts as a delimitating surface of the P3P solution space. These new findings
shed some new lights on the P3P multi-solution phenomenon, an important issue
in PnP study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08621</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08621</id><created>2019-06-20</created><authors><author><keyname>Hollermann</keyname><forenames>Dinah Elena</forenames></author><author><keyname>Goerigk</keyname><forenames>Marc</forenames></author><author><keyname>Hoffrogge</keyname><forenames>D&#xf6;rthe Franzisca</forenames></author><author><keyname>Hennen</keyname><forenames>Maike</forenames></author><author><keyname>Bardow</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>Flexible here-and-now decisions for two-stage multi-objective
  optimization: Method and application to energy system design selection</title><categories>math.OC cs.SY eess.SY</categories><comments>20 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The synthesis of energy systems is a two-stage optimization problem where
design decisions have to be implemented here-and-now (first stage), while for
the operation of installed components, we can wait-and-see (second stage). To
identify a sustainable design, we need to account for both economical and
environmental criteria leading to multi-objective optimization problems.
However, multi-objective optimization leads not to one optimal design but to
multiple Pareto-efficient design options in general. Thus, the decision maker
usually has to decide manually which design should finally be implemented.
  In this paper, we propose the flexible here-and-now decision (flex-hand)
approach for automatic identification of one single design for multi-objective
optimization. The approach minimizes the distance of the Pareto front based on
one fixed design to the Pareto front allowing multiple designs. Uncertainty
regarding parameters of future operations can be easily included through a
robust extension of the flex-hand approach.
  Results of a real-world case study show that the obtained design is highly
flexible to adapt operation to the considered objective functions. Thus, the
design provides an energy system with the ability to adapt to a changing focus
in decision criteria, e. g., due to changing political aims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08629</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08629</id><created>2019-06-19</created><updated>2019-10-22</updated><authors><author><keyname>Kim</keyname><forenames>Heetae</forenames></author><author><keyname>Lee</keyname><forenames>Mi Jin</forenames></author><author><keyname>Lee</keyname><forenames>Sang Hoon</forenames></author><author><keyname>Son</keyname><forenames>Seung-Woo</forenames></author></authors><title>On structural and dynamical factors determining the integrated basin
  instability of power-grid nodes</title><categories>physics.soc-ph eess.SP</categories><comments>11 pages, 5 figures, 3 tables</comments><journal-ref>Chaos 29, 103132 (2019)</journal-ref><doi>10.1063/1.5115532</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In electric power systems delivering alternating current, it is essential to
maintain its synchrony of the phase with the rated frequency. The
synchronization stability that quantifies how well the power-grid system
recovers its synchrony against perturbation depends on various factors. As an
intrinsic factor that we can design and control, the transmission capacity of
the power grid affects the synchronization stability. Therefore, the transition
pattern of the synchronization stability with the different levels of
transmission capacity against external perturbation provides the stereoscopic
perspective to understand the synchronization behavior of power grids. In this
study, we extensively investigate the factors affecting the synchronization
stability transition by using the concept of basin stability as a function of
the transmission capacity. For a systematic approach, we introduce the
integrated basin instability, which literally adds up the instability values as
the transmission capacity increases. We first take simple 5-node motifs as a
case study of building blocks of power grids, and a more realistic IEEE 24-bus
model to highlight the complexity of decisive factors. We find that both
structural properties such as gate keepers in network topology and dynamical
properties such as large power input/output at nodes cause synchronization
instability. The results suggest that evenly distributed power generation and
avoidance of bottlenecks can improve the overall synchronization stability of
power-grid systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08634</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08634</id><created>2019-06-18</created><updated>2019-07-27</updated><authors><author><keyname>Toghi</keyname><forenames>Behrad</forenames></author><author><keyname>Saifuddin</keyname><forenames>Md</forenames></author><author><keyname>Mughal</keyname><forenames>M. O.</forenames></author><author><keyname>Fallah</keyname><forenames>Yaser P.</forenames></author></authors><title>Spatio-temporal Dynamics of Cellular V2X Communication in Dense
  Vehicular Networks</title><categories>eess.SY cs.SY eess.SP</categories><comments>Accepted to 2019 IEEE Connected and Automated Vehicles Symposium
  (IEEE CAVS-2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular Vehicle-to-everything (C-V2X) communication is a major V2X solution
proposed and developed by the 3rd Generation Partnership Project (3GPP). Our
previous work has studied scalability aspects of C-V2X and demonstrated its
potential for accommodating large numbers of vehicles in dense vehicular
scenarios. However, existing studies in the scientific literature mostly have a
network-level approach to the problem and do not assess the temporal and
spatial dynamics of C-V2X networks in heavy network load situations. In this
work we shed light on the spatio-temporal characteristics of these networks and
investigate the effectiveness of the congestion control algorithm in dense
vehicular ad-hoc networks (VANETs) in terms of settling time, stability, and
reliability to be employed for the purpose of safety-critical vehicular
applications, where latency plays a major role.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08645</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08645</id><created>2019-06-19</created><authors><author><keyname>Bononi</keyname><forenames>A.</forenames></author><author><keyname>Antona</keyname><forenames>J. -C.</forenames></author><author><keyname>M&#xe9;seguer</keyname><forenames>A. Carbo</forenames></author><author><keyname>Serena</keyname><forenames>P.</forenames></author></authors><title>A model for the generalized droop formula</title><categories>eess.SP</categories><comments>submitted to ECOC 2019, with typos corrected in red in this ARXIV
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a new analytical model that fully justifies the recently disclosed
Generalized Droop Formula of the nonlinear signal-to-noise (SNR) ratio in
very-long submarine links with power-mode amplifiers, and show its relation
with the Gaussian-Noise model SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08647</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08647</id><created>2019-06-20</created><updated>2019-10-15</updated><authors><author><keyname>Biswas</keyname><forenames>Astik</forenames></author><author><keyname>Y&#x131;lmaz</keyname><forenames>Emre</forenames></author><author><keyname>de Wet</keyname><forenames>Febe</forenames></author><author><keyname>van der Westhuizen</keyname><forenames>Ewald</forenames></author><author><keyname>Niesler</keyname><forenames>Thomas</forenames></author></authors><title>Semi-supervised acoustic model training for five-lingual code-switched
  ASR</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted for publication at Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents recent progress in the acoustic modelling of
under-resourced code-switched (CS) speech in multiple South African languages.
We consider two approaches. The first constructs separate bilingual acoustic
models corresponding to language pairs (English-isiZulu, English-isiXhosa,
English-Setswana and English-Sesotho). The second constructs a single unified
five-lingual acoustic model representing all the languages (English, isiZulu,
isiXhosa, Setswana and Sesotho). For these two approaches we consider the
effectiveness of semi-supervised training to increase the size of the very
sparse acoustic training sets. Using approximately 11 hours of untranscribed
speech, we show that both approaches benefit from semi-supervised training. The
bilingual TDNN-F acoustic models also benefit from the addition of CNN layers
(CNN-TDNN-F), while the five-lingual system does not show any significant
improvement. Furthermore, because English is common to all language pairs in
our data, it dominates when training a unified language model, leading to
improved English ASR performance at the expense of the other languages.
Nevertheless, the five-lingual model offers flexibility because it can process
more than two languages simultaneously, and is therefore an attractive option
as an automatic transcription system in a semi-supervised training pipeline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08662</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08662</id><created>2019-06-20</created><authors><author><keyname>Wang</keyname><forenames>Guan</forenames></author><author><keyname>Hu</keyname><forenames>Jianming</forenames></author><author><keyname>Li</keyname><forenames>Zhiheng</forenames></author><author><keyname>Li</keyname><forenames>Li</forenames></author></authors><title>Cooperative Lane Changing via Deep Reinforcement Learning</title><categories>eess.SY cs.AI cs.LG cs.SY</categories><comments>7 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study how to learn an appropriate lane changing strategy
for autonomous vehicles by using deep reinforcement learning. We show that the
reward of the system should consider the overall traffic efficiency instead of
the travel efficiency of an individual vehicle. In summary, cooperation leads
to a more harmonic and efficient traffic system rather than competition
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08673</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08673</id><created>2019-06-19</created><authors><author><keyname>Song</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Yan</forenames></author><author><keyname>Huang</keyname><forenames>Dongmei</forenames></author><author><keyname>Liotta</keyname><forenames>Antonio</forenames></author><author><keyname>Perra</keyname><forenames>Cristian</forenames></author></authors><title>Enhancement of Underwater Images with Statistical Model of Background
  Light and Optimization of Transmission Map</title><categories>eess.IV cs.MM</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Underwater images often have severe quality degradation and distortion due to
light absorption and scattering in the water medium. A hazed image formation
model is widely used to restore the image quality. It depends on two optical
parameters: the background light and the transmission map. Underwater images
can also be enhanced by color and contrast correction from the perspective of
image processing. In this paper, we propose an effective underwater image
enhancement method for underwater images in composition of underwater image
restoration and color correction. Firstly, a manually annotated background
lights (MABLs) database is developed. With reference to the relationship
between MABLs and the histogram distributions of various underwater images,
robust statistical models of BLs estimation are provided. Next, the TM of R
channel is roughly estimated based on the new underwater dark channel prior via
the statistic of clear and high resolution underwater images, then a scene
depth map based on the underwater light attenuation prior and an adjusted
reversed saturation map are applied to compensate and modify the coarse TM of R
channel. Next, TMs of G-B channels are estimated based on the difference of
attenuation ratios between R channel and G-B channels. Finally, to improve the
color and contrast of the restored image with a natural appearance, a variation
of white balance is introduced as post-processing. In order to guide the
priority of underwater image enhancement, sufficient evaluations are conducted
to discuss the impacts of the key parameters including BL and TM, and the
importance of the color correction. Comparisons with other state-of-the-art
methods demonstrate that our proposed underwater image enhancement method can
achieve higher accuracy of estimated BLs, less computation time, more superior
performance, and more valuable information retention.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08713</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08713</id><created>2019-06-20</created><authors><author><keyname>Yamac</keyname><forenames>Mehmet</forenames></author><author><keyname>Ahishali</keyname><forenames>Mete</forenames></author><author><keyname>Passalis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Raitoharju</keyname><forenames>Jenni</forenames></author><author><keyname>Sankur</keyname><forenames>Bulent</forenames></author><author><keyname>Gabbouj</keyname><forenames>Moncef</forenames></author></authors><title>Reversible Privacy Preservation using Multi-level Encryption and
  Compressive Sensing</title><categories>cs.CR cs.CV eess.IV eess.SP</categories><comments>5 pages, submitted/accepted, EUSIPCO 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Security monitoring via ubiquitous cameras and their more extended in
intelligent buildings stand to gain from advances in signal processing and
machine learning. While these innovative and ground-breaking applications can
be considered as a boon, at the same time they raise significant privacy
concerns. In fact, recent GDPR (General Data Protection Regulation) legislation
has highlighted and become an incentive for privacy-preserving solutions.
Typical privacy-preserving video monitoring schemes address these concerns by
either anonymizing the sensitive data. However, these approaches suffer from
some limitations, since they are usually non-reversible, do not provide
multiple levels of decryption and computationally costly. In this paper, we
provide a novel privacy-preserving method, which is reversible, supports
de-identification at multiple privacy levels, and can efficiently perform data
acquisition, encryption and data hiding by combining multi-level encryption
with compressive sensing. The effectiveness of the proposed approach in
protecting the identity of the users has been validated using the goodness of
reconstruction quality and strong anonymization of the faces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08719</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08719</id><created>2019-06-20</created><authors><author><keyname>Yang</keyname><forenames>Niankai</forenames></author><author><keyname>Chang</keyname><forenames>Dongsik</forenames></author><author><keyname>Amini</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Johnson-Roberson</keyname><forenames>Matthew</forenames></author><author><keyname>Sun</keyname><forenames>Jing</forenames></author></authors><title>Energy Management for Autonomous Underwater Vehicles Using Economic
  Model Predictive Control</title><categories>eess.SY cs.SY math.OC</categories><comments>6 pages, 10 figures, 2 tables, 2019 Annual American Control
  Conference (ACC), July 10-12, 2019, Philadelphia, PA, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of energy-optimal control for autonomous
underwater vehicles (AUVs). To improve the endurance of AUVs, we propose a
novel energy-optimal control scheme based on the economic model predictive
control (MPC) framework. We first formulate a cost function that computes the
energy spent for vehicle operation over a finite-time prediction horizon. Then,
to account for the energy consumption beyond the prediction horizon, a terminal
cost that approximates the energy to reach the goal (energy-to-go) is
incorporated into the MPC cost function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08754</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08754</id><created>2019-06-20</created><authors><author><keyname>Sherry</keyname><forenames>Ferdia</forenames></author><author><keyname>Benning</keyname><forenames>Martin</forenames></author><author><keyname>Reyes</keyname><forenames>Juan Carlos De los</forenames></author><author><keyname>Graves</keyname><forenames>Martin J.</forenames></author><author><keyname>Maierhofer</keyname><forenames>Georg</forenames></author><author><keyname>Williams</keyname><forenames>Guy</forenames></author><author><keyname>Sch&#xf6;nlieb</keyname><forenames>Carola-Bibiane</forenames></author><author><keyname>Ehrhardt</keyname><forenames>Matthias J.</forenames></author></authors><title>Learning the Sampling Pattern for MRI</title><categories>eess.IV cs.CV cs.NA math.NA math.OC</categories><comments>The main document is 10 pages, the supporting document is 2 pages and
  attached at the end of the main document</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discovery of the theory of compressed sensing brought the realisation
that many inverse problems can be solved even when measurements are
&quot;incomplete&quot;. This is particularly interesting in magnetic resonance imaging
(MRI), where long acquisition times can limit its use. In this work, we
consider the problem of learning a sparse sampling pattern that can be used to
optimally balance acquisition time versus quality of the reconstructed image.
We use a supervised learning approach, making the assumption that our training
data is representative enough of new data acquisitions. We demonstrate that
this is indeed the case, even if the training data consists of just 5 training
pairs of measurements and ground-truth images; with a training set of brain
images of size 192 by 192, for instance, one of the learned patterns samples
only 32% of k-space, however results in reconstructions with mean SSIM 0.956 on
a test set of similar images. The proposed framework is general enough to learn
arbitrary sampling patterns, including common patterns such as Cartesian,
spiral and radial sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08773</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08773</id><created>2019-06-20</created><authors><author><keyname>Nawaz</keyname><forenames>Tassadaq</forenames></author><author><keyname>Seminara</keyname><forenames>Marco</forenames></author><author><keyname>Caputo</keyname><forenames>Stefano</forenames></author><author><keyname>Mucchi</keyname><forenames>Lorenzo</forenames></author><author><keyname>Cataliotti</keyname><forenames>Francesco</forenames></author><author><keyname>Catani</keyname><forenames>Jacopo</forenames></author></authors><title>IEEE 802.15.7-Compliant Ultra-low Latency Relaying VLC System for
  Safety-Critical ITS</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The integration of Visible-Light Communications technology (VLC) in
Intelligent Transportation Systems (ITS) is a very promising platform for a
cost-effective implementation of revolutionary ITS and cooperative ITS
protocols. In this paper, we propose an infrastructure-to-vehicle-to-vehicle
(I2V2V) VLC system for ITS, implementing it through a regular LED traffic light
serving as a transmitter and a digital Active Decodeand- Relay (ADR) stage for
decoding and relaying the received information towards further incoming units.
The proposed VLC system targets the challenging and important case of ultra-low
latency ADR transmission of short packets, as this is needed for emerging
applications of automatic braking, car platooning and other critical automatic
and/or assisted driving applications. The experimental validation of the ADR
VLC chain, as well as a thorough statistical analysis of errors distribution in
the transmission, has been performed for short to medium distances, up to 50
meters. The performances of the designed system are evaluated by measuring the
packet error rate (PER) and latency in the whole ADR transmission chain. Our
analysis shows that our system attains ultra-low, sub-ms latencies at 99.9%
confidence level for PER as high as 5 x 10^-3, yet granting a latency below 10
ms even for distances of 50 m. The demonstrated system prototype is compatible
with IEEE 802.15.7 standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08812</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08812</id><created>2019-06-20</created><authors><author><keyname>Yang</keyname><forenames>Zhong</forenames></author><author><keyname>Liu</keyname><forenames>Yuanwei</forenames></author><author><keyname>Chen</keyname><forenames>Yue</forenames></author><author><keyname>Al-Dhahir</keyname><forenames>Naofal</forenames></author></authors><title>Cache-Aided NOMA Mobile Edge Computing: A Reinforcement Learning
  Approach</title><categories>eess.SP</categories><comments>30 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel non-orthogonal multiple access (NOMA) based cache-aided mobile edge
computing (MEC) framework is proposed. For the purpose of efficiently
allocating communication and computation resources to users' computation tasks
requests, we propose a long-short-term memory (LSTM) network to predict the
task popularity. Based on the predicted task popularity, a long-term reward
maximization problem is formulated that involves a joint optimization of the
task offloading decisions, computation resource allocation, and caching
decisions. To tackle this challenging problem, a single-agent Q-learning
(SAQ-learning) algorithm is invoked to learn a long-term resource allocation
strategy. Furthermore, a Bayesian learning automata (BLA) based multi-agent
Q-learning (MAQ-learning) algorithm is proposed for task offloading decisions.
More specifically, a BLA based action select scheme is proposed for the agents
in MAQ-learning to select the optimal action in every state. We prove that the
BLA based action selection scheme is instantaneously self-correcting and the
selected action is an optimal solution for each state. Extensive simulation
results demonstrate that: 1) The prediction error of the proposed LSTMs based
task popularity prediction decreases with increasing learning rate. 2) The
proposed framework significantly outperforms the benchmarks like all local
computing, all offloading computing, and non-cache computing. 3) The proposed
BLA based MAQ-learning achieves an improved performance compared to
conventional reinforcement learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08823</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08823</id><created>2019-06-20</created><authors><author><keyname>Albuquerque</keyname><forenames>Isabela</forenames></author><author><keyname>Monteiro</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Rosanne</keyname><forenames>Olivier</forenames></author><author><keyname>Tiwari</keyname><forenames>Abhishek</forenames></author><author><keyname>Gagnon</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author><author><keyname>Falk</keyname><forenames>Tiago H.</forenames></author></authors><title>Cross-Subject Statistical Shift Estimation for Generalized
  Electroencephalography-based Mental Workload Assessment</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assessment of mental workload in real world conditions is key to ensure the
performance of workers executing tasks which demand sustained attention.
Previous literature has employed electroencephalography (EEG) to this end.
However, EEG correlates of mental workload vary across subjects and physical
strain, thus making it difficult to devise models capable of simultaneously
presenting reliable performance across users. The field of domain adaptation
(DA) aims at developing methods that allow for generalization across different
domains by learning domain-invariant representations. Such DA methods, however,
rely on the so-called covariate shift assumption, which typically does not hold
for EEG-based applications. As such, in this paper we propose a way to measure
the statistical (marginal and conditional) shift observed on data obtained from
different users and use this measure to quantitatively assess the effectiveness
of different adaptation strategies. In particular, we use EEG data collected
from individuals performing a mental task while running in a treadmill and
explore the effects of different normalization strategies commonly used to
mitigate cross-subject variability. We show the effects that different
normalization schemes have on statistical shifts and their relationship with
the accuracy of mental workload prediction as assessed on unseen participants
at train time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08827</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08827</id><created>2019-06-20</created><authors><author><keyname>Uus</keyname><forenames>Alena</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author><author><keyname>Jackson</keyname><forenames>Laurence</forenames></author><author><keyname>Rutherford</keyname><forenames>Mary</forenames></author><author><keyname>Hajnal</keyname><forenames>Joseph V.</forenames></author><author><keyname>Deprez</keyname><forenames>Maria</forenames></author></authors><title>Deformable Slice-to-Volume Registration for Motion Correction in Fetal
  Body MRI</title><categories>physics.med-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In MRI, motion correction for fetal body poses a particular challenge due to
the presence of local non-rigid transformations of organs caused by bending and
stretching. The existing slice-to-volume (SVR) reconstruction methods provide
efficient solution for the fetal brain that undergoes only rigid transformation
or 4D fetal heart with rigid states correlated to cardiac phases. However, for
fetal body reconstruction, rigid registration cannot resolve the issue of
misregistrations due to deformable motion. This results in propagation of
registration error to the reconstructed volume and subsequent degradation of
features. We propose a novel approach for non-rigid motion correction in 3D
volumes based on an extension of the classical SVR method with hierarchical
deformable registration scheme and structure-based outlier rejection.
Deformable SVR (DSVR) method allows high resolution reconstruction of the fetal
trunk and the robust scheme for structure-based rejection of misregistered
slices minimises the impact of registration error. The method performance is
evaluated by comparison to the SVR and patch-to-volume registration methods for
reconstruction of fetal trunk on a series of fetal MRI datasets from 28-30
weeks gestational age (GA) range with varying degree of motion corruption. An
additional phantom study with simulated non-rigid motion is used for the
assessment of consistency of DSVR reconstructed volumes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08833</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08833</id><created>2019-06-20</created><authors><author><keyname>Yan</keyname><forenames>Aimin</forenames></author><author><keyname>Wu</keyname><forenames>Xizeng</forenames></author><author><keyname>Liu</keyname><forenames>Hong</forenames></author></authors><title>Sample phase gradient and fringe phase shift in dual phase grating X-ray
  interferometry</title><categories>physics.med-ph eess.IV physics.optics</categories><comments>submitted to Optics Express for review</comments><doi>10.1364/OE.27.035437</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the key tasks in grating based x-ray phase contrast imaging is to
accurately retrieve local phase gradients of a sample from measured intensity
fringe shifts. To fulfill this task in dual phase grating interferometry, one
needs to know the exact mathematical relationship between the two. In this
work, using intuitive analysis of the sample-generated fringe shifts based on
the beat pattern formation mechanism, the authors derived the formulas relating
sample's phase gradients to fringe phase shifts. These formulas provide also a
design optimization tool for dual phase grating interferometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08834</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08834</id><created>2019-06-20</created><updated>2019-06-24</updated><authors><author><keyname>Singh</keyname><forenames>Kanwar Bharat</forenames></author><author><keyname>Arat</keyname><forenames>Mustafa Ali</forenames></author></authors><title>Deep Learning in the Automotive Industry: Recent Advances and
  Application Examples</title><categories>cs.LG cs.RO eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most exciting technology breakthroughs in the last few years has
been the rise of deep learning. State-of-the-art deep learning models are being
widely deployed in academia and industry, across a variety of areas, from image
analysis to natural language processing. These models have grown from fledgling
research subjects to mature techniques in real-world use. The increasing scale
of data, computational power and the associated algorithmic innovations are the
main drivers for the progress we see in this field. These developments also
have a huge potential for the automotive industry and therefore the interest in
deep learning-based technology is growing. A lot of the product innovations,
such as self-driving cars, parking and lane-change assist or safety functions,
such as autonomous emergency braking, are powered by deep learning algorithms.
Deep learning is poised to offer gains in performance and functionality for
most ADAS (Advanced Driver Assistance System) solutions. Virtual sensing for
vehicle dynamics application, vehicle inspection/heath monitoring, automated
driving and data-driven product development are key areas that are expected to
get the most attention. This article provides an overview of the recent
advances and some associated challenges in deep learning techniques in the
context of automotive applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08839</identifier>
 <datestamp>2019-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08839</id><created>2019-06-20</created><updated>2019-08-22</updated><authors><author><keyname>Campos-Mac&#xed;as</keyname><forenames>Leobardo</forenames></author><author><keyname>Aldana-L&#xf3;pez</keyname><forenames>Rodrigo</forenames></author><author><keyname>de la Guardia</keyname><forenames>Rafael</forenames></author><author><keyname>Parra-Vilchis</keyname><forenames>Jos&#xe9; I.</forenames></author><author><keyname>G&#xf3;mez-Guti&#xe9;rrez</keyname><forenames>David</forenames></author></authors><title>Autonomous Navigation of MAVs in Unknown Cluttered Environments</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an autonomous navigation framework for reaching a goal in
unknown 3D cluttered environments. The framework consists of three main
components. First, a computationally efficient method for mapping the
environment from the disparity measurements obtained from a depth sensor.
Second, a stochastic method to generate a path to a given goal, taking into
account field of view constraints on the space that is assumed to be safe for
navigation. Third, a fast method for the online generation of motion plans,
taking into account the robot's dynamic constraints, model and environmental
uncertainty and disturbances. To highlight the contribution with respect to the
available literature, we provide a qualitative and quantitative comparison with
state of the art methods for reaching a goal and for exploration in unknown
environments, showing the superior performance of our approach. To illustrate
the effectiveness of the proposed framework, we present experiments in multiple
indoors and outdoors environments running the algorithm fully on board and in
real-time, using a robotic platform based on the Intel Ready to Fly drone kit,
which represents the implementation in the most frugal platform for navigation
in unknown cluttered environments demonstrated to date. See video at
https://youtu.be/Wq0e7vF6nZM
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08847</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08847</id><created>2019-06-20</created><authors><author><keyname>Chen</keyname><forenames>Kainan</forenames></author><author><keyname>Jin</keyname><forenames>Wenyu</forenames></author><author><keyname>Desikan</keyname><forenames>Bharadwaj</forenames></author></authors><title>A Signal Subspace Rotation Method for Localization of Multiple Wideband
  Sound Sources</title><categories>eess.AS cs.SD</categories><comments>5 pages, 2019 IEEE Workshop on Applications of Signal Processing to
  Audio and Acoustics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of extending narrowband multichannel sound source
localization algorithms to the wideband case is addressed. The DOA estimation
of narrowband algorithms is based on the estimate of inter-channel phase
differences (IPD) between microphones of the sound sources. A new method for
wideband sound source DOA estimation based on signal subspace rotation is
present. The proposed algorithm normalizes the narrowband signal statistics by
rotating the estimated signal subspace to the wideband counterpart in the
eigenvector domain. Then the wideband DOA estimate can be obtained by
estimating the normalized IPD from these wideband signal statistics. In
addition to requiring less computational complexity compared to repeating the
narrowband algorithms for all relevant frequencies of wideband signals, the
proposed method also does not require any additional prior knowledge. The
experimental results demonstrate the efficacy and the robustness of the
proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08861</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08861</id><created>2019-05-23</created><authors><author><keyname>Roy</keyname><forenames>Deboleena</forenames></author><author><keyname>Panda</keyname><forenames>Priyadarshini</forenames></author><author><keyname>Roy</keyname><forenames>Kaushik</forenames></author></authors><title>Synthesizing Images from Spatio-Temporal Representations using
  Spike-based Backpropagation</title><categories>cs.NE cs.CV cs.LG eess.IV stat.ML</categories><comments>17 pages, 10 Figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spiking neural networks (SNNs) offer a promising alternative to current
artificial neural networks to enable low-power event-driven neuromorphic
hardware. Spike-based neuromorphic applications require processing and
extracting meaningful information from spatio-temporal data, represented as
series of spike trains over time. In this paper, we propose a method to
synthesize images from multiple modalities in a spike-based environment. We use
spiking auto-encoders to convert image and audio inputs into compact
spatio-temporal representations that is then decoded for image synthesis. For
this, we use a direct training algorithm that computes loss on the membrane
potential of the output layer and back-propagates it by using a sigmoid
approximation of the neuron's activation function to enable differentiability.
The spiking autoencoders are benchmarked on MNIST and Fashion-MNIST and achieve
very low reconstruction loss, comparable to ANNs. Then, spiking autoencoders
are trained to learn meaningful spatio-temporal representations of the data,
across the two modalities - audio and visual. We synthesize images from audio
in a spike-based environment by first generating, and then utilizing such
shared multi-modal spatio-temporal representations. Our audio to image
synthesis model is tested on the task of converting TI-46 digits audio samples
to MNIST images. We are able to synthesize images with high fidelity and the
model achieves competitive performance against ANNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08869</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08869</id><created>2019-06-20</created><authors><author><keyname>Farnell</keyname><forenames>Elin</forenames></author><author><keyname>Kvinge</keyname><forenames>Henry</forenames></author><author><keyname>Dixon</keyname><forenames>John P.</forenames></author><author><keyname>Dupuis</keyname><forenames>Julia R.</forenames></author><author><keyname>Kirby</keyname><forenames>Michael</forenames></author><author><keyname>Peterson</keyname><forenames>Chris</forenames></author><author><keyname>Schundler</keyname><forenames>Elizabeth C.</forenames></author><author><keyname>Smith</keyname><forenames>Christian W.</forenames></author></authors><title>A data-driven approach to sampling matrix selection for compressive
  sensing</title><categories>eess.SP cs.LG eess.IV</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampling is a fundamental aspect of any implementation of compressive
sensing. Typically, the choice of sampling method is guided by the
reconstruction basis. However, this approach can be problematic with respect to
certain hardware constraints and is not responsive to domain-specific context.
We propose a method for defining an order for a sampling basis that is optimal
with respect to capturing variance in data, thus allowing for meaningful
sensing at any desired level of compression. We focus on the Walsh-Hadamard
sampling basis for its relevance to hardware constraints, but our approach
applies to any sampling basis of interest. We illustrate the effectiveness of
our method on the Physical Sciences Inc. Fabry-P\'{e}rot interferometer sensor
multispectral dataset, the Johns Hopkins Applied Physics Lab FTIR-based
longwave infrared sensor hyperspectral dataset, and a Colorado State University
Swiss Ranger depth image dataset. The spectral datasets consist of simulant
experiments, including releases of chemicals such as GAA and SF6. We combine
our sampling and reconstruction with the adaptive coherence estimator (ACE) and
bulk coherence for chemical detection and we incorporate an algorithmic
threshold for ACE values to determine the presence or absence of a chemical. We
compare results across sampling methods in this context. We have successful
chemical detection at a compression rate of 90%. For all three datasets, we
compare our sampling approach to standard orderings of sampling basis such as
random, sequency, and an analog of sequency that we term `frequency.' In one
instance, the peak signal to noise ratio was improved by over 30% across a test
set of depth images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08871</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08871</id><created>2019-06-17</created><updated>2019-11-12</updated><authors><author><keyname>Krishna</keyname><forenames>Gautam</forenames></author><author><keyname>Tran</keyname><forenames>Co</forenames></author><author><keyname>Carnahan</keyname><forenames>Mason</forenames></author><author><keyname>Tewfik</keyname><forenames>Ahmed H</forenames></author></authors><title>Advancing Speech Recognition With No Speech Or With Noisy Speech</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>Extended version of our accepted IEEE EUSIPCO 2019 paper with
  additional results for CTC model based recognition. arXiv admin note:
  substantial text overlap with arXiv:1906.08045, arXiv:1906.08044</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we demonstrate end-to-end continuous speech recognition (CSR)
using electroencephalography (EEG) signals with no speech signal as input. An
attention model based automatic speech recognition (ASR) and connectionist
temporal classification (CTC) based ASR systems were implemented for performing
recognition. We further demonstrate CSR for noisy speech by fusing with EEG
features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08873</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08873</id><created>2019-06-18</created><updated>2019-08-31</updated><authors><author><keyname>Tripathi</keyname><forenames>Suraj</forenames></author><author><keyname>Ramesh</keyname><forenames>Abhiram</forenames></author><author><keyname>Kumar</keyname><forenames>Abhay</forenames></author><author><keyname>Singh</keyname><forenames>Chirag</forenames></author><author><keyname>Yenigalla</keyname><forenames>Promod</forenames></author></authors><title>Learning Discriminative features using Center Loss and Reconstruction as
  Regularizer for Speech Emotion Recognition</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>10 pages, Accepted in IJCAI Affective Computing Workshop 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a Convolutional Neural Network (CNN) inspired by
Multitask Learning (MTL) and based on speech features trained under the joint
supervision of softmax loss and center loss, a powerful metric learning
strategy, for the recognition of emotion in speech. Speech features such as
Spectrograms and Mel-frequency Cepstral Coefficient s (MFCCs) help retain
emotion-related low-level characteristics in speech. We experimented with
several Deep Neural Network (DNN) architectures that take in speech features as
input and trained them under both softmax and center loss, which resulted in
highly discriminative features ideal for Speech Emotion Recognition (SER). Our
networks also employ a regularizing effect by simultaneously performing the
auxiliary task of reconstructing the input speech features. This sharing of
representations among related tasks enables our network to better generalize
the original task of SER. Some of our proposed networks contain far fewer
parameters when compared to state-of-the-art architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08889</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08889</id><created>2019-06-20</created><authors><author><keyname>Feng</keyname><forenames>Tuo</forenames></author><author><keyname>Gu</keyname><forenames>Dongbing</forenames></author></authors><title>SGANVO: Unsupervised Deep Visual Odometry and Depth Estimation with
  Stacked Generative Adversarial Networks</title><categories>cs.RO cs.CV eess.IV</categories><comments>7 pages, 4 figures,</comments><report-no>ras.ral.19-0181.628f4a7b</report-no><doi>10.1109/LRA.2019.2925555</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently end-to-end unsupervised deep learning methods have achieved an
effect beyond geometric methods for visual depth and ego-motion estimation
tasks. These data-based learning methods perform more robustly and accurately
in some of the challenging scenes. The encoder-decoder network has been widely
used in the depth estimation and the RCNN has brought significant improvements
in the ego-motion estimation. Furthermore, the latest use of Generative
Adversarial Nets(GANs) in depth and ego-motion estimation has demonstrated that
the estimation could be further improved by generating pictures in the game
learning process. This paper proposes a novel unsupervised network system for
visual depth and ego-motion estimation: Stacked Generative Adversarial
Network(SGANVO). It consists of a stack of GAN layers, of which the lowest
layer estimates the depth and ego-motion while the higher layers estimate the
spatial features. It can also capture the temporal dynamic due to the use of a
recurrent representation across the layers. See Fig.1 for details. We select
the most commonly used KITTI [1] data set for evaluation. The evaluation
results show that our proposed method can produce better or comparable results
in depth and ego-motion estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08891</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08891</id><created>2019-06-20</created><authors><author><keyname>Choudhuri</keyname><forenames>Sandipan</forenames></author><author><keyname>Basu</keyname><forenames>Kaustav</forenames></author><author><keyname>Thomas</keyname><forenames>Kevin</forenames></author><author><keyname>Sen</keyname><forenames>Arunabha</forenames></author></authors><title>Predicting Future Opioid Incidences Today</title><categories>cs.CV cs.CY cs.HC eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to the Center of Disease Control (CDC), the Opioid epidemic has
claimed more than 72,000 lives in the US in 2017 alone. In spite of various
efforts at the local, state and federal level, the impact of the epidemic is
becoming progressively worse, as evidenced by the fact that the number of
Opioid related deaths increased by 12.5\% between 2016 and 2017. Predictive
analytics can play an important role in combating the epidemic by providing
decision making tools to stakeholders at multiple levels - from health care
professionals to policy makers to first responders. Generating Opioid incidence
heat maps from past data, aid these stakeholders to visualize the profound
impact of the Opioid epidemic. Such post-fact creation of the heat map provides
only retrospective information, and as a result, may not be as useful for
preventive action in the current or future time-frames. In this paper, we
present a novel deep neural architecture, which learns subtle spatio-temporal
variations in Opioid incidences data and accurately predicts future heat maps.
We evaluated the efficacy of our model on two open source datasets- (i) The
Cincinnati Heroin Overdose dataset, and (ii) Connecticut Drug Related Death
Dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08901</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08901</id><created>2019-06-20</created><updated>2019-10-11</updated><authors><author><keyname>Sennesh</keyname><forenames>Eli</forenames></author><author><keyname>Khan</keyname><forenames>Zulqarnain</forenames></author><author><keyname>Dy</keyname><forenames>Jennifer</forenames></author><author><keyname>Satpute</keyname><forenames>Ajay B.</forenames></author><author><keyname>Hutchinson</keyname><forenames>J. Benjamin</forenames></author><author><keyname>van de Meent</keyname><forenames>Jan-Willem</forenames></author></authors><title>Neural Topographic Factor Analysis for fMRI Data</title><categories>cs.LG eess.IV stat.ML</categories><comments>8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functional magnetic resonance imaging experiments produce gigabytes of
high-dimensional spatio-temporal data for a small number of sampled
participants and stimuli. Analyses of this data commonly average over all
trials, ignoring variation among participants and stimuli. As a means of
reasoning about this variation, we propose Neural Topographic Factor Analysis
(NTFA), a deep generative model that parameterizes factors as functions of
embeddings for participants and stimuli. We evaluate NTFA on a synthetically
generated dataset, results from an in-house pilot study, and two publicly
available datasets. We demonstrate that NTFA produces more accurate
reconstructions with fewer parameters than related methods. Moreover, NTFA
constitutes a first step towards reasoning about individual variation; learned
embeddings uncover latent categories of stimuli, and partially separate latent
groups of participants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08916</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08916</id><created>2019-06-20</created><authors><author><keyname>Vidwans</keyname><forenames>Amruta</forenames></author><author><keyname>Verma</keyname><forenames>Prateek</forenames></author><author><keyname>Rao</keyname><forenames>Preeti</forenames></author></authors><title>Understanding and Classifying Cultural Music Using Melodic Features Case
  Of Hindustani, Carnatic And Turkish Music</title><categories>cs.SD eess.AS</categories><comments>The work appeared in the 3rd CompMusic Workshop for Developing
  Computational models for the Discovery of the Worlds Music held at IIT Madras
  at Chennai in 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a melody based classification of musical styles by exploiting the
pitch and energy based characteristics derived from the audio signal. Three
prominent musical styles were chosen which have improvisation as integral part
with similar melodic principles, theme, and structure of concerts namely,
Hindustani, Carnatic and Turkish music. Listeners of one or more of these
genres can discriminate between these based on the melodic contour alone.
Listening tests were carried out using melodic attributes alone, on similar
melodic pieces with respect to raga/makam, and removing any instrumentation cue
to validate our hypothesis that style distinction is evident in the melody. Our
method is based on finding a set of highly discriminatory features, derived
from musicology, to capture distinct characteristics of the melodic contour.
Behavior in terms of transitions of the pitch contour, the presence of
micro-tonal notes and the nature of variations in the vocal energy are
exploited. The automatically classified style labels are found to correlate
well with subjective listening judgments. This was verified by using
statistical tests to compare the labels from subjective and objective
judgments. The melody based features, when combined with timbre based features,
were seen to improve the classification performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08919</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08919</id><created>2019-06-20</created><authors><author><keyname>Kaleva</keyname><forenames>Jarkko</forenames></author><author><keyname>Myers</keyname><forenames>Nitin Jonathan</forenames></author><author><keyname>T&#xf6;lli</keyname><forenames>Antti</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>A Geometry-aided Message Passing Method for AoA-Based Short Range MIMO
  Channel Estimation</title><categories>eess.SP</categories><comments>To appear in the proceedings of the 20th IEEE International Workshop
  on Signal Processing Advances in Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short range channels commonly arise in millimeter wave (mmWave) wearable
settings, where the length of the antenna arrays can be comparable to the
distance between the radios. Conventional mmWave MIMO channel estimation
techniques based on the far field assumption may perform poorly in short range
settings due to the large angular spread and, hence, high available rank. We
propose a geometry-aided message passing algorithm that exploits structure in
short range line-of-sight (LoS) channels for spatial sub-Nyquist channel
estimation. Our approach parametrizes the channel using angle-of-arrivals
(AoAs) that are locally defined for subarrays of an antenna array. Furthermore,
it leverages the dependencies between the local AoAs using factors based on the
array geometry. We show that the LoS MIMO channel can be reconstructed using
the derived local AoA estimates and the known transceiver geometry. The
proposed approach achieves a reasonable rate with greatly reduced pilot
transmissions when compared to exhaustive beam search-based local AoA
estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08925</identifier>
 <datestamp>2019-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08925</id><created>2019-06-20</created><updated>2019-09-19</updated><authors><author><keyname>Chipade</keyname><forenames>Vishnu S.</forenames></author><author><keyname>Panagou</keyname><forenames>Dimitra</forenames></author></authors><title>Herding an Adversarial Swarm in an Obstacle Environment</title><categories>eess.SY cs.SY</categories><comments>6 pages, CDC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a defense approach against a swarm of adversarial agents.
We employ a closed formation (`StringNet') of defending agents around the
adversarial agents to restrict their motion and guide them to a safe area while
navigating in an obstacle-populated environment. Control laws for forming the
StringNet and guiding it to a safe area are developed, and the stability of the
closed-loop system is analyzed formally. The adversarial swarm is assumed to
move as a flock in the presence of rectangular obstacles. Simulation results
are provided to demonstrate the efficacy of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08926</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08926</id><created>2019-06-20</created><authors><author><keyname>Yongnam</keyname><forenames>U</forenames></author><author><keyname>Taehyong</keyname><forenames>Ri</forenames></author></authors><title>Scheduling for Flexible Manufacturing System with Objective Function to
  be Minimization of Total Processing Time and Unbalance of Machine Load</title><categories>cs.DC cs.SY eess.SY</categories><comments>11Pages,3Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For scheduling in flexible manufacturing system (FMS), many factors should be
considered, it is difficult to solve the scheduling problem by satisfying
different criteria (production cost, utilization of system, number of movements
of part, make-span, and tardiness in due date and so on) and constrains. The
paper proposes mathematical model of a job shop scheduling problem (JSSP) to
balance the load of all machines and utilize effectively all machines in FMS.
This paper defines the evaluation function of the unbalance of the machine load
and formulates the optimization problem with two objectives minimizing
unbalance of the machine load and the total processing time, scheduling problem
having been solved by integer linear programming, thus scheduling problem
having been solved. The results of calculation show that the total processing
time on all machines is reduced and machine loading is balanced better than
previous works, and job shop scheduling also could be scheduled more easily in
FMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08968</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08968</id><created>2019-06-21</created><authors><author><keyname>Di Carlo</keyname><forenames>Diego</forenames><affiliation>PANAMA</affiliation></author><author><keyname>Deleforge</keyname><forenames>Antoine</forenames><affiliation>MULTISPEECH</affiliation></author><author><keyname>Bertin</keyname><forenames>Nancy</forenames><affiliation>PANAMA</affiliation></author></authors><title>Mirage: 2D Source Localization Using Microphone Pair Augmentation with
  Echoes</title><categories>eess.AS eess.SP physics.class-ph</categories><proxy>ccsd</proxy><journal-ref>International Conferenze on Acoustic, Speech Signal Processing -
  ICASSP 2019, May 2019, Calgary, United Kingdom</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is commonly observed that acoustic echoes hurt performance of sound source
localization (SSL) methods. We introduce the concept of microphone array
augmentation with echoes (MIRAGE) and show how estimation of early-echo
characteristics can in fact benefit SSL. We propose a learning-based scheme for
echo estimation combined with a physics-based scheme for echo aggregation. In a
simple scenario involving 2 microphones close to a reflective surface and one
source, we show using simulated data that the proposed approach performs
similarly to a correlation-based method in azimuth estimation while retrieving
elevation as well from 2 microphones only, an impossible task in anechoic
settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08970</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08970</id><created>2019-06-21</created><authors><author><keyname>Rajam&#xe4;ki</keyname><forenames>Robin</forenames></author><author><keyname>Chepuri</keyname><forenames>Sundeep Prabhakar</forenames></author><author><keyname>Koivunen</keyname><forenames>Visa</forenames></author></authors><title>Analog Beamforming for Active Imaging using Sparse Arrays</title><categories>eess.SP</categories><comments>5 pages, conference submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies analog beamforming in active sensing applications, such as
millimeter-wave radar or ultrasound imaging. Analog beamforming architectures
employ a single RF-IF chain connected to all array elements via inexpensive
phase shifters. This can drastically lower costs compared to fully-digital
beamformers having a dedicated RF-IF chain for each sensor. However,
controlling only the element phases may lead to elevated side-lobe levels and
degraded image quality. We address this issue by image addition, which
synthesizes a high resolution image by adding together several lower resolution
component images. Image addition also facilitates the use of sparse arrays,
which can further reduce array costs. To limit the image acquisition time, we
formulate an optimization problem for minimizing the number of component
images, subject to achieving a desired point spread function. We propose a
gradient descent algorithm for finding a locally optimal solution to this
problem. We also derive an upper bound on the number of component images needed
for achieving the traditional fully-digital beamformer solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08977</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08977</id><created>2019-06-21</created><authors><author><keyname>Yi</keyname><forenames>Yuan-Hao</forenames></author><author><keyname>Ai</keyname><forenames>Yang</forenames></author><author><keyname>Ling</keyname><forenames>Zhen-Hua</forenames></author><author><keyname>Dai</keyname><forenames>Li-Rong</forenames></author></authors><title>Singing Voice Synthesis Using Deep Autoregressive Neural Networks for
  Acoustic Modeling</title><categories>cs.SD cs.LG eess.AS</categories><comments>Interspeech2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method of using autoregressive neural networks for the
acoustic modeling of singing voice synthesis (SVS). Singing voice differs from
speech and it contains more local dynamic movements of acoustic features, e.g.,
vibratos. Therefore, our method adopts deep autoregressive (DAR) models to
predict the F0 and spectral features of singing voice in order to better
describe the dependencies among the acoustic features of consecutive frames.
For F0 modeling, discretized F0 values are used and the influences of the
history length in DAR are analyzed by experiments. An F0 post-processing
strategy is also designed to alleviate the inconsistency between the predicted
F0 contours and the F0 values determined by music notes. Furthermore, we extend
the DAR model to deal with continuous spectral features, and a prenet module
with self-attention layers is introduced to process historical frames.
Experiments on a Chinese singing voice corpus demonstrate that our method using
DARs can produce F0 contours with vibratos effectively, and can achieve better
objective and subjective performance than the conventional method using
recurrent neural networks (RNNs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08985</identifier>
 <datestamp>2019-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.08985</id><created>2019-06-21</created><updated>2019-12-04</updated><authors><author><keyname>Stark</keyname><forenames>Maximilian</forenames></author><author><keyname>Wang</keyname><forenames>Linfang</forenames></author><author><keyname>Wesel</keyname><forenames>Richard D.</forenames></author><author><keyname>Bauch</keyname><forenames>Gerhard</forenames></author></authors><title>Information Bottleneck Decoding of Rate-Compatible 5G-LDPC Codes</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The new 5G communications standard increases data rates and supports
low-latency communication that places constraints on the computational
complexity of channel decoders. 5G low-density parity-check (LDPC) codes have
the so-called protograph-based raptor-like (PBRL) structure which offers
inherent rate-compatibility and excellent performance. Practical LDPC decoder
implementations use message-passing decoding with finite precision, which
becomes coarse as complexity is more severely constrained. Performance degrades
as the precision becomes more coarse. Recently, the information bottleneck (IB)
method was used to design mutual-information-maximizing lookup tables that
replace conventional finite-precision node computations. Additionally, the IB
approach exchanges messages represented by integers with very small bit width.
This paper extends the IB principle to the flexible class of PBRL LDPC codes as
standardized in 5G. The extensions includes puncturing and rate-compatible IB
decoder design. As an example of the new approach, a 4-bit information
bottleneck decoder is evaluated for PBRL LDPC codes over a typical range of
rates. Bit error rate simulations show that the proposed scheme outperforms
offset min-sum decoding algorithms and operates within 0.2 dB of
double-precision sum-product belief propagation decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09026</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09026</id><created>2019-06-21</created><authors><author><keyname>Amin</keyname><forenames>Ahmed Al</forenames></author><author><keyname>Narottama</keyname><forenames>Bhaskara</forenames></author><author><keyname>Shin</keyname><forenames>Soo Young</forenames></author></authors><title>Capacity Enhancement of Cooperative NOMA over Rician Fading Channels
  with Orbital Angular Momentum</title><categories>eess.SP cs.NI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This letter proposes the usage of orbital angular momentum (OAM) for
cooperative non-orthogonal multiple access (CNOMA) to enhance sum capacity (SC)
for the future cellular communication system. The proposed CNOMA-OAM scheme is
analyzed and compared with other schemes, i.e., conventional CNOMA,
conventional orthogonal multiple access (OMA) with OAM. The impact of the power
allocation factor for OAM beam over SC is also analyzed. The analytical result
is justified by simulation results which demonstrate that the proposed
CNOMA-OAM provides higher SC compared to other schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09035</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09035</id><created>2019-06-21</created><authors><author><keyname>Huang</keyname><forenames>Xin</forenames></author><author><keyname>Li</keyname><forenames>Duan</forenames></author><author><keyname>Long</keyname><forenames>Daniel Zhuoyu</forenames></author></authors><title>Revised Progressive-Hedging-Algorithm Based Two-layer Solution Scheme
  for Bayesian Reinforcement Learning</title><categories>eess.SY cs.LG cs.SY</categories><comments>9 pages, 1 table, submitted to NeurIPS 2019, under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic control with both inherent random system noise and lack of
knowledge on system parameters constitutes the core and fundamental topic in
reinforcement learning (RL), especially under non-episodic situations where
online learning is much more demanding. This challenge has been notably
addressed in Bayesian RL recently where some approximation techniques have been
developed to find suboptimal policies. While existing approaches mainly focus
on approximating the value function, or on involving Thompson sampling, we
propose a novel two-layer solution scheme in this paper to approximate the
optimal policy directly, by combining the time-decomposition based dynamic
programming (DP) at the lower layer and the scenario-decomposition based
revised progressive hedging algorithm (PHA) at the upper layer, for a type of
Bayesian RL problem. The key feature of our approach is to separate reducible
system uncertainty from irreducible one at two different layers, thus
decomposing and conquering. We demonstrate our solution framework more
especially via the linear-quadratic-Gaussian problem with unknown gain, which,
although seemingly simple, has been a notorious subject over more than half
century in dual control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09096</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09096</id><created>2019-06-19</created><authors><author><keyname>Usevitch</keyname><forenames>James</forenames></author><author><keyname>Panagou</keyname><forenames>Dimitra</forenames></author></authors><title>Resilient Leader-Follower Consensus to Arbitrary Reference Values in
  Time-Varying Graphs</title><categories>eess.SY cs.SY</categories><comments>arXiv admin note: text overlap with arXiv:1906.08254</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several algorithms in prior literature have been proposed which guarantee
consensus of normally behaving agents in a network that may contain
adversarially behaving agents. These algorithms guarantee that the consensus
value lies within the convex hull of initial normal agents' states, with the
exact consensus value possibly being unknown. In leader-follower consensus
problems however, the objective is for normally behaving agents to track a
reference state that may take on values outside of this convex hull. In this
paper we present methods for agents in time-varying graphs with discrete-time
dynamics to resiliently track a reference state propagated by a set of leaders
despite a bounded subset of the leaders and followers behaving adversarially.
Our results are demonstrated through simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09097</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09097</id><created>2019-06-19</created><updated>2020-01-06</updated><authors><author><keyname>Di</keyname><forenames>Bolei</forenames></author><author><keyname>Lamperski</keyname><forenames>Andrew</forenames></author></authors><title>Newton's Method and Differential Dynamic Programming for Unconstrained
  Nonlinear Dynamic Games</title><categories>eess.SY cs.SY</categories><comments>19 pages. The shortened version was accepted at CDC 2019. arXiv admin
  note: substantial text overlap with arXiv:1809.08302</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic games arise when multiple agents with differing objectives control a
dynamic system. They model a wide variety of applications in economics,
defense, energy systems and etc. However, compared to single-agent control
problems, the computational methods for dynamic games are relatively limited.
As in the single-agent case, only specific dynamic games can be solved exactly,
so approximation algorithms are required. In this paper, we show how to extend
a recursive Newton's algorithm and the popular differential dynamic programming
(DDP) for single-agent optimal control to the case of full-information non-zero
sum dynamic games. In the single-agent case, the convergence of DDP is proved
by comparison with Newton's method, which converges locally at a quadratic
rate. We show that the iterates of Newton's method and DDP are sufficiently
close for the DDP to inherit the quadratic convergence rate of Newton's method.
We also prove both methods result in an open-loop Nash equilibrium and a local
feedback $O(\epsilon^2)$-Nash equilibrium. Numerical examples are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09109</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09109</id><created>2019-06-19</created><authors><author><keyname>Garg</keyname><forenames>Kunal</forenames></author><author><keyname>Panagou</keyname><forenames>Dimitra</forenames></author></authors><title>Finite-Time Stability of Hybrid Systems: A Multiple Generalized Lyapunov
  Functions Approach</title><categories>eess.SY cs.SY math.OC</categories><comments>Submitted to IEEE CSS-Letters, under review. arXiv admin note:
  substantial text overlap with arXiv:1901.08513</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies finite-time stability of a class of hybrid systems. We
present sufficient conditions in terms of multiple generalized Lyapunov
functions for the origin of the hybrid system to be finite-time stable. More
specifically, we show that even if the value of the generalized Lyapunov
functions increase between consecutive switches, finite-time stability can be
guaranteed if the finite-time convergent mode is active long enough. In
contrast to earlier work where the Lyapunov functions are required to be
decreasing during the continuous flows and non-increasing at the discrete
jumps, we allow the generalized Lyapunov functions to increase \emph{both}
during the continuous flows and the discrete jumps. As thus, the derived
stability results are less conservative compared to the related literature.
Numerical example demonstrates the efficacy of the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09121</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09121</id><created>2019-06-21</created><authors><author><keyname>Piazzo</keyname><forenames>Lorenzo</forenames></author><author><keyname>Elia</keyname><forenames>Davide</forenames></author><author><keyname>Molinari</keyname><forenames>Sergio</forenames></author></authors><title>Minimum Variance Solution of Underdetermined Systems of Linear Equations</title><categories>math.OC eess.SP</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A system of linear equations is said underdetermined when there are more
unknowns than equations. Such systems may have infinitely many solutions. In
this case, it is important to single out solutions possessing special features.
A well known example is the Minimum Norm (MN) solution, which is the solution
having the least Euclidean norm. In this note, we consider another useful
solution, related with the MN one, which we call the Minimum Variance (MV)
solution. We discuss some of its properties and derive a simple, closed form
expression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09155</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09155</id><created>2019-06-21</created><authors><author><keyname>Dubnov</keyname><forenames>Shlomo</forenames></author></authors><title>Query-based Deep Improvisation</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><journal-ref>7th International Workshop on Musical Metacreation, International
  Conference on Computational Creativity 2019</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we explore techniques for generating new music using a
Variational Autoencoder (VAE) neural network that was trained on a corpus of
specific style. Instead of randomly sampling the latent states of the network
to produce free improvisation, we generate new music by querying the network
with musical input in a style different from the training corpus. This allows
us to produce new musical output with longer-term structure that blends aspects
of the query to the style of the network. In order to control the level of this
blending we add a noisy channel between the VAE encoder and decoder using
bit-allocation algorithm from communication rate-distortion theory. Our
experiments provide new insight into relations between the representational and
structural information of latent states and the query signal, suggesting their
possible use for composition purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09159</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09159</id><created>2019-06-21</created><authors><author><keyname>Amin</keyname><forenames>A. A.</forenames></author><author><keyname>Uddin</keyname><forenames>M. B.</forenames></author><author><keyname>Shin</keyname><forenames>S. Y.</forenames></author></authors><title>Performance Enhancement of Hybrid SWIPT Protocol for Cooperative NOMA
  Downlink Transmission</title><categories>eess.SP cs.NI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Time splitting and power splitting incorporating, a hybrid Simultaneous
Wireless Information and Power Transfer (SWIPT) based cooperative
Non-Orthogonal Multiple Access (CNOMA) protocol is considered in this paper.
Cell center user of the CNOMA system acts as a relay to enhance the reliability
of the cell edge user (CEU). SWIPT is considered to empower the relay operation
to avoid the battery draining issue. To enhance the system performance in terms
of ergodic sum capacity (ESC) and outage probabilities (OP), an integration of
CNOMA strategy and hybrid SWIPT protocol for the downlink (DL) transmission is
proposed here. By utilizing the idle link of hybrid SWIPT protocol an enhanced
hybrid SWIPT protocol is proposed here to enhance the performance of CNOMA DL
transmission. Moreover, Maximal ratio combining is utilized as a diversity
combining technique at CEU to enhance the performance as well. The performance
of the proposed protocol is examined in terms of ergodic sum capacity, outage
probabilities and energy efficiency. Finally, the analytical results are
justified by the Monte-Carlo simulation. Numerical results demonstrate that the
proposed protocol with effective CNOMA strategy achieves superior performance
than HS-CNOMA with selection combining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09165</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09165</id><created>2019-06-21</created><authors><author><keyname>Kelz</keyname><forenames>Rainer</forenames></author><author><keyname>B&#xf6;ck</keyname><forenames>Sebastian</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Deep Polyphonic ADSR Piano Note Transcription</title><categories>cs.SD eess.AS</categories><comments>5 pages, 2 figures, published as ICASSP'19</comments><journal-ref>ICASSP 2019 - 2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), Brighton, United Kingdom, 2019, pp.
  246-250</journal-ref><doi>10.1109/ICASSP.2019.8683582</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We investigate a late-fusion approach to piano transcription, combined with a
strong temporal prior in the form of a handcrafted Hidden Markov Model (HMM).
The network architecture under consideration is compact in terms of its number
of parameters and easy to train with gradient descent. The network outputs are
fused over time in the final stage to obtain note segmentations, with an HMM
whose transition probabilities are chosen based on a model of attack, decay,
sustain, release (ADSR) envelopes, commonly used for sound synthesis. The note
segments are then subject to a final binary decision rule to reject too weak
note segment hypotheses. We obtain state-of-the-art results on the MAPS
dataset, and are able to outperform other approaches by a large margin, when
predicting complete note regions from onsets to offsets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09181</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09181</id><created>2019-06-21</created><authors><author><keyname>Samarin</keyname><forenames>Nikita</forenames></author><author><keyname>Sannella</keyname><forenames>Donald</forenames></author></authors><title>A Key to Your Heart: Biometric Authentication Based on ECG Signals</title><categories>cs.CR cs.SY eess.SY</categories><comments>Appears in the &quot;Who Are You?! Adventures in Authentication&quot; workshop
  (WAY 2019) co-located with the Symposium on Usable Privacy and Security
  (SOUPS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, there has been a shift of interest towards the field of
biometric authentication, which proves the identity of the user using their
biological characteristics. We explore a novel biometric based on the
electrical activity of the human heart in the form of electrocardiogram (ECG)
signals. In order to explore the stability of ECG as a biometric, we collect
data from 55 participants over two sessions with a period of 4 months in
between. We also use a consumer-grade ECG monitor that is more affordable and
usable than a medical-grade counterpart. Using a standard approach to evaluate
our classifier, we obtain error rates of 2.4% for data collected within one
session and 9.7% for data collected across two sessions. The experimental
results suggest that ECG signals collected using a consumer-grade monitor can
be successfully used for user authentication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09209</identifier>
 <datestamp>2019-06-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09209</id><created>2019-06-21</created><authors><author><keyname>Jameel</keyname><forenames>Furqan</forenames></author><author><keyname>Duan</keyname><forenames>Ruifeng</forenames></author><author><keyname>Chang</keyname><forenames>Zheng</forenames></author><author><keyname>Liljemark</keyname><forenames>Aleksi</forenames></author><author><keyname>Ristaniemi</keyname><forenames>Tapani</forenames></author><author><keyname>Jantti</keyname><forenames>Riku</forenames></author></authors><title>Applications of Backscatter Communications for Healthcare Networks</title><categories>eess.SP cs.SY eess.SY</categories><comments>10 Pages, 4 Figures, 2 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Backscatter communication is expected to help in revitalizing the domain of
healthcare through its myriad applications. From on-body sensors to in-body
implants and miniature embeddable devices, there are many potential use cases
that can leverage the miniature and low-powered nature of backscatter devices.
However, the existing literature lacks a comprehensive study that provides a
distilled review of the latest studies on backscatter communications from the
healthcare perspective. Thus, with the objective to promote the utility of
backscatter communication in healthcare, this paper aims to identify specific
applications of backscatter systems. A detailed taxonomy of recent studies and
gap analysis for future research directions are provided in this work. Finally,
we conduct measurements at 590 MHz in different propagation environments with
the in-house designed backscatter device. The link budget results show the
promise of backscatter devices to communicate over large distances for indoor
environments which demonstrates its potential in the healthcare system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09211</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09211</id><created>2019-06-21</created><updated>2019-10-27</updated><authors><author><keyname>Hanson</keyname><forenames>Joshua</forenames></author><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author></authors><title>Universal Approximation of Input-Output Maps by Temporal Convolutional
  Nets</title><categories>cs.LG cs.SY eess.SY math.OC stat.ML</categories><comments>final version to appear in NeurIPS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been a recent shift in sequence-to-sequence modeling from recurrent
network architectures to convolutional network architectures due to
computational advantages in training and operation while still achieving
competitive performance. For systems having limited long-term temporal
dependencies, the approximation capability of recurrent networks is essentially
equivalent to that of temporal convolutional nets (TCNs). We prove that TCNs
can approximate a large class of input-output maps having approximately finite
memory to arbitrary error tolerance. Furthermore, we derive quantitative
approximation rates for deep ReLU TCNs in terms of the width and depth of the
network and modulus of continuity of the original input-output map, and apply
these results to input-output maps of systems that admit finite-dimensional
state-space realizations (i.e., recurrent models).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09284</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09284</id><created>2019-06-21</created><updated>2019-09-10</updated><authors><author><keyname>Su</keyname><forenames>Nanchi</forenames></author><author><keyname>Liu</keyname><forenames>Fan</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author></authors><title>Enhancing the Physical Layer Security of Dual-functional Radar
  Communication Systems</title><categories>eess.SP</categories><comments>6 pages, 5 figures, accepted by IEEE GLOBECOM 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dual-functional radar communication (DFRC) system has recently attracted
significant academic attentions as an enabling solution for realizing
radar-communication spectrum sharing. During the DFRC transmission, however,
the critical information could be leaked to the targets, which might be
potential eavesdroppers. Therefore, the physical layer security has to be taken
into consideration. In this paper, fractional programming (FP) problems are
formulated to minimize the signal-to-interference-plus-noise ratio (SINR) at
targets under the constraints for the SINR of legitimate users. By doing so,
the secrecy rate of communication can be guaranteed. We first assume that
communication CSI and the angle of the target are precisely known. After that,
problem is extended to the cases with uncertainty in the target's location,
which indicates that the target might appear in a certain angular interval.
Finally, numerical results have been provided to validate the effectiveness of
the proposed method showing that it is viable to guarantee both radar and
secrecy communication performances by using the techniques we propose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09292</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09292</id><created>2019-06-21</created><updated>2019-07-22</updated><authors><author><keyname>Hu</keyname><forenames>Ke</forenames></author><author><keyname>Bruguier</keyname><forenames>Antoine</forenames></author><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Prabhavalkar</keyname><forenames>Rohit</forenames></author><author><keyname>Pundak</keyname><forenames>Golan</forenames></author></authors><title>Phoneme-Based Contextualization for Cross-Lingual Speech Recognition in
  End-to-End Models</title><categories>cs.CL cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contextual automatic speech recognition, i.e., biasing recognition towards a
given context (e.g. user's playlists, or contacts), is challenging in
end-to-end (E2E) models. Such models maintain a limited number of candidates
during beam-search decoding, and have been found to recognize rare named
entities poorly. The problem is exacerbated when biasing towards proper nouns
in foreign languages, e.g., geographic location names, which are virtually
unseen in training and are thus out-of-vocabulary (OOV). While grapheme or
wordpiece E2E models might have a difficult time spelling OOV words, phonemes
are more acoustically salient and past work has shown that E2E phoneme models
can better predict such words. In this work, we propose an E2E model containing
both English wordpieces and phonemes in the modeling space, and perform
contextual biasing of foreign words at the phoneme level by mapping
pronunciations of foreign words into similar English phonemes. In experimental
evaluations, we find that the proposed approach performs 16% better than a
grapheme-only biasing model, and 8% better than a wordpiece-only biasing model
on a foreign place name recognition task, with only slight degradation on
regular English tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09295</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09295</id><created>2019-06-21</created><authors><author><keyname>Khatibi</keyname><forenames>Mohammad</forenames></author><author><keyname>Ahmed</keyname><forenames>Sara</forenames></author></authors><title>Impact of Distributed Energy Resources on Frequency Regulation of the
  Bulk Power System</title><categories>eess.SY cs.SY eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growing penetration of distributed energy resources (DERs) has increased
the complexity of the power system due to their intermittent characteristics
and lower inertial response, such as photovoltaic (PV) systems and wind
turbines. This restructuring of the power system has a considerable effect on
the transient response of the system resulting in inter-area oscillations, less
synchronized coupling and power swings. Furthermore, the concept of being
distributed itself and generating electricity from multiple locations in the
power system makes the transient impact of DERs even worse by raising issues
such as reverse power flows. This paper studies some impacts of the changing
nature of power system which are limiting the large scale integration of DERs.
In addition, a solution to increase the inertial response of the system is
addressed by adding virtual inertia to the inverter based DERs in the power
system. The proposed control results in increasing the stability margin and
tracking the rated frequency of the system. The injected synchronized active
power to the system will prevent the protection relays from tripping by
improving the rate of change of frequency. The proposed system operation is
implemented on a sample power grid comprising of generation, transmission and
distribution and results are verified experimentally through the Opal-RT
real-time simulation system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09297</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09297</id><created>2019-06-21</created><updated>2019-09-16</updated><authors><author><keyname>Kashyap</keyname><forenames>Mruganka</forenames></author><author><keyname>Lessard</keyname><forenames>Laurent</forenames></author></authors><title>Explicit Agent-Level Optimal Cooperative Controllers for Dynamically
  Decoupled Systems with Output Feedback</title><categories>cs.SY eess.SY math.OC</categories><comments>Published at IEEE Conference on Decision and Control, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a dynamically decoupled network of agents each with a local
output-feedback controller. We assume each agent is a node in a directed
acyclic graph and the controllers share information along the edges in order to
cooperatively optimize a global objective. We develop explicit state-space
formulations for the jointly optimal networked controllers that highlight the
role of the graph structure. Specifically, we provide generically minimal
agent-level implementations of the local controllers along with intuitive
interpretations of their states and the information that should be transmitted
between controllers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09298</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09298</id><created>2019-06-21</created><updated>2019-08-13</updated><authors><author><keyname>Teyeb</keyname><forenames>Oumer</forenames></author><author><keyname>Muhammad</keyname><forenames>Ajmal</forenames></author><author><keyname>Mildh</keyname><forenames>Gunnar</forenames></author><author><keyname>Dahlman</keyname><forenames>Erik</forenames></author><author><keyname>Barac</keyname><forenames>Filip</forenames></author><author><keyname>Makki</keyname><forenames>Behrooz</forenames></author></authors><title>Integrated Access Backhauled Networks</title><categories>cs.NI eess.SP</categories><comments>Accepted for presentation in IEEE VTC fall 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G is finally here. Initial deployments are already operational in several
major cities and first 5G-capable devices are being released. Though it is not
limited only to millimeter wave deployments, the main promise of 5G lies in the
utilization of the high bandwidth available at high frequencies. However,
high-frequency deployments are coverage-limited and require denser placement of
base stations, which can increase the cost significantly. One of the main
contributing factors to the cost is fiber deployment. Integrated access
backhauling (IAB), where part of the wireless spectrum is used for the backhaul
connection of base stations instead of fiber, is an attractive solution that
could make dense deployments economically viable. With this main objective,
3GPP is in the process of standardizing multi-hop IAB networks. This paper
provides an overview of the main features of the multi-hop IAB 3GPP rel-16
standard and the rationale behind the design choices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09300</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09300</id><created>2019-06-21</created><updated>2019-07-18</updated><authors><author><keyname>Soleymani</keyname><forenames>Sobhan</forenames></author><author><keyname>Dabouei</keyname><forenames>Ali</forenames></author><author><keyname>Dawson</keyname><forenames>Jeremy</forenames></author><author><keyname>Nasrabadi</keyname><forenames>Nasser M.</forenames></author></authors><title>Adversarial Examples to Fool Iris Recognition Systems</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>2019 International Conference on Biometrics (ICB 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial examples have recently proven to be able to fool deep learning
methods by adding carefully crafted small perturbation to the input space
image. In this paper, we study the possibility of generating adversarial
examples for code-based iris recognition systems. Since generating adversarial
examples requires back-propagation of the adversarial loss, conventional filter
bank-based iris-code generation frameworks cannot be employed in such a setup.
Therefore, to compensate for this shortcoming, we propose to train a deep
auto-encoder surrogate network to mimic the conventional iris code generation
procedure. This trained surrogate network is then deployed to generate the
adversarial examples using the iterative gradient sign method algorithm. We
consider non-targeted and targeted attacks through three attack scenarios.
Considering these attacks, we study the possibility of fooling an iris
recognition system in white-box and black-box frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09329</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09329</id><created>2019-06-21</created><authors><author><keyname>Vald&#xe9;s</keyname><forenames>Mat&#xed;as</forenames></author><author><keyname>Fiori</keyname><forenames>Marcelo</forenames></author></authors><title>Re-Weighted $\ell_1$ Algorithms within the Lagrange Duality Framework:
  Bringing Interpretability to Weights</title><categories>math.OC cs.LG cs.NA eess.SP math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an important problem in signal processing, which consists in
finding the sparsest solution of a linear system $\Phi x=b$. This problem has
applications in several areas, but is NP-hard in general. Usually an
alternative convex problem is considered, based on minimizing the (weighted)
$\ell_{1}$ norm. For this alternative to be useful, weights should be chosen as
to obtain a solution of the original NP-hard problem. A well known algorithm
for this is the Re-Weighted $\ell_{1}$, proposed by Cand\`es, Wakin and Boyd.
In this article we introduce a new methodology for updating the weights of a
Re-Weighted $\ell_{1}$ algorithm, based on identifying these weights as
Lagrange multipliers. This is then translated into an algorithm with
performance comparable to the usual methodology, but allowing an interpretation
of the weights as Lagrange multipliers. The methodology may also be used for a
noisy linear system, obtaining in this case a Re-Weighted LASSO algorithm, with
a promising performance according to the experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09334</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09334</id><created>2019-06-21</created><updated>2019-06-29</updated><authors><author><keyname>Lostanlen</keyname><forenames>Vincent</forenames></author><author><keyname>Hecker</keyname><forenames>Florian</forenames></author></authors><title>The Shape of RemiXXXes to Come: Audio Texture Synthesis with
  Time-frequency Scattering</title><categories>cs.SD cs.MM eess.AS</categories><comments>8 pages, 3 figures. To appear in the proceedings of the International
  Conference on Digital Audio Effects (DAFX-19), Birmingham, UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article explains how to apply time--frequency scattering, a
convolutional operator extracting modulations in the time--frequency domain at
different rates and scales, to the re-synthesis and manipulation of audio
textures. After implementing phase retrieval in the scattering network by
gradient backpropagation, we introduce scale--rate DAFx, a class of audio
transformations expressed in the domain of time--frequency scattering
coefficients. One example of scale--rate DAFx is chirp rate inversion, which
causes each sonic event to be locally reversed in time while leaving the arrow
of time globally unchanged. Over the past two years, our work has led to the
creation of four electroacoustic pieces: ``FAVN''; ``Modulator (Scattering
Transform)''; ``Experimental Palimpsest''; ``Inspection''; and a remix of
Lorenzo Senni's ``XAllegroX'', released by Warp Records on a vinyl entitled
``The Shape of RemiXXXes to Come''. The source code to reproduce experiments
and figures is made freely available at:
https://github.com/lostanlen/scattering.m. A companion website containing demos
is at: https://lostanlen.com/pubs/dafx2019
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09344</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09344</id><created>2019-06-21</created><authors><author><keyname>Sodagari</keyname><forenames>Shabnam</forenames></author></authors><title>Underpinnings of User-Channel Allocation in Non-Orthogonal Multiple
  Access for 5G</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-orthogonal multiple access (NOMA) is a part of 5th generation (5G)
communication systems. This article presents the underpinnings and underlying
structures of the problem of NOMA user-channel allocation. Unlike the
heuristics for NOMA user-channel allocation, the presented results are
guaranteed to converge to a solution. In addition, the solutions are stable.
Generally, the results apply to any NOMA system. Unlike the orthogonal
frequency division multiple access (OFDMA) resource allocation problem, the
core matching is not the solution to NOMA resource allocation. The conditions
under which the fix-point NOMA resource allocation is guaranteed to be stable
from the viewpoint of both the base station and the NOMA users are described.
In addition, relationships of NOMA user-channel resource allocation to game
models and subgame perfect Nash equilibria are elucidated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09354</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09354</id><created>2019-06-21</created><authors><author><keyname>Karargyris</keyname><forenames>Alexandros</forenames></author><author><keyname>Wong</keyname><forenames>Ken C. L.</forenames></author><author><keyname>Wu</keyname><forenames>Joy T.</forenames></author><author><keyname>Moradi</keyname><forenames>Mehdi</forenames></author><author><keyname>Syeda-Mahmood</keyname><forenames>Tanveer</forenames></author></authors><title>Boosting the rule-out accuracy of deep disease detection using class
  weight modifiers</title><categories>eess.IV cs.CV</categories><comments>This paper was accepted by the IEEE International Symposium on
  Biomedical Imaging (ISBI) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many screening applications, the primary goal of a radiologist or
assisting artificial intelligence is to rule out certain findings. The
classifiers built for such applications are often trained on large datasets
that derive labels from clinical notes written for patients. While the quality
of the positive findings described in these notes is often reliable, lack of
the mention of a finding does not always rule out the presence of it. This
happens because radiologists comment on the patient in the context of the exam,
for example focusing on trauma as opposed to chronic disease at emergency
rooms. However, this disease finding ambiguity can affect the performance of
algorithms. Hence it is critical to model the ambiguity during training. We
propose a scheme to apply reasonable class weight modifiers to our loss
function for the no mention cases during training. We experiment with two
different deep neural network architectures and show that the proposed method
results in a large improvement in the performance of the classifiers, specially
on negated findings. The baseline performance of a custom-made dilated block
network proposed in this paper shows an improvement in comparison with baseline
DenseNet-201, while both architectures benefit from the new proposed loss
function weighting scheme. Over 200,000 chest X-ray images and three highly
common diseases, along with their negated counterparts, are included in this
study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09356</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09356</id><created>2019-06-21</created><authors><author><keyname>Traganitis</keyname><forenames>Panagiotis A.</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Unsupervised Ensemble Classification with Dependent Data</title><categories>cs.LG eess.SP stat.ML</categories><comments>Submitted to the IEEE Transactions on Knowledge and Data Engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensemble learning, the machine learning paradigm where multiple algorithms
are combined, has exhibited promising perfomance in a variety of tasks. The
present work focuses on unsupervised ensemble classification. The term
unsupervised refers to the ensemble combiner who has no knowledge of the
ground-truth labels that each classifier has been trained on. While most prior
works on unsupervised ensemble classification are designed for independent and
identically distributed (i.i.d.) data, the present work introduces an
unsupervised scheme for learning from ensembles of classifiers in the presence
of data dependencies. Two types of data dependencies are considered: sequential
data and networked data whose dependencies are captured by a graph. Moment
matching and Expectation Maximization algorithms are developed for the
aforementioned cases, and their performance is evaluated on synthetic and real
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09358</identifier>
 <datestamp>2019-12-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09358</id><created>2019-06-21</created><updated>2019-12-06</updated><authors><author><keyname>Alghamdi</keyname><forenames>Ahmed</forenames></author><author><keyname>Hammad</keyname><forenames>Mohamed</forenames></author><author><keyname>Ugail</keyname><forenames>Hassan</forenames></author><author><keyname>Abdel-Raheem</keyname><forenames>Asmaa</forenames></author><author><keyname>Muhammad</keyname><forenames>Khan</forenames></author><author><keyname>Khalifa</keyname><forenames>Hany S.</forenames></author><author><keyname>El-Latif</keyname><forenames>Ahmed A. Abd</forenames></author></authors><title>Detection of Myocardial Infarction Based on Novel Deep Transfer Learning
  Methods for Urban Healthcare in Smart Cities</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  . In this paper, an effective computer-aided diagnosis (CAD) system is
presented to detect MI signals using the convolution neural network (CNN) for
urban healthcare in smart cities. Two types of transfer learning techniques are
employed to retrain the pre-trained VGG-Net (Fine-tuning and VGG-Net as fixed
feature extractor) and obtained two new networks VGG-MI1 and VGG-MI2. In the
VGG-MI1 model, the last layer of the VGG-Net model is replaced with a specific
layer according to our requirements and various functions are optimized to
reduce overfitting. In the VGG-MI2 model, one layer of the VGG-Net model is
selected as a feature descriptor of the ECG images to describe it with
informative features. Considering the limited availability of dataset, ECG data
is augmented which has increased the classification performance.
Physikalisch-technische bundesanstalt (PTB) Diagnostic ECG database is used for
experimentation, which has been widely employed in MI detection studies. In
case of using VGG-MI1, we achieved an accuracy, sensitivity, and specificity of
99.02%, 98.76%, and 99.17%, respectively and we achieved an accuracy of 99.22%,
a sensitivity of 99.15%, and a specificity of 99.49% with VGG-MI2 model.
Experimental results validate the efficiency of the proposed system in terms of
accuracy sensitivity, and specificity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09359</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09359</id><created>2019-06-21</created><authors><author><keyname>Rupasinghe</keyname><forenames>Anuththara</forenames></author><author><keyname>Babadi</keyname><forenames>Behtash</forenames></author></authors><title>Multitaper Analysis of Evolutionary Spectra from Multivariate Spiking
  Observations</title><categories>cs.IT cs.SY eess.SY math.IT stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extracting the spectral representations of the neural processes that underlie
spiking activity is key to understanding how the brain rhythms mediate
cognitive functions. While spectral estimation of continuous time-series is
well studied, inferring the spectral representation of latent non-stationary
processes based on spiking observations is a challenging problem. In this
paper, we address this issue by developing a multitaper spectral estimation
methodology that can be directly applied to multivariate spiking observations
in order to extract the evolutionary spectral density of the latent
non-stationary processes that drive spiking activity, based on point process
theory. We establish theoretical bounds on the bias-variance trade-off of the
proposed estimator. Finally, we compare the performance of our proposed
technique with existing methods using simulation studies and application to
real data, which reveal significant gains in terms of the bias-variance
trade-off.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09395</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09395</id><created>2019-06-22</created><authors><author><keyname>Lee</keyname><forenames>Jaeheum</forenames></author><author><keyname>Eshraghian</keyname><forenames>Jason K.</forenames></author><author><keyname>Cho</keyname><forenames>Kyoungrok</forenames></author><author><keyname>Eshraghian</keyname><forenames>Kamran</forenames></author></authors><title>Adaptive Precision CNN Accelerator Using Radix-X Parallel Connected
  Memristor Crossbars</title><categories>eess.SP cs.AR eess.IV</categories><comments>12 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural processor development is reducing our reliance on remote server access
to process deep learning operations in an increasingly edge-driven world. By
employing in-memory processing, parallelization techniques, and
algorithm-hardware co-design, memristor crossbar arrays are known to
efficiently compute large scale matrix-vector multiplications. However,
state-of-the-art implementations of negative weights require duplicative column
wires, and high precision weights using single-bit memristors further
distributes computations. These constraints dramatically increase chip area and
resistive losses, which lead to increased power consumption and reduced
accuracy. In this paper, we develop an adaptive precision method by varying the
number of memristors at each crosspoint. We also present a weight mapping
algorithm designed for implementation on our crossbar array. This novel
algorithm-hardware solution is described as the radix-X Convolutional Neural
Network Crossbar Array, and demonstrate how to efficiently represent negative
weights using a single column line, rather than double the number of additional
columns. Using both simulation and experimental results, we verify that our
radix-5 CNN array achieves a validation accuracy of 90.5% on the CIFAR-10
dataset, a 4.5% improvement over binarized neural networks whilst
simultaneously reducing crossbar area by 46% over conventional arrays by
removing the need for duplicate columns to represent signed weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09417</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09417</id><created>2019-06-22</created><updated>2019-06-26</updated><authors><author><keyname>L&#xf3;pez-Espejo</keyname><forenames>Iv&#xe1;n</forenames></author><author><keyname>Tan</keyname><forenames>Zheng-Hua</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author></authors><title>Keyword Spotting for Hearing Assistive Devices Robust to External
  Speakers</title><categories>cs.SD cs.HC cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Keyword spotting (KWS) is experiencing an upswing due to the pervasiveness of
small electronic devices that allow interaction with them via speech. Often,
KWS systems are speaker-independent, which means that any person --user or
not-- might trigger them. For applications like KWS for hearing assistive
devices this is unacceptable, as only the user must be allowed to handle them.
In this paper we propose KWS for hearing assistive devices that is robust to
external speakers. A state-of-the-art deep residual network for small-footprint
KWS is regarded as a basis to build upon. By following a multi-task learning
scheme, this system is extended to jointly perform KWS and users'
own-voice/external speaker detection with a negligible increase in the number
of parameters. For experiments, we generate from the Google Speech Commands
Dataset a speech corpus emulating hearing aids as a capturing device. Our
results show that this multi-task deep residual network is able to achieve a
KWS accuracy relative improvement of around 32% with respect to a system that
does not deal with external speakers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09426</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09426</id><created>2019-06-22</created><authors><author><keyname>Srivastava</keyname><forenames>Brij Mohan Lal</forenames></author><author><keyname>Abraham</keyname><forenames>Basil</forenames></author><author><keyname>Sitaram</keyname><forenames>Sunayana</forenames></author><author><keyname>Mehta</keyname><forenames>Rupesh</forenames></author><author><keyname>Jyothi</keyname><forenames>Preethi</forenames></author></authors><title>End-to-End ASR for Code-switched Hindi-English Speech</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end (E2E) models have been explored for large speech corpora and have
been found to match or outperform traditional pipeline-based systems in some
languages. However, most prior work on end-to-end models use speech corpora
exceeding hundreds or thousands of hours. In this study, we explore end-to-end
models for code-switched Hindi-English language with less than 50 hours of
data. We utilize two specific measures to improve network performance in the
low-resource setting, namely multi-task learning (MTL) and balancing the corpus
to deal with the inherent class imbalance problem i.e. the skewed frequency
distribution over graphemes. We compare the results of the proposed approaches
with traditional, cascaded ASR systems. While the lack of data adversely
affects the performance of end-to-end models, we see promising improvements
with MTL and balancing the corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09434</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09434</id><created>2019-06-22</created><updated>2019-06-29</updated><authors><author><keyname>Fu</keyname><forenames>Min</forenames></author><author><keyname>Zhou</keyname><forenames>Yong</forenames></author><author><keyname>Shi</keyname><forenames>Yuanming</forenames></author></authors><title>Intelligent Reflecting Surface for Downlink Non-Orthogonal Multiple
  Access Networks</title><categories>eess.SP cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surface (IRS) has recently been recognized as a
promising technology to enhance the energy and spectrum efficiency of wireless
networks by controlling the wireless medium with the configurable
electromagnetic materials. In this paper, we consider the downlink transmit
power minimization problem for a IRS-empowered non-orthogonal multiple access
(NOMA) network by jointly optimizing the transmit beamformers at the BS and the
phase shift matrix at the IRS. However, this problem turns out to be a highly
intractable non-convex bi-quadratic programming problem, for which an
alternative minimization framework is proposed via solving the non-convex
quadratic programs alternatively. We further develop a novel
difference-of-convex (DC) programming algorithm to solve the resulting
non-convex quadratic programs efficiently by lifting the quadratic programs
into rank-one constrained matrix optimization problems, followed by
representing the non-convex rank function as a DC function. Simulation results
demonstrate the performance gains of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09464</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09464</id><created>2019-06-22</created><authors><author><keyname>Car&#xe8;</keyname><forenames>Algo</forenames></author><author><keyname>Cs&#xe1;ji</keyname><forenames>Bal&#xe1;zs Csan&#xe1;d</forenames></author><author><keyname>Gerencs&#xe9;r</keyname><forenames>Bal&#xe1;zs</forenames></author><author><keyname>Gerencs&#xe9;r</keyname><forenames>L&#xe1;szl&#xf3;</forenames></author><author><keyname>R&#xe1;sonyi</keyname><forenames>Mikl&#xf3;s</forenames></author></authors><title>On the Poisson Equation of Parameter-Dependent Markov Chains</title><categories>math.PR cs.SY eess.SY</categories><msc-class>60J05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of the paper is to revisit a key mathematical technology within
the theory of stochastic approximation in a Markovian framework, elaborated in
much detail by Benveniste, M\'etivier, and Priouret (1990): the existence,
uniqueness and Lipschitz-continuity of the solutions of parameter-dependent
Poisson equations associated with parameter-dependent Markov chains on general
state spaces. The setup and the methodology of our investigation is based on a
new, elegant stability theory for Markov chains, developed by Hairer and
Mattingly (2011).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09490</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09490</id><created>2019-06-22</created><updated>2019-07-19</updated><authors><author><keyname>Basar</keyname><forenames>Ertugrul</forenames></author><author><keyname>Di Renzo</keyname><forenames>Marco</forenames></author><author><keyname>de Rosny</keyname><forenames>Julien</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Wireless Communications Through Reconfigurable Intelligent Surfaces</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE Access, 20 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The future of mobile communications looks exciting with the potential new use
cases and challenging requirements of future 6th generation (6G) and beyond
wireless networks. Since the beginning of the modern era of wireless
communications, the propagation medium has been perceived as a randomly
behaving entity between the transmitter and the receiver, which degrades the
quality of the received signal due to the uncontrollable interactions of the
transmitted radio waves with the surrounding objects. The recent advent of
reconfigurable intelligent surfaces in wireless communications enables, on the
other hand, network operators to control the scattering, reflection, and
refraction characteristics of the radio waves, by overcoming the negative
effects of natural wireless propagation. Recent results have revealed that
reconfigurable intelligent surfaces can effectively control the wavefront,
e.g., the phase, amplitude, frequency, and even polarization, of the impinging
signals without the need of complex decoding, encoding, and radio frequency
processing operations. Motivated by the potential of this emerging technology,
the present article is aimed to provide the readers with a detailed overview
and historical perspective on state-of-the-art solutions, and to elaborate on
the fundamental differences with other technologies, the most important open
research issues to tackle, and the reasons why the use of reconfigurable
intelligent surfaces necessitates to rethink the communication-theoretic models
currently employed in wireless networks. This article also explores theoretical
performance limits of reconfigurable intelligent surface-assisted communication
systems using mathematical techniques and elaborates on the potential use cases
of intelligent surfaces in 6G and beyond wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09505</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09505</id><created>2019-06-22</created><updated>2019-06-27</updated><authors><author><keyname>Barbeau</keyname><forenames>Michel</forenames></author><author><keyname>Garcia-Alfaro</keyname><forenames>Joaquin</forenames></author><author><keyname>Kranakis</keyname><forenames>Evangelos</forenames></author><author><keyname>Santos</keyname><forenames>Fillipe</forenames></author></authors><title>Quality Amplification of Error Prone Navigation for Swarms of Micro
  Aerial Vehicles (with Detailed Simulations)</title><categories>cs.RO cs.SY eess.SY</categories><comments>11 pages, 6 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an error tolerant path planning algorithm for Micro Aerial
Vehicles (MAV) swarms. We assume a MAV navigation system without relying on
GPS-like techniques. The MAV find their navigation path by using their sensors
and cameras, in order to identify and follow a series of visual landmarks. The
visual landmarks lead the MAV towards the target destination. MAVs are assumed
to be unaware of the terrain and locations of the landmarks. Landmarks are also
assumed to hold a-priori information, whose interpretation (by the MAVs) is
prone to errors. We distinguish two types of errors, namely, recognition and
advice. Recognition errors are due to misinterpretation of sensed data and
a-priori information or confusion of objects (e.g., due to faulty sensors).
Advice errors are due to outdated or wrong information associated to the
landmarks (e.g., due to weather conditions). Our path planning algorithm
proposes swarm cooperation. MAVs communicate and exchange information
wirelessly, to minimize the {\em recognition} and {\em advice} error ratios. By
doing this, the navigation system experiences a quality amplification in terms
of error reduction. As a result, our solution successfully provides an adaptive
error tolerant navigation system. Quality amplification is parametetrized with
regard to the number of MAVs. We validate our approach with theoretical proofs
and numeric simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09508</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09508</id><created>2019-06-22</created><authors><author><keyname>Cole</keyname><forenames>Kenan</forenames></author><author><keyname>Wickenheiser</keyname><forenames>Adam M.</forenames></author></authors><title>Trajectory Generation for UAVs in Unknown Environments with Extreme Wind
  Disturbances</title><categories>eess.SY cs.RO cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread use of unmanned aerial vehicles (UAVs) by the military,
commercial companies, and academia continues to push research for autonomous
vehicle navigation, particularly in varying environmental conditions and
beyond-line-of-sight (BLOS) applications. This article addresses trajectory
generation for UAVs operating in extreme environments where the wind
disturbances may exceed the vehicle's closed-loop stability bounds. To do this,
a controller is developed that has two modes of operation: (1) normal mode, and
(2) drift mode. In the normal mode the vehicle's thrust and sensor limitations
are not exceeded by environmental conditions, whereas in the drift mode they
are. In the drift mode, a drift frame that moves with the prevailing wind is
established in which the vehicle maintains control authority to generate and
track trajectories. The vehicle maintains control authority by relaxing the
inertial frame trajectory tracking requirement and re-planning the trajectory
in the drift frame. Guarantees are established to ensure tracking of the
trajectory, collision avoidance, and respecting the vehicle thrust and sensor
limitations. Simulation results demonstrate the algorithm properties through
two scenarios. First, the performance of two quadrotors is compared where one
utilizes the drift mode and the other does not. Second, multiple vehicles
navigate through two narrow openings between protected and windy environments
to demonstrate on-board updates to navigation parameters based on environmental
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09520</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09520</id><created>2019-06-22</created><authors><author><keyname>Khamidehi</keyname><forenames>Behzad</forenames></author><author><keyname>Sousa</keyname><forenames>Elvino S.</forenames></author></authors><title>Power Efficient Trajectory Optimization for the Cellular-Connected
  Aerial Vehicles</title><categories>eess.SP cs.NI</categories><comments>6 pages, 5 figures, to be presented in IEEE PIMRC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aerial vehicles have recently attracted significant attention in a variety of
commercial and civilian applications due to their high mobility, flexible
deployment and cost-effectiveness. To leverage these promising features, the
aerial users have to satisfy two critical requirements: First, they have to
maintain a reliable communication link to the ground base stations (GBSs)
throughout their flights, to support command and control data flows. Second,
the aerial vehicles have to minimize their propulsion power consumption to
remain functional until the end of their mission. In this paper, we study the
trajectory optimization problem for an aerial user flying over an area
including a set of GBSs. The objective of this problem is to find the
trajectory of the aerial user so that the total propulsion-related power
consumption of the aerial user is minimized while a cellular-connectivity
constraint is satisfied. This problem is a non-convex mixed integer non-linear
problem and hence, it is challenging to find the solution. To deal with, first,
the problem is relaxed and reformulated to a more mathematically tractable
form. Then, using successive convex approximation (SCA) technique, an iterative
algorithm is proposed to convert the problem into a sequence of convex problems
which can be solved efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09524</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09524</id><created>2019-06-22</created><updated>2019-07-10</updated><authors><author><keyname>PU</keyname><forenames>Yi-Fei</forenames></author><author><keyname>Wang</keyname><forenames>Jian</forenames></author></authors><title>Fractional-order Backpropagation Neural Networks: Modified
  Fractional-order Steepest Descent Method for Family of Backpropagation Neural
  Networks</title><categories>cs.NE cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper offers a novel mathematical approach, the modified
Fractional-order Steepest Descent Method (FSDM) for training BackPropagation
Neural Networks (BPNNs); this differs from the majority of the previous
approaches and as such. A promising mathematical method, fractional calculus,
has the potential to assume a prominent role in the applications of neural
networks and cybernetics because of its inherent strengths such as long-term
memory, nonlocality, and weak singularity. Therefore, to improve the
optimization performance of classic first-order BPNNs, in this paper we study
whether it could be possible to modified FSDM and generalize classic
first-order BPNNs to modified FSDM based Fractional-order Backpropagation
Neural Networks (FBPNNs). Motivated by this inspiration, this paper proposes a
state-of-the-art application of fractional calculus to implement a modified
FSDM based FBPNN whose reverse incremental search is in the negative directions
of the approximate fractional-order partial derivatives of the square error. At
first, the theoretical concept of a modified FSDM based FBPNN is described
mathematically. Then, the mathematical proof of the fractional-order global
optimal convergence, an assumption of the structure, and the fractional-order
multi-scale global optimization of a modified FSDM based FBPNN are analysed in
detail. Finally, we perform comparative experiments and compare a modified FSDM
based FBPNN with a classic first-order BPNN, i.e., an example function
approximation, fractional-order multi-scale global optimization, and two
comparative performances with real data. The more efficient optimal searching
capability of the fractional-order multi-scale global optimization of a
modified FSDM based FBPNN to determine the global optimal solution is the major
advantage being superior to a classic first-order BPNN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09539</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09539</id><created>2019-06-22</created><authors><author><keyname>Humphreys</keyname><forenames>Todd E.</forenames></author><author><keyname>Murrian</keyname><forenames>Matthew J.</forenames></author><author><keyname>Narula</keyname><forenames>Lakshay</forenames></author></authors><title>Deep urban unaided precise GNSS vehicle positioning</title><categories>eess.SP cs.RO</categories><comments>11 pages, 9 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the most thorough study to date of vehicular
carrier-phase differential GNSS (CDGNSS) positioning performance in a deep
urban setting unaided by complementary sensors. Using data captured during
approximately 2 hours of driving in and around the dense urban center of
Austin, TX, a CDGNSS system is demonstrated to achieve 17-cm-accurate 3D urban
positioning (95% probability) with solution availability greater than 87%. The
results are achieved without any aiding by inertial, electro-optical, or
odometry sensors. Development and evaluation of the unaided GNSS-based precise
positioning system is a key milestone toward the overall goal of combining
precise GNSS, vision, radar, and inertial sensing for all-weather
high-integrity high-absolute-accuracy positioning for automated and connected
vehicles. The system described and evaluated herein is composed of a
densely-spaced reference network, a software-defined GNSS receiver, and a
real-time kinematic (RTK) positioning engine. A performance sensitivity
analysis reveals that navigation data wipeoff for fully-modulated GNSS signals
and a dense reference network are key to high-performance urban RTK
positioning. A comparison with existing unaided systems for urban GNSS
processing indicates that the proposed system has significantly greater
availability or accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09540</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09540</id><created>2019-06-22</created><updated>2019-09-02</updated><authors><author><keyname>Zhou</keyname><forenames>Yuyin</forenames></author><author><keyname>Dreizin</keyname><forenames>David</forenames></author><author><keyname>Li</keyname><forenames>Yingwei</forenames></author><author><keyname>Zhang</keyname><forenames>Zhishuai</forenames></author><author><keyname>Wang</keyname><forenames>Yan</forenames></author><author><keyname>Yuille</keyname><forenames>Alan</forenames></author></authors><title>Multi-Scale Attentional Network for Multi-Focal Segmentation of Active
  Bleed after Pelvic Fractures</title><categories>eess.IV cs.CV</categories><comments>To appear in MICCAI-MLMI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trauma is the worldwide leading cause of death and disability in those
younger than 45 years, and pelvic fractures are a major source of morbidity and
mortality. Automated segmentation of multiple foci of arterial bleeding from
abdominopelvic trauma CT could provide rapid objective measurements of the
total extent of active bleeding, potentially augmenting outcome prediction at
the point of care, while improving patient triage, allocation of appropriate
resources, and time to definitive intervention. In spite of the importance of
active bleeding in the quick tempo of trauma care, the task is still quite
challenging due to the variable contrast, intensity, location, size, shape, and
multiplicity of bleeding foci. Existing work [4] presents a heuristic
rule-based segmentation technique which requires multiple stages and cannot be
efficiently optimized end-to-end. To this end, we present, Multi-Scale
Attentional Network (MSAN), the first yet reliable end-to-end network, for
automated segmentation of active hemorrhage from contrast-enhanced trauma CT
scans. MSAN consists of the following components: 1) an encoder which fully
integrates the global contextual information from holistic 2D slices; 2) a
multi-scale strategy applied both in the training stage and the inference stage
to handle the challenges induced by variation of target sizes; 3) an
attentional module to further refine the deep features, leading to better
segmentation quality; and 4) a multi-view mechanism to fully leverage the 3D
information. Our MSAN reports a significant improvement of more than 7%
compared to prior arts in terms of DSC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09544</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09544</id><created>2019-06-22</created><authors><author><keyname>Mohseni</keyname><forenames>Soheil</forenames></author><author><keyname>Brent</keyname><forenames>Alan C.</forenames></author><author><keyname>Burmester</keyname><forenames>Daniel</forenames></author></authors><title>A Reliability-Oriented Cost Optimisation Method for Capacity Planning of
  a Multi-Carrier Micro-Grid: A Case Study of Stewart Island, New Zealand</title><categories>eess.SY cs.SY eess.SP</categories><comments>Electricity Engineers' Association (EEA) Conference &amp; Exhibition
  2019, Auckland, New Zealand, 25-27 June 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nearly all types of energy systems (such as power systems, natural gas supply
systems, fuel supply systems, and so forth) are going through a major
transition from centralised, top-down structures to distributed, clean energy
approaches in order to address the concerns regarding climate change, air
quality, depletion of natural resources, and energy security, whilst also
enabling the supply of energy to communities in line with the goals of
sustainable development. Accordingly, the establishment of the concept of
sustainable, decentralised, multi-carrier energy systems, together with the
declining costs of renewable energy technologies, has proposed changes in the
energy industry towards the development of integrated energy systems.
Notwithstanding the potential benefits, the optimal capacity planning of these
systems with multiple energy carriers (such as electricity, heat, hydrogen, and
biogas) is exceedingly complex due to the concurrent goals and interrelated
constraints that must be satisfied, as well as the heavily context-dependent
nature of such schemes. This paper puts forward an innovative optimal capacity
planning method for a cutting-edge, stand-alone multiple energy carrier
micro-grid (MECM) serving the electricity, hot water, and transportation fuel
demands of remote communities. The proposed MECM system is equipped with wind
turbines, a hydrogen sub-system (including an electrolyser, a hydrogen
reservoir, and a fuel cell), a hybrid super-capacitor/battery energy storage
system, a hot water storage tank, a heat exchanger, an inline electric heater,
a hydrogen refuelling station, and some power converters. A numerical case
study for the optimal capacity planning of the suggested MECM configuration, to
be realised on Stewart Island, New Zealand, is presented to evaluate the
effectiveness of the proposed optimisation method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09548</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09548</id><created>2019-06-22</created><authors><author><keyname>Nguyen</keyname><forenames>Phuong-Duy</forenames></author><author><keyname>Ha</keyname><forenames>Vu Nguyen</forenames></author><author><keyname>Le</keyname><forenames>Long Bao</forenames></author></authors><title>Computation Offloading and Resource Allocation for Backhaul Limited
  Cooperative MEC Systems</title><categories>cs.DC cs.NI cs.SY eess.SY</categories><doi>10.1109/VTCFall.2019.8891244</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we jointly optimize computation offloading and resource
allocation to minimize the weighted sum of energy consumption of all mobile
users in a backhaul limited cooperative MEC system with multiple fog servers.
Considering the partial offloading strategy and TDMA transmission at each base
station, the underlying optimization problem with constraints on maximum task
latency and limited computation resource at mobile users and fog servers is
non-convex. We propose to convexify the problem exploiting the relationship
among some optimization variables from which an optimal algorithm is proposed
to solve the resulting problem. We then present numerical results to
demonstrate the significant gains of our proposed design compared to
conventional designs without exploiting cooperation among fog servers and a
greedy algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09549</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09549</id><created>2019-06-23</created><updated>2019-06-29</updated><authors><author><keyname>Huo</keyname><forenames>Yuankai</forenames></author><author><keyname>Terry</keyname><forenames>James G.</forenames></author><author><keyname>Wang</keyname><forenames>Jiachen</forenames></author><author><keyname>Nair</keyname><forenames>Sangeeta</forenames></author><author><keyname>Lasko</keyname><forenames>Thomas A.</forenames></author><author><keyname>Freedman</keyname><forenames>Barry I.</forenames></author><author><keyname>Carr</keyname><forenames>J. Jeffery</forenames></author><author><keyname>Landman</keyname><forenames>Bennett A.</forenames></author></authors><title>Fully Automatic Liver Attenuation Estimation Combing CNN Segmentation
  and Morphological Operations</title><categories>eess.IV cs.CV</categories><comments>Medical Physics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manually tracing regions of interest (ROIs) within the liver is the de facto
standard method for measuring liver attenuation on computed tomography (CT) in
diagnosing nonalcoholic fatty liver disease (NAFLD). However, manual tracing is
resource intensive. To address these limitations and to expand the availability
of a quantitative CT measure of hepatic steatosis, we propose the automatic
liver attenuation ROI-based measurement (ALARM) method for automated liver
attenuation estimation. The ALARM method consists of two major stages: (1) deep
convolutional neural network (DCNN)-based liver segmentation and (2) automated
ROI extraction. First, liver segmentation was achieved using our previously
developed SS-Net. Then, a single central ROI (center-ROI) and three circles ROI
(periphery-ROI) were computed based on liver segmentation and morphological
operations. The ALARM method is available as an open source Docker container
(https://github.com/MASILab/ALARM).246 subjects with 738 abdomen CT scans from
the African American-Diabetes Heart Study (AA-DHS) were used for external
validation (testing), independent from the training and validation cohort (100
clinically acquired CT abdominal scans).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09550</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09550</id><created>2019-06-23</created><updated>2019-06-29</updated><authors><author><keyname>Khamidehi</keyname><forenames>Behzad</forenames></author><author><keyname>Sousa</keyname><forenames>Elvino S.</forenames></author></authors><title>Reinforcement Learning-Based Trajectory Design for the Aerial Base
  Stations</title><categories>eess.SP cs.AI cs.LG cs.NI</categories><comments>6 pages, 3 figures, to be presented in IEEE PIMRC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the trajectory optimization problem for a multi-aerial base
station (ABS) communication network is investigated. The objective is to find
the trajectory of the ABSs so that the sum-rate of the users served by each ABS
is maximized. To reach this goal, along with the optimal trajectory design,
optimal power and sub-channel allocation is also of great importance to support
the users with the highest possible data rates. To solve this complicated
problem, we divide it into two sub-problems: ABS trajectory optimization
sub-problem, and joint power and sub-channel assignment sub-problem. Then,
based on the Q-learning method, we develop a distributed algorithm which solves
these sub-problems efficiently, and does not need significant amount of
information exchange between the ABSs and the core network. Simulation results
show that although Q-learning is a model-free reinforcement learning technique,
it has a remarkable capability to train the ABSs to optimize their trajectories
based on the received reward signals, which carry decent information from the
topology of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09567</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09567</id><created>2019-06-23</created><updated>2019-07-21</updated><authors><author><keyname>Ghodrat</keyname><forenames>Mohsen</forenames></author><author><keyname>Marquez</keyname><forenames>Horacio J</forenames></author></authors><title>On the Local Input-Output Stability of Event-Triggered Control Systems</title><categories>cs.SY eess.SY</categories><comments>37 pages, 6 figures</comments><journal-ref>IEEE Trans. Autom. Control 64(1), 2019, 174-189</journal-ref><doi>10.1109/TAC.2018.2809594</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies performance preserving event design in nonlinear
event-based control systems based on a local L2-type performance criterion.
Considering a finite gain local L2-stable disturbance driven continuous-time
system, we propose a triggering mechanism so that the resulting sampled-data
system preserves similar disturbance attenuation local L2-gain property. The
results are applicable to nonlinear systems with exogenous disturbances bounded
by some Lipschitz-continuous function of state. It is shown that an
exponentially decaying function of time, combined with the proposed triggering
condition, extends the inter-event periods. Compared to the existing works,
this paper analytically estimates the increase in intersampling periods at
least for an arbitrary period of time. We also propose a so-called discrete
triggering condition to quantitatively find the improvement in inter-event
times at least for an arbitrary number of triggering iterations. Illustrative
examples support the analytically derived results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09573</identifier>
 <datestamp>2020-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09573</id><created>2019-06-23</created><updated>2020-02-05</updated><authors><author><keyname>Ai</keyname><forenames>Yang</forenames></author><author><keyname>Ling</keyname><forenames>Zhen-Hua</forenames></author></authors><title>A Neural Vocoder with Hierarchical Generation of Amplitude and Phase
  Spectra for Statistical Parametric Speech Synthesis</title><categories>cs.SD eess.AS</categories><comments>Published in IEEE Transactions on Audio, Speech and Language
  Processing</comments><doi>10.1109/TASLP.2020.2970241</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a neural vocoder named HiNet which reconstructs speech
waveforms from acoustic features by predicting amplitude and phase spectra
hierarchically. Different from existing neural vocoders such as WaveNet,
SampleRNN and WaveRNN which directly generate waveform samples using single
neural networks, the HiNet vocoder is composed of an amplitude spectrum
predictor (ASP) and a phase spectrum predictor (PSP). The ASP is a simple DNN
model which predicts log amplitude spectra (LAS) from acoustic features. The
predicted LAS are sent into the PSP for phase recovery. Considering the issue
of phase warping and the difficulty of phase modeling, the PSP is constructed
by concatenating a neural source-filter (NSF) waveform generator with a phase
extractor. We also introduce generative adversarial networks (GANs) into both
ASP and PSP. Finally, the outputs of ASP and PSP are combined to reconstruct
speech waveforms by short-time Fourier synthesis. Since there are no
autoregressive structures in both predictors, the HiNet vocoder can generate
speech waveforms with high efficiency. Objective and subjective experimental
results show that our proposed HiNet vocoder achieves better naturalness of
reconstructed speech than the conventional STRAIGHT vocoder, a 16-bit WaveNet
vocoder using open source implementation and an NSF vocoder with similar
complexity to the PSP and obtains similar performance with a 16-bit WaveRNN
vocoder. We also find that the performance of HiNet is insensitive to the
complexity of the neural waveform generator in PSP to some extend. After
simplifying its model structure, the time consumed for generating 1s waveforms
of 16kHz speech using a GPU can be further reduced from 0.34s to 0.19s without
significant quality degradation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09652</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09652</id><created>2019-06-23</created><authors><author><keyname>Alexandru</keyname><forenames>Andreea B.</forenames></author><author><keyname>Pappas</keyname><forenames>George J.</forenames></author></authors><title>Secure Multi-party Computation for Cloud-based Control</title><categories>eess.SY cs.CR cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter, we will explore the cloud-outsourced privacy-preserving
computation of a controller on encrypted measurements from a (possibly
distributed) system, taking into account the challenges introduced by the
dynamical nature of the data. The privacy notion used in this work is that of
cryptographic multi-party privacy, i.e., the computation of a functionality
should not reveal anything more than what can be inferred only from the inputs
and outputs of the functionality. The main theoretical concept used towards
this goal is Homomorphic Encryption, which allows the evaluation of sums and
products on encrypted data, and, when combined with other cryptographic
techniques, such as Secret Sharing, results in a powerful tool for solving a
wide range of secure multi-party problems. We will rigorously define these
concepts and discuss how multi-party privacy can be enforced in the
implementation of a Model Predictive Controller, which encompasses computing
stabilizing control actions by solving an optimization problem on encrypted
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09665</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09665</id><created>2019-06-23</created><updated>2019-07-12</updated><authors><author><keyname>Rios</keyname><forenames>Gonzalo</forenames></author><author><keyname>Tobar</keyname><forenames>Felipe</forenames></author></authors><title>Compositionally-Warped Gaussian Processes</title><categories>stat.ML cs.LG eess.SP</categories><comments>Accepted at Elsevier Neural Networks, DOI added and author order
  corrected</comments><doi>10.1016/j.neunet.2019.06.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gaussian process (GP) is a nonparametric prior distribution over
functions indexed by time, space, or other high-dimensional index set. The GP
is a flexible model yet its limitation is given by its very nature: it can only
model Gaussian marginal distributions. To model non-Gaussian data, a GP can be
warped by a nonlinear transformation (or warping) as performed by warped GPs
(WGPs) and more computationally-demanding alternatives such as Bayesian WGPs
and deep GPs. However, the WGP requires a numerical approximation of the
inverse warping for prediction, which increases the computational complexity in
practice. To sidestep this issue, we construct a novel class of warpings
consisting of compositions of multiple elementary functions, for which the
inverse is known explicitly. We then propose the compositionally-warped GP
(CWGP), a non-Gaussian generative model whose expressiveness follows from its
deep compositional architecture, and its computational efficiency is guaranteed
by the analytical inverse warping. Experimental validation using synthetic and
real-world datasets confirms that the proposed CWGP is robust to the choice of
warpings and provides more accurate point predictions, better trained models
and shorter computation times than WGP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09666</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09666</id><created>2019-06-23</created><authors><author><keyname>Moghimi</keyname><forenames>Ali</forenames></author><author><keyname>Yang</keyname><forenames>Ce</forenames></author><author><keyname>Anderson</keyname><forenames>James A.</forenames></author></authors><title>Aerial hyperspectral imagery and deep neural networks for
  high-throughput yield phenotyping in wheat</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Crop production needs to increase in a sustainable manner to meet the growing
global demand for food. To identify crop varieties with high yield potential,
plant scientists and breeders evaluate the performance of hundreds of lines in
multiple locations over several years. To facilitate the process of selecting
advanced varieties, an automated framework was developed in this study. A
hyperspectral camera was mounted on an unmanned aerial vehicle to collect
aerial imagery with high spatial and spectral resolution. Aerial images were
captured in two consecutive growing seasons from three experimental yield
fields composed of hundreds experimental plots (1x2.4 meter), each contained a
single wheat line. The grain of more than thousand wheat plots was harvested by
a combine, weighed, and recorded as the ground truth data. To leverage the high
spatial resolution and investigate the yield variation within the plots, images
of plots were divided into sub-plots by integrating image processing techniques
and spectral mixture analysis with the expert domain knowledge. Afterwards, the
sub-plot dataset was divided into train, validation, and test sets using
stratified sampling. Subsequent to extracting features from each sub-plot, deep
neural networks were trained for yield estimation. The coefficient of
determination for predicting the yield of the test dataset at sub-plot scale
was 0.79 with root mean square error of 5.90 grams. In addition to providing
insights into yield variation at sub-plot scale, the proposed framework can
facilitate the process of high-throughput yield phenotyping as a valuable
decision support tool. It offers the possibility of (i) remote visual
inspection of the plots, (ii) studying the effect of crop density on yield, and
(iii) optimizing plot size to investigate more lines in a dedicated field each
year.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09677</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09677</id><created>2019-06-23</created><authors><author><keyname>Jaffe</keyname><forenames>Lucas</forenames></author><author><keyname>Zelinski</keyname><forenames>Michael</forenames></author><author><keyname>Sakla</keyname><forenames>Wesam</forenames></author></authors><title>Remote Sensor Design for Visual Recognition with Convolutional Neural
  Networks</title><categories>eess.IV cs.CV</categories><comments>Accepted for publication in IEEE Transactions on Geoscience and
  Remote Sensing</comments><report-no>LLNL-JRNL-760588</report-no><doi>10.1109/TGRS.2019.2925813</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While deep learning technologies for computer vision have developed rapidly
since 2012, modeling of remote sensing systems has remained focused around
human vision. In particular, remote sensing systems are usually constructed to
optimize sensing cost-quality trade-offs with respect to human image
interpretability. While some recent studies have explored remote sensing system
design as a function of simple computer vision algorithm performance, there has
been little work relating this design to the state-of-the-art in computer
vision: deep learning with convolutional neural networks. We develop
experimental systems to conduct this analysis, showing results with modern deep
learning algorithms and recent overhead image data. Our results are compared to
standard image quality measurements based on human visual perception, and we
conclude not only that machine and human interpretability differ significantly,
but that computer vision performance is largely self-consistent across a range
of disparate conditions. This research is presented as a cornerstone for a new
generation of sensor design systems which focus on computer algorithm
performance instead of human visual perception.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09683</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09683</id><created>2019-06-23</created><updated>2019-06-27</updated><authors><author><keyname>Cheng</keyname><forenames>Zhengxue</forenames></author><author><keyname>Sun</keyname><forenames>Heming</forenames></author><author><keyname>Takeuchi</keyname><forenames>Masaru</forenames></author><author><keyname>Katto</keyname><forenames>Jiro</forenames></author></authors><title>Learning Image and Video Compression through Spatial-Temporal Energy
  Compaction</title><categories>eess.IV</categories><comments>accepted by CVPR2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compression has been an important research topic for many decades, to produce
a significant impact on data transmission and storage. Recent advances have
shown a great potential of learning image and video compression. Inspired from
related works, in this paper, we present an image compression architecture
using a convolutional autoencoder, and then generalize image compression to
video compression, by adding an interpolation loop into both encoder and
decoder sides. Our basic idea is to realize spatial-temporal energy compaction
in learning image and video compression. Thereby, we propose to add a spatial
energy compaction-based penalty into loss function, to achieve higher image
compression performance. Furthermore, based on temporal energy distribution, we
propose to select the number of frames in one interpolation loop, adapting to
the motion characteristics of video contents. Experimental results demonstrate
that our proposed image compression outperforms the latest image compression
standard with MS-SSIM quality metric, and provides higher performance compared
with state-of-the-art learning compression methods at high bit rates, which
benefits from our spatial energy compaction approach. Meanwhile, our proposed
video compression approach with temporal energy compaction can significantly
outperform MPEG-4 and is competitive with commonly used H.264. Both our image
and video compression can produce more visually pleasant results than
traditional standards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09684</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09684</id><created>2019-06-23</created><updated>2019-06-30</updated><authors><author><keyname>Liu</keyname><forenames>Yalong</forenames></author><author><keyname>Li</keyname><forenames>Jie</forenames></author><author><keyname>Wang</keyname><forenames>Ying</forenames></author><author><keyname>Wang</keyname><forenames>Miaomiao</forenames></author><author><keyname>Li</keyname><forenames>Xianjun</forenames></author><author><keyname>Jiao</keyname><forenames>Zhicheng</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author><author><keyname>Gao</keyname><forenames>Xingbo</forenames></author></authors><title>Refined-Segmentation R-CNN: A Two-stage Convolutional Neural Network for
  Punctate White Matter Lesion Segmentation in Preterm Infants</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate segmentation of punctate white matter lesion (PWML) in infantile
brains by an automatic algorithm can reduce the potential risk of postnatal
development. How to segment PWML effectively has become one of the active
topics in medical image segmentation in recent years. In this paper, we
construct an efficient two-stage PWML semantic segmentation network based on
the characteristics of the lesion, called refined segmentation R-CNN (RS RCNN).
We propose a heuristic RPN (H-RPN) which can utilize surrounding information
around the PWMLs for heuristic segmentation. Also, we design a lightweight
segmentation network to segment the lesion in a fast way. Densely connected
conditional random field (DCRF) is used to optimize the segmentation results.
We only use T1w MRIs to segment PWMLs. The result shows that our model can well
segment the lesion of ordinary size or even pixel size. The Dice similarity
coefficient reaches 0.6616, the sensitivity is 0.7069, the specificity is
0.9997, and the Hausdorff distance is 52.9130. The proposed method outperforms
the state-of-the-art algorithm. (The code of this paper is available on
https://github.com/YalongLiu/Refined-Segmentation-R-CNN)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09701</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09701</id><created>2019-06-23</created><authors><author><keyname>Wang</keyname><forenames>Hui-Ming</forenames></author><author><keyname>Zhang</keyname><forenames>Xu</forenames></author><author><keyname>Jiang</keyname><forenames>Jia-Cheng</forenames></author></authors><title>UAV-Involved Wireless Physical-Layer Secure Communications: Overview and
  Research Directions</title><categories>eess.SP cs.IT cs.NI math.IT</categories><comments>18 pages, 6 figures, accepted by IEEE Wireless Communications for
  publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to their flexible deployment and on-demand mobility, small-scale unmanned
aerial vehicles (UAVs) are anticipated to be involved in widespread
communication applications in the forthcoming fifth-generation (5G) networks.
However, the confidentiality of UAV communication applications is vulnerable to
security threats due to the broadcast nature and dominant line-of-sight (LoS)
channel conditions, and physical-layer security (PLS) technique can be applied
for secrecy performance enhancement in such a context. On the other hand, it is
also promising to exploit UAVs to cooperatively protect secure communications.
This article provides an overview of the recent research efforts on
UAV-involved secure communications at the physical layer. We focus on the
design of secure transmission schemes according to different roles of UAVs and
the optimization of introduced degrees of freedom (DoFs) by the unique
characteristics of UAVs. We also propose some future research directions on
this topic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09721</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09721</id><created>2019-06-24</created><authors><author><keyname>Farokhi</keyname><forenames>Farhad</forenames></author></authors><title>A Game-Theoretic Approach to Adversarial Linear Support Vector
  Classification</title><categories>cs.CR cs.LG cs.SY eess.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we employ a game-theoretic model to analyze the interaction
between an adversary and a classifier. There are two classes (i.e., positive
and negative classes) to which data points can belong. The adversary is
interested in maximizing the probability of miss-detection for the positive
class (i.e., false negative probability). The adversary however does not want
to significantly modify the data point so that it still maintains favourable
traits of the original class. The classifier, on the other hand, is interested
in maximizing the probability of correct detection for the positive class
(i.e., true positive probability) subject to a lower-bound on the probability
of correct detection for the negative class (i.e., true negative probability).
For conditionally Gaussian data points (conditioned on the class) and linear
support vector machine classifiers, we rewrite the optimization problems of the
adversary and the classifier as convex optimization problems and use best
response dynamics to learn an equilibrium of the game. This results in
computing a linear support vector machine classifier that is robust against
adversarial input manipulations. We illustrate the framework on a synthetic
dataset and a public Cardiovascular Disease dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09726</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09726</id><created>2019-06-21</created><authors><author><keyname>Ajani</keyname><forenames>Bhavya</forenames></author></authors><title>Automatic Intracranial Brain Segmentation from Computed Tomography Head
  Images</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast and automatic algorithm to segment Brain (intracranial region) from
computed tomography (CT) head images using combination of HU thresholding,
identification of intracranial voxels through ray intersection with cranium,
special binary erosion and connected components per slice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09731</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09731</id><created>2019-06-24</created><authors><author><keyname>Cheng</keyname><forenames>Zhengxue</forenames></author><author><keyname>Sun</keyname><forenames>Heming</forenames></author><author><keyname>Takeuchi</keyname><forenames>Masaru</forenames></author><author><keyname>Katto</keyname><forenames>Jiro</forenames></author></authors><title>Deep Residual Learning for Image Compression</title><categories>eess.IV</categories><comments>accepted by CVPR workshop and Challenge on Learned Image Compression
  (CLIC) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide a detailed description on our approach designed for
CVPR 2019 Workshop and Challenge on Learned Image Compression (CLIC). Our
approach mainly consists of two proposals, i.e. deep residual learning for
image compression and sub-pixel convolution as up-sampling operations.
Experimental results have indicated that our approaches, Kattolab, Kattolabv2
and KattolabSSIM, achieve 0.972 in MS-SSIM at the rate constraint of 0.15bpp
with moderate complexity during the validation phase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09745</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09745</id><created>2019-06-24</created><authors><author><keyname>Jiang</keyname><forenames>Wenhao</forenames></author><author><keyname>Liu</keyname><forenames>Zhiyu</forenames></author><author><keyname>Lee</keyname><forenames>Kit-Hang</forenames></author><author><keyname>Chen</keyname><forenames>Shihui</forenames></author><author><keyname>Ng</keyname><forenames>Yui-Lun</forenames></author><author><keyname>Dou</keyname><forenames>Qi</forenames></author><author><keyname>Chang</keyname><forenames>Hing-Chiu</forenames></author><author><keyname>Kwok</keyname><forenames>Ka-Wai</forenames></author></authors><title>Respiratory Motion Correction in Abdominal MRI using a Densely Connected
  U-Net with GAN-guided Training</title><categories>eess.IV cs.AI</categories><comments>8 pages, 4 figures, submitted to the 22nd International Conference on
  Medical Image Computing and Computer Assisted Intervention</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Abdominal magnetic resonance imaging (MRI) provides a straightforward way of
characterizing tissue and locating lesions of patients as in standard
diagnosis. However, abdominal MRI often suffers from respiratory motion
artifacts, which leads to blurring and ghosting that significantly deteriorate
the imaging quality. Conventional methods to reduce or eliminate these motion
artifacts include breath holding, patient sedation, respiratory gating, and
image post-processing, but these strategies inevitably involve extra scanning
time and patient discomfort. In this paper, we propose a novel
deep-learning-based model to recover MR images from respiratory motion
artifacts. The proposed model comprises a densely connected U-net with
generative adversarial network (GAN)-guided training and a perceptual loss
function. We validate the model using a diverse collection of MRI data that are
adversely affected by both synthetic and authentic respiration artifacts.
Effective outcomes of motion removal are demonstrated. Our experimental results
show the great potential of utilizing deep-learning-based methods in
respiratory motion correction for abdominal MRI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09746</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09746</id><created>2019-06-24</created><authors><author><keyname>Roblot</keyname><forenames>Sandrine</forenames></author><author><keyname>Hunukumbure</keyname><forenames>Mythri</forenames></author><author><keyname>Varsier</keyname><forenames>Nad&#xe8;ge</forenames></author><author><keyname>Santiago</keyname><forenames>Elena</forenames></author><author><keyname>Bao</keyname><forenames>Yu</forenames></author><author><keyname>Langouet</keyname><forenames>Serge</forenames></author><author><keyname>Hamon</keyname><forenames>Marie-H&#xe9;l&#xe8;ne</forenames></author><author><keyname>Jeux</keyname><forenames>Sebastien</forenames></author></authors><title>Techno-economic analyses for vertical use cases in the 5G domain</title><categories>eess.SP cs.NI</categories><proxy>ccsd</proxy><journal-ref>EuCNC ONE5G special session, Jun 2019, Valencia, Spain</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides techno-economic analyses on the network deployments to
cover 4 key verticals, under 5G-NR. These verticals, namely Automotive, Smart
city, Long range connectivity and Disaster and emergency support, were chosen
to reflect the ONE5G project objective of investigating environments from
densely populated cities (''Megacity'') to large underserved areas. The work
presented covers the network deployment framework including common
centralization strategies and the main cost factors. Initial results presented
for long range connectivity and emergency support networks provide the cost
trade-offs in different deployment options and cost sensitivity to some of the
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09762</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09762</id><created>2019-06-24</created><authors><author><keyname>Meng</keyname><forenames>Xianling</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Yitu</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author></authors><title>Closed-Form Delay-Optimal Computation Offloading in Mobile Edge
  Computing Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>36 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile edge computing (MEC) has recently emerged as a promising technology to
release the tension between computation-intensive applications and
resource-limited mobile terminals (MTs). In this paper, we study the
delay-optimal computation offloading in computation-constrained MEC systems. We
consider the computation task queue at the MEC server due to its constrained
computation capability. In this case, the task queue at the MT and that at the
MEC server are strongly coupled in a cascade manner, which creates complex
interdependencies and brings new technical challenges. We model the computation
offloading problem as an infinite horizon average cost Markov decision process
(MDP), and approximate it to a virtual continuous time system (VCTS) with
reflections. Different to most of the existing works, we develop the dynamic
instantaneous rate estimation for deriving the closed-form approximate priority
functions in different scenarios. Based on the approximate priority functions,
we propose a closed-form multi-level water-filling computation offloading
solution to characterize the influence of not only the local queue state
information (LQSI) but also the remote queue state information (RQSI). A
extension is provided from single MT single MEC server scenarios to multiple
MTs multiple MEC servers scenarios and several insights are derived. Finally,
the simulation results show that the proposed scheme outperforms the
conventional schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09763</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09763</id><created>2019-06-24</created><authors><author><keyname>Freiman</keyname><forenames>Moti</forenames></author><author><keyname>Nickisch</keyname><forenames>Hannes</forenames></author><author><keyname>Prevrhal</keyname><forenames>Sven</forenames></author><author><keyname>Schmitt</keyname><forenames>Holger</forenames></author><author><keyname>Vembar</keyname><forenames>Mani</forenames></author><author><keyname>Maurovich-Horvat</keyname><forenames>P&#xe1;l</forenames></author><author><keyname>Donnelly</keyname><forenames>Patrick</forenames></author><author><keyname>Goshen</keyname><forenames>Liran</forenames></author></authors><title>Improving CCTA based lesions' hemodynamic significance assessment by
  accounting for partial volume modeling in automatic coronary lumen
  segmentation</title><categories>eess.IV cs.CV physics.med-ph</categories><journal-ref>Medical Physics 44: 1040-1049, 2017</journal-ref><doi>10.1002/mp.12121</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: The goal of this study was to assess the potential added benefit of
accounting for partial volume effects (PVE) in an automatic coronary lumen
segmentation algorithm from coronary computed tomography angiography (CCTA).
Materials and methods: We assessed the potential added value of PVE integration
as a part of the automatic coronary lumen segmentation algorithm by means of
segmentation accuracy using the MICCAI 2012 challenge framework and by means of
flow simulation overall accuracy, sensitivity, specificity, negative and
positive predictive values and the receiver operated characteristic (ROC) area
under the curve. We also evaluated the potential benefit of accounting for PVE
in automatic segmentation for flow-simulation for lesions that were diagnosed
as obstructive based on CCTA, which could have indicated a need for an invasive
exam and revascularization. Results: Our segmentation algorithm improves the
maximal surface distance error by ~39% compared to previously published method
on the 18 datasets 50 from the MICCAI 2012 challenge with comparable Dice and
mean surface distance. Results with and without accounting for PVE were
comparable. In contrast, integrating PVE analysis into an automatic coronary
lumen segmentation algorithm improved the flow simulation specificity from 0.6
to 0.68 with the same sensitivity of 0.83. Also, accounting for PVE improved
the area under the ROC curve for detecting hemodynamically significant CAD from
0.76 to 0.8 compared to automatic segmentation without PVE analysis with
invasive FFR threshold of 0.8 as the reference standard. The improvement in the
AUC was statistically significant (N=76, Delong's test, p=0.012). Conclusion:
Accounting for the partial volume effects in automatic coronary lumen
segmentation algorithms has the potential to improve the accuracy of CCTA-based
hemodynamic assessment of coronary artery lesions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09792</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09792</id><created>2019-06-24</created><authors><author><keyname>Liga</keyname><forenames>Gabriele</forenames></author><author><keyname>Sheikh</keyname><forenames>Alireza</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author></authors><title>A novel soft-aided bit-marking decoder for product codes</title><categories>cs.IT eess.SP math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We introduce a novel soft-aided hard-decision decoder for product codes
adopting bit marking via updated reliabilities at each decoding iteration.
Gains up to 0.8 dB vs. standard iterative bounded distance decoding and up to
0.3 dB vs. our previously proposed bit-marking decoder are demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09811</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09811</id><created>2019-06-24</created><authors><author><keyname>Raj</keyname><forenames>Vishnu</forenames></author><author><keyname>Kalyani</keyname><forenames>Sheetal</forenames></author></authors><title>Blind decoding in $\alpha$-Stable noise: An online learning approach</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel method for performing error control coding in Symmetric
$\alpha-$Stable noise environments without any prior knowledge about the value
of $\alpha$ is introduced. We use an online learning framework which employs
multiple distributions to decode the received block and then combines these
results based on the past performance of each individual distributions. The
proposed method is also able to handle a mixture of Symmetric $\alpha-$Stable
distributed noises. Performance results in turbo coded system highlight the
utility of the work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09825</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09825</id><created>2019-06-24</created><authors><author><keyname>Seshadri</keyname><forenames>Shreyas</forenames></author><author><keyname>R&#xe4;s&#xe4;nen</keyname><forenames>Okko</forenames></author></authors><title>SylNet: An Adaptable End-to-End Syllable Count Estimator for Speech</title><categories>cs.CL cs.SD eess.AS</categories><doi>10.1109/LSP.2019.2929415</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic syllable count estimation (SCE) is used in a variety of
applications ranging from speaking rate estimation to detecting social activity
from wearable microphones or developmental research concerned with quantifying
speech heard by language-learning children in different environments. The
majority of previously utilized SCE methods have relied on heuristic DSP
methods, and only a small number of bi-directional long short-term memory
(BLSTM) approaches have made use of modern machine learning approaches in the
SCE task. This paper presents a novel end-to-end method called SylNet for
automatic syllable counting from speech, built on the basis of a recent
developments in neural network architectures. We describe how the entire model
can be optimized directly to minimize SCE error on the training data without
annotations aligned at the syllable level, and how it can be adapted to new
languages using limited speech data with known syllable counts. Experiments on
several different languages reveal that SylNet generalizes to languages beyond
its training data and further improves with adaptation. It also outperforms
several previously proposed methods for syllabification, including end-to-end
BLSTMs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09835</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09835</id><created>2019-06-24</created><authors><author><keyname>Asgari</keyname><forenames>Hajar</forenames></author><author><keyname>Maybodi</keyname><forenames>BabakMazloom-Nezhad</forenames></author><author><keyname>Kreiser</keyname><forenames>Raphaela</forenames></author><author><keyname>Sandamirskaya</keyname><forenames>Yulia</forenames></author></authors><title>Digital Multiplier-less Event-Driven Spiking Neural Network Architecture
  for Learning a Context-Dependent Task</title><categories>q-bio.NC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neuromorphic engineers aim to develop event-based spiking neural networks
(SNNs) in hardware. These SNNs closer resemble dynamics of biological neurons
than todays' artificial neural networks and achieve higher efficiency thanks to
the event-based, asynchronous nature of processing. Learning in SNNs is more
challenging, however. Since conventional supervised learning methods cannot be
ported on SNNs due to the non-differentiable event-based nature of their
activation, learning in SNNs is currently an active research topic.
Reinforcement learning (RL) is particularly promising method for neuromorphic
implementation, especially in the field of autonomous agents' control, and is
in focus of this work. In particular, in this paper we propose a new digital
multiplier-less hardware implementation of an SNN. We show how this network can
learn stimulus-response associations in a context-dependent task through a RL
mechanism. The task is inspired by biological experiments used to study RL in
animals. The architecture is described using the standard digital design flow
and uses power- and space-efficient cores. We implement the behavioral
experiments using a robot, to show that learning in hardware also works in a
closed sensorimotor loop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09841</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09841</id><created>2019-06-24</created><authors><author><keyname>Liu</keyname><forenames>Tianle</forenames></author><author><keyname>Tong</keyname><forenames>Jun</forenames></author><author><keyname>Guo</keyname><forenames>Qinghua</forenames></author><author><keyname>Xi</keyname><forenames>Jiangtao</forenames></author><author><keyname>Yu</keyname><forenames>Yanguang</forenames></author><author><keyname>Xiao</keyname><forenames>Zhitao</forenames></author></authors><title>On the Performance of Massive MIMO Systems With Low-Resolution ADCs Over
  Rician Fading Channels</title><categories>eess.SP cs.IT cs.NI math.IT</categories><comments>12 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers uplink massive multiple-input multiple-output (MIMO)
systems with lowresolution analog-to-digital converters (ADCs) over Rician
fading channels. Maximum-ratio-combining (MRC) and zero-forcing (ZF) receivers
are considered under the assumption of perfect and imperfect channel state
information (CSI). Low-resolution ADCs are considered for both data detection
and channel estimation, and the resulting performance is analyzed. Asymptotic
approximations of the spectrum efficiency (SE) for large systems are derived
based on random matrix theory. With these results, we can provide insights into
the trade-offs between the SE and the ADC resolution and study the influence of
the Rician K-factors on the performance. It is shown that a large value of
K-factors may lead to better performance and alleviate the influence of
quantization noise on channel estimation. Moreover, we investigate the power
scaling laws for both receivers under imperfect CSI and it shows that when the
number of base station (BS) antennas is very large, without loss of SE
performance, the transmission power can be scaled by the number of BS antennas
for both receivers while the overall performance is limited by the resolution
of ADCs. The asymptotic analysis is validated by numerical results. Besides, it
is also shown that the SE gap between the two receivers is narrowed down when
the K-factor is increased. We also show that ADCs with moderate resolutions
lead to better energy efficiency (EE) than that with high-resolution or
extremely low-resolution ADCs and using ZF receivers achieve higher EE as
compared with the MRC receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09847</identifier>
 <datestamp>2020-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09847</id><created>2019-06-24</created><updated>2020-01-14</updated><authors><author><keyname>Menner</keyname><forenames>Marcel</forenames></author><author><keyname>Neuner</keyname><forenames>Lukas</forenames></author><author><keyname>L&#xfc;nenburger</keyname><forenames>Lars</forenames></author><author><keyname>Zeilinger</keyname><forenames>Melanie N.</forenames></author></authors><title>Using Human Ratings for Feedback Control: A Supervised Learning Approach
  with Application to Rehabilitation Robotics</title><categories>cs.RO cs.SY eess.SY</categories><doi>10.1109/TRO.2020.2964147</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for tailoring a parametric controller based on
human ratings. The method leverages supervised learning concepts in order to
train a reward model from data. It is applied to a gait rehabilitation robot
with the goal of teaching the robot how to walk patients physiologically. In
this context, the reward model judges the physiology of the gait cycle (instead
of therapists) using sensor measurements provided by the robot and the
automatic feedback controller chooses the input settings of the robot to
maximize the reward. The key advantage of the proposed method is that only a
few input adaptations are necessary to achieve a physiological gait cycle.
Experiments with nondisabled subjects show that the proposed method permits the
incorporation of human expertise into a control law and to automatically walk
patients physiologically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09867</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09867</id><created>2019-06-24</created><updated>2020-01-06</updated><authors><author><keyname>Ke</keyname><forenames>Malong</forenames></author><author><keyname>Gao</keyname><forenames>Zhen</forenames></author><author><keyname>Wu</keyname><forenames>Yongpeng</forenames></author><author><keyname>Gao</keyname><forenames>Xiqi</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Compressive Sensing Based Adaptive Active User Detection and Channel
  Estimation: Massive Access Meets Massive MIMO</title><categories>eess.SP cs.IT math.IT</categories><comments>15 pages, 12 figures. The current version has been acceptted by IEEE
  Transactions on Signal Processing. A related work has been presented at
  GlobalSIP, Anaheim, USA, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers massive access in massive multiple-input multiple-output
(MIMO) systems and proposes an adaptive active user detection and channel
estimation scheme based on compressive sensing. By exploiting the sporadic
traffic of massive connected user equipments and the virtual angular domain
sparsity of massive MIMO channels, the proposed scheme can support massive
access with dramatically reduced access latency. Specifically, we design
non-orthogonal pseudo-random pilots for uplink broadband massive access, and
formulate the active user detection and channel estimation problems as a
generalized multiple measurement vector compressive sensing problem.
Furthermore, by leveraging the structured sparsity of the uplink channel
matrix, we propose an efficient generalized multiple measurement vector
approximate message passing (GMMV-AMP) algorithm to realize simultaneous active
user detection and channel estimation based on a spatial domain or an angular
domain channel model. To jointly exploit the channel sparsity presented in both
the spatial and the angular domains for enhanced performance, a Turbo-GMMV-AMP
algorithm is developed for detecting the active users and estimating their
channels in an alternating manner. Finally, an adaptive access scheme is
proposed, which adapts the access latency to guarantee reliable massive access
for practical systems with unknown channel sparsity level. Additionally, the
state evolution of the proposed GMMV-AMP algorithm is derived to predict its
performance. Simulation results demonstrate the superiority of the proposed
active user detection and channel estimation schemes compared to several
baseline schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09884</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09884</id><created>2019-06-24</created><updated>2019-08-21</updated><authors><author><keyname>Yan</keyname><forenames>Niu</forenames></author><author><keyname>Ouyang</keyname><forenames>Jihong</forenames></author></authors><title>Cross-Channel Correlation Preserved Three-Stream Lightweight CNNs for
  Demosaicking</title><categories>cs.CV cs.MM eess.IV</categories><comments>This paper, originally titled as &quot;Color Dedemosaicking by Parallel
  CNNs Leveraging Cross-Channel Difference&quot;, was submitted to conference IJCAI
  2019 for peer review at Feb. 14 2019 via the conference submission system.
  The submission was rejected. The August arxiv version of this paper is as
  same as its June arxiv version. We add these comments only</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Demosaicking is a procedure to reconstruct full RGB images from Color Filter
Array (CFA) samples, none of which has all color components available. Recent
deep Convolutional Neural Networks (CNN) based models have obtained state of
the art accuracy on benchmark datasets. However, due to the sequential feature
extraction manner of CNNs, deep demosaicking models may be over slow for daily
use cameras. In this paper, we decouple deep sequential demosaicking to
three-stream lightweight networks, which restore the green channel, the
green-red difference plane and the green-blue difference plane respectively.
This strategy allows independent offline training and parallel online
estimation, whilst preserving the intrinsic cross-channel correlation of
natural images. Moreover, this allows designing each stream according to the
various restoration difficulty of each channel. As validated by extensive
experiments, our method achieves top accuracy at fast speed. Source code will
be released along with paper publication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09885</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09885</id><created>2019-06-24</created><authors><author><keyname>Csap&#xf3;</keyname><forenames>Tam&#xe1;s G&#xe1;bor</forenames></author><author><keyname>Al-Radhi</keyname><forenames>Mohammed Salah</forenames></author><author><keyname>N&#xe9;meth</keyname><forenames>G&#xe9;za</forenames></author><author><keyname>Gosztolya</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Gr&#xf3;sz</keyname><forenames>Tam&#xe1;s</forenames></author><author><keyname>T&#xf3;th</keyname><forenames>L&#xe1;szl&#xf3;</forenames></author><author><keyname>Mark&#xf3;</keyname><forenames>Alexandra</forenames></author></authors><title>Ultrasound-based Silent Speech Interface Built on a Continuous Vocoder</title><categories>cs.SD eess.AS</categories><comments>5 pages, 3 figures, accepted for publication at Interspeech 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recently it was shown that within the Silent Speech Interface (SSI) field,
the prediction of F0 is possible from Ultrasound Tongue Images (UTI) as the
articulatory input, using Deep Neural Networks for articulatory-to-acoustic
mapping. Moreover, text-to-speech synthesizers were shown to produce higher
quality speech when using a continuous pitch estimate, which takes non-zero
pitch values even when voicing is not present. Therefore, in this paper on
UTI-based SSI, we use a simple continuous F0 tracker which does not apply a
strict voiced / unvoiced decision. Continuous vocoder parameters (ContF0,
Maximum Voiced Frequency and Mel-Generalized Cepstrum) are predicted using a
convolutional neural network, with UTI as input. The results demonstrate that
during the articulatory-to-acoustic mapping experiments, the continuous F0 is
predicted with lower error, and the continuous vocoder produces slightly more
natural synthesized speech than the baseline vocoder using standard
discontinuous F0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09888</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09888</id><created>2019-06-24</created><authors><author><keyname>Jameel</keyname><forenames>Furqan</forenames></author><author><keyname>Ristaniemi</keyname><forenames>Tapani</forenames></author><author><keyname>Khan</keyname><forenames>Imran</forenames></author><author><keyname>Lee</keyname><forenames>Byung Moo</forenames></author></authors><title>Simultaneous Harvest-and-Transmit Ambient Backscatter Communications
  under Rayleigh Fading</title><categories>eess.SP cs.SY eess.SY</categories><comments>11 Pages, 7 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ambient backscatter communications is an emerging paradigm and a key enabler
for pervasive connectivity of low-powered wireless devices. It is primarily
beneficial in the Internet of things (IoT) and the situations where computing
and connectivity capabilities expand to sensors and miniature devices that
exchange data on a low power budget. The premise of the ambient backscatter
communication is to build a network of devices capable of operating in a
battery-free manner by means of smart networking, radio frequency (RF) energy
harvesting and power management at the granularity of individual bits and
instructions. Due to this innovation in communication methods, it is essential
to investigate the performance of these devices under practical constraints. To
do so, this article formulates a model for wireless-powered ambient backscatter
devices and derives a closed-form expression of outage probability under
Rayleigh fading. Based on this expression, the article provides the
power-splitting factor that balances the tradeoff between energy harvesting and
achievable data rate. Our results also shed light on the complex interplay of a
power-splitting factor, amount of harvested energy, and the achievable data
rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09902</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09902</id><created>2019-06-18</created><authors><author><keyname>Mziou-Sallami</keyname><forenames>Mallek</forenames><affiliation>IRT SystemX</affiliation></author><author><keyname>Kaddah</keyname><forenames>Rim</forenames><affiliation>IRT SystemX</affiliation></author><author><keyname>Hamida</keyname><forenames>Amira Ben</forenames><affiliation>IRT SystemX</affiliation></author></authors><title>A Study of Solar Irradiance Prediction Error Impact on a Home Energy
  Management System</title><categories>eess.SP</categories><proxy>ccsd</proxy><journal-ref>The Ninth International Conference on Smart Grids, Green
  Communications and IT Energy-aware Technologies, Jun 2019, Ath{\`e}nes,
  Greece</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, Energy Management Systems (EMS) are accessible for homes and
buildings to optimize energy consumption especially when solar panels and
batteries are installed. The intelligence of existing systems is often based on
environmental or exogenous information like the weather, energy prices, and
endogenous information like user consumption behavior and activity. The
solutions aim to adapt a consumption profile to the produced energy in order to
reduce costs. In the case of a perfect prediction of all variables, system
performance can be controlled. In this article, we study the impact of
generation prediction error on the daily energy cost. For this, we consider the
energy management system as a black-box and we simulate multiple scenarios with
different prediction errors using the quasi-random Monte Carlo method. We
observe the global sensitivity of the system by measuring the Sobol indices in
order to identify errors that impact more the daily energy cost. The analyses
are based on French consumption data and on irradiance data for Carpentras,
France. Results show that findings are aligned with battery charge and
discharge strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09905</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09905</id><created>2019-06-18</created><authors><author><keyname>T&#xfc;retken</keyname><forenames>Engin</forenames></author><author><keyname>Van Zaen</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Delgado-Gonzalo</keyname><forenames>Ricard</forenames></author></authors><title>Embedded Deep Learning for Sleep Staging</title><categories>cs.LG eess.SP</categories><journal-ref>Proceedings of the 6th Swiss Data Science Conference (SDS2019)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapidly-advancing technology of deep learning (DL) into the world of the
Internet of Things (IoT) has not fully entered in the fields of m-Health yet.
Among the main reasons are the high computational demands of DL algorithms and
the inherent resource-limitation of wearable devices. In this paper, we present
initial results for two deep learning architectures used to diagnose and
analyze sleep patterns, and we compare them with a previously presented
hand-crafted algorithm. The algorithms are designed to be reliable for consumer
healthcare applications and to be integrated into low-power wearables with
limited computational resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09918</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09918</id><created>2019-06-24</created><authors><author><keyname>Jameel</keyname><forenames>Furqan</forenames></author><author><keyname>Chang</keyname><forenames>Zheng</forenames></author><author><keyname>Huang</keyname><forenames>Jun</forenames></author><author><keyname>Ristaniemi</keyname><forenames>Tapani</forenames></author></authors><title>Internet of Autonomous Vehicles: Architecture, Features, and
  Socio-Technological Challenges</title><categories>cs.NI cs.CY eess.SP</categories><comments>11 Pages, 4 Figures, 2 Tables, IoV, IoAV, Autonomous Vehicles</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobility is the backbone of urban life and a vital economic factor in the
development of the world. Rapid urbanization and the growth of mega-cities is
bringing dramatic changes in the capabilities of vehicles. Innovative solutions
like autonomy, electrification, and connectivity are on the horizon. How, then,
we can provide ubiquitous connectivity to the legacy and autonomous vehicles?
This paper seeks to answer this question by combining recent leaps of
innovation in network virtualization with remarkable feats of wireless
communications. To do so, this paper proposes a novel paradigm called the
Internet of autonomous vehicles (IoAV). We begin painting the picture of IoAV
by discussing the salient features, and applications of IoAV which is followed
by a detailed discussion on the key enabling technologies. Next, we describe
the proposed layered architecture of IoAV and uncover some critical functions
of each layer. This is followed by the performance evaluation of IoAV which
shows the significant advantage of the proposed architecture in terms of
transmission time and energy consumption. Finally, to best capture the benefits
of IoAV, we enumerate some social and technological challenges and explain how
some unresolved issues can disrupt the widespread use of autonomous vehicles in
the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09919</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09919</id><created>2019-06-24</created><authors><author><keyname>Flinth</keyname><forenames>Axel</forenames><affiliation>IMT</affiliation></author><author><keyname>de Gournay</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>IMT, ITAV</affiliation></author><author><keyname>Weiss</keyname><forenames>Pierre</forenames><affiliation>IMT, ITAV</affiliation></author></authors><title>On the linear convergence rates of exchange and continuous methods for
  total variation minimization</title><categories>math.OC eess.SP</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze an exchange algorithm for the numerical solution total-variation
regularized inverse problems over the space M($\Omega$) of Radon measures on a
subset $\Omega$ of R d. Our main result states that under some regularity
conditions, the method eventually converges linearly. Additionally, we prove
that continuously optimizing the amplitudes of positions of the target measure
will succeed at a linear rate with a good initialization. Finally, we propose
to combine the two approaches into an alternating method and discuss the
comparative advantages of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09920</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09920</id><created>2019-06-24</created><authors><author><keyname>Charul</keyname></author><author><keyname>Bhatt</keyname><forenames>Uttkarsha</forenames></author><author><keyname>Biyani</keyname><forenames>Pravesh</forenames></author><author><keyname>Rajawat</keyname><forenames>Ketan</forenames></author></authors><title>Online Variational Bayesian Subspace Filtering with Applications</title><categories>eess.SP</categories><comments>13 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix completion and robust principal component analysis have been widely
used for the recovery of data suffering from missing entries or outliers. In
many real-world applications however, the data is also time-varying, and the
naive approach of per-snapshot recovery is both expensive and sub-optimal. This
paper develops generative Bayesian models that fit sequential multivariate
measurements arising from a low-dimensional time-varying subspace. A
variational Bayesian subspace filtering approach is proposed that learns the
underlying subspace and its state-transition matrix. Different from the
plethora of deterministic counterparts, the proposed approach utilizes
automatic relevance determination priors that obviate the need to tune key
parameters such as rank and noise power. We also propose a forward-backward
algorithm that allows the updates to be carried out at low complexity.
Extensive tests over traffic and electricity data demonstrate the superior
imputation, outlier rejection, and temporal prediction prowess of the proposed
algorithm over the state-of-the-art matrix/tensor completion algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09925</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09925</id><created>2019-06-24</created><authors><author><keyname>Charul</keyname></author><author><keyname>Biyani</keyname><forenames>Pravesh</forenames></author></authors><title>To each route its own ETA: A generative modeling framework for ETA
  prediction</title><categories>cs.LG eess.SP stat.ML</categories><comments>8 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate expected time of arrival (ETA) information is crucial in maintaining
the quality of service of public transit. Recent advances in artificial
intelligence (AI) has led to more effective models for ETA estimation that rely
heavily on a large GPS datasets. More importantly, these are mainly cabs based
datasets which may not be fit for bus-based public transport. Consequently, the
latest methods may not be applicable for ETA estimation in cities with the
absence of large training data set. On the other hand, the ETA estimation
problem in many cities needs to be solved in the absence of big datasets that
also contains outliers, anomalies and may be incomplete. This work presents a
simple but robust model for ETA estimation for a bus route that only relies on
the historical data of the particular route. We propose a system that generates
ETA information for a trip and updates it as the trip progresses based on the
real-time information. We train a deep learning based generative model that
learns the probability distribution of ETA data across trips and conditional on
the current trip information updates the ETA information on the go. Our plug
and play model not only captures the non-linearity of the task well but that
any transit agency can use without needing any other external data source. The
experiments run over three routes, data collected in the city of Delhi
illustrates the promise of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09936</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09936</id><created>2019-06-20</created><authors><author><keyname>Thorey</keyname><forenames>Valentin</forenames></author><author><keyname>Hernandez</keyname><forenames>Albert Bou</forenames></author><author><keyname>Arnal</keyname><forenames>Pierrick J.</forenames></author><author><keyname>During</keyname><forenames>Emmanuel H.</forenames></author></authors><title>AI vs Humans for the diagnosis of sleep apnea</title><categories>eess.SP cs.LG stat.ML</categories><comments>copyright 2019 IEEE. Accepted for publication in 41st International
  Engineering in Medicine and Biology Conference (EMBC), July 23-27, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polysomnography (PSG) is the gold standard for diagnosing sleep obstructive
apnea (OSA). It allows monitoring of breathing events throughout the night. The
detection of these events is usually done by trained sleep experts. However,
this task is tedious, highly time-consuming and subject to important
inter-scorer variability. In this study, we adapted our state-of-the-art deep
learning method for sleep event detection, DOSED, to the detection of sleep
breathing events in PSG for the diagnosis of OSA. We used a dataset of 52 PSG
recordings with apnea-hypopnea event scoring from 5 trained sleep experts. We
assessed the performance of the automatic approach and compared it to the
inter-scorer performance for both the diagnosis of OSA severity and, at the
microscale, for the detection of single breathing events. We observed that
human sleep experts reached an average accuracy of 75\% while the automatic
approach reached 81\% for sleep apnea severity diagnosis. The F1 score for
individual event detection was 0.55 for experts and 0.57 for the automatic
approach, on average. These results demonstrate that the automatic approach can
perform at a sleep expert level for the diagnosis of OSA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09950</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09950</id><created>2019-06-24</created><authors><author><keyname>Meynard</keyname><forenames>Adrien</forenames><affiliation>I2M</affiliation></author></authors><title>S\'eparation de sources doublement non stationnaire</title><categories>eess.SP</categories><comments>in French. GRETSI 2019 - XXVII{\`e}me Colloque francophone de
  traitement du signal et des images, Aug 2019, Lille, France</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind source separation (BSS) techniques aims at joint estimation of source
signals and a mixing matrix from observations of mixtures. This paper addresses
a doubly nonstationary BSS problem, where the mixing matrix is time dependent
and sources are nonstationary, more precisely deformed stationary signals,
following the model of [1]. An algorithm for joint BSS and estimation of
stationarity-breaking deformations and spectra is introduced, that exploits
suitable approximations for the behavior of the wavelet transform of such
nonstationary signals. The performance of the approach is evaluated on
numerical simulations, and compared with other nonstationary BSS algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09951</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09951</id><created>2019-06-24</created><authors><author><keyname>Yang</keyname><forenames>Yan</forenames></author><author><keyname>Yu</keyname><forenames>Juan</forenames></author><author><keyname>Yang</keyname><forenames>Zhifang</forenames></author><author><keyname>Xiang</keyname><forenames>Mingxu</forenames></author><author><keyname>Liu</keyname><forenames>Ren</forenames></author></authors><title>Fast Calculation of Probabilistic Optimal Power Flow: A Deep Learning
  Approach</title><categories>eess.SP cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic optimal power flow (POPF) is an important analytical tool to
ensure the secure and economic operation of power systems. POPF needs to solve
enormous nonlinear and nonconvex optimization problems. The huge computational
burden has become the major bottleneck for the practical application. This
paper presents a deep learning approach to solve the POPF problem efficiently
and accurately. Taking advantage of the deep structure and reconstructive
strategy of stacked denoising auto encoders (SDAE), a SDAE-based optimal power
flow (OPF) is developed to extract the high-level nonlinear correlations
between the system operating condition and the OPF solution. A training process
is designed to learn the feature of POPF. The trained SDAE network can be
utilized to conveniently calculate the OPF solution of random samples generated
by Monte-Carlo simulation (MCS) without the need of optimization. A modified
IEEE 118-bus power system is simulated to demonstrate the effectiveness of the
proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09957</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09957</id><created>2019-06-21</created><updated>2019-09-12</updated><authors><author><keyname>Nehme</keyname><forenames>Elias</forenames></author><author><keyname>Freedman</keyname><forenames>Daniel</forenames></author><author><keyname>Gordon</keyname><forenames>Racheli</forenames></author><author><keyname>Ferdman</keyname><forenames>Boris</forenames></author><author><keyname>Weiss</keyname><forenames>Lucien E.</forenames></author><author><keyname>Alalouf</keyname><forenames>Onit</forenames></author><author><keyname>Orange</keyname><forenames>Reut</forenames></author><author><keyname>Michaeli</keyname><forenames>Tomer</forenames></author><author><keyname>Shechtman</keyname><forenames>Yoav</forenames></author></authors><title>DeepSTORM3D: dense three dimensional localization microscopy and point
  spread function design by deep learning</title><categories>eess.IV physics.optics</categories><comments>main text: 9 pages, 5 figures, supplementary information: 29 pages,
  20 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Localization microscopy is an imaging technique in which the positions of
individual nanoscale point emitters (e.g. fluorescent molecules) are determined
at high precision from their images. This is the key ingredient in
single/multiple-particle-tracking and several super-resolution microscopy
approaches. Localization in three-dimensions (3D) can be performed by modifying
the image that a point-source creates on the camera, namely, the point-spread
function (PSF). The PSF is engineered using additional optical elements to vary
distinctively with the depth of the point-source. However, localizing multiple
adjacent emitters in 3D poses a significant algorithmic challenge, due to the
lateral overlap of their PSFs. Here, we train a neural network to receive an
image containing densely overlapping PSFs of multiple emitters over a large
axial range and output a list of their 3D positions. Furthermore, we then use
the network to design the optimal PSF for the multi-emitter case. We
demonstrate our approach numerically as well as experimentally by 3D STORM
imaging of mitochondria, and volumetric imaging of dozens of
fluorescently-labeled telomeres occupying a mammalian nucleus in a single
snapshot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09958</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09958</id><created>2019-06-21</created><authors><author><keyname>Pavlovic</keyname><forenames>Miroslava Jordovic</forenames></author><author><keyname>Kupusinac</keyname><forenames>Aleksandar</forenames></author><author><keyname>Popovic</keyname><forenames>Marica</forenames></author></authors><title>Classification model for microphone type recognition</title><categories>eess.SP</categories><comments>6 pages, 2 figures, 2 tables, conference Science and Higher Education
  in Function of Sustainable Development</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This paper presents a classification model for microphone type recognition in
photoacoustic experiment. The classification model is obtained by applying a
multilayer perceptron network on a large dataset of simulated experimental
values. The model satisfies the basic requirements of a photoacoustic
experiment: accuracy, reliability and real time operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09972</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09972</id><created>2019-06-21</created><authors><author><keyname>Rivero</keyname><forenames>Daniel</forenames></author><author><keyname>Fernandez-Blanco</keyname><forenames>Enrique</forenames></author><author><keyname>Pazos</keyname><forenames>Alejandro</forenames></author></authors><title>Classical Music Prediction and Composition by means of Variational
  Autoencoders</title><categories>cs.SD cs.LG cs.NE eess.AS</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new model for music prediction based on Variational
Autoencoders (VAEs). In this work, VAEs are used in a novel way in order to
address two different problems: music representation into the latent space, and
using this representation to make predictions of the future values of the
musical piece. This approach was trained with different songs of a classical
composer. As a result, the system can represent the music in the latent space,
and make accurate predictions. Therefore, the system can be used to compose new
music either from an existing piece or from a random starting point. An
additional feature of this system is that a small dataset was used for
training. However, results show that the system is able to return accurate
representations and predictions in unseen data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09981</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09981</id><created>2019-06-21</created><authors><author><keyname>Gao</keyname><forenames>Zhan</forenames></author><author><keyname>Eisen</keyname><forenames>Mark</forenames></author><author><keyname>Ribeiro</keyname><forenames>Alejandro</forenames></author></authors><title>Optimal WDM Power Allocation via Deep Learning for Radio on Free Space
  Optics Systems</title><categories>eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio on Free Space Optics (RoFSO), as a universal platform for heterogeneous
wireless services, is able to transmit multiple radio frequency signals at high
rates in free space optical networks. This paper investigates the optimal
design of power allocation for Wavelength Division Multiplexing (WDM)
transmission in RoFSO systems. The proposed problem is a weighted total
capacity maximization problem with two constraints of total power limitation
and eye safety concern. The model-based Stochastic Dual Gradient algorithm is
presented first, which solves the problem exactly by exploiting the null
duality gap. The model-free Primal-Dual Deep Learning algorithm is then
developed to learn and optimize the power allocation policy with Deep Neural
Network (DNN) parametrization, which can be utilized without any knowledge of
system models. Numerical simulations are performed to exhibit significant
performance of our algorithms compared to the average equal power allocation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09990</identifier>
 <datestamp>2020-01-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09990</id><created>2019-06-24</created><authors><author><keyname>Magna</keyname><forenames>Gabriele</forenames></author><author><keyname>Di Natale</keyname><forenames>Corrado</forenames></author><author><keyname>Martinelli</keyname><forenames>Eugenio</forenames></author></authors><title>Self-repairing Classification Algorithms for Chemical Sensor Array</title><categories>eess.SP</categories><journal-ref>Sensors and Actuators B: Chemical Volume 297, 15 October 2019,
  126721</journal-ref><doi>10.1016/j.snb.2019.126721</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Chemical sensors are usually affected by drift, have low fabrication
reproducibility and can experience failure or breaking events over the long
term. Albeit improvements in fabrication processes are often slow and
inadequate for completely surmounting these issues, data analysis can be used
as of now to improve the available device performances. The present paper
illustrates an algorithm, called Self-Repairing (SR), developed for repairing
classification models after the occurrences of failures in sensor arrays. The
procedure considers replacing broken sensors with replicas and eventually
Self-Repairing algorithm trains these blank elements. Unlike the habitual
alternatives reported in literature, SR performs this operation without the
need of a whole new recalibration, references gas measurements or transfer
dataset and, at the same time, without interrupting the on-going procedure of
gas identification. Furthermore, Self-Repairing algorithm can utilize most of
the standard classifiers as core algorithm; in this paper SR has been applied
to k-NN, PLS-DA and LDA as examples. Models have been tested in a synthetic and
real scenario considering sensor arrays affected by drift and eventually by
failures. Real experiment has been performed with a set of metal oxide sensors
over an 18-months period. Finally, the algorithm has been compared with
standard version of chosen classifiers (k-NN, LDA and PLS-DA) showing superior
performances of Self-Repairing and increasing the tolerance versus consecutive
failures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09997</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.09997</id><created>2019-06-24</created><authors><author><keyname>Liu</keyname><forenames>Shuo</forenames></author><author><keyname>Keren</keyname><forenames>Gil</forenames></author><author><keyname>Schuller</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>Single-Channel Speech Separation with Auxiliary Speaker Embeddings</title><categories>cs.SD cs.LG eess.AS</categories><comments>5 pages including reference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel source separation model to decompose asingle-channel
speech signal into two speech segments belonging to two different speakers. The
proposed model is a neural network based on residual blocks, and uses learnt
speaker embeddings created from additional clean context recordings of the two
speakers as input to assist in attributing the different time-frequency bins to
the two speakers. In experiments, we show that the proposed model yields good
performance in the source separation task, and outperforms the state-of-the-art
baselines. Specifically, separating speech from the challenging VoxCeleb
dataset, the proposed model yields 4.79dB signal-to-distortion ratio, 8.44dB
signal-to-artifacts ratio and 7.11dB signal-to-interference ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10004</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10004</id><created>2019-06-24</created><updated>2019-08-06</updated><authors><author><keyname>Moustakides</keyname><forenames>George V.</forenames></author><author><keyname>Salib</keyname><forenames>Feeby</forenames></author><author><keyname>Basioti</keyname><forenames>Kalliopi</forenames></author></authors><title>Adaptive Blind Separation of Two Dependent Sources</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of adaptive blind separation of two sources from
their instantaneous mixtures. We focus on the case where the two sources are
not necessarily independent. By analyzing a general form of adaptive algorithms
we show that separation is possible not only for independent sources but also
for sources that are dependent provided their joint pdf satisfies certain
symmetry conditions. A very interesting problem consists in identifying the
class of dependent sources that are non-separable, namely, the counterpart of
Gaussian sources of the independent case. We corroborate our theoretical
analysis with a number of simulations and give examples of dependent sources
that can be easily separated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10009</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10009</id><created>2019-06-18</created><authors><author><keyname>Armengaud</keyname><forenames>Eric</forenames></author><author><keyname>Frager</keyname><forenames>Sebastian</forenames></author><author><keyname>Jones</keyname><forenames>Stephen</forenames></author><author><keyname>Massoner</keyname><forenames>Alexander</forenames></author><author><keyname>Parrilla</keyname><forenames>Alejandro Ferreira</forenames></author><author><keyname>Wikstr&#xf6;m</keyname><forenames>Niklas</forenames></author><author><keyname>Macher</keyname><forenames>Georg</forenames></author></authors><title>Development Framework for Longitudinal Automated Driving Functions with
  Off-board Information Integration</title><categories>eess.SP cs.RO</categories><comments>ERTS 2018, Jan 2018, Toulouse, France</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasingly sophisticated function development is taking place with the aim
of developing efficient, safe and increasingly Automated Driving Functions.
This development is possible with the use of diverse data from sources such as
Navigation Systems, eHorizon, on-board sensor data, Vehicle-to-Infrastructure
(V2I) and Vehicle-to-Vehicle (V2V) communication. Increasing challenges arise
with the dependency on large amounts of real-time data coming from off-board
sources. At the core of addressing these challenges lies the concept of a
Digital Dependability Identity (DDI) of a component or system. DDIs are
modular, composable, and executable components in the field, facilitating:
  $\bullet$ efficient synthesis of component and system dependability
information,
  $\bullet$ effective evaluation of information for safe and secure composition
of highly distributed and autonomous Cyber Physical Systems.
  In AVL's Connected Powertrain (TM), Automated Driving Functions are tailored
to Powertrain Control Strategies that predictively increase energy efficiency
according to the powertrain type and its component efficiencies.
Simultaneously, the burden on the driver is reduced by optimizing the vehicle
velocity, whilst minimizing any journey time penalty.In this work, the
development of dependable Automated Driving Functions is exemplified by the
Traffic Light Assistant, an adaptive strategy that utilizes predictions of
preceding traffic, upcoming road curvature, inclination, speed limits, and
especially traffic light signal phase and timing information to increase the
energy efficiency in an urban traffic environment. A key aspect of this
development is the possibility for seamless and simultaneous development; from
office simulation to human-in-the-loop and to real-time tests that include
vehicle and powertrain hardware. Driver's acceptance and comfort is rated in an
advanced diver simulator mounted on a hexapod, capable of emulating
longitudinal and lateral acceleration of a real vehicle. Test results from
real-time function validation on a Powertrain Testbed are shown, including real
traffic light signal phasing information and traffic flow representation on
Graz city roads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10011</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10011</id><created>2019-06-24</created><authors><author><keyname>Engelhardt</keyname><forenames>Sandy</forenames></author><author><keyname>Sharan</keyname><forenames>Lalith</forenames></author><author><keyname>Karck</keyname><forenames>Matthias</forenames></author><author><keyname>De Simone</keyname><forenames>Raffaele</forenames></author><author><keyname>Wolf</keyname><forenames>Ivo</forenames></author></authors><title>Cross-Domain Conditional Generative Adversarial Networks for
  Stereoscopic Hyperrealism in Surgical Training</title><categories>eess.IV cs.CV cs.CY</categories><comments>accepted for MICCAI 2019</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Phantoms for surgical training are able to mimic cutting and suturing
properties and patient-individual shape of organs, but lack a realistic visual
appearance that captures the heterogeneity of surgical scenes. In order to
overcome this in endoscopic approaches, hyperrealistic concepts have been
proposed to be used in an augmented reality-setting, which are based on deep
image-to-image transformation methods. Such concepts are able to generate
realistic representations of phantoms learned from real intraoperative
endoscopic sequences. Conditioned on frames from the surgical training process,
the learned models are able to generate impressive results by transforming
unrealistic parts of the image (e.g.\ the uniform phantom texture is replaced
by the more heterogeneous texture of the tissue). Image-to-image synthesis
usually learns a mapping $G:X~\to~Y$ such that the distribution of images from
$G(X)$ is indistinguishable from the distribution $Y$. However, it does not
necessarily force the generated images to be consistent and without artifacts.
In the endoscopic image domain this can affect depth cues and stereo
consistency of a stereo image pair, which ultimately impairs surgical vision.
We propose a cross-domain conditional generative adversarial network approach
(GAN) that aims to generate more consistent stereo pairs. The results show
substantial improvements in depth perception and realism evaluated by 3 domain
experts and 3 medical students on a 3D monitor over the baseline method. In 84
of 90 instances our proposed method was preferred or rated equal to the
baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10040</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10040</id><created>2019-06-24</created><updated>2019-10-07</updated><authors><author><keyname>Deniz</keyname><forenames>Nestor N.</forenames></author><author><keyname>Murillo</keyname><forenames>Marina H.</forenames></author><author><keyname>Sanchez</keyname><forenames>Guido</forenames></author><author><keyname>Giovanini</keyname><forenames>Leonardo L.</forenames></author></authors><title>Adaptive polytopic estimation for nonlinear systems under bounded
  disturbances using moving horizon</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces an adaptive polytopic estimator design for nonlinear
systems under bounded disturbances combining moving horizon and dual estimation
techniques. It extends the moving horizon estimation results for LTI systems to
polytopic LPV systems. The design and necessary conditions to guarantee the
robust stability and convergence to the true state and parameters for the case
of bounded disturbances and convergence to the true system and state are given
for the vanishing disturbances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10042</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10042</id><created>2019-06-24</created><authors><author><keyname>Chung</keyname><forenames>Joon Son</forenames></author><author><keyname>Lee</keyname><forenames>Bong-Jin</forenames></author><author><keyname>Han</keyname><forenames>Icksang</forenames></author></authors><title>Who said that?: Audio-visual speaker diarisation of real-world meetings</title><categories>cs.SD cs.CV eess.AS</categories><comments>Accepted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this work is to determine 'who spoke when' in real-world
meetings. The method takes surround-view video and single or multi-channel
audio as inputs, and generates robust diarisation outputs. To achieve this, we
propose a novel iterative approach that first enrolls speaker models using
audio-visual correspondence, then uses the enrolled models together with the
visual information to determine the active speaker. We show strong quantitative
and qualitative performance on a dataset of real-world meetings. The method is
also evaluated on the public AMI meeting corpus, on which we demonstrate
results that exceed all comparable methods. We also show that beamforming can
be used together with the video to further improve the performance when
multi-channel audio is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10043</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10043</id><created>2019-06-24</created><updated>2019-12-09</updated><authors><author><keyname>Deniz</keyname><forenames>Nestor N.</forenames></author><author><keyname>Sanchez</keyname><forenames>Guido</forenames></author><author><keyname>Murillo</keyname><forenames>Marina H.</forenames></author><author><keyname>Giovanini</keyname><forenames>Leonardo L.</forenames></author></authors><title>Simultaneous state estimation and control for nonlinear systems subject
  to bounded disturbances</title><categories>cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we address the output--feedback problem for nonlinear systems
under bounded disturbances using a moving horizon approach. The controller is
posed as an optimization-based problem that simultaneously estimates the state
trajectory and computes the future of control inputs. It minimizes a criterion
that involves finite forward and backward horizon with respect the unknown
initial state, measurement noises and control input variables and it is
maximized with respect the unknown disturbances. Under appropriate assumptions
that encode stability and detectability, we show that the states of the
closed-loop system remain bounded. A simulation example is included to show
that the algorithm succeeds even in nonlinear problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10044</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10044</id><created>2019-06-24</created><updated>2019-06-25</updated><authors><author><keyname>Rock</keyname><forenames>Johanna</forenames></author><author><keyname>Toth</keyname><forenames>Mate</forenames></author><author><keyname>Messner</keyname><forenames>Elmar</forenames></author><author><keyname>Meissner</keyname><forenames>Paul</forenames></author><author><keyname>Pernkopf</keyname><forenames>Franz</forenames></author></authors><title>Complex Signal Denoising and Interference Mitigation for Automotive
  Radar Using Convolutional Neural Networks</title><categories>eess.SP cs.CV</categories><comments>FUSION 2019; 8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Driver assistance systems as well as autonomous cars have to rely on sensors
to perceive their environment. A heterogeneous set of sensors is used to
perform this task robustly. Among them, radar sensors are indispensable because
of their range resolution and the possibility to directly measure velocity.
Since more and more radar sensors are deployed on the streets, mutual
interference must be dealt with. In the so far unregulated automotive radar
frequency band, a sensor must be capable of detecting, or even mitigating the
harmful effects of interference, which include a decreased detection
sensitivity. In this paper, we address this issue with Convolutional Neural
Networks (CNNs), which are state-of-the-art machine learning tools. We show
that the ability of CNNs to find structured information in data while
preserving local information enables superior denoising performance. To achieve
this, CNN parameters are found using training with simulated data and
integrated into the automotive radar signal processing chain. The presented
method is compared with the state of the art, highlighting its promising
performance. Hence, CNNs can be employed for interference mitigation as an
alternative to conventional signal processing methods. Code and pre-trained
models are available at https://github.com/johanna-rock/imRICnn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10045</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10045</id><created>2019-06-24</created><authors><author><keyname>Jie</keyname><affiliation>Jack</affiliation></author><author><keyname>Zhang</keyname></author><author><keyname>Newman</keyname><forenames>Jonathan P.</forenames></author><author><keyname>Wang</keyname><forenames>Xiao</forenames></author><author><keyname>Thakur</keyname><forenames>Chetan Singh</forenames></author><author><keyname>Rattray</keyname><forenames>John</forenames></author><author><keyname>Etienne-Cummings</keyname><forenames>Ralph</forenames></author><author><keyname>Wilson</keyname><forenames>Matthew A.</forenames></author></authors><title>A closed-loop all-electronic pixel-wise adaptive imaging system for high
  dynamic range video</title><categories>eess.IV cs.SY eess.SY</categories><comments>9 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrated a CMOS imaging system that adapts each pixel's exposure and
sampling rate to capture high dynamic range (HDR) videos. The system consist of
a custom designed image sensor with pixel-wise exposure configurability and a
real-time pixel exposure controller. These parts operate in a closed-loop to
sample, detect and optimize each pixel's exposure and sampling rate to minimize
local region's underexposure, overexposure and motion blurring. Exposure
control is implemented using all-integrated electronics without external
optical modulation. This reduces overall system size and power consumption.
  The image sensor is implemented using a standard 130nm CMOS process while the
exposure controller is implemented on a computer. We performed experiments
under complex lighting and motion condition to test performance of the system,
and demonstrate the benefit of pixel-wise adaptive imaging on the performance
of computer vision tasks such as segmentation, motion estimation and object
recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10050</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10050</id><created>2019-06-24</created><updated>2020-02-10</updated><authors><author><keyname>Katsikouli</keyname><forenames>Panagiota</forenames></author><author><keyname>Ferraro</keyname><forenames>Pietro</forenames></author><author><keyname>Timoney</keyname><forenames>David</forenames></author><author><keyname>Shorten</keyname><forenames>Robert</forenames></author></authors><title>On DICE-free Smart Cities, Particulate Matter, and Feedback-Enabled
  Access Control</title><categories>eess.SY cs.CY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The link between transport related emissions and human health is a major
issue for city municipalities worldwide. PM emissions from exhaust and
non-exhaust sources are one of the main worrying contributors to air-pollution.
In this paper, we challenge the notion that a ban on internal combustion engine
vehicles will result in clean and safe air in our cities, since emissions from
tyres and other non-exhaust sources are expected to increase in the near
future. To this end, we present data from the city of Dublin that document that
the current amount of tyre-related PM emissions in the city might already be
above or close to the levels deemed safe by the World Health Organization. As a
solution to this problem, we present a feedback-enabled distributed access
control mechanism and ride-sharing scheme to limit the number of vehicles in a
city and therefore maintain the amount of transport-related PM to safe levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10057</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10057</id><created>2019-06-24</created><authors><author><keyname>Li</keyname><forenames>Mu</forenames></author><author><keyname>Ma</keyname><forenames>Kede</forenames></author><author><keyname>You</keyname><forenames>Jane</forenames></author><author><keyname>Zhang</keyname><forenames>David</forenames></author><author><keyname>Zuo</keyname><forenames>Wangmeng</forenames></author></authors><title>Efficient and Effective Context-Based Convolutional Entropy Modeling for
  Image Compression</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has long been understood that precisely estimating the probabilistic
structure of natural visual images is crucial for image compression. Despite
the remarkable success of recent end-to-end optimized image compression, the
latent code representation is assumed to be fully statistically factorized such
that the entropy modeling is feasible. Here we describe context-based
convolutional networks (CCNs) that exploit statistical redundancies in the
codes for improved entropy modeling. We introduce a 3D zigzag coding order
together with a 3D code dividing technique to define proper context and to
achieve parallel entropy decoding, both of which boil down to place
translation-invariant binary masks on convolution filters of CCNs. We
demonstrate the power of CCNs for entropy modeling in both lossless and lossy
image compression. For the former, we directly apply a CCN to binarized image
planes for estimating the Bernoulli distribution of each code. For the latter,
the categorical distribution of each code is represented by a discretized
mixture of Gaussian distributions, whose parameters are estimated by three
CCNs. We jointly optimize the CCN-based entropy model with analysis and
synthesis transforms for rate-distortion performance. Experiments on two image
datasets show that the proposed lossless and lossy image compression methods
based on CCNs generally exhibit better compression performance than existing
methods with manageable computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10089</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10089</id><created>2019-06-24</created><updated>2019-12-31</updated><authors><author><keyname>Eslami</keyname><forenames>Mohammad</forenames></author><author><keyname>Tabarestani</keyname><forenames>Solale</forenames></author><author><keyname>Albarqouni</keyname><forenames>Shadi</forenames></author><author><keyname>Adeli</keyname><forenames>Ehsan</forenames></author><author><keyname>Navab</keyname><forenames>Nassir</forenames></author><author><keyname>Adjouadi</keyname><forenames>Malek</forenames></author></authors><title>Image to Images Translation for Multi-Task Organ Segmentation and Bone
  Suppression in Chest X-Ray Radiography</title><categories>eess.IV cs.CV</categories><doi>10.1109/TMI.2020.2974159</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chest X-ray radiography is one of the earliest medical imaging technologies
and remains one of the most widely-used for diagnosis, screening, and treatment
follow up of diseases related to lungs and heart. The literature in this field
of research reports many interesting studies dealing with the challenging tasks
of bone suppression and organ segmentation but performed separately, limiting
any learning that comes with the consolidation of parameters that could
optimize both processes. This study, and for the first time, introduces a
multitask deep learning model that generates simultaneously the bone-suppressed
image and the organ-segmented image, enhancing the accuracy of tasks,
minimizing the number of parameters needed by the model and optimizing the
processing time, all by exploiting the interplay between the network parameters
to benefit the performance of both tasks. The architectural design of this
model, which relies on a conditional generative adversarial network, reveals
the process on how the well-established pix2pix network (image-to-image
network) is modified to fit the need for multitasking and extending it to the
new image-to-images architecture. The developed source code of this multitask
model is shared publicly on Github as the first attempt for providing the
two-task pix2pix extension, a supervised/paired/aligned/registered
image-to-images translation which would be useful in many multitask
applications. Dilated convolutions are also used to improve the results through
a more effective receptive field assessment. The comparison with
state-of-the-art algorithms along with ablation study and a demonstration video
are provided to evaluate efficacy and gauge the merits of the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10091</identifier>
 <datestamp>2019-06-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10091</id><created>2019-06-24</created><authors><author><keyname>Garg</keyname><forenames>Kunal</forenames></author><author><keyname>Arabi</keyname><forenames>Ehsan</forenames></author><author><keyname>Panagou</keyname><forenames>Dimitra</forenames></author></authors><title>Prescribed-time control under spatiotemporal and input constraints: A QP
  based approach</title><categories>math.OC cs.SY eess.SY</categories><comments>Submitted to IEEE Transactions on Automatic Control, under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a control framework for a general class of
control-affine nonlinear systems under spatiotemporal and input constraints.
First, we present a new result on fixed-time stability, i.e., convergence
within a fixed time independently of the initial conditions, in terms of a
Lyapunov function. We show robustness of the proposed conditions in terms of
fixed-time stability guarantees in the presence of a class of additive
disturbances. Then, we consider the problem of designing control inputs for a
general class of nonlinear, control-affine systems to achieve forward
invariance of a safe set, as well as convergence to a goal set within a
prescribed (i.e., user-defined) time. We show that the aforementioned problem
based on spatiotemporal specifications can be translated into a temporal logic
formula. Then, we present a quadratic program (QP) based formulation to compute
the control input efficiently. We show that the proposed QP is feasible, and
discuss the cases when the solution of the QP solves the considered problem of
control design. In contrast to prior work, we do not make any additional
assumptions on existence of a Lyapunov or a Barrier function for the
feasibility of the QP. We present two case studies to corroborate our proposed
methods. In the first example, the adaptive cruise control problem is
considered, where a following vehicle needs to obtain a desired goal speed
while maintaining a safe distance from the lead vehicle. For the second
example, we consider the problem of robot motion planning for a two-agent
system, where the objective of the robots is to visit a given sequence of sets
in a prescribed time sequence while remaining in a given safe set and
maintaining safe distance from each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10109</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10109</id><created>2019-06-24</created><updated>2019-07-17</updated><authors><author><keyname>Cattaneo</keyname><forenames>Daniele</forenames></author><author><keyname>Vaghi</keyname><forenames>Matteo</forenames></author><author><keyname>Ballardini</keyname><forenames>Augusto Luis</forenames></author><author><keyname>Fontana</keyname><forenames>Simone</forenames></author><author><keyname>Sorrenti</keyname><forenames>Domenico Giorgio</forenames></author><author><keyname>Burgard</keyname><forenames>Wolfram</forenames></author></authors><title>CMRNet: Camera to LiDAR-Map Registration</title><categories>cs.CV cs.LG cs.RO eess.IV</categories><comments>Accepted for presentation at IEEE ITSC2019</comments><journal-ref>2019 IEEE Intelligent Transportation Systems Conference (ITSC) pp.
  1283-1289</journal-ref><doi>10.1109/ITSC.2019.8917470</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present CMRNet, a realtime approach based on a Convolutional
Neural Network to localize an RGB image of a scene in a map built from LiDAR
data. Our network is not trained in the working area, i.e. CMRNet does not
learn the map. Instead it learns to match an image to the map. We validate our
approach on the KITTI dataset, processing each frame independently without any
tracking procedure. CMRNet achieves 0.27m and 1.07deg median localization
accuracy on the sequence 00 of the odometry dataset, starting from a rough pose
estimate displaced up to 3.5m and 17deg. To the best of our knowledge this is
the first CNN-based approach that learns to match images from a monocular
camera to a given, preexisting 3D LiDAR-map.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10178</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10178</id><created>2019-06-24</created><authors><author><keyname>Mani</keyname><forenames>Merry</forenames></author><author><keyname>Aggarwal</keyname><forenames>Hemant Kumar</forenames></author><author><keyname>Magnotta</keyname><forenames>Vincent</forenames></author><author><keyname>Jacob</keyname><forenames>Mathews</forenames></author></authors><title>Improved Reconstruction for high-resolution Multi-shot Diffusion
  Weighted Imaging</title><categories>physics.med-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To introduce a fast and improved direct reconstruction method for
multi-shot diffusion weighted (msDW) scans for high-resolution studies.
  Methods:Multi-shot EPI methods can enable higher spatial resolution for
diffusion MRI studies. Traditionally, such acquisitions required specialized
reconstructions involving phase compensation to correct for inter-shot motion
artifacts. The recently proposed MUSSELS reconstruction belongs to a new class
of parallel imaging-based methods that recover artifact-free DWIs from msDW
data without needing phase compensation. However, computational demands of the
MUSSELS reconstruction scales as the matrix size and the number of shots
increases, which hinders its practical utility for high-resolution
applications. In this work, we propose a computationally efficient formulation
using iterative reweighted least squares (IRLS) method. The new formulation is
not only fast but it enables to accommodate additional priors such as conjugate
symmetry property of the k-space data to improve the reconstruction. Using
whole-brain in-vivo data, we show the utility of the new formulation for
routine high-resolution studies with minimal computational burden.
  Results: The IRLS formulation provides about six times faster reconstruction
for matrix sizes 192x192 and 256x256, compared to the original implementations.
The reconstruction quality is improved by the addition of conjugate symmetry
priors that reduce blurring and preserves the high-resolution details from
partial Fourier acquisitions.
  Conclusion: The proposed method is shown to be computationally efficient to
enable routine high-resolution studies. The computational complexity matches
the traditional msDWI reconstruction methods and provides improved
reconstruction results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10181</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10181</id><created>2019-06-24</created><authors><author><keyname>Mishra</keyname><forenames>Deepak</forenames></author><author><keyname>Johansson</keyname><forenames>H&#xe5;kan</forenames></author></authors><title>Optimal Least-Squares Estimator and Precoder for Energy Beamforming over
  IQ-Impaired Channels</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 3 figures, and this paper has been accepted for publication
  in IEEE Signal Processing Letters</comments><doi>10.1109/LSP.2019.2925533</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Usage of low-cost hardware in large antenna arrays and low-power wireless
devices in Internet-of-Things (IoT) has led to the degradation of practical
beamforming gains due to the underlying hardware impairments like
in-phase-and-quadrature-phase imbalance (IQI). To address this timely concern,
we present a new nontrivial closed-form expression for the globally-optimal
least-squares estimator (LSE) for the IQI-influenced channel between a
multiantenna transmitter and single-antenna IoT device. Thereafter, to maximize
the realistic transmit beamforming gains, a novel precoder design is derived
that accounts for the underlying IQI for maximizing received power in both
single and multiuser settings. Lastly, the simulation results, demonstrating a
significant -8dB improvement in the mean-squared error of the proposed LSE over
existing benchmarks, show that the optimal precoder designing is more critical
than accurately estimating IQI-impaired channels. Also, the proposed
jointly-optimal LSE and beamformer outperforms the existing designs by
providing 24% enhancement in the mean signal power received under IQI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10183</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10183</id><created>2019-06-24</created><authors><author><keyname>Yuan</keyname><forenames>Yading</forenames></author><author><keyname>Sheu</keyname><forenames>Ren-Dih</forenames></author><author><keyname>Fu</keyname><forenames>Luke</forenames></author><author><keyname>Lo</keyname><forenames>Yeh-Chi</forenames></author></authors><title>A Deep Regression Model for Seed Identification in Prostate
  Brachytherapy</title><categories>eess.IV cs.CV physics.med-ph</categories><comments>Accepted for presentation in MICCAI 2019 (8 pages, 4 figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Post-implant dosimetry (PID) is an essential step of prostate brachytherapy
that utilizes CT to image the prostate and allow the location and dose
distribution of the radioactive seeds to be directly related to the actual
prostate. However, it it a very challenging task to identify these seeds in CT
images due to the severe metal artifacts and high-overlapped appearance when
multiple seeds clustered together. In this paper, we propose an automatic and
efficient algorithm based on 3D deep fully convolutional network for
identifying implanted seeds in CT images. Our method models the seed
localization task as a supervised regression problem that projects the input CT
image to a map where each element represents the probability that the
corresponding input voxel belongs to a seed. This deep regression model
significantly suppresses image artifacts and makes the post-processing much
easier and more controllable. The proposed method is validated on a large
clinical database with 7820 seeds in 100 patients, in which 5534 seeds from 70
patients were used for model training and validation. Our method correctly
detected 2150 of 2286 (94.1%) seeds in the 30 testing patients, yielding 16%
improvement as compared to a widely-used commercial seed finder software
(VariSeed, Varian, Palo Alto, CA).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10194</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10194</id><created>2019-06-24</created><authors><author><keyname>Gao</keyname><forenames>Jin</forenames></author><author><keyname>Khandaker</keyname><forenames>Muhammad R. A.</forenames></author><author><keyname>Tariq</keyname><forenames>Faisal</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author><author><keyname>Khan</keyname><forenames>Risala T.</forenames></author></authors><title>Deep Neural Network Based Resource Allocation for V2X Communications</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE VTC 2019-Fall, Honolulu, Hawaii, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on optimal transmit power allocation to maximize the
overall system throughput in a vehicle-to-everything (V2X) communication
system. We propose two methods for solving the power allocation problem namely
the weighted minimum mean square error (WMMSE) algorithm and the deep
learning-based method. In the WMMSE algorithm, we solve the problem using block
coordinate descent (BCD) method. Then we adopt supervised learning technique
for the deep neural network (DNN) based approach considering the power
allocation from the WMMSE algorithm as the target output. We exploit an
efficient implementation of the mini-batch gradient descent algorithm for
training the DNN. Extensive simulation results demonstrate that the DNN
algorithm can provide very good approximation of the iterative WMMSE algorithm
reducing the computational overhead significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10198</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10198</id><created>2019-06-24</created><authors><author><keyname>Aguilar</keyname><forenames>Gustavo</forenames></author><author><keyname>Rozgi&#x107;</keyname><forenames>Viktor</forenames></author><author><keyname>Wang</keyname><forenames>Weiran</forenames></author><author><keyname>Wang</keyname><forenames>Chao</forenames></author></authors><title>Multimodal and Multi-view Models for Emotion Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>ACL 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Studies on emotion recognition (ER) show that combining lexical and acoustic
information results in more robust and accurate models. The majority of the
studies focus on settings where both modalities are available in training and
evaluation. However, in practice, this is not always the case; getting ASR
output may represent a bottleneck in a deployment pipeline due to computational
complexity or privacy-related constraints. To address this challenge, we study
the problem of efficiently combining acoustic and lexical modalities during
training while still providing a deployable acoustic model that does not
require lexical inputs. We first experiment with multimodal models and two
attention mechanisms to assess the extent of the benefits that lexical
information can provide. Then, we frame the task as a multi-view learning
problem to induce semantic information from a multimodal model into our
acoustic-only network using a contrastive loss function. Our multimodal model
outperforms the previous state of the art on the USC-IEMOCAP dataset reported
on lexical and acoustic information. Additionally, our multi-view-trained
acoustic network significantly surpasses models that have been exclusively
trained with acoustic features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10199</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10199</id><created>2019-06-24</created><updated>2019-07-02</updated><authors><author><keyname>Onu</keyname><forenames>Charles C.</forenames></author><author><keyname>Lebensold</keyname><forenames>Jonathan</forenames></author><author><keyname>Hamilton</keyname><forenames>William L.</forenames></author><author><keyname>Precup</keyname><forenames>Doina</forenames></author></authors><title>Neural Transfer Learning for Cry-based Diagnosis of Perinatal Asphyxia</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>Accepted at INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite continuing medical advances, the rate of newborn morbidity and
mortality globally remains high, with over 6 million casualties every year. The
prediction of pathologies affecting newborns based on their cry is thus of
significant clinical interest, as it would facilitate the development of
accessible, low-cost diagnostic tools\cut{ based on wearables and smartphones}.
However, the inadequacy of clinically annotated datasets of infant cries limits
progress on this task. This study explores a neural transfer learning approach
to developing accurate and robust models for identifying infants that have
suffered from perinatal asphyxia. In particular, we explore the hypothesis that
representations learned from adult speech could inform and improve performance
of models developed on infant speech. Our experiments show that models based on
such representation transfer are resilient to different types and degrees of
noise, as well as to signal loss in time and frequency domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10211</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10211</id><created>2019-06-24</created><updated>2020-02-01</updated><authors><author><keyname>Yu</keyname><forenames>Qi</forenames></author><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Cvetkovic</keyname><forenames>Zoran</forenames></author><author><keyname>Zhu</keyname><forenames>Jubo</forenames></author></authors><title>Dictionary Learning with BLOTLESS Update</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms for learning a dictionary to sparsely represent a given dataset
typically alternate between sparse coding and dictionary update stages. Methods
for dictionary update aim to minimise expansion error by updating dictionary
vectors and expansion coefficients given patterns of non-zero coefficients
obtained in the sparse coding stage. We propose a block total least squares
(BLOTLESS) algorithm for dictionary update. BLOTLESS updates a block of
dictionary elements and the corresponding sparse coefficients simultaneously.
In the error free case, three necessary conditions for exact recovery are
identified. Lower bounds on the number of training data are established so that
the necessary conditions hold with high probability. Numerical simulations show
that the bounds approximate well the number of training data needed for exact
dictionary recovery. Numerical experiments further demonstrate several benefits
of dictionary learning with BLOTLESS update compared with state-of-the-art
algorithms especially when the amount of training data is small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10242</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10242</id><created>2019-06-24</created><authors><author><keyname>Gan</keyname><forenames>Luyun</forenames></author><author><keyname>Yuen</keyname><forenames>Brosnan</forenames></author><author><keyname>Lu</keyname><forenames>Tao</forenames></author></authors><title>Multi-label Classification with Optimal Thresholding for
  Multi-composition Spectroscopic Analysis</title><categories>cs.LG eess.SP stat.ML</categories><comments>8 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we implement multi-label neural networks with optimal
thresholding to identify gas species among a multi gas mixture in a cluttered
environment. Using infrared absorption spectroscopy and tested on synthesized
spectral datasets, our approach outperforms conventional binary relevance -
partial least squares discriminant analysis when signal-to-noise ratio and
training sample size are sufficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10274</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10274</id><created>2019-06-24</created><updated>2019-09-13</updated><authors><author><keyname>Boddupalli</keyname><forenames>Nibodh</forenames></author><author><keyname>Hasnain</keyname><forenames>Aqib</forenames></author><author><keyname>Nandanoori</keyname><forenames>Sai Pushpak</forenames></author><author><keyname>Yeung</keyname><forenames>Enoch</forenames></author></authors><title>Koopman Operators for Generalized Persistence of Excitation Conditions
  for Nonlinear Systems</title><categories>math.DS cs.SY eess.SY math.OC q-bio.MN</categories><comments>6 pages. 2 figures, accepted for 58th IEEE Conference on Decision and
  Control - Nice, France - December 11th-13th 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is hard to identify nonlinear biological models strictly from data, with
results that are often sensitive to experimental conditions. Automated
experimental workflows and liquid handling enables unprecedented throughput, as
well as the capacity to generate extremely large datasets. We seek to develop
generalized identifiability conditions for informing the design of automated
experiments to discover predictive nonlinear biological models. For linear
systems, identifiability is characterized by persistence of excitation
conditions. For nonlinear systems, no such persistence of excitation conditions
exist. We use the input-Koopman operator method to model nonlinear systems and
derive identifiability conditions for open-loop systems initialized from a
single initial condition. We show that nonlinear identifiability is
intrinsically tied to the rank of a given dataset's power spectral density,
transformed through the lifted Koopman observable space. We illustrate these
identifiability conditions with a simulated synthetic gene circuit model, the
repressilator. We illustrate how rank degeneracy in datasets results in
overfitted nonlinear models of the repressilator, resulting in poor predictive
accuracy. Our findings provide novel experimental design criteria for discovery
of globally predictive nonlinear models of biological phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10288</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10288</id><created>2019-06-24</created><updated>2019-07-08</updated><authors><author><keyname>Ramos</keyname><forenames>Jonathan S.</forenames></author><author><keyname>Cazzolato</keyname><forenames>Mirela T.</forenames></author><author><keyname>Fai&#xe7;al</keyname><forenames>Bruno S.</forenames></author><author><keyname>Nogueira-Barbosa</keyname><forenames>Marcello H.</forenames></author><author><keyname>Traina</keyname><forenames>Caetano</forenames><suffix>Jr.</suffix></author><author><keyname>Traina</keyname><forenames>Agma J. M.</forenames></author></authors><title>3DBGrowth: volumetric vertebrae segmentation and reconstruction in
  magnetic resonance imaging</title><categories>eess.IV cs.CV</categories><comments>This is a pre-print of an article published in Computer-Based Medical
  Systems. The final authenticated version is available online at:
  https://doi.org/10.1109/CBMS.2019.00091</comments><journal-ref>Computer-Based Medical Systems, 2019</journal-ref><doi>10.1109/CBMS.2019.00091</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmentation of medical images is critical for making several processes of
analysis and classification more reliable. With the growing number of people
presenting back pain and related problems, the semi-automatic segmentation and
3D reconstruction of vertebral bodies became even more important to support
decision making. A 3D reconstruction allows a fast and objective analysis of
each vertebrae condition, which may play a major role in surgical planning and
evaluation of suitable treatments. In this paper, we propose 3DBGrowth, which
develops a 3D reconstruction over the efficient Balanced Growth method for 2D
images. We also take advantage of the slope coefficient from the annotation
time to reduce the total number of annotated slices, reducing the time spent on
manual annotation. We show experimental results on a representative dataset
with 17 MRI exams demonstrating that our approach significantly outperforms the
competitors and, on average, only 37% of the total slices with vertebral body
content must be annotated without losing performance/accuracy. Compared to the
state-of-the-art methods, we have achieved a Dice Score gain of over 5% with
comparable processing time. Moreover, 3DBGrowth works well with imprecise seed
points, which reduces the time spent on manual annotation by the specialist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10324</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10324</id><created>2019-06-25</created><authors><author><keyname>Mehralian</keyname><forenames>Mohammad Amin</forenames></author><author><keyname>Soryani</keyname><forenames>Mohsen</forenames></author></authors><title>EKFPnP: Extended Kalman Filter for Camera Pose Estimation in a Sequence
  of Images</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In real-world applications the Perspective-n-Point (PnP) problem should
generally be applied in a sequence of images which a set of drift-prone
features are tracked over time. In this paper, we consider both the temporal
dependency of camera poses and the uncertainty of features for the sequential
camera pose estimation. Using the Extended Kalman Filter (EKF), a priori
estimate of the camera pose is calculated from the camera motion model and then
corrected by minimizing the reprojection error of the reference points.
Experimental results, using both simulated and real data, demonstrate that the
proposed method improves the robustness of the camera pose estimation, in the
presence of noise, compared to the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10338</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10338</id><created>2019-06-25</created><authors><author><keyname>Freiman</keyname><forenames>Moti</forenames></author><author><keyname>Nickisch</keyname><forenames>Hannes</forenames></author><author><keyname>Schmitt</keyname><forenames>Holger</forenames></author><author><keyname>Maurovich-Horvat</keyname><forenames>Pal</forenames></author><author><keyname>Donnelly</keyname><forenames>Patrick</forenames></author><author><keyname>Vembar</keyname><forenames>Mani</forenames></author><author><keyname>Goshen</keyname><forenames>Liran</forenames></author></authors><title>Learning a sparse database for patch-based medical image segmentation</title><categories>eess.IV cs.CV cs.LG physics.med-ph</categories><journal-ref>Wu G., Munsell B., Zhan Y., Bai W., Sanroma G., Coup\'e P. (eds)
  Patch-Based Techniques in Medical Imaging. Patch-MI 2017. Lecture Notes in
  Computer Science, vol 10530. Springer, Cham</journal-ref><doi>10.1007/978-3-319-67434-6_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a functional for the learning of an optimal database for
patch-based image segmentation with application to coronary lumen segmentation
from coronary computed tomography angiography (CCTA) data. The proposed
functional consists of fidelity, sparseness and robustness to small-variations
terms and their associated weights. Existing work address database optimization
by prototype selection aiming to optimize the database by either adding or
removing prototypes according to a set of predefined rules. In contrast, we
formulate the database optimization task as an energy minimization problem that
can be solved using standard numerical tools. We apply the proposed database
optimization functional to the task of optimizing a database for patch-base
coronary lumen segmentation. Our experiments using the publicly available
MICCAI 2012 coronary lumen segmentation challenge data show that optimizing the
database using the proposed approach reduced database size by 96% while
maintaining the same level of lumen segmentation accuracy. Moreover, we show
that the optimized database yields an improved specificity of CCTA based
fractional flow reserve (0.73 vs 0.7 for all lesions and 0.68 vs 0.65 for
obstructive lesions) using a training set of 132 (76 obstructive) coronary
lesions with invasively measured FFR as the reference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10356</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10356</id><created>2019-06-25</created><authors><author><keyname>Khatun</keyname><forenames>Mahfuza</forenames></author><author><keyname>Guo</keyname><forenames>Changyu</forenames></author><author><keyname>Moro</keyname><forenames>Letizia</forenames></author><author><keyname>Matolak</keyname><forenames>David</forenames></author><author><keyname>Mehrpouyan</keyname><forenames>Hani</forenames></author></authors><title>Millimeter-Wave Path Loss at 73 GHz in Indoor and Outdoor Airport
  Environments</title><categories>eess.SP</categories><comments>5 pages, 9 figures, conference, vtc fall</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, two large-scale fading path loss models are presented based on
indoor and outdoor channel measurements at 73 GHz. The line-of-sight
millimeter-wave propagation measurement campaigns were uniquely conducted
within the indoor and outdoor environments at an airport setting, i.e., the
Boise Airport. The channel measurements were made with directional transmit and
receive antennas with a 24 dBi gain at different receive antenna heights. From
the measured data, we obtained the parameters of two path loss models, i.e.,
the close-in reference distance model (CIM) and the floating-intercept model
(FIM). Results show that the path loss exponents estimated from the CIM are
very close to that of the free-space path loss model, while the FIM provides a
better fit to the measurement data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10369</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10369</id><created>2019-06-25</created><authors><author><keyname>Gupta</keyname><forenames>Chitralekha</forenames></author><author><keyname>Y&#x131;lmaz</keyname><forenames>Emre</forenames></author><author><keyname>Li</keyname><forenames>Haizhou</forenames></author></authors><title>Acoustic Modeling for Automatic Lyrics-to-Audio Alignment</title><categories>eess.AS cs.CL cs.SD</categories><comments>Accepted for publication at Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic lyrics to polyphonic audio alignment is a challenging task not only
because the vocals are corrupted by background music, but also there is a lack
of annotated polyphonic corpus for effective acoustic modeling. In this work,
we propose (1) using additional speech and music-informed features and (2)
adapting the acoustic models trained on a large amount of solo singing vocals
towards polyphonic music using a small amount of in-domain data. Incorporating
additional information such as voicing and auditory features together with
conventional acoustic features aims to bring robustness against the increased
spectro-temporal variations in singing vocals. By adapting the acoustic model
using a small amount of polyphonic audio data, we reduce the domain mismatch
between training and testing data. We perform several alignment experiments and
present an in-depth alignment error analysis on acoustic features, and model
adaptation techniques. The results demonstrate that the proposed strategy
provides a significant error reduction of word boundary alignment over
comparable existing systems, especially on more challenging polyphonic data
with long-duration musical interludes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10386</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10386</id><created>2019-06-25</created><authors><author><keyname>Krikidis</keyname><forenames>Ioannis</forenames></author><author><keyname>Psomas</keyname><forenames>Constantinos</forenames></author></authors><title>Tone-index Multisine Modulation for SWIPT</title><categories>cs.IT eess.SP math.IT</categories><comments>IEEE Signal Processing Letters</comments><doi>10.1109/LSP.2019.2925586</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new simultaneous wireless information and power transfer (SWIPT)
technique that embeds information bits in the tone-index of multisine
waveforms. By varying the number of subcarriers of the transmitted
bandwidth-constrained multisine signal, the proposed scheme enables efficient
radio-frequency energy harvesting and low-complexity information transmission.
The receiver does not require channel estimation and employs a non-coherent
maximum-likelihood detection at the envelope of the received signal. The
performance of the proposed tone-index modulation is evaluated in terms of
average error probability for a flat-fading channel, and we show that it
outperforms its peak-to-average-power-ratio counterpart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10400</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10400</id><created>2019-06-25</created><authors><author><keyname>Ren</keyname><forenames>Xuhua</forenames></author><author><keyname>Zhang</keyname><forenames>Lichi</forenames></author><author><keyname>Wang</keyname><forenames>Qian</forenames></author><author><keyname>Shen</keyname><forenames>Dinggang</forenames></author></authors><title>Brain MR Image Segmentation in Small Dataset with Adversarial Defense
  and Task Reorganization</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical image segmentation is challenging especially in dealing with small
dataset of 3D MR images. Encoding the variation of brain anatomical struc-tures
from individual subjects cannot be easily achieved, which is further
chal-lenged by only a limited number of well labeled subjects for training. In
this study, we aim to address the issue of brain MR image segmentation in small
da-taset. First, concerning the limited number of training images, we adopt
adver-sarial defense to augment the training data and therefore increase the
robustness of the network. Second, inspired by the prior knowledge of neural
anatomies, we reorganize the segmentation tasks of different regions into
several groups in a hierarchical way. Third, the task reorganization extends to
the semantic level, as we incorporate an additional object-level classification
task to contribute high-order visual features toward the pixel-level
segmentation task. In experiments we validate our method by segmenting gray
matter, white matter, and several major regions on a challenge dataset. The
proposed method with only seven subjects for training can achieve 84.46% of
Dice score in the onsite test set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10411</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10411</id><created>2019-06-25</created><authors><author><keyname>Zur</keyname><forenames>Yochai</forenames></author><author><keyname>Adler</keyname><forenames>Amir</forenames></author></authors><title>Deep Learning of Compressed Sensing Operators with Structural Similarity
  Loss</title><categories>eess.IV cs.CV cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Compressed sensing (CS) is a signal processing framework for efficiently
reconstructing a signal from a small number of measurements, obtained by linear
projections of the signal. In this paper we present an end-to-end deep learning
approach for CS, in which a fully-connected network performs both the linear
sensing and non-linear reconstruction stages. During the training phase, the
sensing matrix and the non-linear reconstruction operator are jointly optimized
using Structural similarity index (SSIM) as loss rather than the standard Mean
Squared Error (MSE) loss. We compare the proposed approach with
state-of-the-art in terms of reconstruction quality under both losses, i.e.
SSIM score and MSE score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10413</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10413</id><created>2019-06-25</created><authors><author><keyname>Gargiulo</keyname><forenames>Massimiliano</forenames></author><author><keyname>Dell'Aglio</keyname><forenames>Domenico Antonio Giuseppe</forenames></author><author><keyname>Iodice</keyname><forenames>Antonio</forenames></author><author><keyname>Riccio</keyname><forenames>Daniele</forenames></author><author><keyname>Ruello</keyname><forenames>Giuseppe</forenames></author></authors><title>A CNN-Based Super-Resolution Technique for Active Fire Detection on
  Sentinel-2 Data</title><categories>cs.CV eess.IV</categories><comments>8 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Remote Sensing applications can benefit from a relatively fine spatial
resolution multispectral (MS) images and a high revisit frequency ensured by
the twin satellites Sentinel-2. Unfortunately, only four out of thirteen bands
are provided at the highest resolution of 10 meters, and the others at 20 or 60
meters. For instance the Short-Wave Infrared (SWIR) bands, provided at 20
meters, are very useful to detect active fires. Aiming to a more detailed
Active Fire Detection (AFD) maps, we propose a super-resolution data fusion
method based on Convolutional Neural Network (CNN) to move towards the 10-m
spatial resolution the SWIR bands. The proposed CNN-based solution achieves
better results than alternative methods in terms of some accuracy metrics.
Moreover we test the super-resolved bands from an application point of view by
monitoring active fire through classic indices. Advantages and limits of our
proposed approach are validated on specific geographical area (the mount
Vesuvius, close to Naples) that was damaged by widespread fires during the
summer of 2017.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10417</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10417</id><created>2019-06-25</created><authors><author><keyname>Wabersich</keyname><forenames>Kim P.</forenames></author><author><keyname>Hewing</keyname><forenames>Lukas</forenames></author><author><keyname>Carron</keyname><forenames>Andrea</forenames></author><author><keyname>Zeilinger</keyname><forenames>Melanie N.</forenames></author></authors><title>Probabilistic model predictive safety certification for learning-based
  control</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reinforcement learning (RL) methods have demonstrated their efficiency in
simulation environments. However, many applications for which RL offers great
potential, such as autonomous driving, are also safety critical and require a
certified closed-loop behavior in order to meet safety specifications in the
presence of physical constraints. This paper introduces a concept, called
probabilistic model predictive safety certification (PMPSC), which can be
combined with any RL algorithm and provides provable safety certificates in
terms of state and input chance constraints for potentially large-scale
systems. The certificate is realized through a stochastic tube that safely
connects the current system state with a terminal set of states, that is known
to be safe. A novel formulation in terms of a convex receding horizon problem
allows a recursively feasible real-time computation of such probabilistic
tubes, despite the presence of possibly unbounded disturbances. A design
procedure for PMPSC relying on bayesian inference and recent advances in
probabilistic set invariance is presented. Using a numerical car simulation,
the method and its design procedure are illustrated by enhancing a simple RL
algorithm with safety certificates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10440</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10440</id><created>2019-06-25</created><updated>2019-07-09</updated><authors><author><keyname>Gonzalez-Guerrero</keyname><forenames>Luis</forenames></author><author><keyname>Shams</keyname><forenames>Haymen</forenames></author><author><keyname>Fatadin</keyname><forenames>Irshaad</forenames></author><author><keyname>Wu</keyname><forenames>John Edward</forenames></author><author><keyname>Fice</keyname><forenames>Martyn J.</forenames></author><author><keyname>Naftaly</keyname><forenames>Mira</forenames></author><author><keyname>Seeds</keyname><forenames>Alwyn J.</forenames></author><author><keyname>Renaud</keyname><forenames>Cyril C.</forenames></author></authors><title>Pilot-tone assisted 16-QAM photonic wireless bridge operating at 250 GHz</title><categories>eess.SP</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A photonic wireless bridge operating at a carrier frequency of 250 GHz and
transmitting at a data rate of 20 Gbit/s is proposed and demonstrated. To
mitigate the phase noise of the free-running lasers present in such a link, the
toneassisted carrier recovery is used. Compared to the blind phase noise
compensation (PNC) algorithm, this technique exhibited no penalty, and a
penalty of less than 0.5 dB, when used with aggregated Lorentzian linewidths of
67 kHz and 350 kHz, respectively. The wireless bridge is also demonstrated in a
wavelength division multiplexing (WDM) scenario, where 5 optical channels are
generated and sent to the Tx remote antenna unit (RAU). In this configuration,
the full band from 224 GHz to 294 GHz is used. Finally, to extend the data
rate, two channels are digitally multiplexed at the central office (CO) forming
a twin, singlesideband (SSB) signal. With this arrangement a wireless bridge of
40 Gbit/s is realized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10453</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10453</id><created>2019-06-25</created><authors><author><keyname>Chiumento</keyname><forenames>Alessandro</forenames></author><author><keyname>Marchetti</keyname><forenames>Nicola</forenames></author><author><keyname>Macaluso</keyname><forenames>Irene</forenames></author></authors><title>Energy Efficient WSN: a Cross-layer Graph Signal Processing Solution to
  Information Redundancy</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work an iterative solution to build a network lifetime-preserving
sampling strategy for WSNs is presented. The paper describes the necessary
steps to reconstruct a graph from application data. Once the graph structure is
obtained, a sampling strategy aimed at finding the smallest number of
concurrent sensors needed to reconstruct the data in the unsampled nodes within
a specific error bound, is presented. An iterative method then divides the
sensor nodes into sets to be sampled sequentially to increase lifetime. Results
on a real-life dataset show that the reconstruction RMSE can be easily traded
off for a larger number of disjoint sampling sets which improve the network
lifetime linearly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10471</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10471</id><created>2019-06-25</created><authors><author><keyname>Coutino</keyname><forenames>Mario</forenames></author><author><keyname>Isufi</keyname><forenames>Elvin</forenames></author><author><keyname>Maehara</keyname><forenames>Takanori</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>State-Space Network Topology Identification from Partial Observations</title><categories>eess.SP</categories><comments>13 pages, 3 appendix pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we explore the state-space formulation of a network process to
recover, from partial observations, the underlying network topology that drives
its dynamics. To do so, we employ subspace techniques borrowed from system
identification literature and extend them to the network topology
identification problem. This approach provides a unified view of the
traditional network control theory and signal processing on graphs. In
addition, it provides theoretical guarantees for the recovery of the
topological structure of a deterministic continuous-time linear dynamical
system from input-output observations even though the input and state
interaction networks might be different. The derived mathematical analysis is
accompanied by an algorithm for identifying, from data, a network topology
consistent with the dynamics of the system and conforms to the prior
information about the underlying structure. The proposed algorithm relies on
alternating projections and is provably convergent. Numerical results
corroborate the theoretical findings and the applicability of the proposed
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10486</identifier>
 <datestamp>2019-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10486</id><created>2019-06-25</created><updated>2019-12-22</updated><authors><author><keyname>Moradi</keyname><forenames>Shakiba</forenames></author><author><keyname>Ghelich-Oghli</keyname><forenames>Mostafa</forenames></author><author><keyname>Alizadehasl</keyname><forenames>Azin</forenames></author><author><keyname>Shiri</keyname><forenames>Isaac</forenames></author><author><keyname>Oveisi</keyname><forenames>Niki</forenames></author><author><keyname>Oveisi</keyname><forenames>Mehrdad</forenames></author><author><keyname>Maleki</keyname><forenames>Majid</forenames></author><author><keyname>Dhooge</keyname><forenames>Jan</forenames></author></authors><title>A Novel Deep Learning Based Approach for Left Ventricle Segmentation in
  Echocardiography: MFP-Unet</title><categories>eess.IV cs.CV physics.med-ph</categories><comments>32 Pages, 10 Figures, 5 Tables</comments><journal-ref>https://doi.org/10.1016/j.ejmp.2019.10.001</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmentation of the Left ventricle (LV) is a crucial step for quantitative
measurements such as area, volume, and ejection fraction. However, the
automatic LV segmentation in 2D echocardiographic images is a challenging task
due to ill-defined borders, and operator dependence issues (insufficient
reproducibility). U-net, which is a well-known architecture in medical image
segmentation, addressed this problem through an encoder-decoder path. Despite
outstanding overall performance, U-net ignores the contribution of all semantic
strengths in the segmentation procedure. In the present study, we have proposed
a novel architecture to tackle this drawback. Feature maps in all levels of the
decoder path of U-net are concatenated, their depths are equalized, and
up-sampled to a fixed dimension. This stack of feature maps would be the input
of the semantic segmentation layer. The proposed network yielded
state-of-the-art results when comparing with results from U-net, dilated U-net,
and deeplabv3, using the same dataset. An average Dice Metric (DM) of 0.945,
Hausdorff Distance (HD) of 1.62, Jaccard Coefficient (JC) of 0.97, and Mean
Absolute Distance (MAD) of 1.32 are achieved. The correlation graph,
bland-altman analysis, and box plot showed a great agreement between automatic
and manually calculated volume, area, and length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10487</identifier>
 <datestamp>2019-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10487</id><created>2019-06-25</created><updated>2019-12-04</updated><authors><author><keyname>Mehrabian</keyname><forenames>Armin</forenames></author><author><keyname>Miscuglio</keyname><forenames>Mario</forenames></author><author><keyname>Alkabani</keyname><forenames>Yousra</forenames></author><author><keyname>Sorger</keyname><forenames>Volker J.</forenames></author><author><keyname>El-Ghazawi</keyname><forenames>Tarek</forenames></author></authors><title>A Winograd-based Integrated Photonics Accelerator for Convolutional
  Neural Networks</title><categories>cs.ET cs.DC cs.LG eess.SP</categories><comments>12 pages, photonics, artificial intelligence, convolutional neural
  networks, Winograd</comments><msc-class>B.0, B.7, C.1, C.1.2, C.1.4, C.3, C.5, I.2, I.2.5, I.2.10, I.2.11,
  I.4, I.5, I.5.2, I.5.4, I.5.5, I.6, I.6.3</msc-class><acm-class>B.0; B.7; C.1; C.1.2; C.1.4; C.3; C.5; I.2; I.2.5; I.2.10; I.2.11;
  I.4; I.5; I.5.2; I.5.4; I.5.5; I.6; I.6.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural Networks (NNs) have become the mainstream technology in the artificial
intelligence (AI) renaissance over the past decade. Among different types of
neural networks, convolutional neural networks (CNNs) have been widely adopted
as they have achieved leading results in many fields such as computer vision
and speech recognition. This success in part is due to the widespread
availability of capable underlying hardware platforms. Applications have always
been a driving factor for design of such hardware architectures. Hardware
specialization can expose us to novel architectural solutions, which can
outperform general purpose computers for tasks at hand. Although different
applications demand for different performance measures, they all share speed
and energy efficiency as high priorities. Meanwhile, photonics processing has
seen a resurgence due to its inherited high speed and low power nature. Here,
we investigate the potential of using photonics in CNNs by proposing a CNN
accelerator design based on Winograd filtering algorithm. Our evaluation
results show that while a photonic accelerator can compete with
current-state-of-the-art electronic platforms in terms of both speed and power,
it has the potential to improve the energy efficiency by up to three orders of
magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10489</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10489</id><created>2019-06-25</created><authors><author><keyname>Beckers</keyname><forenames>Thomas</forenames></author><author><keyname>Hirche</keyname><forenames>Sandra</forenames></author></authors><title>Keep soft robots soft -- a data-driven based trade-off between
  feed-forward and feedback control</title><categories>eess.SY cs.RO cs.SY</categories><comments>Presented at the workshop on &quot;Robust autonomy: tools for safety in
  real-world uncertain environments&quot; (RSS 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tracking control for soft robots is challenging due to uncertainties in the
system model and environment. Using high feedback gains to overcome this issue
results in an increasing stiffness that clearly destroys the inherent safety
property of soft robots. However, accurate models for feed-forward control are
often difficult to obtain. In this article, we employ Gaussian Process
regression to obtain a data-driven model that is used for the feed-forward
compensation of unknown dynamics. The model fidelity is used to adapt the
feed-forward and feedback part allowing low feedback gains in regions of high
model confidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10508</identifier>
 <datestamp>2020-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10508</id><created>2019-06-25</created><updated>2019-12-12</updated><authors><author><keyname>Zhang</keyname><forenames>Jing-Xuan</forenames></author><author><keyname>Ling</keyname><forenames>Zhen-Hua</forenames></author><author><keyname>Dai</keyname><forenames>Li-Rong</forenames></author></authors><title>Non-Parallel Sequence-to-Sequence Voice Conversion with Disentangled
  Linguistic and Speaker Representations</title><categories>eess.AS cs.SD</categories><comments>Accepted by IEEE/ACM Transactions on Aduio, Speech and Language
  Processing</comments><journal-ref>IEEE/ACM Transactions on Audio, Speech and Language Processing vol
  28 no 1 (2020) 540-552</journal-ref><doi>10.1109/TASLP.2019.2960721</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method of sequence-to-sequence (seq2seq) voice
conversion using non-parallel training data. In this method, disentangled
linguistic and speaker representations are extracted from acoustic features,
and voice conversion is achieved by preserving the linguistic representations
of source utterances while replacing the speaker representations with the
target ones. Our model is built under the framework of encoder-decoder neural
networks. A recognition encoder is designed to learn the disentangled
linguistic representations with two strategies. First, phoneme transcriptions
of training data are introduced to provide the references for leaning
linguistic representations of audio signals. Second, an adversarial training
strategy is employed to further wipe out speaker information from the
linguistic representations. Meanwhile, speaker representations are extracted
from audio signals by a speaker encoder. The model parameters are estimated by
two-stage training, including a pretraining stage using a multi-speaker dataset
and a fine-tuning stage using the dataset of a specific conversion pair. Since
both the recognition encoder and the decoder for recovering acoustic features
are seq2seq neural networks, there are no constrains of frame alignment and
frame-by-frame conversion in our proposed method. Experimental results showed
that our method obtained higher similarity and naturalness than the best
non-parallel voice conversion method in Voice Conversion Challenge 2018.
Besides, the performance of our proposed method was closed to the
state-of-the-art parallel seq2seq voice conversion method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10517</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10517</id><created>2019-06-21</created><updated>2019-06-26</updated><authors><author><keyname>Lanza</keyname><forenames>Alessandro</forenames></author><author><keyname>Morigi</keyname><forenames>Serena</forenames></author><author><keyname>Pragliola</keyname><forenames>Monica</forenames></author><author><keyname>Sgallari</keyname><forenames>Fiorella</forenames></author></authors><title>Space-variant Generalized Gaussian Regularization for Image Restoration</title><categories>eess.IV cs.NA math.NA</categories><journal-ref>Computer Methods in Biomechanics and Biomedical Engineering:
  Imaging &amp; Visualization, 2018</journal-ref><doi>10.1080/21681163.2018.1471620</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new space-variant regularization term for variational image
restoration based on the assumption that the gradient magnitudes of the target
image distribute locally according to a half-Generalized Gaussian distribution.
This leads to a highly flexible regularizer characterized by two per-pixel free
parameters, which are automatically estimated from the observed image. The
proposed regularizer is coupled with either the $L_2$ or the $L_1$ fidelity
terms, in order to effectively deal with additive white Gaussian noise or
impulsive noises such as, e.g, additive white Laplace and salt and pepper
noise. The restored image is efficiently computed by means of an iterative
numerical algorithm based on the alternating direction method of multipliers.
Numerical examples indicate that the proposed regularizer holds the potential
for achieving high quality restorations for a wide range of target images
characterized by different gradient distributions and for the different types
of noise considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10547</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10547</id><created>2019-06-24</created><authors><author><keyname>Simonetta</keyname><forenames>Federico</forenames></author><author><keyname>Cancino-Chac&#xf3;n</keyname><forenames>Carlos</forenames></author><author><keyname>Ntalampiras</keyname><forenames>Stavros</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>A Convolutional Approach to Melody Line Identification in Symbolic
  Scores</title><categories>cs.SD cs.IR cs.LG eess.AS</categories><comments>In Proceedings of 20th International Society for Music Information
  Retrieval Conference</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In many musical traditions, the melody line is of primary significance in a
piece. Human listeners can readily distinguish melodies from accompaniment;
however, making this distinction given only the written score -- i.e. without
listening to the music performed -- can be a difficult task. Solving this task
is of great importance for both Music Information Retrieval and musicological
applications. In this paper, we propose an automated approach to identifying
the most salient melody line in a symbolic score. The backbone of the method
consists of a convolutional neural network (CNN) estimating the probability
that each note in the score (more precisely: each pixel in a piano roll
encoding of the score) belongs to the melody line. We train and evaluate the
method on various datasets, using manual annotations where available and solo
instrument parts where not. We also propose a method to inspect the CNN and to
analyze the influence exerted by notes on the prediction of other notes; this
method can be applied whenever the output of a neural network has the same size
as the input.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10554</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10554</id><created>2019-06-24</created><authors><author><keyname>Farooq</keyname><forenames>U.</forenames></author><author><keyname>Iftikhar</keyname><forenames>A.</forenames></author><author><keyname>Khan</keyname><forenames>M. S.</forenames></author><author><keyname>Shafique</keyname><forenames>M. F.</forenames></author><author><keyname>Shubair</keyname><forenames>Raed M.</forenames></author></authors><title>Design of a 1x4 CPW Microstrip Antenna Array on PET Substrate for
  Biomedical Applications</title><categories>physics.med-ph eess.SP</categories><comments>11 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a single layer Coplanar Waveguide-fed microstrip patch antenna
array is presented for biomedical applications. The proposed antenna array is
realized on a transparent and flexible Polyethylene Terephthalate substrate,
has 1x4 radiating elements and measures only 280 x 192 mm2. The antenna array
resonates at 2.68 GHz and has a peak-simulated gain of 10 dBi. A prototype is
also fabricated, and the conductive patterns are drawn using cost-efficient
adhesive copper foils instead of conventional copper or silver nanoparticle
ink. The corresponding measured results agree well with the simulated results.
The proposed low profile and cost-efficient transmit antenna array has the
potential for wearable born-worn applications, including wireless powering of
implantable medical devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10555</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10555</id><created>2019-06-25</created><authors><author><keyname>Chung</keyname><forenames>Joon Son</forenames></author></authors><title>Naver at ActivityNet Challenge 2019 -- Task B Active Speaker Detection
  (AVA)</title><categories>cs.SD cs.CV eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report describes our submission to the ActivityNet Challenge at CVPR
2019. We use a 3D convolutional neural network (CNN) based front-end and an
ensemble of temporal convolution and LSTM classifiers to predict whether a
visible person is speaking or not. Our results show significant improvements
over the baseline on the AVA-ActiveSpeaker dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10603</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10603</id><created>2019-06-25</created><authors><author><keyname>Farnell</keyname><forenames>Elin</forenames></author><author><keyname>Kvinge</keyname><forenames>Henry</forenames></author><author><keyname>Dupuis</keyname><forenames>Julia R.</forenames></author><author><keyname>Kirby</keyname><forenames>Michael</forenames></author><author><keyname>Peterson</keyname><forenames>Chris</forenames></author><author><keyname>Schundler</keyname><forenames>Elizabeth C.</forenames></author></authors><title>Total variation vs L1 regularization: a comparison of compressive
  sensing optimization methods for chemical detection</title><categories>eess.IV eess.SP</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the fundamental assumptions of compressive sensing (CS) is that a
signal can be reconstructed from a small number of samples by solving an
optimization problem with the appropriate regularization term. Two standard
regularization terms are the L1 norm and the total variation (TV) norm. We
present a comparison of CS reconstruction results based on these two approaches
in the context of chemical detection, and we demonstrate that optimization
based on the L1 norm outperforms optimization based on the TV norm. Our
comparison is driven by CS sampling, reconstruction, and chemical detection in
two real-world datasets: the Physical Sciences Inc. Fabry-P\'{e}rot
interferometer sensor multispectral dataset and the Johns Hopkins Applied
Physics Lab FTIR-based longwave infrared sensor hyperspectral dataset. Both
datasets contain the release of a chemical simulant such as glacial acetic
acid, triethyl phosphate, and sulfur hexafluoride. For chemical detection we
use the adaptive coherence estimator (ACE) and bulk coherence, and we propose
algorithmic ACE thresholds to define the presence or absence of a chemical of
interest in both un-compressed data cubes and reconstructed data cubes. The
un-compressed data cubes provide an approximate ground truth. We demonstrate
that optimization based on either the L1 norm or TV norm results in successful
chemical detection at a compression rate of 90%, but we show that L1
optimization is preferable. We present quantitative comparisons of chemical
detection on reconstructions from the two methods, with an emphasis on the
number of pixels with an ACE value above the threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10606</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10606</id><created>2019-06-25</created><authors><author><keyname>Meseguer-Brocal</keyname><forenames>Gabriel</forenames></author><author><keyname>Cohen-Hadria</keyname><forenames>Alice</forenames></author><author><keyname>Peeters</keyname><forenames>Geoffroy</forenames></author></authors><title>DALI: a large Dataset of synchronized Audio, LyrIcs and notes,
  automatically created using teacher-student machine learning paradigm</title><categories>eess.AS cs.DB cs.LG cs.SD</categories><journal-ref>Proceedings of the 19th International Society for Music
  Information Retrieval Conference, ISMIR, Paris, France, pp. 431-437, 2018</journal-ref><doi>10.5281/zenodo.1492443</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The goal of this paper is twofold. First, we introduce DALI, a large and rich
multimodal dataset containing 5358 audio tracks with their time-aligned vocal
melody notes and lyrics at four levels of granularity. The second goal is to
explain our methodology where dataset creation and learning models interact
using a teacher-student machine learning paradigm that benefits each other. We
start with a set of manual annotations of draft time-aligned lyrics and notes
made by non-expert users of Karaoke games. This set comes without audio.
Therefore, we need to find the corresponding audio and adapt the annotations to
it. To that end, we retrieve audio candidates from the Web. Each candidate is
then turned into a singing-voice probability over time using a teacher, a deep
convolutional neural network singing-voice detection system (SVD), trained on
cleaned data. Comparing the time-aligned lyrics and the singing-voice
probability, we detect matches and update the time-alignment lyrics
accordingly. From this, we obtain new audio sets. They are then used to train
new SVD students used to perform again the above comparison. The process could
be repeated iteratively. We show that this allows to progressively improve the
performances of our SVD and get better audio-matching and alignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10623</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10623</id><created>2019-06-25</created><authors><author><keyname>Ortega</keyname><forenames>Juan D. S.</forenames></author><author><keyname>Cardinal</keyname><forenames>Patrick</forenames></author><author><keyname>Koerich</keyname><forenames>Alessandro L.</forenames></author></authors><title>Emotion Recognition Using Fusion of Audio and Video Features</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a fusion approach to continuous emotion recognition
that combines visual and auditory modalities in their representation spaces to
predict the arousal and valence levels. The proposed approach employs a
pre-trained convolution neural network and transfer learning to extract
features from video frames that capture the emotional content. For the auditory
content, a minimalistic set of parameters such as prosodic, excitation, vocal
tract, and spectral descriptors are used as features. The fusion of these two
modalities is carried out at a feature level, before training a single support
vector regressor (SVR) or at a prediction level, after training one SVR for
each modality. The proposed approach also includes preprocessing and
post-processing techniques which contribute favorably to improving the
concordance correlation coefficient (CCC). Experimental results for predicting
spontaneous and natural emotions on the RECOLA dataset have shown that the
proposed approach takes advantage of the complementary information of visual
and auditory modalities and provides CCCs of 0.749 and 0.565 for arousal and
valence, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10640</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10640</id><created>2019-06-25</created><authors><author><keyname>Ashok</keyname><forenames>Pranav</forenames></author><author><keyname>K&#x159;et&#xed;nsk&#xfd;</keyname><forenames>Jan</forenames></author><author><keyname>Larsen</keyname><forenames>Kim Guldstrand</forenames></author><author><keyname>Co&#xeb;nt</keyname><forenames>Adrien Le</forenames></author><author><keyname>Taankvist</keyname><forenames>Jakob Haahr</forenames></author><author><keyname>Weininger</keyname><forenames>Maximilian</forenames></author></authors><title>SOS: Safe, Optimal and Small Strategies for Hybrid Markov Decision
  Processes</title><categories>eess.SY cs.LO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For hybrid Markov decision processes, UPPAAL Stratego can compute strategies
that are safe for a given safety property and (in the limit) optimal for a
given cost function. Unfortunately, these strategies cannot be exported easily
since they are computed as a very long list. In this paper, we demonstrate
methods to learn compact representations of the strategies in the form of
decision trees. These decision trees are much smaller, more understandable, and
can easily be exported as code that can be loaded into embedded systems.
Despite the size compression and actual differences to the original strategy,
we provide guarantees on both safety and optimality of the decision-tree
strategy. On the top, we show how to obtain yet smaller representations, which
are still guaranteed safe, but achieve a desired trade-off between size and
optimality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10642</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10642</id><created>2019-06-25</created><authors><author><keyname>Andr&#xe9;n</keyname><forenames>Filip Pr&#xf6;stl</forenames></author><author><keyname>Strasser</keyname><forenames>Thomas I.</forenames></author><author><keyname>Baut</keyname><forenames>Julien Le</forenames></author><author><keyname>Rossi</keyname><forenames>Marco</forenames></author><author><keyname>Vigano</keyname><forenames>Giacomo</forenames></author><author><keyname>Della Croce</keyname><forenames>Giacomo</forenames></author><author><keyname>Horsmanheimo</keyname><forenames>Seppo</forenames></author><author><keyname>Azar</keyname><forenames>Armin Ghasem</forenames></author><author><keyname>Iba&#xf1;ez</keyname><forenames>Adrian</forenames></author></authors><title>Validating Coordination Schemes between Transmission and Distribution
  System Operators using a Laboratory-Based Approach</title><categories>eess.SY cs.SY</categories><comments>2019 IEEE PowerTech Milan</comments><doi>10.1109/PTC.2019.8810770</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The secure operation of future power systems will rely on better coordination
between transmission system and distribution system operators. Increasing
integration of renewables throughout the whole system is challenging the
traditional operation. To tackle this problem, the SmartNet project proposes
and evaluates five different coordination schemes between system operators
using three benchmark scenarios from Denmark, Italy, and Spain. In the project,
field tests in each of the benchmark countries are complemented with a number
of laboratory validation tests, to cover scenarios that cannot be tested in
field trials. This paper presents the outcome of these laboratory tests. Three
tests are shown, focusing on controller validation, analysis of communication
impacts, and how well price-based controls can integrate with the SmartNet
coordination schemes. The results demonstrate important indications for the
field tests and also show some of the limitations with the current
implementations of the coordinations schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10643</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10643</id><created>2019-06-23</created><authors><author><keyname>Zhang</keyname><forenames>Haimiao</forenames></author><author><keyname>Dong</keyname><forenames>Bin</forenames></author></authors><title>A Review on Deep Learning in Medical Image Reconstruction</title><categories>eess.IV cs.CV cs.LG physics.med-ph</categories><comments>31 pages, 6 figures. Survey paper</comments><msc-class>60H10, 92C55, 93C15, 94A08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical imaging is crucial in modern clinics to guide the diagnosis and
treatment of diseases. Medical image reconstruction is one of the most
fundamental and important components of medical imaging, whose major objective
is to acquire high-quality medical images for clinical usage at the minimal
cost and risk to the patients. Mathematical models in medical image
reconstruction or, more generally, image restoration in computer vision, have
been playing a prominent role. Earlier mathematical models are mostly designed
by human knowledge or hypothesis on the image to be reconstructed, and we shall
call these models handcrafted models. Later, handcrafted plus data-driven
modeling started to emerge which still mostly relies on human designs, while
part of the model is learned from the observed data. More recently, as more
data and computation resources are made available, deep learning based models
(or deep models) pushed the data-driven modeling to the extreme where the
models are mostly based on learning with minimal human designs. Both
handcrafted and data-driven modeling have their own advantages and
disadvantages. One of the major research trends in medical imaging is to
combine handcrafted modeling with deep modeling so that we can enjoy benefits
from both approaches. The major part of this article is to provide a conceptual
review of some recent works on deep modeling from the unrolling dynamics
viewpoint. This viewpoint stimulates new designs of neural network
architectures with inspirations from optimization algorithms and numerical
differential equations. Given the popularity of deep modeling, there are still
vast remaining challenges in the field, as well as opportunities which we shall
discuss at the end of this article.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10651</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10651</id><created>2019-06-25</created><updated>2019-08-24</updated><authors><author><keyname>Hase</keyname><forenames>Peter</forenames></author><author><keyname>Chen</keyname><forenames>Chaofan</forenames></author><author><keyname>Li</keyname><forenames>Oscar</forenames></author><author><keyname>Rudin</keyname><forenames>Cynthia</forenames></author></authors><title>Interpretable Image Recognition with Hierarchical Prototypes</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>Published as a full paper at HCOMP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vision models are interpretable when they classify objects on the basis of
features that a person can directly understand. Recently, methods relying on
visual feature prototypes have been developed for this purpose. However, in
contrast to how humans categorize objects, these approaches have not yet made
use of any taxonomical organization of class labels. With such an approach, for
instance, we may see why a chimpanzee is classified as a chimpanzee, but not
why it was considered to be a primate or even an animal. In this work we
introduce a model that uses hierarchically organized prototypes to classify
objects at every level in a predefined taxonomy. Hence, we may find distinct
explanations for the prediction an image receives at each level of the
taxonomy. The hierarchical prototypes enable the model to perform another
important task: interpretably classifying images from previously unseen classes
at the level of the taxonomy to which they correctly relate, e.g. classifying a
hand gun as a weapon, when the only weapons in the training data are rifles.
With a subset of ImageNet, we test our model against its counterpart black-box
model on two tasks: 1) classification of data from familiar classes, and 2)
classification of data from previously unseen classes at the appropriate level
in the taxonomy. We find that our model performs approximately as well as its
counterpart black-box model while allowing for each classification to be
interpreted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10654</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10654</id><created>2019-06-25</created><authors><author><keyname>Huang</keyname><forenames>Chao</forenames></author><author><keyname>Fan</keyname><forenames>Jiameng</forenames></author><author><keyname>Li</keyname><forenames>Wenchao</forenames></author><author><keyname>Chen</keyname><forenames>Xin</forenames></author><author><keyname>Zhu</keyname><forenames>Qi</forenames></author></authors><title>ReachNN: Reachability Analysis of Neural-Network Controlled Systems</title><categories>eess.SY cs.LG cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applying neural networks as controllers in dynamical systems has shown great
promises. However, it is critical yet challenging to verify the safety of such
control systems with neural-network controllers in the loop. Previous methods
for verifying neural network controlled systems are limited to a few specific
activation functions. In this work, we propose a new reachability analysis
approach based on Bernstein polynomials that can verify neural-network
controlled systems with a more general form of activation functions, i.e., as
long as they ensure that the neural networks are Lipschitz continuous.
Specifically, we consider abstracting feedforward neural networks with
Bernstein polynomials for a small subset of inputs. To quantify the error
introduced by abstraction, we provide both theoretical error bound estimation
based on the theory of Bernstein polynomials and more practical sampling based
error bound estimation, following a tight Lipschitz constant estimation
approach based on forward reachability analysis. Compared with previous
methods, our approach addresses a much broader set of neural networks,
including heterogeneous neural networks that contain multiple types of
activation functions. Experiment results on a variety of benchmarks show the
effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10656</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10656</id><created>2019-06-25</created><authors><author><keyname>Islam</keyname><forenames>Md Atiqul</forenames></author><author><keyname>Alexandropoulos</keyname><forenames>George C.</forenames></author><author><keyname>Smida</keyname><forenames>Besma</forenames></author></authors><title>A Unified Beamforming and A/D Self-Interference Cancellation Design for
  Full Duplex MIMO Radios</title><categories>eess.SP</categories><comments>7 pages, 4 figures, To appear in the Proceedings of the IEEE
  International Symposium on Personal, Indoor and Mobile Radio Communications
  (PIMRC), 8-11 September 2019, Istanbul, Turkey</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we focus on reduced complexity full duplex Multiple-Input
Multiple-Output (MIMO) systems and present a joint design of digital transmit
and receive beamforming with Analog and Digital (A/D) self-interference
cancellation. We capitalize on a recently proposed multi-tap analog canceller
architecture, whose number of taps does not scale with the number of
transceiver antennas, and consider practical transmitter impairments for the
full duplex operation. Particularly, transmitter IQ imbalance and nonlinear
power amplification are assumed via relevant realistic models. Aiming at
suppressing the residual linear and nonlinear self-interference signal below
the noise floor, we propose a novel digital self-interference cancellation
technique that is jointly designed with the configuration of the analog taps
and digital beamformers. Differently from the state of the art, we design
pilot-assisted estimation of all involved wireless channels. Our representative
Monte Carlo simulation results demonstrate that our unified full duplex MIMO
design exhibits higher self-interference cancellation capability with less
analog taps compared to available techniques, which results in improved
achievable rate and bit error performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10657</identifier>
 <datestamp>2019-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10657</id><created>2019-06-25</created><updated>2019-10-08</updated><authors><author><keyname>Murillo</keyname><forenames>Marina</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>Guido</forenames></author><author><keyname>Genzelis</keyname><forenames>Lucas</forenames></author><author><keyname>Deniz</keyname><forenames>Nahuel</forenames></author><author><keyname>Giovanini</keyname><forenames>Leonardo</forenames></author></authors><title>A Receding Horizon Framework for Autonomy in Unmanned Vehicles</title><categories>eess.SY cs.SY</categories><comments>This article was rejected for publication in Optimal Control,
  Applications and Methods</comments><journal-ref>Under review at Optimal Control, Applications and Methods, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we present a unified framework based on receding horizon
techniques that can be used to design the three tasks (guidance, navigation and
path-planning) which are involved in the autonomy of unmanned vehicles. This
tasks are solved using model predictive control and moving horizon estimation
techniques, which allows us to include physical and dynamical constraints at
the design stage, thus leading to optimal and feasible results. In order to
demonstrate the capabilities of the proposed framework, we have used Gazebo
simulator in order to drive a Jackal unmanned ground vehicle (UGV) along a
desired path computed by the path-planning task. The results we have obtained
are successful as the estimation and guidance errors are small and the Jackal
UGV is able to follow the desired path satisfactorily and it is also capable to
avoid the obstacles which are in its way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10681</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10681</id><created>2019-06-25</created><authors><author><keyname>Ye</keyname><forenames>Mao</forenames></author><author><keyname>Ray</keyname><forenames>Vishva</forenames></author><author><keyname>Wu</keyname><forenames>Dachuan</forenames></author><author><keyname>Yi</keyname><forenames>Yasha</forenames></author></authors><title>Metalens With Artificial Focus Pattern</title><categories>eess.IV physics.optics</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metalens as one of the most popular applications of emmerging optical
metasurfaces has raised widspread interest recently. With nano structures fully
controlling phase, polarization and transmission, metalens has achieved
comparable performance of commercial objective lenses. While recent studies
seeking for the accomplishment of traditional focusing behaviors through
metalens are successful, inthis work, we have discovered that instead of
focusing light to a point, metasurface further enables shaping the focus into a
flexibly designed pattern, with more promises and potentials. New mechanism and
generalizations of conventional point-focused metalens guiding principles have
been proposed with metalens concentrating light to artificial focus pattern. As
proving examples, we have demonstrated the engineering of metalens with
artificial focus pattern by creating line and ring-shaped focus as 'drawing
tools'. The metalens with 'U' and 'M' shaped focus are characterized for the
proof of concepts. These metalens are fabricated through a single layer of
silicon-based material through CMOS compatible nano fabrication process. The
mechanism to generate artificial focus pattern can be applied to a plethora of
future on-chip optical devices with applications ranging from beam engineering
to next generation nano lithography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10725</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10725</id><created>2019-06-25</created><authors><author><keyname>Duque</keyname><forenames>Andr&#xe9;s F.</forenames></author><author><keyname>Wolf</keyname><forenames>Guy</forenames></author><author><keyname>Moon</keyname><forenames>Kevin R.</forenames></author></authors><title>Visualizing High Dimensional Dynamical Processes</title><categories>stat.ML cs.LG eess.SP</categories><comments>7 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manifold learning techniques for dynamical systems and time series have shown
their utility for a broad spectrum of applications in recent years. While these
methods are effective at learning a low-dimensional representation, they are
often insufficient for visualizing the global and local structure of the data.
In this paper, we present DIG (Dynamical Information Geometry), a visualization
method for multivariate time series data that extracts an information geometry
from a diffusion framework. Specifically, we implement a novel group of
distances in the context of diffusion operators, which may be useful to reveal
structure in the data that may not be accessible by the commonly used diffusion
distances. Finally, we present a case study applying our visualization tool to
EEG data to visualize sleep stages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10729</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10729</id><created>2019-06-25</created><authors><author><keyname>Zhang</keyname><forenames>Yucheng</forenames></author><author><keyname>Lobo-Mueller</keyname><forenames>Edrise M.</forenames></author><author><keyname>Karanicolas</keyname><forenames>Paul</forenames></author><author><keyname>Gallinger</keyname><forenames>Steven</forenames></author><author><keyname>Haider</keyname><forenames>Masoom A.</forenames></author><author><keyname>Khalvati</keyname><forenames>Farzad</forenames></author></authors><title>CNN-based Survival Model for Pancreatic Ductal Adenocarcinoma in Medical
  Imaging</title><categories>q-bio.QM cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cox proportional hazard model (CPH) is commonly used in clinical research for
survival analysis. In quantitative medical imaging (radiomics) studies, CPH
plays an important role in feature reduction and modeling. However, the
underlying linear assumption of CPH model limits the prognostic performance. In
addition, the multicollinearity of radiomic features and multiple testing
problem further impedes the CPH models performance. In this work, using
transfer learning, a convolutional neural network (CNN) based survival model
was built and tested on preoperative CT images of resectable Pancreatic Ductal
Adenocarcinoma (PDAC) patients. The proposed CNN-based survival model
outperformed the traditional CPH-based radiomics approach in terms of
concordance index by 22%, providing a better fit for patients' survival
patterns. The proposed CNN-based survival model outperforms CPH-based radiomics
pipeline in PDAC prognosis. This approach offers a better fit for survival
patterns based on CT images and overcomes the limitations of conventional
survival models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10746</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10746</id><created>2019-06-25</created><authors><author><keyname>Oselio</keyname><forenames>Brandon</forenames></author><author><keyname>Sadeghian</keyname><forenames>Amir</forenames></author><author><keyname>Savarese</keyname><forenames>Silvio</forenames></author><author><keyname>Hero</keyname><forenames>Alfred</forenames></author></authors><title>Time-Varying Interaction Estimation Using Ensemble Methods</title><categories>eess.SP cs.IT cs.LG eess.IV math.IT</categories><comments>2019 IEEE Data Science Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Directed information (DI) is a useful tool to explore time-directed
interactions in multivariate data. However, as originally formulated DI is not
well suited to interactions that change over time. In previous work, adaptive
directed information was introduced to accommodate non-stationarity, while
still preserving the utility of DI to discover complex dependencies between
entities. There are many design decisions and parameters that are crucial to
the effectiveness of ADI. Here, we apply ideas from ensemble learning in order
to alleviate this issue, allowing for a more robust estimator for exploratory
data analysis. We apply these techniques to interaction estimation in a crowded
scene, utilizing the Stanford drone dataset as an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10747</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10747</id><created>2019-06-25</created><authors><author><keyname>Deligianni</keyname><forenames>Fani</forenames></author><author><keyname>Domingos</keyname><forenames>Ines</forenames></author><author><keyname>Yang</keyname><forenames>Guang-Zhong</forenames></author></authors><title>Intention Detection of Gait Adaptation in Natural Settings</title><categories>cs.HC eess.SP</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Gait adaptation is an important part of gait analysis and its neuronal origin
and dynamics has been studied extensively. In neurorehabilitation, it is
important as it perturbs neuronal dynamics and allows patients to restore some
of their motor function. Exoskeletons and robotics of the lower limbs are
increasingly used to facilitate rehabilitation as well as supporting daily
function. Their efficiency and safety depends on how well can sense the human
intention to move and adapt the gait accordingly. This paper presents a gait
adaptation scheme in natural settings. It allows monitoring of subjects in more
realistic environment without the requirement of specialized equipment such as
treadmill and foot pressure sensors. We extract gait characteristics based on a
single RBG camera whereas wireless EEG signals are monitored simultaneously. We
demonstrate that the method can not only successfully detect adaptation steps
but also detect efficiently whether the subject adjust their pace to higher or
lower speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10751</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10751</id><created>2019-06-25</created><authors><author><keyname>Badiu</keyname><forenames>Mihai-Alin</forenames></author><author><keyname>Coon</keyname><forenames>Justin P.</forenames></author></authors><title>Communication Through a Large Reflecting Surface With Phase Errors</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assume the communication between a source and a destination is supported by a
large reflecting surface (LRS), which consists of an array of reflector
elements with adjustable reflection phases. By knowing the phase shifts induced
by the composite propagation channels through the LRS, the phases of the
reflectors can be configured such that the signals combine coherently at the
destination, which improves the communication performance. However, perfect
phase estimation or high-precision configuration of the reflection phases is
unfeasible. In this paper, we study the transmission through an LRS with phase
errors that have a generic distribution. We show that the LRS-based composite
channel is equivalent to a point-to-point Nakagami fading channel. This
equivalent representation allows for theoretical analysis of the performance
and can help the system designer study the interplay between performance, the
distribution of phase errors, and the number of reflectors. Numerical
evaluation of the error probability for a limited number of reflectors confirms
the theoretical prediction and shows that the performance is remarkably robust
against the phase errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10760</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10760</id><created>2019-06-25</created><updated>2019-07-25</updated><authors><author><keyname>Notarstefano</keyname><forenames>Giuseppe</forenames></author><author><keyname>Notarnicola</keyname><forenames>Ivano</forenames></author><author><keyname>Camisa</keyname><forenames>Andrea</forenames></author></authors><title>Distributed Optimization for Smart Cyber-Physical Networks</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The presence of embedded electronics and communication capabilities as well
as sensing and control in smart devices has given rise to the novel concept of
cyber-physical networks, in which agents aim at cooperatively solving complex
tasks by local computation and communication. Numerous estimation, learning,
decision and control tasks in smart networks involve the solution of
large-scale, structured optimization problems in which network agents have only
a partial knowledge of the whole problem. Distributed optimization aims at
designing local computation and communication rules for the network processors
allowing them to cooperatively solve the global optimization problem without
relying on any central unit. The purpose of this survey is to provide an
introduction to distributed optimization methodologies. Principal approaches,
namely (primal) consensus-based, duality-based and constraint exchange methods,
are formalized. An analysis of the basic schemes is supplied, and
state-of-the-art extensions are reviewed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10786</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10786</id><created>2019-06-25</created><authors><author><keyname>Alwan</keyname><forenames>Hayder O.</forenames></author><author><keyname>Sadeghian</keyname><forenames>Hamidreza</forenames></author><author><keyname>Abdelwahed</keyname><forenames>Sherif</forenames></author></authors><title>Optimized energy utilization in small and large commercial loads and
  residential areas</title><categories>eess.SY cs.SY math.OC</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In smart grid, the demand side management (DSM) techniques need to be
designed to process a large number of controllable loads of several types. In
this paper, we proposed a framework to study the demand side management in
smart grid which contains a variety of loads in two service areas, one with
multiple residential households, and one bus with commercial customers.
Specifically, each household may have renewable generation as well as
interruptible and uninterruptible appliances to make individual scheduling to
optimize the electric energy cost by making the best time of the electricity
usage according to the day ahead forecast of electricity prices. A high load
bus represents a commercial area employed to demonstrate the impact of high
load at any bus on voltage profile, power loss, and load flow condition, and to
show the performance of the proposed DSM for large number of appliance. Using
the developed simulation model, we examine the performance of the proposed DSM
and study their impact on the distribution network operation and renewable
generation, overall voltage deviation, real power loss, and possible problems
such as reverse power flows, voltage rise have examined and compared, these
problems can easily be seen at the commercial load bus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10790</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10790</id><created>2019-06-25</created><authors><author><keyname>Wei</keyname><forenames>Xiaoqian</forenames></author><author><keyname>Yang</keyname><forenames>Jianying</forenames></author><author><keyname>Fan</keyname><forenames>Xiangru</forenames></author></authors><title>Design of distributed guidance laws for multi-UAV cooperative attacking
  a moving target based on reducing surrounding area</title><categories>eess.SY cs.SY</categories><comments>arXiv admin note: substantial text overlap with arXiv:1906.11153</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, two cooperative guidance laws based on the area around the
target of multiattackers are designed to deal with the problem of cooperative
encirclement or simultaneous attack in the case of known target acceleration
and unknown target acceleration. Multi-attacker communication network only
needs to contain a directed spanning tree, and does not require all attackers
to observe the target information, where at least one can observe the target.
The components along the attacker-target line of sight in the novel guidance
laws can reduce the relative remaining distance between the attacker and the
target at the same speed, thus completing simultaneous attack and avoiding the
calculation of the remaining time. The components of the guidance laws
perpendicular to the attacker-target line of sight can make the normal overload
of relative motion zero, so that the trajectory will not be distorted and the
collision problem within the attacker group can be avoided. The simulation
results verify the practicability of the novel guidance laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10799</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10799</id><created>2019-06-25</created><authors><author><keyname>Cudmore</keyname><forenames>Peter</forenames></author><author><keyname>Gawthrop</keyname><forenames>Peter J.</forenames></author><author><keyname>Pan</keyname><forenames>Michael</forenames></author><author><keyname>Crampin</keyname><forenames>Edmund J.</forenames></author></authors><title>Computer-aided modelling of complex physical systems with BondGraphTools</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BondGraphTools is a Python library for scripted modelling of complex
multi-physics systems. In contrast to existing modelling solutions,
BondGraphTools is based upon the well established bond graph methodology,
provides a programming interface for symbolic model composition, and is
intended to be used in conjunction with the existing scientific Python
toolchain. Here we discuss the design, implementation and use of
BondGraphTools, demonstrate how it can be used to accelerate systems modelling
with an example from optomechanics, and comment on current and future
applications in cross-domain modelling, particularly in systems biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10814</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10814</id><created>2019-06-25</created><authors><author><keyname>Sun</keyname><forenames>Shilong</forenames></author><author><keyname>Kooij</keyname><forenames>Bert Jan</forenames></author><author><keyname>Yarovoy</keyname><forenames>Alexander G.</forenames></author></authors><title>Inversion of Multi-frequency Data with the Cross-Correlated Contrast
  Source Inversion Method</title><categories>eess.SP</categories><journal-ref>https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2017RS006505</journal-ref><doi>10.1029/2017RS006505</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cross-correlated contrast source inversion (CC-CSI) is a non-linear iterative
inversion method that is proposed recently for solving the inverse scattering
problems. In CC-CSI, a cross-correlated error is constructed and introduced to
the cost functional, which improves the inversion ability when compared to the
classical design of the cost functional by exploiting the mismatch between the
data error and state error. In this paper, the multi-frequency inversion for
electromagnetic waves is considered and a multi-frequency version of CC-CSI is
proposed. Numerical and experimental inversion results of both transverse
magnetic (TM) and transverse electric (TE) polarization demonstrate that, when
multi-frequency data are available, CC-CSI still outperforms the
multiplicative-regularized CSI method (MR-CSI) in the inversion of more
complicated scatterers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10815</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10815</id><created>2019-06-25</created><authors><author><keyname>Wu</keyname><forenames>Dongqi</forenames></author><author><keyname>Zheng</keyname><forenames>Xiangtian</forenames></author><author><keyname>Kalathil</keyname><forenames>Dileep</forenames></author><author><keyname>Xie</keyname><forenames>Le</forenames></author></authors><title>Nested Reinforcement Learning Based Control for Protective Relays in
  Power Distribution Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper envisions a new control architecture for the protective relay
setting in future power distribution systems. With deepening penetration of
distributed energy resources at the end users level, it has been recognized as
a key engineering challenge to redesign the protective relays in the future
distribution system. Conceptually, these protective relays are the discrete
ON/OFF control devices at the end of each branch and node in a power network.
The key technical difficulty lies in how to set up the relay control logic so
that the protection could successfully differentiate heavy load and faulty
operating conditions. This paper proposes a new nested reinforcement learning
approach to take advantage of the structural properties of distribution
networks and develop a new set of training methods for tuning the protective
relays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10834</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10834</id><created>2019-06-25</created><authors><author><keyname>Yang</keyname><forenames>Zhenchuan</forenames></author><author><keyname>Zhang</keyname><forenames>Chun</forenames></author><author><keyname>Zhang</keyname><forenames>Weibin</forenames></author><author><keyname>Jin</keyname><forenames>Jianxiu</forenames></author><author><keyname>Chen</keyname><forenames>Dongpeng</forenames></author></authors><title>Essence Knowledge Distillation for Speech Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that a speech recognition system that combines multiple
acoustic models trained on the same data significantly outperforms a
single-model system. Unfortunately, real time speech recognition using a whole
ensemble of models is too computationally expensive. In this paper, we propose
to distill the knowledge of essence in an ensemble of models (i.e. the teacher
model) to a single model (i.e. the student model) that needs much less
computation to deploy. Previously, all the soften outputs of the teacher model
are used to optimize the student model. We argue that not all the outputs of
the ensemble are necessary to be distilled. Some of the outputs may even
contain noisy information that is useless or even harmful to the training of
the student model. In addition, we propose to train the student model with a
multitask learning approach by utilizing both the soften outputs of the teacher
model and the correct hard labels. The proposed method achieves some surprising
results on the Switchboard data set. When the student model is trained together
with the correct labels and the essence knowledge from the teacher model, it
not only significantly outperforms another single model with the same
architecture that is trained only with the correct labels, but also
consistently outperforms the teacher model that is used to generate the soft
labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10848</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10848</id><created>2019-06-26</created><authors><author><keyname>Han</keyname><forenames>Jing</forenames></author><author><keyname>Ma</keyname><forenames>Shengqian</forenames></author><author><keyname>Wang</keyname><forenames>Yujie</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Low-Complexity Equalization of MIMO-OSDM</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Vehicular Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal signal-division multiplexing (OSDM) is an attractive alternative
to conventional orthogonal frequency-division multiplexing (OFDM) due to its
enhanced ability in peak-to-average power ratio (PAPR) reduction. Combining
OSDM with multiple-input multiple-output (MIMO) signaling has the potential to
achieve high spectral and power efficiency. However, a direct channel
equalization in this case incurs a cubic complexity, which may be expensive for
practical use. To solve the problem, low-complexity per-vector and block
equalization algorithms of MIMO-OSDM are proposed in this paper for
time-invariant and time-varying channels, respectively. By exploiting the
channel matrix structures, these algorithms have only a linear complexity in
the transformed domain. Simulation results demonstrate their validity and the
related performance comparisons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10853</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10853</id><created>2019-06-26</created><authors><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author></authors><title>A New Look at Cell-Free Massive MIMO: Making It Practical With Dynamic
  Cooperation</title><categories>cs.IT eess.SP math.IT</categories><comments>To appear at the 2019 IEEE International Symposium on Personal,
  Indoor and Mobile Radio Communications (IEEE PIMRC 2019), 6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper takes a new look at Cell-free Massive MIMO (multiple-input
multiple-output) through the lens of the dynamic cooperation cluster framework
from the Network MIMO literature. The purpose is to identify and address
scalability issues that appear in prior work. We provide distributed algorithms
for initial access, pilot assignment, cluster formation, precoding, and
combining that are scalable in the sense of being implementable with
arbitrarily many users. Interestingly, the suggested precoding and combining
outperform conjugate beamforming and matched filtering, respectively, while
also being fully distributed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10859</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10859</id><created>2019-06-26</created><authors><author><keyname>Wu</keyname><forenames>Peng-fei</forenames></author><author><keyname>Ling</keyname><forenames>Zhen-hua</forenames></author><author><keyname>Liu</keyname><forenames>Li-juan</forenames></author><author><keyname>Jiang</keyname><forenames>Yuan</forenames></author><author><keyname>Wu</keyname><forenames>Hong-chuan</forenames></author><author><keyname>Dai</keyname><forenames>Li-rong</forenames></author></authors><title>End-to-End Emotional Speech Synthesis Using Style Tokens and
  Semi-Supervised Training</title><categories>eess.AS cs.SD</categories><comments>5 pages, 2 figures submitted to APSIPA2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an end-to-end emotional speech synthesis (ESS) method
which adopts global style tokens (GSTs) for semi-supervised training. This
model is built based on the GST-Tacotron framework. The style tokens are
defined to present emotion categories. A cross entropy loss function between
token weights and emotion labels is designed to obtain the interpretability of
style tokens utilizing the small portion of training data with emotion labels.
Emotion recognition experiments confirm that this method can achieve one-to-one
correspondence between style tokens and emotion categories effectively.
Objective and subjective evaluation results show that our model outperforms the
conventional Tacotron model for ESS when only 5\% of training data has emotion
labels. Its subjective performance is close to the Tacotron model trained using
all emotion labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10864</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10864</id><created>2019-06-26</created><authors><author><keyname>Sun</keyname><forenames>Shilong</forenames></author><author><keyname>Kooij</keyname><forenames>Bert Jan</forenames></author><author><keyname>Jin</keyname><forenames>Tian</forenames></author><author><keyname>Yarovoy</keyname><forenames>Alexander G.</forenames></author></authors><title>Cross-correlated Contrast Source Inversion</title><categories>eess.SP</categories><doi>10.1109/TAP.2017.2673758</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we improved the performance of the contrast source inversion
(CSI) method by incorporating a so-called cross-correlated cost functional,
which interrelates the state error and the data error in the measurement
domain. The proposed method is referred to as the cross-correlated CSI. It
enables better robustness and higher inversion accuracy than both the classical
CSI and multiplicative regularized CSI (MR-CSI). In addition, we show how the
gradient of the modified cost functional can be calculated without
significantly increasing the computational burden. The advantages of the
proposed algorithms are demonstrated using a 2-D benchmark problem excited by a
transverse magnetic wave as well as a transverse electric wave, respectively,
in comparison to classical CSI and MR-CSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10875</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10875</id><created>2019-06-26</created><authors><author><keyname>Sun</keyname><forenames>Shilong</forenames></author><author><keyname>Kooij</keyname><forenames>Bert Jan</forenames></author><author><keyname>Yarovoy</keyname><forenames>Alexander G.</forenames></author><author><keyname>Jin</keyname><forenames>Tian</forenames></author></authors><title>A Linear Method for Shape Reconstruction based on the Generalized
  Multiple Measurement Vectors Model</title><categories>eess.SP</categories><doi>10.1109/TAP.2018.2806404</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel linear method for shape reconstruction is proposed
based on the generalized multiple measurement vectors (GMMV) model. Finite
difference frequency domain (FDFD) is applied to discretized Maxwell's
equations, and the contrast sources are solved iteratively by exploiting the
joint sparsity as a regularized constraint. Cross validation (CV) technique is
used to terminate the iterations, such that the required estimation of the
noise level is circumvented. The validity is demonstrated with an excitation of
transverse magnetic (TM) experimental data, and it is observed that, in the
aspect of focusing performance, the GMMV-based linear method outperforms the
extensively used linear sampling method (LSM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10876</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10876</id><created>2019-06-26</created><authors><author><keyname>Kanda</keyname><forenames>Naoyuki</forenames></author><author><keyname>Horiguchi</keyname><forenames>Shota</forenames></author><author><keyname>Takashima</keyname><forenames>Ryoichi</forenames></author><author><keyname>Fujita</keyname><forenames>Yusuke</forenames></author><author><keyname>Nagamatsu</keyname><forenames>Kenji</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author></authors><title>Auxiliary Interference Speaker Loss for Target-Speaker Speech
  Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted to INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel auxiliary loss function for target-speaker
automatic speech recognition (ASR). Our method automatically extracts and
transcribes target speaker's utterances from a monaural mixture of multiple
speakers speech given a short sample of the target speaker. The proposed
auxiliary loss function attempts to additionally maximize interference speaker
ASR accuracy during training. This will regularize the network to achieve a
better representation for speaker separation, thus achieving better accuracy on
the target-speaker ASR. We evaluated our proposed method using
two-speaker-mixed speech in various signal-to-interference-ratio conditions. We
first built a strong target-speaker ASR baseline based on the state-of-the-art
lattice-free maximum mutual information. This baseline achieved a word error
rate (WER) of 18.06% on the test set while a normal ASR trained with clean data
produced a completely corrupted result (WER of 84.71%). Then, our proposed loss
further reduced the WER by 6.6% relative to this strong baseline, achieving a
WER of 16.87%. In addition to the accuracy improvement, we also showed that the
auxiliary output branch for the proposed loss can even be used for a secondary
ASR for interference speakers' speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10886</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10886</id><created>2019-06-26</created><authors><author><keyname>Zhou</keyname><forenames>Zibin</forenames></author><author><keyname>Wang</keyname><forenames>Fei</forenames></author><author><keyname>Xi</keyname><forenames>Wenjuan</forenames></author><author><keyname>Chen</keyname><forenames>Huaying</forenames></author><author><keyname>Gao</keyname><forenames>Peng</forenames></author><author><keyname>He</keyname><forenames>Chengkang</forenames></author></authors><title>Joint Multi-frame Detection and Segmentation for Multi-cell Tracking</title><categories>cs.CV cs.GR eess.IV</categories><comments>Accepted by International Conference on Image and Graphics (ICIG
  2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tracking living cells in video sequence is difficult, because of cell
morphology and high similarities between cells. Tracking-by-detection methods
are widely used in multi-cell tracking. We perform multi-cell tracking based on
the cell centroid detection, and the performance of the detector has high
impact on tracking performance. In this paper, UNet is utilized to extract
inter-frame and intra-frame spatio-temporal information of cells. Detection
performance of cells in mitotic phase is improved by multi-frame input. Good
detection results facilitate multi-cell tracking. A mitosis detection algorithm
is proposed to detect cell mitosis and the cell lineage is built up. Another
UNet is utilized to acquire primary segmentation. Jointly using detection and
primary segmentation, cells can be fine segmented in highly dense cell
population. Experiments are conducted to evaluate the effectiveness of our
method, and results show its state-of-the-art performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10891</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10891</id><created>2019-06-26</created><updated>2019-09-26</updated><authors><author><keyname>Naranjo-Alcazar</keyname><forenames>Javier</forenames></author><author><keyname>Perez-Castanos</keyname><forenames>Sergi</forenames></author><author><keyname>Martin-Morato</keyname><forenames>Irene</forenames></author><author><keyname>Zuccarello</keyname><forenames>Pedro</forenames></author><author><keyname>Cobos</keyname><forenames>Maximo</forenames></author></authors><title>On the performance of residual block design alternatives in
  convolutional neural networks for end-to-end audio classification</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Residual learning is a recently proposed learning framework to facilitate the
training of very deep neural networks. Residual blocks or units are made of a
set of stacked layers, where the inputs are added back to their outputs with
the aim of creating identity mappings. In practice, such identity mappings are
accomplished by means of the so-called skip or residual connections. However,
multiple implementation alternatives arise with respect to where such skip
connections are applied within the set of stacked layers that make up a
residual block. While ResNet architectures for image classification using
convolutional neural networks (CNNs) have been widely discussed in the
literature, few works have adopted ResNet architectures so far for 1D audio
classification tasks. Thus, the suitability of different residual block designs
for raw audio classification is partly unknown. The purpose of this paper is to
analyze and discuss the performance of several residual block implementations
within a state-of-the-art CNN-based architecture for end-to-end audio
classification using raw audio waveforms. For comparison purposes, we analyze
as well the performance of the residual blocks under a similar 2D architecture
using a conventional time-frequency audio represen-tation as input. The results
show that the achieved accuracy is considerably dependent, not only on the
specific residual block implementation, but also on the selected input
normalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10893</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10893</id><created>2019-06-26</created><authors><author><keyname>Zhao</keyname><forenames>Yang</forenames></author><author><keyname>Zhao</keyname><forenames>Jun</forenames></author><author><keyname>Jiang</keyname><forenames>Linshan</forenames></author><author><keyname>Tan</keyname><forenames>Rui</forenames></author><author><keyname>Niyato</keyname><forenames>Dusit</forenames></author></authors><title>Mobile Edge Computing, Blockchain and Reputation-based Crowdsourcing IoT
  Federated Learning: A Secure, Decentralized and Privacy-preserving System</title><categories>cs.CR cs.HC cs.LG cs.NI cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet-of-Things (IoT) companies strive to get feedback from users to
improve their products and services. However, traditional surveys cannot
reflect the actual conditions of customers' due to the limited questions.
Besides, survey results are affected by various subjective factors. In
contrast, the recorded usages of IoT devices reflect customers' behaviours more
comprehensively and accurately. We design an intelligent system to help IoT
device manufacturers to take advantage of customers' data and build a machine
learning model to predict customers' requirements and possible consumption
behaviours with federated learning (FL) technology. The FL consists of two
stages: in the first stage, customers train the initial model using the phone
and the edge computing server collaboratively. The mobile edge computing
server's high computation power can assist customers' training locally.
Customers first collect data from various IoT devices using phones, and then
download and train the initial model with their data. During the training,
customers first extract features using their mobiles, and then add the
Laplacian noise to the extracted features based on differential privacy, a
formal and popular notion to quantify privacy. After achieving the local model,
customers sign on their models respectively and send them to the blockchain. We
use the blockchain to replace the centralized aggregator which belongs to the
third party in FL. In the second stage, miners calculate the averaged model
using the collected models sent from customers. By the end of the crowdsourcing
job, one of the miners, who is selected as the temporary leader, uploads the
model to the blockchain. Besides, to attract more customers to participate in
the crowdsourcing FL, we design an incentive mechanism, which awards
participants with coins that can be used to purchase other services provided by
the company.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10900</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10900</id><created>2019-06-26</created><authors><author><keyname>Sun</keyname><forenames>Shilong</forenames></author><author><keyname>Kooij</keyname><forenames>Bert Jan</forenames></author><author><keyname>Yarovoy</keyname><forenames>Alexander G.</forenames></author></authors><title>A Linear Model for Microwave Imaging of Highly Conductive Scatterers</title><categories>eess.SP</categories><doi>10.1109/TMTT.2017.2772795</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a linear model based on multiple measurement vectors model is
proposed to formulate the inverse scattering problem of highly conductive
objects at one single frequency. Considering the induced currents which are
mostly distributed on the boundaries of the scatterers, joint sparse structure
is enforced by a sum-of-norm regularization. Since no \textit{a priori}
information is required and no approximation of the scattering model has been
made, the proposed method is versatile. Imaging results with transverse
magnetic and transverse electric polarized synthetic data and Fresnel data
demonstrate its higher resolving ability than both linear sampling method and
its improved version with higher, but acceptable, computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10909</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10909</id><created>2019-06-26</created><authors><author><keyname>Cui</keyname><forenames>Zhuangzhuang</forenames></author><author><keyname>Guan</keyname><forenames>Ke</forenames></author><author><keyname>Briso</keyname><forenames>C&#xe9;sar</forenames></author><author><keyname>He</keyname><forenames>Danping</forenames></author><author><keyname>Ai</keyname><forenames>Bo</forenames></author><author><keyname>Zhong</keyname><forenames>Zhangdui</forenames></author></authors><title>Probabilistic Two-Ray Model for Air-to-Air Channel in Built-Up Areas</title><categories>eess.SP cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a probabilistic two-ray (PTR) path loss model for
air-to-air (AA) propagation channel in built-up areas. Based on the statistical
model of city deployment, the PTR path loss model can be applied to suburban,
urban, dense urban, and high-rise urban. The path loss is optimally fitted as
the Weibull distribution and its fluctuation is fitted as the Normal
distribution in ray-tracing simulations. The good agreements between our model
and ray tracing indicate the proposed model can provide a useful tool for
accurate and quick prediction for aerial platforms. As an extended research of
PTR model, we extract the shadowing factor by numerous simulations and propose
the altitude-dependent shadowing model. The result shows that the proposed
shadowing model has very good consistent with the measurement-based model,
which indicates that our research performs well in the extensibility and
generality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10931</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10931</id><created>2019-06-26</created><authors><author><keyname>Sun</keyname><forenames>Shilong</forenames></author><author><keyname>Kooij</keyname><forenames>Bert Jan</forenames></author><author><keyname>Yarovoy</keyname><forenames>Alexander G.</forenames></author></authors><title>Linearized 3-D Electromagnetic Contrast Source Inversion and Its
  Applications to Half-space Configurations</title><categories>eess.SP</categories><doi>10.1109/TGRS.2017.2672861</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main computational drawbacks in the application of 3-D iterative
inversion techniques is the requirement of solving the field quantities for the
updated contrast in every iteration. In this paper, the 3-D electromagnetic
inverse scattering problem is put into a discretized finite-difference
frequency-domain scheme and linearized into a cascade of two linear
functionals. To deal with the nonuniqueness effectively, the joint structure of
the contrast sources is exploited using a sum-of-$\ell_1$-norm optimization
scheme. A cross-validation technique is used to check whether the optimization
process is accurate enough. The total fields are, then, calculated and used to
reconstruct the contrast by minimizing a cost functional defined as the sum of
the data error and state error. In this procedure, the total fields in the
inversion domain are computed only once, while the quality and accuracy of the
obtained reconstructions are maintained. The novel method is applied to
ground-penetrating radar imaging and through-the-wall imaging, in which the
validity and efficiency of the method is demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10945</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10945</id><created>2019-06-26</created><authors><author><keyname>Mancini</keyname><forenames>Mauro</forenames></author><author><keyname>Bloise</keyname><forenames>Nicoletta</forenames></author><author><keyname>Capello</keyname><forenames>Elisa</forenames></author><author><keyname>Punta</keyname><forenames>Elisabetta</forenames></author></authors><title>Sliding Mode Control Techniques and Artificial Potential Field for
  Dynamic Collision Avoidance in Rendezvous Maneuvers</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper considers autonomous rendezvous maneuver and proximity operations
of two spacecraft in presence of obstacles. A strategy that combines guidance
and control algorithms is analyzed. The proposed closed-loop system is able to
guarantee a safe path in a real environment, as well as robustness with respect
to external disturbances and dynamic obstacles. The guidance strategy exploits
a suitably designed Artificial Potential Field (APF), while the controller
relies on Sliding Mode Control (SMC), for both position and attitude tracking
of the spacecraft. As for the position control, two different first order SMC
methods are considered, namely the component-wise and the simplex-based control
techniques. The proposed integrated guidance and control strategy is validated
by extensive simulations performed with a six degree-of-freedom (DOF) orbital
simulator and appears suitable for real-time control with minimal on-board
computational effort. Fuel consumption and control effort are evaluated,
including different update frequencies of the closed-loop software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10956</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10956</id><created>2019-06-26</created><authors><author><keyname>Pinal-Moctezuma</keyname><forenames>Fernando</forenames></author><author><keyname>Delgado-Prieto</keyname><forenames>Miguel</forenames></author><author><keyname>Romeral-Martinez</keyname><forenames>Luis</forenames></author></authors><title>An Acoustic Emission Activity Detection Method based on Short-Term
  Waveform Features: Application to Metallic Components under Uniaxial Tensile
  Test</title><categories>eess.SP</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Acoustic Emission (AE) phenomenon has been used as a powerful tool with
the purpose to either detect, locate or assess damage for a wide range of
applications. Derived from its monitoring, one major current challenge on the
analysis of the acquired signal is the proper identification and separation of
each AE event. Current advanced methods for detecting events are primarily
focused on identifying with high accuracy the beginning of the AE wave;
however, the detection of the conclusion has been disregarded in the
literature. For an automatic continuous detection of events within a data
stream, this lack of accuracy for the conclusion of the events generates errors
in two critical aspects. In one hand, it deteriorates the accuracy of the
measurement of the events duration, truncating the span of the event
(undesirable in evaluation applications), and in the other hand, it causes
false detections. In this work, an accurate and computationally efficient AE
activity detector is presented, using a framework inspired by the area of
speech processing, and which provides the required indicators to accurately
detect the onset and the end of an AE event. This is achieved by means of a
threshold approach that instead of directly operates with the transduced
voltage signal it does so over the Short-Term Energy and the Short-Term
Zero-Crossing Rate measures of the signal. The STE-ZCR method is developed for
an application related to the continuous monitoring of a single AE channel
derived from the characterization of metallic components by means of a uniaxial
tensile test. Additionally, two experimental test-benches are implemented with
the aim to quantify the accuracy and the quality of event detection of the
presented method. Finally, the obtained results are compared with four
different techniques, representing the current state of the art related to AE
activity detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10971</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10971</id><created>2019-06-26</created><authors><author><keyname>Grigorescu</keyname><forenames>Sorin</forenames></author><author><keyname>Trasnea</keyname><forenames>Bogdan</forenames></author><author><keyname>Marina</keyname><forenames>Liviu</forenames></author><author><keyname>Vasilcoi</keyname><forenames>Andrei</forenames></author><author><keyname>Cocias</keyname><forenames>Tiberiu</forenames></author></authors><title>NeuroTrajectory: A Neuroevolutionary Approach to Local State Trajectory
  Learning for Autonomous Vehicles</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous vehicles are controlled today either based on sequences of
decoupled perception-planning-action operations, either based on End2End or
Deep Reinforcement Learning (DRL) systems. Current deep learning solutions for
autonomous driving are subject to several limitations (e.g. they estimate
driving actions through a direct mapping of sensors to actuators, or require
complex reward shaping methods). Although the cost function used for training
can aggregate multiple weighted objectives, the gradient descent step is
computed by the backpropagation algorithm using a single-objective loss. To
address these issues, we introduce NeuroTrajectory, which is a multi-objective
neuroevolutionary approach to local state trajectory learning for autonomous
driving, where the desired state trajectory of the ego-vehicle is estimated
over a finite prediction horizon by a perception-planning deep neural network.
In comparison to DRL methods, which predict optimal actions for the upcoming
sampling time, we estimate a sequence of optimal states that can be used for
motion control. We propose an approach which uses genetic algorithms for
training a population of deep neural networks, where each network individual is
evaluated based on a multi-objective fitness vector, with the purpose of
establishing a so-called Pareto front of optimal deep neural networks. The
performance of an individual is given by a fitness vector composed of three
elements. Each element describes the vehicle's travel path, lateral velocity
and longitudinal speed, respectively. The same network structure can be trained
on synthetic, as well as on real-world data sequences. We have benchmarked our
system against a baseline Dynamic Window Approach (DWA), as well as against an
End2End supervised learning method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.10996</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.10996</id><created>2019-06-26</created><authors><author><keyname>Balke</keyname><forenames>Stefan</forenames></author><author><keyname>Dorfer</keyname><forenames>Matthias</forenames></author><author><keyname>Carvalho</keyname><forenames>Luis</forenames></author><author><keyname>Arzt</keyname><forenames>Andreas</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Learning Soft-Attention Models for Tempo-invariant Audio-Sheet Music
  Retrieval</title><categories>cs.IR cs.CV cs.LG cs.SD eess.AS</categories><comments>Accepted for publication at ISMIR 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Connecting large libraries of digitized audio recordings to their
corresponding sheet music images has long been a motivation for researchers to
develop new cross-modal retrieval systems. In recent years, retrieval systems
based on embedding space learning with deep neural networks got a step closer
to fulfilling this vision. However, global and local tempo deviations in the
music recordings still require careful tuning of the amount of temporal context
given to the system. In this paper, we address this problem by introducing an
additional soft-attention mechanism on the audio input. Quantitative and
qualitative results on synthesized piano data indicate that this attention
increases the robustness of the retrieval system by focusing on different parts
of the input representation based on the tempo of the audio. Encouraged by
these results, we argue for the potential of attention models as a very general
tool for many MIR tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11003</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11003</id><created>2019-06-26</created><updated>2019-07-31</updated><authors><author><keyname>Celik</keyname><forenames>Onur</forenames></author><author><keyname>Abdulsamad</keyname><forenames>Hany</forenames></author><author><keyname>Peters</keyname><forenames>Jan</forenames></author></authors><title>Chance-Constrained Trajectory Optimization for Non-linear Systems with
  Unknown Stochastic Dynamics</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iterative trajectory optimization techniques for non-linear dynamical systems
are among the most powerful and sample-efficient methods of model-based
reinforcement learning and approximate optimal control. By leveraging
time-variant local linear-quadratic approximations of system dynamics and
reward, such methods can find both a target-optimal trajectory and time-variant
optimal feedback controllers. However, the local linear-quadratic assumptions
are a major source of optimization bias that leads to catastrophic greedy
updates, raising the issue of proper regularization. Moreover, the approximate
models' disregard for any physical state-action limits of the system causes
further aggravation of the problem, as the optimization moves towards
unreachable areas of the state-action space. In this paper, we address the
issue of constrained systems in the scenario of online-fitted stochastic linear
dynamics. We propose modeling state and action physical limits as probabilistic
chance constraints linear in both state and action and introduce a new
trajectory optimization technique that integrates these probabilistic
constraints by optimizing a relaxed quadratic program. Our empirical
evaluations show a significant improvement in learning robustness, which
enables our approach to perform more effective updates and avoid premature
convergence observed in state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11014</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11014</id><created>2019-06-26</created><authors><author><keyname>Shamir</keyname><forenames>Reuben R</forenames></author><author><keyname>Bomzon</keyname><forenames>Zeev</forenames></author></authors><title>Evaluation of head segmentation quality for treatment planning of tumor
  treating fields in brain tumors</title><categories>eess.IV cs.CV</categories><comments>published as a long abstract in IPCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tumor treating fields (TTFields) is an FDA approved therapy for the treatment
of Gliobastoma Multiform (GBM) and currently being investigated for additional
tumor types. TTFields are delivered to the tumor through the placement of
transducer arrays (TAs) placed on the patient scalp. The positions of the TAs
are associated with treatment outcomes via simulations of the electric fields.
Therefore, we are currently developing a method for recommending optimal
placement of TAs. A key step to achieve this goal is to correctly segment the
head into tissues of similar electrical properties. Visual inspection of
segmentation quality is invaluable but time-consuming. Automatic quality
assessment can assist in automatic refinement of the segmentation parameters,
suggest flaw points to the user and indicate if the segmented method is of
sufficient accuracy for TTFields simulation. As a first step in this direction,
we identified a set of features that are relevant to atlas-based segmentation
and show that these are significantly correlated (p &lt; 0.05) with a similarity
measure between validated and automatically computed segmentations.
Furthermore, we incorporated these features in a decision tree regressor to
predict the similarity of the validated and computed segmentations of 20
TTFields patients using a leave-one-out approach. The predicted similarity
measures were highly correlated with the actual ones (average abs. difference
3% (SD = 3%); r = 0.92, p &lt; 0.001). We conclude that quality estimation of
segmentations is feasible by incorporating machine learning and
segmentation-relevant features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11018</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11018</id><created>2019-06-21</created><authors><author><keyname>Lim</keyname><forenames>Minkyu</forenames></author><author><keyname>Kim</keyname><forenames>Ji-Hwan</forenames></author></authors><title>Integration of TensorFlow based Acoustic Model with Kaldi WFST Decoder</title><categories>eess.AS cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the Kaldi framework provides state-of-the-art components for speech
recognition like feature extraction, deep neural network (DNN)-based acoustic
models, and a weighted finite state transducer (WFST)-based decoder, it is
difficult to implement a new flexible DNN model. By contrast, a general-purpose
deep learning framework, such as TensorFlow, can easily build various types of
neural network architectures using a tensor-based computation method, but it is
difficult to apply them to WFST-based speech recognition. In this study, a
TensorFlow-based acoustic model is integrated with a WFST-based Kaldi decoder
to combine the two frameworks. The features and alignments used in Kaldi are
converted so they can be trained by the TensorFlow model, and the DNN-based
acoustic model is then trained. In the integrated Kaldi decoder, the posterior
probabilities are calculated by querying the trained TensorFlow model, and a
beam search is performed to generate the lattice. The advantages of the
proposed one-pass decoder include the application of various types of neural
networks to WFST-based speech recognition and WFST-based online decoding using
a TensorFlow-based acoustic model. The TensorFlow based acoustic models trained
using the RM, WSJ, and LibriSpeech datasets show the same level of performance
as the model trained using the Kaldi framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11031</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11031</id><created>2019-06-26</created><authors><author><keyname>Shamir</keyname><forenames>Reuben R</forenames></author><author><keyname>Duchin</keyname><forenames>Yuval</forenames></author><author><keyname>Kim</keyname><forenames>Jinyoung</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author><author><keyname>Harel</keyname><forenames>Noam</forenames></author></authors><title>Continuous Dice Coefficient: a Method for Evaluating Probabilistic
  Segmentations</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: Overlapping measures are often utilized to quantify the similarity
between two binary regions. However, modern segmentation algorithms output a
probability or confidence map with continuous values in the zero-to-one
interval. Moreover, these binary overlapping measures are biased to structure
size. Addressing these challenges is the objective of this work. Methods: We
extend the definition of the classical Dice coefficient (DC) overlap to
facilitate the direct comparison of a ground truth binary image with a
probabilistic map. We call the extended method continuous Dice coefficient
(cDC) and show that 1) cDC is less or equal to 1 and cDC = 1 if-and-only-if the
structures overlap is complete, and, 2) cDC is monotonically decreasing with
the amount of overlap. We compare the classical DC and the cDC in a simulation
of partial volume effects that incorporates segmentations of common targets for
deep-brainstimulation. Lastly, we investigate the cDC for an automatic
segmentation of the subthalamic-nucleus. Results: Partial volume effect
simulation on thalamus (large structure) resulted with DC and cDC averages (SD)
of 0.98 (0.006) and 0.99 (0.001), respectively. For subthalamic-nucleus (small
structure) DC and cDC were 0.86 (0.025) and 0.97 (0.006), respectively. The DC
and cDC for automatic STN segmentation were 0.66 and 0.80, respectively.
Conclusion: The cDC is well defined for probabilistic segmentation, less biased
to structure size and more robust to partial volume effects in comparison to
DC. Significance: The proposed method facilitates a better evaluation of
segmentation algorithms. As a better measurement tool, it opens the door for
the development of better segmentation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11047</identifier>
 <datestamp>2019-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11047</id><created>2019-06-21</created><updated>2019-10-03</updated><authors><author><keyname>von Platen</keyname><forenames>Patrick</forenames></author><author><keyname>Zhang</keyname><forenames>Chao</forenames></author><author><keyname>Woodland</keyname><forenames>Philip</forenames></author></authors><title>Multi-Span Acoustic Modelling using Raw Waveform Signals</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>To appear in INTERSPEECH 2019</comments><doi>10.21437/Interspeech.2019-2454</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional automatic speech recognition (ASR) systems often use an acoustic
model (AM) built on handcrafted acoustic features, such as log Mel-filter bank
(FBANK) values. Recent studies found that AMs with convolutional neural
networks (CNNs) can directly use the raw waveform signal as input. Given
sufficient training data, these AMs can yield a competitive word error rate
(WER) to those built on FBANK features. This paper proposes a novel multi-span
structure for acoustic modelling based on the raw waveform with multiple
streams of CNN input layers, each processing a different span of the raw
waveform signal. Evaluation on both the single channel CHiME4 and AMI data sets
show that multi-span AMs give a lower WER than FBANK AMs by an average of about
5% (relative). Analysis of the trained multi-span model reveals that the CNNs
can learn filters that are rather different to the log Mel filters.
Furthermore, the paper shows that a widely used single span raw waveform AM can
be improved by using a smaller CNN kernel size and increased stride to yield
improved WERs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11049</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11049</id><created>2019-06-20</created><authors><author><keyname>Nakashima</keyname><forenames>Ryo</forenames></author><author><keyname>Ozaki</keyname><forenames>Ryo</forenames></author><author><keyname>Taniguchi</keyname><forenames>Tadahiro</forenames></author></authors><title>Unsupervised Phoneme and Word Discovery from Multiple Speakers using
  Double Articulation Analyzer and Neural Network with Parametric Bias</title><categories>eess.AS cs.SD</categories><comments>21 pages. Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new unsupervised machine learning method for
simultaneous phoneme and word discovery from multiple speakers. Human infants
can acquire knowledge of phonemes and words from interactions with his/her
mother as well as with others surrounding him/her. From a computational
perspective, phoneme and word discovery from multiple speakers is a more
challenging problem than that from one speaker because the speech signals from
different speakers exhibit different acoustic features. This paper proposes an
unsupervised phoneme and word discovery method that simultaneously uses
nonparametric Bayesian double articulation analyzer (NPB-DAA) and deep sparse
autoencoder with parametric bias in hidden layer (DSAE-PBHL). We assume that an
infant can recognize and distinguish speakers based on certain other features,
e.g., visual face recognition. DSAE-PBHL is aimed to be able to subtract
speaker-dependent acoustic features and extract speaker-independent features.
An experiment demonstrated that DSAE-PBHL can subtract distributed
representations of acoustic signals, enabling extraction based on the types of
phonemes rather than on the speakers. Another experiment demonstrated that a
combination of NPB-DAA and DSAE-PB outperformed the available methods in
phoneme and word discovery tasks involving speech signals with Japanese vowel
sequences from multiple speakers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11070</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11070</id><created>2019-06-26</created><updated>2019-09-16</updated><authors><author><keyname>Bai</keyname><forenames>Li</forenames></author><author><keyname>Thomopulos</keyname><forenames>Dimitri</forenames></author><author><keyname>Crisostomi</keyname><forenames>Emanuele</forenames></author></authors><title>Preference-based Energy Exchange in a Network of Microgrids</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-to-peer energy trading is emerging as a new paradigm that in the near
future may disrupt conventional electricity markets and heavily affect energy
exchanges in networks of microgrids. In this paper, a preference mechanism is
considered to compute optimal energy exchanges in a network of microgrids with
or without the supervision of the distribution system operator, and the
alternating direction method of multipliers is adopted for its distributed
solution. The effect of the preference mechanism on the resulting power flow in
the network is further studied and discussed for realistic case studies.
Results show that a desired power flow in the network of interconnected
microgrids can be achieved with different preference values locally chosen or
imposed by the system operator. In particular, appropriate preferences may be
used to give rise to different clusters of microgrids and reduce energy
exchanges between different clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11084</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11084</id><created>2019-06-26</created><updated>2019-10-01</updated><authors><author><keyname>Gray</keyname><forenames>W. Steven</forenames></author><author><keyname>Venkatesh</keyname><forenames>G. S.</forenames></author><author><keyname>Espinosa</keyname><forenames>Luis A. Duffaut</forenames></author></authors><title>Combining Learning and Model Based Control via Discrete-Time Chen-Fliess
  Series</title><categories>eess.SY cs.SY</categories><comments>Fixed typos, discussed future work, updated references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A learning control system is presented suitable for control affine nonlinear
plants based on discrete-time Chen-Fliess series and capable of incorporating
knowledge of a given physical model. The underlying noncommutative algebraic
and combinatorial structures needed to realize the multivariable case are also
described. The method is demonstrated using a two-input, two-output
Lotka-Volterra system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11113</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11113</id><created>2019-06-26</created><authors><author><keyname>Elvander</keyname><forenames>Filip</forenames></author><author><keyname>Sw&#xe4;rd</keyname><forenames>Johan</forenames></author><author><keyname>Jakobsson</keyname><forenames>Andreas</forenames></author></authors><title>Mismatched Estimation of Polynomially Damped Signals</title><categories>eess.SP stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider the problem of estimating the parameters of
polynomially damped sinusoidal signals, commonly encountered in, for instance,
spectroscopy. Generally, finding the parameter values of such signals
constitutes a high-dimensional problem, often further complicated by not
knowing the number of signal components or their specific signal structures. In
order to alleviate the computational burden, we herein propose a mismatched
estimation procedure using simplified, approximate signal models. Despite the
approximation, we show that such a procedure is expected to yield predictable
results, allowing for statistically and computationally efficient estimates of
the signal parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11118</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11118</id><created>2019-06-26</created><authors><author><keyname>Kapil</keyname><forenames>Ansh</forenames></author><author><keyname>Wiestler</keyname><forenames>Tobias</forenames></author><author><keyname>Lanzmich</keyname><forenames>Simon</forenames></author><author><keyname>Silva</keyname><forenames>Abraham</forenames></author><author><keyname>Steele</keyname><forenames>Keith</forenames></author><author><keyname>Rebelatto</keyname><forenames>Marlon</forenames></author><author><keyname>Schmidt</keyname><forenames>Guenter</forenames></author><author><keyname>Brieu</keyname><forenames>Nicolas</forenames></author></authors><title>DASGAN -- Joint Domain Adaptation and Segmentation for the Analysis of
  Epithelial Regions in Histopathology PD-L1 Images</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of the tumor environment on digital histopathology slides is
becoming key for the understanding of the immune response against cancer,
supporting the development of novel immuno-therapies. We introduce here a novel
deep learning solution to the related problem of tumor epithelium segmentation.
While most existing deep learning segmentation approaches are trained on
time-consuming and costly manual annotation on single stain domain (PD-L1), we
leverage here semi-automatically labeled images from a second stain domain
(Cytokeratin-CK). We introduce an end-to-end trainable network that jointly
segment tumor epithelium on PD-L1 while leveraging unpaired image-to-image
translation between CK and PD-L1, therefore completely bypassing the need for
serial sections or re-staining of slides. Extending the method to differentiate
between PD-L1 positive and negative tumor epithelium regions enables the
automated estimation of the PD-L1 Tumor Cell (TC) score. Quantitative
experimental results demonstrate the accuracy of our approach against
state-of-the-art segmentation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11129</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11129</id><created>2019-06-12</created><authors><author><keyname>Yasarla</keyname><forenames>Rajeev</forenames></author><author><keyname>Patel</keyname><forenames>Vishal M.</forenames></author></authors><title>Uncertainty Guided Multi-Scale Residual Learning-using a Cycle Spinning
  CNN for Single Image De-Raining</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>The IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single image de-raining is an extremely challenging problem since the rainy
image may contain rain streaks which may vary in size, direction and density.
Previous approaches have attempted to address this problem by leveraging some
prior information to remove rain streaks from a single image. One of the major
limitations of these approaches is that they do not consider the location
information of rain drops in the image. The proposed Uncertainty guided
Multi-scale Residual Learning (UMRL) network attempts to address this issue by
learning the rain content at different scales and using them to estimate the
final de-rained output. In addition, we introduce a technique which guides the
network to learn the network weights based on the confidence measure about the
estimate. Furthermore, we introduce a new training and testing procedure based
on the notion of cycle spinning to improve the final de-raining performance.
Extensive experiments on synthetic and real datasets to demonstrate that the
proposed method achieves significant improvements over the recent
state-of-the-art methods. Code is available at:
https://github.com/rajeevyasarla/UMRL--using-Cycle-Spinning
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11135</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11135</id><created>2019-06-26</created><authors><author><keyname>Qasmi</keyname><forenames>Fahad</forenames></author><author><keyname>Shehab</keyname><forenames>Mohammad</forenames></author><author><keyname>Alves</keyname><forenames>Hirley</forenames></author><author><keyname>Latva-aho</keyname><forenames>Matti</forenames></author></authors><title>Fixed Rate Statistical QoS Provisioning for Markovian Sources in Machine
  Type Communication</title><categories>cs.NI cs.IT eess.SP math.IT</categories><comments>arXiv admin note: text overlap with arXiv:1808.06839</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the trade-off between reliability and latency in
machine type communication (MTC), which consists of single transmitter and
receiver in the presence of Rayleigh fading channel. We assume that the
transmitter does not know the channel conditions, therefore it would be
transmitting information over a fixed rate. The fixed rate transmission is
modeled as a two-state continuous-time Markov process, where the optimum
transmission rate is obtained. Moreover, we conduct a performance analysis for
different arrival traffic originated from MTC device via effective rate
transmission. We consider that the arrival traffic is modeled as a Markovian
process namely Discrete-Time Markov process, Fluid Markov process, and Markov
Modulated Poisson process, under delay violation constraints. Using effective
bandwidth and effective capacity theories, we evaluate the trade-off between
reliability-latency and identify QoS (Quality of Service) requirement, and
derive lower and upper bounds for the effective capacity subject to channel
memory decay rate limits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11139</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11139</id><created>2019-06-26</created><authors><author><keyname>Lee</keyname><forenames>Kyungyun</forenames></author><author><keyname>Nam</keyname><forenames>Juhan</forenames></author></authors><title>Learning a Joint Embedding Space of Monophonic and Mixed Music Signals
  for Singing Voice</title><categories>cs.SD eess.AS</categories><comments>ISMIR 2019, Delft, Netherlands</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Previous approaches in singer identification have used one of monophonic
vocal tracks or mixed tracks containing multiple instruments, leaving a
semantic gap between these two domains of audio. In this paper, we present a
system to learn a joint embedding space of monophonic and mixed tracks for
singing voice. We use a metric learning method, which ensures that tracks from
both domains of the same singer are mapped closer to each other than those of
different singers. We train the system on a large synthetic dataset generated
by music mashup to reflect real-world music recordings. Our approach opens up
new possibilities for cross-domain tasks, e.g., given a monophonic track of a
singer as a query, retrieving mixed tracks sung by the same singer from the
database. Also, it requires no additional vocal enhancement steps such as
source separation. We show the effectiveness of our system for singer
identification and query-by-singer in both the same-domain and cross-domain
tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11153</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11153</id><created>2019-06-26</created><authors><author><keyname>Wei</keyname><forenames>Xiaoqian</forenames></author><author><keyname>Yang</keyname><forenames>Jianying</forenames></author><author><keyname>Fan</keyname><forenames>Xiangru</forenames></author></authors><title>Distributed Optimal Guidance Laws for Multiple Unmanned Aerial Vehicles
  Attacking A Moving Target</title><categories>eess.SY cs.SY</categories><comments>arXiv admin note: substantial text overlap with arXiv:1906.10790</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, two cooperative guidance laws based on two-point boundary
value are designed to deal with the problem of cooperative encirclement and
simultaneous attack under condition of both known target acceleration and
unknown target acceleration. The only requirement for the multi-attacker
communication network is that it contains a directed spanning tree. The
guidance laws can function properly as long as at least one attacker can
observed the target. The acceleration components along the attacker-target line
of sight in the novel guidance laws can reduce the relative remaining distance
between each of the attackers and the target at the same speed, thus completing
simultaneous attack and avoiding the calculation of the remaining time. The
components of the guidance laws perpendicular to the attacker-target line of
sight can make the normal overload of relative motion zero, so that the
trajectory will be smooth and the collision problem within the attacker can be
avoided. Simulation results verified the practicability of the novel guidance
laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11154</identifier>
 <datestamp>2019-06-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11154</id><created>2019-06-26</created><authors><author><keyname>Dervi&#x161;kadi&#x107;</keyname><forenames>Asja</forenames></author><author><keyname>Frigo</keyname><forenames>Guglielmo</forenames></author><author><keyname>Paolone</keyname><forenames>Mario</forenames></author></authors><title>Beyond Phasors: Continuous-Spectrum Modeling of Power Systems using the
  Hilbert Transform</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern power systems are at risk of largely reducing the inertia of
generation assets and prone to experience extreme dynamics. The consequence is
that, during electromechanical transients triggered by large contingencies,
transmission of electrical power may take place in a broad spectrum well beyond
the single fundamental component. Traditional modeling approaches rely on the
phasor representation derived from the Fourier Transform (FT) of the signal
under analysis. During large transients, though, FT-based analysis may fail to
accurately identify the fundamental component parameters, in terms of
amplitude, frequency and phase. In this paper, we propose an alternative
approach relying on the Hilbert Transform (HT), that, in view of the
possibility to identify the whole spectrum, enables the tracking of signal
dynamics. We compare FT- and HT-based approaches during representative
operating conditions, i.e., amplitude modulations, frequency ramps and step
changes, in synthetic and real-world datasets. We further validate the
approaches using a contingency analysis on the IEEE 39-bus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11318</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11318</id><created>2019-06-26</created><authors><author><keyname>Mosleh</keyname><forenames>Susanna</forenames></author><author><keyname>Liu</keyname><forenames>Lingjia</forenames></author><author><keyname>Ashdown</keyname><forenames>Jonathan D.</forenames></author><author><keyname>Perrins</keyname><forenames>Erik</forenames></author><author><keyname>Turck</keyname><forenames>Kurt</forenames></author></authors><title>Content-Based User Association and MIMO Operation over Cached Cloud-RAN
  Networks</title><categories>eess.SP cs.SY eess.SY</categories><comments>12 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud radio access network (Cloud-RAN) has been introduced to support
ever-growing end-users' needs. To reduce the backhaul traffic and aid
coordinated multi-point (CoMP) transmission, base station (BS)-level caching
technique can be utilized, where popular contents are pre-fetched at each BS.
In this paper, multiple-input-multiple-output (MIMO) operation and user
association policy are linked to the underlying cache placement strategy to
ensure a good trade-off between load balancing and backhaul traffic taking into
account the underlying wireless channel and the finite cache capacity at BSs.
Due to the coupled interference among mobile stations, the binary nature of the
underlying cache placement and user association matrices, the resulting
mixed-timescale mixed integer optimization problem is nonconvex and NP-hard. To
solve this problem, we decompose the joint optimization problem into a
long-term content placement sub-problem and a short-term content delivery
sub-problem. A novel iterative algorithm is introduced by leveraging the
alternating direction method of multipliers together with a stochastic parallel
successive convex approximation-based algorithm. The introduced scheme enables
all BSs to update their optimization variables in parallel by solving a
sequence of convex subproblems. Simulation evaluation demonstrates the
efficiency of our strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11330</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11330</id><created>2019-06-26</created><authors><author><keyname>Prateek</keyname><forenames>G. V.</forenames></author><author><keyname>Ju</keyname><forenames>Yo-El</forenames></author><author><keyname>Nehorai</keyname><forenames>Arye</forenames></author></authors><title>Sparsity-Assisted Signal Denoising and Pattern Recognition in
  Time-Series Data</title><categories>eess.SP</categories><comments>22 pages, 16 figures, submitted to IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of signal denoising and pattern recognition in
processing batch-mode time-series data by combining linear time-invariant
filters, orthogonal multiresolution representations, and sparsity-based
methods. We propose a novel approach to designing higher-order zero-phase
low-pass, high-pass, and band-pass infinite impulse response filters as
matrices, using spectral transformation of the state-space representation of
digital filters. We also propose a proximal gradient-based technique to
factorize a special class of zero-phase high-pass and band-pass digital filters
so that the factorization product preserves the zero-phase property of the
filter and also incorporates a sparse-derivative component of the input in the
signal model. To demonstrate applications of our novel filter designs, we
validate and propose new signal models to simultaneously denoise and identify
patterns of interest. We begin by using our proposed filter design to test an
existing signal model that simultaneously combines linear time invariant (LTI)
filters and sparsity-based methods. We develop a new signal model called
sparsity-assisted signal denoising (SASD) by combining our proposed filter
designs with the existing signal model. Thereafter, we propose and derive a new
signal model called sparsity-assisted pattern recognition (SAPR). In SAPR, we
combine LTI band-pass filters and sparsity-based methods with orthogonal
multiresolution representations, such as wavelets, to detect specific patterns
in the input signal. Finally, we combine the signal denoising and pattern
recognition tasks, and derive a new signal model called the sparsity-assisted
signal denoising and pattern recognition (SASDPR). We illustrate the
capabilities of the SAPR and SASDPR frameworks using
sleep-electroencephalography data to detect K-complexes and sleep spindles,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11331</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11331</id><created>2019-06-26</created><authors><author><keyname>Huang</keyname><forenames>Linbin</forenames></author><author><keyname>Xin</keyname><forenames>Huanhai</forenames></author><author><keyname>D&#xf6;rfler</keyname><forenames>Florian</forenames></author></authors><title>$H_{\infty}$-Control of Grid-Connected Converters: Design, Objectives
  and Decentralized Stability Certificates</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modern power system features the high penetration of power converters due
to the development of renewables, HVDC, etc. Currently, the controller design
and parameter tuning of power converters heavily rely on rich engineering
experience and extrapolation from a single converter system, which may lead to
inferior performance or even instabilities under variable grid conditions. In
this paper, we propose an $H_{\infty}$-control design framework to provide a
systematic way for the robust and optimal control design of power converters.
We discuss how to choose weighting functions to achieve anticipated and robust
performance with regards to multiple control objectives. Further, we show that
the operating mode of the converter (grid-forming or grid-following) can be
conveniently specified by proper choice of weighting functions. Furthermore,
based on the small gain theorem, we propose a decentralized stability criterion
which enables to guarantee the small-signal stability of multi-converter
systems through local $H_{\infty}$-control design of the converters. We provide
high-fidelity nonlinear simulations to illustrate the effectiveness of our
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11335</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11335</id><created>2019-06-14</created><authors><author><keyname>Dimiccoli</keyname><forenames>Mariella</forenames></author><author><keyname>Wendt</keyname><forenames>Herwig</forenames></author></authors><title>Enhancing temporal segmentation by nonlocal self-similarity</title><categories>eess.IV cs.CV</categories><comments>Accepted to ICIP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Temporal segmentation of untrimmed videos and photo-streams is currently an
active area of research in computer vision and image processing. This paper
proposes a new approach to improve the temporal segmentation of photo-streams.
The method consists in enhancing image representations by encoding long-range
temporal dependencies. Our key contribution is to take advantage of the
temporal stationarity assumption of photostreams for modeling each frame by its
nonlocal self-similarity function. The proposed approach is put to test on the
EDUB-Seg dataset, a standard benchmark for egocentric photostream temporal
segmentation. Starting from seven different (CNN based) image features, the
method yields consistent improvements in event segmentation quality, leading to
an average increase of F-measure of 3.71% with respect to the state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11355</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11355</id><created>2019-06-26</created><updated>2019-11-09</updated><authors><author><keyname>Stimper</keyname><forenames>Vincent</forenames></author><author><keyname>Bauer</keyname><forenames>Stefan</forenames></author><author><keyname>Ernstorfer</keyname><forenames>Ralph</forenames></author><author><keyname>Sch&#xf6;lkopf</keyname><forenames>Bernhard</forenames></author><author><keyname>Xian</keyname><forenames>R. Patrick</forenames></author></authors><title>Multidimensional Contrast Limited Adaptive Histogram Equalization</title><categories>eess.IV eess.SP physics.data-an q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contrast enhancement is an important preprocessing technique for improving
the performance of downstream tasks in image processing and computer vision.
Among the existing approaches based on nonlinear histogram transformations,
contrast limited adaptive histogram equalization (CLAHE) is a popular choice
for dealing with 2D images obtained in natural and scientific settings. The
recent hardware upgrade in data acquisition systems results in significant
increase in data complexity, including their sizes and dimensions. Measurements
of densely sampled data higher than three dimensions, usually composed of 3D
data as a function of external parameters, are becoming commonplace in various
applications in the natural sciences and engineering. The initial understanding
of these complex multidimensional datasets often requires human intervention
through visual examination, which may be hampered by the varying levels of
contrast permeating through the dimensions. We show both qualitatively and
quantitatively that using our multidimensional extension of CLAHE (MCLAHE)
simultaneously on all dimensions of the datasets allows better visualization
and discernment of multidimensional image features, as demonstrated using cases
from 4D photoemission spectroscopy and fluorescence microscopy. Our
implementation of multidimensional CLAHE in Tensorflow is publicly accessible
and supports parallelization with multiple CPUs and various other hardware
accelerators, including GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11359</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11359</id><created>2019-06-26</created><authors><author><keyname>Chen</keyname><forenames>Siheng</forenames></author><author><keyname>Niu</keyname><forenames>Sufeng.</forenames></author><author><keyname>Lan</keyname><forenames>Tian</forenames></author><author><keyname>Liu</keyname><forenames>Baoan</forenames></author></authors><title>Large-scale 3D point cloud representations via graph inception networks
  with applications to autonomous driving</title><categories>eess.SP cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel graph-neural-network-based system to effectively represent
large-scale 3D point clouds with the applications to autonomous driving. Many
previous works studied the representations of 3D point clouds based on two
approaches, voxelization, which causes discretization errors and learning,
which is hard to capture huge variations in large-scale scenarios. In this
work, we combine voxelization and learning: we discretize the 3D space into
voxels and propose novel graph inception networks to represent 3D points in
each voxel. This combination makes the system avoid discretization errors and
work for large-scale scenarios. The entire system for large-scale 3D point
clouds acts like the blocked discrete cosine transform for 2D images; we thus
call it the point cloud neural transform (PCT). We further apply the proposed
PCT to represent real-time LiDAR sweeps produced by self-driving cars and the
PCT with graph inception networks significantly outperforms its competitors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11369</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11369</id><created>2019-06-26</created><authors><author><keyname>Chakrabarty</keyname><forenames>Ankush</forenames></author><author><keyname>Quirynen</keyname><forenames>Rien</forenames></author><author><keyname>Danielson</keyname><forenames>Claus</forenames></author><author><keyname>Gao</keyname><forenames>Weinan</forenames></author></authors><title>Approximate Dynamic Programming For Linear Systems with State and Input
  Constraints</title><categories>eess.SY cs.LG cs.SY math.DS math.OC</categories><comments>Short version appeared in European Control Conference, 2019, Naples,
  Italy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enforcing state and input constraints during reinforcement learning (RL) in
continuous state spaces is an open but crucial problem which remains a
roadblock to using RL in safety-critical applications. This paper leverages
invariant sets to update control policies within an approximate dynamic
programming (ADP) framework that guarantees constraint satisfaction for all
time and converges to the optimal policy (in a linear quadratic regulator
sense) asymptotically. An algorithm for implementing the proposed constrained
ADP approach in a data-driven manner is provided. The potential of this
formalism is demonstrated via numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11372</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11372</id><created>2019-06-26</created><authors><author><keyname>Barreto</keyname><forenames>Carlos</forenames></author><author><keyname>Mojica-Nava</keyname><forenames>Eduardo</forenames></author><author><keyname>Quijano</keyname><forenames>Nicanor</forenames></author></authors><title>Incentive Mechanisms to Prevent Efficiency Loss of Non-Profit Utilities</title><categories>cs.GT cs.SY eess.SY</categories><comments>17 pages, 3 figures, accepted in the International Journal of
  Electrical Power and Energy Systems</comments><journal-ref>International Journal of Electrical Power &amp; Energy Systems, Volume
  110, 2019, Pages 523-535, ISSN 0142-0615</journal-ref><doi>10.1016/j.ijepes.2019.03.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modernization of the power system introduces technologies that may
improve the system's efficiency by enhancing the capabilities of users. Despite
their potential benefits, such technologies can have a negative impact. This
subject has widely analyzed, mostly considering for-profit electric utilities.
However, the literature has a gap regarding the impact of new technologies on
non-profit utilities.
  In this work, we quantify the price of anarchy of non-profit utilities, that
is, the cost caused by lack of coordination of users. We find that users, in
the worst case, can consume up to twice the optimal demand, obtaining a small
fraction of the optimal surplus. For this reason, we leverage the theory of
mechanism design to design an incentive scheme that reduces the inefficiencies
of the system, which preserves the privacy of users. We illustrate with
simulations the efficiency loss of the system and show two instances of
incentive mechanism that satisfy either budget balance and budget deficit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11402</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11402</id><created>2019-06-26</created><authors><author><keyname>Feng</keyname><forenames>Jie</forenames></author><author><keyname>Wu</keyname><forenames>Yongpeng</forenames></author><author><keyname>Zhai</keyname><forenames>Guangtao</forenames></author><author><keyname>Liu</keyname><forenames>Ning</forenames></author><author><keyname>Zhang</keyname><forenames>Wenjun</forenames></author></authors><title>An Algorithm for Transmitting VR Video Based on Adaptive Modulation</title><categories>cs.NI cs.IT eess.SP math.IT</categories><comments>This paper contains 6 pages with 6 figures and has been accepted by
  2019 IEEE/CIC International Conference on Communications in China (ICCC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtual reality (VR) is making waves around the world recently. However,
traditional video streaming is not suitable for VR video because of the huge
size and view switch requirements of VR videos. Since the view of each user is
limited, it is unnecessary to send the whole 360-degree scene at high quality
which can be a heavy burden for the transmission system. Assuming filed-of-view
(FoV) of each user can be predicted with high probability, we can divide the
video screen into partitions and send those partitions which will appear in FoV
at high quality. Hence, we propose an novel strategy for VR video streaming.
First, we define a quality-of-experience metric to measure the viewing
experience of users and define a channel model to reflect the fluctuation of
the wireless channel. Next, we formulate the optimization problem and find its
feasible solution by convex optimization. In order to improve bandwidth
efficiency, we also add adaptive modulation to this part. Finally, we compare
our algorithm with other VR streaming algorithm in the simulation. It turns out
that our algorithm outperforms other algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11408</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11408</id><created>2019-06-26</created><authors><author><keyname>Sunaina</keyname></author><author><keyname>Butola</keyname><forenames>Mansi</forenames></author><author><keyname>Khare</keyname><forenames>Kedar</forenames></author></authors><title>Mean Gradient Descent: An optimization approach for single-shot
  interferogram analysis</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex object wave recovery from single-shot interference pattern is an
important practical problem in interferometry and digital holography. The most
popular single-shot interferogram analysis method involves Fourier filtering of
cross-term but this method suffers from poor resolution. For obtaining full
pixel resolution, it is necessary to model the object wave recovery as an
optimization problem. The optimization approach typically involves minimizing a
cost function consisting of a data consistency term and one or more constraint
terms. Despite its potential performance advantages, this method is not used
widely due to several tedious and difficult tasks such as empirical tuning of
free parameters. We introduce a new optimization approach Mean gradient descent
(MGD) for single-shot interferogram analysis that is simple to implement,
robust and does not require any free parameters. The MGD iteration does not try
to achieve minimization of any cost function but instead aims to reach a
solution point where the data consistency and the constraint terms balance each
other. This is achieved by iteratively progressing the solution in the
direction that bisects the descent directions associated with the error and
constraint terms. Numerical illustrations are shown for recovery of a step
phase object from its corresponding off-axis as well as on-axis interferograms
simulated with multiple noise levels. Our results show full pixel resolution as
evident from the recovery of phase step and excellent rms phase accuracy
relative to the ground truth phase map. The concept of MGD as presented here
can potentially find applications to wider class of optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11410</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11410</id><created>2019-06-26</created><authors><author><keyname>Tamir</keyname><forenames>Jonathan I.</forenames></author><author><keyname>Ong</keyname><forenames>Frank</forenames></author><author><keyname>Anand</keyname><forenames>Suma</forenames></author><author><keyname>Karasan</keyname><forenames>Ekin</forenames></author><author><keyname>Wang</keyname><forenames>Ke</forenames></author><author><keyname>Lustig</keyname><forenames>Michael</forenames></author></authors><title>Computational MRI with Physics-based Constraints: Application to
  Multi-contrast and Quantitative Imaging</title><categories>eess.IV eess.SP</categories><doi>10.1109/MSP.2019.2940062</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing takes advantage of low-dimensional signal structure to
reduce sampling requirements far below the Nyquist rate. In magnetic resonance
imaging (MRI), this often takes the form of sparsity through wavelet transform,
finite differences, and low rank extensions. Though powerful, these image
priors are phenomenological in nature and do not account for the mechanism
behind the image formation. On the other hand, MRI signal dynamics are governed
by physical laws, which can be explicitly modeled and used as priors for
reconstruction. {1}These explicit and implicit signal priors can be
synergistically combined in an inverse problem framework to recover sharp,
multi-contrast images from highly accelerated scans. Furthermore, the
physics-based constraints provide a recipe for recovering quantitative,
bio-physical parameters from the data. This article introduces physics-based
modeling constraints in MRI and shows how they can be used in conjunction with
compressed sensing for image reconstruction and quantitative imaging. We
describe model-based quantitative MRI, as well as its linear subspace
approximation. We also discuss approaches to selecting user-controllable scan
parameters given knowledge of the physical model. We present several MRI
applications that take advantage of this framework for the purpose of
multi-contrast imaging and quantitative mapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11466</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11466</id><created>2019-06-27</created><authors><author><keyname>Ye</keyname><forenames>Jia</forenames></author><author><keyname>Guo</keyname><forenames>Shuaishuai</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Joint Reflecting and Precoding Designs for SER Minimization in
  Reconfigurable Intelligent Surfaces Assisted MIMO Systems</title><categories>eess.SP</categories><comments>14 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the use of a reconfigurable intelligent surface (RIS)
to aid point-to-point multiple-input multiple-output (MIMO) wireless
communications. We present efficient designs for both the reflecting elements
at the RIS and the precoder at the transmitter, which target at minimizing the
symbol error rate (SER) of the transmission. Specifically, we iteratively
design the reflecting and precoding to directly minimize symbol error rate
(MSER), referred as MSER-Reflecting and MSER-Precoding, which are shown to
achieve favorable results but at the cost of high computational complexity.
Therefore, a simplified semidefinite programming-based (SDP-) reflecting scheme
and a simplified maximizing the minimum Euclidean distance (MMED-) precoding
design are studied to reduce computational complexity. Furthermore, direct
solutions for precoder design, e.g., maximum ratio transmission (MRT-)
precoding and Eigen-Precoding are investigated in terms of SER for comparison.
Simulation results show that the RIS-assisted MIMO communications combined with
the proposed reflectors and precoders can offer a lower SER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11467</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11467</id><created>2019-06-27</created><authors><author><keyname>Shin</keyname><forenames>Younghak</forenames></author><author><keyname>Qadir</keyname><forenames>Hemin Ali</forenames></author><author><keyname>Balasingham</keyname><forenames>Ilangko</forenames></author></authors><title>Abnormal Colon Polyp Image Synthesis Using Conditional Adversarial
  Networks for Improved Detection Performance</title><categories>eess.IV cs.CV</categories><comments>10 pages</comments><journal-ref>IEEE Access 6 (2018): 56007-56017</journal-ref><doi>10.1109/ACCESS.2018.2872717</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major obstacles in automatic polyp detection during colonoscopy is
the lack of labeled polyp training images. In this paper, we propose a
framework of conditional adversarial networks to increase the number of
training samples by generating synthetic polyp images. Using a normal binary
form of polyp mask which represents only the polyp position as an input
conditioned image, realistic polyp image generation is a difficult task in a
generative adversarial networks approach. We propose an edge filtering-based
combined input conditioned image to train our proposed networks. This enables
realistic polyp image generations while maintaining the original structures of
the colonoscopy image frames. More importantly, our proposed framework
generates synthetic polyp images from normal colonoscopy images which have the
advantage of being relatively easy to obtain. The network architecture is based
on the use of multiple dilated convolutions in each encoding part of our
generator network to consider large receptive fields and avoid many
contractions of a feature map size. An image resizing with convolution for
upsampling in the decoding layers is considered to prevent artifacts on
generated images. We show that the generated polyp images are not only
qualitatively realistic but also help to improve polyp detection performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11479</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11479</id><created>2019-06-27</created><authors><author><keyname>Chen</keyname><forenames>Hongruixuan</forenames></author><author><keyname>Wu</keyname><forenames>Chen</forenames></author><author><keyname>Du</keyname><forenames>Bo</forenames></author><author><keyname>Zhang</keyname><forenames>Liangpei</forenames></author></authors><title>Deep Siamese Multi-scale Convolutional Network for Change Detection in
  Multi-temporal VHR Images</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Very high resolution (VHR) images provide abundant ground details and spatial
distribution information. Change detection in multi-temporal VHR images plays a
significant role in urban expansion and area internal change analysis.
Nevertheless, traditional change detection methods can neither take full
advantage of spatial context information nor cope with the complex internal
heterogeneity of VHR images. In this paper, we propose a powerful multi-scale
feature convolution unit (MFCU) for change detection in VHR images. The
proposed unit is able to extract multi-scale features in the same layer. Based
on the proposed unit, two novel deep Siamese convolutional networks, deep
Siamese multi-scale convolutional network (DSMS-CN) and deep Siamese
multi-scale fully convolutional network (DSMS-FCN), are designed for
unsupervised and supervised change detection in multi-temporal VHR images. For
unsupervised change detection, we implement automatic pre-classification to
obtain training patch samples, and the DSMS-CN fits the statistical
distribution of changed and unchanged area from patch samples through
multi-scale feature extraction module and deep Siamese architecture. For
supervised change detection, the end-to-end deep fully convolutional network
DSMS-FCN is trained in any size of multi-temporal VHR images, and directly
output the binary change map. In addition, for the purpose of solving the
inaccurate localization problem, the fully connected conditional random field
(FC-CRF) is combined with DSMS-FCN to refine the results. The experimental
results with challenging data sets confirm that the two proposed architectures
perform better than the state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11484</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11484</id><created>2019-06-27</created><authors><author><keyname>Sakamoto</keyname><forenames>Mitsuki</forenames></author><author><keyname>Hiasa</keyname><forenames>Yuta</forenames></author><author><keyname>Otake</keyname><forenames>Yoshito</forenames></author><author><keyname>Takao</keyname><forenames>Masaki</forenames></author><author><keyname>Suzuki</keyname><forenames>Yuki</forenames></author><author><keyname>Sugano</keyname><forenames>Nobuhiko</forenames></author><author><keyname>Sato</keyname><forenames>Yoshinobu</forenames></author></authors><title>Automated Segmentation of Hip and Thigh Muscles in Metal
  Artifact-Contaminated CT using Convolutional Neural Network-Enhanced
  Normalized Metal Artifact Reduction</title><categories>eess.IV cs.CV physics.med-ph</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In total hip arthroplasty, analysis of postoperative medical images is
important to evaluate surgical outcome. Since Computed Tomography (CT) is most
prevalent modality in orthopedic surgery, we aimed at the analysis of CT image.
In this work, we focus on the metal artifact in postoperative CT caused by the
metallic implant, which reduces the accuracy of segmentation especially in the
vicinity of the implant. Our goal was to develop an automated segmentation
method of the bones and muscles in the postoperative CT images. We propose a
method that combines Normalized Metal Artifact Reduction (NMAR), which is one
of the state-of-the-art metal artifact reduction methods, and a Convolutional
Neural Network-based segmentation using two U-net architectures. The first
U-net refines the result of NMAR and the muscle segmentation is performed by
the second U-net. We conducted experiments using simulated images of 20
patients and real images of three patients to evaluate the segmentation
accuracy of 19 muscles. In simulation study, the proposed method showed
statistically significant improvement (p&lt;0.05) in the average symmetric surface
distance (ASD) metric for 14 muscles out of 19 muscles and the average ASD of
all muscles from 1.17 +/- 0.543 mm (mean +/- std over all patients) to 1.10 +/-
0.509 mm over our previous method. The real image study using the manual trace
of gluteus maximus and medius muscles showed ASD of 1.32 +/- 0.25 mm. Our
future work includes training of a network in an end-to-end manner for both the
metal artifact reduction and muscle segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11509</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11509</id><created>2019-06-27</created><authors><author><keyname>Leamy</keyname><forenames>Paul</forenames></author><author><keyname>Burke</keyname><forenames>Ted</forenames></author><author><keyname>Berry</keyname><forenames>Damon</forenames></author><author><keyname>Dorran</keyname><forenames>David</forenames></author></authors><title>Re-annotation of cough events in the AMI corpus</title><categories>eess.AS eess.SP</categories><comments>Data presented in this work is available to download using the link
  included in the references</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Cough sounds act as an important indicator of an individual's physical
health, often used by medical professionals in diagnosing a patient's ailments.
In recent years progress has been made in the area of automatically detecting
cough events and, in certain cases, automatically identifying the ailment
associated with a particular cough sound. Ethical and sensitivity issues
associated with audio recordings of coughs makes it more difficult for this
data to be made publicly available. However, without the public availability of
a reliable database of cough sounds, developments in the area of audio event
detection are likely to be hampered. The purpose of this paper is to spread
awareness of a database containing a large amount of naturally occurring cough
sounds that can be used for the implementation, evaluation, and comparison of
new machine learning algorithms that allow for audio event detection associated
with cough sounds. Using a purpose built GUI designed in MATLAB, the
re-annotation procedure followed a reusable methodology that allowed for quick
and efficient importing and marking of audio signals, resulting in a
re-annotated version of the Augmented Multi-party Interaction (AMI) corpus'
cough location annotations, with 1369 individual cough events. All cough
annotations and the re-annotation tool are made available for download and
public use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11521</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11521</id><created>2019-06-27</created><authors><author><keyname>Klejch</keyname><forenames>Ondrej</forenames></author><author><keyname>Fainberg</keyname><forenames>Joachim</forenames></author><author><keyname>Bell</keyname><forenames>Peter</forenames></author><author><keyname>Renals</keyname><forenames>Steve</forenames></author></authors><title>Lattice-Based Unsupervised Test-Time Adaptation of Neural Network
  Acoustic Models</title><categories>cs.CL cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic model adaptation to unseen test recordings aims to reduce the
mismatch between training and testing conditions. Most adaptation schemes for
neural network models require the use of an initial one-best transcription for
the test data, generated by an unadapted model, in order to estimate the
adaptation transform. It has been found that adaptation methods using
discriminative objective functions - such as cross-entropy loss - often require
careful regularisation to avoid over-fitting to errors in the one-best
transcriptions. In this paper we solve this problem by performing
discriminative adaptation using lattices obtained from a first pass decoding,
an approach that can be readily integrated into the lattice-free maximum mutual
information (LF-MMI) framework. We investigate this approach on three
transcription tasks of varying difficulty: TED talks, multi-genre broadcast
(MGB) and a low-resource language (Somali). We find that our proposed approach
enables many more parameters to be adapted without over-fitting being observed,
and is successful even when the initial transcription has a WER in excess of
50%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11559</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11559</id><created>2019-06-27</created><authors><author><keyname>Kishk</keyname><forenames>Mustafa A.</forenames></author><author><keyname>Bader</keyname><forenames>Ahmed</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Capacity and Coverage Enhancement Using Long-Endurance Tethered Airborne
  Base Stations</title><categories>cs.NI cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Airborne base stations (carried by drones) have a great potential to enhance
coverage and capacity of cellular networks. Multiple scenarios and use cases
will highly benefit from such technology such as (i) offloading terrestrial
base stations (BSs) in dense and urban areas, and (ii) providing coverage for
rural areas. However, one of the main challenges facing the deployment of
airborne BSs is the limited available energy at the drone, which limits the
flight time. In fact, most of the currently used unmanned aerial vehicles
(UAVs) can only operate for one hour maximum. This limits the performance of
the UAV-enabled cellular network due to the need to frequently visit the ground
station to recharge, leaving the UAV's coverage area temporarily out of
service. In this article, we propose a new UAV-enabled cellular network setup
based on tethered UAVs (TUAVs). In the proposed setup, the TUAV is connected to
a ground station (GS) through a tether, which provides the TUAV with both
energy and data. This enables a flight that can stay for days. We describe in
detail the components of the proposed system. Furthermore, we enlist the main
advantages of a TUAV-enabled cellular network compared to typical untethered
UAVs. Next, we discuss the potential applications and use cases for TUAVs.
Finally, we discuss the challenges, design considerations, and future research
directions to realize the proposed setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11571</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11571</id><created>2019-06-27</created><authors><author><keyname>Balandra</keyname><forenames>Alfonso</forenames></author><author><keyname>Hasegawa</keyname><forenames>Shoichi</forenames></author></authors><title>Sensitivity to Haptic-Audio Envelope Asynchrony</title><categories>cs.HC cs.SD eess.AS</categories><comments>Work in progress paper for World Haptics 2019</comments><journal-ref>World Haptics 2019 (Work in Progress)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We want to understand the human capabilities to perceive amplitude
similarities between a haptic and an audio signal. So, four psychophysical
experiments were performed. Three of them measured the asynchrony JND (Just
Noticeable Difference) at the signals' attack, release and decay, while the
forth experiment measured the amplitude decrease on the middle of the signal.
All the experiments used a combination of the constant stimulus and staircase
methods to present two stimuli, while the participants' (N=12) task was to
identify which of the two stimuli was synchronized. The audiotactile stimulus
was defined using an stereo audio signal with an ADSR (Attack Decay Sustain
Release) envelope. The partial results reveal JNDs for temporal asynchrony of:
54ms for attack, 265ms for decay and 57ms for release. Also the results reveal
an amplitude decrease JND of 25\%. Although for decay the results were to
disperse, therefore we suspect that the participants were not able to the
changes on the haptic signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11577</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11577</id><created>2019-06-27</created><authors><author><keyname>Ratha</keyname><forenames>Debanshu</forenames></author><author><keyname>Pottier</keyname><forenames>Eric</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Avik</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author></authors><title>A PolSAR Scattering Power Factorization Framework and Novel
  Roll-Invariant Parameters Based Unsupervised Classification Scheme Using a
  Geodesic Distance</title><categories>eess.SP cs.CV</categories><comments>Submitted to IEEE Transactions on Geoscience and Remote Sensing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a generic Scattering Power Factorization Framework (SPFF) for
Polarimetric Synthetic Aperture Radar (PolSAR) data to directly obtain $N$
scattering power components along with a residue power component for each
pixel. Each scattering power component is factorized into similarity (or
dissimilarity) using elementary targets and a generalized random volume model.
The similarity measure is derived using a geodesic distance between pairs of
$4\times4$ real Kennaugh matrices. In standard model-based decomposition
schemes, the $3\times3$ Hermitian positive semi-definite covariance (or
coherency) matrix is expressed as a weighted linear combination of scattering
targets following a fixed hierarchical process. In contrast, under the proposed
framework, a convex splitting of unity is performed to obtain the weights while
preserving the dominance of the scattering components. The product of the total
power (Span) with these weights provides the non-negative scattering power
components. Furthermore, the framework along the geodesic distance is
effectively used to obtain specific roll-invariant parameters which are then
utilized to design an unsupervised classification scheme. The SPFF, the roll
invariant parameters, and the classification results are assessed using C-band
RADARSAT-2 and L-band ALOS-2 images of San Francisco.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11600</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11600</id><created>2019-06-27</created><authors><author><keyname>Decenci&#xe8;re</keyname><forenames>Etienne</forenames></author><author><keyname>Velasco-Forero</keyname><forenames>Santiago</forenames></author><author><keyname>Min</keyname><forenames>Fu</forenames></author><author><keyname>Chen</keyname><forenames>Juanjuan</forenames></author><author><keyname>Burdin</keyname><forenames>H&#xe9;l&#xe8;ne</forenames></author><author><keyname>Gauthier</keyname><forenames>Gervais</forenames></author><author><keyname>La&#xff;</keyname><forenames>Bruno</forenames></author><author><keyname>Bornschloegl</keyname><forenames>Thomas</forenames></author><author><keyname>Baldeweck</keyname><forenames>Th&#xe9;r&#xe8;se</forenames></author></authors><title>Dealing with Topological Information within a Fully Convolutional Neural
  Network</title><categories>cs.CV eess.IV</categories><comments>International Conference on Advanced Concepts for Intelligent Vision
  Systems (ACIVS 2018)</comments><journal-ref>Advanced Concepts for Intelligent Vision Systems. ACIVS 2018.
  Lecture Notes in Computer Science, vol 11182. Springer, Cham</journal-ref><doi>10.1007/978-3-030-01449-0_39</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fully convolutional neural network has a receptive field of limited size
and therefore cannot exploit global information, such as topological
information. A solution is proposed in this paper to solve this problem, based
on pre-processing with a geodesic operator. It is applied to the segmentation
of histological images of pigmented reconstructed epidermis acquired via Whole
Slide Imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11604</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11604</id><created>2019-06-27</created><authors><author><keyname>Kim</keyname><forenames>Suyoun</forenames></author><author><keyname>Dalmia</keyname><forenames>Siddharth</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author></authors><title>Gated Embeddings in End-to-End Speech Recognition for
  Conversational-Context Fusion</title><categories>cs.CL cs.SD eess.AS</categories><comments>ACL 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel conversational-context aware end-to-end speech recognizer
based on a gated neural network that incorporates
conversational-context/word/speech embeddings. Unlike conventional speech
recognition models, our model learns longer conversational-context information
that spans across sentences and is consequently better at recognizing long
conversations. Specifically, we propose to use the text-based external word
and/or sentence embeddings (i.e., fastText, BERT) within an end-to-end
framework, yielding a significant improvement in word error rate with better
conversational-context representation. We evaluated the models on the
Switchboard conversational speech corpus and show that our model outperforms
standard end-to-end speech recognition models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11611</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11611</id><created>2019-06-27</created><authors><author><keyname>Aghdam</keyname><forenames>Sina Rezaei</forenames></author><author><keyname>Jacobsson</keyname><forenames>Sven</forenames></author><author><keyname>Eriksson</keyname><forenames>Thomas</forenames></author></authors><title>Distortion-Aware Linear Precoding for Millimeter-Wave Multiuser MISO
  Downlink</title><categories>eess.SP</categories><comments>Presented at IEEE ICC 2019 (Workshop on millimeter-wave
  communications for 5G and B5G)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose an iterative scheme for computing a linear precoder
that takes into account the impact of hardware impairments in the multiuser
multiple-input single-output downlink. We particularly focus on the case when
the transmitter is equipped with nonlinear power amplifiers. Using Bussgang's
theorem, we formulate a lower bound on the achievable sum rate in the presence
of hardware impairments, and maximize it using projected gradient ascent. We
provide numerical examples that demonstrate the efficacy of the proposed
distortion-aware scheme for precoding over a millimeter-wave~channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11615</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11615</id><created>2019-06-27</created><updated>2019-07-24</updated><authors><author><keyname>Rau</keyname><forenames>Richard</forenames></author><author><keyname>Unal</keyname><forenames>Ozan</forenames></author><author><keyname>Schweizer</keyname><forenames>Dieter</forenames></author><author><keyname>Vishnevskiy</keyname><forenames>Valery</forenames></author><author><keyname>Goksel</keyname><forenames>Orcun</forenames></author></authors><title>Attenuation Imaging with Pulse-Echo Ultrasound based on an Acoustic
  Reflector</title><categories>eess.SP eess.IV physics.bio-ph physics.med-ph</categories><comments>Accepted at MICCAI 2019 (International Conference on Medical Image
  Computing and Computer Assisted Intervention)</comments><journal-ref>Medical Image Computing and Computer Assisted Intervention -
  MICCAI 2019 pp 601-609</journal-ref><doi>10.1007/978-3-030-32254-0_67</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasound attenuation is caused by absorption and scattering in tissue and
is thus a function of tissue composition, hence its imaging offers great
potential for screening and differential diagnosis. In this paper we propose a
novel method that allows to reconstruct spatial attenuation distribution in
tissue based on computed tomography, using reflections from a passive acoustic
reflector. This requires a standard ultrasound transducer operating in
pulse-echo mode, thus it can be implemented on conventional ultrasound systems
with minor modifications. We use calibration with water measurements in order
to normalize measurements for quantitative imaging of attenuation. In contrast
to earlier techniques, we herein show that attenuation reconstructions are
possible without any geometric prior on the inclusion location or shape. We
present a quantitative evaluation of reconstructions based on simulations,
gelatin phantoms, and ex-vivo bovine skeletal muscle tissue, achieving
contrast-to-noise ratio of up to 2.3 for an inclusion in ex-vivo tissue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11620</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11620</id><created>2019-06-15</created><authors><author><keyname>Bian</keyname><forenames>Wenhao</forenames></author><author><keyname>Wang</keyname><forenames>Jie</forenames></author><author><keyname>Zhuang</keyname><forenames>Bojin</forenames></author><author><keyname>Yang</keyname><forenames>Jiankui</forenames></author><author><keyname>Wang</keyname><forenames>Shaojun</forenames></author><author><keyname>Xiao</keyname><forenames>Jing</forenames></author></authors><title>Audio-Based Music Classification with DenseNet And Data Augmentation</title><categories>eess.AS cs.MM cs.SD</categories><comments>accepted by The 16th Pacific Rim International Conference on AI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, deep learning technique has received intense attention owing
to its great success in image recognition. A tendency of adaption of deep
learning in various information processing fields has formed, including music
information retrieval (MIR). In this paper, we conduct a comprehensive study on
music audio classification with improved convolutional neural networks (CNNs).
To the best of our knowledge, this the first work to apply Densely Connected
Convolutional Networks (DenseNet) to music audio tagging, which has been
demonstrated to perform better than Residual neural network (ResNet).
Additionally, two specific data augmentation approaches of time overlapping and
pitch shifting have been proposed to address the deficiency of labelled data in
the MIR. Moreover, an ensemble learning of stacking is employed based on SVM.
We believe that the proposed combination of strong representation of DenseNet
and data augmentation can be adapted to other audio processing tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11645</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11645</id><created>2019-06-26</created><authors><author><keyname>Gabdrakhmanov</keyname><forenames>Lenar</forenames></author><author><keyname>Garaev</keyname><forenames>Rustem</forenames></author><author><keyname>Razinkov</keyname><forenames>Evgenii</forenames></author></authors><title>RUSLAN: Russian Spoken Language Corpus for Speech Synthesis</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Accepted to SPECOM'2019</comments><msc-class>I.2.7</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present RUSLAN -- a new open Russian spoken language corpus for the
text-to-speech task. RUSLAN contains 22200 audio samples with text annotations
-- more than 31 hours of high-quality speech of one person -- being the largest
annotated Russian corpus in terms of speech duration for a single speaker. We
trained an end-to-end neural network for the text-to-speech task on our corpus
and evaluated the quality of the synthesized speech using Mean Opinion Score
test. Synthesized speech achieves 4.05 score for naturalness and 3.78 score for
intelligibility on a 5-point MOS scale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11710</identifier>
 <datestamp>2019-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11710</id><created>2019-06-27</created><updated>2019-12-18</updated><authors><author><keyname>Dewhurst</keyname><forenames>David Rushing</forenames></author><author><keyname>Alshaabi</keyname><forenames>Thayer</forenames></author><author><keyname>Kiley</keyname><forenames>Dilan</forenames></author><author><keyname>Arnold</keyname><forenames>Michael V.</forenames></author><author><keyname>Minot</keyname><forenames>Joshua R.</forenames></author><author><keyname>Danforth</keyname><forenames>Christopher M.</forenames></author><author><keyname>Dodds</keyname><forenames>Peter Sheridan</forenames></author></authors><title>The shocklet transform: A decomposition method for the identification of
  local, mechanism-driven dynamics in sociotechnical time series</title><categories>physics.soc-ph cs.DS eess.SP physics.data-an</categories><comments>29 pages (20 body, 9 appendix), 20 figures (13 body, 7 appendix),
  three online appendices available at http://compstorylab.org/shocklets/ (two
  displaying interactive visualizations and one containing over 10,000
  figures), open-source implementation of STAR algorithm and discrete shocklet
  transform available at
  https://gitlab.com/compstorylab/discrete-shocklet-transform</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a qualitative, shape-based, timescale-independent time-domain
transform used to extract local dynamics from sociotechnical time
series---termed the Discrete Shocklet Transform (DST)---and an associated
similarity search routine, the Shocklet Transform And Ranking (STAR) algorithm,
that indicates time windows during which panels of time series display
qualitatively-similar anomalous behavior. After distinguishing our algorithms
from other methods used in anomaly detection and time series similarity search,
such as the matrix profile, seasonal-hybrid ESD, and discrete wavelet
transform-based procedures, we demonstrate the DST's ability to identify
mechanism-driven dynamics at a wide range of timescales and its relative
insensitivity to functional parameterization. As an application, we analyze a
sociotechnical data source (usage frequencies for a subset of words on Twitter)
and highlight our algorithms' utility by using them to extract both a typology
of mechanistic local dynamics and a data-driven narrative of socially-important
events as perceived by English-language Twitter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11759</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11759</id><created>2019-06-20</created><authors><author><keyname>Raposo</keyname><forenames>Francisco Afonso</forenames></author><author><keyname>de Matos</keyname><forenames>David Martins</forenames></author><author><keyname>Ribeiro</keyname><forenames>Ricardo</forenames></author></authors><title>Low-dimensional Embodied Semantics for Music and Language</title><categories>q-bio.NC cs.IR cs.LG cs.SD eess.AS stat.ML</categories><comments>6 pages, 1 figure, 1 table</comments><acm-class>I.2.6; H.5.5; H.5.1; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Embodied cognition states that semantics is encoded in the brain as firing
patterns of neural circuits, which are learned according to the statistical
structure of human multimodal experience. However, each human brain is
idiosyncratically biased, according to its subjective experience history,
making this biological semantic machinery noisy with respect to the overall
semantics inherent to media artifacts, such as music and language excerpts. We
propose to represent shared semantics using low-dimensional vector embeddings
by jointly modeling several brains from human subjects. We show these
unsupervised efficient representations outperform the original high-dimensional
fMRI voxel spaces in proxy music genre and language topic classification tasks.
We further show that joint modeling of several subjects increases the semantic
richness of the learned latent vector spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11783</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11783</id><created>2019-06-27</created><authors><author><keyname>Lee</keyname><forenames>Jongpil</forenames></author><author><keyname>Park</keyname><forenames>Jiyoung</forenames></author><author><keyname>Nam</keyname><forenames>Juhan</forenames></author></authors><title>Representation Learning of Music Using Artist, Album, and Track
  Information</title><categories>cs.IR cs.MM cs.SD eess.AS</categories><comments>International Conference on Machine Learning (ICML) 2019, Machine
  Learning for Music Discovery Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised music representation learning has been performed mainly using
semantic labels such as music genres. However, annotating music with semantic
labels requires time and cost. In this work, we investigate the use of factual
metadata such as artist, album, and track information, which are naturally
annotated to songs, for supervised music representation learning. The results
show that each of the metadata has individual concept characteristics, and
using them jointly improves overall performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11788</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11788</id><created>2019-06-27</created><authors><author><keyname>Mohamadi</keyname><forenames>Salman</forenames></author><author><keyname>Yeganegi</keyname><forenames>Farhang</forenames></author><author><keyname>Nasrabadi</keyname><forenames>Nasser M</forenames></author></authors><title>Detection and Statistical Modeling of Birth-Death Anomaly</title><categories>eess.SP</categories><comments>5 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Generally, anomaly detection has a great importance particularly in applied
statistical signal processing. Here we provide a general framework in order to
detect anomaly through the statistical modeling. In this paper, it is assumed
that a signal is corrupted by noise whose variance follows an ARMA model. The
assumption on the signal is further compromised to encompass the inherent
nonstationarity associated with natural phenomenon, hence, the signal of
interest is assumed to follow an ARIMA model and the noise to denote an
anomaly, however, unknown. Anomaly is assumed to possess heteroskedastic
properties, therefore, ARCH/GARCH modeling could extract the anomaly pattern
given an additive model for signal of interest and anomaly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11818</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11818</id><created>2019-06-27</created><authors><author><keyname>Kvinge</keyname><forenames>Henry</forenames></author><author><keyname>Farnell</keyname><forenames>Elin</forenames></author><author><keyname>Dupuis</keyname><forenames>Julia R.</forenames></author><author><keyname>Kirby</keyname><forenames>Michael</forenames></author><author><keyname>Peterson</keyname><forenames>Chris</forenames></author><author><keyname>Schundler</keyname><forenames>Elizabeth C.</forenames></author></authors><title>More chemical detection through less sampling: amplifying chemical
  signals in hyperspectral data cubes through compressive sensing</title><categories>eess.IV cs.CV eess.SP</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing (CS) is a method of sampling which permits some classes
of signals to be reconstructed with high accuracy even when they were
under-sampled. In this paper we explore a phenomenon in which bandwise CS
sampling of a hyperspectral data cube followed by reconstruction can actually
result in amplification of chemical signals contained in the cube. Perhaps most
surprisingly, chemical signal amplification generally seems to increase as the
level of sampling decreases. In some examples, the chemical signal is
significantly stronger in a data cube reconstructed from 10% CS sampling than
it is in the raw, 100% sampled data cube. We explore this phenomenon in two
real-world datasets including the Physical Sciences Inc. Fabry-P\'{e}rot
interferometer sensor multispectral dataset and the Johns Hopkins Applied
Physics Lab FTIR-based longwave infrared sensor hyperspectral dataset. Each of
these datasets contains the release of a chemical simulant, such as glacial
acetic acid, triethyl phospate, and sulfur hexafluoride, and in all cases we
use the adaptive coherence estimator (ACE) to detect a target signal in the
hyperspectral data cube. We end the paper by suggesting some theoretical
justifications for why chemical signals would be amplified in CS sampled and
reconstructed hyperspectral data cubes and discuss some practical implications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11827</identifier>
 <datestamp>2019-06-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11827</id><created>2019-06-21</created><authors><author><keyname>Lanza</keyname><forenames>Alessandro</forenames></author><author><keyname>Morigi</keyname><forenames>Serena</forenames></author><author><keyname>Pragliola</keyname><forenames>Monica</forenames></author><author><keyname>Sgallari</keyname><forenames>Fiorella</forenames></author></authors><title>Space-variant TV regularization for image restoration</title><categories>eess.IV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1906.10517</comments><journal-ref>Conference: European Congress on Computational Methods in Applied
  Sciences and Engineering, 2018</journal-ref><doi>10.1007/978-3-319-68195-5_17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose two new variational models aimed to outperform the popular total
variation (TV) model for image restoration with L$_2$ and L$_1$ fidelity terms.
In particular, we introduce a space-variant generalization of the TV
regularizer, referred to as TV$_p^{SV}$, where the so-called shape parameter
$p\,$ is automatically and locally estimated by applying a statistical
inference technique based on the generalized Gaussian distribution. The
restored image is efficiently computed by using an alternating direction method
of multipliers procedure. We validated our models on images corrupted by
Gaussian blur and two important types of noise, namely the additive white
Gaussian noise and the impulsive salt and pepper noise. Numerical examples show
that the proposed approach is particularly effective and well suited for images
characterized by a wide range of gradient distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11834</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11834</id><created>2019-06-27</created><authors><author><keyname>Liu</keyname><forenames>Shuanglong</forenames></author><author><keyname>Chu</keyname><forenames>Ringo S. W.</forenames></author><author><keyname>Wang</keyname><forenames>Xiwei</forenames></author><author><keyname>Luk</keyname><forenames>Wayne</forenames></author></authors><title>Optimizing CNN-based Hyperspectral Image Classification on FPGAs</title><categories>eess.IV cs.CV</categories><comments>This article is accepted for publication at ARC'2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral image (HSI) classification has been widely adopted in
applications involving remote sensing imagery analysis which require high
classification accuracy and real-time processing speed. Methods based on
Convolutional neural networks (CNNs) have been proven to achieve
state-of-the-art accuracy in classifying HSIs. However, CNN models are often
too computationally intensive to achieve real-time response due to the high
dimensional nature of HSI, compared to traditional methods such as Support
Vector Machines (SVMs). Besides, previous CNN models used in HSI are not
specially designed for efficient implementation on embedded devices such as
FPGAs. This paper proposes a novel CNN-based algorithm for HSI classification
which takes into account hardware efficiency. A customized architecture which
enables the proposed algorithm to be mapped effectively onto FPGA resources is
then proposed to support real-time on-board classification with low power
consumption. Implementation results show that our proposed accelerator on a
Xilinx Zynq 706 FPGA board achieves more than 70x faster than an Intel 8-core
Xeon CPU and 3x faster than an NVIDIA GeForce 1080 GPU. Compared to previous
SVM-based FPGA accelerators, we achieve comparable processing speed but provide
a much higher classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11871</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11871</id><created>2019-06-27</created><authors><author><keyname>Karak&#xfc;&#xe7;&#xfc;k</keyname><forenames>Ahmet</forenames></author><author><keyname>Dirik</keyname><forenames>Ahmet Emir</forenames></author></authors><title>PRNU Based Source Camera Attribution for Image Sets Anonymized with
  Patch-Match Algorithm</title><categories>eess.IV cs.MM eess.SP</categories><comments>Dataset avaiable on https://github.com/akarakucuk/2019_PM_SCI_DATA/</comments><doi>10.1016/j.diin.2019.06.001</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Patch-Match is an efficient algorithm used for structural image editing and
available as a tool on popular commercial photo-editing software. The tool
allows users to insert or remove objects from photos using information from
similar scene content. Recently, a modified version of this algorithm was
proposed as a counter-measure against Photo-Response Non-Uniformity (PRNU)
based Source Camera Identification (SCI). The algorithm can provide anonymity
at a great rate (97\%) and impede PRNU based SCI without the need of any other
information, hence leaving no-known recourse for the PRNU-based SCI. In this
paper, we propose a method to identify sources of the Patch-Match-applied
images by using randomized subsets of images and the traditional PRNU based SCI
methods. We evaluate the proposed method on two forensics scenarios in which an
adversary makes use of the Patch-Match algorithm and distorts the PRNU noise
pattern in the incriminating images he took with his camera. Our results show
that it is possible to link sets of Patch-Match-applied images back to their
source camera even in the presence of images that come from unknown cameras. To
our best knowledge, the proposed method represents the very first
counter-measure against the usage of of Patch-Match in the digital forensics
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11872</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11872</id><created>2019-06-12</created><authors><author><keyname>Shwartzman</keyname><forenames>Or</forenames></author><author><keyname>Gazit</keyname><forenames>Harel</forenames></author><author><keyname>Shelef</keyname><forenames>Ilan</forenames></author><author><keyname>Riklin-Raviv</keyname><forenames>Tammy</forenames></author></authors><title>The Impact of an Inter-rater Bias on Neural Network Training</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of inter-rater variability is often discussed in the context of
manual labeling of medical images. It is assumed to be bypassed by automatic
model-based approaches for image segmentation which are considered `objective',
providing single, deterministic solutions. However, the emergence of
data-driven approaches such as Deep Neural Networks (DNNs) and their
application to supervised semantic segmentation - brought this issue of raters'
disagreement back to the front-stage. In this paper, we highlight the issue of
inter-rater bias as opposed to random inter-observer variability and
demonstrate its influence on DNN training, leading to different segmentation
results for the same input images. In fact, lower Dice scores are calculated if
training and test segmentations are of different raters. Moreover, we
demonstrate that inter-rater bias in the training examples is amplified when
considering the segmentation predictions for the test data. We support our
findings by showing that a classifier-DNN trained to distinguish between raters
based on their manual annotations performs better when the automatic
segmentation predictions rather than the raters' annotations were tested.
  For this study, we used the ISBI 2015 Multiple Sclerosis (MS) challenge
dataset, which includes annotations by two raters with different levels of
expertise. The results obtained allow us to underline a worrisome clinical
implication of a DNN bias induced by an inter-rater bias during training.
Specially, we show that the differences in MS-lesion load estimates increase
when the volume calculations are done based on the DNNs' segmentation
predictions instead of the manual annotations used for training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11873</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11873</id><created>2019-06-12</created><authors><author><keyname>Radi</keyname><forenames>Hager</forenames></author><author><keyname>Ali</keyname><forenames>Waleed</forenames></author></authors><title>VolMap: A Real-time Model for Semantic Segmentation of a LiDAR
  surrounding view</title><categories>cs.CV cs.LG cs.RO eess.IV</categories><comments>Accepted at Thirty-sixth International Conference on Machine Learning
  (ICML 2019) Workshop on AI for Autonomous Driving</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper introduces VolMap, a real-time approach for the semantic
segmentation of a 3D LiDAR surrounding view system in autonomous vehicles. We
designed an optimized deep convolution neural network that can accurately
segment the point cloud produced by a 360\degree{} LiDAR setup, where the input
consists of a volumetric bird-eye view with LiDAR height layers used as input
channels. We further investigated the usage of multi-LiDAR setup and its effect
on the performance of the semantic segmentation task. Our evaluations are
carried out on a large scale 3D object detection benchmark containing a LiDAR
cocoon setup, along with KITTI dataset, where the per-point segmentation labels
are derived from 3D bounding boxes. We show that VolMap achieved an excellent
balance between high accuracy and real-time running on CPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11875</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11875</id><created>2019-06-12</created><authors><author><keyname>Quellec</keyname><forenames>Gwenol&#xe9;</forenames></author><author><keyname>Lamard</keyname><forenames>Mathieu</forenames></author><author><keyname>Lay</keyname><forenames>Bruno</forenames></author><author><keyname>Guilcher</keyname><forenames>Alexandre Le</forenames></author><author><keyname>Erginay</keyname><forenames>Ali</forenames></author><author><keyname>Cochener</keyname><forenames>B&#xe9;atrice</forenames></author><author><keyname>Massin</keyname><forenames>Pascale</forenames></author></authors><title>Instant automatic diagnosis of diabetic retinopathy</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this study is to evaluate the performance of the OphtAI system
for the automatic detection of referable diabetic retinopathy (DR) and the
automatic assessment of DR severity using color fundus photography. OphtAI
relies on ensembles of convolutional neural networks trained to recognize eye
laterality, detect referable DR and assess DR severity. The system can either
process single images or full examination records. To document the automatic
diagnoses, accurate heatmaps are generated. The system was developed and
validated using a dataset of 763,848 images from 164,660 screening procedures
from the OPHDIAT screening program. For comparison purposes, it was also
evaluated in the public Messidor-2 dataset. Referable DR can be detected with
an area under the ROC curve of AUC = 0.989 in the Messidor-2 dataset, using the
University of Iowa's reference standard (95% CI: 0.984-0.994). This is
significantly better than the only AI system authorized by the FDA, evaluated
in the exact same conditions (AUC = 0.980). OphtAI can also detect
vision-threatening DR with an AUC of 0.997 (95% CI: 0.996-0.998) and
proliferative DR with an AUC of 0.997 (95% CI: 0.995-0.999). The system runs in
0.3 seconds using a graphics processing unit and less than 2 seconds without.
OphtAI is safer, faster and more comprehensive than the only AI system
authorized by the FDA so far. Instant DR diagnosis is now possible, which is
expected to streamline DR screening and to give easy access to DR screening to
more diabetic patients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11877</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11877</id><created>2019-06-10</created><authors><author><keyname>Luo</keyname><forenames>Zijin</forenames></author><author><keyname>Guzdial</keyname><forenames>Matthew</forenames></author><author><keyname>Riedl</keyname><forenames>Mark</forenames></author></authors><title>Making CNNs for Video Parsing Accessible</title><categories>cs.CV cs.AI cs.LG eess.IV</categories><comments>11 pages, 6 figures, Foundations of Digital Games 2018</comments><doi>10.1145/3337722.3337755</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to extract sequences of game events for high-resolution e-sport
games has traditionally required access to the game's engine. This serves as a
barrier to groups who don't possess this access. It is possible to apply deep
learning to derive these logs from gameplay video, but it requires
computational power that serves as an additional barrier. These groups would
benefit from access to these logs, such as small e-sport tournament organizers
who could better visualize gameplay to inform both audience and commentators.
In this paper we present a combined solution to reduce the required
computational resources and time to apply a convolutional neural network (CNN)
to extract events from e-sport gameplay videos. This solution consists of
techniques to train a CNN faster and methods to execute predictions more
quickly. This expands the types of machines capable of training and running
these models, which in turn extends access to extracting game logs with this
approach. We evaluate the approaches in the domain of DOTA2, one of the most
popular e-sports. Our results demonstrate our approach outperforms standard
backpropagation baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11879</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11879</id><created>2019-05-31</created><authors><author><keyname>Qasaimeh</keyname><forenames>Murad</forenames></author><author><keyname>Denolf</keyname><forenames>Kristof</forenames></author><author><keyname>Lo</keyname><forenames>Jack</forenames></author><author><keyname>Vissers</keyname><forenames>Kees</forenames></author><author><keyname>Zambreno</keyname><forenames>Joseph</forenames></author><author><keyname>Jones</keyname><forenames>Phillip H.</forenames></author></authors><title>Comparing Energy Efficiency of CPU, GPU and FPGA Implementations for
  Vision Kernels</title><categories>cs.CV eess.IV</categories><comments>8 pages, Design Automation Conference (DAC), The 15th IEEE
  International Conference on Embedded Software and Systems, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developing high performance embedded vision applications requires balancing
run-time performance with energy constraints. Given the mix of hardware
accelerators that exist for embedded computer vision (e.g. multi-core CPUs,
GPUs, and FPGAs), and their associated vendor optimized vision libraries, it
becomes a challenge for developers to navigate this fragmented solution space.
To aid with determining which embedded platform is most suitable for their
application, we conduct a comprehensive benchmark of the run-time performance
and energy efficiency of a wide range of vision kernels. We discuss rationales
for why a given underlying hardware architecture innately performs well or
poorly based on the characteristics of a range of vision kernel categories.
Specifically, our study is performed for three commonly used HW accelerators
for embedded vision applications: ARM57 CPU, Jetson TX2 GPU and ZCU102 FPGA,
using their vendor optimized vision libraries: OpenCV, VisionWorks and
xfOpenCV. Our results show that the GPU achieves an energy/frame reduction
ratio of 1.1-3.2x compared to the others for simple kernels. While for more
complicated kernels and complete vision pipelines, the FPGA outperforms the
others with energy/frame reduction ratios of 1.2-22.3x. It is also observed
that the FPGA performs increasingly better as a vision application's pipeline
complexity grows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11885</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11885</id><created>2019-06-10</created><authors><author><keyname>Feng</keyname><forenames>Chun-Mei</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Li</keyname><forenames>Zuoyong</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author></authors><title>Robust Classification with Sparse Representation Fusion on Diverse Data
  Subsets</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse Representation (SR) techniques encode the test samples into a sparse
linear combination of all training samples and then classify the test samples
into the class with the minimum residual. The classification of SR techniques
depends on the representation capability on the test samples. However, most of
these models view the representation problem of the test samples as a
deterministic problem, ignoring the uncertainty of the representation. The
uncertainty is caused by two factors, random noise in the samples and the
intrinsic randomness of the sample set, which means that if we capture a group
of samples, the obtained set of samples will be different in different
conditions. In this paper, we propose a novel method based upon Collaborative
Representation that is a special instance of SR and has closed-form solution.
It performs Sparse Representation Fusion based on the Diverse Subset of
training samples (SRFDS), which reduces the impact of randomness of the sample
set and enhances the robustness of classification results. The proposed method
is suitable for multiple types of data and has no requirement on the pattern
type of the tasks. In addition, SRFDS not only preserves a closed-form solution
but also greatly improves the classification performance. Promising results on
various datasets serve as the evidence of better performance of SRFDS than
other SR-based methods. The Matlab code of SRFDS will be accessible at
http://www.yongxu.org/lunwen.html.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11887</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11887</id><created>2019-06-09</created><authors><author><keyname>Hu</keyname><forenames>Benlin</forenames></author><author><keyname>Lei</keyname><forenames>Cheng</forenames></author><author><keyname>Wang</keyname><forenames>Dong</forenames></author><author><keyname>Zhang</keyname><forenames>Shu</forenames></author><author><keyname>Chen</keyname><forenames>Zhenyu</forenames></author></authors><title>A Preliminary Study on Data Augmentation of Deep Learning for Image
  Classification</title><categories>cs.CV cs.LG eess.IV</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning models have a large number of freeparameters that need to be
calculated by effective trainingof the models on a great deal of training data
to improvetheir generalization performance. However, data obtaining andlabeling
is expensive in practice. Data augmentation is one of themethods to alleviate
this problem. In this paper, we conduct apreliminary study on how three
variables (augmentation method,augmentation rate and size of basic dataset per
label) can affectthe accuracy of deep learning for image classification. The
studyprovides some guidelines: (1) it is better to use transformationsthat
alter the geometry of the images rather than those justlighting and color. (2)
2-3 times augmentation rate is good enoughfor training. (3) the smaller amount
of data, the more obviouscontributions could have.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11890</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11890</id><created>2019-06-04</created><authors><author><keyname>Tassano</keyname><forenames>Matias</forenames></author><author><keyname>Delon</keyname><forenames>Julie</forenames></author><author><keyname>Veit</keyname><forenames>Thomas</forenames></author></authors><title>DVDnet: A Fast Network for Deep Video Denoising</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a state-of-the-art video denoising algorithm based
on a convolutional neural network architecture. Previous neural network based
approaches to video denoising have been unsuccessful as their performance
cannot compete with the performance of patch-based methods. However, our
approach outperforms other patch-based competitors with significantly lower
computing times. In contrast to other existing neural network denoisers, our
algorithm exhibits several desirable properties such as a small memory
footprint, and the ability to handle a wide range of noise levels with a single
network model. The combination between its denoising performance and lower
computational load makes this algorithm attractive for practical denoising
applications. We compare our method with different state-of-art algorithms,
both visually and with respect to objective quality metrics. The experiments
show that our algorithm compares favorably to other state-of-art methods. Video
examples, code and models are publicly available at
\url{https://github.com/m-tassano/dvdnet}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11893</identifier>
 <datestamp>2019-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11893</id><created>2019-06-10</created><authors><author><keyname>Elfakharany</keyname><forenames>A.</forenames></author><author><keyname>Yusof</keyname><forenames>R.</forenames></author><author><keyname>Ismail</keyname><forenames>N.</forenames></author><author><keyname>Arfa</keyname><forenames>R.</forenames></author><author><keyname>Yunus</keyname><forenames>M.</forenames></author></authors><title>HalalNet: A Deep Neural Network that Classifies the Halalness
  Slaughtered Chicken from their Images</title><categories>cs.CV eess.IV</categories><comments>Submitted in the International Conference on Artificial Intelligence
  and Robotics for Industrial Applications, AIR2018</comments><journal-ref>International Journal of Integrated Engineering, Vol. 11, no. 4,
  Sept. 2019,
  https://publisher.uthm.edu.my/ojs/index.php/ijie/article/view/4194</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Halal requirement in food is important for millions of Muslims worldwide
especially for meat and chicken products, insuring that slaughter houses adhere
to this requirement is a challenging task to do manually. In this paper a
method is proposed that uses a camera that takes images of slaughtered chicken
on the conveyor in a slaughter house, the images are then analyzed by a deep
neural network to classify if the image is of a halal slaughtered chicken or
not. However, traditional deep learning models require large amounts of data to
train on, which in this case these amounts of data were challenging to collect
especially the images of non-halal slaughtered chicken, hence this paper shows
how the use of one shot learning [1] and transfer learning [2] can reach high
accuracy on the few amounts of data that were available. The architecture used
is based on the Siamese neural networks architecture which ranks the similarity
between two inputs [3] while using the Xception network [4] as the twin
networks. We call it HalalNet. This work was done as part of SYCUT (syriah
compliant slaughtering system) which is a monitoring system that monitors the
halalness of the slaughtered chicken in a slaughter house. The data used to
train and validate HalalNet was collected from the Azain slaughtering site
(Semenyih, Selangor, Malaysia) containing images of both halal and non-halal
slaughtered chicken.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11899</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11899</id><created>2019-06-11</created><authors><author><keyname>Dizaji</keyname><forenames>Farzad Shafiei</forenames></author></authors><title>Lidar based Detection and Classification of Pedestrians and Vehicles
  Using Machine Learning Methods</title><categories>cs.CV cs.LG cs.RO eess.IV stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The goal of this paper is to classify objects mapped by LiDAR sensor into
different classes such as vehicles, pedestrians and bikers. Utilizing a
LiDAR-based object detector and Neural Networks-based classifier, a novel
real-time object detection is presented essentially with respect to aid
self-driving vehicles in recognizing and classifying other objects encountered
in the course of driving and proceed accordingly. We discuss our work using
machine learning methods to tackle a common high-level problem found in machine
learning applications for self-driving cars: the classification of pointcloud
data obtained from a 3D LiDAR sensor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11902</identifier>
 <datestamp>2020-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11902</id><created>2019-06-14</created><updated>2020-02-11</updated><authors><author><keyname>Rane</keyname><forenames>Roshan</forenames></author><author><keyname>Sz&#xfc;gyi</keyname><forenames>Edit</forenames></author><author><keyname>Saxena</keyname><forenames>Vageesh</forenames></author><author><keyname>Ofner</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Stober</keyname><forenames>Sebastian</forenames></author></authors><title>PredNet and Predictive Coding: A Critical Review</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The PredNet architecture by Lotter et al. combines a biologically plausible
architecture called Predictive Coding with self-supervised video prediction in
order to learn the complex structure of the visual world. While the
architecture has drawn a lot of attention and various extensions of the model
exist, there is a lack of a critical analysis. We fill in the gap by evaluating
PredNet, both as an implementation of Predictive Coding theory and as a
self-supervised video prediction model, using a challenging video action
classification dataset. We also design an extended architecture to test if
conditioning future frame predictions on the action class of the video and
vise-versa improves the model performance. With substantial evidence, we show
that PredNet does not completely follow the principles of Predictive Coding.
Our comprehensive analysis and results are aimed to guide future research based
on PredNet or similar architectures based on the Predictive Coding theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11907</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11907</id><created>2019-06-18</created><updated>2019-10-11</updated><authors><author><keyname>Law</keyname><forenames>Stephen</forenames></author><author><keyname>Neira</keyname><forenames>Mateo</forenames></author></authors><title>An unsupervised approach to Geographical Knowledge Discovery using
  street level and street network images</title><categories>cs.CV cs.CY cs.LG eess.IV</categories><comments>SigSpatial 2019 GeoAI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent researches have shown the increasing use of machine learn-ing methods
in geography and urban analytics, primarily to extract features and patterns
from spatial and temporal data using a supervised approach. Researches
integrating geographical processes in machine learning models and the use of
unsupervised approacheson geographical data for knowledge discovery had been
sparse. This research contributes to the ladder, where we show how latent
variables learned from unsupervised learning methods on urbanimages can be used
for geographic knowledge discovery. In particular, we propose a simple approach
called Convolutional-PCA(ConvPCA) which are applied on both street level and
street network images to find a set of uncorrelated and ordered visual
latentcomponents. The approach allows for meaningful explanations using a
combination of geographical and generative visualisations to explore the latent
space, and to show how the learned representation can be used to predict urban
characteristics such as streetquality and street network attributes. The
research also finds that the visual components from the ConvPCA model achieves
similaraccuracy when compared to less interpretable dimension reduction
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11913</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11913</id><created>2019-06-27</created><authors><author><keyname>Grondin</keyname><forenames>Francois</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Multiple Sound Source Localization with SVD-PHAT</title><categories>eess.AS eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a modification of phase transform on singular value
decomposition (SVD-PHAT) to localize multiple sound sources. This work aims to
improve localization accuracy and keeps the algorithm complexity low for
real-time applications. This method relies on multiple scans of the search
space, with projection of each low-dimensional observation onto orthogonal
subspaces. We show that this method localizes multiple sound sources more
accurately than discrete SRP-PHAT, with a reduction in the Root Mean Square
Error up to 0.0395 radians.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11919</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11919</id><created>2019-06-12</created><authors><author><keyname>Amirabadi</keyname><forenames>Mohammad Ali</forenames></author></authors><title>A new fast approach for an EEG-based Motor Imagery BCI classification</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, Brain Computer Interface has an important role in the life quality
of parallelized people. However, this technique is mainly affected by the
quality of the recorded signal in each trial. This problem could be solved by
rejecting low-quality trials. But developing the processing based on the
recorded signal from the brain, which is a mixture of the target signal plus
noise and artifact, would not be favorable in situations that all trials have
low quality. This paper solves this problem by presenting a new fast algorithm
for separating recorded source signals. Results indicate the improvement in
classification accuracy of the proposed method compared with the classification
accuracy of processing on the recorded mixture signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11979</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11979</id><created>2019-06-27</created><authors><author><keyname>Hao</keyname><forenames>Hanxiang</forenames></author><author><keyname>G&#xfc;era</keyname><forenames>David</forenames></author><author><keyname>Reibman</keyname><forenames>Amy R.</forenames></author><author><keyname>Delp</keyname><forenames>Edward J.</forenames></author></authors><title>A Utility-Preserving GAN for Face Obscuration</title><categories>cs.CV cs.CR cs.LG eess.IV</categories><comments>6 pages, 5 figures, presented at the ICML 2019 Worksop on Synthetic
  Realities: Deep Learning for Detecting AudioVisual Fakes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From TV news to Google StreetView, face obscuration has been used for privacy
protection. Due to recent advances in the field of deep learning, obscuration
methods such as Gaussian blurring and pixelation are not guaranteed to conceal
identity. In this paper, we propose a utility-preserving generative model,
UP-GAN, that is able to provide an effective face obscuration, while preserving
facial utility. By utility-preserving we mean preserving facial features that
do not reveal identity, such as age, gender, skin tone, pose, and expression.
We show that the proposed method achieves the best performance in terms of
obscuration and utility preservation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11981</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.11981</id><created>2019-06-27</created><authors><author><keyname>Chu</keyname><forenames>Ringo S. W.</forenames></author><author><keyname>Ng</keyname><forenames>Ho-Cheung</forenames></author><author><keyname>Wang</keyname><forenames>Xiwei</forenames></author><author><keyname>Luk</keyname><forenames>Wayne</forenames></author></authors><title>Convolution Based Spectral Partitioning Architecture for Hyperspectral
  Image Classification</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted for publication in IGARSS'2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral images (HSIs) can distinguish materials with high number of
spectral bands, which is widely adopted in remote sensing applications and
benefits in high accuracy land cover classifications. However, HSIs processing
are tangled with the problem of high dimensionality and limited amount of
labelled data. To address these challenges, this paper proposes a deep learning
architecture using three dimensional convolutional neural networks with
spectral partitioning to perform effective feature extraction. We conduct
experiments using Indian Pines and Salinas scenes acquired by NASA Airborne
Visible/Infra-Red Imaging Spectrometer. In comparison to prior results, our
architecture shows competitive performance for classification results over
current methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12001</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12001</id><created>2019-06-27</created><authors><author><keyname>Fraternali</keyname><forenames>Francesco</forenames></author></authors><title>Towards Large-Scale Autonomous Wireless Sensor Networks</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks (WSNs) have the goal of gathering data from the
environment. The advent of the Internet of Things (IoT) drastically changed
WSN's vision that, as never before, needs to expand and include hundreds or
thousands of sensors. But to follow the current IoT trends new techniques need
to be implemented since orders of thousands of sensor nodes are not manageable
by today's WSNs systems that often rely on manual configuration and hence are
not practical. As an example, the replacement of batteries of thousand of nodes
could be extremely arduous or even impossible for structural health monitoring
of civil infrastructures (i.e. bridges, towers). Hence, the solution to the
growing burden of the system manager is automation, allowing the system to
check its own status, to re-configure itself and fix the major problems in the
network whenever it is possible. In this paper, we present and discuss the main
features needed to achieve an autonomous large scale WSN. Furthermore, we
compare these features with the state of the art of real-world large scale WSN
deployments showing that further solutions are needed to drastically reduce
human intervention while guaranteeing the main functionalities of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12021</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12021</id><created>2019-06-27</created><updated>2019-07-01</updated><authors><author><keyname>Anwar</keyname><forenames>Saeed</forenames></author><author><keyname>Barnes</keyname><forenames>Nick</forenames></author></authors><title>Densely Residual Laplacian Super-Resolution</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Super-Resolution convolutional neural networks have recently demonstrated
high-quality restoration for single images. However, existing algorithms often
require very deep architectures and long training times. Furthermore, current
convolutional neural networks for super-resolution are unable to exploit
features at multiple scales and weigh them equally, limiting their learning
capability. In this exposition, we present a compact and accurate
super-resolution algorithm namely, Densely Residual Laplacian Network (DRLN).
The proposed network employs cascading residual on the residual structure to
allow the flow of low-frequency information to focus on learning high and
mid-level features. In addition, deep supervision is achieved via the densely
concatenated residual blocks settings, which also helps in learning from
high-level complex features. Moreover, we propose Laplacian attention to model
the crucial features to learn the inter and intra-level dependencies between
the feature maps. Furthermore, comprehensive quantitative and qualitative
evaluations on low-resolution, noisy low-resolution, and real historical image
benchmark datasets illustrate that our DRLN algorithm performs favorably
against the state-of-the-art methods visually and accurately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12077</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12077</id><created>2019-06-28</created><authors><author><keyname>Dragoni</keyname><forenames>Laurent</forenames></author><author><keyname>Flamary</keyname><forenames>R&#xe9;mi</forenames></author><author><keyname>Lounici</keyname><forenames>Karim</forenames></author><author><keyname>Reynaud-Bouret</keyname><forenames>Patricia</forenames></author></authors><title>Large scale Lasso with windowed active set for convolutional spike
  sorting</title><categories>stat.ML cs.LG eess.SP math.OC stat.AP stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spike sorting is a fundamental preprocessing step in neuroscience that is
central to access simultaneous but distinct neuronal activities and therefore
to better understand the animal or even human brain. But numerical complexity
limits studies that require processing large scale datasets in terms of number
of electrodes, neurons, spikes and length of the recorded signals. We propose
in this work a novel active set algorithm aimed at solving the Lasso for a
classical convolutional model. Our algorithm can be implemented efficiently on
parallel architecture and has a linear complexity w.r.t. the temporal
dimensionality which ensures scaling and will open the door to online spike
sorting. We provide theoretical results about the complexity of the algorithm
and illustrate it in numerical experiments along with results about the
accuracy of the spike recovery and robustness to the regularization parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12086</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12086</id><created>2019-06-28</created><authors><author><keyname>Fiducioso</keyname><forenames>Marcello</forenames></author><author><keyname>Curi</keyname><forenames>Sebastian</forenames></author><author><keyname>Schumacher</keyname><forenames>Benedikt</forenames></author><author><keyname>Gwerder</keyname><forenames>Markus</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author></authors><title>Safe Contextual Bayesian Optimization for Sustainable Room Temperature
  PID Control Tuning</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><comments>7 pages; Published in IJCAI 19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tune one of the most common heating, ventilation, and air conditioning
(HVAC) control loops, namely the temperature control of a room. For economical
and environmental reasons, it is of prime importance to optimize the
performance of this system. Buildings account from 20 to 40% of a country
energy consumption, and almost 50% of it comes from HVAC systems. Scenario
projections predict a 30% decrease in heating consumption by 2050 due to
efficiency increase. Advanced control techniques can improve performance;
however, the proportional-integral-derivative (PID) control is typically used
due to its simplicity and overall performance. We use Safe Contextual Bayesian
Optimization to optimize the PID parameters without human intervention. We
reduce costs by 32% compared to the current PID controller setting while
assuring safety and comfort to people in the room. The results of this work
have an immediate impact on the room control loop performances and its related
commissioning costs. Furthermore, this successful attempt paves the way for
further use at different levels of HVAC systems, with promising energy,
operational, and commissioning costs savings, and it is a practical
demonstration of the positive effects that Artificial Intelligence can have on
environmental sustainability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12113</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12113</id><created>2019-06-28</created><authors><author><keyname>Khan</keyname><forenames>Adil</forenames></author><author><keyname>Khan</keyname><forenames>Abdul Qayyum</forenames></author><author><keyname>Sarwar</keyname><forenames>Muhammad</forenames></author><author><keyname>Abubakar</keyname><forenames>Muhammad</forenames></author><author><keyname>Iqbal</keyname><forenames>Naeem</forenames></author></authors><title>An Accurate Fault Location Algorithm for Meshed Power Networks Utilizing
  Hybrid Sparse Voltage and Current Measurements</title><categories>eess.SP cs.SY eess.SY</categories><comments>16 pages, 3 figures, 7 tables, submitted in Electric Power Systems
  Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an accurate fault location algorithm technique based on
hybrid synchronized sparse voltage and sparse current phasor measurements. The
proposed algorithm addresses the performance limitation of fault location
algorithms based on only synchronized sparse voltage measurements (SSVM) and on
only synchronized sparse current measurements (SSCM). In the proposed method,
bus voltage phasor of faulty line or close to the faulty line and branch
current phasor of the adjacent line is utilized. The paper contributes to
improve the accuracy of fault location and deter the effect of CT saturation by
using hybrid voltage and current measurements. The proposed algorithm has been
tested on four bus two area power system and IEEE 14 bus system with the
typical features of an actual distribution system. The robustness of algorithm
has been tested by variation in fault location, fault resistance, load
switching. The simulation results demonstrate the accuracy of the proposed
algorithm and ensure a reliable fault detection and location method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12121</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12121</id><created>2019-06-28</created><updated>2020-02-03</updated><authors><author><keyname>St-Jean</keyname><forenames>Samuel</forenames></author><author><keyname>De Luca</keyname><forenames>Alberto</forenames></author><author><keyname>Tax</keyname><forenames>Chantal M. W.</forenames></author><author><keyname>Viergever</keyname><forenames>Max A.</forenames></author><author><keyname>Leemans</keyname><forenames>Alexander</forenames></author></authors><title>Automated characterization of noise distributions in diffusion MRI data</title><categories>eess.IV stat.AP stat.CO</categories><comments>v3: Peer reviewed version v2: Manuscript as submitted to Medical
  image analysis v1: Manuscript as submitted to Magnetic resonance in medicine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge of the noise distribution in diffusion MRI is the centerpiece to
quantify uncertainties arising from the acquisition process. Accurate
estimation beyond textbook distributions often requires information about the
acquisition process, which is usually not available. We introduce two new
automated methods using the moments and maximum likelihood equations of the
Gamma distribution to estimate all unknown parameters using only the magnitude
data. A rejection step is used to make the framework automatic and robust to
artifacts. Simulations were created for two diffusion weightings with parallel
imaging. Furthermore, MRI data of a water phantom with different combinations
of parallel imaging were acquired. Finally, experiments on freely available
datasets are used to assess reproducibility when limited information about the
acquisition protocol is available. Additionally, we demonstrated the
applicability of the proposed methods for a bias correction and denoising task
on an in vivo dataset. A generalized version of the bias correction framework
for non integer degrees of freedom is also introduced. The proposed framework
is compared with three other algorithms with datasets from three vendors,
employing different reconstruction methods. Simulations showed that assuming a
Rician distribution can lead to misestimation of the noise distribution in
parallel imaging. Results showed that signal leakage in multiband can also lead
to a misestimation of the noise distribution. Repeated acquisitions of in vivo
datasets show that the estimated parameters are stable and have lower
variability than compared methods. Results show that the proposed methods
reduce the appearance of noise at high b-value. The proposed algorithms herein
can estimate both parameters of the noise distribution automatically, are
robust to signal leakage artifacts and perform best when used on acquired noise
maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12145</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12145</id><created>2019-06-28</created><authors><author><keyname>Jaeckel</keyname><forenames>Stephan</forenames></author><author><keyname>Turay</keyname><forenames>Nick</forenames></author><author><keyname>Raschkowski</keyname><forenames>Leszek</forenames></author><author><keyname>Thiele</keyname><forenames>Lars</forenames></author><author><keyname>Vuohtoniemi</keyname><forenames>Risto</forenames></author><author><keyname>Sonkki</keyname><forenames>Marko</forenames></author><author><keyname>Hovinen</keyname><forenames>Veikko</forenames></author><author><keyname>Burkhardt</keyname><forenames>Frank</forenames></author><author><keyname>Karunakaran</keyname><forenames>Prasanth</forenames></author><author><keyname>Heyn</keyname><forenames>Thomas</forenames></author></authors><title>Industrial Indoor Measurements from 2-6 GHz for the 3GPP-NR and QuaDRiGa
  Channel Model</title><categories>eess.SP</categories><comments>7 pages, 3 figures, 3 tables, submitted to IEEE VTC Fall '19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing reliable low latency wireless links for advanced manufacturing and
processing systems is a vision of Industry 4.0. Developing, testing and rating
requires accurate models of the radio propagation channel. The current 3GPP-NR
model as well as the QuaDRiGa model lack the propagation parameters for the
industrial indoor scenario. To close this gap, measurements were conducted at
2.37 GHz and 5.4 GHz at operational Siemens premises in Nuremberg, Germany.
Furthermore, the campaign was planned to allow the test and parameterization of
new features of the QuaDRiGa channel model such as support for device-to-device
(D2D) radio links and spatial consistency. A total of 5.9 km measurement track
was used to extract the statistical model parameters for line of sight (LOS)
and Non-LOS propagation conditions. It was found that the metallic walls and
objects in the halls create a rich scattering environment, where a large number
of multipath components arrive at the receiver from all directions. This leads
to a robust communication link, provided that the transceivers can handle the
interference. The extracted parameters can be used in geometric-stochastic
channel models such as QuaDRiGa to support simulation studies, both on link and
system level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12149</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12149</id><created>2019-06-28</created><authors><author><keyname>Jaeckel</keyname><forenames>Stephan</forenames></author><author><keyname>Raschkowski</keyname><forenames>Leszek</forenames></author><author><keyname>Burkhardt</keyname><forenames>Frank</forenames></author><author><keyname>Thiele</keyname><forenames>Lars</forenames></author></authors><title>A Spatially Consistent Geometric D2D Small-Scale Fading Model for
  Multiple Frequencies</title><categories>eess.SP</categories><comments>5 pages, 3 figures, accepted at IEEE VTC Fall '19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3GPP new radio (NR) channel model introduced spatial consistency and a
correlation model for multiple frequencies. Future extensions of this model
will incorporate mobility at both ends of the link. These features are
essential for many emerging wireless technologies in the 5G era. However, the
existing small-scale-fading (SSF) model does not integrate these features
coherently. To solve this problem, we propose a new SSF model that seamlessly
integrates with the remaining NR model and allows the simultaneous simulation
of all three features. We demonstrate this integration by showing that the
output of the new SSF model agrees well with large-scale fading (LSF) parameter
distributions provided by 3GPP. This enables the simulation of new wireless
technology proposals that were difficult to realize with existing
geometry-based stochastic channel models (GSCMs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12170</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12170</id><created>2019-06-25</created><authors><author><keyname>Margam</keyname><forenames>Dilip Kumar</forenames></author><author><keyname>Aralikatti</keyname><forenames>Rohith</forenames></author><author><keyname>Sharma</keyname><forenames>Tanay</forenames></author><author><keyname>Thanda</keyname><forenames>Abhinav</forenames></author><author><keyname>K</keyname><forenames>Pujitha A</forenames></author><author><keyname>Roy</keyname><forenames>Sharad</forenames></author><author><keyname>Venkatesan</keyname><forenames>Shankar M</forenames></author></authors><title>LipReading with 3D-2D-CNN BLSTM-HMM and word-CTC models</title><categories>cs.CV cs.LG cs.SD eess.AS eess.IV</categories><comments>Submitted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, deep learning based machine lipreading has gained
prominence. To this end, several architectures such as LipNet, LCANet and
others have been proposed which perform extremely well compared to traditional
lipreading DNN-HMM hybrid systems trained on DCT features. In this work, we
propose a simpler architecture of 3D-2D-CNN-BLSTM network with a bottleneck
layer. We also present analysis of two different approaches for lipreading on
this architecture. In the first approach, 3D-2D-CNN-BLSTM network is trained
with CTC loss on characters (ch-CTC). Then BLSTM-HMM model is trained on
bottleneck lip features (extracted from 3D-2D-CNN-BLSTM ch-CTC network) in a
traditional ASR training pipeline. In the second approach, same 3D-2D-CNN-BLSTM
network is trained with CTC loss on word labels (w-CTC). The first approach
shows that bottleneck features perform better compared to DCT features. Using
the second approach on Grid corpus' seen speaker test set, we report $1.3\%$
WER - a $55\%$ improvement relative to LCANet. On unseen speaker test set we
report $8.6\%$ WER which is $24.5\%$ improvement relative to LipNet. We also
verify the method on a second dataset of $81$ speakers which we collected.
Finally, we also discuss the effect of feature duplication on BLSTM-HMM model
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12174</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12174</id><created>2019-06-24</created><authors><author><keyname>Li</keyname><forenames>Yongfei</forenames></author><author><keyname>Yang</keyname><forenames>Dongfang</forenames></author><author><keyname>Wang</keyname><forenames>Shicheng</forenames></author><author><keyname>He</keyname><forenames>Hao</forenames></author></authors><title>Road-network-based Rapid Geolocalization</title><categories>cs.CV cs.AI eess.IV</categories><comments>19pages, 10 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has always been a research hotspot to use geographic information to assist
the navigation of unmanned aerial vehicles. In this paper, a road-network-based
localization method is proposed. We match roads in the measurement images to
the reference road vector map, and realize successful localization on areas as
large as a whole city. The road network matching problem is treated as a point
cloud registration problem under two-dimensional projective transformation, and
solved under a hypothesise-and-test framework. To deal with the projective
point cloud registration problem, a global projective invariant feature is
proposed, which consists of two road intersections augmented with the
information of their tangents. We call it two road intersections tuple. We
deduce the closed-form solution for determining the alignment transformation
from a pair of matching two road intersections tuples. In addition, we propose
the necessary conditions for the tuples to match. This can reduce the candidate
matching tuples, thus accelerating the search to a great extent. We test all
the candidate matching tuples under a hypothesise-and-test framework to search
for the best match. The experiments show that our method can localize the
target area over an area of 400 within 1 second on a single cpu.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12187</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12187</id><created>2019-06-26</created><authors><author><keyname>Brodeski</keyname><forenames>Daniel</forenames></author><author><keyname>Bilik</keyname><forenames>Igal</forenames></author><author><keyname>Giryes</keyname><forenames>Raja</forenames></author></authors><title>Deep Radar Detector</title><categories>cs.CV cs.LG eess.SP stat.ML</categories><comments>Accepted to RadarConf 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While camera and LiDAR processing have been revolutionized since the
introduction of deep learning, radar processing still relies on classical
tools. In this paper, we introduce a deep learning approach for radar
processing, working directly with the radar complex data. To overcome the lack
of radar labeled data, we rely in training only on the radar calibration data
and introduce new radar augmentation techniques. We evaluate our method on the
radar 4D detection task and demonstrate superior performance compared to the
classical approaches while keeping real-time performance. Applying deep
learning on radar data has several advantages such as eliminating the need for
an expensive radar calibration process each time and enabling classification of
the detected objects with almost zero-overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12189</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12189</id><created>2019-06-27</created><authors><author><keyname>Koller</keyname><forenames>Torsten</forenames></author><author><keyname>Berkenkamp</keyname><forenames>Felix</forenames></author><author><keyname>Turchetta</keyname><forenames>Matteo</forenames></author><author><keyname>Boedecker</keyname><forenames>Joschka</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author></authors><title>Learning-based Model Predictive Control for Safe Exploration and
  Reinforcement Learning</title><categories>eess.SY cs.AI cs.LG cs.SY</categories><comments>14 pages, 7 figures. arXiv admin note: substantial text overlap with
  arXiv:1803.08287</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reinforcement learning has been successfully used to solve difficult tasks in
complex unknown environments. However, these methods typically do not provide
any safety guarantees during the learning process. This is particularly
problematic, since reinforcement learning agent actively explore their
environment. This prevents their use in safety-critical, real-world
applications. In this paper, we present a learning-based model predictive
control scheme that provides high-probability safety guarantees throughout the
learning process. Based on a reliable statistical model, we construct provably
accurate confidence intervals on predicted trajectories. Unlike previous
approaches, we allow for input-dependent uncertainties. Based on these reliable
predictions, we guarantee that trajectories satisfy safety constraints.
Moreover, we use a terminal set constraint to recursively guarantee the
existence of safe control actions at every iteration. We evaluate the resulting
algorithm to safely explore the dynamics of an inverted pendulum and to solve a
reinforcement learning task on a cart-pole system with safety constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12193</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12193</id><created>2019-06-28</created><updated>2019-08-11</updated><authors><author><keyname>Fan</keyname><forenames>Zhun</forenames></author><author><keyname>Mo</keyname><forenames>Jiajie</forenames></author><author><keyname>Qiu</keyname><forenames>Benzhang</forenames></author><author><keyname>Li</keyname><forenames>Wenji</forenames></author><author><keyname>Zhu</keyname><forenames>Guijie</forenames></author><author><keyname>Li</keyname><forenames>Chong</forenames></author><author><keyname>Hu</keyname><forenames>Jianye</forenames></author><author><keyname>Rong</keyname><forenames>Yibiao</forenames></author><author><keyname>Chen</keyname><forenames>Xinjian</forenames></author></authors><title>Accurate Retinal Vessel Segmentation via Octave Convolution Neural
  Network</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Retinal vessel segmentation is a crucial step in diagnosing and screening
various diseases, including diabetes, ophthalmologic diseases, and
cardiovascular diseases. In this paper, we propose an effective and efficient
method for vessel segmentation in color fundus images using encoder-decoder
based octave convolution network. Compared with other convolution networks
utilizing vanilla convolution for feature extraction, the proposed method
adopts octave convolution for learning multiple-spatial-frequency features,
thus can better capture retinal vasculatures with varying sizes and shapes. It
is demonstrated that the feature maps of low-frequency kernels respond mainly
to the major vascular tree, whereas the high-frequency feature maps can better
capture the fine details of thin vessels. To provide the network the capability
of learning how to decode multifrequency features, we extend octave convolution
and propose a new operation named octave transposed convolution. A novel
architecture of convolutional neural network is proposed based on the
encoder-decoder architecture of UNet, which can generate high resolution vessel
segmentation in one single forward feeding. The proposed method is evaluated on
four publicly available datasets, including DRIVE, STARE, CHASE_DB1, and HRF.
Extensive experimental results demonstrate that the proposed approach achieves
better or comparable performance to the state-of-the-art methods with fast
processing speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12195</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12195</id><created>2019-06-27</created><authors><author><keyname>Ghelfi</keyname><forenames>Emanuele</forenames></author><author><keyname>Galeone</keyname><forenames>Paolo</forenames></author><author><keyname>De Simoni</keyname><forenames>Michele</forenames></author><author><keyname>Di Mattia</keyname><forenames>Federico</forenames></author></authors><title>Adversarial Pixel-Level Generation of Semantic Images</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Generative Adversarial Networks (GANs) have obtained extraordinary success in
the generation of realistic images, a domain where a lower pixel-level accuracy
is acceptable. We study the problem, not yet tackled in the literature, of
generating semantic images starting from a prior distribution. Intuitively this
problem can be approached using standard methods and architectures. However, a
better-suited approach is needed to avoid generating blurry, hallucinated and
thus unusable images since tasks like semantic segmentation require pixel-level
exactness. In this work, we present a novel architecture for learning to
generate pixel-level accurate semantic images, namely Semantic Generative
Adversarial Networks (SemGANs). The experimental evaluation shows that our
architecture outperforms standard ones from both a quantitative and a
qualitative point of view in many semantic image generation tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12216</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12216</id><created>2019-06-28</created><authors><author><keyname>Pasquini</keyname><forenames>Mirko</forenames></author><author><keyname>Angeli</keyname><forenames>David</forenames></author></authors><title>On the robust existence of piecewise quadratic Lyapunov functions for
  hybrid models of gene regulatory networks</title><categories>eess.SY cs.SY q-bio.MN</categories><comments>Submitted to the 58th IEEE Conference on Decision and Control - Nice,
  France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we addressed the problem of stability analysis for an uncertain
piecewise affine model of a genetic regulatory network. In particular we
considered polytopic parameter uncertainties on the proteins production rate
functions, giving conditions for the existence of a piecewise quadratic
Lyapunov function for any possible realization of the system. In the spirit of
other works in literature, the resulting conditions will be given on the
vertices of the parameter polytope, while still taking into consideration the
piecewise nature of the Lyapunov function and the presence, in general, of
sliding modes solutions. An example is shown to prove the validity and
applicability of the theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12223</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12223</id><created>2019-06-28</created><authors><author><keyname>Elmahdy</keyname><forenames>Mohamed S.</forenames></author><author><keyname>Wolterink</keyname><forenames>Jelmer M.</forenames></author><author><keyname>Sokooti</keyname><forenames>Hessam</forenames></author><author><keyname>I&#x161;gum</keyname><forenames>Ivana</forenames></author><author><keyname>Staring</keyname><forenames>Marius</forenames></author></authors><title>Adversarial optimization for joint registration and segmentation in
  prostate CT radiotherapy</title><categories>eess.IV cs.CV</categories><comments>Accepted to MICCAI 2019, 13-17 Oct 2019, Shenzhen, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Joint image registration and segmentation has long been an active area of
research in medical imaging. Here, we reformulate this problem in a deep
learning setting using adversarial learning. We consider the case in which
fixed and moving images as well as their segmentations are available for
training, while segmentations are not available during testing; a common
scenario in radiotherapy. The proposed framework consists of a 3D end-to-end
generator network that estimates the deformation vector field (DVF) between
fixed and moving images in an unsupervised fashion and applies this DVF to the
moving image and its segmentation. A discriminator network is trained to
evaluate how well the moving image and segmentation align with the fixed image
and segmentation. The proposed network was trained and evaluated on follow-up
prostate CT scans for image-guided radiotherapy, where the planning CT contours
are propagated to the daily CT images using the estimated DVF. A quantitative
comparison with conventional registration using \texttt{elastix} showed that
the proposed method improved performance and substantially reduced computation
time, thus enabling real-time contour propagation necessary for online-adaptive
radiotherapy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12227</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12227</id><created>2019-06-28</created><authors><author><keyname>Quinton</keyname><forenames>Pierre</forenames></author><author><keyname>Mart&#xed;nez-Nuevo</keyname><forenames>Pablo</forenames></author><author><keyname>M&#xf8;ller</keyname><forenames>Martin B.</forenames></author></authors><title>An Image Source Method Framework for Arbitrary Reflecting Boundaries</title><categories>eess.SP eess.AS</categories><comments>9 pages, 6 figures</comments><msc-class>28A78</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a theoretical framework for the image source method that
generalizes to arbitrary reflecting boundaries, e.g. boundaries that are curved
or even with certain openings. Furthermore, it can seamlessly incorporate
boundary absorption, source directivity, and nonspecular reflections. This
framework is based on the notion of reflection paths that allows the
introduction of the concepts of validity and visibility of virtual sources.
These definitions facilitate the determination, for a given source and receiver
location, of the distribution of virtual sources that explain the boundary
effects of a wide range of reflecting surfaces. The structure of the set of
virtual sources is then more general than just punctual virtual sources. Due to
this more diverse configuration of image sources, we represent the room impulse
response as an integral involving the temporal excitation signal against a
measure determined by the source and receiver locations, and the original
boundary. The latter smoothly enables, in an analytically tractable manner, the
incorporation of more general boundary shapes as well as directivity of sources
and boundary absorption while, at the same time, maintaining the conceptual
benefits of the image source method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12248</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12248</id><created>2019-06-28</created><authors><author><keyname>Choi</keyname><forenames>Jihun</forenames></author><author><keyname>Rao</keyname><forenames>Chirag</forenames></author><author><keyname>Dagefu</keyname><forenames>Fikadu T.</forenames></author></authors><title>Real-Time Digital Video Streaming at Low-VHF for Compact Autonomous
  Agents in Complex Scenes</title><categories>eess.IV eess.SP</categories><comments>Accepted for publication in 2019 IEEE 89th Vehicular Technology
  Conference</comments><doi>10.1109/VTCSpring.2019.8746359</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an experimental investigation of real-time digital video
streaming in physically complex Non-Line-Of-Sight (NLoS) channels using a
low-power, low-VHF system integrated on a compact robotic platform. Reliable
video streaming in NLoS channels over infrastructure-poor ad-hoc radio networks
is challenging due to multipath and shadow fading. In this effort, we focus on
exploiting the near-ground low-VHF channel which has been shown to have
improved penetration, reduced fading, and lower power requirements (which is
critical for autonomous agents with limited power) compared to higher
frequencies. Specifically, we develop a compact, low-power, low-VHF radio
test-bed enabled by recent advances in efficient miniature antennas and
off-the-shelf software-defined radios. Our main goal is to carry out an
empirical study in realistic environments of how the improved propagation
conditions at low-VHF affect the reliability of video-streaming with
constraints stemming from the limited available bandwidth with electrically
small low-VHF antennas. We show quantitative performance analysis of video
streaming from a robotic platform navigating inside a large occupied building
received by a node located outdoors: bit error rate (BER) and channel-induced
Peak Signal-to-Noise Ratio (PSNR) degradation. The results show
channel-effect-free-like video streaming with the low-VHF system in complex
NLoS channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12250</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12250</id><created>2019-06-01</created><authors><author><keyname>Nassif</keyname><forenames>Roula</forenames></author><author><keyname>Vlaski</keyname><forenames>Stefan</forenames></author><author><keyname>Sayed</keyname><forenames>Ali H.</forenames></author></authors><title>Adaptation and learning over networks under subspace constraints -- Part
  II: Performance Analysis</title><categories>cs.MA eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1905.08750</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Part I of this paper considered optimization problems over networks where
agents have individual objectives to meet, or individual parameter vectors to
estimate, subject to subspace constraints that require the objectives across
the network to lie in low-dimensional subspaces. Starting from the centralized
projected gradient descent, an iterative and distributed solution was proposed
that responds to streaming data and employs stochastic approximations in place
of actual gradient vectors, which are generally unavailable. We examined the
second-order stability of the learning algorithm and we showed that, for small
step-sizes $\mu$, the proposed strategy leads to small estimation errors on the
order of $\mu$. This Part II examines steady-state performance. The results
reveal explicitly the influence of the gradient noise, data characteristics,
and subspace constraints, on the network performance. The results also show
that in the small step-size regime, the iterates generated by the distributed
algorithm achieve the centralized steady-state performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12263</identifier>
 <datestamp>2019-10-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12263</id><created>2019-06-28</created><updated>2019-10-18</updated><authors><author><keyname>Jost</keyname><forenames>Ferdinand</forenames></author><author><keyname>Peter</keyname><forenames>Pascal</forenames></author><author><keyname>Weickert</keyname><forenames>Joachim</forenames></author></authors><title>Compressing Flow Fields with Edge-aware Homogeneous Diffusion Inpainting</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In spite of the fact that efficient compression methods for dense
two-dimensional flow fields would be very useful for modern video codecs,
hardly any research has been performed in this area so far. Our paper addresses
this problem by proposing the first lossy diffusion-based codec for this
purpose. It keeps only a few flow vectors on a coarse grid. Additionally stored
edge locations ensure the accurate representation of discontinuities. In the
decoding step, the missing information is recovered by homogeneous diffusion
inpainting that incorporates the stored edges as reflecting boundary
conditions. In spite of the simple nature of this codec, our experiments show
that it achieves remarkable quality for compression ratios up to 800 : 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12286</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12286</id><created>2019-06-28</created><updated>2019-09-09</updated><authors><author><keyname>Meredith</keyname><forenames>David</forenames></author></authors><title>RecurSIA-RRT: Recursive translatable point-set pattern discovery with
  removal of redundant translators</title><categories>cs.LG cs.SD eess.AS</categories><comments>Submitted to 12th International Workshop on Machine Learning and
  Music (https://musml2019.weebly.com/)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce two algorithms, RECURSIA and RRT, designed to increase the
compression factor achievable using point-set cover algorithms based on the SIA
and SIATEC pattern discovery algorithms. SIA computes the maximal translatable
patterns (MTPs) in a point set, while SIATEC computes the translational
equivalence class (TEC) of every MTP in a point set, where the TEC of an MTP is
the set of translationally invariant occurrences of that MTP in the point set.
In its output, SIATEC encodes each MTP TEC as a pair, &lt;P,V&gt;, where P is the
first occurrence of the MTP and V is the set of non-zero vectors that map P
onto its other occurrences. RECURSIA recursively applies a TEC cover algorithm
to the pattern P, in each TEC, &lt;P,V&gt;, that it discovers. RRT attempts to remove
translators from V in each TEC without reducing the total set of points covered
by the TEC. When evaluated with COSIATEC, SIATECCompress and Forth's algorithm
on the JKU Patterns Development Database, using RECURSIA with or without RRT
increased compression factor and recall but reduced precision. Using RRT alone
increased compression factor and reduced recall and precision, but had a
smaller effect than RECURSIA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12329</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12329</id><created>2019-06-28</created><authors><author><keyname>Felgueira</keyname><forenames>Telmo</forenames></author><author><keyname>Rodrigues</keyname><forenames>Silvio</forenames></author><author><keyname>Perone</keyname><forenames>Christian S.</forenames></author><author><keyname>Castro</keyname><forenames>Rui</forenames></author></authors><title>The Impact of Feature Causality on Normal Behaviour Models for
  SCADA-based Wind Turbine Fault Detection</title><categories>eess.SP cs.LG stat.ML</categories><comments>Presented at ICML 2019 Workshop: Climate Change: How Can AI Help?</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The cost of wind energy can be reduced by using SCADA data to detect faults
in wind turbine components. Normal behavior models are one of the main fault
detection approaches, but there is a lack of consensus in how different input
features affect the results. In this work, a new taxonomy based on the causal
relations between the input features and the target is presented. Based on this
taxonomy, the impact of different input feature configurations on the modelling
and fault detection performance is evaluated. To this end, a framework that
formulates the detection of faults as a classification problem is also
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.12338</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1906.12338</id><created>2019-06-28</created><authors><author><keyname>Yakopcic</keyname><forenames>Chris</forenames></author><author><keyname>Rahman</keyname><forenames>Nayim</forenames></author><author><keyname>Atahary</keyname><forenames>Tanvir</forenames></author><author><keyname>Taha</keyname><forenames>Tarek M.</forenames></author><author><keyname>Beigh</keyname><forenames>Alex</forenames></author><author><keyname>Douglass</keyname><forenames>Scott</forenames></author></authors><title>High Speed Cognitive Domain Ontologies for Asset Allocation Using Loihi
  Spiking Neurons</title><categories>cs.NE eess.SP</categories><comments>Accepted and to appear in the proceedings of the 2019 IEEE-INNS
  International Joint Conference on Neural Networks. Citation: C. Yakopcic, T.
  Atahary, N. Rahman, T. M. Taha, A. Beigh, and S. Douglass, High Speed
  Approximate Cognitive Domain Ontologies for Asset Allocation Using Loihi
  Spiking Neurons, IEEE-INNS International Joint Conference on Neural Networks,
  Budapest, Hungary, July, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive agents are typically utilized in autonomous systems for automated
decision making. These systems interact at real time with their environment and
are generally heavily power constrained. Thus, there is a strong need for a
real time agent running on a low power platform. The agent examined is the
Cognitively Enhanced Complex Event Processing (CECEP) architecture. This is an
autonomous decision support tool that reasons like humans and enables enhanced
agent-based decision-making. It has applications in a large variety of domains
including autonomous systems, operations research, intelligence analysis, and
data mining. One of the key components of CECEP is the mining of knowledge from
a repository described as a Cognitive Domain Ontology (CDO). One problem that
is often tasked to CDOs is asset allocation. Given the number of possible
solutions in this allocation problem, determining the optimal solution via CDO
can be very time consuming. In this work we show that a grid of isolated
spiking neurons is capable of generating solutions to this problem very
quickly, although some degree of approximation is required to achieve the
speedup. However, the approximate spiking approach presented in this work was
able to complete all allocation simulations with greater than 99.9% accuracy.
To show the feasibility of low power implementation, this algorithm was
executed using the Intel Loihi manycore neuromorphic processor. Given the vast
increase in speed (greater than 1000 times in larger allocation problems), as
well as the reduction in computational requirements, the presented algorithm is
ideal for moving asset allocation to low power, portable, embedded hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00028</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00028</id><created>2019-06-28</created><authors><author><keyname>Chagas</keyname><forenames>Paulo</forenames></author><author><keyname>Souza</keyname><forenames>Luiz</forenames></author><author><keyname>Ara&#xfa;jo</keyname><forenames>Ikaro</forenames></author><author><keyname>Aldeman</keyname><forenames>Nayze</forenames></author><author><keyname>Duarte</keyname><forenames>Angelo</forenames></author><author><keyname>Angelo</keyname><forenames>Michele</forenames></author><author><keyname>dos-Santos</keyname><forenames>Washington LC</forenames></author><author><keyname>Oliveira</keyname><forenames>Luciano</forenames></author></authors><title>Classification of glomerular hypercellularity using convolutional
  features and support vector machine</title><categories>eess.IV cs.CV</categories><comments>26 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Glomeruli are histological structures of the kidney cortex formed by
interwoven blood capillaries, and are responsible for blood filtration.
Glomerular lesions impair kidney filtration capability, leading to protein loss
and metabolic waste retention. An example of lesion is the glomerular
hypercellularity, which is characterized by an increase in the number of cell
nuclei in different areas of the glomeruli. Glomerular hypercellularity is a
frequent lesion present in different kidney diseases. Automatic detection of
glomerular hypercellularity would accelerate the screening of scanned
histological slides for the lesion, enhancing clinical diagnosis. Having this
in mind, we propose a new approach for classification of hypercellularity in
human kidney images. Our proposed method introduces a novel architecture of a
convolutional neural network (CNN) along with a support vector machine,
achieving near perfect average results with the FIOCRUZ data set in a binary
classification (lesion or normal). Our deep-based classifier outperformed the
state-of-the-art results on the same data set. Additionally, classification of
hypercellularity sub-lesions was also performed, considering mesangial,
endocapilar and both lesions; in this multi-classification task, our proposed
method just failed in 4\% of the cases. To the best of our knowledge, this is
the first study on deep learning over a data set of glomerular hypercellularity
images of human kidney.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00036</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00036</id><created>2019-06-25</created><authors><author><keyname>Amirabadi</keyname><forenames>M. A.</forenames></author></authors><title>Novel Suboptimal approaches for Hyperparameter Tuning of Deep Neural
  Network [under the shelf of Optical Communication]</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperparameter tuning is the main challenge of machine learning (ML)
algorithms. Grid search is a popular method in hyperparameter tuning of simple
ML algorithms; however, high computational complexity in complex ML algorithms
such as Deep Neural Networks (DNN) is the main barrier towards its practical
implementation. In this paper, two novel suboptimal grid search methods are
presented, which search the grid marginally and alternating. In order to
examine these methods, hyperparameter tuning is applied on two different DNN
based Optical Communication (OC) systems (Fiber OC, and Free Space Optical
(FSO) communication). The hyperparameter tuning of ML algorithms, despite its
importance is ignored in ML for OC investigations. In addition, this is the
first consideration of both FSO and Fiber OC systems in an ML for OC
investigation. Results indicate that despite greatly reducing computation load,
favorable performance could be achieved by the proposed methods. In addition,
it is shown that the alternating search method has better performance than
marginal grid search method. In sum, the proposed structures are
cost-effective, and appropriate for real-time applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00037</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00037</id><created>2019-06-28</created><authors><author><keyname>Mehrotra</keyname><forenames>Rashi</forenames></author><author><keyname>Ansari</keyname><forenames>Rafay Iqbal</forenames></author><author><keyname>Pitilakis</keyname><forenames>Alexandros</forenames></author><author><keyname>Nie</keyname><forenames>Shuai</forenames></author><author><keyname>Liaskos</keyname><forenames>Christos</forenames></author><author><keyname>Kantartzis</keyname><forenames>Nikolaos V.</forenames></author><author><keyname>Pitsillides</keyname><forenames>Andreas</forenames></author></authors><title>3D Channel Modeling and Characterization for Hypersurface Empowered
  Indoor Environment at 60 GHz Millimeter-Wave Band</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a three-dimensional (3D) communication channel model for
an indoor environment considering the effect of the Hypersurface. The
Hypersurface is a software controlled intelligent metasurface, which can be
used to manipulate electromagnetic waves, as for example for non-specular
reflection and full absorption. Thus it can control the impinging rays from a
transmitter towards a receiver location in both LOS and NLOS paths, e.g. to
combat distance and improve wireless connectivity. We focus on the 60 GHz
mmWave frequency band due to its increasing significance in 5G/6G networks and
evaluate the effect of Hypersurface in an indoor environment in terms of
attenuation coefficients related to the Hypersurface reflection and absorption
functionalities, using CST simulation, a 3D electromagnetic simulator of high
frequency components. To highlight the benefits of Hypersurface coated walls
versus plain walls, we use the derived Hypersurface 3D channel model and a
custom 3D ray-tracing simulator for plain walls considering a typical indoor
scenario for different Tx-Rx location and separation distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00039</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00039</id><created>2019-06-28</created><authors><author><keyname>Eriksen</keyname><forenames>Bj&#xf8;rn-Olav H.</forenames></author><author><keyname>Breivik</keyname><forenames>Morten</forenames></author><author><keyname>Wilthil</keyname><forenames>Erik F.</forenames></author><author><keyname>Fl&#xe5;ten</keyname><forenames>Andreas L.</forenames></author><author><keyname>Brekke</keyname><forenames>Edmund F.</forenames></author></authors><title>The Branching-Course MPC Algorithm for Maritime Collision Avoidance</title><categories>eess.SY cs.SY</categories><comments>Submitted to Journal of Field Robotics</comments><journal-ref>Journal of Field Robotics 36 (2019) 1222-1249</journal-ref><doi>10.1002/rob.21900</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a new algorithm for short-term maritime collision
avoidance (COLAV) named the branching-course MPC (BC-MPC) algorithm. The
algorithm is designed to be robust with respect to noise on obstacle estimates,
which is a significant source of disturbance when using exteroceptive sensors
such as e.g. radars for obstacle detection and tracking. Exteroceptive sensors
do not require vessel-to-vessel communication, which enables COLAV toward
vessels not equipped with e.g. automatic identification system (AIS)
transponders, in addition to increasing the robustness with respect to faulty
information which may be provided by other vessels. The BC-MPC algorithm is
compliant with rules 8 and 17 of the International Regulations for Preventing
Collisions at Sea (COLREGs), and favors maneuvers following rules 13-15. This
results in a COLREGs-aware algorithm which can ignore rules 13-15 when
necessary. The algorithm is experimentally validated in several full-scale
experiments in the Trondheimsfjord in 2017 using a radar-based system for
obstacle detection and tracking. The COLAV experiments show good performance in
compliance with the desired algorithm behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00058</identifier>
 <datestamp>2020-01-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00058</id><created>2019-06-28</created><updated>2020-01-04</updated><authors><author><keyname>Biffi</keyname><forenames>Carlo</forenames></author><author><keyname>Cerrolaza</keyname><forenames>Juan J.</forenames></author><author><keyname>Tarroni</keyname><forenames>Giacomo</forenames></author><author><keyname>Bai</keyname><forenames>Wenjia</forenames></author><author><keyname>de Marvao</keyname><forenames>Antonio</forenames></author><author><keyname>Oktay</keyname><forenames>Ozan</forenames></author><author><keyname>Ledig</keyname><forenames>Christian</forenames></author><author><keyname>Folgoc</keyname><forenames>Loic Le</forenames></author><author><keyname>Kamnitsas</keyname><forenames>Konstantinos</forenames></author><author><keyname>Doumou</keyname><forenames>Georgia</forenames></author><author><keyname>Duan</keyname><forenames>Jinming</forenames></author><author><keyname>Prasad</keyname><forenames>Sanjay K.</forenames></author><author><keyname>Cook</keyname><forenames>Stuart A.</forenames></author><author><keyname>O'Regan</keyname><forenames>Declan P.</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author></authors><title>Explainable Anatomical Shape Analysis through Deep Hierarchical
  Generative Models</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted for publication in IEEE Transactions on Medical Imaging
  (TMI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantification of anatomical shape changes currently relies on scalar global
indexes which are largely insensitive to regional or asymmetric modifications.
Accurate assessment of pathology-driven anatomical remodeling is a crucial step
for the diagnosis and treatment of many conditions. Deep learning approaches
have recently achieved wide success in the analysis of medical images, but they
lack interpretability in the feature extraction and decision processes. In this
work, we propose a new interpretable deep learning model for shape analysis. In
particular, we exploit deep generative networks to model a population of
anatomical segmentations through a hierarchy of conditional latent variables.
At the highest level of this hierarchy, a two-dimensional latent space is
simultaneously optimised to discriminate distinct clinical conditions, enabling
the direct visualisation of the classification space. Moreover, the anatomical
variability encoded by this discriminative latent space can be visualised in
the segmentation space thanks to the generative properties of the model, making
the classification task transparent. This approach yielded high accuracy in the
categorisation of healthy and remodelled left ventricles when tested on unseen
segmentations from our own multi-centre dataset as well as in an external
validation set, and on hippocampi from healthy controls and patients with
Alzheimer's disease when tested on ADNI data. More importantly, it enabled the
visualisation in three-dimensions of both global and regional anatomical
features which better discriminate between the conditions under exam. The
proposed approach scales effectively to large populations, facilitating
high-throughput analysis of normal anatomy and pathology in large-scale studies
of volumetric imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00068</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00068</id><created>2019-06-28</created><authors><author><keyname>Kuang</keyname><forenames>Dongyang</forenames></author></authors><title>On Reducing Negative Jacobian Determinant of the Deformation Predicted
  by Deep Registration Networks</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image registration is a fundamental step in medical image analysis. Ideally,
the transformation that registers one image to another should be a
diffeomorphism that is both invertible and smooth. Traditional methods like
geodesic shooting approach the problem via differential geometry, with
theoretical guarantees that the resulting transformation will be smooth and
invertible. Most previous research using unsupervised deep neural networks for
registration have used a local smoothness constraint (typically, a spatial
variation loss) to address the smoothness issue. These networks usually produce
non-invertible transformations with ``folding'' in multiple voxel locations,
indicated by a negative determinant of the Jacobian matrix of the
transformation. While using a loss function that specifically penalizes the
folding is a straightforward solution, this usually requires carefully tuning
the regularization strength, especially when there are also other losses. In
this paper we address this problem from a different angle, by investigating
possible training mechanisms that will help the network avoid negative
Jacobians and produce smoother deformations. We contribute two independent
ideas in this direction. Both ideas greatly reduce the number of folding
locations in the predicted deformation, without making changes to the
hyperparameters or the architecture used in the existing baseline registration
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00069</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00069</id><created>2019-06-28</created><authors><author><keyname>Kuang</keyname><forenames>Dongyang</forenames></author></authors><title>A 1d convolutional network for leaf and time series classification</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a 1d convolutional neural network is designed for
classification tasks of leaves with centroid contour distance curve (CCDC) as
the single feature. With this classifier, simple feature as CCDC shows more
discriminating power than people thought previously. The same architecture can
also be applied for classifying 1 dimensional time series with little changes.
Experiments on some benchmark datasets shows this architecture can provide
classification accuracies that are higher than some existing methods. Code for
the paper is available at https://github.com/dykuang/Leaf Project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00081</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00081</id><created>2019-06-28</created><authors><author><keyname>Rusu</keyname><forenames>Cristian</forenames></author></authors><title>A Note on Shift Retrieval Problems</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1812.01115</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we discuss the shift retrieval problems, both classical and
compressed, and provide connections between them using circulant matrices. We
review the properties of circulant matrices necessary for our calculations and
then show how shifts can be recovered from a single measurement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00098</identifier>
 <datestamp>2019-12-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00098</id><created>2019-06-28</created><updated>2019-12-06</updated><authors><author><keyname>Wu</keyname><forenames>Min</forenames></author><author><keyname>Kwiatkowska</keyname><forenames>Marta</forenames></author></authors><title>Robustness Guarantees for Deep Neural Networks on Videos</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread adoption of deep learning models places demands on their
robustness. In this paper, we consider the robustness of deep neural networks
on videos, which comprise both the spatial features of individual frames
extracted by a convolutional neural network and the temporal dynamics between
adjacent frames captured by a recurrent neural network. To measure robustness,
we study the maximum safe radius problem, which computes the minimum distance
from the optical flow set obtained from a given input to that of an adversarial
example in the norm ball. We demonstrate that, under the assumption of
Lipschitz continuity, the problem can be approximated using finite optimisation
via discretising the optical flow space, and the approximation has provable
guarantees. We then show that the finite optimisation problem can be solved by
utilising a two-player turn-based game in a cooperative setting, where the
first player selects the optical flows and the second player determines the
dimensions to be manipulated in the chosen flow. We employ an anytime approach
to solve the game, in the sense of approximating the value of the game by
monotonically improving its upper and lower bounds. We exploit a gradient-based
search algorithm to compute the upper bounds, and the admissible A* algorithm
to update the lower bounds. Finally, we evaluate our framework on the UCF101
video dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00106</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00106</id><created>2019-06-28</created><updated>2019-09-17</updated><authors><author><keyname>Turan</keyname><forenames>Berkay</forenames></author><author><keyname>Tucker</keyname><forenames>Nathaniel</forenames></author><author><keyname>Alizadeh</keyname><forenames>Mahnoosh</forenames></author></authors><title>Smart Charging Benefits in Autonomous Mobility on Demand Systems</title><categories>eess.SY cs.SY</categories><comments>9 pages, 1 figure, ITSC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the potential benefits from smart charging for a
fleet of electric vehicles (EVs) providing autonomous mobility-on-demand (AMoD)
services. We first consider a profit-maximizing platform operator who makes
decisions for routing, charging, rebalancing, and pricing for rides based on a
network flow model. Clearly, each of these decisions directly influence the
fleet's smart charging potential; however, it is not possible to directly
characterize the effects of various system parameters on smart charging under a
classical network flow model. As such, we propose a modeling variation that
allows us to decouple the charging and routing problems faced by the operator.
This variation allows us to provide closed-form mathematical expressions
relating the charging costs to the maximum battery capacity of the vehicles as
well as the fleet operational costs. We show that investing in larger battery
capacities and operating more vehicles for rebalancing reduces the charging
costs, while increasing the fleet operational costs. Hence, we study the
trade-off the operator faces, analyze the minimum cost fleet charging strategy,
and provide numerical results illustrating the smart charging benefits to the
operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00112</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00112</id><created>2019-06-28</created><authors><author><keyname>Mitra</keyname><forenames>Vikramjit</forenames></author><author><keyname>Booker</keyname><forenames>Sue</forenames></author><author><keyname>Marchi</keyname><forenames>Erik</forenames></author><author><keyname>Farrar</keyname><forenames>David Scott</forenames></author><author><keyname>Peitz</keyname><forenames>Ute Dorothea</forenames></author><author><keyname>Cheng</keyname><forenames>Bridget</forenames></author><author><keyname>Teves</keyname><forenames>Ermine</forenames></author><author><keyname>Mehta</keyname><forenames>Anuj</forenames></author><author><keyname>Naik</keyname><forenames>Devang</forenames></author></authors><title>Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect
  Expression from Voice</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>5 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Millions of people reach out to digital assistants such as Siri every day,
asking for information, making phone calls, seeking assistance, and much more.
The expectation is that such assistants should understand the intent of the
users query. Detecting the intent of a query from a short, isolated utterance
is a difficult task. Intent cannot always be obtained from speech-recognized
transcriptions. A transcription driven approach can interpret what has been
said but fails to acknowledge how it has been said, and as a consequence, may
ignore the expression present in the voice. Our work investigates whether a
system can reliably detect vocal expression in queries using acoustic and
paralinguistic embedding. Results show that the proposed method offers a
relative equal error rate (EER) decrease of 60% compared to a bag-of-word based
system, corroborating that expression is significantly represented by vocal
attributes, rather than being purely lexical. Addition of emotion embedding
helped to reduce the EER by 30% relative to the acoustic embedding,
demonstrating the relevance of emotion in expressive voice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00126</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00126</id><created>2019-06-28</created><updated>2020-02-03</updated><authors><author><keyname>Rahmani</keyname><forenames>Babak</forenames></author><author><keyname>Loterie</keyname><forenames>Damien</forenames></author><author><keyname>Kakkava</keyname><forenames>Eirini</forenames></author><author><keyname>Borhani</keyname><forenames>Navid</forenames></author><author><keyname>Te&#x11f;in</keyname><forenames>U&#x11f;ur</forenames></author><author><keyname>Psaltis</keyname><forenames>Demetri</forenames></author><author><keyname>Moser</keyname><forenames>Christophe</forenames></author></authors><title>Competing Neural Networks for Robust Control of Nonlinear Systems</title><categories>physics.optics cs.LG eess.IV</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The output of physical systems is often accessible by measurements such as
the 3D position of a robotic arm actuated by many actuators or the speckle
patterns formed by shining the spot of a laser pointer on a wall. The selection
of the input of such a system (actuators and the shape of the laser spot
respectively) to obtain a desired output is difficult because it is an
ill-posed problem i.e. there are multiple inputs yielding the same output. In
this paper, we propose an approach that provides a robust solution to this
dilemma for any physical system. We show that it is possible to find the
appropriate input of a system that results in a desired output, despite the
input-output relation being nonlinear and\or with incomplete measurements of
the systems variables. We showcase our approach using an extremely ill-posed
problem in imaging. We demonstrate the projection of arbitrary shapes through a
multimode fiber (MMF) when a sample of intensity-only measurements are taken at
the output. We show image projection fidelity as high as ~90 %, which is on par
with the gold standard methods which characterize the system fully by phase and
amplitude measurements. The generality as well as simplicity of the proposed
approach provides a new way of target-oriented control in real-world
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00190</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00190</id><created>2019-06-29</created><authors><author><keyname>He</keyname><forenames>Xingkang</forenames></author><author><keyname>Johansson</keyname><forenames>Karl Henrik</forenames></author><author><keyname>Fang</keyname><forenames>Haitao</forenames></author></authors><title>Distributed Design of Robust Kalman Filters over Corrupted Channels</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The robust state estimation problem is on how to design robust filters for
estimating an unknown state of uncertain systems. This paper considers this
problem for multi-agent systems with multiplicative noise and degraded
measurements over corrupted channels. Employing a covariance intersection
fusion method, we propose a distributed robust Kalman filter with stochastic
gains, which enables a sequence of upper bounds of conditional mean square
error given channel noise to be calculated online. Considering the limitation
of step-wise optimization, for better performance, we propose a switching
fusion scheme based on a sliding window method, which provides an online design
of covariance intersection weights by solving a semi-definite programming
problem. Compared to the filter fusing latest estimates, the one based on the
switching fusion method has a smaller upper bound of the conditional mean
square error. We present a robust collective observability condition, which
degenerates to the traditional collective observability condition for
time-varying stochastic systems if there is no measurement degradation or
multiplicative noise. Under this condition and strong connectivity, we prove
that the mean square errors of two filters are both uniformly upper bounded by
a constant matrix over a finite transient time, which depends on the system
observability and the network size. Different to existing results, some
requirements including stability for the systems and observability of the
sub-systems are not needed for our results. Finally, a numerical simulation is
provided to validate the theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00198</identifier>
 <datestamp>2020-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00198</id><created>2019-06-29</created><updated>2019-07-14</updated><authors><author><keyname>Eriksen</keyname><forenames>Bj&#xf8;rn-Olav H.</forenames></author><author><keyname>Bitar</keyname><forenames>Glenn</forenames></author><author><keyname>Breivik</keyname><forenames>Morten</forenames></author><author><keyname>Lekkas</keyname><forenames>Anastasios M.</forenames></author></authors><title>Hybrid Collision Avoidance for ASVs Compliant with COLREGs Rules 8 and
  13-17</title><categories>eess.SY cs.SY</categories><comments>Submitted to Frontiers in Robotics and AI</comments><journal-ref>Frontiers in Robotics and AI: 7(11), 2020, 1-18</journal-ref><doi>10.3389/frobt.2020.00011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a three-layered hybrid collision avoidance (COLAV) system
for autonomous surface vehicles, compliant with rules 8 and 13-17 of the
International Regulations for Preventing Collisions at Sea (COLREGs). The COLAV
system consists of a high-level planner producing an energy-optimized
trajectory, a model predictive control based mid-level COLAV algorithm
considering moving obstacles and the COLREGs, and the branching-course model
predictive control algorithm for short-term COLAV handling emergency situations
in accordance with the COLREGs. Previously developed algorithms by the authors
are used for the high-level planner and short-term COLAV, while we in this
paper further develop the mid-level algorithm to make it comply with COLREGs
rules 13-17. This includes developing a state machine for classifying obstacle
vessels using a combination of the geometrical situation, the distance and time
to the closest point of approach (CPA) and a new CPA-like measure. The
performance of the hybrid COLAV system is tested through numerical simulations
for three scenarios representing a range of different challenges, including
multi-obstacle situations with multiple simultaneously active COLREGs rules,
and also obstacles ignoring the COLREGs. The COLAV system avoids collision in
all the scenarios, and follows the energy-optimized trajectory when the
obstacles do not interfere with it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00209</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00209</id><created>2019-06-29</created><authors><author><keyname>Chen</keyname><forenames>XiaoYu</forenames></author><author><keyname>Wang</keyname><forenames>Xu</forenames></author><author><keyname>Bai</keyname><forenames>Lianfa</forenames></author><author><keyname>Han</keyname><forenames>Jing</forenames></author><author><keyname>Zhao</keyname><forenames>Zhuang</forenames></author></authors><title>High Sensitivity Snapshot Spectrometer Based on Deep Network Unmixing</title><categories>eess.IV cs.CV</categories><comments>16 pages, 13 figures and 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a convolution neural network based method to
recover the light intensity distribution from the overlapped dispersive spectra
instead of adding an extra light path to capture it directly for the first
time. Then, we construct a single-path sub-Hadamard snapshot spectrometer based
on our previous dual-path snapshot spectrometer. In the proposed single-path
spectrometer, we use the reconstructed light intensity as the original light
intensity and recover high signal-to-noise ratio spectra successfully. Compared
with dual-path snapshot spectrometer, the network based single-path
spectrometer has a more compact structure and maintains snapshot and high
sensitivity. Abundant simulated and experimental results have demonstrated that
the proposed method can obtain a better reconstructed signal-to-noise ratio
spectrum than the dual-path sub-Hadamard spectrometer because of its higher
light throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00220</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00220</id><created>2019-06-29</created><authors><author><keyname>Yang</keyname><forenames>Qingkai</forenames></author><author><keyname>Fang</keyname><forenames>Hao</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Jiang</keyname><forenames>Zhong-Ping</forenames></author><author><keyname>Cao</keyname><forenames>Ming</forenames></author></authors><title>Distributed Global Output-Feedback Control for a Class of Euler-Lagrange
  Systems</title><categories>eess.SY cs.RO cs.SY</categories><comments>The original published paper and its errata are presented</comments><journal-ref>IEEE Transactions on Automatic Control, vol. 62, no, 9, pp.
  4855-4861, 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This published paper investigates the distributed tracking control problem
for a class of Euler-Lagrange multi-agent systems when the agents can only
measure the positions. In this case, the lack of the separation principle and
the strong nonlinearity in unmeasurable states pose severe technical challenges
to global output-feedback control design. To overcome these difficulties, a
global nonsingular coordinate transformation matrix in the upper triangular
form is firstly proposed such that the nonlinear dynamic model can be partially
linearized with respect to the unmeasurable states. And, a new type of velocity
observers is designed to estimate the unmeasurable velocities for each system.
Then, based on the outputs of the velocity observers, we propose distributed
control laws that enable the coordinated tracking control system to achieve
uniform global exponential stability (UGES). Both theoretical analysis and
numerical simulations are presented to validate the effectiveness of the
proposed control scheme. Followed by the original paper, a typo and a mistake
is corrected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00242</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00242</id><created>2019-06-29</created><authors><author><keyname>Sriram</keyname><forenames>Ajay</forenames></author><author><keyname>Masoudi</keyname><forenames>Meysam</forenames></author><author><keyname>Alabbasi</keyname><forenames>Abdulrahman</forenames></author><author><keyname>Cavdar</keyname><forenames>Cicek</forenames></author></authors><title>Joint Functional Splitting and Content Placement for Green Hybrid CRAN</title><categories>cs.NI eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A hybrid cloud radio access network (H-CRAN) architecture has been proposed
to alleviate the midhaul capacity limitation in C-RAN. In this architecture,
functional splitting is utilized to distribute the processing functions between
a central cloud and edge clouds. The flexibility of selecting specific split
point enables the H-CRAN designer to reduce midhaul bandwidth, or reduce
latency, or save energy, or distribute the computation task depending on
equipment availability. Meanwhile, techniques for caching are proposed to
reduce content delivery latency and the required bandwidth. However, caching
imposes new constraints on functional splitting. In this study, considering
H-CRAN, a constraint programming problem is formulated to minimize the overall
power consumption by selecting the optimal functional split point and content
placement, taking into account the content access delay constraint. We also
investigate the trade-off between the overall power consumption and occupied
midhaul bandwidth in the network. Our results demonstrate that functional
splitting together with enabling caching at edge clouds reduces not only
content access delays but also fronthaul bandwidth consumption but at the
expense of higher power consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00273</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00273</id><created>2019-06-29</created><authors><author><keyname>Lin</keyname><forenames>Wei-An</forenames></author><author><keyname>Liao</keyname><forenames>Haofu</forenames></author><author><keyname>Peng</keyname><forenames>Cheng</forenames></author><author><keyname>Sun</keyname><forenames>Xiaohang</forenames></author><author><keyname>Zhang</keyname><forenames>Jingdan</forenames></author><author><keyname>Luo</keyname><forenames>Jiebo</forenames></author><author><keyname>Chellappa</keyname><forenames>Rama</forenames></author><author><keyname>Zhou</keyname><forenames>Shaohua Kevin</forenames></author></authors><title>DuDoNet: Dual Domain Network for CT Metal Artifact Reduction</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Computed tomography (CT) is an imaging modality widely used for medical
diagnosis and treatment. CT images are often corrupted by undesirable artifacts
when metallic implants are carried by patients, which creates the problem of
metal artifact reduction (MAR). Existing methods for reducing the artifacts due
to metallic implants are inadequate for two main reasons. First, metal
artifacts are structured and non-local so that simple image domain enhancement
approaches would not suffice. Second, the MAR approaches which attempt to
reduce metal artifacts in the X-ray projection (sinogram) domain inevitably
lead to severe secondary artifact due to sinogram inconsistency. To overcome
these difficulties, we propose an end-to-end trainable Dual Domain Network
(DuDoNet) to simultaneously restore sinogram consistency and enhance CT images.
The linkage between the sigogram and image domains is a novel Radon inversion
layer that allows the gradients to back-propagate from the image domain to the
sinogram domain during training. Extensive experiments show that our method
achieves significant improvements over other single domain MAR approaches. To
the best of our knowledge, it is the first end-to-end dual-domain network for
MAR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00281</identifier>
 <datestamp>2020-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00281</id><created>2019-06-29</created><updated>2020-02-19</updated><authors><author><keyname>Kao</keyname><forenames>Po-Yu</forenames></author><author><keyname>Chen</keyname><forenames>Jefferson W.</forenames></author><author><keyname>Manjunath</keyname><forenames>B. S.</forenames></author></authors><title>Improving 3D U-Net for Brain Tumor Segmentation by Utilizing Lesion
  Prior</title><categories>cs.CV cs.LG eess.IV</categories><comments>5 pages, 4 figures, 1 table, LNCS format</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose a novel, simple and effective method to integrate lesion prior and
a 3D U-Net for improving brain tumor segmentation. First, we utilize the
ground-truth brain tumor lesions from a group of patients to generate the
heatmaps of different types of lesions. These heatmaps are used to create the
volume-of-interest (VOI) map which contains prior information about brain tumor
lesions. The VOI map is then integrated with the multimodal MR images and input
to a 3D U-Net for segmentation. The proposed method is evaluated on a public
benchmark dataset, and the experimental results show that the proposed feature
fusion method achieves an improvement over the baseline methods. In addition,
our proposed method also achieves a competitive performance compared to
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00283</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00283</id><created>2019-06-29</created><authors><author><keyname>Chen</keyname><forenames>Richard J.</forenames></author><author><keyname>Bobrow</keyname><forenames>Taylor L.</forenames></author><author><keyname>Athey</keyname><forenames>Thomas</forenames></author><author><keyname>Mahmood</keyname><forenames>Faisal</forenames></author><author><keyname>Durr</keyname><forenames>Nicholas J.</forenames></author></authors><title>SLAM Endoscopy enhanced by adversarial depth prediction</title><categories>eess.IV cs.CV cs.RO</categories><report-no>KDD'19 Workshop on Applied Data Science for Healthcare</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical endoscopy remains a challenging application for simultaneous
localization and mapping (SLAM) due to the sparsity of image features and size
constraints that prevent direct depth-sensing. We present a SLAM approach that
incorporates depth predictions made by an adversarially-trained convolutional
neural network (CNN) applied to monocular endoscopy images. The depth network
is trained with synthetic images of a simple colon model, and then fine-tuned
with domain-randomized, photorealistic images rendered from computed tomography
measurements of human colons. Each image is paired with an error-free depth map
for supervised adversarial learning. Monocular RGB images are then fused with
corresponding depth predictions, enabling dense reconstruction and mosaicing as
an endoscope is advanced through the gastrointestinal tract. Our preliminary
results demonstrate that incorporating monocular depth estimation into a SLAM
architecture can enable dense reconstruction of endoscopic scenes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00294</identifier>
 <datestamp>2019-12-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00294</id><created>2019-06-29</created><updated>2019-11-27</updated><authors><author><keyname>Liao</keyname><forenames>Haofu</forenames></author><author><keyname>Lin</keyname><forenames>Wei-An</forenames></author><author><keyname>Huo</keyname><forenames>Zhimin</forenames></author><author><keyname>Vogelsang</keyname><forenames>Levon</forenames></author><author><keyname>Sehnert</keyname><forenames>William J.</forenames></author><author><keyname>Zhou</keyname><forenames>S. Kevin</forenames></author><author><keyname>Luo</keyname><forenames>Jiebo</forenames></author></authors><title>Generative Mask Pyramid Network for CT/CBCT Metal Artifact Reduction
  with Joint Projection-Sinogram Correction</title><categories>eess.IV cs.CV</categories><comments>This paper is accepted to MICCAI 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  A conventional approach to computed tomography (CT) or cone beam CT (CBCT)
metal artifact reduction is to replace the X-ray projection data within the
metal trace with synthesized data. However, existing projection or sinogram
completion methods cannot always produce anatomically consistent information to
fill the metal trace, and thus, when the metallic implant is large, significant
secondary artifacts are often introduced. In this work, we propose to replace
metal artifact affected regions with anatomically consistent content through
joint projection-sinogram correction as well as adversarial learning. To handle
the metallic implants of diverse shapes and large sizes, we also propose a
novel mask pyramid network that enforces the mask information across the
network's encoding layers and a mask fusion loss that reduces early saturation
of adversarial training. Our experimental results show that the proposed
projection-sinogram correction designs are effective and our method recovers
information from the metal traces better than the state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00300</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00300</id><created>2019-06-29</created><updated>2019-09-14</updated><authors><author><keyname>Li</keyname><forenames>Heyi</forenames></author><author><keyname>Chen</keyname><forenames>Dongdong</forenames></author><author><keyname>Nailon</keyname><forenames>William H.</forenames></author><author><keyname>Davies</keyname><forenames>Mike E.</forenames></author><author><keyname>Laurenson</keyname><forenames>David I.</forenames></author></authors><title>Signed Laplacian Deep Learning with Adversarial Augmentation for
  Improved Mammography Diagnosis</title><categories>eess.IV cs.LG stat.ML</categories><comments>To appear in MICCAI October 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer-aided breast cancer diagnosis in mammography is limited by
inadequate data and the similarity between benign and cancerous masses. To
address this, we propose a signed graph regularized deep neural network with
adversarial augmentation, named \textsc{DiagNet}. Firstly, we use adversarial
learning to generate positive and negative mass-contained mammograms for each
mass class. After that, a signed similarity graph is built upon the expanded
data to further highlight the discrimination. Finally, a deep convolutional
neural network is trained by jointly optimizing the signed graph regularization
and classification loss. Experiments show that the \textsc{DiagNet} framework
outperforms the state-of-the-art in breast mass diagnosis in mammography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00322</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00322</id><created>2019-06-30</created><authors><author><keyname>Zhao</keyname><forenames>Xueyuan</forenames></author><author><keyname>Sadhu</keyname><forenames>Vidyasagar</forenames></author><author><keyname>Pompili</keyname><forenames>Dario</forenames></author></authors><title>Analog Signal Compression and Multiplexing Techniques for Healthcare
  Internet of Things</title><categories>eess.SP cs.NI</categories><comments>9 pages, IEEE MASS 2017</comments><journal-ref>2017 IEEE 14th International Conference on Mobile Ad Hoc and
  Sensor Systems (MASS), Orlando, 2017, pp. 398-406</journal-ref><doi>10.1109/MASS.2017.62</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scalability is a major issue for Internet of Things (IoT) as the total amount
of traffic data collected and/or the number of sensors deployed grow. In some
IoT applications such as healthcare, power consumption is also a key design
factor for the IoT devices. In this paper, a multi-signal compression and
encoding method based on Analog Joint Source Channel Coding (AJSCC) is proposed
that works fully in the analog domain without the need for power-hungry
Analog-to-Digital Converters (ADCs). Compression is achieved by quantizing all
the input signals but one. While saving power, this method can also reduce the
number of devices by combining one or more sensing functionalities into a
single device (called 'AJSCC device'). Apart from analog encoding, AJSCC
devices communicate to an aggregator node (FPMM receiver) using a novel
Frequency Position Modulation and Multiplexing (FPMM) technique. Such joint
modulation and multiplexing technique presents three mayor advantages---it is
robust to interference at particular frequency bands, it protects against
eavesdropping, and it consumes low power due to a very low Signal-to-Noise
Ratio (SNR) operating region at the receiver. Performance of the proposed
multi-signal compression method and FPMM technique is evaluated via simulations
in terms of Mean Square Error (MSE) and Miss Detection Rate (MDR),
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00324</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00324</id><created>2019-06-30</created><updated>2019-09-21</updated><authors><author><keyname>Rusu</keyname><forenames>Mirabela</forenames></author><author><keyname>Kunder</keyname><forenames>Christian A.</forenames></author><author><keyname>Teslovich</keyname><forenames>Nikola C.</forenames></author><author><keyname>Wang</keyname><forenames>Jeffrey B</forenames></author><author><keyname>Sood</keyname><forenames>Rewa R.</forenames></author><author><keyname>Shao</keyname><forenames>Wei</forenames></author><author><keyname>Chan</keyname><forenames>Leo C.</forenames></author><author><keyname>West</keyname><forenames>Robert</forenames></author><author><keyname>Fan</keyname><forenames>Richard</forenames></author><author><keyname>Ghanouni</keyname><forenames>Pejman</forenames></author><author><keyname>Brooks</keyname><forenames>James B.</forenames></author><author><keyname>Sonn</keyname><forenames>Geoffrey A.</forenames></author></authors><title>Registration of pre-surgical MRI and whole-mount histopathology images
  in prostate cancer patients with radical prostatectomy via RAPSODI</title><categories>eess.IV</categories><comments>version 2</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Magnetic resonance imaging (MRI) has great potential to improve prostate
cancer diagnosis. It can spare men with a normal exam from undergoing invasive
biopsy while making biopsies more accurate in men with lesions suspicious for
cancer. Yet, the subtle differences between cancer and confounding conditions,
render the interpretation of MRI challenging. The tissue collected from
patients that undergo pre-surgical MRI and radical prostatectomy provides a
unique opportunity to correlate histopathology images of the entire prostate
with MRI in order to accurately map the extent of prostate cancer onto MRI.
Here, we introduce the RAPSODI (framework for the registration of radiology and
pathology images. RAPSODI relies on a three-step procedure that first
reconstructs in 3D the resected tissue using the serial whole-mount
histopathology slices, then registers corresponding histopathology and MRI
slices, and finally maps the cancer outlines from the histopathology slices
onto MRI. We tested RAPSODI in a phantom study where we simulated various
conditions, e.g., tissue specimen rotation upon mounting on glass slides,
tissue shrinkage during fixation, or imperfect slice-to-slice correspondences
between histology and MRI. Our experiments showed that RAPSODI can reliably
correct for rotations within $\pm15^{\circ}$ and shrinkage up to 10%. We also
evaluated RAPSODI in 89 patients from two institutions that underwent radical
prostatectomy, yielding 543 histopathology slices that were registered to
corresponding T2 weighted MRI slices. We found a Dice coefficient of 0.98$ \pm
$0.01 for the prostate, prostate boundary Hausdorff distance of 1.71$ \pm $0.48
mm, a urethra deviation of 2.91$ \pm $1.25 mm, and a landmark deviation of
2.88$ \pm $0.70 mm between registered histopathology images and MRI. Our robust
framework successfully mapped the extent of disease from histopathology slices
onto MRI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00328</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00328</id><created>2019-06-30</created><authors><author><keyname>Zhao</keyname><forenames>Xueyuan</forenames></author><author><keyname>Sadhu</keyname><forenames>Vidyasagar</forenames></author><author><keyname>Le</keyname><forenames>Tuan</forenames></author><author><keyname>Pompili</keyname><forenames>Dario</forenames></author><author><keyname>Javanmard</keyname><forenames>Mehdi</forenames></author></authors><title>Towards Wireless Health Monitoring via Analog Signal Compression based
  Biosensing Platform</title><categories>eess.SP cs.ET cs.NI</categories><comments>10 pages IEEE TBioCAS Journal, Special Issue on ISCAS'17</comments><journal-ref>in IEEE Transactions on Biomedical Circuits and Systems, pp.
  461-470, June 2018</journal-ref><doi>10.1109/TBCAS.2018.2829512</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless all-analog biosensor design for concurrent microfluidic and
physiological signal monitoring is presented in this work. The key component is
an all-analog circuit capable of compressing two analog sources into one analog
signal by Analog Joint Source-Channel Coding (AJSCC). Two circuit designs are
discussed, including the stacked-Voltage Controlled Voltage Source (VCVS)
design with the fixed number of levels, and an improved design, which supports
a flexible number of AJSCC levels. Experimental results are presented on the
wireless biosensor prototype, composed of Printed Circuit Board (PCB)
realizations of the stacked-VCVS design. Furthermore, circuit simulation and
wireless link simulation results are presented on the improved design. Results
indicate that the proposed wireless biosensor is well suited for sensing two
biological signals simultaneously with high accuracy, and can be applied to a
wide variety of low-power and low-cost wireless continuous health monitoring
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00339</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00339</id><created>2019-06-30</created><authors><author><keyname>Mahmood</keyname><forenames>Mishal</forenames></author><author><keyname>Azam</keyname><forenames>Mariam</forenames></author><author><keyname>Fatima</keyname><forenames>Khair-un-Nisa</forenames></author><author><keyname>Sarwar</keyname><forenames>Muhammad</forenames></author><author><keyname>Abubakar</keyname><forenames>Muhammad</forenames></author><author><keyname>Hussain</keyname><forenames>Babar</forenames></author></authors><title>Design and Implementation of an Automatic Synchronizing and Protection
  Relay through Power-Hardware-in-the-Loop (PHIL) Simulation</title><categories>eess.SY cs.SY eess.SP</categories><comments>6 pages, 14 figures, submitted in IEEE International Symposium on
  Recent Advances in Electrical Engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the design and implementation of an automatic
synchronizing and protection relay to automate the synchronization process of a
Distributed Energy Resource (DER) to the Main Grid. The proposed design utilize
a cost-effective data acquisition using arduino in combination with LabVIEW
software to implement the multi-purpose synchronizing relay. The proposed
synchronizing relay is capable of synchronizing a Distributed Generator (DG) to
the power grid from black-start and fulfills the requirements imposed by the
utility. The synchronizing relay is implemented through voltage and frequency
control of an actual lab-scale synchronous generator. In the synchronization
process, frequency synchronization is done using speed control of the stepper
motor as prime mover and voltage synchronization is accomplished using
Excitation Control module through Power-Hardware-in-the-Loop (PHIL) simulation.
In grid-connected mode, active and reactive power controls and protection
schemes for the synchronous generator have also been implemented. The proposed
multi-function relay has been deployed and tested on a lab-scale test bed to
validate the proposed design and functionality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00344</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00344</id><created>2019-06-30</created><authors><author><keyname>Sabzian</keyname><forenames>Hossein</forenames></author><author><keyname>Hashemi</keyname><forenames>Seyyed Mostafa Seyyed</forenames></author><author><keyname>Kamrani</keyname><forenames>Ehsan</forenames></author></authors><title>Development of a novel matrix-based methodology for system engineering:
  A case study</title><categories>eess.SY cs.SY</categories><comments>22 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developing a structured method for analyzing various aspects of a system
requires a novel methodology. This study is aimed at developing such as
methodology through combining two major matrix methods, namely, Design
Structure Matrix (DSM) and Interface Structure Matrix (ISM). Through this
paper, a business process modeling method is applied to turn a real work
project to a process model. Then that process model is written in two various
matrix forms of DSM and ISM. These two matrices are analyzed by two types of
algorithm for extracting activity levels and sub-processes. In the end, a Mixed
Matrix Model (MMM) is built upon these activity levels and sub-processes, which
can be used as a framework for the engineering of real-world systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00366</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00366</id><created>2019-06-30</created><updated>2019-09-24</updated><authors><author><keyname>Alkeem</keyname><forenames>Ebrahim Al</forenames></author><author><keyname>Kim</keyname><forenames>Song-Kyoo</forenames></author><author><keyname>Yeun</keyname><forenames>Chan Yeob</forenames></author><author><keyname>Zemerly</keyname><forenames>M. Jamal</forenames></author><author><keyname>Poon</keyname><forenames>Kin</forenames></author><author><keyname>Yoo</keyname><forenames>Paul D.</forenames></author></authors><title>An Enhanced Electrocardiogram Biometric Authentication System Using
  Machine Learning</title><categories>cs.CR cs.LG eess.SP stat.ML</categories><comments>This paper has been published in the IEEE Access</comments><journal-ref>IEEE Access 7 (2019), pp. 123069-123075</journal-ref><doi>10.1109/ACCESS.2019.2937357</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional authentication systems use alphanumeric or graphical passwords,
or token-based techniques that require &quot;something you know and something you
have&quot;. The disadvantages of these systems include the risks of forgetfulness,
loss, and theft. To address these shortcomings, biometric authentication is
rapidly replacing traditional authentication methods and is becoming a part of
everyday life. The electrocardiogram (ECG) is one of the most recent traits
considered for biometric purposes. In this work we describe an ECG-based
authentication system suitable for security checks and hospital environments.
The proposed system will help investigators studying ECG-based biometric
authentication techniques to define dataset boundaries and to acquire
high-quality training data. We evaluated the performance of the proposed system
and found that it could achieve up to the 92 percent identification accuracy.
In addition, by applying the Amang ECG (amgecg) toolbox within MATLAB, we
investigated the two parameters that directly affect the accuracy of
authentication: the ECG slicing time (sliding window) and the sampling time
period, and found their optimal values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00374</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00374</id><created>2019-06-30</created><authors><author><keyname>Morgulis</keyname><forenames>Nir</forenames></author><author><keyname>Kreines</keyname><forenames>Alexander</forenames></author><author><keyname>Mendelowitz</keyname><forenames>Shachar</forenames></author><author><keyname>Weisglass</keyname><forenames>Yuval</forenames></author></authors><title>Fooling a Real Car with Adversarial Traffic Signs</title><categories>cs.CR cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The attacks on the neural-network-based classifiers using adversarial images
have gained a lot of attention recently. An adversary can purposely generate an
image that is indistinguishable from a innocent image for a human being but is
incorrectly classified by the neural networks. The adversarial images do not
need to be tuned to a particular architecture of the classifier - an image that
fools one network can fool another one with a certain success rate.The
published works mostly concentrate on the use of modified image files for
attacks against the classifiers trained on the model databases. Although there
exists a general understanding that such attacks can be carried in the real
world as well, the works considering the real-world attacks are scarce.
Moreover, to the best of our knowledge, there have been no reports on the
attacks against real production-grade image classification systems.In our work
we present a robust pipeline for reproducible production of adversarial traffic
signs that can fool a wide range of classifiers, both open-source and
production-grade in the real world. The efficiency of the attacks was checked
both with the neural-network-based classifiers and legacy computer vision
systems. Most of the attacks have been performed in the black-box mode, e.g.
the adversarial signs produced for a particular classifier were used to attack
a variety of other classifiers. The efficiency was confirmed in drive-by
experiments with a production-grade traffic sign recognition systems of a real
car.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00382</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00382</id><created>2019-06-30</created><authors><author><keyname>Singh</keyname><forenames>Saket</forenames></author><author><keyname>Sheet</keyname><forenames>Debdoot</forenames></author><author><keyname>Dasgupta</keyname><forenames>Mithun</forenames></author></authors><title>Adversarially Trained Deep Neural Semantic Hashing Scheme for Subjective
  Search in Fashion Inventory</title><categories>cs.CV cs.LG eess.IV</categories><comments>The paper comprises of 8 Pages that contain 9 figures and 3 tables to
  support the work. The paper got accepted in the ACM's 25th KDD conference's
  workshop titled AI for fashion</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The simple approach of retrieving a closest match of a query image from one
in the gallery, compares an image pair using sum of absolute difference in
pixel or feature space. The process is computationally expensive, ill-posed to
illumination, background composition, pose variation, as well as inefficient to
be deployed on gallery sets with more than 1000 elements. Hashing is a faster
alternative which involves representing images in reduced dimensional simple
feature spaces. Encoding images into binary hash codes enables similarity
comparison in an image-pair using the Hamming distance measure. The challenge,
however, lies in encoding the images using a semantic hashing scheme that lets
subjective neighbors lie within the tolerable Hamming radius. This work
presents a solution employing adversarial learning of a deep neural semantic
hashing network for fashion inventory retrieval. It consists of a feature
extracting convolutional neural network (CNN) learned to (i) minimize error in
classifying type of clothing, (ii) minimize hamming distance between semantic
neighbors and maximize distance between semantically dissimilar images, (iii)
maximally scramble a discriminator's ability to identify the corresponding hash
code-image pair when processing a semantically similar query-gallery image
pair. Experimental validation for fashion inventory search yields a mean
average precision (mAP) of 90.65% in finding the closest match as compared to
53.26% obtained by the prior art of deep Cauchy hashing for hamming space
retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00388</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00388</id><created>2019-06-30</created><authors><author><keyname>Xiao</keyname><forenames>Jiadong</forenames></author><author><keyname>Li</keyname><forenames>Lin</forenames></author><author><keyname>Zou</keyname><forenames>Yanbiao</forenames></author><author><keyname>Zhang</keyname><forenames>Tie</forenames></author></authors><title>Reinforcement Learning for Robotic Time-optimal Path Tracking Using
  Prior Knowledge</title><categories>cs.RO cs.SY eess.SY</categories><comments>27 pages, 14 figures, 4 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time-optimal path tracking, as a significant tool for industrial robots, has
attracted the attention of numerous researchers. In most time-optimal path
tracking problems, the actuator torque constraints are assumed to be
conservative, which ignores the motor characteristic; i.e., the actuator torque
constraints are velocity-dependent, and the relationship between torque and
velocity is piecewise linear. However, considering that the motor
characteristics increase the solving difficulty, in this study, an improved
Q-learning algorithm for robotic time-optimal path tracking using prior
knowledge is proposed. After considering the limitations of the Q-learning
algorithm, an improved action-value function is proposed to improve the
convergence rate. The proposed algorithms use the idea of reward and penalty,
rewarding the actions that satisfy constraint conditions and penalizing the
actions that break constraint conditions, to finally obtain a time-optimal
trajectory that satisfies the constraint conditions. The effectiveness of the
algorithms is verified by experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00390</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00390</id><created>2019-06-30</created><authors><author><keyname>E</keyname><forenames>Haihong</forenames></author><author><keyname>Niu</keyname><forenames>Peiqing</forenames></author><author><keyname>Chen</keyname><forenames>Zhongfu</forenames></author><author><keyname>Song</keyname><forenames>Meina</forenames></author></authors><title>A Novel Bi-directional Interrelated Model for Joint Intent Detection and
  Slot Filling</title><categories>cs.CL cs.AI eess.AS</categories><comments>Accepted paper of ACL 2019 (short paper) with 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A spoken language understanding (SLU) system includes two main tasks, slot
filling (SF) and intent detection (ID). The joint model for the two tasks is
becoming a tendency in SLU. But the bi-directional interrelated connections
between the intent and slots are not established in the existing joint models.
In this paper, we propose a novel bi-directional interrelated model for joint
intent detection and slot filling. We introduce an SF-ID network to establish
direct connections for the two tasks to help them promote each other mutually.
Besides, we design an entirely new iteration mechanism inside the SF-ID network
to enhance the bi-directional interrelated connections. The experimental
results show that the relative improvement in the sentence-level semantic frame
accuracy of our model is 3.79% and 5.42% on ATIS and Snips datasets,
respectively, compared to the state-of-the-art model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00391</identifier>
 <datestamp>2019-11-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00391</id><created>2019-06-30</created><updated>2019-11-08</updated><authors><author><keyname>Gholipoor</keyname><forenames>Narges</forenames></author><author><keyname>Saeedi</keyname><forenames>Hamid</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Jorswieck</keyname><forenames>Eduard</forenames></author></authors><title>E2E Delay Guarantee for the Tactile Internet via joint NFV and Radio
  Resource Allocation</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Tactile Internet (TI) is one of the next generation wireless network
services with end to end (E2E) delay as low as 1~ms. Since this ultra low E2E
delay cannot be met in the current 4G network architecture, it is necessary to
investigate this service in the next generation wireless network by considering
new technologies such as network function virtualization (NFV). On the other
hand, given the importance of E2E delay in the TI service, it is crucial to
consider the delay of all parts of the network, including the radio access part
and the NFV core part. In this paper, for the first time, we investigate the
joint radio resource allocation (R-RA) and NFV resource allocation (NFV-RA) in
a heterogeneous network where queuing delays, transmission delays, and delays
resulting from virtual network function (VNF) execution are jointly considered.
For this setup, we formulate a new resource allocation (RA) problem to minimize
the total cost function subject to guaranteeing E2E delay of each user. Since
the proposed optimization problem is highly non-convex, we exploit alternative
search method (ASM), successive convex approximation (SCA), and heuristic
algorithms to solve it. Simulation results reveal that in the proposed scheme
can significantly reduce the network costs compared to the case where the two
problems are optimized separately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00422</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00422</id><created>2019-06-30</created><updated>2020-02-22</updated><authors><author><keyname>Zhong</keyname><forenames>Zijia</forenames></author><author><keyname>Lee</keyname><forenames>Joyoung</forenames></author><author><keyname>Zhao</keyname><forenames>Liuhui</forenames></author></authors><title>Dedicated Lane for Connected and Automated Vehicle: How Much Does A
  Homogeneous Traffic Flow Contribute?</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dedicated lanes for connected and automated vehicles (CAVs) can provide not
only the technological accommodation but also the desired market incentive for
road user to adapt CAVs. Thus far, the majority of the impact assessment of CAV
focused on the network-wide benefits. In this paper, we investigate the change
of the traffic flow characteristics with two configurations of CAV lane across
levels of market penetration. The traffic flow characteristics are quantified
from the perspectives of lane-level headway distribution, communication
density, and overall network performance. The results highlight the
contributions of the CAV lane. First, a CAV lane significantly improves the
speed-flow characteristics by extending the stable region of the speed-flow
curve and yielding a greater optimum flow. The highest value of optimum flow is
3400 vehicles per lane per hour at 90% MPR with one CAV lane. Furthermore, the
concentration of CAVs at a lane results in a narrower headway distribution
(with smaller standard deviation), even with partial market penetration. The
duel-bell-shape distribution, resulted from heterogeneous traffic flow remains
even at 60-80% market penetration. In comparison, such duel-bell-shape
distribution is not observed in both dedicated lane cases. Moreover, the CAV
lane creates a more consistent CAV density which maintains the communication
density level at a predictable level, hence decreasing the probability of
packet drop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00437</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00437</id><created>2019-06-30</created><authors><author><keyname>LaLonde</keyname><forenames>Rodney</forenames></author><author><keyname>Tanner</keyname><forenames>Irene</forenames></author><author><keyname>Nikiforaki</keyname><forenames>Katerina</forenames></author><author><keyname>Papadakis</keyname><forenames>Georgios Z.</forenames></author><author><keyname>Kandel</keyname><forenames>Pujan</forenames></author><author><keyname>Bolan</keyname><forenames>Candice W.</forenames></author><author><keyname>Wallace</keyname><forenames>Michael B.</forenames></author><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author></authors><title>INN: Inflated Neural Networks for IPMN Diagnosis</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>Accepted for publication at MICCAI 2019 (22nd International
  Conference on Medical Image Computing and Computer Assisted Intervention).
  Code is publicly available at
  https://github.com/lalonderodney/INN-Inflated-Neural-Nets</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intraductal papillary mucinous neoplasm (IPMN) is a precursor to pancreatic
ductal adenocarcinoma. While over half of patients are diagnosed with
pancreatic cancer at a distant stage, patients who are diagnosed early enjoy a
much higher 5-year survival rate of $34\%$ compared to $3\%$ in the former;
hence, early diagnosis is key. Unique challenges in the medical imaging domain
such as extremely limited annotated data sets and typically large 3D volumetric
data have made it difficult for deep learning to secure a strong foothold. In
this work, we construct two novel &quot;inflated&quot; deep network architectures,
$\textit{InceptINN}$ and $\textit{DenseINN}$, for the task of diagnosing IPMN
from multisequence (T1 and T2) MRI. These networks inflate their 2D layers to
3D and bootstrap weights from their 2D counterparts (Inceptionv3 and
DenseNet121 respectively) trained on ImageNet to the new 3D kernels. We also
extend the inflation process by further expanding the pre-trained kernels to
handle any number of input modalities and different fusion strategies. This is
one of the first studies to train an end-to-end deep network on multisequence
MRI for IPMN diagnosis, and shows that our proposed novel inflated network
architectures are able to handle the extremely limited training data (139 MRI
scans), while providing an absolute improvement of $8.76\%$ in accuracy for
diagnosing IPMN over the current state-of-the-art. Code is publicly available
at https://github.com/lalonderodney/INN-Inflated-Neural-Nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00438</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00438</id><created>2019-06-30</created><authors><author><keyname>Hu</keyname><forenames>Yipeng</forenames></author><author><keyname>Gibson</keyname><forenames>Eli</forenames></author><author><keyname>Barratt</keyname><forenames>Dean C.</forenames></author><author><keyname>Emberton</keyname><forenames>Mark</forenames></author><author><keyname>Noble</keyname><forenames>J. Alison</forenames></author><author><keyname>Vercauteren</keyname><forenames>Tom</forenames></author></authors><title>Conditional Segmentation in Lieu of Image Registration</title><categories>eess.IV cs.CV cs.LG</categories><comments>Accepted to MICCAI 2019</comments><doi>10.1007/978-3-030-32245-8_45</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical pairwise image registration methods search for a spatial
transformation that optimises a numerical measure that indicates how well a
pair of moving and fixed images are aligned. Current learning-based
registration methods have adopted the same paradigm and typically predict, for
any new input image pair, dense correspondences in the form of a dense
displacement field or parameters of a spatial transformation model. However, in
many applications of registration, the spatial transformation itself is only
required to propagate points or regions of interest (ROIs). In such cases,
detailed pixel- or voxel-level correspondence within or outside of these ROIs
often have little clinical value. In this paper, we propose an alternative
paradigm in which the location of corresponding image-specific ROIs, defined in
one image, within another image is learnt. This results in replacing image
registration by a conditional segmentation algorithm, which can build on
typical image segmentation networks and their widely-adopted training
strategies. Using the registration of 3D MRI and ultrasound images of the
prostate as an example to demonstrate this new approach, we report a median
target registration error (TRE) of 2.1 mm between the ground-truth ROIs defined
on intraoperative ultrasound images and those propagated from the preoperative
MR images. Significantly lower (&gt;34%) TREs were obtained using the proposed
conditional segmentation compared with those obtained from a
previously-proposed spatial-transformation-predicting registration network
trained with the same multiple ROI labels for individual image pairs. We
conclude this work by using a quantitative bias-variance analysis to provide
one explanation of the observed improvement in registration accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00443</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00443</id><created>2019-06-30</created><authors><author><keyname>Ram</keyname><forenames>Dhananjay</forenames></author><author><keyname>Miculicich</keyname><forenames>Lesly</forenames></author><author><keyname>Bourlard</keyname><forenames>Herv&#xe9;</forenames></author></authors><title>Multilingual Bottleneck Features for Query by Example Spoken Term
  Detection</title><categories>cs.CL cs.HC cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State of the art solutions to query by example spoken term detection
(QbE-STD) usually rely on bottleneck feature representation of the query and
audio document to perform dynamic time warping (DTW) based template matching.
Here, we present a study on QbE-STD performance using several monolingual as
well as multilingual bottleneck features extracted from feed forward networks.
Then, we propose to employ residual networks (ResNet) to estimate the
bottleneck features and show significant improvements over the corresponding
feed forward network based features. The neural networks are trained on
GlobalPhone corpus and QbE-STD experiments are performed on a very challenging
QUESST 2014 database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00450</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00450</id><created>2019-06-30</created><updated>2019-07-15</updated><authors><author><keyname>Benzaman</keyname><forenames>Ben</forenames></author><author><keyname>Pakdamanian</keyname><forenames>Erfan</forenames></author></authors><title>Discrete Event Simulation of Driver's Routing Behavior Rule at a Road
  Intersection</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several factors influence traffic congestion and overall traffic dynamics.
Simulation modeling has been utilized to understand the traffic performance
parameters during traffic congestions. This paper focuses on driver behavior of
route selection by differentiating three distinguishable decisions, which are
shortest distance routing, shortest time routing and less crowded road routing.
This research generated 864 different scenarios to capture various traffic
dynamics under collective driving behavior of route selection. Factors such as
vehicle arrival rate, behaviors at system boundary and traffic light phasing
were considered. The simulation results revealed that shortest time routing
scenario offered the best solution considering all forms of interactions among
the factors. Overall, this routing behavior reduces traffic wait time and total
time (by 69.5% and 65.72%) compared to shortest distance routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00457</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00457</id><created>2019-06-30</created><authors><author><keyname>Ling</keyname><forenames>Shaoshi</forenames></author><author><keyname>Salazar</keyname><forenames>Julian</forenames></author><author><keyname>Kirchhoff</keyname><forenames>Katrin</forenames></author></authors><title>Contextual Phonetic Pretraining for End-to-end Utterance-level Language
  and Speaker Recognition</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>submitted to INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pretrained contextual word representations in NLP have greatly improved
performance on various downstream tasks. For speech, we propose contextual
frame representations that capture phonetic information at the acoustic frame
level and can be used for utterance-level language, speaker, and speech
recognition. These representations come from the frame-wise intermediate
representations of an end-to-end, self-attentive ASR model (SAN-CTC) on spoken
utterances. We first train the model on the Fisher English corpus with
context-independent phoneme labels, then use its representations at inference
time as features for task-specific models on the NIST LRE07 closed-set language
recognition task and a Fisher speaker recognition task, giving significant
improvements over the state-of-the-art on both (e.g., language EER of 4.68% on
3sec utterances, 23% relative reduction in speaker EER). Results remain
competitive when using a novel dilated convolutional model for language
recognition, or when ASR pretraining is done with character labels only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00459</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00459</id><created>2019-06-30</created><authors><author><keyname>Huang</keyname><forenames>Linan</forenames></author><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author></authors><title>N-Person Discrete-Time Dynamic Games of Asymmetric Information</title><categories>eess.SY cs.GT cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a class of N-person discrete-time dynamic games with an
asymmetric information structure. Each player has private information revealed
only to himself, which is modeled as a random variable called the type. Each
player aims to find an optimal feedback control policy to reach the desired
state while minimizing the control cost without exact knowledge of the system
dynamics. Players can form a belief on the unknowns based on the observation of
the state trajectory and update it via the Bayesian rule to learn the type
value of other players. To deal with the uncertainty caused by the private
information, each player forms his control policy under the expectation of the
type belief, which forms the perfect Bayesian Nash equilibrium (PBNE). The
strong coupling of the type estimation and the control policy establishes no
separation principle in our non-classical information structure. In particular,
we investigate the linear-quadratic setting, and we obtain generalized Riccati
equations and an affine state-feedback PBNE policy. Moreover, we show that the
PBNE policy is unique if it exists and is strongly time consistent. Finally, we
numerically illustrate the proposed framework with a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00460</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00460</id><created>2019-06-30</created><authors><author><keyname>Schmidt</keyname><forenames>Erick</forenames></author><author><keyname>Ruble</keyname><forenames>Zach A.</forenames></author><author><keyname>Akopian</keyname><forenames>David</forenames></author><author><keyname>Pack</keyname><forenames>Daniel J.</forenames></author></authors><title>A Reduced Complexity Cross-correlation Interference Mitigation Technique
  on a Real-time Software-defined Radio GPS L1 Receiver</title><categories>eess.SP cs.SY eess.SY</categories><journal-ref>Published in 2018 IEEE/ION Position, Location and Navigation
  Symposium (PLANS)</journal-ref><doi>10.1109/PLANS.2018.8373471</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The U.S. global position system (GPS) is one of the existing global
navigation satellite systems (GNSS) that provides position and time information
for users in civil, commercial and military backgrounds. Because of its
reliance on many applications nowadays, it's crucial for GNSS receivers to have
robustness to intentional or unintentional interference. Because most
commercial GPS receivers are not flexible, software-defined radio emerged as a
promising solution for fast prototyping and research on interference mitigation
algorithms. This paper provides a proposed minimum mean-squared error (MMSE)
interference mitigation technique which is enhanced for computational
feasibility and implemented on a real-time capable GPS L1 SDR receiver. The GPS
SDR receiver SW has been optimized for real-time operation on National
Instruments' LabVIEW (LV) platform in conjunction with C/C++ dynamic link
libraries (DLL) for improved efficiency. Performance results of said algorithm
with real signals and injected interference are discussed. The proposed SDR
receiver gains in terms of BER curves for several interferers are demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00463</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00463</id><created>2019-06-30</created><authors><author><keyname>Schmidt</keyname><forenames>Erick</forenames></author><author><keyname>Akopian</keyname><forenames>David</forenames></author></authors><title>Exploiting Acceleration Features of LabVIEW platform for Real-Time GNSS
  Software Receiver Optimization</title><categories>eess.SP cs.PF cs.SY eess.SY</categories><journal-ref>Proceedings of the 30th International Technical Meeting of the
  Satellite Division of The Institute of Navigation (ION GNSS+ 2017)</journal-ref><doi>10.33012/2017.15179</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the new generation of LabVIEW-based GPS receiver testbed
that is based on National Instruments' (NI) LabVIEW (LV) platform in
conjunction to C/C++ dynamic link libraries (DLL) used inside the platform for
performance execution. This GPS receiver has been optimized for real-time
operation and has been developed for fast prototyping and easiness on future
additions and implementations to the system. The receiver DLLs are divided into
three baseband modules: acquisition, tracking, and navigation. The openness of
received baseband modules allows for extensive research topics such as signal
quality improvement on GPS-denied areas, signal spoofing, and signal
interferences. The hardware used in the system was chosen with an effort to
achieve portability and mobility in the SDR receiver. Several acceleration
factors that accomplish real-time operation and that are inherent to LabVIEW
mechanisms, such as multithreading, parallelization and dedicated
loop-structures, are discussed. The proposed SDR also exploits C/C++
optimization techniques for single-instruction multiple-data (SIMD) capable
processors in software correlators for real-time operation of GNSS tracking
loops. It is demonstrated that LabVIEW-based solutions provide competitive
real-time solutions for fast prototyping of receiver algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00465</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00465</id><created>2019-06-30</created><authors><author><keyname>Schmidt</keyname><forenames>Erick</forenames></author><author><keyname>Akopian</keyname><forenames>David</forenames></author></authors><title>Fast prototyping of an SDR WLAN 802.11b receiver for an indoor
  positioning system</title><categories>eess.SP cs.PF</categories><journal-ref>Proceedings of the 31st International Technical Meeting of the
  Satellite Division of The Institute of Navigation (ION GNSS+ 2018)</journal-ref><doi>10.33012/2018.16045</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indoor positioning systems (IPS) are emerging technologies due to an
increasing popularity and demand in location based service (LBS). Because
traditional positioning systems such as GPS are limited to outdoor
applications, many IPS have been proposed in literature. WLAN-based IPS are the
most promising due to its proven accuracy and infrastructure deployment.
Several WLAN-based IPS have been proposed in the past, from which the best
results have been shown by so-called fingerprint-based systems. This paper
proposes an indoor positioning system which extends traditional WLAN
fingerprinting by using received signal strength (RSS) measurements along with
channel estimates as an effort to improve classification accuracy for scenarios
with a low number of Access Points (APs). The channel estimates aim to
characterize complex indoor environments making it a unique signature for
fingerprinting-based IPS and therefore improving pattern recognition in
radio-maps. Since commercial WLAN cards offer limited measurement information,
software-defined radio (SDR) as an emerging trend for fast prototyping and
research integration is chosen as the best cost-effective option to extract
channel estimates. Therefore, this paper first proposes an 802.11b WLAN SDR
beacon receiver capable of measuring RSS and channel estimates. The SDR is
designed using LabVIEW (LV) environment and leverages several inherent platform
acceleration features that achieve real-time capturing. The receiver achieves a
fast-rate measurement capture of 9 packets per second per AP. The
classification of the propose IPS uses a support vector machine (SVM) for
offline training and online navigation. Several tests are conducted in a
cluttered indoor environment with a single AP in 802.11b legacy mode. Finally,
navigation accuracy results are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00468</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00468</id><created>2019-06-30</created><authors><author><keyname>Schmidt</keyname><forenames>Erick</forenames></author><author><keyname>Akopian</keyname><forenames>David</forenames></author></authors><title>A Fast-rate WLAN Measurement Tool for Improved Miss-rate in Indoor
  Navigation</title><categories>cs.NI cs.PF cs.SE eess.SP</categories><journal-ref>Proceedings of the 31st International Technical Meeting of the
  Satellite Division of The Institute of Navigation (ION GNSS+ 2018)</journal-ref><doi>10.33012/2018.16042</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, location-based services (LBS) have steered attention to indoor
positioning systems (IPS). WLAN-based IPSs relying on received signal strength
(RSS) measurements such as fingerprinting are gaining popularity due to proven
high accuracy of their results. Typically, sets of RSS measurements at selected
locations from several WLAN access points (APs) are used to calibrate the
system. Retrieval of such measurements from WLAN cards are commonly at one-Hz
rate. Such measurement collection is needed for offline radio-map surveying
stage which aligns fingerprints to locations, and for online navigation stage,
when collected measurements are associated with the radio-map for user
navigation. As WLAN network is not originally designed for positioning, an RSS
measurement miss could have a high impact on the fingerprinting system.
Additionally, measurement fluctuations require laborious signal processing, and
surveying process can be very time consuming. This paper proposes a fast-rate
measurement collection method that addresses previously mentioned problems by
achieving a higher probability of RSS measurement collection during a given
one-second window. This translates to more data for statistical processing and
faster surveying. The fast-rate collection approach is analyzed against the
conventional measurement rate in a proposed testing methodology that mimics
real-life scenarios related to IPS surveying and online navigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00477</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00477</id><created>2019-06-30</created><updated>2019-12-28</updated><authors><author><keyname>Srinivasan</keyname><forenames>Tejas</forenames></author><author><keyname>Sanabria</keyname><forenames>Ramon</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author></authors><title>Analyzing Utility of Visual Context in Multimodal Speech Recognition
  Under Noisy Conditions</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted to How2 Workshop, ICML 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimodal learning allows us to leverage information from multiple sources
(visual, acoustic and text), similar to our experience of the real world.
However, it is currently unclear to what extent auxiliary modalities improve
performance over unimodal models, and under what circumstances the auxiliary
modalities are useful. We examine the utility of the auxiliary visual context
in Multimodal Automatic Speech Recognition in adversarial settings, where we
deprive the models from partial audio signal during inference time. Our
experiments show that while MMASR models show significant gains over
traditional speech-to-text architectures (upto 4.2% WER improvements), they do
not incorporate visual information when the audio signal has been corrupted.
This shows that current methods of integrating the visual modality do not
improve model robustness to noise, and we need better visually grounded
adaptation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00478</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00478</id><created>2019-06-30</created><authors><author><keyname>Schmidt</keyname><forenames>Erick</forenames></author><author><keyname>Akopian</keyname><forenames>David</forenames></author></authors><title>Indoor positioning system using WLAN channel estimates as fingerprints
  for mobile devices</title><categories>cs.NI eess.SP</categories><journal-ref>Proceedings Volume 9411, Mobile Devices and Multimedia: Enabling
  Technologies, Algorithms, and Applications 2015; 94110R (2015)</journal-ref><doi>10.1117/12.2083670</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing integration of location based services (LBS) such as GPS in
mobile devices, indoor position systems (IPS) have become an important role for
research. There are several IPS methods such as AOA, TOA, TDOA, which use
trilateration for indoor location estimation but are generally based on
line-of-sight. Other methods rely on classification such as fingerprinting
which uses WLAN indoor signals. This paper re-examines the classical WLAN
fingerprinting accuracy which uses received signal strength (RSS) measurements
by introducing channel estimates for improvements in the classification of
indoor locations. The purpose of this paper is to improve existing
classification algorithms used in fingerprinting by introducing channel
estimates when there are a low number of APs available. The channel impulse
response, or in this case the channel estimation from the receiver, should
characterize a complex indoor area which usually has multipath, thus providing
a unique signature for each location which proves useful for better pattern
recognition. In this experiment, channel estimates are extracted from a
Software-Defined Radio (SDR) environment, thus exploiting the benefits of SDR
from a NI-USRP model and LabVIEW software. Measurements are taken from a known
building, and several scenarios with one and two access points (APs) are used
in this experiment. Also, three granularities in distance between locations are
analyzed. A Support Vector Machine (SVM) is used as the algorithm for pattern
recognition of different locations based on the samples taken from RSS and
channel estimation coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00482</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00482</id><created>2019-06-30</created><authors><author><keyname>Choi</keyname><forenames>Jinseok</forenames></author><author><keyname>Sung</keyname><forenames>Junmo</forenames></author><author><keyname>Prasad</keyname><forenames>Narayan</forenames></author><author><keyname>Qi</keyname><forenames>Xiao-Feng</forenames></author><author><keyname>Evans</keyname><forenames>Brian L.</forenames></author><author><keyname>Gatherer</keyname><forenames>Alan</forenames></author></authors><title>Base Station Antenna Selection for Low-Resolution ADC Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates antenna selection at a base station with large
antenna arrays and low-resolution analog-to-digital converters. For downlink
transmit antenna selection for narrowband channels, we show (1) a selection
criterion that maximizes sum rate with zero-forcing precoding equivalent to
that of a perfect quantization system; (2) maximum sum rate increases with
number of selected antennas; (3) derivation of the sum rate loss function from
using a subset of antennas; and (4) unlike high-resolution converter systems,
sum rate loss reaches a maximum at a point of total transmit power and
decreases beyond that point to converge to zero. For wideband
orthogonal-frequency-division-multiplexing (OFDM) systems, our results hold
when entire subcarriers share a common subset of antennas. For uplink receive
antenna selection for narrowband channels, we (1) generalize a greedy antenna
selection criterion to capture tradeoffs between channel gain and quantization
error; (2) propose a quantization-aware fast antenna selection algorithm using
the criterion; and (3) derive a lower bound on sum rate achieved by the
proposed algorithm based on submodular functions. For wideband OFDM systems, we
extend our algorithm and derive a lower bound on its sum rate. Simulation
results validate theoretical analyses and show increases in sum rate over
conventional algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00511</identifier>
 <datestamp>2019-10-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00511</id><created>2019-06-30</created><authors><author><keyname>Keipour</keyname><forenames>Azarakhsh</forenames></author><author><keyname>Mousaei</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Scherer</keyname><forenames>Sebastian</forenames></author></authors><title>Automatic Real-time Anomaly Detection for Autonomous Aerial Vehicles</title><categories>eess.SY cs.RO cs.SY</categories><comments>2019 IEEE International Conference on Robotics and Automation (ICRA)
  [7 pages, 7 figures]</comments><doi>10.1109/ICRA.2019.8794286</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent increase in the use of aerial vehicles raises concerns about the
safety and reliability of autonomous operations. There is a growing need for
methods to monitor the status of these aircraft and report any faults and
anomalies to the safety pilot or to the autopilot to deal with the emergency
situation. In this paper, we present a real-time approach using the Recursive
Least Squares method to detect anomalies in the behavior of an aircraft. The
method models the relationship between correlated input-output pairs online and
uses the model to detect the anomalies. The result is an easy-to-deploy anomaly
detection method that does not assume a specific aircraft model and can detect
many types of faults and anomalies in a wide range of autonomous aircraft. The
experiments on this method show a precision of $88.23\%$, recall of $88.23\%$
and $86.36\%$ accuracy for over 22 flight tests. The other contribution is
providing a new fault detection open dataset for autonomous aircraft, which
contains complete data and the ground truth for 22 fixed-wing flights with
eight different types of mid-flight actuator failures to help future fault
detection research for aircraft.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00516</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00516</id><created>2019-06-30</created><updated>2019-10-22</updated><authors><author><keyname>Zhang</keyname><forenames>Weixia</forenames></author><author><keyname>Ma</keyname><forenames>Kede</forenames></author><author><keyname>Zhai</keyname><forenames>Guangtao</forenames></author><author><keyname>Yang</keyname><forenames>Xiaokang</forenames></author></authors><title>Learning to Blindly Assess Image Quality in the Laboratory and Wild</title><categories>cs.CV cs.LG eess.IV</categories><comments>Update the fidelity loss version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational models for blind image quality assessment (BIQA) are typically
trained in well-controlled laboratory environments with limited
generalizability to realistically distorted images. Similarly, BIQA models
optimized for images captured in the wild cannot adequately handle
synthetically distorted images. To face the cross-distortion-scenario
challenge, we develop a BIQA model and an approach of training it on multiple
IQA databases (of different distortion scenarios) simultaneously. A key step in
our approach is to create and combine image pairs within individual databases
as the training set, which effectively bypasses the issue of perceptual scale
realignment. We compute a continuous quality annotation for each pair from the
corresponding human opinions, indicating the probability of one image having
better perceptual quality. We train a deep neural network for BIQA over the
training set of massive image pairs by minimizing the fidelity loss.
Experiments on six IQA databases demonstrate that the optimized model by the
proposed training strategy is effective in blindly assessing image quality in
the laboratory and wild, outperforming previous BIQA methods by a large margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00538</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00538</id><created>2019-07-01</created><authors><author><keyname>Zhang</keyname><forenames>Deyou</forenames></author><author><keyname>Li</keyname><forenames>Ang</forenames></author><author><keyname>Chen</keyname><forenames>He</forenames></author><author><keyname>Wei</keyname><forenames>Ning</forenames></author><author><keyname>Ding</keyname><forenames>Ming</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Beam Allocation for Millimeter-Wave MIMO Tracking Systems</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new beam allocation strategy aiming to maximize
the average successful tracking probability (ASTP) of time-varying
millimeter-wave MIMO systems. In contrast to most existing works that employ
one transmitting-receiving (Tx-Rx) beam pair once only in each training period,
we investigate a more general framework, where the Tx-Rx beam pairs are allowed
to be used repeatedly to improve the received signal powers in specific
directions. In the case of orthogonal Tx-Rx beam pairs, a power-based estimator
is employed to track the time-varying AoA and AoD of the channel, and the
resulting training beam pair sequence design problem is formulated as an
integer nonlinear programming (I-NLP) problem. By dividing the feasible region
into a set of subregions, the formulated I-NLP is decomposed into a series of
concave sub I-NLPs, which can be solved by recursively invoking a nonlinear
branch-and-bound algorithm. To reduce the computational cost, we relax the
integer constraints of each sub I-NLP and obtain a low-complexity solution via
solving the Karush-Kuhn-Tucker conditions of their relaxed problems. For the
case when the Tx-Rx beam pairs are overlapped in the angular space, we estimate
the updated AoA and AoD via an orthogonal matching pursuit (OMP) algorithm.
Moreover, since no explicit expression for the ASTP exists for the OMP-based
estimator, we derive a closed-form lower bound of the ASTP, based on which a
favorable beam pair allocation strategy can be obtained. Numerical results
demonstrate the superiority of the proposed beam allocation strategy over
existing benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00540</identifier>
 <datestamp>2019-11-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00540</id><created>2019-07-01</created><authors><author><keyname>Rahman</keyname><forenames>Mohammad Ashiqur</forenames></author><author><keyname>Shahriar</keyname><forenames>Md Hasan</forenames></author><author><keyname>Al-Shaer</keyname><forenames>Ehab</forenames></author><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author></authors><title>A Formal Approach for Efficient Navigation Management of Hybrid Electric
  Vehicles on Long Trips</title><categories>cs.LO cs.ET cs.SY eess.SY</categories><msc-class>68Q60</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Plug-in Hybrid Electric Vehicles (PHEVs) are gaining popularity due to their
economic efficiency as well as their contribution to green management. PHEVs
allow the driver to use electric power exclusively for driving and then switch
to gasoline as needed. The more gasoline a vehicle uses, the higher cost is
required for the trip. However, a PHEV cannot last for a long period on stored
electricity without being recharged. Thus, it needs frequent recharging
compared to traditional gasoline-powered vehicles. Moreover, the battery
recharging time is usually long, which leads to longer delays on a trip.
Therefore, it is necessary to provide a flexible navigation management scheme
along with an efficient recharging schedule, which allows the driver to choose
an optimal route based on the fuel-cost and time-to-destination constraints. In
this paper, we present a formal model to solve this PHEV navigation management
problem. The model is solved to provide a driver with a comprehensive routing
plan including the potential recharging and refueling points that satisfy the
given requirements, particularly the maximum fuel cost and the maximum trip
time. In addition, we propose a price-based navigation control technique to
achieve better load balance for the traffic system. Evaluation results show
that the proposed formal models can be solved efficiently even with large road
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00542</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00542</id><created>2019-07-01</created><authors><author><keyname>Heo</keyname><forenames>Hee-Soo</forenames></author><author><keyname>Jung</keyname><forenames>Jee-weon</forenames></author><author><keyname>Shim</keyname><forenames>Hye-jin</forenames></author><author><keyname>Yang</keyname><forenames>IL-Ho</forenames></author><author><keyname>Yu</keyname><forenames>Ha-Jin</forenames></author></authors><title>Cosine similarity-based adversarial process</title><categories>cs.LG eess.AS eess.IV stat.ML</categories><comments>10 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An adversarial process between two deep neural networks is a promising
approach to train a robust model. In this paper, we propose an adversarial
process using cosine similarity, whereas conventional adversarial processes are
based on inverted categorical cross entropy (CCE). When used for training an
identification model, the adversarial process induces the competition of two
discriminative models; one for a primary task such as speaker identification or
image recognition, the other one for a subsidiary task such as channel
identification or domain identification. In particular, the adversarial process
degrades the performance of the subsidiary model by eliminating the subsidiary
information in the input which, in assumption, may degrade the performance of
the primary model. The conventional adversarial processes maximize the CCE of
the subsidiary model to degrade the performance. We have studied a framework
for training robust discriminative models by eliminating channel or domain
information (subsidiary information) by applying such an adversarial process.
However, we found through experiments that using the process of maximizing the
CCE does not guarantee the performance degradation of the subsidiary model. In
the proposed adversarial process using cosine similarity, on the contrary, the
performance of the subsidiary model can be degraded more efficiently by
searching feature space orthogonal to the subsidiary model. The experiments on
speaker identification and image recognition show that we found features that
make the outputs of the subsidiary models independent of the input, and the
performances of the primary models are improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00550</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00550</id><created>2019-07-01</created><authors><author><keyname>Zhou</keyname><forenames>Cheng</forenames></author><author><keyname>Wang</keyname><forenames>Gangcheng</forenames></author><author><keyname>Huang</keyname><forenames>Heyan</forenames></author><author><keyname>Song</keyname><forenames>Lijun</forenames></author><author><keyname>Xue</keyname><forenames>Kang</forenames></author></authors><title>Edge detection based on joint iteration ghost imaging</title><categories>eess.IV physics.optics</categories><comments>11 pages, 6 figures</comments><doi>10.1364/OE.27.027295</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imaging and edge detection have been widely applied and played an important
role in security checking and medical diagnosis. However, as we know, most edge
detection based on ghost imaging system require a large measurement times and
the target object image cannot be provided directly. In this work, a new edge
detection based on joint iteration of projected Landweber iteration
regularization and guided filter ghost imaging method have been proposed which
can be improved the feature detection quality in ghost imaging. This method can
also achieve high quality imaging. Simulation and experiment results show that
the spatial information and edge information of target object are successfully
recovered from the random speckle patterns without special coding under a low
measurement times, and the edge image quality is improved remarkably. This
approach improves the the applicability of ghost imaging, and can satisfy the
practical application fields of imaging and edge detection at the same time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00553</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00553</id><created>2019-07-01</created><authors><author><keyname>Kim</keyname><forenames>Min Jun</forenames></author><author><keyname>Beck</keyname><forenames>Fabian</forenames></author><author><keyname>Ott</keyname><forenames>Christian</forenames></author><author><keyname>Albu-Schaeffer</keyname><forenames>Alin</forenames></author></authors><title>Model-free Friction Observers for Flexible Joint Robots with Torque
  Measurements</title><categories>cs.RO cs.SY eess.SY</categories><comments>IEEE Transactions on Robotics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper tackles a friction compensation problem without using a friction
model. The unique feature of the proposed friction observer is that the nominal
motor-side signal is fed back into the controller instead of the measured
signal. By doing so, asymptotic stability and passivity of the controller are
maintained. Another advantage of the proposed observer is that it provides a
clear understanding for the stiction compensation which is hard to be captured
in model-free approaches. This allows to design observers that do not
overcompensate for the stiction. The proposed scheme is validated through
simulations and experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00594</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00594</id><created>2019-07-01</created><authors><author><keyname>Zhang</keyname><forenames>Heng</forenames></author><author><keyname>Zhang</keyname><forenames>Zhichao</forenames></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author><author><keyname>Cao</keyname><forenames>Shan</forenames></author></authors><title>Fingerprint-based Localization using Commercial LTE Signals: A
  Field-Trial Study</title><categories>eess.SP cs.SY eess.SY</categories><comments>5 pages, 7 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless localization for mobile device has attracted more and more interests
by increasing the demand for location based services. Fingerprint-based
localization is promising, especially in non-Line-of-Sight (NLoS) or rich
scattering environments, such as urban areas and indoor scenarios. In this
paper, we propose a novel fingerprint-based localization technique based on
deep learning framework under commercial long term evolution (LTE) systems.
Specifically, we develop a software defined user equipment to collect the real
time channel state information (CSI) knowledge from LTE base stations and
extract the intrinsic features among CSI observations. On top of that, we
propose a time domain fusion approach to assemble multiple positioning
estimations. Experimental results demonstrated that the proposed localization
technique can significantly improve the localization accuracy and robustness,
e.g. achieves Mean Distance Error (MDE) of 0.47 meters for indoor and of 19.9
meters for outdoor scenarios, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00625</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00625</id><created>2019-07-01</created><authors><author><keyname>Dey</keyname><forenames>Nilabjo</forenames></author><author><keyname>Sharda</keyname><forenames>Janak</forenames></author><author><keyname>Saxena</keyname><forenames>Utkarsh</forenames></author><author><keyname>Kaushik</keyname><forenames>Divya</forenames></author><author><keyname>Singh</keyname><forenames>Utkarsh</forenames></author><author><keyname>Bhowmik</keyname><forenames>Debanjan</forenames></author></authors><title>On-chip learning in a conventional silicon MOSFET based Analog Hardware
  Neural Network</title><categories>cs.NE cs.SY eess.SY</categories><comments>18 pages, 10 figures, 1 table (shorter version submitted to
  conference for review)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On-chip learning in a crossbar array based analog hardware Neural Network
(NN) has been shown to have major advantages in terms of speed and energy
compared to training NN on a traditional computer. However analog hardware NN
proposals and implementations thus far have mostly involved Non Volatile Memory
(NVM) devices like Resistive Random Access Memory (RRAM), Phase Change Memory
(PCM), spintronic devices or floating gate transistors as synapses. Fabricating
systems based on RRAM, PCM or spintronic devices need in-house laboratory
facilities and cannot be done through merchant foundries, unlike conventional
silicon based CMOS chips. Floating gate transistors need large voltage pulses
for weight update, making on-chip learning in such systems energy inefficient.
This paper proposes and implements through SPICE simulations on-chip learning
in analog hardware NN using only conventional silicon based MOSFETs (without
any floating gate) as synapses since they are easy to fabricate. We first model
the synaptic characteristic of our single transistor synapse using SPICE
circuit simulator and benchmark it against experimentally obtained
current-voltage characteristics of a transistor. Next we design a Fully
Connected Neural Network (FCNN) crossbar array using such transistor synapses.
We also design analog peripheral circuits for neuron and synaptic weight update
calculation, needed for on-chip learning, again using conventional transistors.
Simulating the entire system on SPICE simulator, we obtain high training and
test accuracy on the standard Fisher's Iris dataset, widely used in machine
learning. We also compare the speed and energy performance of our transistor
based implementation of analog hardware NN with some previous implementations
of NN with NVM devices and show comparable performance with respect to on-chip
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00651</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00651</id><created>2019-07-01</created><authors><author><keyname>Imamura</keyname><forenames>Ryuji</forenames></author><author><keyname>Itasaka</keyname><forenames>Tatsuki</forenames></author><author><keyname>Okuda</keyname><forenames>Masahiro</forenames></author></authors><title>Self-supervised Hyperspectral Image Restoration using Separable Image
  Prior</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised learning with a convolutional neural network is recognized as a
powerful means of image restoration. However, most such methods have been
designed for application to grayscale and/or color images; therefore, they have
limited success when applied to hyperspectral image restoration. This is
partially owing to large datasets being difficult to collect, and also the
heavy computational load associated with the restoration of an image with many
spectral bands. To address this difficulty, we propose a novel self-supervised
learning strategy for application to hyperspectral image restoration. Our
method automatically creates a training dataset from a single degraded image
and trains a denoising network without any clear images. Another notable
feature of our method is the use of a separable convolutional layer. We
undertake experiments to prove that the use of a separable network allows us to
acquire the prior of a hyperspectral image and to realize efficient
restoration. We demonstrate the validity of our method through extensive
experiments and show that our method has better characteristics than those that
are currently regarded as state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00662</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00662</id><created>2019-07-01</created><authors><author><keyname>Tervo</keyname><forenames>Roope</forenames></author><author><keyname>Karjalainen</keyname><forenames>Joonas</forenames></author><author><keyname>Jung</keyname><forenames>Alexander</forenames></author></authors><title>Short-term prediction of Electricity Outages Caused by Convective Storms</title><categories>eess.SP cs.LG</categories><comments>arXiv admin note: text overlap with arXiv:1805.07897</comments><doi>10.1109/TGRS.2019.2921809</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prediction of power outages caused by convective storms which are highly
localised in space and time is of crucial importance to power grid operators.
We propose a new machine learning approach to predict the damage caused by
storms. This approach hinges identifying and tracking of storm cells using
weather radar images on the application of machine learning techniques. Overall
prediction process consists of identifying storm cells from CAPPI weather radar
images by contouring them with a solid 35 dBZ threshold, predicting a track of
storm cells and classifying them based on their damage potential to power grid
operators. Tracked storm cells are then classified by combining data obtained
from weather radar, ground weather observations and lightning detectors. We
compare random forest classifiers and deep neural networks as alternative
methods to classify storm cells. The main challenge is that the training data
are heavily imbalanced as extreme weather events are rare.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00691</identifier>
 <datestamp>2019-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00691</id><created>2019-07-01</created><authors><author><keyname>Hennessy</keyname><forenames>Brendan</forenames></author><author><keyname>Tingay</keyname><forenames>Steven</forenames></author><author><keyname>Hancock</keyname><forenames>Paul</forenames></author><author><keyname>Young</keyname><forenames>Robert</forenames></author><author><keyname>Tremblay</keyname><forenames>Steven</forenames></author><author><keyname>Wayth</keyname><forenames>Randall B.</forenames></author><author><keyname>Morgan</keyname><forenames>John</forenames></author><author><keyname>McSweeney</keyname><forenames>Sammy</forenames></author><author><keyname>Crosse</keyname><forenames>Brian</forenames></author><author><keyname>Johnston-Hollitt</keyname><forenames>Melanie</forenames></author><author><keyname>Kaplan</keyname><forenames>David L.</forenames></author><author><keyname>Pallot</keyname><forenames>Dave</forenames></author><author><keyname>Walker</keyname><forenames>Mia</forenames></author></authors><title>Improved Techniques for the Surveillance of the Near Earth Space
  Environment with the Murchison Widefield Array</title><categories>eess.SP astro-ph.IM</categories><comments>Presented at the 2019 IEEE Radar Conference in Boston earlier this
  year</comments><journal-ref>2019 IEEE Radar Conference (RadarConf)</journal-ref><doi>10.1109/RADAR.2019.8835821</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we demonstrate improved techniques to extend coherent
processing intervals for passive radar processing, with the Murchison Widefield
Array. Specifically, we apply a two stage linear range and Doppler migration
compensation by utilising Keystone Formatting and a recent dechirping method.
These methods are used to further demonstrate the potential for the
surveillance of space with the Murchison Widefield Array using passive radar,
by detecting objects orders of magnitude smaller than previous work. This paper
also demonstrates how the linear Doppler migration methods can be extended to
higher order compensation to further increase potential processing intervals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00695</identifier>
 <datestamp>2019-12-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00695</id><created>2019-07-01</created><updated>2019-12-26</updated><authors><author><keyname>Dubost</keyname><forenames>Florian</forenames></author><author><keyname>de Bruijne</keyname><forenames>Marleen</forenames></author><author><keyname>Nardin</keyname><forenames>Marco</forenames></author><author><keyname>Dalca</keyname><forenames>Adrian V.</forenames></author><author><keyname>Donahue</keyname><forenames>Kathleen L.</forenames></author><author><keyname>Giese</keyname><forenames>Anne-Katrin</forenames></author><author><keyname>Etherton</keyname><forenames>Mark R.</forenames></author><author><keyname>Wu</keyname><forenames>Ona</forenames></author><author><keyname>de Groot</keyname><forenames>Marius</forenames></author><author><keyname>Niessen</keyname><forenames>Wiro</forenames></author><author><keyname>Vernooij</keyname><forenames>Meike</forenames></author><author><keyname>Rost</keyname><forenames>Natalia S.</forenames></author><author><keyname>Schirmer</keyname><forenames>Markus D.</forenames></author></authors><title>Multi-atlas image registration of clinical data with automated quality
  assessment using ventricle segmentation</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Registration is a core component of many imaging pipelines. In case of
clinical scans, with lower resolution and sometimes substantial motion
artifacts, registration can produce poor results. Visual assessment of
registration quality in large clinical datasets is inefficient. In this work,
we propose to automatically assess the quality of registration to an atlas in
clinical FLAIR MRI scans of the brain. The method consists of automatically
segmenting the ventricles of a given scan using a neural network, and comparing
the segmentation to the atlas' ventricles propagated to image space. We used
the proposed method to improve clinical image registration to a general atlas
by computing multiple registrations and then selecting the registration that
yielded the highest ventricle overlap. Methods were evaluated in a single-site
dataset of more than 1000 scans, as well as a multi-center dataset comprising
142 clinical scans from 12 sites. The automated ventricle segmentation reached
a Dice coefficient with manual annotations of 0.89 in the single-site dataset,
and 0.83 in the multi-center dataset. Registration via age-specific atlases
could improve ventricle overlap compared to a direct registration to the
general atlas (Dice similarity coefficient increase up to 0.15). Experiments
also showed that selecting scans with the registration quality assessment
method could improve the quality of average maps of white matter hyperintensity
burden, instead of using all scans for the computation of the white matter
hyperintensity map. In this work, we demonstrated the utility of an automated
tool for assessing image registration quality in clinical scans. This image
quality assessment step could ultimately assist in the translation of automated
neuroimaging pipelines to the clinic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00734</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00734</id><created>2019-07-01</created><authors><author><keyname>Valdenegro-Toro</keyname><forenames>Matias</forenames></author></authors><title>Learning Objectness from Sonar Images for Class-Independent Object
  Detection</title><categories>cs.CV cs.LG cs.RO eess.IV</categories><comments>European Conference on Mobile Robots 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting novel objects without class information is not trivial, as it is
difficult to generalize from a small training set. This is an interesting
problem for underwater robotics, as modeling marine objects is inherently more
difficult in sonar images, and training data might not be available apriori.
Detection proposals algorithms can be used for this purpose but usually
requires a large amount of output bounding boxes. In this paper we propose the
use of a fully convolutional neural network that regresses an objectness value
directly from a Forward-Looking sonar image. By ranking objectness, we can
produce high recall (96 %) with only 100 proposals per image. In comparison,
EdgeBoxes requires 5000 proposals to achieve a slightly better recall of 97 %,
while Selective Search requires 2000 proposals to achieve 95 % recall. We also
show that our method outperforms a template matching baseline by a considerable
margin, and is able to generalize to completely new objects. We expect that
this kind of technique can be used in the field to find lost objects under the
sea.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00758</identifier>
 <datestamp>2019-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00758</id><created>2019-07-01</created><updated>2019-11-27</updated><authors><author><keyname>Eshky</keyname><forenames>Aciel</forenames></author><author><keyname>Ribeiro</keyname><forenames>Manuel Sam</forenames></author><author><keyname>Richmond</keyname><forenames>Korin</forenames></author><author><keyname>Renals</keyname><forenames>Steve</forenames></author></authors><title>Synchronising audio and ultrasound by learning cross-modal embeddings</title><categories>cs.CL cs.CV cs.LG cs.SD eess.AS eess.IV</categories><comments>5 pages, 1 figure, 4 tables; Interspeech 2019 with the following
  edits: 1) Loss and accuracy upon convergence were accidentally reported from
  an older model. Now updated with model described throughout the paper. All
  other results remain unchanged. 2) Max true offset in the training data
  corrected from 179ms to 1789ms. 3) Detectability &quot;boundary/range&quot; renamed to
  detectability &quot;thresholds&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audiovisual synchronisation is the task of determining the time offset
between speech audio and a video recording of the articulators. In child speech
therapy, audio and ultrasound videos of the tongue are captured using
instruments which rely on hardware to synchronise the two modalities at
recording time. Hardware synchronisation can fail in practice, and no mechanism
exists to synchronise the signals post hoc. To address this problem, we employ
a two-stream neural network which exploits the correlation between the two
modalities to find the offset. We train our model on recordings from 69
speakers, and show that it correctly synchronises 82.9% of test utterances from
unseen therapy sessions and unseen speakers, thus considerably reducing the
number of utterances to be manually synchronised. An analysis of model
performance on the test utterances shows that directed phone articulations are
more difficult to automatically synchronise compared to utterances containing
natural variation in speech such as words, sentences, or conversations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00765</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00765</id><created>2019-07-01</created><updated>2019-12-16</updated><authors><author><keyname>Azzara</keyname><forenames>Riccardo Mario</forenames></author><author><keyname>Girardi</keyname><forenames>Maria</forenames></author><author><keyname>Iafolla</keyname><forenames>Valerio</forenames></author><author><keyname>Lucchesi</keyname><forenames>David</forenames></author><author><keyname>Padovani</keyname><forenames>Cristina</forenames></author><author><keyname>Pellegrini</keyname><forenames>Daniele</forenames></author></authors><title>Ambient vibrations of age-old masonry towers: results of long-term
  dynamic monitoring in the historic centre of Lucca</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents the results of an ambient vibration monitoring campaign
conducted on so-called Clock Tower (Torre delle Ore), one the best known and
most visited monuments in the historic centre of Lucca. The vibrations of the
tower were continuously monitored from November 2017 to March 2018 using
high-sensitivity instrumentation. In particular, four seismic stations provided
by the Istituto Nazionale di Geofisica e Vulcanologia and two three-axial
accelerometers developed by AGI S.r.l., spin-off of the Istituto Nazionale di
Astrofisica, were installed on the tower. The measured vibration level was
generally very low, since the structure lies in the middle of a limited traffic
area. Nevertheless, the availability of two different types of highly sensitive
and accurate instruments allowed the authors to follow the dynamic behaviour of
the tower during the entire monitoring period and has moreover provided
cross-validation of the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00766</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00766</id><created>2019-07-01</created><authors><author><keyname>Tarver</keyname><forenames>Chance</forenames></author><author><keyname>Balatsoukas-Stimming</keyname><forenames>Alexios</forenames></author><author><keyname>Cavallaro</keyname><forenames>Joseph R.</forenames></author></authors><title>Design and Implementation of a Neural Network Based Predistorter for
  Enhanced Mobile Broadband</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital predistortion is the process of correcting for nonlinearities in the
analog RF front-end of a wireless transmitter. These nonlinearities contribute
to adjacent channel leakage, degrade the error vector magnitude of transmitted
signals, and often force the transmitter to reduce its transmission power into
a more linear but less power-efficient region of the device. Most predistortion
techniques are based on polynomial models with an indirect learning
architecture which have been shown to be overly sensitive to noise. In this
work, we use neural network based predistortion with a novel neural network
training method that avoids the indirect learning architecture and that shows
significant improvements in both the adjacent channel leakage ratio and error
vector magnitude. Moreover, we show that, by using a neural network based
predistorter, we are able to achieve a 42% reduction in latency and 9.6%
increase in throughput on an FPGA accelerator with 15% fewer multiplications
per sample when compared to a similarly performing memory-polynomial
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00770</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00770</id><created>2019-06-27</created><authors><author><keyname>Speiser</keyname><forenames>Artur</forenames></author><author><keyname>Turaga</keyname><forenames>Srinivas C.</forenames></author><author><keyname>Macke</keyname><forenames>Jakob H.</forenames></author></authors><title>Teaching deep neural networks to localize sources in super-resolution
  microscopy by combining simulation-based learning and unsupervised learning</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-molecule localization microscopy constructs super-resolution images by
the sequential imaging and computational localization of sparsely activated
fluorophores. Accurate and efficient fluorophore localization algorithms are
key to the success of this computational microscopy method. We present a novel
localization algorithm based on deep learning which significantly improves upon
the state of the art. Our contributions are a novel network architecture for
simultaneous detection and localization, and a new training algorithm which
enables this deep network to solve the Bayesian inverse problem of detecting
and localizing single molecules. Our network architecture uses temporal context
from multiple sequentially imaged frames to detect and localize molecules. Our
training algorithm combines simulation-based supervised learning with
autoencoder-based unsupervised learning to make it more robust against mismatch
in the generative model. We demonstrate the performance of our method on
datasets imaged using a variety of point spread functions and fluorophore
densities. While existing localization algorithms can achieve optimal
localization accuracy in data with low fluorophore density, they are confounded
by high densities. Our method significantly outperforms the state of the art at
high densities and thus, enables faster imaging than previous approaches. Our
work also more generally shows how to train deep networks to solve challenging
Bayesian inverse problems in biology and physics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00772</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00772</id><created>2019-07-01</created><authors><author><keyname>Mustafa</keyname><forenames>Ahmed</forenames></author><author><keyname>Biswas</keyname><forenames>Arijit</forenames></author><author><keyname>Bergler</keyname><forenames>Christian</forenames></author><author><keyname>Schottenhamml</keyname><forenames>Julia</forenames></author><author><keyname>Maier</keyname><forenames>Andreas</forenames></author></authors><title>Analysis by Adversarial Synthesis -- A Novel Approach for Speech
  Vocoding</title><categories>eess.AS cs.LG cs.SD</categories><comments>Accepted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical parametric speech coding techniques provide a compact
representation for speech signals. This affords a very low transmission rate
but with a reduced perceptual quality of the reconstructed signals. Recently,
autoregressive deep generative models such as WaveNet and SampleRNN have been
used as speech vocoders to scale up the perceptual quality of the reconstructed
signals without increasing the coding rate. However, such models suffer from a
very slow signal generation mechanism due to their sample-by-sample modelling
approach. In this work, we introduce a new methodology for neural speech
vocoding based on generative adversarial networks (GANs). A fake speech signal
is generated from a very compressed representation of the glottal excitation
using conditional GANs as a deep generative model. This fake speech is then
refined using the LPC parameters of the original speech signal to obtain a
natural reconstruction. The reconstructed speech waveforms based on this
approach show a higher perceptual quality than the classical vocoder
counterparts according to subjective and objective evaluation scores for a
dataset of 30 male and female speakers. Moreover, the usage of GANs enables to
generate signals in one-shot compared to autoregressive generative models. This
makes GANs promising for exploration to implement high-quality neural vocoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00787</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00787</id><created>2019-06-28</created><authors><author><keyname>Triess</keyname><forenames>Larissa T.</forenames></author><author><keyname>Peter</keyname><forenames>David</forenames></author><author><keyname>Rist</keyname><forenames>Christoph B.</forenames></author><author><keyname>Enzweiler</keyname><forenames>Markus</forenames></author><author><keyname>Z&#xf6;llner</keyname><forenames>J. Marius</forenames></author></authors><title>CNN-based synthesis of realistic high-resolution LiDAR data</title><categories>eess.IV cs.LG stat.ML</categories><comments>2019 IEEE Intelligent Vehicles Symposium (IV)</comments><doi>10.1109/IVS.2019.8813771</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel CNN-based approach for synthesizing
high-resolution LiDAR point cloud data. Our approach generates semantically and
perceptually realistic results with guidance from specialized loss-functions.
First, we utilize a modified per-point loss that addresses missing LiDAR point
measurements. Second, we align the quality of our generated output with
real-world sensor data by applying a perceptual loss. In large-scale
experiments on real-world datasets, we evaluate both the geometric accuracy and
semantic segmentation performance using our generated data vs. ground truth. In
a mean opinion score testing we further assess the perceptual quality of our
generated point clouds. Our results demonstrate a significant quantitative and
qualitative improvement in both geometry and semantics over traditional non
CNN-based up-sampling methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00789</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00789</id><created>2019-06-28</created><authors><author><keyname>Gayan</keyname><forenames>Samiru</forenames></author><author><keyname>Inaltekin</keyname><forenames>Hazer</forenames></author><author><keyname>Senanayake</keyname><forenames>Rajitha</forenames></author><author><keyname>Evans</keyname><forenames>Jamie</forenames></author></authors><title>Phase Modulated Communication with Low-Resolution ADCs</title><categories>eess.SP cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1902.10896</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a low-resolution wireless communication system in which
transmitted signals are corrupted by fading and additive noise. First, a
universal lower bound on the average symbol error probability (SEP), correct
for all M-ary modulation schemes, is obtained when the number of quantization
bits is not enough to resolve M signal points. Second, in the special case of
M-ary phase shift keying (M-PSK), the optimum maximum likelihood detector for
equiprobable signal points is derived. Third, utilizing the structure of the
derived optimum receiver, a general average SEP expression for the M-PSK
modulation with n-bit quantization is obtained when the wireless channel is
subject to fading with a circularly-symmetric distribution. Finally, an
extensive simulation study of the derived analytical results is presented for
general Nakagami-m fading channels. It is observed that a transceiver
architecture with n-bit quantization is asymptotically optimum in terms of
communication reliability if n is greater than or equal to log_2(M +1). That
is, the decay exponent for the average SEP is the same and equal to m with
infinite-bit and n-bit quantizers for n greater than or equal to log_2(M+1). On
the other hand, it is only equal to half and 0 for n = log_2(M) and n &lt;
log_2(M), respectively. Hence, for fading environments with a large value of m,
using an extra quantization bit improves communication reliability
significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00793</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00793</id><created>2019-07-01</created><authors><author><keyname>Astapenya</keyname><forenames>Volodymyr</forenames></author><author><keyname>Sokolov</keyname><forenames>Volodymyr</forenames></author><author><keyname>TajDini</keyname><forenames>Mahyar</forenames></author></authors><title>Results and Tools for Evaluating the Effectiveness of Focusing Systems
  to Improve Accessibility in Wireless Networks</title><categories>eess.SP cs.NI</categories><comments>in Ukrainian</comments><acm-class>C.2.0; C.2.1</acm-class><journal-ref>Cybersecurity: Education, Science, Technique (ISSN: 2663-4023),
  no. 4, 2019</journal-ref><doi>10.28925/2663-4023.2019.4.90103</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The widespread use of wireless technologies leads to an ever-increasing
number of users and permanently functioning devices. However, the growth of the
number of wireless users in a limited space and a limited frequency range leads
to an increase in their mutual influence, which ultimately affects the
throughput of wireless channels and even the performance of the system as a
whole. The article presents the statistics and tendencies of the distribution
of wireless networks of the IEEE 802.11 standard systems, as well as analyzes
the main problems that arise during the expansion of their use. Substantiation
and choice of ways to overcome these difficulties largely depends on the
objective control of radiation parameters of access points and subscriber funds
in a particular environment. The review of the state control facilities
provided by the developers of the equipment is presented, and author's variants
of experimental measuring complexes are offered, allowing to control signal and
information parameters of Wi-Fi systems. The experimental results obtained with
the use of the indicated means, obtained using the accelerating metal-plate
lens as an additional autonomous element for focusing the field, including for
MIMO systems, the effect of the accelerating metal-plate lens on the spatial
distribution of the field, on the spectral structure of the signal are
presented. In addition, polarization effects were investigated. Possible ways
to further increase the availability, integrity of information and energy
efficiency of wireless access systems are discussed. The authors propose
simpler and less costly options for increasing the direction of radiation on
the basis of an accelerating metal-plate lens, experimentally tested, as well
as the use of zone zoning on the path of the computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00797</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00797</id><created>2019-07-01</created><updated>2019-07-21</updated><authors><author><keyname>Wu</keyname><forenames>Yi-Chiao</forenames></author><author><keyname>Hayashi</keyname><forenames>Tomoki</forenames></author><author><keyname>Tobing</keyname><forenames>Patrick Lumban</forenames></author><author><keyname>Kobayashi</keyname><forenames>Kazuhiro</forenames></author><author><keyname>Toda</keyname><forenames>Tomoki</forenames></author></authors><title>Quasi-Periodic WaveNet Vocoder: A Pitch Dependent Dilated Convolution
  Model for Parametric Speech Generation</title><categories>eess.AS cs.SD</categories><comments>5 pages, 4 figures, Proc. Interspeech, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a quasi-periodic neural network (QPNet) vocoder
with a novel network architecture named pitch-dependent dilated convolution
(PDCNN) to improve the pitch controllability of WaveNet (WN) vocoder. The
effectiveness of the WN vocoder to generate high-fidelity speech samples from
given acoustic features has been proved recently. However, because of the fixed
dilated convolution and generic network architecture, the WN vocoder hardly
generates speech with given F0 values which are outside the range observed in
training data. Consequently, the WN vocoder lacks the pitch controllability
which is one of the essential capabilities of conventional vocoders. To address
this limitation, we propose the PDCNN component which has the time-variant
adaptive dilation size related to the given F0 values and a cascade network
structure of the QPNet vocoder to generate quasi-periodic signals such as
speech. Both objective and subjective tests are conducted, and the experimental
results demonstrate the better pitch controllability of the QPNet vocoder
compared to the same and double sized WN vocoders while attaining comparable
speech qualities. Index Terms: WaveNet, vocoder, quasi-periodic signal,
pitch-dependent dilated convolution, pitch controllability
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00811</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00811</id><created>2019-07-01</created><authors><author><keyname>Wang</keyname><forenames>Xiaoyang</forenames></author><author><keyname>Mavromatis</keyname><forenames>Ioannis</forenames></author><author><keyname>Tassi</keyname><forenames>Andrea</forenames></author><author><keyname>Santos-Rodriguez</keyname><forenames>Raul</forenames></author><author><keyname>Piechocki</keyname><forenames>Robert J.</forenames></author></authors><title>Location Anomalies Detection for Connected and Autonomous Vehicles</title><categories>cs.LG cs.NI eess.SP stat.ML</categories><comments>Accepted to IEEE CAVS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future Connected and Automated Vehicles (CAV), and more generally ITS, will
form a highly interconnected system. Such a paradigm is referred to as the
Internet of Vehicles (herein Internet of CAVs) and is a prerequisite to
orchestrate traffic flows in cities. For optimal decision making and
supervision, traffic centres will have access to suitably anonymized CAV
mobility information. Safe and secure operations will then be contingent on
early detection of anomalies. In this paper, a novel unsupervised learning
model based on deep autoencoder is proposed to detect the self-reported
location anomaly in CAVs, using vehicle locations and the Received Signal
Strength Indicator (RSSI) as features. Quantitative experiments on simulation
datasets show that the proposed approach is effective and robust in detecting
self-reported location anomalies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00818</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00818</id><created>2019-07-01</created><updated>2019-08-15</updated><authors><author><keyname>Ribeiro</keyname><forenames>Manuel Sam</forenames></author><author><keyname>Eshky</keyname><forenames>Aciel</forenames></author><author><keyname>Richmond</keyname><forenames>Korin</forenames></author><author><keyname>Renals</keyname><forenames>Steve</forenames></author></authors><title>Ultrasound tongue imaging for diarization and alignment of child speech
  therapy sessions</title><categories>eess.AS cs.CL cs.SD eess.IV</categories><comments>5 pages, 3 figures, Accepted for publication at Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the automatic processing of child speech therapy sessions
using ultrasound visual biofeedback, with a specific focus on complementing
acoustic features with ultrasound images of the tongue for the tasks of speaker
diarization and time-alignment of target words. For speaker diarization, we
propose an ultrasound-based time-domain signal which we call estimated tongue
activity. For word-alignment, we augment an acoustic model with low-dimensional
representations of ultrasound images of the tongue, learned by a convolutional
neural network. We conduct our experiments using the Ultrasuite repository of
ultrasound and speech recordings for child speech therapy sessions. For both
tasks, we observe that systems augmented with ultrasound data outperform
corresponding systems using only the audio signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00821</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00821</id><created>2019-07-01</created><authors><author><keyname>Simidjievski</keyname><forenames>Nikola</forenames></author><author><keyname>Todorovski</keyname><forenames>Ljup&#x10d;o</forenames></author><author><keyname>Kocijan</keyname><forenames>Ju&#x161;</forenames></author><author><keyname>D&#x17e;eroski</keyname><forenames>Sa&#x161;o</forenames></author></authors><title>Equation Discovery for Nonlinear System Identification</title><categories>cs.LG cs.SY eess.SY math.DS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Equation discovery methods enable modelers to combine domain-specific
knowledge and system identification to construct models most suitable for a
selected modeling task. The method described and evaluated in this paper can be
used as a nonlinear system identification method for gray-box modeling. It
consists of two interlaced parts of modeling that are computer-aided. The first
performs computer-aided identification of a model structure composed of
elements selected from user-specified domain-specific modeling knowledge, while
the second part performs parameter estimation. In this paper, recent
developments of the equation discovery method called process-based modeling,
suited for nonlinear system identification, are elaborated and illustrated on
two continuous-time case studies. The first case study illustrates the use of
the process-based modeling on synthetic data while the second case-study
evaluates on measured data for a standard system-identification benchmark. The
experimental results clearly demonstrate the ability of process-based modeling
to reconstruct both model structure and parameters from measured data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00824</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00824</id><created>2019-07-01</created><authors><author><keyname>Scurto</keyname><forenames>Hugo</forenames></author><author><keyname>Van Kerrebroeck</keyname><forenames>Bavo</forenames></author><author><keyname>Caramiaux</keyname><forenames>Baptiste</forenames></author><author><keyname>Bevilacqua</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author></authors><title>Designing Deep Reinforcement Learning for Human Parameter Exploration</title><categories>cs.HC cs.LG cs.SD eess.AS</categories><comments>Preprint. Under review for publication in ACM Transactions on
  Computer-Human Interaction (TOCHI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software tools for generating digital sound often present users with
high-dimensional, parametric interfaces, that may not facilitate exploration of
diverse sound designs. In this paper, we propose to investigate artificial
agents using deep reinforcement learning to explore parameter spaces in
partnership with users for sound design. We describe a series of user-centred
studies to probe the creative benefits of these agents and adapting their
design to exploration. Preliminary studies observing users' exploration
strategies with parametric interfaces and testing different agent exploration
behaviours led to the design of a fully-functioning prototype, called
Co-Explorer, that we evaluated in a workshop with professional sound designers.
We found that the Co-Explorer enables a novel creative workflow centred on
human-machine partnership, which has been positively received by practitioners.
We also highlight varied user exploration behaviors throughout partnering with
our system. Finally, we frame design guidelines for enabling such
co-exploration workflow in creative digital applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00831</identifier>
 <datestamp>2019-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00831</id><created>2019-07-01</created><updated>2019-11-23</updated><authors><author><keyname>Yoon</keyname><forenames>Young-Chul</forenames></author><author><keyname>Kim</keyname><forenames>Du Yong</forenames></author><author><keyname>Yoon</keyname><forenames>Kwangjin</forenames></author><author><keyname>Song</keyname><forenames>Young-min</forenames></author><author><keyname>Jeon</keyname><forenames>Moongu</forenames></author></authors><title>Online Multiple Pedestrian Tracking using Deep Temporal Appearance
  Matching Association</title><categories>cs.CV cs.LG eess.IV</categories><comments>14 pages, 16 figures, 3rd ranked tracker of the MOTChallenge on
  CVPR19 workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In online multiple pedestrian tracking, it is of great importance to model
appearance and geometric similarity between existing tracks and targets
appeared in a new frame. The appearance model contains discriminative
information with higher dimension compared to the geometric model. Thanks to
the recent success of deep learning based methods, handling of high dimensional
appearance information becomes possible. Among many deep networks, the Siamese
network with triplet loss is popularly adopted as an appearance feature
extractor. Since the Siamese network can extract features of each input
independently, it is possible to update and maintain target-specific features.
However, it is not suitable for multi-object settings that require comparison
with other inputs. In this paper we propose a novel track appearance model
based on joint-inference network to address this issue. The proposed method
enables comparison of two inputs to be used for adaptive appearance modeling.
It contributes to disambiguating the process of target-observation matching and
consolidating the identity consistency. Intensive experimental results support
effectiveness of our method. Our work has been awarded as a 3rd-highest tracker
on MOTChallenge19, held in CVPR2019.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00835</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00835</id><created>2019-07-01</created><authors><author><keyname>Eshky</keyname><forenames>Aciel</forenames></author><author><keyname>Ribeiro</keyname><forenames>Manuel Sam</forenames></author><author><keyname>Cleland</keyname><forenames>Joanne</forenames></author><author><keyname>Richmond</keyname><forenames>Korin</forenames></author><author><keyname>Roxburgh</keyname><forenames>Zoe</forenames></author><author><keyname>Scobbie</keyname><forenames>James</forenames></author><author><keyname>Wrench</keyname><forenames>Alan</forenames></author></authors><title>UltraSuite: A Repository of Ultrasound and Acoustic Data from Child
  Speech Therapy Sessions</title><categories>cs.CL cs.CV cs.SD eess.AS eess.IV</categories><comments>5 pages, 1 figure, 3 tables; accepted to Interspeech 2018: 19th
  Annual Conference of the International Speech Communication Association
  (ISCA)</comments><doi>10.21437/Interspeech.2018-1736</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce UltraSuite, a curated repository of ultrasound and acoustic
data, collected from recordings of child speech therapy sessions. This release
includes three data collections, one from typically developing children and two
from children with speech sound disorders. In addition, it includes a set of
annotations, some manual and some automatically produced, and software tools to
process, transform and visualise the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00856</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00856</id><created>2019-07-01</created><authors><author><keyname>Sarker</keyname><forenames>Md. Mostafa Kamal</forenames></author><author><keyname>Rashwan</keyname><forenames>Hatem A.</forenames></author><author><keyname>Abdel-Nasser</keyname><forenames>Mohamed</forenames></author><author><keyname>Singh</keyname><forenames>Vivek Kumar</forenames></author><author><keyname>Banu</keyname><forenames>Syeda Furruka</forenames></author><author><keyname>Akram</keyname><forenames>Farhan</forenames></author><author><keyname>Chowdhury</keyname><forenames>Forhad U H</forenames></author><author><keyname>Choudhury</keyname><forenames>Kabir Ahmed</forenames></author><author><keyname>Chambon</keyname><forenames>Sylvie</forenames></author><author><keyname>Radeva</keyname><forenames>Petia</forenames></author><author><keyname>Puig</keyname><forenames>Domenec</forenames></author></authors><title>MobileGAN: Skin Lesion Segmentation Using a Lightweight Generative
  Adversarial Network</title><categories>eess.IV cs.CV</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Skin lesion segmentation in dermoscopic images is a challenge due to their
blurry and irregular boundaries. Most of the segmentation approaches based on
deep learning are time and memory consuming due to the hundreds of millions of
parameters. Consequently, it is difficult to apply them to real dermatoscope
devices with limited GPU and memory resources. In this paper, we propose a
lightweight and efficient Generative Adversarial Networks (GAN) model, called
MobileGAN for skin lesion segmentation. More precisely, the MobileGAN combines
1D non-bottleneck factorization networks with position and channel attention
modules in a GAN model. The proposed model is evaluated on the test dataset of
the ISBI 2017 challenges and the validation dataset of ISIC 2018 challenges.
Although the proposed network has only 2.35 millions of parameters, it is still
comparable with the state-of-the-art. The experimental results show that our
MobileGAN obtains comparable performance with an accuracy of 97.61%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00860</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00860</id><created>2019-07-01</created><authors><author><keyname>Zhang</keyname><forenames>Jiankang</forenames></author><author><keyname>Xu</keyname><forenames>Chao</forenames></author><author><keyname>Bai</keyname><forenames>Tong</forenames></author><author><keyname>Wang</keyname><forenames>Fasong</forenames></author><author><keyname>Zhong</keyname><forenames>Shida</forenames></author></authors><title>Energy Efficient Transmission Based on Grouped Spatial Modulation for
  upstream DSL Systems</title><categories>eess.SP</categories><comments>14 pages, 15 figures</comments><doi>10.1109/ACCESS.2019.2926063</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The digital Subscriber Line (DSL) remains an important component of
heterogeneous networking, especially in historic city-centers, where using
optical fibre is less realistic. Recently, the power consumption has become an
important performance metric in telecommunication due to the associated
environmental issues. In the recent bonding model, customer sites have been
equipped with two/four copper pairs, which may be exploited for designing
grouped spatial modulation (SM) aiming for reducing the power consumption and
mitigating the stubborn crosstalk in DSL communications. Explicitly, we view
the two pair copper pairs equipped for each user as a group and propose an
energy efficient transmission scheme based on grouped SM strategy for the
upstream DSL systems, which is capable of reducing the power consumption of the
upstream transmitters by activating a single copper line of each user. More
especially, in order to compensate for the potential bit-rate reduction imposed
by reducing the number of activated lines, the proposed scheme implicitly
delivers ``virtual bits&quot; via activating/deactivating the lines in addition to
the classic modulation scheme. This is particularly beneficial in the DSL
context, because the cross-talk imposed by activating several lines may swamp
the desired signal. Furthermore, a pair of near-optimal soft turbo detection
schemes are proposed for exploiting the unique properties of the DSL channel in
order to eliminate the error propagation problem of SM detection routinely
encountered in wireless channels. Both the attainable energy-efficiency and the
achievable Bit Error Ratio (BER) are investigated. Our simulation results
demonstrate that the proposed group-based SM is capable of outperforming the
vectoring scheme both in terms of its energy efficiency for all the examined
loop lengths and transmit powers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00873</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00873</id><created>2019-07-01</created><authors><author><keyname>Shi</keyname><forenames>Bowen</forenames></author><author><keyname>Sun</keyname><forenames>Ming</forenames></author><author><keyname>Kao</keyname><forenames>Chieh-Chi</forenames></author><author><keyname>Rozgic</keyname><forenames>Viktor</forenames></author><author><keyname>Matsoukas</keyname><forenames>Spyros</forenames></author><author><keyname>Wang</keyname><forenames>Chao</forenames></author></authors><title>Compression of Acoustic Event Detection Models With Quantized
  Distillation</title><categories>eess.AS cs.LG cs.SD</categories><comments>Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic Event Detection (AED), aiming at detecting categories of events
based on audio signals, has found application in many intelligent systems.
Recently deep neural network significantly advances this field and reduces
detection errors to a large scale. However how to efficiently execute deep
models in AED has received much less attention. Meanwhile state-of-the-art AED
models are based on large deep models, which are computational demanding and
challenging to deploy on devices with constrained computational resources. In
this paper, we present a simple yet effective compression approach which
jointly leverages knowledge distillation and quantization to compress larger
network (teacher model) into compact network (student model). Experimental
results show proposed technique not only lowers error rate of original compact
network by 15% through distillation but also further reduces its model size to
a large extent (2% of teacher, 12% of full-precision student) through
quantization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00881</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00881</id><created>2019-07-01</created><authors><author><keyname>Lal</keyname><forenames>Cerine</forenames></author><author><keyname>Subhash</keyname><forenames>Hrebesh M</forenames></author><author><keyname>Alexandrov</keyname><forenames>Sergey</forenames></author><author><keyname>Leahy</keyname><forenames>Martin J</forenames></author></authors><title>Feasibility of cmOCT angiographic technique using 200 kHz VCSEL source
  for in vivo microcirculation imaging applications</title><categories>physics.med-ph eess.IV</categories><journal-ref>Applied optics 57.22 (2018): E224-E231</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Optical coherence tomography (OCT) angiography is a well-established in vivo
imaging technique to assess the overall vascular morphology of tissues and is
an emerging field of research for the assessment of blood flow dynamics and
functional parameters such as oxygen saturation. In this study, we present a
modified scanning based correlation mapping OCT (cmOCT) using a 200 kHz high
speed swept source OCT system operating at 1300 nm and demonstrate its wide
field imaging capability in ocular angiographic studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00887</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00887</id><created>2019-07-01</created><authors><author><keyname>Singh</keyname><forenames>Vivek Kumar</forenames></author><author><keyname>Rashwan</keyname><forenames>Hatem A.</forenames></author><author><keyname>Abdel-Nasser</keyname><forenames>Mohamed</forenames></author><author><keyname>Sarker</keyname><forenames>Md. Mostafa Kamal</forenames></author><author><keyname>Akram</keyname><forenames>Farhan</forenames></author><author><keyname>Pandey</keyname><forenames>Nidhi</forenames></author><author><keyname>Romani</keyname><forenames>Santiago</forenames></author><author><keyname>Puig</keyname><forenames>Domenec</forenames></author></authors><title>An Efficient Solution for Breast Tumor Segmentation and Classification
  in Ultrasound Images Using Deep Adversarial Learning</title><categories>eess.IV cs.CV</categories><comments>9 pages</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This paper proposes an efficient solution for tumor segmentation and
classification in breast ultrasound (BUS) images. We propose to add an atrous
convolution layer to the conditional generative adversarial network (cGAN)
segmentation model to learn tumor features at different resolutions of BUS
images. To automatically re-balance the relative impact of each of the highest
level encoded features, we also propose to add a channel-wise weighting block
in the network. In addition, the SSIM and L1-norm loss with the typical
adversarial loss are used as a loss function to train the model. Our model
outperforms the state-of-the-art segmentation models in terms of the Dice and
IoU metrics, achieving top scores of 93.76% and 88.82%, respectively. In the
classification stage, we show that few statistics features extracted from the
shape of the boundaries of the predicted masks can properly discriminate
between benign and malignant tumors with an accuracy of 85%$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00892</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00892</id><created>2019-07-01</created><authors><author><keyname>Reddy</keyname><forenames>Siddartha</forenames></author><author><keyname>Chepuri</keyname><forenames>Sundeep Prabhakar</forenames></author></authors><title>Sampling And Reconstruction Of Diffusive Fields On Graphs</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, the focus is on the reconstruction of a diffusive field and
the localization of the underlying driving sources on arbitrary graphs by
observing a significantly smaller subset of vertices of the graph uniformly in
time. Specifically, we focus on the heat diffusion equation driven by an
initial field and an external time-invariant input. When the underlying driving
sources are modeled as an initial field or external input, the sources (hence
the diffusive field) can be recovered from the subsampled observations without
imposing any band-limiting or sparsity constraints. When the diffusion is
induced by both the initial field and external input, then the field and
sources can be recovered from the subsampled observations, however, by imposing
band-limiting constraints on either the initial field or external input. For
heat diffusion on graphs, we can compensate for the unobserved vertices with
the temporal samples at the observed vertices. If the observations are
noiseless, then the recovery is exact. Nonetheless, the developed least squares
estimators perform reasonably well with noisy observations. We apply the
developed theory for localizing and recovering hot spots on a rectangular metal
plate with a cavity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00941</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00941</id><created>2019-07-01</created><updated>2019-09-30</updated><authors><author><keyname>Liu</keyname><forenames>Yi</forenames></author><author><keyname>Yuan</keyname><forenames>Hao</forenames></author><author><keyname>Wang</keyname><forenames>Zhengyang</forenames></author><author><keyname>Ji</keyname><forenames>Shuiwang</forenames></author></authors><title>Global Pixel Transformers for Virtual Staining of Microscopy Images</title><categories>eess.IV cs.LG stat.ML</categories><comments>10 pages, 6 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visualizing the details of different cellular structures is of great
importance to elucidate cellular functions. However, it is challenging to
obtain high quality images of different structures directly due to complex
cellular environments. Fluorescence staining is a popular technique to label
different structures but has several drawbacks. In particular, label staining
is time consuming and may affect cell morphology, and simultaneous labels are
inherently limited. This raises the need of building computational models to
learn relationships between unlabeled microscopy images and labeled
fluorescence images, and to infer fluorescence labels of other microscopy
images excluding the physical staining process. We propose to develop a novel
deep model for virtual staining of unlabeled microscopy images. We first
propose a novel network layer, known as the global pixel transformer layer,
that fuses global information from inputs effectively. The proposed global
pixel transformer layer can generate outputs with arbitrary dimensions, and can
be employed for all the regular, down-sampling, and up-sampling operators. We
then incorporate our proposed global pixel transformer layers and dense blocks
to build an U-Net like network. We believe such a design can promote feature
reusing between layers. In addition, we propose a multi-scale input strategy to
encourage networks to capture features at different scales. We conduct
evaluations across various fluorescence image prediction tasks to demonstrate
the effectiveness of our approach. Both quantitative and qualitative results
show that our method outperforms the state-of-the-art approach significantly.
It is also shown that our proposed global pixel transformer layer is useful to
improve the fluorescence image prediction results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00943</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00943</id><created>2019-07-01</created><authors><author><keyname>Feng</keyname><forenames>Xinyang</forenames></author><author><keyname>Lipton</keyname><forenames>Zachary C.</forenames></author><author><keyname>Yang</keyname><forenames>Jie</forenames></author><author><keyname>Small</keyname><forenames>Scott A.</forenames></author><author><keyname>Provenzano</keyname><forenames>Frank A.</forenames></author></authors><title>Estimating brain age based on a healthy population with deep learning
  and structural MRI</title><categories>cs.CV eess.IV q-bio.QM</categories><comments>32 pages, 9 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous studies have established that estimated brain age, as derived from
statistical models trained on healthy populations, constitutes a valuable
biomarker that is predictive of cognitive decline and various neurological
diseases. In this work, we curate a large-scale heterogeneous dataset (N =
10,158, age range 18 - 97) of structural brain MRIs in a healthy population
from multiple publicly-available sources, upon which we train a deep learning
model for brain age estimation. The availability of the large-scale dataset
enables a more uniform age distribution across adult life-span for effective
age estimation with no bias toward certain age groups. We demonstrate that the
age estimation accuracy, evaluated with mean absolute error (MAE) and
correlation coefficient (r), outperforms previously reported methods in both a
hold-out test set reflective of the custom population (MAE = 4.06 years, r =
0.970) and an independent life-span evaluation dataset (MAE = 4.21 years, r =
0.960) on which a previous study has evaluated. We further demonstrate the
utility of the estimated age in life-span aging analysis of cognitive
functions. Furthermore, we conduct extensive ablation tests and employ
feature-attribution techniques to analyze which regions contribute the most
predictive value, demonstrating the prominence of the frontal lobe as well as
pattern shift across life-span. In summary, we achieve superior age estimation
performance confirming the efficacy of deep learning and the added utility of
training with data both in larger number and more uniformly distributed than in
previous studies. We demonstrate the regional contribution to our brain age
predictions through multiple routes and confirm the association of divergence
between estimated and chronological brain age with neuropsychological measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00968</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00968</id><created>2019-06-30</created><authors><author><keyname>Sadhu</keyname><forenames>Vidyasagar</forenames></author><author><keyname>Devaraj</keyname><forenames>Sanjana</forenames></author><author><keyname>Pompili</keyname><forenames>Dario</forenames></author></authors><title>Energy-efficient Wireless Analog Sensing for Persistent Underwater
  Environmental Monitoring</title><categories>eess.SP cs.ET cs.NI</categories><comments>5 pages, IEEE UComms 2018</comments><journal-ref>2018 Fourth Underwater Communications and Networking Conference
  (UComms), Lerici, 2018, pp. 1-5</journal-ref><doi>10.1109/UComms.2018.8493166</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of sensors or &quot;things&quot; as part of the new Internet of Underwater
Things (IoUTs) paradigm comes with multiple challenges including limited
battery capacity, not polluting the water body, and the ability to track
continuously phenomena with high temporal/spatial variability. We claim that
traditional digital sensors are incapable to meet these demands because of
their high power consumption, high complexity (cost), and the use of
non-biodegradable materials. To address the above challenges, we propose a
novel architecture consisting of a sensing substrate of dense analog
biodegradable sensors over which lies the traditional Wireless Sensor Network
(WSN). The substrate analog biodegradable sensors perform Shannon mapping (a
data-compression technique) using just a single Field Effect Transistor (FET)
without the need for power-hungry Analog-to-Digital Converters (ADCs) resulting
in much lower power consumption, complexity, and the ability to be powered
using only sustainable energy-harvesting techniques. A novel and efficient
decoding technique is also presented. Both encoding/decoding techniques have
been verified via Spice and MATLAB simulations accounting for underwater
acoustic channel variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00971</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00971</id><created>2019-07-01</created><authors><author><keyname>Esling</keyname><forenames>Philippe</forenames></author><author><keyname>Masuda</keyname><forenames>Naotake</forenames></author><author><keyname>Bardet</keyname><forenames>Adrien</forenames></author><author><keyname>Despres</keyname><forenames>Romeo</forenames></author><author><keyname>Chemla--Romeu-Santos</keyname><forenames>Axel</forenames></author></authors><title>Universal audio synthesizer control with normalizing flows</title><categories>cs.LG cs.HC cs.MM cs.SD eess.AS stat.ML</categories><comments>DaFX 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The ubiquity of sound synthesizers has reshaped music production and even
entirely defined new music genres. However, the increasing complexity and
number of parameters in modern synthesizers make them harder to master. Hence,
the development of methods allowing to easily create and explore with
synthesizers is a crucial need. Here, we introduce a novel formulation of audio
synthesizer control. We formalize it as finding an organized latent audio space
that represents the capabilities of a synthesizer, while constructing an
invertible mapping to the space of its parameters. By using this formulation,
we show that we can address simultaneously automatic parameter inference,
macro-control learning and audio-based preset exploration within a single
model. To solve this new formulation, we rely on Variational Auto-Encoders
(VAE) and Normalizing Flows (NF) to organize and map the respective auditory
and parameter spaces. We introduce the disentangling flows, which allow to
perform the invertible mapping between separate latent spaces, while steering
the organization of some latent dimensions to match target variation factors by
splitting the objective as partial density evaluation. We evaluate our proposal
against a large set of baseline models and show its superiority in both
parameter inference and audio reconstruction. We also show that the model
disentangles the major factors of audio variations as latent dimensions, that
can be directly used as macro-parameters. We also show that our model is able
to learn semantic controls of a synthesizer by smoothly mapping to its
parameters. Finally, we discuss the use of our model in creative applications
and its real-time implementation in Ableton Live
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00973</identifier>
 <datestamp>2020-01-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.00973</id><created>2019-07-01</created><updated>2020-01-09</updated><authors><author><keyname>Ezhov</keyname><forenames>Ivan</forenames></author><author><keyname>Lipkova</keyname><forenames>Jana</forenames></author><author><keyname>Shit</keyname><forenames>Suprosanna</forenames></author><author><keyname>Kofler</keyname><forenames>Florian</forenames></author><author><keyname>Collomb</keyname><forenames>Nore</forenames></author><author><keyname>Lemasson</keyname><forenames>Benjamin</forenames></author><author><keyname>Barbier</keyname><forenames>Emmanuel</forenames></author><author><keyname>Menze</keyname><forenames>Bjoern</forenames></author></authors><title>Neural parameters estimation for brain tumor growth modeling</title><categories>q-bio.QM cs.LG eess.IV stat.ML</categories><doi>10.1007/978-3-030-32245-8_87</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the dynamics of brain tumor progression is essential for
optimal treatment planning. Cast in a mathematical formulation, it is typically
viewed as evaluation of a system of partial differential equations, wherein the
physiological processes that govern the growth of the tumor are considered. To
personalize the model, i.e. find a relevant set of parameters, with respect to
the tumor dynamics of a particular patient, the model is informed from
empirical data, e.g., medical images obtained from diagnostic modalities, such
as magnetic-resonance imaging. Existing model-observation coupling schemes
require a large number of forward integrations of the biophysical model and
rely on simplifying assumption on the functional form, linking the output of
the model with the image information. In this work, we propose a learning-based
technique for the estimation of tumor growth model parameters from medical
scans. The technique allows for explicit evaluation of the posterior
distribution of the parameters by sequentially training a mixture-density
network, relaxing the constraint on the functional form and reducing the number
of samples necessary to propagate through the forward model for the estimation.
We test the method on synthetic and real scans of rats injected with brain
tumors to calibrate the model and to predict tumor progression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01004</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01004</id><created>2019-07-01</created><updated>2019-08-26</updated><authors><author><keyname>De Luca</keyname><forenames>Felice</forenames></author><author><keyname>Hossain</keyname><forenames>Md Iqbal</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen</forenames></author></authors><title>Symmetry Detection and Classification in Drawings of Graphs</title><categories>cs.CV cs.CG eess.IV</categories><comments>Appears in the Proceedings of the 27th International Symposium on
  Graph Drawing and Network Visualization (GD 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetry is a key feature observed in nature (from flowers and leaves, to
butterflies and birds) and in human-made objects (from paintings and
sculptures, to manufactured objects and architectural design). Rotational,
translational, and especially reflectional symmetries, are also important in
drawings of graphs. Detecting and classifying symmetries can be very useful in
algorithms that aim to create symmetric graph drawings and in this paper we
present a machine learning approach for these tasks. Specifically, we show that
deep neural networks can be used to detect reflectional symmetries with 92%
accuracy. We also build a multi-class classifier to distinguish between
reflectional horizontal, reflectional vertical, rotational, and translational
symmetries. Finally, we make available a collection of images of graph drawings
with specific symmetric features that can be used in machine learning systems
for training, testing and validation purposes. Our datasets, best trained ML
models, source code are available online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01030</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01030</id><created>2019-07-01</created><authors><author><keyname>Beck</keyname><forenames>Eugen</forenames></author><author><keyname>Zhou</keyname><forenames>Wei</forenames></author><author><keyname>Schl&#xfc;ter</keyname><forenames>Ralf</forenames></author><author><keyname>Ney</keyname><forenames>Hermann</forenames></author></authors><title>LSTM Language Models for LVCSR in First-Pass Decoding and
  Lattice-Rescoring</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  LSTM based language models are an important part of modern LVCSR systems as
they significantly improve performance over traditional backoff language
models. Incorporating them efficiently into decoding has been notoriously
difficult. In this paper we present an approach based on a combination of
one-pass decoding and lattice rescoring. We perform decoding with the LSTM-LM
in the first pass but recombine hypothesis that share the last two words,
afterwards we rescore the resulting lattice. We run our systems on GPGPU
equipped machines and are able to produce competitive results on the Hub5'00
and Librispeech evaluation corpora with a runtime better than real-time. In
addition we shortly investigate the possibility to carry out the full sum over
all state-sequences belonging to a given word-hypothesis during decoding
without recombination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01034</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01034</id><created>2019-07-01</created><updated>2019-07-04</updated><authors><author><keyname>Gaziv</keyname><forenames>Guy</forenames></author></authors><title>Learning to aggregate feature representations</title><categories>cs.CV eess.IV q-bio.NC</categories><comments>Report for Algonauts2019 challenge. 4 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Algonauts challenge requires to construct a multi-subject encoder of
images to brain activity. Deep networks such as ResNet-50 and AlexNet trained
for image classification are known to produce feature representations along
their intermediate stages which closely mimic the visual hierarchy. However the
challenges introduced in the Algonauts project, including combining data from
multiple subjects, relying on very few similarity data points, solving for
various ROIs, and multi-modality, require devising a flexible framework which
can efficiently accommodate them. Here we build upon a recent state-of-the-art
classification network (SE-ResNeXt-50) and construct an adaptive combination of
its intermediate representations. While the pretrained network serves as a
backbone of our model, we learn how to aggregate feature representations along
five stages of the network. During learning, our method enables to modulate and
screen outputs from each stage along the network as governed by the optimized
objective. We applied our method to the Algonauts2019 fMRI and MEG challenges.
Using the combined fMRI and MEG data, our approach was rated among the leading
five for both challenges. Surprisingly we find that for both the lower and
higher order areas (EVC and IT) the adaptive aggregation favors features
stemming at later stages of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01035</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01035</id><created>2019-07-01</created><updated>2020-02-01</updated><authors><author><keyname>Arik</keyname><forenames>Muharrem</forenames></author><author><keyname>Akan</keyname><forenames>Ozgur B.</forenames></author></authors><title>Capacity Analysis for Joint Radar-Communication Capable Coherent MIMO
  Radars</title><categories>eess.SP</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, huge attention is attracted to the concept of integrating
communication and radar missions within the same platform. Joint
radar-communications (JRC) system gives an important opportunity to reduce
spectrum usage and product cost while doing concurrent operation, as target
sensing via radar processing and establishing communication links. A
JRC-capable coherent MIMO radar system have been proposed recently in the
literature. Several methods are introduced to reach dual goal as a notable null
level towards the direction of interest of the radar and MIMO radar waveform
orthogonality. Due to the limitations originated form the JRC operation,
communication channel may encounter unwanted amplitude variations. This
unwanted modulation normally affects the communication performance by its
nature, due to the fades on radiated signal amplitude towards the direction of
communication. However, the effect of this unintentional modulation on
communication channel is yet to be investigated. In this paper, the
communication channel for JRC capable phase-coded coherent MIMO radars is
analyzed and investigated under additive white Gaussian noise and
Rayleigh/Rician fading conditions. Communication capacity is evaluated for each
channel condition. The results reveal that, using the single-side limited null
direction fixed waveform generation method displays the best capacity
performance under all channel conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01038</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01038</id><created>2019-07-01</created><authors><author><keyname>Jha</keyname><forenames>Saurabh</forenames></author><author><keyname>Banerjee</keyname><forenames>Subho S.</forenames></author><author><keyname>Cyriac</keyname><forenames>James</forenames></author><author><keyname>Kalbarczyk</keyname><forenames>Zbigniew T.</forenames></author><author><keyname>Iyer</keyname><forenames>Ravishankar K.</forenames></author></authors><title>AVFI: Fault Injection for Autonomous Vehicles</title><categories>eess.SP</categories><comments>Published in: 2018 48th Annual IEEE/IFIP International Conference on
  Dependable Systems and Networks Workshops (DSN-W)</comments><doi>10.1109/DSN-W.2018.00027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous vehicle (AV) technology is rapidly becoming a reality on U.S.
roads, offering the promise of improvements in traffic management, safety, and
the comfort and efficiency of vehicular travel. With this increasing popularity
and ubiquitous deployment, resilience has become a critical requirement for
public acceptance and adoption. Recent studies into the resilience of AVs have
shown that though the AV systems are improving over time, they have not reached
human levels of automation. Prior work in this area has studied the safety and
resilience of individual components of the AV system (e.g., testing of neural
networks powering the perception function). However, methods for holistic
end-to-end resilience assessment of AV systems are still non-existent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01042</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01042</id><created>2019-07-01</created><authors><author><keyname>Marin-Palomo</keyname><forenames>Pablo</forenames></author><author><keyname>Kemal</keyname><forenames>Juned N.</forenames></author><author><keyname>Freude</keyname><forenames>Wolfgang</forenames></author><author><keyname>Randel</keyname><forenames>Sebastian</forenames></author><author><keyname>Koos</keyname><forenames>Christian</forenames></author></authors><title>OSNR limitations of chip-based optical frequency comb sources for WDM
  coherent communications</title><categories>eess.SP physics.optics</categories><comments>8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optical frequency combs have the potential to become key building blocks of
optical communication subsystems. The strictly equidistant, narrow-band
spectral lines of a frequency comb can serve both as carriers for massively
parallel data transmission and as local oscillator for coherent reception.
Recent experiments have demonstrated the viability of various chip-based comb
generator concepts for communication applications, offering transmission
capacities of tens of Tbit/s. Here, we investigate the influence of the comb
line power and of the carrier-to-noise power ratio on the performance of a
frequency comb in a WDM system. We distinguish two regimes of operation
depending on whether the comb source or the transmission link limits the
performance of the system, i.e., defines the link reach, restricts the choice
of modulation format and sets the maximum symbol rate. Finally, we investigate
the achievable OSNR and channel capacity when using the tones of a soliton Kerr
frequency comb as multi-wavelength carriers for WDM systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01071</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01071</id><created>2019-07-01</created><authors><author><keyname>Tucker</keyname><forenames>Nathaniel</forenames></author><author><keyname>Turan</keyname><forenames>Berkay</forenames></author><author><keyname>Alizadeh</keyname><forenames>Mahnoosh</forenames></author></authors><title>Online Charge Scheduling for Electric Vehicles in Autonomous Mobility on
  Demand Fleets</title><categories>eess.SY cs.MA cs.SY</categories><comments>9 pages, 3 figures, Accepted to ITSC 2019, Auckland, NZ</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we study an online charge scheduling strategy for fleets of
autonomous-mobility-on-demand electric vechicles (AMoD EVs). We consider the
case where vehicles complete trips and then enter a between-ride state
throughout the day, with their information becoming available to the fleet
operator in an online fashion. In the between-ride state, the vehicles must be
scheduled for charging and then routed to their next passenger pick-up
locations. Additionally, due to the unknown daily sequences of ride requests,
the problem cannot be solved by any offline approach. As such, we study an
online welfare maximization heuristic based on primal-dual methods that
allocates limited fleet charging resources and rebalances the vehicles while
avoiding congestion at charging facilities and pick-up locations. We discuss a
competitive ratio result comparing the performance of our online solution to
the clairvoyant offline solution and provide numerical results highlighting the
performance of our heuristic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01081</identifier>
 <datestamp>2020-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01081</id><created>2019-07-01</created><authors><author><keyname>G&#xfc;nl&#xfc;</keyname><forenames>Onur</forenames></author><author><keyname>Schaefer</keyname><forenames>Rafael F.</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author></authors><title>Private Authentication with Physical Identifiers Through Broadcast
  Channel Measurements</title><categories>cs.IT cs.CR cs.MM eess.SP math.IT math.PR</categories><comments>Longer version of the paper accepted to the IEEE Information Theory
  Workshop 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A basic model for key agreement with biometric or physical identifiers is
extended to include measurements of a hidden source through a general broadcast
channel (BC). An inner bound for strong secrecy, maximum key rate, and minimum
privacy-leakage and database-storage rates is proposed. The inner bound is
shown to be tight for physically-degraded and less-noisy BCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01085</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01085</id><created>2019-07-01</created><updated>2019-12-08</updated><authors><author><keyname>Sridhar</keyname><forenames>Srinath</forenames></author><author><keyname>Rempe</keyname><forenames>Davis</forenames></author><author><keyname>Valentin</keyname><forenames>Julien</forenames></author><author><keyname>Bouaziz</keyname><forenames>Sofien</forenames></author><author><keyname>Guibas</keyname><forenames>Leonidas J.</forenames></author></authors><title>Multiview Aggregation for Learning Category-Specific Shape
  Reconstruction</title><categories>cs.CV cs.LG eess.IV</categories><comments>In Proceedings of Advances in Neural Information Processing Systems
  (NeurIPS) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of learning category-specific 3D shape
reconstruction from a variable number of RGB views of previously unobserved
object instances. Most approaches for multiview shape reconstruction operate on
sparse shape representations, or assume a fixed number of views. We present a
method that can estimate dense 3D shape, and aggregate shape across multiple
and varying number of input views. Given a single input view of an object
instance, we propose a representation that encodes the dense shape of the
visible object surface as well as the surface behind line of sight occluded by
the visible surface. When multiple input views are available, the shape
representation is designed to be aggregated into a single 3D shape using an
inexpensive union operation. We train a 2D CNN to learn to predict this
representation from a variable number of views (1 or more). We further
aggregate multiview information by using permutation equivariant layers that
promote order-agnostic view information exchange at the feature level.
Experiments show that our approach is able to produce dense 3D reconstructions
of objects that improve in quality as more views are added.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01112</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01112</id><created>2019-07-01</created><updated>2019-07-18</updated><authors><author><keyname>Kim</keyname><forenames>Yongjune</forenames></author><author><keyname>Choi</keyname><forenames>Won Ho</forenames></author><author><keyname>Guyot</keyname><forenames>Cyril</forenames></author><author><keyname>Cassuto</keyname><forenames>Yuval</forenames></author></authors><title>On the Optimal Refresh Power Allocation for Energy-Efficient Memories</title><categories>cs.AR cs.IT eess.SP math.IT</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Refresh is an important operation to prevent loss of data in dynamic
random-access memory (DRAM). However, frequent refresh operations incur
considerable power consumption and degrade system performance. Refresh power
cost is especially significant in high-capacity memory devices and
battery-powered edge/mobile applications. In this paper, we propose a
principled approach to optimizing the refresh power allocation. Given a model
for the bit error rate dependence on power, we formulate a convex optimization
problem to minimize the word mean squared error for a refresh power constraint;
hence we can guarantee the optimality of the obtained refresh power
allocations. In addition, we provide an integer programming problem to optimize
the discrete refresh interval assignments. For an 8-bit accessed word,
numerical results show that the optimized nonuniform refresh intervals reduce
the refresh power by 29% at a peak signal-to-noise ratio of 50dB compared to
the uniform assignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01149</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01149</id><created>2019-07-01</created><authors><author><keyname>Wu</keyname><forenames>Ruiyuan</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Li</keyname><forenames>Qiang</forenames></author></authors><title>Hyperspectral Super-Resolution via Global-Local Low-Rank Matrix
  Estimation</title><categories>eess.IV cs.LG eess.SP</categories><comments>27 pages, 9 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral super-resolution (HSR) is a problem that aims to estimate an
image of high spectral and spatial resolutions from a pair of co-registered
multispectral (MS) and hyperspectral (HS) images, which have coarser spectral
and spatial resolutions, respectively. In this paper we pursue a low-rank
matrix estimation approach for HSR. We assume that the spectral-spatial
matrices associated with the whole image and the local areas of the image have
low rank structures. The local low-rank assumption, in particular, has the aim
of providing a more flexible model for accounting for local variation effects
due to endmember variability. We formulate the HSR problem as a global-local
rank-regularized least-squares problem. By leveraging on the recent advances in
non-convex large-scale optimization, namely, the smooth Schatten-p
approximation and the accelerated majorization-minimization method, we
developed an efficient algorithm for the global-local low-rank problem.
Numerical experiments on synthetic and semi-real data show that the proposed
algorithm outperforms a number of benchmark algorithms in terms of recovery
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01154</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01154</id><created>2019-07-02</created><authors><author><keyname>Hutchings</keyname><forenames>Patrick</forenames></author><author><keyname>McCormack</keyname><forenames>Jon</forenames></author></authors><title>Adaptive Music Composition for Games</title><categories>cs.MM cs.AI cs.SD eess.AS</categories><comments>Preprint. Accepted for publication in IEEE Transactions on Games,
  2019</comments><acm-class>I.2.1; H.5.5; D.2.11</acm-class><doi>10.1109/TG.2019.2921979</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generation of music that adapts dynamically to content and actions has an
important role in building more immersive, memorable and emotive game
experiences. To date, the development of adaptive music systems for video games
is limited by both the nature of algorithms used for real-time music generation
and the limited modelling of player action, game world context and emotion in
current games. We propose that these issues must be addressed in tandem for the
quality and flexibility of adaptive game music to significantly improve.
Cognitive models of knowledge organisation and emotional affect are integrated
with multi-modal, multi-agent composition techniques to produce a novel
Adaptive Music System (AMS). The system is integrated into two stylistically
distinct games. Gamers reported an overall higher immersion and correlation of
music with game-world concepts with the AMS than with the original game
soundtracks in both games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01160</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01160</id><created>2019-07-02</created><authors><author><keyname>Wichern</keyname><forenames>Gordon</forenames></author><author><keyname>Antognini</keyname><forenames>Joe</forenames></author><author><keyname>Flynn</keyname><forenames>Michael</forenames></author><author><keyname>Zhu</keyname><forenames>Licheng Richard</forenames></author><author><keyname>McQuinn</keyname><forenames>Emmett</forenames></author><author><keyname>Crow</keyname><forenames>Dwight</forenames></author><author><keyname>Manilow</keyname><forenames>Ethan</forenames></author><author><keyname>Roux</keyname><forenames>Jonathan Le</forenames></author></authors><title>WHAM!: Extending Speech Separation to Noisy Environments</title><categories>cs.SD cs.CL cs.LG eess.AS stat.ML</categories><comments>Accepted for publication at Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent progress in separating the speech signals from multiple overlapping
speakers using a single audio channel has brought us closer to solving the
cocktail party problem. However, most studies in this area use a constrained
problem setup, comparing performance when speakers overlap almost completely,
at artificially low sampling rates, and with no external background noise. In
this paper, we strive to move the field towards more realistic and challenging
scenarios. To that end, we created the WSJ0 Hipster Ambient Mixtures (WHAM!)
dataset, consisting of two speaker mixtures from the wsj0-2mix dataset combined
with real ambient noise samples. The samples were collected in coffee shops,
restaurants, and bars in the San Francisco Bay Area, and are made publicly
available. We benchmark various speech separation architectures and objective
functions to evaluate their robustness to noise. While separation performance
decreases as a result of noise, we still observe substantial gains relative to
the noisy signals for most approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01164</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01164</id><created>2019-07-02</created><authors><author><keyname>Pati</keyname><forenames>Ashis</forenames></author><author><keyname>Lerch</keyname><forenames>Alexander</forenames></author><author><keyname>Hadjeres</keyname><forenames>Ga&#xeb;tan</forenames></author></authors><title>Learning to Traverse Latent Spaces for Musical Score Inpainting</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>20th International Society for Music Information Retrieval Conference
  (ISMIR), 2019, Delft, The Netherlands; 6 pages, 8 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Music Inpainting is the task of filling in missing or lost information in a
piece of music. We investigate this task from an interactive music creation
perspective. To this end, a novel deep learning-based approach for musical
score inpainting is proposed. The designed model takes both past and future
musical context into account and is capable of suggesting ways to connect them
in a musically meaningful manner. To achieve this, we leverage the
representational power of the latent space of a Variational Auto-Encoder and
train a Recurrent Neural Network which learns to traverse this latent space
conditioned on the past and future musical contexts. Consequently, the designed
model is capable of generating several measures of music to connect two musical
excerpts. The capabilities and performance of the model are showcased by
comparison with competitive baselines using several objective and subjective
evaluation methods. The results show that the model generates meaningful
inpaintings and can be used in interactive music creation applications.
Overall, the method demonstrates the merit of learning complex trajectories in
the latent spaces of deep generative models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01169</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01169</id><created>2019-07-02</created><authors><author><keyname>Nguyen</keyname><forenames>Linh</forenames></author><author><keyname>Miro</keyname><forenames>Jaime Valls</forenames></author><author><keyname>Qiu</keyname><forenames>Xiaojun</forenames></author></authors><title>Can a Robot Hear the Shape and Dimensions of a Room?</title><categories>cs.SD cs.RO eess.AS eess.SP</categories><comments>IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowing the geometry of a space is desirable for many applications, e.g.
sound source localization, sound field reproduction or auralization. In
circumstances where only acoustic signals can be obtained, estimating the
geometry of a room is a challenging proposition. Existing methods have been
proposed to reconstruct a room from the room impulse responses (RIRs). However,
the sound source and microphones must be deployed in a feasible region of the
room for it to work, which is impractical when the room is unknown. This work
propose to employ a robot equipped with a sound source and four acoustic
sensors, to follow a proposed path planning strategy to moves around the room
to collect first image sources for room geometry estimation. The strategy can
effectively drives the robot from a random initial location through the room so
that the room geometry is guaranteed to be revealed. Effectiveness of the
proposed approach is extensively validated in a synthetic environment, where
the results obtained are highly promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01184</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01184</id><created>2019-07-02</created><authors><author><keyname>Nguyen</keyname><forenames>Linh</forenames></author><author><keyname>Miro</keyname><forenames>Jaime Valls</forenames></author><author><keyname>Shi</keyname><forenames>Lei</forenames></author><author><keyname>Vidal-Calleja</keyname><forenames>Teresa</forenames></author></authors><title>Gaussian Mixture Marginal Distributions for Modelling Remaining Pipe
  Wall Thickness of Critical Water Mains in Non-Destructive Evaluation</title><categories>cs.LG cs.SY eess.SY stat.AP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rapidly estimating the remaining wall thickness (RWT) is paramount for the
non-destructive condition assessment evaluation of large critical metallic
pipelines. A robotic vehicle with embedded magnetism-based sensors has been
developed to traverse the inside of a pipeline and conduct inspections at the
location of a break. However its sensing speed is constrained by the magnetic
principle of operation, thus slowing down the overall operation in seeking
dense RWT mapping. To ameliorate this drawback, this work proposes the partial
scanning of the pipe and then employing Gaussian Processes (GPs) to infer RWT
at the unseen pipe sections. Since GP prediction assumes to have normally
distributed input data - which does correspond with real RWT measurements -
Gaussian mixture (GM) models are proven in this work as fitting marginal
distributions to effectively capture the probability of any RWT value in the
inspected data. The effectiveness of the proposed approach is extensively
validated from real-world data collected in collaboration with a water utility
from a cast iron water main pipeline in Sydney, Australia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01186</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01186</id><created>2019-07-02</created><authors><author><keyname>Georgiev</keyname><forenames>Todor</forenames></author><author><keyname>Qin</keyname><forenames>He</forenames></author><author><keyname>Li</keyname><forenames>Haotian</forenames></author></authors><title>John Transform and Ultrahyperbolic Equation for Lightfields</title><categories>eess.IV</categories><comments>18 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores possibilities for new uses of the Radon transform for
imaging and analysis of lightfields. We show that the previously reported
Dimansionality Gap can be derived from an ultrahyperbolic PDE, first proposed
by F. John, which is satisfied by lightfields. Based on inverse John transform
we demonstrate rigorous Focal Stack rendering and viewing from arbitrary
angles. Based on Asgeirsson's theorems for the ultrahyperbolic PDE we derive
new kernels for processing lightfields. Our kernels provide alternative methods
for depth computation and other image processing in lightfields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01195</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01195</id><created>2019-07-02</created><authors><author><keyname>Oneata</keyname><forenames>Dan</forenames></author><author><keyname>Cucu</keyname><forenames>Horia</forenames></author></authors><title>Kite: Automatic speech recognition for unmanned aerial vehicles</title><categories>cs.SD cs.CV eess.AS</categories><comments>5 pages, accepted at Interspeech 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper addresses the problem of building a speech recognition system
attuned to the control of unmanned aerial vehicles (UAVs). Even though UAVs are
becoming widespread, the task of creating voice interfaces for them is largely
unaddressed. To this end, we introduce a multi-modal evaluation dataset for UAV
control, consisting of spoken commands and associated images, which represent
the visual context of what the UAV &quot;sees&quot; when the pilot utters the command. We
provide baseline results and address two research directions: (i) how robust
the language models are, given an incomplete list of commands at train time;
(ii) how to incorporate visual information in the language model. We find that
recurrent neural networks (RNNs) are a solution to both tasks: they can be
successfully adapted using a small number of commands and they can be extended
to use visual cues. Our results show that the image-based RNN outperforms its
text-only counterpart even if the command-image training associations are
automatically generated and inherently imperfect. The dataset and our code are
available at http://kite.speed.pub.ro.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01205</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01205</id><created>2019-07-02</created><authors><author><keyname>Scherer</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Rinner</keyname><forenames>Bernhard</forenames></author></authors><title>Persistent Multi-UAV Surveillance with Data Latency Constraints</title><categories>cs.RO eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss surveillance with multiple unmanned aerial vehicles (UAV) that
minimize idleness (the time between consecutive visits of sensing locations)
and constrain latency (the time between capturing data at a sensing location
and its arrival at the base station). This is important in persistent
surveillance scenarios where sensing locations should not only be visited
periodically, but the captured data also should reach the base station in due
time even if the area is larger than the communication range. Our approach
employs the concept of minimum-latency paths (MLP) to guarantee that the data
reaches the base station within a predefined latency bound. To reach the bound,
multiple UAVs cooperatively transport the data in a store-and-forward fashion.
Additionally, MLPs specify a lower bound for any latency minimization problem
where multiple mobile agents transport data in a store-and-forward fashion. We
introduce three variations of a heuristic employing MLPs and compare their
performance in a simulation study. The results show that extensions of the
simplest of our approaches, where data is transported after each visit of a
sensing location, show improved performance and the tradeoff between latency
and idleness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01253</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01253</id><created>2019-07-02</created><authors><author><keyname>&#xc7;all&#x131;</keyname><forenames>Erdi</forenames></author><author><keyname>Murphy</keyname><forenames>Keelin</forenames></author><author><keyname>Sogancioglu</keyname><forenames>Ecem</forenames></author><author><keyname>van Ginneken</keyname><forenames>Bram</forenames></author></authors><title>FRODO: Free rejection of out-of-distribution samples: application to
  chest x-ray analysis</title><categories>cs.LG eess.IV stat.ML</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/H1e7kWD794</report-no><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we propose a method to reject out-of-distribution samples which
can be adapted to any network architecture and requires no additional training
data. Publicly available chest x-ray data (38,353 images) is used to train a
standard ResNet-50 model to detect emphysema. Feature activations of
intermediate layers are used as descriptors defining the training data
distribution. A novel metric, FRODO, is measured by using the Mahalanobis
distance of a new test sample to the training data distribution. The method is
tested using a held-out test dataset of 21,176 chest x-rays (in-distribution)
and a set of 14,821 out-of-distribution x-ray images of incorrect orientation
or anatomy. In classifying test samples as in or out-of distribution, our
method achieves an AUC score of 0.99.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01262</identifier>
 <datestamp>2019-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01262</id><created>2019-07-02</created><updated>2019-09-12</updated><authors><author><keyname>Xie</keyname><forenames>Huidong</forenames></author><author><keyname>Shan</keyname><forenames>Hongming</forenames></author><author><keyname>Cong</keyname><forenames>Wenxiang</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaohua</forenames></author><author><keyname>Liu</keyname><forenames>Shaohua</forenames></author><author><keyname>Ning</keyname><forenames>Ruola</forenames></author><author><keyname>Wang</keyname><forenames>Ge</forenames></author></authors><title>Dual Network Architecture for Few-view CT -- Trained on ImageNet Data
  and Transferred for Medical Imaging</title><categories>eess.IV cs.CV cs.LG</categories><comments>11 pages, 5 figures, 2019 SPIE Optical Engineering + Applications</comments><doi>10.1117/12.2531198</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  X-ray computed tomography (CT) reconstructs cross-sectional images from
projection data. However, ionizing X-ray radiation associated with CT scanning
might induce cancer and genetic damage. Therefore, the reduction of radiation
dose has attracted major attention. Few-view CT image reconstruction is an
important topic to reduce the radiation dose. Recently, data-driven algorithms
have shown great potential to solve the few-view CT problem. In this paper, we
develop a dual network architecture (DNA) for reconstructing images directly
from sinograms. In the proposed DNA method, a point-based fully-connected layer
learns the backprojection process requesting significantly less memory than the
prior arts do. Proposed method uses O(C*N*N_c) parameters where N and N_c
denote the dimension of reconstructed images and number of projections
respectively. C is an adjustable parameter that can be set as low as 1. Our
experimental results demonstrate that DNA produces a competitive performance
over the other state-of-the-art methods. Interestingly, natural images can be
used to pre-train DNA to avoid overfitting when the amount of real patient
images is limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01268</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01268</id><created>2019-07-02</created><updated>2019-07-03</updated><authors><author><keyname>Chen</keyname><forenames>Chen</forenames></author><author><keyname>Bai</keyname><forenames>Wenjia</forenames></author><author><keyname>Davies</keyname><forenames>Rhodri H.</forenames></author><author><keyname>Bhuva</keyname><forenames>Anish N.</forenames></author><author><keyname>Manisty</keyname><forenames>Charlotte</forenames></author><author><keyname>Moon</keyname><forenames>James C.</forenames></author><author><keyname>Aung</keyname><forenames>Nay</forenames></author><author><keyname>Lee</keyname><forenames>Aaron M.</forenames></author><author><keyname>Sanghvi</keyname><forenames>Mihir M.</forenames></author><author><keyname>Fung</keyname><forenames>Kenneth</forenames></author><author><keyname>Paiva</keyname><forenames>Jose Miguel</forenames></author><author><keyname>Petersen</keyname><forenames>Steffen E.</forenames></author><author><keyname>Lukaschuk</keyname><forenames>Elena</forenames></author><author><keyname>Piechnik</keyname><forenames>Stefan K.</forenames></author><author><keyname>Neubauer</keyname><forenames>Stefan</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author></authors><title>Improving the generalizability of convolutional neural network-based
  segmentation on CMR images</title><categories>eess.IV cs.CV</categories><comments>15 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural network (CNN) based segmentation methods provide an
efficient and automated way for clinicians to assess the structure and function
of the heart in cardiac MR images. While CNNs can generally perform the
segmentation tasks with high accuracy when training and test images come from
the same domain (e.g. same scanner or site), their performance often degrades
dramatically on images from different scanners or clinical sites. We propose a
simple yet effective way for improving the network generalization ability by
carefully designing data normalization and augmentation strategies to
accommodate common scenarios in multi-site, multi-scanner clinical imaging data
sets. We demonstrate that a neural network trained on a single-site
single-scanner dataset from the UK Biobank can be successfully applied to
segmenting cardiac MR images across different sites and different scanners
without substantial loss of accuracy. Specifically, the method was trained on a
large set of 3,975 subjects from the UK Biobank. It was then directly tested on
600 different subjects from the UK Biobank for intra-domain testing and two
other sets for cross-domain testing: the ACDC dataset (100 subjects, 1 site, 2
scanners) and the BSCMR-AS dataset (599 subjects, 6 sites, 9 scanners). The
proposed method produces promising segmentation results on the UK Biobank test
set which are comparable to previously reported values in the literature, while
also performing well on cross-domain test sets, achieving a mean Dice metric of
0.90 for the left ventricle, 0.81 for the myocardium and 0.82 for the right
ventricle on the ACDC dataset; and 0.89 for the left ventricle, 0.83 for the
myocardium on the BSCMR-AS dataset. The proposed method offers a potential
solution to improve CNN-based model generalizability for the cross-scanner and
cross-site cardiac MR image segmentation task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01271</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01271</id><created>2019-07-02</created><updated>2019-10-03</updated><authors><author><keyname>Zhang</keyname><forenames>Huihong</forenames></author><author><keyname>Yang</keyname><forenames>Jianlong</forenames></author><author><keyname>Zhou</keyname><forenames>Kang</forenames></author><author><keyname>Li</keyname><forenames>Fei</forenames></author><author><keyname>Hu</keyname><forenames>Yan</forenames></author><author><keyname>Gao</keyname><forenames>Shenghua</forenames></author><author><keyname>Zhang</keyname><forenames>Xiulan</forenames></author><author><keyname>Liu</keyname><forenames>Jiang</forenames></author></authors><title>Eliminating Shadow Artifacts via Generative Inpainting Networks to
  Quantify Vascular Changes of the Choroid</title><categories>physics.med-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shadow artifacts from retinal vessels hinder the development of quantitative
choroidal biomarkers in Optical Coherence Tomography (OCT), which limits the
clinical applications of the choroidal OCT to the measures of layer thickness.
In this paper, we present a novel framework that could eliminate the retinal
shadows and realize the quantification of choroidal vasculature. Different from
existing methods, we convert the shadow elimination into an object removal
task, which can be handled by image inpainting techniques. We adopt and
finetune a two-stage generative inpainting network which connects the edges of
the vessels ahead of refilling the shadow-contaminated areas. It shows
surpassing performance in repairing the choroidal vasculature compared with
traditional inpainting algorithms. We further verify the feasibility of the
proposed frame using a prospective observational study, which detects the
choroidal vascular changes related to the Intra-Ocular Pressure (IOP) elevation
of 34 healthy volunteers. As the average IOP increases from $15.84\pm1.99$ mmHg
to $34.48\pm5.35$ mmHg, we achieve the decreases of the choroidal vessel
density and flow index from $0.491\pm0.020$ to $0.463\pm0.019$ and from
$0.336\pm0.025$ to $0.300\pm0.019$, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01277</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01277</id><created>2019-07-02</created><updated>2019-11-21</updated><authors><author><keyname>Meseguer-Brocal</keyname><forenames>Gabriel</forenames></author><author><keyname>Peeters</keyname><forenames>Geoffroy</forenames></author></authors><title>Conditioned-U-Net: Introducing a Control Mechanism in the U-Net for
  Multiple Source Separations</title><categories>eess.AS cs.LG cs.SD</categories><journal-ref>Proceedings of the 20th International Society for Music
  Information Retrieval Conference, ISMIR, Delft, Netherlands, 2019</journal-ref><doi>10.5281/zenodo.3527766</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Data-driven models for audio source separation such as U-Net or Wave-U-Net
are usually models dedicated to and specifically trained for a single task,
e.g. a particular instrument isolation. Training them for various tasks at once
commonly results in worse performances than training them for a single
specialized task. In this work, we introduce the Conditioned-U-Net (C-U-Net)
which adds a control mechanism to the standard U-Net. The control mechanism
allows us to train a unique and generic U-Net to perform the separation of
various instruments. The C-U-Net decides the instrument to isolate according to
a one-hot-encoding input vector. The input vector is embedded to obtain the
parameters that control Feature-wise Linear Modulation (FiLM) layers. FiLM
layers modify the U-Net feature maps in order to separate the desired
instrument via affine transformations. The C-U-Net performs different
instrument separations, all with a single model achieving the same performances
as the dedicated ones at a lower cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01284</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01284</id><created>2019-07-02</created><authors><author><keyname>Dugar</keyname><forenames>Pranay</forenames></author><author><keyname>Chatterjee</keyname><forenames>Anirban</forenames></author><author><keyname>Bhat</keyname><forenames>Rajesh Shreedhar</forenames></author><author><keyname>Sahoo</keyname><forenames>Saswata</forenames></author></authors><title>Semi-Bagging Based Deep Neural Architecture to Extract Text from High
  Entropy Images</title><categories>cs.CV cs.LG eess.IV</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extracting texts of various size and shape from images containing multiple
objects is an important problem in many contexts, especially, in connection to
e-commerce, augmented reality assistance system in natural scene, etc. The
existing works (based on only CNN) often perform sub-optimally when the image
contains regions of high entropy having multiple objects. This paper presents
an end-to-end text detection strategy combining a segmentation algorithm and an
ensemble of multiple text detectors of different types to detect text in every
individual image segments independently. The proposed strategy involves a
super-pixel based image segmenter which splits an image into multiple regions.
A convolutional deep neural architecture is developed which works on each of
the segments and detects texts of multiple shapes, sizes, and structures. It
outperforms the competing methods in terms of coverage in detecting texts in
images especially the ones where the text of various types and sizes are
compacted in a small region along with various other objects. Furthermore, the
proposed text detection method along with a text recognizer outperforms the
existing state-of-the-art approaches in extracting text from high entropy
images. We validate the results on a dataset consisting of product images on an
e-commerce website.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01288</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01288</id><created>2019-07-02</created><authors><author><keyname>Gazzar</keyname><forenames>Ahmed El</forenames></author><author><keyname>Cerliani</keyname><forenames>Leonardo</forenames></author><author><keyname>van Wingen</keyname><forenames>Guido</forenames></author><author><keyname>Thomas</keyname><forenames>Rajat Mani</forenames></author></authors><title>Simple 1-D Convolutional Networks for Resting-State fMRI Based
  Classification in Autism</title><categories>q-bio.NC cs.LG eess.IV stat.ML</categories><comments>accepted for publication in IJCNN 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning methods are increasingly being used with neuroimaging data like
structural and function magnetic resonance imaging (MRI) to predict the
diagnosis of neuropsychiatric and neurological disorders. For psychiatric
disorders in particular, it is believed that one of the most promising modality
is the resting-state functional MRI (rsfMRI), which captures the intrinsic
connectivity between regions in the brain. Because rsfMRI data points are
inherently high-dimensional (~1M), it is impossible to process the entire input
in its raw form. In this paper, we propose a very simple transformation of the
rsfMRI images that captures all of the temporal dynamics of the signal but
sub-samples its spatial extent. As a result, we use a very simple 1-D
convolutional network which is fast to train, requires minimal preprocessing
and performs at par with the state-of-the-art on the classification of Autism
spectrum disorders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01309</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01309</id><created>2019-07-02</created><authors><author><keyname>Razak</keyname><forenames>Rihab Abdul</forenames></author><author><keyname>Srikant</keyname><forenames>Sukumar</forenames></author><author><keyname>Chung</keyname><forenames>Hoam</forenames></author></authors><title>Scalar Field Estimation with Mobile Sensor Networks</title><categories>eess.SY cs.MA cs.SY math.OC</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of estimating a scalar field using a
network of mobile sensors which can measure the value of the field at their
instantaneous location. The scalar field to be estimated is assumed to be
represented by positive definite radial basis kernels and we use techniques
from adaptive control and Lyapunov analysis to prove the stability of the
proposed estimation algorithm. The convergence of the estimated parameter
values to the true values is guaranteed by planning the motion of the mobile
sensors to satisfy persistence-like conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01319</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01319</id><created>2019-07-02</created><authors><author><keyname>Kim</keyname><forenames>Boah</forenames></author><author><keyname>Kim</keyname><forenames>Jieun</forenames></author><author><keyname>Lee</keyname><forenames>June-Goo</forenames></author><author><keyname>Kim</keyname><forenames>Dong Hwan</forenames></author><author><keyname>Park</keyname><forenames>Seong Ho</forenames></author><author><keyname>Ye</keyname><forenames>Jong Chul</forenames></author></authors><title>Unsupervised Deformable Image Registration Using Cycle-Consistent CNN</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><comments>accepted for MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical image registration is one of the key processing steps for biomedical
image analysis such as cancer diagnosis. Recently, deep learning based
supervised and unsupervised image registration methods have been extensively
studied due to its excellent performance in spite of ultra-fast computational
time compared to the classical approaches. In this paper, we present a novel
unsupervised medical image registration method that trains deep neural network
for deformable registration of 3D volumes using a cycle-consistency. Thanks to
the cycle consistency, the proposed deep neural networks can take diverse pair
of image data with severe deformation for accurate registration. Experimental
results using multiphase liver CT images demonstrate that our method provides
very precise 3D image registration within a few seconds, resulting in more
accurate cancer size estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01332</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01332</id><created>2019-07-02</created><authors><author><keyname>Uran</keyname><forenames>Axel</forenames></author><author><keyname>van Gemeren</keyname><forenames>Coert</forenames></author><author><keyname>van Diepen</keyname><forenames>Rosanne</forenames></author><author><keyname>Chavarriaga</keyname><forenames>Ricardo</forenames></author><author><keyname>Mill&#xe1;n</keyname><forenames>Jos&#xe9; del R.</forenames></author></authors><title>Applying Transfer Learning To Deep Learned Models For EEG Analysis</title><categories>cs.LG eess.SP stat.ML</categories><comments>14 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The introduction of deep learning and transfer learning techniques in fields
such as computer vision allowed a leap forward in the accuracy of image
classification tasks. Currently there is only limited use of such techniques in
neuroscience. The challenge of using deep learning methods to successfully
train models in neuroscience, lies in the complexity of the information that is
processed, the availability of data and the cost of producing sufficient high
quality annotations. Inspired by its application in computer vision, we
introduce transfer learning on electrophysiological data to enable training a
model with limited amounts of data. Our method was tested on the dataset of the
BCI competition IV 2a and compared to the top results that were obtained using
traditional machine learning techniques. Using our DL model we outperform the
top result of the competition by 33%. We also explore transferability of
knowledge between trained models over different experiments, called
inter-experimental transfer learning. This reduces the amount of required data
even further and is especially useful when few subjects are available. This
method is able to outperform the standard deep learning methods used in the BCI
competition IV 2b approaches by 18%. In this project we propose a method that
can produce reliable electroencephalography (EEG) signal classification, based
on modest amounts of training data through the use of transfer learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01334</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01334</id><created>2019-07-02</created><authors><author><keyname>Taghipour</keyname><forenames>Javad</forenames></author><author><keyname>Azmi</keyname><forenames>Paeiz</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Forouzesh</keyname><forenames>Moslem</forenames></author><author><keyname>Pishro-Nik</keyname><forenames>Hossein</forenames></author></authors><title>Bit Error Probability Instead of Secrecy Rate Criterion to Enhance
  Performance for Secure Wireless Communication Systems</title><categories>eess.SP</categories><comments>11 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we propose a new practical power allocation technique based on
bit error probability (BEP) for physical layer security systems. It is shown
that the secrecy rate that is the most commonly used in physical layer security
systems, cannot be a suitable criterion lonely. Large positive values are
suitable for the secrecy rate in physical layer security, but it does not
consider the performance of the legitimate and adversary users. In this paper,
we consider and analyze BEP for physical layer security systems because based
on it, the performance of the legitimate and adversary users are guaranteed and
it is needed to use lower power. BEP is calculated for the legitimate and
adversary users and it is shown that BEP can be better criterion for
performance evaluation of the physical layer security systems. Based on BEP,
the optimum transmit power is obtained and a new definition for outage
probability is proposed and obtained theoretically. Also, the proposed approach
is applied for adversary users with unknown mode and the cooperative adversary
users. Simulation results show that the proposed method needs more than 5dB
lower power for different scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01346</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01346</id><created>2019-07-02</created><authors><author><keyname>Schmieder</keyname><forenames>Mathis</forenames></author><author><keyname>Undi</keyname><forenames>Fabian</forenames></author><author><keyname>Peter</keyname><forenames>Michael</forenames></author><author><keyname>Koenig</keyname><forenames>Ephraim</forenames></author><author><keyname>Keusgen</keyname><forenames>Wilhelm</forenames></author></authors><title>Directional Wideband Channel Measurements at 28 GHz in an Industrial
  Environment</title><categories>eess.SP</categories><comments>Submitted to Globecom 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the expected adoption of millimeter wave technologies for industrial
communication, it is fundamentally important to properly understand the radio
channel characteristics of such environments. This paper presents the setup,
scenario and results of a measurement campaign at 28 GHz in a machine hall. The
radio channel was measured with a bandwidth of 2 GHz and both large scale
parameters and directional information were extracted. Evaluation of the power
delay profiles shows that the channel contains dense multipath components. A
path loss model is parameterized and blockage losses, RMS delay and angle
spreads are evaluated. Comparison with the 3GPP TR 38.901 channel model shows
that none of the currently defined scenarios is a fit for industrial settings.
This emphasizes the need for a newly defined scenario with an industry specific
parameter set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01348</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01348</id><created>2019-07-02</created><updated>2019-08-02</updated><authors><author><keyname>Xiao</keyname><forenames>Jiadong</forenames></author><author><keyname>Li</keyname><forenames>Lin</forenames></author><author><keyname>Zhang</keyname><forenames>Tie</forenames></author><author><keyname>Zou</keyname><forenames>Yanbiao</forenames></author></authors><title>Time-Optimal Path Tracking for Industrial Robots: A Dynamic Model-Free
  Reinforcement Learning Approach</title><categories>cs.RO cs.SY eess.SY</categories><comments>8 pages,9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In pursuit of the time-optimal path tracking (TOPT) trajectory of a robot
manipulator along a preset path, a beforehand identified robot dynamic model is
usually used to obtain the required optimal trajectory for perfect tracking.
However, due to the inevitable model-plant mismatch, there may be a big error
between the actually measured torques and the calculated torques by the dynamic
model, which causes the obtained trajectory to be suboptimal or even be
infeasible by exceeding given limits. This paper presents a TOPT-oriented SARSA
algorithm (TOPTO-SARSA) and a two-step method for finding the time-optimal
motion and ensuring the feasibility : Firstly, using TOPTO-SARSA to find a safe
trajectory that satisfies the kinematic constraints through the interaction
between reinforcement learning agent and kinematic model. Secondly, using
TOPTO-SARSA to find the optimal trajectory through the interaction between the
agent and the real world, and assure the actually measured torques satisfy the
given limits at the last interaction. The effectiveness of the proposed
algorithm has been verified through experiments on a 6-DOF robot manipulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01350</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01350</id><created>2019-07-02</created><updated>2019-07-03</updated><authors><author><keyname>Forouzesh</keyname><forenames>Moslem</forenames></author><author><keyname>Azmi</keyname><forenames>Paeiz</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Goeckel</keyname><forenames>Dennis</forenames></author></authors><title>Covert Communication Using Null Space and 3D Beamforming</title><categories>eess.SP</categories><comments>4 figure, 1 algorithm</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Covert communication is often limited in rate because it is difficult to hide
the signal in the background noise. Recent work has shown that jamming can
significantly improve the rate at which covert communications can be conducted;
however, the rate could be improved further if the jamming incident on the
intended receiver can be mitigated. Here, we consider a multiple-antenna jammer
that employs beamforming to place the intended receiver in the null space of
the jamming and a multi-antenna transmitter equipped with three-dimensional
(3D) antennas that is able to beamform toward its intended recipient. To
evaluate this design, we formulate an optimization problem and present an
iterative algorithm to solve it. Numerical results consider both the rate of
covert communications with the proposed architecture and the gap between the
result from our optimization and that obtained from exhaustive search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01361</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01361</id><created>2019-07-01</created><authors><author><keyname>Tassano</keyname><forenames>Matias</forenames></author><author><keyname>Delon</keyname><forenames>Julie</forenames></author><author><keyname>Veit</keyname><forenames>Thomas</forenames></author></authors><title>FastDVDnet: Towards Real-Time Video Denoising Without Explicit Motion
  Estimation</title><categories>cs.CV cs.GR cs.LG eess.IV</categories><comments>Code for this algorithm and results can be found in
  https://github.com/m-tassano/fastdvdnet. arXiv admin note: text overlap with
  arXiv:1906.11890</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a state-of-the-art video denoising algorithm based
on a convolutional neural network architecture. Until recently, video denoising
with neural networks had been a largely under explored domain, and existing
methods could not compete with the performance of the best patch-based methods.
The approach we introduce in this paper, called FastDVDnet, shows similar or
better performance than other state-of-the-art competitors with significantly
lower computing times. In contrast to other existing neural network denoisers,
our algorithm exhibits several desirable properties such as fast runtimes, and
the ability to handle a wide range of noise levels with a single network model.
The characteristics of its architecture make it possible to avoid using a
costly motion compensation stage while achieving excellent performance. The
combination between its denoising performance and lower computational load
makes this algorithm attractive for practical denoising applications. We
compare our method with different state-of-art algorithms, both visually and
with respect to objective quality metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01367</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01367</id><created>2019-06-28</created><authors><author><keyname>Kumar</keyname><forenames>Yaman</forenames></author><author><keyname>Jain</keyname><forenames>Rohit</forenames></author><author><keyname>Salik</keyname><forenames>Khwaja Mohd.</forenames></author><author><keyname>Shah</keyname><forenames>Rajiv Ratn</forenames></author><author><keyname>yin</keyname><forenames>Yifang</forenames></author><author><keyname>Zimmermann</keyname><forenames>Roger</forenames></author></authors><title>Lipper: Synthesizing Thy Speech using Multi-View Lipreading</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Accepted at AAAI 2019</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Lipreading has a lot of potential applications such as in the domain of
surveillance and video conferencing. Despite this, most of the work in building
lipreading systems has been limited to classifying silent videos into classes
representing text phrases. However, there are multiple problems associated with
making lipreading a text-based classification task like its dependence on a
particular language and vocabulary mapping. Thus, in this paper we propose a
multi-view lipreading to audio system, namely Lipper, which models it as a
regression task. The model takes silent videos as input and produces speech as
the output. With multi-view silent videos, we observe an improvement over
single-view speech reconstruction results. We show this by presenting an
exhaustive set of experiments for speaker-dependent, out-of-vocabulary and
speaker-independent settings. Further, we compare the delay values of Lipper
with other speechreading systems in order to show the real-time nature of audio
produced. We also perform a user study for the audios produced in order to
understand the level of comprehensibility of audios produced using Lipper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01368</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01368</id><created>2019-07-02</created><authors><author><keyname>Str&#xf6;m</keyname><forenames>Peter</forenames><affiliation>Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm, Sweden</affiliation></author><author><keyname>Kartasalo</keyname><forenames>Kimmo</forenames><affiliation>Faculty of Medicine and Health Technology, Tampere University, Tampere, Finland</affiliation></author><author><keyname>Olsson</keyname><forenames>Henrik</forenames><affiliation>Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm, Sweden</affiliation></author><author><keyname>Solorzano</keyname><forenames>Leslie</forenames><affiliation>Centre for Image Analysis, Department of Information Technology, Uppsala University, Uppsala, Sweden</affiliation></author><author><keyname>Delahunt</keyname><forenames>Brett</forenames><affiliation>Department of Pathology and Molecular Medicine, Wellington School of Medicine and Health Sciences, University of Otago, Wellington, New Zealand</affiliation></author><author><keyname>Berney</keyname><forenames>Daniel M.</forenames><affiliation>Barts Cancer Institute, Queen Mary University of London, London, UK</affiliation></author><author><keyname>Bostwick</keyname><forenames>David G.</forenames><affiliation>Bostwick Laboratories, Orlando, FL, USA</affiliation></author><author><keyname>Evans</keyname><forenames>Andrew J.</forenames><affiliation>Laboratory Medicine Program, University Health Network, Toronto General Hospital, Toronto, ON, Canada</affiliation></author><author><keyname>Grignon</keyname><forenames>David J.</forenames><affiliation>Department of Pathology and Laboratory Medicine, Indiana University School of Medicine, Indianapolis, IN, USA</affiliation></author><author><keyname>Humphrey</keyname><forenames>Peter A.</forenames><affiliation>Department of Pathology, Yale University School of Medicine, New Haven, CT, USA</affiliation></author><author><keyname>Iczkowski</keyname><forenames>Kenneth A.</forenames><affiliation>Department of Pathology, Medical College of Wisconsin, Milwaukee, WI, USA</affiliation></author><author><keyname>Kench</keyname><forenames>James G.</forenames><affiliation>Department of Tissue Pathology and Diagnostic Oncology, Royal Prince Alfred Hospital and Central Clinical School, University of Sydney, Sydney, NSW, Australia</affiliation></author><author><keyname>Kristiansen</keyname><forenames>Glen</forenames><affiliation>Institute of Pathology, University Hospital Bonn, Bonn, Germany</affiliation></author><author><keyname>van der Kwast</keyname><forenames>Theodorus H.</forenames><affiliation>Laboratory Medicine Program, University Health Network, Toronto General Hospital, Toronto, ON, Canada</affiliation></author><author><keyname>Leite</keyname><forenames>Katia R. M.</forenames><affiliation>Department of Urology, Laboratory of Medical Research, University of S&#xe3;o Paulo Medical School, S&#xe3;o Paulo, Brazil</affiliation></author><author><keyname>McKenney</keyname><forenames>Jesse K.</forenames><affiliation>Pathology and Laboratory Medicine Institute, Cleveland Clinic, Cleveland, OH, USA</affiliation></author><author><keyname>Oxley</keyname><forenames>Jon</forenames><affiliation>Department of Cellular Pathology, Southmead Hospital, Bristol, UK</affiliation></author><author><keyname>Pan</keyname><forenames>Chin-Chen</forenames><affiliation>Department of Pathology, Taipei Veterans General Hospital, Taipei, Taiwan</affiliation></author><author><keyname>Samaratunga</keyname><forenames>Hemamali</forenames><affiliation>Aquesta Uropathology and University of Queensland, Brisbane, Qld, Australia</affiliation></author><author><keyname>Srigley</keyname><forenames>John R.</forenames><affiliation>Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, ON, Canada</affiliation></author><author><keyname>Takahashi</keyname><forenames>Hiroyuki</forenames><affiliation>Department of Pathology, Jikei University School of Medicine, Tokyo, Japan</affiliation></author><author><keyname>Tsuzuki</keyname><forenames>Toyonori</forenames><affiliation>Department of Surgical Pathology, School of Medicine, Aichi Medical University, Nagoya, Japan</affiliation></author><author><keyname>Varma</keyname><forenames>Murali</forenames><affiliation>Department of Cellular Pathology, University Hospital of Wales, Cardiff, UK</affiliation></author><author><keyname>Zhou</keyname><forenames>Ming</forenames><affiliation>Department of Pathology, UT Southwestern Medical Center, Dallas, TX, USA</affiliation></author><author><keyname>Lindberg</keyname><forenames>Johan</forenames><affiliation>Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm, Sweden</affiliation></author><author><keyname>Bergstr&#xf6;m</keyname><forenames>Cecilia</forenames><affiliation>Department of Immunology, Genetics and Pathology, Uppsala University, Uppsala, Sweden</affiliation></author><author><keyname>Ruusuvuori</keyname><forenames>Pekka</forenames><affiliation>Faculty of Medicine and Health Technology, Tampere University, Tampere, Finland</affiliation></author><author><keyname>W&#xe4;hlby</keyname><forenames>Carolina</forenames><affiliation>Centre for Image Analysis, Department of Information Technology, Uppsala University, Uppsala, Sweden</affiliation><affiliation>BioImage Informatics Facility of SciLifeLab, Uppsala, Sweden</affiliation></author><author><keyname>Gr&#xf6;nberg</keyname><forenames>Henrik</forenames><affiliation>Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm, Sweden</affiliation><affiliation>Department of Oncology, S:t G&#xf6;ran Hospital, Stockholm, Sweden</affiliation></author><author><keyname>Rantalainen</keyname><forenames>Mattias</forenames><affiliation>Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm, Sweden</affiliation></author><author><keyname>Egevad</keyname><forenames>Lars</forenames><affiliation>Department of Oncology and Pathology, Karolinska Institutet, Stockholm, Sweden</affiliation></author><author><keyname>Eklund</keyname><forenames>Martin</forenames><affiliation>Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm, Sweden</affiliation></author></authors><title>Pathologist-Level Grading of Prostate Biopsies with Artificial
  Intelligence</title><categories>cs.CV cs.AI eess.IV</categories><comments>45 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: An increasing volume of prostate biopsies and a world-wide
shortage of uro-pathologists puts a strain on pathology departments.
Additionally, the high intra- and inter-observer variability in grading can
result in over- and undertreatment of prostate cancer. Artificial intelligence
(AI) methods may alleviate these problems by assisting pathologists to reduce
workload and harmonize grading.
  Methods: We digitized 6,682 needle biopsies from 976 participants in the
population based STHLM3 diagnostic study to train deep neural networks for
assessing prostate biopsies. The networks were evaluated by predicting the
presence, extent, and Gleason grade of malignant tissue for an independent test
set comprising 1,631 biopsies from 245 men. We additionally evaluated grading
performance on 87 biopsies individually graded by 23 experienced urological
pathologists from the International Society of Urological Pathology. We
assessed discriminatory performance by receiver operating characteristics (ROC)
and tumor extent predictions by correlating predicted millimeter cancer length
against measurements by the reporting pathologist. We quantified the
concordance between grades assigned by the AI and the expert urological
pathologists using Cohen's kappa.
  Results: The performance of the AI to detect and grade cancer in prostate
needle biopsy samples was comparable to that of international experts in
prostate pathology. The AI achieved an area under the ROC curve of 0.997 for
distinguishing between benign and malignant biopsy cores, and 0.999 for
distinguishing between men with or without prostate cancer. The correlation
between millimeter cancer predicted by the AI and assigned by the reporting
pathologist was 0.96. For assigning Gleason grades, the AI achieved an average
pairwise kappa of 0.62. This was within the range of the corresponding values
for the expert pathologists (0.60 to 0.73).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01369</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01369</id><created>2019-06-26</created><updated>2019-07-03</updated><authors><author><keyname>Kubasova</keyname><forenames>Uliyana</forenames></author><author><keyname>Murray</keyname><forenames>Gabriel</forenames></author><author><keyname>Braley</keyname><forenames>McKenzie</forenames></author></authors><title>Analyzing Verbal and Nonverbal Features for Predicting Group Performance</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>Accepted to INTERSPEECH 2019 (Graz, Austria)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work analyzes the efficacy of verbal and nonverbal features of group
conversation for the task of automatic prediction of group task performance. We
describe a new publicly available survival task dataset that was collected and
annotated to facilitate this prediction task. In these experiments, the new
dataset is merged with an existing survival task dataset, allowing us to
compare feature sets on a much larger amount of data than has been used in
recent related work. This work is also distinct from related research on social
signal processing (SSP) in that we compare verbal and nonverbal features,
whereas SSP is almost exclusively concerned with nonverbal aspects of social
interaction. A key finding is that nonverbal features from the speech signal
are extremely effective for this task, even on their own. However, the most
effective individual features are verbal features, and we highlight the most
important ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01370</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01370</id><created>2019-06-26</created><updated>2019-07-03</updated><authors><author><keyname>Altenhofen</keyname><forenames>Christian</forenames></author><author><keyname>Attene</keyname><forenames>Marco</forenames></author><author><keyname>Barrowclough</keyname><forenames>Oliver</forenames></author><author><keyname>Chiumenti</keyname><forenames>Michele</forenames></author><author><keyname>Livesu</keyname><forenames>Marco</forenames></author><author><keyname>Marini</keyname><forenames>Federico</forenames></author><author><keyname>Martinelli</keyname><forenames>Massimiliano</forenames></author><author><keyname>Skytt</keyname><forenames>Vibeke</forenames></author><author><keyname>Tamellini</keyname><forenames>Lorenzo</forenames></author></authors><title>Parametric shape optimization for combined additive-subtractive
  manufacturing</title><categories>cs.CE cs.SY eess.SY math.OC</categories><comments>second version: fixed a problem with pdf conversion that would make
  Table 1 overlap with text. Added header with page number</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the industrial practice, additive manufacturing processes are often
followed by post-processing operations such as subtractive machining, milling,
etc. to achieve the desired surface quality and dimensional accuracy. Hence, a
given part must be 3D printed with extra material to enable such finishing
phase. This combined additive/subtractive technique can be optimized to reduce
manufacturing costs by saving printing time and reducing material and energy
usage. In this work, a numerical methodology based on parametric shape
optimization is proposed for optimizing the thickness of the extra material,
allowing for minimal machining operations while ensuring the finishing
requirements. Moreover, the proposed approach is complemented by a novel
algorithm for generating inner structures leading to reduced distortion and
improved weight reduction. The computational effort induced by classical
constrained optimization methods is alleviated by replacing both the objective
and constraint functions by their sparse-grid surrogates. Numerical results
showcase the effectiveness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01372</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01372</id><created>2019-07-01</created><authors><author><keyname>Peyser</keyname><forenames>Cal</forenames></author><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Wu</keyname><forenames>Zelin</forenames></author></authors><title>Improving Performance of End-to-End ASR on Numeric Sequences</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recognizing written domain numeric utterances (e.g. I need $1.25.) can be
challenging for ASR systems, particularly when numeric sequences are not seen
during training. This out-of-vocabulary (OOV) issue is addressed in
conventional ASR systems by training part of the model on spoken domain
utterances (e.g. I need one dollar and twenty five cents.), for which numeric
sequences are composed of in-vocabulary numbers, and then using an FST
verbalizer to denormalize the result. Unfortunately, conventional ASR models
are not suitable for the low memory setting of on-device speech recognition.
E2E models such as RNN-T are attractive for on-device ASR, as they fold the AM,
PM and LM of a conventional model into one neural network. However, in the
on-device setting the large memory footprint of an FST denormer makes spoken
domain training more difficult. In this paper, we investigate techniques to
improve E2E model performance on numeric data. We find that using a
text-to-speech system to generate additional numeric training data, as well as
using a small-footprint neural network to perform spoken-to-written domain
denorming, yields improvement in several numeric classes. In the case of the
longest numeric sequences, we see reduction of WER by up to a factor of 8.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01376</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01376</id><created>2019-07-02</created><updated>2019-07-08</updated><authors><author><keyname>Uzunova</keyname><forenames>Hristina</forenames></author><author><keyname>Ehrhardt</keyname><forenames>Jan</forenames></author><author><keyname>Jacob</keyname><forenames>Fabian</forenames></author><author><keyname>Frydrychowicz</keyname><forenames>Alex</forenames></author><author><keyname>Handels</keyname><forenames>Heinz</forenames></author></authors><title>Multi-scale GANs for Memory-efficient Generation of High Resolution
  Medical Images</title><categories>eess.IV cs.CV</categories><comments>Accepted at MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently generative adversarial networks (GANs) are rarely applied to
medical images of large sizes, especially 3D volumes, due to their large
computational demand. We propose a novel multi-scale patch-based GAN approach
to generate large high resolution 2D and 3D images. Our key idea is to first
learn a low-resolution version of the image and then generate patches of
successively growing resolutions conditioned on previous scales. In a domain
translation use-case scenario, 3D thorax CTs of size 512x512x512 and thorax
X-rays of size 2048x2048 are generated and we show that, due to the constant
GPU memory demand of our method, arbitrarily large images of high resolution
can be generated. Moreover, compared to common patch-based approaches, our
multi-resolution scheme enables better image quality and prevents patch
artifacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01377</identifier>
 <datestamp>2019-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01377</id><created>2019-07-02</created><updated>2019-10-29</updated><authors><author><keyname>Wong</keyname><forenames>Tak Ming</forenames></author><author><keyname>Kahl</keyname><forenames>Matthias</forenames></author><author><keyname>Bol&#xed;var</keyname><forenames>Peter Haring</forenames></author><author><keyname>Kolb</keyname><forenames>Andreas</forenames></author><author><keyname>M&#xf6;ller</keyname><forenames>Michael</forenames></author></authors><title>Training Auto-encoder-based Optimizers for Terahertz Image
  Reconstruction</title><categories>cs.CV cs.LG eess.IV</categories><comments>This is a pre-print of a conference paper published in German
  Conference on Pattern Recognition (GCPR) 2019</comments><journal-ref>Pattern Recognition. DAGM GCPR 2019. Lecture Notes in Computer
  Science, vol 11824. Springer, Cham</journal-ref><doi>10.1007/978-3-030-33676-9_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Terahertz (THz) sensing is a promising imaging technology for a wide variety
of different applications. Extracting the interpretable and physically
meaningful parameters for such applications, however, requires solving an
inverse problem in which a model function determined by these parameters needs
to be fitted to the measured data. Since the underlying optimization problem is
nonconvex and very costly to solve, we propose learning the prediction of
suitable parameters from the measured data directly. More precisely, we develop
a model-based autoencoder in which the encoder network predicts suitable
parameters and the decoder is fixed to a physically meaningful model function,
such that we can train the encoding network in an unsupervised way. We
illustrate numerically that the resulting network is more than 140 times faster
than classical optimization techniques while making predictions with only
slightly higher objective values. Using such predictions as starting points of
local optimization techniques allows us to converge to better local minima
about twice as fast as optimization without the network-based initialization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01406</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01406</id><created>2019-07-01</created><authors><author><keyname>Dhamala</keyname><forenames>Jwala</forenames></author><author><keyname>Ghimire</keyname><forenames>Sandesh</forenames></author><author><keyname>Sapp</keyname><forenames>John L.</forenames></author><author><keyname>Horacek</keyname><forenames>B. Milan</forenames></author><author><keyname>Wang</keyname><forenames>Linwei</forenames></author></authors><title>Bayesian Optimization on Large Graphs via a Graph Convolutional
  Generative Model: Application in Cardiac Model Personalization</title><categories>eess.IV cs.CV cs.LG</categories><comments>9 pages, 5 figures, MICCAI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Personalization of cardiac models involves the optimization of organ tissue
properties that vary spatially over the non-Euclidean geometry model of the
heart. To represent the high-dimensional (HD) unknown of tissue properties,
most existing works rely on a low-dimensional (LD) partitioning of the
geometrical model. While this exploits the geometry of the heart, it is of
limited expressiveness to allow partitioning that is small enough for effective
optimization. Recently, a variational auto-encoder (VAE) was utilized as a more
expressive generative model to embed the HD optimization into the LD latent
space. Its Euclidean nature, however, neglects the rich geometrical information
in the heart. In this paper, we present a novel graph convolutional VAE to
allow generative modeling of non-Euclidean data, and utilize it to embed
Bayesian optimization of large graphs into a small latent space. This approach
bridges the gap of previous works by introducing an expressive generative model
that is able to incorporate the knowledge of spatial proximity and hierarchical
compositionality of the underlying geometry. It further allows transferring of
the learned features across different geometries, which was not possible with a
regular VAE. We demonstrate these benefits of the presented method in synthetic
and real data experiments of estimating tissue excitability in a cardiac
electrophysiological model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01409</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01409</id><created>2019-07-01</created><authors><author><keyname>Michel</keyname><forenames>Wilfried</forenames></author><author><keyname>Schl&#xfc;ter</keyname><forenames>Ralf</forenames></author><author><keyname>Ney</keyname><forenames>Hermann</forenames></author></authors><title>Comparison of Lattice-Free and Lattice-Based Sequence Discriminative
  Training Criteria for LVCSR</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>Submitted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence discriminative training criteria have long been a standard tool in
automatic speech recognition for improving the performance of acoustic models
over their maximum likelihood / cross entropy trained counterparts. While
previously a lattice approximation of the search space has been necessary to
reduce computational complexity, recently proposed methods use other
approximations to dispense of the need for the computationally expensive step
of separate lattice creation.
  In this work we present a memory efficient implementation of the
forward-backward computation that allows us to use uni-gram word-level language
models in the denominator calculation while still doing a full summation on
GPU. This allows for a direct comparison of lattice-based and lattice-free
sequence discriminative training criteria such as MMI and sMBR, both using the
same language model during training.
  We compared performance, speed of convergence, and stability on large
vocabulary continuous speech recognition tasks like Switchboard and Quaero. We
found that silence modeling seriously impacts the performance in the
lattice-free case and needs special treatment. In our experiments lattice-free
MMI comes on par with its lattice-based counterpart. Lattice-based sMBR still
outperforms all lattice-free training criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01413</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01413</id><created>2019-07-01</created><authors><author><keyname>Ribeiro</keyname><forenames>Manuel Sam</forenames></author><author><keyname>Eshky</keyname><forenames>Aciel</forenames></author><author><keyname>Richmond</keyname><forenames>Korin</forenames></author><author><keyname>Renals</keyname><forenames>Steve</forenames></author></authors><title>Speaker-independent classification of phonetic segments from raw
  ultrasound in child speech</title><categories>eess.AS cs.CL cs.CV cs.LG cs.SD eess.IV</categories><comments>5 pages, 4 figures, published in ICASSP2019 (IEEE International
  Conference on Acoustics, Speech and Signal Processing, 2019)</comments><doi>10.1109/ICASSP.2019.8683564</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasound tongue imaging (UTI) provides a convenient way to visualize the
vocal tract during speech production. UTI is increasingly being used for speech
therapy, making it important to develop automatic methods to assist various
time-consuming manual tasks currently performed by speech therapists. A key
challenge is to generalize the automatic processing of ultrasound tongue images
to previously unseen speakers. In this work, we investigate the classification
of phonetic segments (tongue shapes) from raw ultrasound recordings under
several training scenarios: speaker-dependent, multi-speaker,
speaker-independent, and speaker-adapted. We observe that models underperform
when applied to data from speakers not seen at training time. However, when
provided with minimal additional speaker information, such as the mean
ultrasound frame, the models generalize better to unseen speakers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01430</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01430</id><created>2019-07-02</created><authors><author><keyname>Laradji</keyname><forenames>Issam H.</forenames></author><author><keyname>Vazquez</keyname><forenames>David</forenames></author><author><keyname>Schmidt</keyname><forenames>Mark</forenames></author></authors><title>Where are the Masks: Instance Segmentation with Image-level Supervision</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted at BMVC2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major obstacle in instance segmentation is that existing methods often need
many per-pixel labels in order to be effective. These labels require large
human effort and for certain applications, such labels are not readily
available. To address this limitation, we propose a novel framework that can
effectively train with image-level labels, which are significantly cheaper to
acquire. For instance, one can do an internet search for the term &quot;car&quot; and
obtain many images where a car is present with minimal effort. Our framework
consists of two stages: (1) train a classifier to generate pseudo masks for the
objects of interest; (2) train a fully supervised Mask R-CNN on these pseudo
masks. Our two main contribution are proposing a pipeline that is simple to
implement and is amenable to different segmentation methods; and achieves new
state-of-the-art results for this problem setup. Our results are based on
evaluating our method on PASCAL VOC 2012, a standard dataset for weakly
supervised methods, where we demonstrate major performance gains compared to
existing methods with respect to mean average precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01442</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01442</id><created>2019-06-29</created><authors><author><keyname>Zhao</keyname><forenames>Xueyuan</forenames></author><author><keyname>Sadhu</keyname><forenames>Vidyasagar</forenames></author><author><keyname>Yang</keyname><forenames>Anthony</forenames></author><author><keyname>Pompili</keyname><forenames>Dario</forenames></author></authors><title>Improved Circuit Design of Analog Joint Source Channel Coding for
  Low-power and Low-complexity Wireless Sensors</title><categories>eess.SP cs.IT cs.NI math.IT</categories><comments>8 pages, IEEE Sensor Journal</comments><journal-ref>IEEE Sensors Journal, vol. 18, no. 1, pp. 281-289, 2018</journal-ref><doi>10.1109/JSEN.2017.2761765</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To enable low-power and low-complexity wireless monitoring, an improved
circuit design of Analog Joint Source Channel Coding (AJSCC) is proposed for
wireless sensor nodes. This innovative design is based on Analog Divider Blocks
(ADB) with tunable spacing between AJSCC levels. The ADB controls the switching
between two types of Voltage Controlled Voltage Sources (VCVS). LTSpice
simulations were performed to evaluate the performance of the circuit, and the
power consumption and circuit complexity of this new ADB-based design were
compared with our previous parallel-VCVS design. It is found that this improved
circuit design based on ADB outperforms the design based on parallel VCVS for a
large number of AJSCC levels (&gt;= 16), both in terms of power consumption as
well as circuit complexity, thus enabling persistent and higher
temporal/spatial resolution environmental sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01448</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01448</id><created>2019-07-02</created><authors><author><keyname>Kao</keyname><forenames>Chieh-Chi</forenames></author><author><keyname>Sun</keyname><forenames>Ming</forenames></author><author><keyname>Gao</keyname><forenames>Yixin</forenames></author><author><keyname>Vitaladevuni</keyname><forenames>Shiv</forenames></author><author><keyname>Wang</keyname><forenames>Chao</forenames></author></authors><title>Sub-band Convolutional Neural Networks for Small-footprint Spoken Term
  Classification</title><categories>eess.AS cs.SD</categories><comments>Accepted by Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a Sub-band Convolutional Neural Network for spoken term
classification. Convolutional neural networks (CNNs) have proven to be very
effective in acoustic applications such as spoken term classification, keyword
spotting, speaker identification, acoustic event detection, etc. Unlike
applications in computer vision, the spatial invariance property of 2D
convolutional kernels does not fit acoustic applications well since the meaning
of a specific 2D kernel varies a lot along the feature axis in an input feature
map. We propose a sub-band CNN architecture to apply different convolutional
kernels on each feature sub-band, which makes the overall computation more
efficient. Experimental results show that the computational efficiency brought
by sub-band CNN is more beneficial for small-footprint models. Compared to a
baseline full band CNN for spoken term classification on a publicly available
Speech Commands dataset, the proposed sub-band CNN architecture reduces the
computation by 39.7% on commands classification, and 49.3% on digits
classification with accuracy maintained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01459</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01459</id><created>2019-07-02</created><authors><author><keyname>Hugues-Salas</keyname><forenames>Emilio</forenames></author><author><keyname>Wang</keyname><forenames>Qibing</forenames></author><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Rajkumar</keyname><forenames>Kalyani</forenames></author><author><keyname>Kanellos</keyname><forenames>George T.</forenames></author><author><keyname>Nejabati</keyname><forenames>Reza</forenames></author><author><keyname>Simeonidou</keyname><forenames>Dimitra</forenames></author></authors><title>Coexistence of 11.2Tb/s Carrier-Grade Classical Channels and a DV-QKD
  Channel over a 7-Core Multicore Fibre</title><categories>eess.SP cs.CR</categories><comments>4 pages, 5 Figures, EUROPEAN CONFERENCE ON OPTICAL COMMUNICATIONS
  (ECOC'19)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We successfully demonstrate coexistence of record-high 11.2 Tb/s (56x200Gb/s)
classical channels with a discrete-variable-QKD channel over a multicore fibre.
Continuous secret key generation is confirmed together with classical channel
performance below the SDFEC limit and a minimum quantum channel spacing of 17nm
in the C-band.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01497</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01497</id><created>2019-07-02</created><authors><author><keyname>Richardson</keyname><forenames>Alan</forenames></author><author><keyname>Feller</keyname><forenames>Caelen</forenames></author></authors><title>Seismic data denoising and deblending using deep learning</title><categories>eess.IV cs.LG physics.comp-ph physics.geo-ph</categories><comments>17 pages, 7 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  An important step of seismic data processing is removing noise, including
interference due to simultaneous and blended sources, from the recorded data.
Traditional methods are time-consuming to apply as they often require manual
choosing of parameters to obtain good results. We use deep learning, with a
U-net model incorporating a ResNet architecture pretrained on ImageNet and
further trained on synthetic seismic data, to perform this task. The method is
applied to common offset gathers, with adjacent offset gathers of the gather
being denoised provided as additional input channels. Here we show that this
approach leads to a method that removes noise from several datasets recorded in
different parts of the world with moderate success. We find that providing
three adjacent offset gathers on either side of the gather being denoised is
most effective. As this method does not require parameters to be chosen, it is
more automated than traditional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01513</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01513</id><created>2019-06-25</created><authors><author><keyname>Van Zaen</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Ch&#xe9;telat</keyname><forenames>Olivier</forenames></author><author><keyname>Lemay</keyname><forenames>Mathieu</forenames></author><author><keyname>Calvo</keyname><forenames>Enric M.</forenames></author><author><keyname>Delgado-Gonzalo</keyname><forenames>Ricard</forenames></author></authors><title>Classification of Cardiac Arrhythmias from Single Lead ECG with a
  Convolutional Recurrent Neural Network</title><categories>eess.SP cs.LG</categories><comments>Nominated to best paper award</comments><journal-ref>Proceedings of the International Joint Conference on Biomedical
  Engineering Systems and Technologies (BIOSTEC19), Prague, Czech Republic,
  February 22-24, 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While most heart arrhythmias are not immediately harmful, they can lead to
severe complications. In particular, atrial fibrillation, the most common
arrhythmia, is characterized by fast and irregular heart beats and increases
the risk of suffering a stroke. To detect such abnormal heart conditions, we
propose a system composed of two main parts: a smart vest with two cooperative
sensors to collect ECG data and a neural network architecture to classify heart
rhythms. The smart vest uses two dry bi-electrodes to record a single lead ECG
signal. The biopotential signal is then streamed via a gateway to the cloud
where a neural network detects and classifies the heart arrhythmias. We
selected an architecture that combines convolutional and recurrent layers. The
convolutional layers extract relevant features from sliding windows of ECG and
the recurrent layer aggregates them for a final softmax layer that performs the
classification. Our neural network achieves an accuracy of 87.50% on the
dataset of the challenge of Computing in Cardiology 2017.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01514</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01514</id><created>2019-06-25</created><updated>2019-10-27</updated><authors><author><keyname>Zhang</keyname><forenames>Jie</forenames></author><author><keyname>Li</keyname><forenames>Bohao</forenames></author><author><keyname>Xiang</keyname><forenames>Kexin</forenames></author><author><keyname>Shi</keyname><forenames>Xuegang</forenames></author></authors><title>Method of diagnosing heart disease based on deep learning ECG signal</title><categories>eess.SP cs.CV</categories><comments>9 pages,5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional method of diagnosing heart disease on ECG signal is
artificial observation. Some have tried to combine expertise and signal
processing to classify ECG signal by heart disease type. However, the currency
is not so sufficient that it can be used in medical applications. We develop an
algorithm that combines signal processing and deep learning to classify ECG
signals into Normal AF other rhythm and noise, which help us solve this
problem. It is demonstrated that we can obtain the time-frequency diagram of
ECG signal by wavelet transform, and use DNN to classify the time-frequency
diagram to find out the heart disease that the signal collector may have.
Overall, an accuracy of 94 percent is achieved on the validation set. According
to the evaluation criteria of PhysioNet/Computing in Cardiology (CinC) in 2017,
the F1 score of this method is 0.957, which is higher than the first place in
the competition in 2017.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01515</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01515</id><created>2019-06-25</created><authors><author><keyname>Jayawardana</keyname><forenames>Yasith</forenames></author><author><keyname>Jaime</keyname><forenames>Mark</forenames></author><author><keyname>Thapaliya</keyname><forenames>Sashi</forenames></author><author><keyname>Jayarathna</keyname><forenames>Sampath</forenames></author></authors><title>Electroencephalogram (EEG) for Delineating Objective Measure of Autism
  Spectrum Disorder (ASD) (Extended Version)</title><categories>eess.SP cs.IR cs.LG cs.NE stat.ML</categories><doi>10.4018/978-1-5225-7467-5.ch002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autism Spectrum Disorder (ASD) is a developmental disorder that often impairs
a child's normal development of the brain. According to CDC, it is estimated
that 1 in 6 children in the US suffer from development disorders, and 1 in 68
children in the US suffer from ASD. This condition has a negative impact on a
person's ability to hear, socialize and communicate. Overall, ASD has a broad
range of symptoms and severity; hence the term spectrum is used. One of the
main contributors to ASD is known to be genetics. Up to date, no suitable cure
for ASD has been found. Early diagnosis is crucial for the long-term treatment
of ASD, but this is challenging due to the lack of a proper objective measures.
Subjective measures often take more time, resources, and have false positives
or false negatives. There is a need for efficient objective measures that can
help in diagnosing this disease early as possible with less effort.
  EEG measures the electric signals of the brain via electrodes placed on
various places on the scalp. These signals can be used to study complex
neuropsychiatric issues. Studies have shown that EEG has the potential to be
used as a biomarker for various neurological conditions including ASD. This
chapter will outline the usage of EEG measurement for the classification of ASD
using machine learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01516</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01516</id><created>2019-06-25</created><updated>2019-10-20</updated><authors><author><keyname>Zhou</keyname><forenames>Zhou</forenames></author><author><keyname>Liu</keyname><forenames>Lingjia</forenames></author><author><keyname>Chang</keyname><forenames>Hao-Hsuan</forenames></author></authors><title>Learning for Detection: MIMO-OFDM Symbol Detection through Downlink
  Pilots</title><categories>eess.SP cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reservoir computing (RC) is a special recurrent neural network which consists
of a fixed high dimensional feature mapping and trained readout weights. In
this paper, we introduce a new RC structure for multiple-input, multiple-output
orthogonal frequency-division multiplexing (MIMO-OFDM) symbol detection, namely
windowed echo state network (WESN). The theoretical analysis shows that adding
buffers in input layers can bring an enhanced short-term memory (STM) to the
underlying neural network. Furthermore, a unified training framework is
developed for the WESN MIMO-OFDM symbol detector using both comb and scattered
pilot patterns that are compatible with the structure adopted in 3GPP
LTE/LTE-Advanced systems. Complexity analysis suggests the advantages of WESN
based symbol detector over state-of-the-art symbol detectors such as the linear
minimum mean square error (LMMSE) detection and the sphere decoder, when the
system is employed with a large number of OFDM sub-carriers. Numerical
evaluations illustrate the advantage of the introduced WESN-based symbol
detector and demonstrate that the improvement of STM can significantly improve
symbol detection performance as well as effectively mitigate model mismatch
effects compared to existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01517</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01517</id><created>2019-06-25</created><authors><author><keyname>Sun</keyname><forenames>Rongrong</forenames></author><author><keyname>Talarico</keyname><forenames>Salvatore</forenames></author><author><keyname>Chang</keyname><forenames>Wenting</forenames></author><author><keyname>Niu</keyname><forenames>Huaning</forenames></author><author><keyname>Yang</keyname><forenames>Hongwen</forenames></author></authors><title>Enabling NB-IoT on Unlicensed Spectrum</title><categories>eess.SP</categories><comments>7 pages, 5 tables, 5 Figures. Accepted in IEEE International
  Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC),
  (Istanbul, Turkey), September 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The deployment of Internet of Things (IoT) technologies in unlicensed
spectrum is a candidate feature for 5G to support massive connections of IoT
devices. Current IoT unlicensed band technologies, such as Sigfox and LoRa, are
all at an early stage of deployment without a significant market share. In this
context, the MulteFire (MF) Alliance has envisioned to adapt the cellular
NB-IoT design to operate within the Sub-1 GHz unlicensed spectrum. However, the
diverse regulatory requirements within this unlicensed band put a hurdle to the
world-wide deployment of unlicensed band IoT technologies. To settle this
challenge, MF has designed a specific framework for narrow-band (NB)-IoT
systems operating on unlicensed spectrum (NB-IoT-U), which can be utilized
under both the Federal Communications Commission (FCC) and European
Telecommunication Standards Institute (ETSI) regulatory requirements. In this
paper, enhanced synchronization and physical broadcasting signals are proposed
based upon the framework designed by MF with the aim to allow a more robust
detection, and to fulfil the coverage targets set for this technology.
Furthermore, in order to allow the system to operate as a frequency hopping
spread spectrum (FHSS) system, a novel frequency hopping pattern generator
compliant with the regulatory requirements is designed, and its performance is
evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01518</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01518</id><created>2019-06-26</created><authors><author><keyname>Cui</keyname><forenames>Zhuangzhuang</forenames></author><author><keyname>Guan</keyname><forenames>Ke</forenames></author><author><keyname>Briso</keyname><forenames>C&#xe9;sar</forenames></author><author><keyname>He</keyname><forenames>Danping</forenames></author><author><keyname>Cheng</keyname><forenames>Jianqiao</forenames></author><author><keyname>Zhong</keyname><forenames>Zhangdui</forenames></author><author><keyname>Quitin</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Analytical Modeling of UAV-to-Vehicle Propagation Channels in Built-Up
  Areas</title><categories>eess.SP cs.SY eess.SY</categories><comments>Submmitted to IEEE Wireless Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter presents an analytical path loss model for air-ground (AG)
propagation between unmanned aerial vehicles (UAVs) and ground-based vehicles.
We consider built-up areas, such as the ones defined by ITU-R. The
three-dimensional (3D) path loss model is based on propagation conditions and
essential parameters are derived by using geometric methods. Owing to the
generality, the analytical model is capable of arbitrary deployments of
buildings, such as suburban, urban and dense urban. The analytical model is
evaluated numerically, and validations conducted by ray-tracing simulations
show the high accuracy of the proposed model. The closed-form analytical
formulas provide a useful tool for quick and accurate prediction of
UAV-to-vehicle propagation channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01520</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01520</id><created>2019-06-27</created><authors><author><keyname>Liu</keyname><forenames>Zixi</forenames></author><author><keyname>Zhu</keyname><forenames>Qi</forenames></author><author><keyname>Su</keyname><forenames>Mei</forenames></author></authors><title>Metal Object Detection Based on Load Impedance and Input Power
  Characteristics for High-dimensional WPT System</title><categories>eess.SP cs.SY eess.SY</categories><comments>9 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-dimensional wireless power transfer (WPT) systems have received
increasing attention for charging mobile devices. With the receivers have
higher spatial freedom, the systems are more susceptible to the metal objects
in the surroundings. However, conventional methods for metal object detection
(MOD) can't satisfy the requirements of safety and stability of new systems.
This paper proposed a metal detection method which is more suitable for
high-dimensional WPT systems. The key feature of the proposed method is
combining load impedance and input power characteristics curves to determine
whether the receiver is a metal object or a coil. And the influence of the
metal is discussed in the circuit and magnetic model. The method is
theoretically proven by the simulation calculation. And the experiments
verified that the method can accurately detect the metal objects by setting the
threshold curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01521</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01521</id><created>2019-06-27</created><authors><author><keyname>Ren</keyname><forenames>Hai-Peng</forenames></author><author><keyname>Zhao</keyname><forenames>Hong-Er</forenames></author><author><keyname>Bai</keyname><forenames>Chao</forenames></author><author><keyname>Yin</keyname><forenames>Hui-Ping</forenames></author><author><keyname>Grebogi</keyname><forenames>Celso</forenames></author></authors><title>Artificial Intelligence Enhances the Performance of Chaos-based Wireless
  Communication</title><categories>eess.SP</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some new findings for chaos-based wireless communication systems have been
identified recently. First, chaos has proven to be the optimal communication
waveform because chaotic signals can achieve the maximum signal to noise ratio
at receiver with the simplest matched filter. Second, the information
transmitted in chaotic signals is not modified by the multipath wireless
channel. Third, chaos properties can be used to relief inter-symbol
interference (ISI) caused by multipath propagation. Although recent work has
reported the method of obtaining the optimal threshold to eliminate the ISI in
chaos-based wireless communication, its practical implementation is still a
challenge. By knowing the channel parameters and all symbols, especially the
future symbol to be transmitted in advance, it is almost an impossible task in
the practical communication systems. Owning to Artificial intelligence (AI)
recent developments, Convolutional Neural Network (CNN) with deep learning
structure is being proposed to predict future symbols based on the received
signal, so as to further reduce ISI and obtain better bit error rate (BER)
performance as compared to that used the existing sub-optimal threshold. The
feature of the method involves predicting the future symbol and obtaining a
better threshold suitable for time variant channel. Numerical simulation and
experimental results validate our theory and the superiority of the proposed
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01522</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01522</id><created>2019-06-28</created><authors><author><keyname>Zhang</keyname><forenames>Kaiqi</forenames></author><author><keyname>Zhang</keyname><forenames>Xiyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Zheng</forenames></author></authors><title>Tucker Tensor Decomposition on FPGA</title><categories>eess.SP cs.AR</categories><comments>Accepted by ICCAD 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tensor computation has emerged as a powerful mathematical tool for solving
high-dimensional and/or extreme-scale problems in science and engineering. The
last decade has witnessed tremendous advancement of tensor computation and its
applications in machine learning and big data. However, its hardware
optimization on resource-constrained devices remains an (almost) unexplored
field. This paper presents an hardware accelerator for a classical tensor
computation framework, Tucker decomposition. We study three modules of this
architecture: tensor-times-matrix (TTM), matrix singular value decomposition
(SVD), and tensor permutation, and implemented them on Xilinx FPGA for
prototyping. In order to further reduce the computing time, a warm-start
algorithm for the Jacobi iterations in SVD is proposed. A fixed-point simulator
is used to evaluate the performance of our design. Some synthetic data sets and
a real MRI data set are used to validate the design and evaluate its
performance. We compare our work with state-of-the-art software toolboxes
running on both CPU and GPU, and our work shows 2.16 - 30.2x speedup on the
cardiac MRI data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01523</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01523</id><created>2019-06-30</created><authors><author><keyname>Dong</keyname><forenames>Rui</forenames></author><author><keyname>She</keyname><forenames>Changyang</forenames></author><author><keyname>Hardjawana</keyname><forenames>Wibowo</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Deep Learning for Hybrid 5G Services in Mobile Edge Computing Systems:
  Learn from a Digital Twin</title><categories>eess.SP cs.IT cs.LG math.IT</categories><comments>To appear in IEEE Trans. on Wireless Commun. (accepted with minor
  revision)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider a mobile edge computing system with both
ultra-reliable and low-latency communications services and delay tolerant
services. We aim to minimize the normalized energy consumption, defined as the
energy consumption per bit, by optimizing user association, resource
allocation, and offloading probabilities subject to the quality-of-service
requirements. The user association is managed by the mobility management entity
(MME), while resource allocation and offloading probabilities are determined by
each access point (AP). We propose a deep learning (DL) architecture, where a
digital twin of the real network environment is used to train the DL algorithm
off-line at a central server. From the pre-trained deep neural network (DNN),
the MME can obtain user association scheme in a real-time manner. Considering
that real networks are not static, the digital twin monitors the variation of
real networks and updates the DNN accordingly. For a given user association
scheme, we propose an optimization algorithm to find the optimal resource
allocation and offloading probabilities at each AP. Simulation results show
that our method can achieve lower normalized energy consumption with less
computation complexity compared with an existing method and approach to the
performance of the global optimal solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01525</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01525</id><created>2019-04-22</created><authors><author><keyname>Bangari</keyname><forenames>Viraj</forenames></author><author><keyname>Marquez</keyname><forenames>Bicky A.</forenames></author><author><keyname>Miller</keyname><forenames>Heidi B.</forenames></author><author><keyname>Tait</keyname><forenames>Alexander N.</forenames></author><author><keyname>Nahmias</keyname><forenames>Mitchell A.</forenames></author><author><keyname>de Lima</keyname><forenames>Thomas Ferreira</forenames></author><author><keyname>Peng</keyname><forenames>Hsuan-Tung</forenames></author><author><keyname>Prucnal</keyname><forenames>Paul R.</forenames></author><author><keyname>Shastri</keyname><forenames>Bhavin J.</forenames></author></authors><title>Digital Electronics and Analog Photonics for Convolutional Neural
  Networks (DEAP-CNNs)</title><categories>eess.SP cs.NE physics.app-ph physics.optics</categories><comments>12 pages, 9 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Networks (CNNs) are powerful and highly ubiquitous tools
for extracting features from large datasets for applications such as computer
vision and natural language processing. However, a convolution is a
computationally expensive operation in digital electronics. In contrast,
neuromorphic photonic systems, which have experienced a recent surge of
interest over the last few years, propose higher bandwidth and energy
efficiencies for neural network training and inference. Neuromorphic photonics
exploits the advantages of optical electronics, including the ease of analog
processing, and busing multiple signals on a single waveguide at the speed of
light. Here, we propose a Digital Electronic and Analog Photonic (DEAP) CNN
hardware architecture that has potential to be 2.8 to 14 times faster while
maintaining the same power usage of current state-of-the-art GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01526</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01526</id><created>2019-06-11</created><authors><author><keyname>Mohanty</keyname><forenames>Saraju P.</forenames></author><author><keyname>Kougianos</keyname><forenames>Elias</forenames></author></authors><title>iVAMS 2.0: Machine-Learning-Metamodel-Integrated Intelligent Verilog-AMS
  for Fast and Accurate Mixed-Signal Design Optimization</title><categories>eess.SP</categories><comments>28 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The gap between abstraction levels in analog design is a major obstacle for
advancing analog and mixed-signal (AMS) design automation and computer-aided
design (CAD). Intelligent models for low-level analog building blocks are
needed to bridge the accuracy gap between behavioral and transistor-level
simulations. The models should be able to accurately estimate the
characteristics of the analog block over a large design space. Machine learning
(ML) models based on actual silicon have the capabilities of capturing detailed
characteristics of complex designs. In this paper, a ML model called Artificial
Neural Network Metamodels (ANNM) have been explored to capture the highly
nonlinear nature of analog blocks. The application of these intelligent models
to multi-objective AMS block optimization is demonstrated. Parameterized
behavioral models in Verilog-AMS based on the ANN metamodels are constructed
for efficient AMS design exploration. To the best of the authors' knowledge
this is the first paper to integrate ANN models in Verilog-AMS, which is called
iVAMS 2.0. To demonstrate the application of iVAMS 2.0, this paper presents two
case studies: an operational amplifier (OP-AMP) and a phase-locked loop (PLL).
A biologically-inspired &quot;firefly optimization algorithm&quot; is applied to an
OP-AMP design in the iVAMS 2.0 framework. The optimization process is sped up
by 5580X due to the use of iVAMS with negligible loss in accuracy. Similarly,
for a PLL design, the physical design aware ANNs are trained and used as
metamodels to predict its frequency, locking time, and power. Thorough
experimental results demonstrate that only 100 sample points are sufficient for
ANNs to predict the output of circuits with 21 design parameters within 3%
accuracy. A proposed artificial bee colony (ABC) based algorithm performs
optimization over the ANN metamodels of the PLL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01527</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01527</id><created>2019-06-17</created><authors><author><keyname>Ren</keyname><forenames>Zhiwei</forenames></author><author><keyname>Jin</keyname><forenames>Lichuan</forenames></author><author><keyname>Wen</keyname><forenames>Tianlong</forenames></author><author><keyname>Liao</keyname><forenames>Yulong</forenames></author><author><keyname>Tang</keyname><forenames>Xiaoli</forenames></author><author><keyname>Zhang</keyname><forenames>Huaiwu</forenames></author><author><keyname>Zhong</keyname><forenames>Zhiyong</forenames></author></authors><title>MuFA (Multi-type Fourier Analyzer): A tool for batch generation of
  MuMax3 input scripts and multi-type Fourier analysis from micromagnetic
  simulation output data</title><categories>eess.SP</categories><doi>10.1016/j.cpc.2019.06.023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a tool for batch generation of input scripts and multi-type
Fourier analysis from simulation results for the micromagnetic software MuMax3.
The introduction of graphical user interface and parameter-sweeping
functionality strongly speed up the input scripts creation and accelerate model
optimization processes consequently. Three types of important Fourier analysis
methods are provided for the acquisition of the quantitative frequency
compositions, the spin-wave dispersion curve and the spatial distribution of
spin-wave powers at different frequencies, respectively. Since the Fourier
analysis is accelerated by parallel computations, the time cost is reduced to
an acceptable level even in the presentation of tens of gigabytes data. With
the MuMax3 and our proposal, a complete micromagnetic simulating tool chain
from scripts generation to post analysis has been developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01528</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01528</id><created>2019-07-02</created><authors><author><keyname>Cheng</keyname><forenames>Yi Fei</forenames></author><author><keyname>Sabry</keyname><forenames>Ziad</forenames></author><author><keyname>Strachan</keyname><forenames>Megan</forenames></author><author><keyname>Cornell</keyname><forenames>Skyler</forenames></author><author><keyname>Chanenson</keyname><forenames>Jake</forenames></author><author><keyname>Collins</keyname><forenames>Eva-Maria S.</forenames></author><author><keyname>Ganapati</keyname><forenames>Vidya</forenames></author></authors><title>Deep Learned Optical Multiplexing for Multi-Focal Plane Microscopy</title><categories>physics.optics eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To obtain microscope images at multiple focal planes, the distance between
the objective and sample can be mechanically adjusted. Images are acquired
sequentially at each axial distance. Digital refocusing with a light-emitting
diode (LED) array microscope allows elimination of this mechanical movement. In
an LED array microscope, the light source of a conventional widefield
microscope is replaced with a 2-dimensional LED matrix. A stack of images is
acquired from the LED array microscope by sequentially illuminating each LED
and capturing an image. Previous work has shown that we can achieve digital
refocusing by post-processing this LED image stack. Though mechanical scanning
is eliminated, digital refocusing with an LED array microscope has low temporal
resolution due to the acquisition of multiple images. In this work, we propose
a new paradigm for multi-focal plane microscopy for live imaging, utilizing an
LED array microscope and deep learning. In our deep learning approach, we look
for a single LED illumination pattern that allows the information from multiple
focal planes to be multiplexed into a single image. We jointly optimize this
LED illumination pattern with the parameters of a post-processing deep neural
network, using a training set of LED image stacks from fixed, not live, Dugesia
japonica planarians. Once training is complete, we obtain multiple focal planes
by inputting a single multiplexed LED image into the trained post-processing
deep neural network. We demonstrate live imaging of a D. japonica planarian at
5 focal planes with our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01529</identifier>
 <datestamp>2019-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01529</id><created>2019-07-02</created><authors><author><keyname>van der Heide</keyname><forenames>Sjoerd</forenames></author><author><keyname>Chen</keyname><forenames>Bin</forenames></author><author><keyname>Hout</keyname><forenames>Menno van den</forenames></author><author><keyname>Hafermann</keyname><forenames>Hartmut</forenames></author><author><keyname>Koonen</keyname><forenames>Ton</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author><author><keyname>Okonkwo</keyname><forenames>Chigo</forenames></author></authors><title>Experimental Demonstration of Eight-dimensional Modulation Formats for
  Long-haul Optical Transmission</title><categories>eess.SP</categories><comments>ECOC (European Conference on Optical Communication) 2019 submission.
  Accepted for oral presentation at 11:15 on 2019/09/25 in the &quot;Modulation and
  Coding&quot; session</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Two novel 5.5 bit/4D modulation formats are experimentally demonstrated to
transmit over 9680 km of SSMF. A reach increase of 29.4% over the 6 bit/4D
PM-8QAM is shown. Furthermore, increased nonlinear tolerance with respect to
PM-8QAM is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01592</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01592</id><created>2019-07-02</created><authors><author><keyname>Bryan</keyname><forenames>Kurt</forenames></author><author><keyname>Walter</keyname><forenames>Deborah</forenames></author></authors><title>Geolocation of Multiple Noncooperative Emitters Using Received Signal
  Strength: Sparsity, Resolution, and Detectability</title><categories>eess.SP</categories><comments>14 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the problem of locating multiple non-cooperative
radio frequency (RF) emitters using only received signal strength (RSS) data.
We assume that the number of emitters is unknown and that individual emitters
cannot be distinguished in the RSS data. Moreover, we assume that the
environment in which the data has been collected has not been mapped or
&quot;fingerprinted&quot; by the prior collection of RSS data. Our primary interest is
the limiting resolution that can be obtained by this type of data, and the
lowest power emitters that can be detected, as a function of noise level,
sensor geometry, and other variables. We formulate the recovery problem as one
of sparse approximation or compressed sensing, and investigate an appropriate
recovery algorithm for this setting, and use it to illustrate our conclusions.
We also include a reconstruction based on sampled data we collected, to
illustrate the reasonableness of our parameter choices and conclusions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01593</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01593</id><created>2019-07-02</created><updated>2019-07-22</updated><authors><author><keyname>Fidon</keyname><forenames>Lucas</forenames></author><author><keyname>Ebner</keyname><forenames>Michael</forenames></author><author><keyname>Garcia-Peraza-Herrera</keyname><forenames>Luis C.</forenames></author><author><keyname>Modat</keyname><forenames>Marc</forenames></author><author><keyname>Ourselin</keyname><forenames>Sebastien</forenames></author><author><keyname>Vercauteren</keyname><forenames>Tom</forenames></author></authors><title>Incompressible image registration using divergence-conforming B-splines</title><categories>eess.IV</categories><comments>Accepted at MICCAI 2019</comments><doi>10.1007/978-3-030-32245-8_49</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Anatomically plausible image registration often requires volumetric
preservation. Previous approaches to incompressible image registration have
exploited relaxed constraints, ad hoc optimisation methods or practically
intractable computational schemes. Divergence-free velocity fields have been
used to achieve incompressibility in the continuous domain, although, after
discretisation, no guarantees have been provided. In this paper, we introduce
stationary velocity fields (SVFs) parameterised by divergence-conforming
B-splines in the context of image registration. We demonstrate that sparse
linear constraints on the parameters of such divergence-conforming B-Splines
SVFs lead to being exactly divergence-free at any point of the continuous
spatial domain. In contrast to previous approaches, our framework can easily
take advantage of modern solvers for constrained optimisation, symmetric
registration approaches, arbitrary image similarity and additional
regularisation terms. We study the numerical incompressibility error for the
transformation in the case of an Euler integration, which gives theoretical
insights on the improved accuracy error over previous methods. We evaluate the
proposed framework using synthetically deformed multimodal brain images, and
the STACOM11 myocardial tracking challenge. Accuracy measurements demonstrate
that our method compares favourably with state-of-the-art methods whilst
achieving volume preservation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01599</identifier>
 <datestamp>2019-09-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01599</id><created>2019-07-02</created><updated>2019-09-20</updated><authors><author><keyname>Li</keyname><forenames>Guchong</forenames></author></authors><title>Multi-object Tracking in Unknown Detection Probability with the PMBM
  Filter</title><categories>eess.SY cs.SY</categories><comments>11 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the joint multi-object tracking (MOT) and the estimate
of detection probability with the \emph{Poisson multi-Bernoulli mixture} (PMBM)
filter. In a majority of multi-object scenarios, the knowledge of detection
probability is usually uncertain, which is often estimated offline from the
training data. In such cases, online filtering is not allowed or believable,
otherwise, significate parameter mismatch will result in biased estimates
(state and cardinality of objects). Consequently, the ability of adaptively
estimating the detection probability is essential in practice. In this paper,
we detail how the detection probability can be estimated accompanied with the
state estimates. Besides, closed-form solutions to the proposed method are
derived by approximating the intensity of Poisson random finite set (RFS) to a
Beta-Gaussian mixture form and density of Bernoulli RFS to a single
Beta-Gaussian form. Simulation results show the effectiveness and superiority
of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01607</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01607</id><created>2019-07-02</created><updated>2019-07-04</updated><authors><author><keyname>Liang</keyname><forenames>Xia</forenames></author><author><keyname>Wu</keyname><forenames>Junmin</forenames></author><author><keyname>Yin</keyname><forenames>Yan</forenames></author></authors><title>MIDI-Sandwich: Multi-model Multi-task Hierarchical Conditional VAE-GAN
  networks for Symbolic Single-track Music Generation</title><categories>eess.AS cs.LG cs.MM cs.SD</categories><comments>cast KSEM2019 on May 3, 2019 (weak rejected)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most existing neural network models for music generation explore how to
generate music bars, then directly splice the music bars into a song. However,
these methods do not explore the relationship between the bars, and the
connected song as a whole has no musical form structure and sense of musical
direction. To address this issue, we propose a Multi-model Multi-task
Hierarchical Conditional VAE-GAN (Variational Autoencoder-Generative
adversarial networks) networks, named MIDI-Sandwich, which combines musical
knowledge, such as musical form, tonic, and melodic motion. The MIDI-Sandwich
has two submodels: Hierarchical Conditional Variational Autoencoder (HCVAE) and
Hierarchical Conditional Generative Adversarial Network (HCGAN). The HCVAE uses
hierarchical structure. The underlying layer of HCVAE uses Local Conditional
Variational Autoencoder (L-CVAE) to generate a music bar which is pre-specified
by the First and Last Notes (FLN). The upper layer of HCVAE uses Global
Variational Autoencoder(G-VAE) to analyze the latent vector sequence generated
by the L-CVAE encoder, to explore the musical relationship between the bars,
and to produce the song pieced together by multiple music bars generated by the
L-CVAE decoder, which makes the song both have musical structure and sense of
direction. At the same time, the HCVAE shares a part of itself with the HCGAN
to further improve the performance of the generated music. The MIDI-Sandwich is
validated on the Nottingham dataset and is able to generate a single-track
melody sequence (17x8 beats), which is superior to the length of most of the
generated models (8 to 32 beats). Meanwhile, by referring to the experimental
methods of many classical kinds of literature, the quality evaluation of the
generated music is performed. The above experiments prove the validity of the
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01629</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01629</id><created>2019-07-02</created><authors><author><keyname>Lal</keyname><forenames>Cerine</forenames></author><author><keyname>Leahy</keyname><forenames>Martin J</forenames></author></authors><title>An Updated Review of Methods and Advancements in Microvascular Blood
  Flow Imaging</title><categories>physics.med-ph eess.IV physics.bio-ph physics.ins-det</categories><journal-ref>Microcirculation. 2016 Jul;23(5):345-63</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  There has been a consistent growth in research involving imaging of
microvasculature over the past few decades. By 2008, publications mentioning
the microcirculation had grown more than 2000 per annum. Many techniques have
been demonstrated for measurement of the microcirculation ranging from the
earliest invasive techniques to the present high speed, high resolution
non-invasive imaging techniques. Understanding the microvasculature is vital in
tackling fundamental research questions as well as to understand effects of
disease progression on the physiological wellbeing of an individual. We have
previously provided a wide ranging review [38] covering most of the available
techniques and their applications. In this review, we discuss the recent
advances made and applications in the field of microcirculation imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01640</identifier>
 <datestamp>2019-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01640</id><created>2019-06-25</created><updated>2019-12-19</updated><authors><author><keyname>Damak</keyname><forenames>Khalil</forenames></author><author><keyname>Nasraoui</keyname><forenames>Olfa</forenames></author></authors><title>SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender
  System</title><categories>cs.IR cs.LG cs.SD eess.AS stat.ML</categories><comments>8 pages, 6 figures; added offline validation of explainability method</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State of the art music recommender systems mainly rely on either matrix
factorization-based collaborative filtering approaches or deep learning
architectures. Deep learning models usually use metadata for content-based
filtering or predict the next user interaction by learning from temporal
sequences of user actions. Despite advances in deep learning for song
recommendation, none has taken advantage of the sequential nature of songs by
learning sequence models that are based on content. Aside from the importance
of prediction accuracy, other significant aspects are important, such as
explainability and solving the cold start problem. In this work, we propose a
hybrid deep learning model, called &quot;SeER&quot;, that uses collaborative filtering
(CF) and deep learning sequence models on the MIDI content of songs for
recommendation in order to provide more accurate personalized recommendations;
solve the item cold start problem; and generate a relevant explanation for a
song recommendation. Our evaluation experiments show promising results compared
to state of the art baseline and hybrid song recommender systems in terms of
ranking evaluation. Moreover, based on proposed tests for offline validation,
we show that our personalized explanations capture properties that are in
accordance with the user's preferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01646</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01646</id><created>2019-06-30</created><authors><author><keyname>Zhao</keyname><forenames>Xueyuan</forenames></author><author><keyname>Sadhu</keyname><forenames>Vidyasagar</forenames></author><author><keyname>Le</keyname><forenames>Tuan</forenames></author><author><keyname>Pompili</keyname><forenames>Dario</forenames></author><author><keyname>Javanmard</keyname><forenames>Mehdi</forenames></author></authors><title>Towards Low-power Wearable Wireless Sensors for Molecular Biomarker and
  Physiological Signal Monitoring</title><categories>eess.SP</categories><comments>4 pages ISCAS 2017. arXiv admin note: substantial text overlap with
  arXiv:1907.00328</comments><journal-ref>IEEE International Symposium on Circuits and Systems (ISCAS),
  2017, pp. 1-4</journal-ref><doi>10.1109/ISCAS.2017.8050558</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A low-power wearable wireless sensor measuring both molecular biomarkers and
physiological signals is proposed, where the former are measured by a
microfluidic biosensing system while the latter are measured electrically. The
low-power consumption of the sensor is achieved by an all-analog circuit
implementing Analog Joint Source-Channel Coding (AJSCC) compression. The sensor
is applicable to a wide range of biomedical applications that require real-time
concurrent molecular biomarker and physiological signal monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01649</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01649</id><created>2019-07-02</created><authors><author><keyname>Cunningham</keyname><forenames>Ryan J.</forenames></author><author><keyname>Loram</keyname><forenames>Ian D.</forenames></author></authors><title>Estimation of Absolute States of Human Skeletal Muscle via Standard
  B-Mode Ultrasound Imaging and Deep Convolutional Neural Networks</title><categories>eess.IV cs.CV</categories><comments>10 pages, 5 figures, 2 tables. This paper is currently under review</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Objective: To test automated in vivo estimation of active and passive
skeletal muscle states using ultrasonic imaging. Background: Current technology
(electromyography, dynamometry, shear wave imaging) provides no general,
non-invasive method for online estimation of skeletal intramuscular states.
Ultrasound (US) allows non-invasive imaging of muscle, yet current
computational approaches have never achieved simultaneous extraction nor
generalisation of independently varying, active and passive states. We use deep
learning to investigate the generalizable content of 2D US muscle images.
Method: US data synchronized with electromyography of the calf muscles, with
measures of joint moment/angle were recorded from 32 healthy participants (7
female, ages: 27.5, 19-65). We extracted a region of interest of medial
gastrocnemius and soleus using our prior developed accurate segmentation
algorithm. From the segmented images, a deep convolutional neural network was
trained to predict three absolute, drift-free, components of the
neurobiomechanical state (activity, joint angle, joint moment) during
experimentally designed, simultaneous, independent variation of passive (joint
angle) and active (electromyography) inputs. Results: For all 32 held-out
participants (16-fold cross-validation) the ankle joint angle,
electromyography, and joint moment were estimated to accuracy 55+-8%, 57+-11%,
and 46+-9% respectively. Significance: With 2D US imaging, deep neural networks
can encode in generalizable form, the activity-length-tension state
relationship of muscle. Observation only, low power, 2D US imaging can provide
a new category of technology for non-invasive estimation of neural output,
length and tension in skeletal muscle. This proof of principle has value for
personalised muscle diagnosis in pain, injury, neurological conditions,
neuropathies, myopathies and ageing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01656</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01656</id><created>2019-07-02</created><updated>2019-07-25</updated><authors><author><keyname>Subramanian</keyname><forenames>Vaishnavi</forenames></author><author><keyname>Wang</keyname><forenames>Hongzhi</forenames></author><author><keyname>Wu</keyname><forenames>Joy T.</forenames></author><author><keyname>Wong</keyname><forenames>Ken C. L.</forenames></author><author><keyname>Sharma</keyname><forenames>Arjun</forenames></author><author><keyname>Syeda-Mahmood</keyname><forenames>Tanveer</forenames></author></authors><title>Automated Detection and Type Classification of Central Venous Catheters
  in Chest X-Rays</title><categories>eess.IV cs.CV</categories><comments>Accepted to Medical Image Computing and Computer Assisted
  Intervention (MICCAI) 2019; Data available: ML-CDS Challenge, MICCAI2019
  (http://www.mcbr-cds.org/challenge/challenge-description.html)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Central venous catheters (CVCs) are commonly used in critical care settings
for monitoring body functions and administering medications. They are often
described in radiology reports by referring to their presence, identity and
placement. In this paper, we address the problem of automatic detection of
their presence and identity through automated segmentation using deep learning
networks and classification based on their intersection with previously learned
shape priors from clinician annotations of CVCs. The results not only
outperform existing methods of catheter detection achieving 85.2% accuracy at
91.6% precision, but also enable high precision (95.2%) classification of
catheter types on a large dataset of over 10,000 chest X-rays, presenting a
robust and practical solution to this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01661</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01661</id><created>2019-07-02</created><updated>2019-07-11</updated><authors><author><keyname>Li</keyname><forenames>Xiaoxiao</forenames></author><author><keyname>Dvornek</keyname><forenames>Nicha C.</forenames></author><author><keyname>Zhou</keyname><forenames>Yuan</forenames></author><author><keyname>Zhuang</keyname><forenames>Juntang</forenames></author><author><keyname>Ventola</keyname><forenames>Pamela</forenames></author><author><keyname>Duncan</keyname><forenames>James S.</forenames></author></authors><title>Graph Neural Network for Interpreting Task-fMRI Biomarkers</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><journal-ref>Medical Image Computing and Computer-Assisted Intervention 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding the biomarkers associated with ASD is helpful for understanding the
underlying roots of the disorder and can lead to earlier diagnosis and more
targeted treatment. A promising approach to identify biomarkers is using Graph
Neural Networks (GNNs), which can be used to analyze graph structured data,
i.e. brain networks constructed by fMRI. One way to interpret important
features is through looking at how the classification probability changes if
the features are occluded or replaced. The major limitation of this approach is
that replacing values may change the distribution of the data and lead to
serious errors. Therefore, we develop a 2-stage pipeline to eliminate the need
to replace features for reliable biomarker interpretation. Specifically, we
propose an inductive GNN to embed the graphs containing different properties of
task-fMRI for identifying ASD and then discover the brain regions/sub-graphs
used as evidence for the GNN classifier. We first show GNN can achieve high
accuracy in identifying ASD. Next, we calculate the feature importance scores
using GNN and compare the interpretation ability with Random Forest. Finally,
we run with different atlases and parameters, proving the robustness of the
proposed method. The detected biomarkers reveal their association with social
behaviors. We also show the potential of discovering new informative
biomarkers. Our pipeline can be generalized to other graph feature importance
interpretation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01683</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01683</id><created>2019-07-02</created><authors><author><keyname>Nathan</keyname><forenames>Sabari</forenames></author><author><keyname>Kansal</keyname><forenames>Priya</forenames></author></authors><title>SkeletonNet: Shape Pixel to Skeleton Pixel</title><categories>cs.CV cs.CG cs.LG eess.IV</categories><comments>Published in CVPRw 2019</comments><journal-ref>IEEE/CVPRw 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Learning for Geometric Shape Understating has organized a challenge for
extracting different kinds of skeletons from the images of different objects.
This competition is organized in association with CVPR 2019. There are three
different tracks of this competition. The present manuscript describes the
method used to train the model for the dataset provided in the first track. The
first track aims to extract skeleton pixels from the shape pixels of 89
different objects. For the purpose of extracting the skeleton, a U-net model
which is comprised of an encoder-decoder structure has been used. In our
proposed architecture, unlike the plain decoder in the traditional Unet, we
have designed the decoder in the format of HED architecture, wherein we have
introduced 4 side layers and fused them to one dilation convolutional layer to
connect the broken links of the skeleton. Our proposed architecture achieved
the F1 score of 0.77 on test data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01684</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01684</id><created>2019-07-02</created><authors><author><keyname>Cherifi</keyname><forenames>Karim</forenames></author><author><keyname>Hariche</keyname><forenames>Kamel</forenames></author></authors><title>Solvents based model reduction of linear systems</title><categories>eess.SY cs.SY eess.SP</categories><comments>16 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model order reduction is the approximation of dynamical systems into
equivalent systems with smaller order. Model reduction has been studied
extensively for different types of systems. In this paper, we present two
methods for multi input multi output linear systems. These methods are based on
solvents, also called block poles. These methods are particularly suitable if
the given system is in matrix transfer function form. The first method
eliminates solvents one by one whereas, the second method can eliminate
multiple solvents at the same time. The two presented methods are implemented
in MATLAB in order to provide a systematic method for the model order reduction
of MIMO linear systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01697</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01697</id><created>2019-07-02</created><authors><author><keyname>Wu</keyname><forenames>Dongrui</forenames></author><author><keyname>Mendel</keyname><forenames>Jerry</forenames></author></authors><title>Recommendations on Designing Practical Interval Type-2 Fuzzy Systems</title><categories>cs.AI cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interval type-2 (IT2) fuzzy systems have become increasingly popular in the
last 20 years. They have demonstrated superior performance in many
applications. However, the operation of an IT2 fuzzy system is more complex
than that of its type-1 counterpart. There are many questions to be answered in
designing an IT2 fuzzy system: Should singleton or non-singleton fuzzifier be
used? How many membership functions (MFs) should be used for each input? Should
Gaussian or piecewise linear MFs be used? Should Mamdani or Takagi-Sugeno-Kang
(TSK) inference be used? Should minimum or product $t$-norm be used? Should
type-reduction be used or not? How to optimize the IT2 fuzzy system? These
questions may look overwhelming and confusing to IT2 beginners. In this paper
we recommend some representative starting choices for an IT2 fuzzy system
design, which hopefully will make IT2 fuzzy systems more accessible to IT2
fuzzy system designers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01703</identifier>
 <datestamp>2020-02-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01703</id><created>2019-07-02</created><updated>2020-02-13</updated><authors><author><keyname>Gupta</keyname><forenames>Sidharth</forenames></author><author><keyname>Gribonval</keyname><forenames>R&#xe9;mi</forenames></author><author><keyname>Daudet</keyname><forenames>Laurent</forenames></author><author><keyname>Dokmani&#x107;</keyname><forenames>Ivan</forenames></author></authors><title>Don't take it lightly: Phasing optical random projections with unknown
  operators</title><categories>cs.LG cs.ET eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we tackle the problem of recovering the phase of complex linear
measurements when only magnitude information is available and we control the
input. We are motivated by the recent development of dedicated optics-based
hardware for rapid random projections which leverages the propagation of light
in random media. A signal of interest $\mathbf{\xi} \in \mathbb{R}^N$ is mixed
by a random scattering medium to compute the projection $\mathbf{y} =
\mathbf{A} \mathbf{\xi}$, with $\mathbf{A} \in \mathbb{C}^{M \times N}$ being a
realization of a standard complex Gaussian iid random matrix. Such optics-based
matrix multiplications can be much faster and energy-efficient than their CPU
or GPU counterparts, yet two difficulties must be resolved: only the intensity
${|\mathbf{y}|}^2$ can be recorded by the camera, and the transmission matrix
$\mathbf{A}$ is unknown. We show that even without knowing $\mathbf{A}$, we can
recover the unknown phase of $\mathbf{y}$ for some equivalent transmission
matrix with the same distribution as $\mathbf{A}$. Our method is based on two
observations: first, conjugating or changing the phase of any row of
$\mathbf{A}$ does not change its distribution; and second, since we control the
input we can interfere $\mathbf{\xi}$ with arbitrary reference signals. We show
how to leverage these observations to cast the measurement phase retrieval
problem as a Euclidean distance geometry problem. We demonstrate appealing
properties of the proposed algorithm in both numerical simulations and real
hardware experiments. Not only does our algorithm accurately recover the
missing phase, but it mitigates the effects of quantization and the sensitivity
threshold, thus improving the measured magnitudes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01709</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01709</id><created>2019-07-02</created><authors><author><keyname>On</keyname><forenames>Kyoung-Woon</forenames></author><author><keyname>Kim</keyname><forenames>Eun-Sol</forenames></author><author><keyname>Heo</keyname><forenames>Yu-Jung</forenames></author><author><keyname>Zhang</keyname><forenames>Byoung-Tak</forenames></author></authors><title>Compositional Structure Learning for Sequential Video Data</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional sequential learning methods such as Recurrent Neural Networks
(RNNs) focus on interactions between consecutive inputs, i.e. first-order
Markovian dependency. However, most of sequential data, as seen with videos,
have complex temporal dependencies that imply variable-length semantic flows
and their compositions, and those are hard to be captured by conventional
methods. Here, we propose Temporal Dependency Networks (TDNs) for learning
video data by discovering these complex structures of the videos. The TDNs
represent video as a graph whose nodes and edges correspond to frames of the
video and their dependencies respectively. Via a parameterized kernel with
graph-cut and graph convolutions, the TDNs find compositional temporal
dependencies of the data in multilevel graph forms. We evaluate the proposed
method on the large-scale video dataset Youtube-8M. The experimental results
show that our model efficiently learns the complex semantic structure of video
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01717</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01717</id><created>2019-07-02</created><authors><author><keyname>Das</keyname><forenames>Deepan</forenames></author><author><keyname>Mishra</keyname><forenames>Deepak</forenames></author></authors><title>Unsupervised Anomalous Trajectory Detection for Crowded Scenes</title><categories>cs.CV eess.IV</categories><report-no>CFP1858A-USB</report-no><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  We present an improved clustering based, unsupervised anomalous trajectory
detection algorithm for crowded scenes. The proposed work is based on four
major steps, namely, extraction of trajectories from crowded scene video,
extraction of several features from these trajectories, independent mean-shift
clustering and anomaly detection. First, the trajectories of all moving objects
in a crowd are extracted using a multi feature video object tracker. These
trajectories are then transformed into a set of feature spaces. Mean shift
clustering is applied on these feature matrices to obtain distinct clusters,
while a Shannon Entropy based anomaly detector identifies corresponding
anomalies. In the final step, a voting mechanism identifies the trajectories
that exhibit anomalous characteristics. The algorithm is tested on crowd scene
videos from datasets. The videos represent various possible crowd scenes with
different motion patterns and the method performs well to detect the expected
anomalous trajectories from the scene.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01742</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01742</id><created>2019-07-03</created><authors><author><keyname>Reddy</keyname><forenames>Chandan K A</forenames></author><author><keyname>Cutler</keyname><forenames>Ross</forenames></author><author><keyname>Gehrke</keyname><forenames>Johannes</forenames></author></authors><title>Supervised Classifiers for Audio Impairments with Noisy Labels</title><categories>cs.SD cs.LG eess.AS</categories><comments>To appear in INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice-over-Internet-Protocol (VoIP) calls are prone to various speech
impairments due to environmental and network conditions resulting in bad user
experience. A reliable audio impairment classifier helps to identify the cause
for bad audio quality. The user feedback after the call can act as the ground
truth labels for training a supervised classifier on a large audio dataset.
However, the labels are noisy as most of the users lack the expertise to
precisely articulate the impairment in the perceived speech. In this paper, we
analyze the effects of massive noise in labels in training dense networks and
Convolutional Neural Networks (CNN) using engineered features, spectrograms and
raw audio samples as inputs. We demonstrate that CNN can generalize better on
the training data with a large number of noisy labels and gives remarkably
higher test performance. The classifiers were trained both on randomly
generated label noise and the label noise introduced by human errors. We also
show that training with noisy labels requires a significant increase in the
training dataset size, which is in proportion to the amount of noise in the
labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01743</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01743</id><created>2019-07-03</created><authors><author><keyname>Wang</keyname><forenames>Yi</forenames></author><author><keyname>Dou</keyname><forenames>Haoran</forenames></author><author><keyname>Hu</keyname><forenames>Xiaowei</forenames></author><author><keyname>Zhu</keyname><forenames>Lei</forenames></author><author><keyname>Yang</keyname><forenames>Xin</forenames></author><author><keyname>Xu</keyname><forenames>Ming</forenames></author><author><keyname>Qin</keyname><forenames>Jing</forenames></author><author><keyname>Heng</keyname><forenames>Pheng-Ann</forenames></author><author><keyname>Wang</keyname><forenames>Tianfu</forenames></author><author><keyname>Ni</keyname><forenames>Dong</forenames></author></authors><title>Deep Attentive Features for Prostate Segmentation in 3D Transrectal
  Ultrasound</title><categories>eess.IV cs.CV cs.LG</categories><comments>11 pages, 10 figures, 2 tables. Accepted by IEEE transactions on
  Medical Imaging</comments><doi>10.1109/TMI.2019.2913184</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic prostate segmentation in transrectal ultrasound (TRUS) images is of
essential importance for image-guided prostate interventions and treatment
planning. However, developing such automatic solutions remains very challenging
due to the missing/ambiguous boundary and inhomogeneous intensity distribution
of the prostate in TRUS, as well as the large variability in prostate shapes.
This paper develops a novel 3D deep neural network equipped with attention
modules for better prostate segmentation in TRUS by fully exploiting the
complementary information encoded in different layers of the convolutional
neural network (CNN). Our attention module utilizes the attention mechanism to
selectively leverage the multilevel features integrated from different layers
to refine the features at each individual layer, suppressing the non-prostate
noise at shallow layers of the CNN and increasing more prostate details into
features at deep layers. Experimental results on challenging 3D TRUS volumes
show that our method attains satisfactory segmentation performance. The
proposed attention mechanism is a general strategy to aggregate multi-level
deep features and has the potential to be used for other medical image
segmentation tasks. The code is publicly available at
https://github.com/wulalago/DAF3D.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01744</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01744</id><created>2019-07-03</created><authors><author><keyname>Wang</keyname><forenames>Jian</forenames></author><author><keyname>Li</keyname><forenames>Xiaoyao</forenames></author><author><keyname>Shu</keyname><forenames>Xiangbo</forenames></author><author><keyname>Li</keyname><forenames>Weiqin</forenames></author></authors><title>Region-Manipulated Fusion Networks for Pancreatitis Recognition</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This work first attempts to automatically recognize pancreatitis on CT scan
images. However, different form the traditional object recognition, such
pancreatitis recognition is challenging due to the fine-grained and non-rigid
appearance variability of the local diseased regions. To this end, we propose a
customized Region-Manipulated Fusion Networks (RMFN) to capture the key
characteristics of local lesion for pancreatitis recognition. Specifically, to
effectively highlight the imperceptible lesion regions, a novel
region-manipulated scheme in RMFN is proposed to force the lesion regions while
weaken the non-lesion regions by ceaselessly aggregating the multi-scale local
information onto feature maps. The proposed scheme can be flexibly equipped
into the existing neural networks, such as AlexNet and VGG. To evaluate the
performance of the propose method, a real CT image database about pancreatitis
is collected from hospitals \footnote{The database is available later}. And
experimental results on such database well demonstrate the effectiveness of the
proposed method for pancreatitis recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01747</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01747</id><created>2019-07-03</created><authors><author><keyname>Liu</keyname><forenames>Rui</forenames></author><author><keyname>Zhu</keyname><forenames>Xichan</forenames></author></authors><title>Statistical Characteristics of Driver Accelerating Behavior and Its
  Probability Model</title><categories>cs.RO cs.SY eess.SY</categories><comments>8 pages, 14 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The naturalistic driving data are employed to study the accelerating behavior
of the driver. Firstly, the question that whether the database is big enough to
achieve a convergent accelerating behavior of the driver is studied. The kernel
density estimation is applied to estimate the distributions of the
accelerations. The Kullback-Liebler divergence is employed to evaluate the
distinction between datasets composed of different quantity of data. The
results show that a convergent accelerating behavior of the driver can be
obtained by using the database in this study. Secondly, the bivariate
accelerating behavior is proposed. It is shown that the bivariate distribution
between longitudinal acceleration and lateral acceleration follows the dual
triangle distribution pattern. Two bivariate distribution models are proposed
to explain this phenomenon, i.e. the bivariate Normal distribution model (BNDM)
and the bivariate Pareto distribution model (BPDM). The univariate acceleration
behavior is presented to examine which model is better. It is identified that
the marginal distribution and conditional distribution of the accelerations
approximately follow the univariate Pareto distribution. Hence, the BPDM is a
more appropriate one to describe the bivariate accelerating behavior of the
driver. This reveals that the bivariate distribution pattern will never reach a
circle-shaped region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01749</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01749</id><created>2019-07-03</created><authors><author><keyname>Cai</keyname><forenames>Zexin</forenames></author><author><keyname>Yang</keyname><forenames>Yaogen</forenames></author><author><keyname>Zhang</keyname><forenames>Chuxiong</forenames></author><author><keyname>Qin</keyname><forenames>Xiaoyi</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>Polyphone Disambiguation for Mandarin Chinese Using Conditional Neural
  Network with Multi-level Embedding Features</title><categories>cs.CL eess.AS stat.ML</categories><comments>5 pages, 1 figure, 2 tables, submit to INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a conditional neural network architecture for Mandarin
Chinese polyphone disambiguation. The system is composed of a bidirectional
recurrent neural network component acting as a sentence encoder to accumulate
the context correlations, followed by a prediction network that maps the
polyphonic character embeddings along with the conditions to corresponding
pronunciations. We obtain the word-level condition from a pre-trained
word-to-vector lookup table. One goal of polyphone disambiguation is to address
the homograph problem existing in the front-end processing of Mandarin Chinese
text-to-speech system. Our system achieves an accuracy of 94.69\% on a publicly
available polyphonic character dataset. To further validate our choices on the
conditional feature, we investigate polyphone disambiguation systems with
multi-level conditions respectively. The experimental results show that both
the sentence-level and the word-level conditional embedding features are able
to attain good performance for Mandarin Chinese polyphone disambiguation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01759</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01759</id><created>2019-07-03</created><authors><author><keyname>Fasogbon</keyname><forenames>Peter</forenames></author><author><keyname>Aksu</keyname><forenames>Emre</forenames></author></authors><title>Calibration of fisheye camera using entrance pupil</title><categories>eess.IV cs.CV</categories><comments>5 pages, 4 figures, Accepted for publication at ICIP 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Most conventional camera calibration algorithms assume that the imaging
device has a Single Viewpoint (SVP). This is not necessarily true for special
imaging device such as fisheye lenses. As a consequence, the intrinsic camera
calibration result is not always reliable. In this paper, we propose a new
formation model that tends to relax this assumption so that a Non-Single
Viewpoint (NSVP) system is corrected to always maintain a SVP, by taking into
account the variation of the Entrance Pupil (EP) using thin lens modeling. In
addition, we present a calibration procedure for the image formation to
estimate these EP parameters using non linear optimization procedure with
bundle adjustment. From experiments, we are able to obtain slightly better
re-projection error than traditional methods, and the camera parameters are
better estimated. The proposed calibration procedure is simple and can easily
be integrated to any other thin lens image formation model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01803</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01803</id><created>2019-07-03</created><authors><author><keyname>Koutini</keyname><forenames>Khaled</forenames></author><author><keyname>Eghbal-zadeh</keyname><forenames>Hamid</forenames></author><author><keyname>Dorfer</keyname><forenames>Matthias</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>The Receptive Field as a Regularizer in Deep Convolutional Neural
  Networks for Acoustic Scene Classification</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>IEEE EUSIPCO 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Networks (CNNs) have had great success in many machine
vision as well as machine audition tasks. Many image recognition network
architectures have consequently been adapted for audio processing tasks.
However, despite some successes, the performance of many of these did not
translate from the image to the audio domain. For example, very deep
architectures such as ResNet and DenseNet, which significantly outperform VGG
in image recognition, do not perform better in audio processing tasks such as
Acoustic Scene Classification (ASC). In this paper, we investigate the reasons
why such powerful architectures perform worse in ASC compared to simpler models
(e.g., VGG). To this end, we analyse the receptive field (RF) of these CNNs and
demonstrate the importance of the RF to the generalization capability of the
models. Using our receptive field analysis, we adapt both ResNet and DenseNet,
achieving state-of-the-art performance and eventually outperforming the
VGG-based models. We introduce systematic ways of adapting the RF in CNNs, and
present results on three data sets that show how changing the RF over the time
and frequency dimensions affects a model's performance. Our experimental
results show that very small or very large RFs can cause performance
degradation, but deep models can be made to generalize well by carefully
choosing an appropriate RF size within a certain range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01807</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01807</id><created>2019-07-03</created><authors><author><keyname>Zhang</keyname><forenames>Xinyue</forenames></author><author><keyname>Song</keyname><forenames>Jiahao</forenames></author><author><keyname>Wang</keyname><forenames>Yuan</forenames></author><author><keyname>Zhang</keyname><forenames>Yawen</forenames></author><author><keyname>Zhang</keyname><forenames>Zuodong</forenames></author><author><keyname>Wang</keyname><forenames>Runsheng</forenames></author><author><keyname>Huang</keyname><forenames>Ru</forenames></author></authors><title>An Energy-Efficient Mixed-Signal Parallel Multiply-Accumulate (MAC)
  Engine Based on Stochastic Computing</title><categories>eess.SP</categories><comments>6 pages,6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNN) have achieved excellent performance on
various tasks, but deploying CNN to edge is constrained by the high energy
consumption of convolution operation. Stochastic computing (SC) is an
attractive paradigm which performs arithmetic operations with simple logic
gates and low hardware cost. This paper presents an energy-efficient
mixed-signal multiply-accumulate (MAC) engine based on SC. A parallel
architecture is adopted in this work to solve the latency problem of SC. The
simulation results show that the overall energy consumption of our design is
5.03pJ per 26-input MAC operation under 28nm CMOS technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01813</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01813</id><created>2019-07-03</created><authors><author><keyname>Slizovskaia</keyname><forenames>Olga</forenames></author><author><keyname>G&#xf3;mez</keyname><forenames>Emilia</forenames></author><author><keyname>Haro</keyname><forenames>Gloria</forenames></author></authors><title>A Case Study of Deep-Learned Activations via Hand-Crafted Audio Features</title><categories>cs.SD cs.LG eess.AS</categories><comments>The 2018 Joint Workshop on Machine Learning for Music, The Federated
  Artificial Intelligence Meeting (FAIM), Joint workshop program of ICML,
  IJCAI/ECAI, and AAMAS, Stockholm, Sweden, Saturday, July 14th, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The explainability of Convolutional Neural Networks (CNNs) is a particularly
challenging task in all areas of application, and it is notably
under-researched in music and audio domain. In this paper, we approach
explainability by exploiting the knowledge we have on hand-crafted audio
features. Our study focuses on a well-defined MIR task, the recognition of
musical instruments from user-generated music recordings. We compute the
similarity between a set of traditional audio features and representations
learned by CNNs. We also propose a technique for measuring the similarity
between activation maps and audio features which typically presented in the
form of a matrix, such as chromagrams or spectrograms. We observe that some
neurons' activations correspond to well-known classical audio features. In
particular, for shallow layers, we found similarities between activations and
harmonic and percussive components of the spectrum. For deeper layers, we
compare chromagrams with high-level activation maps as well as loudness and
onset rate with deep-learned embeddings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01818</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01818</id><created>2019-07-03</created><authors><author><keyname>Zhao</keyname><forenames>Hui</forenames></author><author><keyname>Liu</keyname><forenames>Yuanwei</forenames></author><author><keyname>Sultan-Salem</keyname><forenames>Ahemd</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>A Simple Evaluation for the Secrecy Outage Probability Over
  Generalized-K Fading Channels</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 3 figures</comments><doi>10.1109/LCOMM.2019.2926360</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple approximation for the secrecy outage probability (SOP) over
generalized-K fading channels is developed. This approximation becomes tighter
as the average signal-to-noise ratio (SNR) of the wiretap channel decreases.
Based on this simple expression, we also analyze the asymptotic SOP in the high
SNR region of the main channel. Besides simplifying the SOP expression
significantly, this asymptotic SOP expression reveals the secrecy diversity
order in a general case. Numerical results demonstrate the high accuracy of our
proposed approximation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01821</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01821</id><created>2019-07-03</created><authors><author><keyname>M&#xe4;rtens</keyname><forenames>Marcus</forenames></author><author><keyname>Izzo</keyname><forenames>Dario</forenames></author><author><keyname>Krzic</keyname><forenames>Andrej</forenames></author><author><keyname>Cox</keyname><forenames>Dani&#xeb;l</forenames></author></authors><title>Super-Resolution of PROBA-V Images Using Convolutional Neural Networks</title><categories>cs.CV eess.IV</categories><comments>To appear in Special Issue on Applications of Artificial Intelligence
  in Aerospace Engineering in the Journal &quot;Astrodynamics&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ESA's PROBA-V Earth observation satellite enables us to monitor our planet at
a large scale, studying the interaction between vegetation and climate and
provides guidance for important decisions on our common global future. However,
the interval at which high resolution images are recorded spans over several
days, in contrast to the availability of lower resolution images which is often
daily. We collect an extensive dataset of both, high and low resolution images
taken by PROBA-V instruments during monthly periods to investigate Multi Image
Super-resolution, a technique to merge several low resolution images to one
image of higher quality. We propose a convolutional neural network that is able
to cope with changes in illumination, cloud coverage and landscape features
which are challenges introduced by the fact that the different images are taken
over successive satellite passages over the same region. Given a bicubic
upscaling of low resolution images taken under optimal conditions, we find the
Peak Signal to Noise Ratio of the reconstructed image of the network to be
higher for a large majority of different scenes. This shows that applied
machine learning has the potential to enhance large amounts of previously
collected earth observation data during multiple satellite passes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01831</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01831</id><created>2019-07-03</created><updated>2019-10-19</updated><authors><author><keyname>Xu</keyname><forenames>Yixin</forenames></author><author><keyname>Qi</keyname><forenames>Jianzhong</forenames></author><author><keyname>Borovica-Gajic</keyname><forenames>Renata</forenames></author><author><keyname>Kulik</keyname><forenames>Lars</forenames></author></authors><title>GeoPrune: Efficiently Finding Shareable Vehicles Based on Geometric
  Properties</title><categories>cs.DB eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On-demand ride-sharing is rapidly growing.Matching trip requests to vehicles
efficiently is critical for the service quality of ride-sharing. To match trip
requests with vehicles, a prune-and-select scheme is commonly used. The pruning
stage identifies feasible vehicles that can satisfy the trip constraints (e.g.,
trip time). The selection stage selects the optimal one(s) from the feasible
vehicles. The pruning stage is crucial to reduce the complexity of the
selection stage and to achieve efficient matching. We propose an effective and
efficient pruning algorithm called GeoPrune. GeoPrune represents the time
constraints of trip requests using circles and ellipses, which can be computed
and updated efficiently. Experiments on real-world datasets show that GeoPrune
reduces the number of vehicle candidates in nearly all cases by an order of
magnitude and the update cost by two to three orders of magnitude compared to
the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01841</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01841</id><created>2019-07-03</created><authors><author><keyname>Dogan</keyname><forenames>Yahya</forenames></author><author><keyname>Keles</keyname><forenames>Hacer Yalim</forenames></author></authors><title>Semi-supervised Image Attribute Editing using Generative Adversarial
  Networks</title><categories>cs.CV eess.IV</categories><comments>This paper is under consideration at Neurocomputing Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image attribute editing is a challenging problem that has been recently
studied by many researchers using generative networks. The challenge is in the
manipulation of selected attributes of images while preserving the other
details. The method to achieve this goal is to find an accurate latent vector
representation of an image and a direction corresponding to the attribute.
Almost all the works in the literature use labeled datasets in a supervised
setting for this purpose. In this study, we introduce an architecture called
Cyclic Reverse Generator (CRG), which allows learning the inverse function of
the generator accurately via an encoder in an unsupervised setting by utilizing
cyclic cost minimization. Attribute editing is then performed using the CRG
models for finding desired attribute representations in the latent space. In
this work, we use two arbitrary reference images, with and without desired
attributes, to compute an attribute direction for editing. We show that the
proposed approach performs better in terms of image reconstruction compared to
the existing end-to-end generative models both quantitatively and
qualitatively. We demonstrate state-of-the-art results on both real images and
generated images in MNIST and CelebA datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01847</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01847</id><created>2019-07-03</created><authors><author><keyname>Li</keyname><forenames>Wei</forenames></author><author><keyname>Yuan</keyname><forenames>Zehuan</forenames></author><author><keyname>Guo</keyname><forenames>Dashan</forenames></author><author><keyname>Huang</keyname><forenames>Lei</forenames></author><author><keyname>Fang</keyname><forenames>Xiangzhong</forenames></author><author><keyname>Wang</keyname><forenames>Changhu</forenames></author></authors><title>Deformable Tube Network for Action Detection in Videos</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of spatio-temporal action detection in videos.
Existing methods commonly either ignore temporal context in action recognition
and localization, or lack the modelling of flexible shapes of action tubes. In
this paper, we propose a two-stage action detector called Deformable Tube
Network (DTN), which is composed of a Deformation Tube Proposal Network (DTPN)
and a Deformable Tube Recognition Network (DTRN) similar to the Faster R-CNN
architecture. In DTPN, a fast proposal linking algorithm (FTL) is introduced to
connect region proposals across frames to generate multiple deformable action
tube proposals. To perform action detection, we design a 3D convolution network
with skip connections for tube classification and regression. Modelling action
proposals as deformable tubes explicitly considers the shape of action tubes
compared to 3D cuboids. Moreover, 3D convolution based recognition network can
learn temporal dynamics sufficiently for action detection. Our experimental
results show that we significantly outperform the methods with 3D cuboids and
obtain the state-of-the-art results on both UCF-Sports and AVA datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01848</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01848</id><created>2019-07-03</created><authors><author><keyname>Vlaski</keyname><forenames>Stefan</forenames></author><author><keyname>Sayed</keyname><forenames>Ali H.</forenames></author></authors><title>Distributed Learning in Non-Convex Environments -- Part I: Agreement at
  a Linear Rate</title><categories>math.OC cs.MA eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Driven by the need to solve increasingly complex optimization problems in
signal processing and machine learning, there has been increasing interest in
understanding the behavior of gradient-descent algorithms in non-convex
environments. Most available works on distributed non-convex optimization
problems focus on the deterministic setting where exact gradients are available
at each agent. In this work and its Part II, we consider stochastic cost
functions, where exact gradients are replaced by stochastic approximations and
the resulting gradient noise persistently seeps into the dynamics of the
algorithm. We establish that the diffusion learning strategy continues to yield
meaningful estimates non-convex scenarios in the sense that the iterates by the
individual agents will cluster in a small region around the network centroid.
We use this insight to motivate a short-term model for network evolution over a
finite-horizon. In Part II [2] of this work, we leverage this model to
establish descent of the diffusion strategy through saddle points in O(1/$\mu$)
steps and the return of approximately second-order stationary points in a
polynomial number of iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01849</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01849</id><created>2019-07-03</created><authors><author><keyname>Vlaski</keyname><forenames>Stefan</forenames></author><author><keyname>Sayed</keyname><forenames>Ali H.</forenames></author></authors><title>Distributed Learning in Non-Convex Environments -- Part II: Polynomial
  Escape from Saddle-Points</title><categories>cs.MA cs.LG eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The diffusion strategy for distributed learning from streaming data employs
local stochastic gradient updates along with exchange of iterates over
neighborhoods. In Part I [2] of this work we established that agents cluster
around a network centroid and proceeded to study the dynamics of this point. We
established expected descent in non-convex environments in the large-gradient
regime and introduced a short-term model to examine the dynamics over
finite-time horizons. Using this model, we establish in this work that the
diffusion strategy is able to escape from strict saddle-points in O(1/$\mu$)
iterations; it is also able to return approximately second-order stationary
points in a polynomial number of iterations. Relative to prior works on the
polynomial escape from saddle-points, most of which focus on centralized
perturbed or stochastic gradient descent, our approach requires less
restrictive conditions on the gradient noise process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01861</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01861</id><created>2019-07-03</created><authors><author><keyname>Zobiri</keyname><forenames>Fairouz</forenames></author><author><keyname>Meslem</keyname><forenames>Nacim</forenames></author><author><keyname>Bidegaray-Fesquet</keyname><forenames>Brigitte</forenames></author></authors><title>Self-triggered stabilizing controllers for linear continuous-time
  systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-triggered control is an improvement on event-triggered control methods.
Unlike the latter, self-triggered control does not require monitoring the
behavior of the system constantly. Instead, self-triggered algorithms predict
the events at which the control law has to be updated before they happen,
relying on system model and past information.\\ In this work, we present a
self-triggered version of an event-triggered control method in which events are
generated when a pseudo-Lyapunov function (PLF) associated with the system
increases up to a certain limit. This approach has been shown to considerably
decrease the communications between the controller and the plant, while
maintaining system stability. To predict the intersections between the PLF and
the upper limit, we use a simple and fast root-finding algorithm. The algorithm
mixes the global convergence properties of the bisection and the fast
convergence properties of the Newton-Raphson method. \\ Moreover, to ensure the
convergence of the method, the initial iterate of the algorithm is found
through a minimization algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01865</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01865</id><created>2019-07-03</created><authors><author><keyname>Bashar</keyname><forenames>Manijeh</forenames></author><author><keyname>Burr</keyname><forenames>Alister G.</forenames></author><author><keyname>Haneda</keyname><forenames>Katsuyuki</forenames></author><author><keyname>Cumanan</keyname><forenames>Kanapathippillai</forenames></author><author><keyname>Molu</keyname><forenames>Mehdi M.</forenames></author><author><keyname>Khalily</keyname><forenames>Mohsen</forenames></author><author><keyname>Xiao</keyname><forenames>Pei</forenames></author></authors><title>Evaluation of Low Complexity Massive MIMO Techniques Under Realistic
  Channel Conditions</title><categories>eess.SP cs.IT math.IT</categories><comments>IEEE TVT 2019, 7 pages, 4 figures,</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A low complexity massive multiple-input multiple-output (MIMO) technique is
studied with a geometry-based stochastic channel model, called COST 2100 model.
We propose to exploit the discrete-time Fourier transform of the antenna
correlation function to perform user scheduling. The proposed algorithm relies
on a trade off between the number of occupied bins of the eigenvalue spectrum
of the channel covariance matrix for each user and spectral overlap among the
selected users. We next show that linear precoding design can be performed
based only on the channel correlation matrix. The proposed scheme exploits the
angular bins of the eigenvalue spectrum of the channel covariance matrix to
build up an &quot;approximate eigenchannels&quot; for the users. We investigate the
reduction of average system throughput with no channel state information at the
transmitter (CSIT). Analysis and numerical results show that while the
throughput slightly decreases due to the absence of CSIT, the complexity of the
system is reduced significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01870</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01870</id><created>2019-07-03</created><authors><author><keyname>Wimmer</keyname><forenames>Wilhelm</forenames></author><author><keyname>Vandersteen</keyname><forenames>Clair</forenames></author><author><keyname>Guevara</keyname><forenames>Nicolas</forenames></author><author><keyname>Caversaccio</keyname><forenames>Marco</forenames></author><author><keyname>Delingette</keyname><forenames>Herv&#xe9;</forenames></author></authors><title>Robust Cochlear Modiolar Axis Detection in CT</title><categories>eess.IV cs.CV</categories><comments>Accepted for MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cochlea, the auditory part of the inner ear, is a spiral-shaped organ
with large morphological variability. An individualized assessment of its shape
is essential for clinical applications related to tonotopy and cochlear
implantation. To unambiguously reference morphological parameters, reliable
recognition of the cochlear modiolar axis in computed tomography (CT) images is
required. The conventional method introduces measurement uncertainties, as it
is based on manually selected and difficult to identify landmarks. Herein, we
present an algorithm for robust modiolar axis detection in clinical CT images.
We define the modiolar axis as the rotation component of the kinematic spiral
motion inherent in the cochlear shape. For surface fitting, we use a compact
shape representation in a 7-dimensional kinematic parameter space based on
extended Pl\&quot;ucker coordinates. It is the first time such a kinematic
representation is used for shape analysis in medical images. Robust surface
fitting is achieved with an adapted approximate maximum likelihood method
assuming a Student-t distribution, enabling axis detection even in partially
available surface data. We verify the algorithm performance on a synthetic data
set with cochlear surface subsets. In addition, we perform an experimental
study with four experts in 23 human cochlea CT data sets to compare the
automated detection with the manually found axes. Axes found from co-registered
high resolution micro-CT scans are used for reference. Our experiments show
that the algorithm reduces the alignment error providing more reliable modiolar
axis detection for clinical and research applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01871</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01871</id><created>2019-07-03</created><authors><author><keyname>Juurakko</keyname><forenames>Juliaana</forenames></author><author><keyname>Purisha</keyname><forenames>Zenith</forenames></author><author><keyname>S&#xe4;rkk&#xe4;</keyname><forenames>Simo</forenames></author></authors><title>CT Data of a Pen-Spring: Application to Under-Sampled Dynamic X-ray
  Tomography</title><categories>physics.med-ph eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the documentation of Computed Tomography (CT) data of a pen-spring.
The open data set is available at
https://zenodo.org/record/3266936#.XRyMdCZS9oA and can be freely used for
scientific purposes with appropriate references to the data and to this
document in arxiv.org. The provided data set includes the X-ray sinograms ({\tt
finalSino}) of a single 2D slice from a different height of the spring. The
{\tt finalSino} was obtained from a measured 10-projection or 100-projection
{\tt sinogram} using fan-beam geometry by down-sampling and taking logarithms.
The data set includes also those original measured {\tt sinogram}s and
corresponding measurement matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01881</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01881</id><created>2019-07-03</created><authors><author><keyname>Amari</keyname><forenames>Abdelkerim</forenames></author><author><keyname>Goossens</keyname><forenames>Sebastiaan</forenames></author><author><keyname>Gultekin</keyname><forenames>Yunus Can</forenames></author><author><keyname>Vassilieva</keyname><forenames>Olga</forenames></author><author><keyname>Kim</keyname><forenames>Inwoong</forenames></author><author><keyname>Ikeuchi</keyname><forenames>Tadashi</forenames></author><author><keyname>Okonkwo</keyname><forenames>Chigo</forenames></author><author><keyname>Willems</keyname><forenames>Frans M. J.</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author></authors><title>Enumerative Sphere Shaping for Rate Adaptation and Reach Increase in WDM
  Transmission Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>4 Pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of enumerative sphere shaping (ESS), constant composition
distribution matching (CCDM), and uniform signalling are compared at the same
forward error correction rate. ESS is shown to offer a reach increase of
approximately 10% and 22% compared to CCDM and uniform signalling,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01886</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01886</id><created>2019-06-18</created><authors><author><keyname>Liu</keyname><forenames>Jia</forenames></author><author><keyname>Ke</keyname><forenames>Yan</forenames></author><author><keyname>Lei</keyname><forenames>Yu</forenames></author><author><keyname>Zhang</keyname><forenames>Zhuo</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author><author><keyname>Luo</keyname><forenames>Peng</forenames></author><author><keyname>Zhang</keyname><forenames>Minqing</forenames></author><author><keyname>Yang</keyname><forenames>Xiaoyuan</forenames></author></authors><title>Recent Advances of Image Steganography with Generative Adversarial
  Networks</title><categories>cs.CR cs.MM eess.IV</categories><comments>39 pages, 26 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past few years, the Generative Adversarial Network (GAN) which
proposed in 2014 has achieved great success. GAN has achieved many research
results in the field of computer vision and natural language processing. Image
steganography is dedicated to hiding secret messages in digital images, and has
achieved the purpose of covert communication. Recently, research on image
steganography has demonstrated great potential for using GAN and neural
networks. In this paper we review different strategies for steganography such
as cover modification, cover selection and cover synthesis by GANs, and discuss
the characteristics of these methods as well as evaluation metrics and provide
some possible future research directions in image steganography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01891</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01891</id><created>2019-06-27</created><authors><author><keyname>Chillar&#xf3;n</keyname><forenames>M&#xf3;nica</forenames></author><author><keyname>Quintana-Ort&#xed;</keyname><forenames>Gregorio</forenames></author><author><keyname>Vidal</keyname><forenames>Vicente</forenames></author><author><keyname>Verd&#xfa;</keyname><forenames>Gumersindo</forenames></author></authors><title>Computed tomography medical image reconstruction on affordable equipment
  by using out-of-core techniques</title><categories>eess.IV cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As Computed Tomography (CT) scans are an essential medical test, many
techniques have been proposed to reconstruct high-quality images using a
smaller amount of radiation. One approach is to employ algebraic factorization
methods to reconstruct the images, using fewer views than the traditional
analytical methods. However, their main drawback is the high computational cost
and hence the time needed to obtain the images, which is critical in the daily
clinical practice. For this reason, faster methods for solving this problem are
required. In this paper, we propose a new reconstruction method based on the QR
factorization that is very efficient on affordable equipment (standard
multicore processors and standard Solid-State Drives) by using out-of-core
techniques. Combining both affordable hardware and the new software, we can
boost the performance of the reconstructions and implement a reliable and
competitive method that reconstructs high-quality CT images quickly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01898</identifier>
 <datestamp>2020-02-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01898</id><created>2019-07-01</created><updated>2019-09-26</updated><authors><author><keyname>Moscovich</keyname><forenames>Amit</forenames></author><author><keyname>Halevi</keyname><forenames>Amit</forenames></author><author><keyname>And&#xe9;n</keyname><forenames>Joakim</forenames></author><author><keyname>Singer</keyname><forenames>Amit</forenames></author></authors><title>Cryo-EM reconstruction of continuous heterogeneity by Laplacian spectral
  volumes</title><categories>eess.IV cs.LG stat.AP stat.ML</categories><comments>33 pages, 10 figures</comments><msc-class>62P10, 65R32, 94A08</msc-class><acm-class>I.4.5; I.5.4; J.3</acm-class><journal-ref>Inverse Problems, 36(2), 024003 (2020)</journal-ref><doi>10.1088/1361-6420/ab4f55</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-particle electron cryomicroscopy is an essential tool for
high-resolution 3D reconstruction of proteins and other biological
macromolecules. An important challenge in cryo-EM is the reconstruction of
non-rigid molecules with parts that move and deform. Traditional reconstruction
methods fail in these cases, resulting in smeared reconstructions of the moving
parts. This poses a major obstacle for structural biologists, who need
high-resolution reconstructions of entire macromolecules, moving parts
included. To address this challenge, we present a new method for the
reconstruction of macromolecules exhibiting continuous heterogeneity. The
proposed method uses projection images from multiple viewing directions to
construct a graph Laplacian through which the manifold of three-dimensional
conformations is analyzed. The 3D molecular structures are then expanded in a
basis of Laplacian eigenvectors, using a novel generalized tomographic
reconstruction algorithm to compute the expansion coefficients. These
coefficients, which we name spectral volumes, provide a high-resolution
visualization of the molecular dynamics. We provide a theoretical analysis and
evaluate the method empirically on several simulated data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01913</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01913</id><created>2019-07-02</created><authors><author><keyname>Attar</keyname><forenames>Rahman</forenames></author><author><keyname>Pereanez</keyname><forenames>Marco</forenames></author><author><keyname>Bowles</keyname><forenames>Christopher</forenames></author><author><keyname>Piechnik</keyname><forenames>Stefan K.</forenames></author><author><keyname>Neubauer</keyname><forenames>Stefan</forenames></author><author><keyname>Petersen</keyname><forenames>Steffen E.</forenames></author><author><keyname>Frangi</keyname><forenames>Alejandro F.</forenames></author></authors><title>3D Cardiac Shape Prediction with Deep Neural Networks: Simultaneous Use
  of Images and Patient Metadata</title><categories>eess.IV cs.LG stat.ML</categories><comments>Accepted for publication in MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large prospective epidemiological studies acquire cardiovascular magnetic
resonance (CMR) images for pre-symptomatic populations and follow these over
time. To support this approach, fully automatic large-scale 3D analysis is
essential. In this work, we propose a novel deep neural network using both CMR
images and patient metadata to directly predict cardiac shape parameters. The
proposed method uses the promising ability of statistical shape models to
simplify shape complexity and variability together with the advantages of
convolutional neural networks for the extraction of solid visual features. To
the best of our knowledge, this is the first work that uses such an approach
for 3D cardiac shape prediction. We validated our proposed CMR analytics method
against a reference cohort containing 500 3D shapes of the cardiac ventricles.
Our results show broadly significant agreement with the reference shapes in
terms of the estimated volume of the cardiac ventricles, myocardial mass, 3D
Dice, and mean and Hausdorff distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01914</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01914</id><created>2019-07-02</created><authors><author><keyname>Karaulov</keyname><forenames>Ievgen</forenames></author><author><keyname>Tkanov</keyname><forenames>Dmytro</forenames></author></authors><title>Attention model for articulatory features detection</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>Interspeech 2019, 5 pages, 2 figures</comments><msc-class>68T10</msc-class><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Articulatory distinctive features, as well as phonetic transcription, play
important role in speech-related tasks: computer-assisted pronunciation
training, text-to-speech conversion (TTS), studying speech production
mechanisms, speech recognition for low-resourced languages. End-to-end
approaches to speech-related tasks got a lot of traction in recent years. We
apply Listen, Attend and Spell~(LAS)~\cite{Chan-LAS2016} architecture to phones
recognition on a small small training set, like TIMIT~\cite{TIMIT-1992}. Also,
we introduce a novel decoding technique that allows to train manners and places
of articulation detectors end-to-end using attention models. We also explore
joint phones recognition and articulatory features detection in multitask
learning setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01919</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01919</id><created>2019-07-02</created><updated>2019-07-05</updated><authors><author><keyname>Wang</keyname><forenames>Jen-Hung</forenames></author><author><keyname>Lu</keyname><forenames>Ping-En</forenames></author><author><keyname>Chang</keyname><forenames>Cheng-Shang</forenames></author><author><keyname>Lee</keyname><forenames>Duan-Shin</forenames></author></authors><title>A Reinforcement Learning Approach for the Multichannel Rendezvous
  Problem</title><categories>eess.SP cs.LG</categories><comments>5 pages, 9 figures. arXiv admin note: text overlap with
  arXiv:1906.10424</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the multichannel rendezvous problem in cognitive
radio networks (CRNs) where the probability that two users hopping on the same
channel have a successful rendezvous is a function of channel states. The
channel states are modelled by two-state Markov chains that have a good state
and a bad state. These channel states are not observable by the users. For such
a multichannel rendezvous problem, we are interested in finding the optimal
policy to minimize the expected time-to-rendezvous (ETTR) among the class of
{\em dynamic blind rendezvous policies}, i.e., at the $t^{th}$ time slot each
user selects channel $i$ independently with probability $p_i(t)$, $i=1,2,
\ldots, N$. By formulating such a multichannel rendezvous problem as an
adversarial bandit problem, we propose using a reinforcement learning approach
to learn the channel selection probabilities $p_i(t)$, $i=1,2, \ldots, N$. Our
experimental results show that the reinforcement learning approach is very
effective and yields comparable ETTRs when comparing to various approximation
policies in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01930</identifier>
 <datestamp>2020-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01930</id><created>2019-07-02</created><updated>2020-02-10</updated><authors><author><keyname>Hosseinalipour</keyname><forenames>Seyyedali</forenames></author><author><keyname>Rahmati</keyname><forenames>Ali</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author></authors><title>Interference Avoidance Position Planning in Dual-hop and Multi-hop UAV
  Relay Networks</title><categories>cs.NI cs.SY eess.SY</categories><comments>16 pages, 13 figures. arXiv admin note: substantial text overlap with
  arXiv:1903.01428</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider unmanned aerial vehicle (UAV)-assisted wireless communication
employing UAVs as relay nodes to increase the throughput between a pair of
transmitter and receiver. We focus on developing effective methods to position
the UAV(s) in the sky in the presence of interference in the environment, the
existence of which makes the problem non-trivial and our methodology different
from the current art. We study the optimal position planning, which aims to
maximize the (average) signal-to-interference-ratio (SIR) of the system, in the
presence of: i) one major source of interference, ii) stochastic interference.
For each scenario, we first consider utilizing a single UAV in the dual-hop
relay mode and determine its optimal position. Afterward, multiple UAVs in the
multi-hop relay mode are considered, for which we investigate two novel
problems concerned with determining the optimal number of required UAVs and
developing an optimal fully distributed position alignment method.
Subsequently, we propose a cost-effective method that simultaneously minimizes
the number of UAVs and determines their optimal positions to guarantee a
certain (average) SIR of the system. Alternatively, for a given number of UAVs,
we develop a fully distributed placement algorithm along with its performance
guarantee. Numerical simulations are provided to evaluate the performance of
our proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01953</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01953</id><created>2019-07-02</created><authors><author><keyname>Thomas</keyname><forenames>Armin W.</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Klaus-Robert</forenames></author><author><keyname>Samek</keyname><forenames>Wojciech</forenames></author></authors><title>Deep Transfer Learning For Whole-Brain fMRI Analyses</title><categories>eess.IV cs.LG stat.ML</categories><comments>8 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The application of deep learning (DL) models to the decoding of cognitive
states from whole-brain functional Magnetic Resonance Imaging (fMRI) data is
often hindered by the small sample size and high dimensionality of these
datasets. Especially, in clinical settings, where patient data are scarce. In
this work, we demonstrate that transfer learning represents a solution to this
problem. Particularly, we show that a DL model, which has been previously
trained on a large openly available fMRI dataset of the Human Connectome
Project, outperforms a model variant with the same architecture, but which is
trained from scratch, when both are applied to the data of a new, unrelated
fMRI task. Even further, the pre-trained DL model variant is already able to
correctly decode 67.51% of the cognitive states from a test dataset with 100
individuals, when fine-tuned on a dataset of the size of only three subjects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01956</identifier>
 <datestamp>2019-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01956</id><created>2019-07-03</created><authors><author><keyname>Tang</keyname><forenames>Wankai</forenames></author><author><keyname>Chen</keyname><forenames>Ming Zheng</forenames></author><author><keyname>Dai</keyname><forenames>Jun Yan</forenames></author><author><keyname>Zeng</keyname><forenames>Yong</forenames></author><author><keyname>Zhao</keyname><forenames>Xinsheng</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Cheng</keyname><forenames>Qiang</forenames></author><author><keyname>Cui</keyname><forenames>Tie Jun</forenames></author></authors><title>Wireless Communications with Programmable Metasurface: New Paradigms,
  Opportunities, and Challenges on Transceiver Design</title><categories>eess.SP cs.IT math.IT</categories><comments>15 pages, 5 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many emerging technologies, such as ultra-massive multiple-input
multiple-output (UM-MIMO), terahertz (THz) communications are under active
discussion as promising technologies to support the extremely high access rate
and superior network capacity in the future sixth-generation (6G) mobile
communication systems. However, such technologies are still facing many
challenges for practical implementation. In particular, UM-MIMO and THz
communication require extremely large number of radio frequency (RF) chains,
and hence suffering from prohibitive hardware cost and complexity. In this
article, we introduce a new paradigm to address the above issues, namely
wireless communication enabled by programmable metasurfaces, by exploiting the
powerful capability of metasurfaces in manipulating electromagnetic waves. We
will first introduce the basic concept of programmable metasurfaces, followed
by the promising paradigm shift in future wireless communication systems
enabled by programmable metasurfaces. In particular, we propose two prospective
paradigms of applying programmable metasurfaces in wireless transceivers:
namely RF chain-free transmitter and space-down-conversion receiver, which both
have great potential to simplify the architecture and reduce the hardware cost
of future wireless transceivers. Furthermore, we present the design
architectures, preliminary experimental results and main advantages of these
new paradigms and discuss their potential opportunities and challenges toward
ultra-massive 6G communications with low hardware complexity, low cost, and
high energy efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01957</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01957</id><created>2019-07-03</created><updated>2019-07-12</updated><authors><author><keyname>Do</keyname><forenames>Cong-Thanh</forenames></author></authors><title>End-to-End Speech Recognition with High-Frame-Rate Features Extraction</title><categories>eess.AS cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art end-to-end automatic speech recognition (ASR) extracts
acoustic features from input speech signal every 10 ms which corresponds to a
frame rate of 100 frames/second. In this report, we investigate the use of
high-frame-rate features extraction in end-to-end ASR. High frame rates of 200
and 400 frames/second are used in the features extraction and provide
additional information for end-to-end ASR. The effectiveness of high-frame-rate
features extraction is evaluated independently and in combination with speed
perturbation based data augmentation. Experiments performed on two speech
corpora, Wall Street Journal (WSJ) and CHiME-5, show that using high-frame-rate
features extraction yields improved performance for end-to-end ASR, both
independently and in combination with speed perturbation. On WSJ corpus, the
relative reduction of word error rate (WER) yielded by high-frame-rate features
extraction independently and in combination with speed perturbation are up to
21.3% and 24.1%, respectively. On CHiME-5 corpus, the corresponding relative
WER reductions are up to 2.8% and 7.9%, respectively, on the test data recorded
by microphone arrays and up to 11.8% and 21.2%, respectively, on the test data
recorded by binaural microphones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01978</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01978</id><created>2019-07-03</created><authors><author><keyname>Hu</keyname><forenames>Hsu-Chieh</forenames></author><author><keyname>Smith</keyname><forenames>Stephen F.</forenames></author></authors><title>Using Bi-Directional Information Exchange to Improve Decentralized
  Schedule-Driven Traffic Control</title><categories>cs.AI cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work in decentralized, schedule-driven traffic control has
demonstrated the ability to improve the efficiency of traffic flow in complex
urban road networks. In this approach, a scheduling agent is associated with
each intersection. Each agent senses the traffic approaching its intersection
and in real-time constructs a schedule that minimizes the cumulative wait time
of vehicles approaching the intersection over the current look-ahead horizon.
In order to achieve network level coordination in a scalable manner, scheduling
agents communicate only with their direct neighbors. Each time an agent
generates a new intersection schedule it communicates its expected outflows to
its downstream neighbors as a prediction of future demand and these outflows
are appended to the downstream agent's locally perceived demand. In this paper,
we extend this basic coordination algorithm to additionally incorporate the
complementary flow of information reflective of an intersection's current
congestion level to its upstream neighbors. We present an asynchronous
decentralized algorithm for updating intersection schedules and congestion
level estimates based on these bi-directional information flows. By relating
this algorithm to the self-optimized decision making of the basic operation, we
are able to approach network-wide optimality and reduce inefficiency due to
strictly self-interested intersection control decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01979</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01979</id><created>2019-07-03</created><authors><author><keyname>Aijaz</keyname><forenames>Adnan</forenames></author><author><keyname>Stanoev</keyname><forenames>Aleksandar</forenames></author><author><keyname>Sooriyabandara</keyname><forenames>Mahesh</forenames></author></authors><title>Toward Real-Time Wireless Control of Mobile Platforms for Future
  Industrial Systems</title><categories>cs.NI cs.SY eess.SY</categories><comments>Presented at IEEE INFOCOM 2019 (Demo paper)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of mobile platforms (MPs) is particularly attractive for various
industrial applications. This demonstration highlights the importance of remote
control of MPs and shows its viability over a high-performance wireless
solution designed for closed-loop control. Further, it shows the viability of
formation control of a network of MPs through a leader-follower approach
underpinned by high-performance wireless.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.01984</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.01984</id><created>2019-07-03</created><authors><author><keyname>Hu</keyname><forenames>Hsu-Chieh</forenames></author><author><keyname>Smith</keyname><forenames>Stephen F.</forenames></author><author><keyname>Goldstein</keyname><forenames>Rick</forenames></author></authors><title>Cooperative Schedule-Driven Intersection Control with Connected and
  Autonomous Vehicles</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work in decentralized, schedule-driven traffic control has
demonstrated the ability to improve the efficiency of traffic flow in complex
urban road networks. In this approach, a scheduling agent is associated with
each intersection. Each agent senses the traffic approaching its intersection
and in real-time constructs a schedule that minimizes the cumulative wait time
of vehicles approaching the intersection over the current look-ahead horizon.
In this paper, we propose a cooperative algorithm that utilizes both connected
and autonomous vehicles (CAV) and schedule-driven traffic control to create
better traffic flow in the city. The algorithm enables an intersection
scheduling agent to adjust the arrival time of an approaching platoon through
use of wireless communication to control the velocity of vehicles. The sequence
of approaching platoons is thus shifted toward a new shape that has smaller
cumulative delay. We demonstrate how this algorithm outperforms the original
approach in a real-time traffic signal control problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02003</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02003</id><created>2019-07-03</created><authors><author><keyname>Mlynarski</keyname><forenames>Pawel</forenames></author><author><keyname>Delingette</keyname><forenames>Herv&#xe9;</forenames></author><author><keyname>Alghamdi</keyname><forenames>Hamza</forenames></author><author><keyname>Bondiau</keyname><forenames>Pierre-Yves</forenames></author><author><keyname>Ayache</keyname><forenames>Nicholas</forenames></author></authors><title>Anatomically Consistent Segmentation of Organs at Risk in MRI with
  Convolutional Neural Networks</title><categories>eess.IV cs.CV</categories><comments>Submitted to Computerized Medical Imaging and Graphics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Planning of radiotherapy involves accurate segmentation of a large number of
organs at risk, i.e. organs for which irradiation doses should be minimized to
avoid important side effects of the therapy. We propose a deep learning method
for segmentation of organs at risk inside the brain region, from Magnetic
Resonance (MR) images. Our system performs segmentation of eight structures:
eye, lens, optic nerve, optic chiasm, pituitary gland, hippocampus, brainstem
and brain. We propose an efficient algorithm to train neural networks for an
end-to-end segmentation of multiple and non-exclusive classes, addressing
problems related to computational costs and missing ground truth segmentations
for a subset of classes. We enforce anatomical consistency of the result in a
postprocessing step, in particular we introduce a graph-based algorithm for
segmentation of the optic nerves, enforcing the connectivity between the eyes
and the optic chiasm. We report cross-validated quantitative results on a
database of 44 contrast-enhanced T1-weighted MRIs with provided segmentations
of the considered organs at risk, which were originally used for radiotherapy
planning. In addition, the segmentations produced by our model on an
independent test set of 50 MRIs are evaluated by an experienced radiotherapist
in order to qualitatively assess their accuracy. The mean distances between
produced segmentations and the ground truth ranged from 0.1 mm to 0.7 mm across
different organs. A vast majority (96 %) of the produced segmentations were
found acceptable for radiotherapy planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02005</identifier>
 <datestamp>2019-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02005</id><created>2019-07-03</created><updated>2019-07-31</updated><authors><author><keyname>Zhao</keyname><forenames>Dongwei</forenames></author><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Lin</keyname><forenames>Xiaojun</forenames></author></authors><title>Technical report for &quot;Virtual Energy Storage Sharing and Capacity
  Allocation&quot;</title><categories>eess.SY cs.GT cs.SY math.OC</categories><comments>This is the online appendix for the paper published in IEEE
  Transactions on Smart Grid</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy storage can play an important role in energy management of end users.
To promote an efficient utilization of energy storage, we develop a novel
business model to enable virtual storage sharing among a group of users.
Specifically, a storage aggregator invests and operates the central physical
storage unit, by virtualizing it into separable virtual capacities and selling
to users. Each user purchases the virtual capacity, and utilize it to reduce
the energy cost. We formulate the interaction between the aggregator and users
as a two-stage optimization problem. In Stage 1, over the investment horizon,
the aggregator determines the investment and pricing decisions. In Stage 2, in
each operational horizon, each user decides the virtual capacity to purchase
together with the operation of the virtual storage. We characterize a stepwise
form of the optimal solution of Stage-2 Problem and a piecewise linear
structure of the optimal profit of Stage-1 Problem, both with respect to the
virtual capacity price. Based on the solution structure, we design an algorithm
to attain the optimal solution of the two-stage problem. In our simulation
results, the proposed storage virtualization model can reduce the physical
energy storage investment of the aggregator by 54.3% and reduce the users'
total costs by 34.7%, compared to the case where users acquire their own
physical storage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02045</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02045</id><created>2019-07-03</created><authors><author><keyname>Nilsson</keyname><forenames>Gustav</forenames></author><author><keyname>Como</keyname><forenames>Giacomo</forenames></author></authors><title>Generalized Proportional Allocation Policies for Robust Control of
  Dynamical Flow Networks</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a robust control problem for dynamical flow networks. In the
considered dynamical models, traffic flows along the links of a transportation
network --modeled as a capacited multigraph-- and queues up at the nodes,
whereby control policies determine which incoming queues at a node are to be
allocated service simultaneously, within some predetermined scheduling
constraints. We first prove a fundamental performance limitation by showing
that for a dynamical flow network to be stabilizable by some control policy it
is necessary that the exogenous inflows belong to a certain stability region,
that is determined by the network topology, link capacities, and scheduling
constraints. Then, we introduce a family of distributed controls, referred to
as Generalized Proportional Allocation (GPA) policies, and prove that they
stabilize a dynamical transportation network whenever the exogenous inflows
belong to such stability region. The proposed GPA control policies are
decentralized and fully scalable as they rely on local feedback information
only. Differently from previously studied maximally stabilizing control
strategies, the GPA control policies do not require any global information
about the network topology, the exogenous inflows, or the routing, which makes
them robust to demand variations and unpredicted changes in the link capacities
or the routing decisions. Moreover, the proposed GPA control policies also take
into account the overhead time while switching between services. Our
theoretical results find one application in the control of urban traffic
networks with signalized intersections, where vehicles have to queue up at
junctions and the traffic signal controls determine the green light allocation
to the different incoming lanes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02060</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02060</id><created>2019-07-03</created><authors><author><keyname>Zia</keyname><forenames>Aneeq</forenames></author><author><keyname>Guo</keyname><forenames>Liheng</forenames></author><author><keyname>Zhou</keyname><forenames>Linlin</forenames></author><author><keyname>Essa</keyname><forenames>Irfan</forenames></author><author><keyname>Jarc</keyname><forenames>Anthony</forenames></author></authors><title>Novel evaluation of surgical activity recognition models using
  task-based efficiency metrics</title><categories>cs.CV eess.IV</categories><journal-ref>International Journal of Computer Assisted Radiology and Surgery
  (IJCARS) 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: Surgical task-based metrics (rather than entire procedure metrics)
can be used to improve surgeon training and, ultimately, patient care through
focused training interventions. Machine learning models to automatically
recognize individual tasks or activities are needed to overcome the otherwise
manual effort of video review. Traditionally, these models have been evaluated
using frame-level accuracy. Here, we propose evaluating surgical activity
recognition models by their effect on task-based efficiency metrics. In this
way, we can determine when models have achieved adequate performance for
providing surgeon feedback via metrics from individual tasks.
  Methods: We propose a new CNN-LSTM model, RP-Net-V2, to recognize the 12
steps of robotic-assisted radical prostatectomies (RARP). We evaluated our
model both in terms of conventional methods (e.g. Jaccard Index, task boundary
accuracy) as well as novel ways, such as the accuracy of efficiency metrics
computed from instrument movements and system events.
  Results: Our proposed model achieves a Jaccard Index of 0.85 thereby
outperforming previous models on robotic-assisted radical prostatectomies.
Additionally, we show that metrics computed from tasks automatically identified
using RP-Net-V2 correlate well with metrics from tasks labeled by clinical
experts.
  Conclusions: We demonstrate that metrics-based evaluation of surgical
activity recognition models is a viable approach to determine when models can
be used to quantify surgical efficiencies. We believe this approach and our
results illustrate the potential for fully automated, post-operative efficiency
reports.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02063</identifier>
 <datestamp>2019-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02063</id><created>2019-07-03</created><authors><author><keyname>Hessar</keyname><forenames>Mehrdad</forenames></author><author><keyname>Najafi</keyname><forenames>Ali</forenames></author><author><keyname>Iyer</keyname><forenames>Vikram</forenames></author><author><keyname>Gollakota</keyname><forenames>Shyamnath</forenames></author></authors><title>TinySDR: Low-Power SDR Platform for Over-the-Air Programmable IoT
  Testbeds</title><categories>eess.SP cs.NI</categories><comments>16 pages, accepted to NSDI 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless protocol design for IoT networks is an active area of research which
has seen significant interest and developments in recent years. The research
community is however handicapped by the lack of a flexible, easily deployable
platform for prototyping IoT endpoints that would allow for ground up protocol
development and investigation of how such protocols perform at scale. We
introduce tinySDR, the first software-defined radio platform tailored to the
needs of power-constrained IoT endpoints. TinySDR provides a standalone, fully
programmable low power software-defined radio solution that can be duty cycled
for battery operation like a real IoT endpoint, and more importantly, can be
programmed over the air to allow for large scale deployment. We present
extensive evaluation of our platform showing it consumes as little as 30 uW of
power in sleep mode, which is 10,000x lower than existing SDR platforms. We
present two case studies by implementing LoRa and BLE beacons on the platform
and achieve sensitivities of -126 dBm and -94 dBm respectively while consuming
11% and 3% of the FPGA resources. Finally, using tinySDR, we explore the
research question of whether an IoT device can demodulate concurrent LoRa
transmissions in real-time, within its power and computing constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02091</identifier>
 <datestamp>2020-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02091</id><created>2019-07-03</created><updated>2020-02-05</updated><authors><author><keyname>Zhang</keyname><forenames>Qianzhi</forenames></author><author><keyname>Dehghanpour</keyname><forenames>Kaveh</forenames></author><author><keyname>Wang</keyname><forenames>Zhaoyu</forenames></author><author><keyname>Qiu</keyname><forenames>Feng</forenames></author><author><keyname>Zhao</keyname><forenames>Dongbo</forenames></author></authors><title>Multi-Agent Safe Policy Learning for Power Management of Networked
  Microgrids</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a supervised multi-agent safe policy learning (SMAS-PL)
method for optimal power management of networked microgrids (MGs) in
distribution systems. While conventional reinforcement learning (RL) algorithms
are black-box decision models that could fail to satisfy grid operational
constraints, our proposed method is constrained by AC power flow equations and
other operational limits. Accordingly, the training process employs the
gradient information of operational constraints to ensure that the optimal
control policy functions generate safe and feasible decisions. Furthermore, we
have developed a distributed consensus-based optimization approach to train the
agents' policy functions while maintaining MGs' privacy and data ownership
boundaries. After training, the learned optimal policy functions can be safely
used by the MGs to dispatch their local resources, without the need to solve a
complex optimization problem from scratch. Numerical experiments have been
devised to verify the performance of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02096</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02096</id><created>2019-07-03</created><authors><author><keyname>Varga</keyname><forenames>Domonkos</forenames></author></authors><title>A comprehensive evaluation of full-reference image quality assessment
  algorithms on KADID-10k</title><categories>eess.IV cs.CV</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Significant progress has been made in the past decade for full-reference
image quality assessment (FR-IQA). However, new large scale image quality
databases have been released for evaluating image quality assessment
algorithms. In this study, our goal is to give a comprehensive evaluation of
state-of-the-art FR-IQA metrics using the recently published KADID-10k database
which is largest available one at the moment. Our evaluation results and the
associated discussions is very helpful to obtain a clear understanding about
the status of state-of-the-art FR-IQA metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02110</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02110</id><created>2019-07-03</created><authors><author><keyname>Doshi</keyname><forenames>Jimit</forenames></author><author><keyname>Erus</keyname><forenames>Guray</forenames></author><author><keyname>Habes</keyname><forenames>Mohamad</forenames></author><author><keyname>Davatzikos</keyname><forenames>Christos</forenames></author></authors><title>DeepMRSeg: A convolutional deep neural network for anatomy and
  abnormality segmentation on MR images</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>18 pages, 8 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmentation has been a major task in neuroimaging. A large number of
automated methods have been developed for segmenting healthy and diseased brain
tissues. In recent years, deep learning techniques have attracted a lot of
attention as a result of their high accuracy in different segmentation
problems. We present a new deep learning based segmentation method, DeepMRSeg,
that can be applied in a generic way to a variety of segmentation tasks. The
proposed architecture combines recent advances in the field of biomedical image
segmentation and computer vision. We use a modified UNet architecture that
takes advantage of multiple convolution filter sizes to achieve multi-scale
feature extraction adaptive to the desired segmentation task. Importantly, our
method operates on minimally processed raw MRI scan. We validated our method on
a wide range of segmentation tasks, including white matter lesion segmentation,
segmentation of deep brain structures and hippocampus segmentation. We provide
code and pre-trained models to allow researchers apply our method on their own
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02151</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02151</id><created>2019-07-03</created><authors><author><keyname>Chakrabarty</keyname><forenames>Ankush</forenames></author><author><keyname>Jha</keyname><forenames>Devesh K.</forenames></author><author><keyname>Buzzard</keyname><forenames>Gregery T.</forenames></author><author><keyname>Wang</keyname><forenames>Yebin</forenames></author><author><keyname>Vamvoudakis</keyname><forenames>Kyriakos</forenames></author></authors><title>Safe Approximate Dynamic Programming Via Kernelized Lipschitz Estimation</title><categories>eess.SY cs.LG cs.SY math.DS math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a method for obtaining safe initial policies for reinforcement
learning via approximate dynamic programming (ADP) techniques for uncertain
systems evolving with discrete-time dynamics. We employ kernelized Lipschitz
estimation and semidefinite programming for computing admissible initial
control policies with provably high probability. Such admissible controllers
enable safe initialization and constraint enforcement while providing
exponential stability of the equilibrium of the closed-loop system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02153</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02153</id><created>2019-07-03</created><authors><author><keyname>Yu</keyname><forenames>Daesung</forenames></author><author><keyname>Kim</keyname><forenames>Junbeom</forenames></author><author><keyname>Park</keyname><forenames>Seok-Hwan</forenames></author></authors><title>An Efficient Rate-Splitting Multiple Access Scheme for the Downlink of
  C-RAN Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted for publication in IEEE Wireless Communications Letters (4
  pages, 2 figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the optimization of rate-splitting multiple access (RSMA)
transmission technique for a cloud radio access network (C-RAN) downlink
system. Main idea of RSMA is to split the message for each user equipment (UE)
to private and common messages and perform superposition coding at transmitters
so as to enable flexible decoding at receivers. It is challenging to implement
ideal RSMA scheme particularly when there are many UEs, since the number of
common signals exponentially increases with the number of UEs. An efficient
RSMA scheme is hence proposed that uses a linearly increasing number of common
signals whose decoding UEs are selected using hierarchical clustering. Via
numerical results, we show the performance gains of the proposed RSMA scheme
over conventional space-division multiple access (SDMA) and nonorthogonal
multiple access (NOMA) schemes as well as over a conventional RSMA scheme that
uses a single common signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02187</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02187</id><created>2019-07-03</created><authors><author><keyname>Maruf</keyname><forenames>Abdullah Al</forenames></author><author><keyname>Ostadijafari</keyname><forenames>Mohammad</forenames></author><author><keyname>Dubey</keyname><forenames>Anamika</forenames></author><author><keyname>Roy</keyname><forenames>Sandip</forenames></author></authors><title>Small-Signal Stability Analysis for Droop-Controlled Inverter-based
  Microgrids with Losses and Filtering</title><categories>eess.SY cs.SY</categories><doi>10.1145/3307772.3328310</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An islanded microgrid supplied by multiple distributed energy resources
(DERs) often employs droop-control mechanisms for power sharing. Because
microgrids do not include inertial elements, and low pass filtering of noisy
measurements introduces lags in control, droop-like controllers may pose
significant stability concerns. This paper aims to understand the effects of
droop-control on the small-signal stability and transient response of the
microgrid. Towards this goal, we present a compendium of results on the
small-signal stability of droop-controlled inverter-based microgrids with
heterogeneous loads, which distinguishes: (1) lossless vs. lossy networks; (2)
droop mechanisms with and without filters, and (3) mesh vs. radial network
topologies. Small-signal and transient characteristics are also studied using
multiple simulation studies on IEEE test systems
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02191</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02191</id><created>2019-07-03</created><authors><author><keyname>Cai</keyname><forenames>Danwei</forenames></author><author><keyname>Cai</keyname><forenames>Weicheng</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>The DKU-SMIIP System for NIST 2018 Speaker Recognition Evaluation</title><categories>eess.AS</categories><comments>Accepted by Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the system submission for the NIST 2018 Speaker
Recognition Evaluation by DKU Speech and Multi-Modal Intelligent Information
Processing (SMIIP) Lab. We explore various kinds of state-of-the-art front-end
extractors as well as back-end modeling for text-independent speaker
verifications. Our submitted primary systems employ multiple state-of-the-art
front-end extractors, including the MFCC i-vector, the DNN tandem i-vector, the
TDNN x-vector, and the deep ResNet. After speaker embedding is extracted, we
exploit several kinds of back-end modeling to perform variability compensation
and domain adaptation for mismatch training and testing conditions. The final
submitted system on the fixed condition obtains actual detection cost of 0.392
and 0.494 on CMN2 and VAST evaluation data respectively. After the official
evaluation, we further extend our experiments by investigating multiple
encoding layer designs and loss functions for the deep ResNet system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02194</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02194</id><created>2019-07-03</created><authors><author><keyname>Cai</keyname><forenames>Danwei</forenames></author><author><keyname>Qin</keyname><forenames>Xiaoyi</forenames></author><author><keyname>Cai</keyname><forenames>Weicheng</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>The DKU System for the Speaker Recognition Task of the 2019 VOiCES from
  a Distance Challenge</title><categories>eess.AS</categories><comments>Accepted by Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the DKU system for the speaker recognition task of
the VOiCES from a distance challenge 2019. We investigate the whole system
pipeline for the far-field speaker verification, including data pre-processing,
short-term spectral feature representation, utterance-level speaker modeling,
back-end scoring, and score normalization. Our best single system employs a
residual neural network trained with angular softmax loss. Also, the weighted
prediction error algorithms can further improve performance. It achieves 0.3668
minDCF and 5.58% EER on the evaluation set by using a simple cosine similarity
scoring. Finally, the submitted primary system obtains 0.3532 minDCF and 4.96%
EER on the evaluation set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02197</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02197</id><created>2019-07-03</created><authors><author><keyname>Igbafe</keyname><forenames>Orikumhi</forenames></author><author><keyname>Kang</keyname><forenames>Jeongwan</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Kim</keyname><forenames>Sunwoo</forenames></author></authors><title>Location-aware Beam Alignment for mmWave Communications</title><categories>eess.SP cs.IT math.IT</categories><comments>30 pages, 8 figures, The short version of this paper has been
  presented at the 2018 56th Annual Allerton Conference on Communication
  Control, and Computing (Allerton), USA</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Beam alignment is required in millimeter wave communication to ensure high
data rate transmission. However, with narrow beamwidth in massive MIMO, beam
alignment could be computationally intensive due to the large number of beam
pairs to be measured. In this paper, we propose an efficient beam alignment
framework by exploiting the location information of the user equipment (UE) and
potential reflecting points. The proposed scheme allows the UE and the base
station to perform a coordinated beam search from a small set of beams within
the error boundary of the location information, the selected beams are then
used to guide the search of future beams. To further reduce the number of beams
to be searched, we propose an intelligent search scheme within a small window
of beams to determine the direction of the actual beam. The proposed beam
alignment algorithm is verified on simulation with some location uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02208</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02208</id><created>2019-07-02</created><authors><author><keyname>Fuhg</keyname><forenames>Jan N.</forenames></author><author><keyname>Fau</keyname><forenames>Amelie</forenames></author></authors><title>Surrogate model approach for investigating the stability of a
  friction-induced oscillator of Duffing's type</title><categories>eess.SY cs.SY</categories><comments>33 pages, 20 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parametric studies for dynamic systems are of high interest to detect
instability domains. This prediction can be demanding as it requires a refined
exploration of the parametric space due to the disrupted mechanical behavior.
In this paper, an efficient surrogate strategy is proposed to investigate the
behavior of an oscillator of Duffing's type in combination with an
elasto-plastic friction force model. Relevant quantities of interest are
discussed. Sticking time is considered using a machine learning technique based
on Gaussian processes called kriging. The largest Lyapunov exponent is proposed
as an efficient indicator of non-regular behavior. This indicator is estimated
using a perturbation method. A dedicated adaptive kriging strategy for
classification called MiVor is utilized and appears to be highly proficient in
order to detect instabilities over the parametric space and can furthermore be
used for complex response surfaces in multi-dimensional parametric domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02209</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02209</id><created>2019-05-26</created><authors><author><keyname>Cam</keyname><forenames>Handan</forenames></author><author><keyname>Duman</keyname><forenames>Osman</forenames></author></authors><title>Earthquake Prediction With Artificial Neural Network Method: The
  Application Of West Anatolian Fault In Turkey</title><categories>cs.OH cs.LG eess.SP</categories><journal-ref>GUEJISS, Gumushane University Electronic Journal of The Institute
  of Social Sciences Volume: 7, Number: 17, Year: 2016</journal-ref><doi>10.17823/gusb.352</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A method that exactly knows the earthquakes beforehand and can generalize
them cannot still been developed. However, earthquakes are tried to be
predicted through numerous methods. One of these methods, artificial neural
networks give appropriate outputs to different patterns by learning the
relationship between the determined inputs and outputs. In this study, a
feedforward back propagation artificial neural network that is connected to
Gutenberg-Richter relationship and that bases on b value used in earthquake
predictions was developed. The artificial neural network was trained employing
earthquake data belonging to four different regions which have intensive
seismic activity in the west of Turkey. After the training process, the
earthquake data belonging to later dates of the same regions were used for
testing and the performance of the network was put forward. When the prediction
results of the developed network are examined, the prediction results that the
network predicts that an earthquake is not going to occur are quite high in all
regions. Furthermore, the earthquake prediction results that the network
predicts that an earthquake is going to occur are different to some extent for
the studied regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02215</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02215</id><created>2019-07-04</created><authors><author><keyname>Shu</keyname><forenames>Feng</forenames></author><author><keyname>Liu</keyname><forenames>Lin</forenames></author><author><keyname>Zhang</keyname><forenames>Yumeng</forenames></author><author><keyname>Xia</keyname><forenames>Guiyang</forenames></author><author><keyname>Liu</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Wang</keyname><forenames>Jiangzhou</forenames></author></authors><title>A Deep-learning-based Joint Inference for Secure Spatial Modulation
  Receiver</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a green and secure wireless transmission way, secure spatial modulation
(SM) is becoming a hot research area. Its basic idea is to exploit both the
index of activated transmit antenna and amplitude phase modulation (APM) signal
to carry messages, improve security, and save energy. In this paper, we
reviewed its crucial techniques: transmit antenna selection (TAS), artificial
noise (AN) projection, power allocation (PA), and joint detection at desired
receiver. To achieve the optimal performance of maximum likelihood (ML)
detector, a deep-neural-network (DNN) joint detector is proposed to jointly
infer the index of transmit antenna and signal constellation point with a
lower-complexity. Here, each layer of DNN is redesigned to optimize the joint
inference performance of two distinct types of information: transmit antenna
index and signal constellation point. Simulation results show that the proposed
DNN method performs 3dB better than the conventional DNN structure and is close
to ML detection in the low and medium signal-to-noise ratio regions in terms of
the bit error rate (BER) performance, but its complexity is far
lower-complexity compared to ML. Finally, three key techniques TAS, PA, and AN
projection at transmitter can be combined to make SM a true secure modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02219</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02219</id><created>2019-07-04</created><authors><author><keyname>Zhou</keyname><forenames>Fengyu</forenames></author><author><keyname>Anderson</keyname><forenames>James</forenames></author><author><keyname>Low</keyname><forenames>Steven H.</forenames></author></authors><title>The Optimal Power Flow Operator: Theory and Computation</title><categories>math.OC cs.SY eess.SY</categories><comments>35 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal power flow problems (OPFs) are mathematical programs used to
distribute power over networks subject to network operation constraints and the
physics of power flows. In this work we take the view of treating an OPF
problem as an operator which maps user demand to generated power and allow the
network parameters to take values in some admissible set. The contributions of
this paper are to formalize this operator theoretic approach, define and
characterize a restricted parameter sets under which the mapping has a
singleton output, independent binding constraints, and is differentiable. We
further provide a closed-form expression for the Jacobian matrix of the OPF
operator and describe how various derivatives can be computed using a recently
proposed scheme based on homogenous self-dual embedding. Our framework of
treating a mathematical program as an operator allows us to pose sensitivity
and robustness questions from a completely different mathematical perspective
and provide new insights into well studied problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02230</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02230</id><created>2019-07-04</created><authors><author><keyname>Zhang</keyname><forenames>Zhichao</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author><author><keyname>Qiao</keyname><forenames>Tianhao</forenames></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Cao</keyname><forenames>Shan</forenames></author></authors><title>Attention based Convolutional Recurrent Neural Network for Environmental
  Sound Classification</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted to Chinese Conference on Pattern Recognition and Computer
  Vision (PRCV) 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Environmental sound classification (ESC) is a challenging problem due to the
complexity of sounds. The ESC performance is heavily dependent on the
effectiveness of representative features extracted from the environmental
sounds. However, ESC often suffers from the semantically irrelevant frames and
silent frames. In order to deal with this, we employ a frame-level attention
model to focus on the semantically relevant frames and salient frames.
Specifically, we first propose an convolutional recurrent neural network to
learn spectro-temporal features and temporal correlations. Then, we extend our
convolutional RNN model with a frame-level attention mechanism to learn
discriminative feature representations for ESC. Experiments were conducted on
ESC-50 and ESC-10 datasets. Experimental results demonstrated the effectiveness
of the proposed method and achieved the state-of-the-art performance in terms
of classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02244</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02244</id><created>2019-07-04</created><authors><author><keyname>Tran</keyname><forenames>Son</forenames></author><author><keyname>Du</keyname><forenames>Ming</forenames></author><author><keyname>Chanda</keyname><forenames>Sampath</forenames></author><author><keyname>Manmatha</keyname><forenames>R.</forenames></author><author><keyname>Taylor</keyname><forenames>Cj</forenames></author></authors><title>Searching for Apparel Products from Images in the Wild</title><categories>cs.CV eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this age of social media, people often look at what others are wearing. In
particular, Instagram and Twitter influencers often provide images of
themselves wearing different outfits and their followers are often inspired to
buy similar clothes.We propose a system to automatically find the closest
visually similar clothes in the online Catalog (street-to-shop searching). The
problem is challenging since the original images are taken under different pose
and lighting conditions. The system initially localizes high-level descriptive
regions (top, bottom, wristwear. . . ) using multiple CNN detectors such as
YOLO and SSD that are trained specifically for apparel domain. It then
classifies these regions into more specific regions such as t-shirts, tunic or
dresses. Finally, a feature embedding learned using a multi-task function is
recovered for every item and then compared with corresponding items in the
online Catalog database and ranked according to distance. We validate our
approach component-wise using benchmark datasets and end-to-end using human
evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02253</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02253</id><created>2019-07-04</created><authors><author><keyname>Kim</keyname><forenames>Byung-Hak</forenames></author><author><keyname>Ganapathi</keyname><forenames>Varun</forenames></author></authors><title>Lumi\`ereNet: Lecture Video Synthesis from Audio</title><categories>cs.LG cs.CV eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Lumi\`ereNet, a simple, modular, and completely deep-learning
based architecture that synthesizes, high quality, full-pose headshot lecture
videos from instructor's new audio narration of any length. Unlike prior works,
Lumi\`ereNet is entirely composed of trainable neural network modules to learn
mapping functions from the audio to video through (intermediate) estimated
pose-based compact and abstract latent codes. Our video demos are available at
[22] and [23].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02265</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02265</id><created>2019-07-04</created><authors><author><keyname>C&#xed;fka</keyname><forenames>Ond&#x159;ej</forenames></author><author><keyname>&#x15e;im&#x15f;ekli</keyname><forenames>Umut</forenames></author><author><keyname>Richard</keyname><forenames>Ga&#xeb;l</forenames></author></authors><title>Supervised Symbolic Music Style Translation Using Synthetic Data</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>ISMIR 2019 camera-ready</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Research on style transfer and domain translation has clearly demonstrated
the ability of deep learning-based algorithms to manipulate images in terms of
artistic style. More recently, several attempts have been made to extend such
approaches to music (both symbolic and audio) in order to enable transforming
musical style in a similar manner. In this study, we focus on symbolic music
with the goal of altering the 'style' of a piece while keeping its original
'content'. As opposed to the current methods, which are inherently restricted
to be unsupervised due to the lack of 'aligned' data (i.e. the same musical
piece played in multiple styles), we develop the first fully supervised
algorithm for this task. At the core of our approach lies a synthetic data
generation scheme which allows us to produce virtually unlimited amounts of
aligned data, and hence avoid the above issue. In view of this data generation
scheme, we propose an encoder-decoder model for translating symbolic music
accompaniments between a number of different styles. Our experiments show that
our models, although trained entirely on synthetic data, are capable of
producing musically meaningful accompaniments even for real (non-synthetic)
MIDI recordings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02272</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02272</id><created>2019-07-04</created><authors><author><keyname>Wijesinghe</keyname><forenames>Philip</forenames></author><author><keyname>Escobet-Montalb&#xe1;n</keyname><forenames>Adri&#xe0;</forenames></author><author><keyname>Chen</keyname><forenames>Mingzhou</forenames></author><author><keyname>Munro</keyname><forenames>Peter R T</forenames></author><author><keyname>Dholakia</keyname><forenames>Kishan</forenames></author></authors><title>Optimal compressive multiphoton imaging at depth using single-pixel
  detection</title><categories>physics.optics eess.IV</categories><doi>10.1364/OL.44.004981</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing can overcome the Nyquist criterion and record images with
a fraction of the usual number of measurements required. However, conventional
measurement bases are susceptible to diffraction and scattering, prevalent in
high-resolution microscopy. Here, we explore the random Morlet basis as an
optimal set for compressive multiphoton imaging, based on its ability to
minimise the space-frequency uncertainty. We implement this approach for the
newly developed method of wide-field multiphoton microscopy with single-pixel
detection (TRAFIX), which allows imaging through turbid media without
correction. The Morlet basis is well-suited to TRAFIX at depth, and promises a
route for rapid acquisition with low photodamage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02287</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02287</id><created>2019-07-04</created><authors><author><keyname>Chen</keyname><forenames>Zhibo</forenames></author><author><keyname>Shi</keyname><forenames>Jun</forenames></author><author><keyname>Li</keyname><forenames>Weiping</forenames></author></authors><title>Learned Fast HEVC Intra Coding</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In High Efficiency Video Coding (HEVC), excellent rate-distortion (RD)
performance is achieved in part by having flexible quadtree coding unit (CU)
partition and a large number of intra-prediction modes. Such an excellent RD
performance is achieved at the expense of much higher computational complexity.
In this paper, we propose a Learned Fast HEVC Intra coding (LFHI) framework
taking into account the comprehensive factors of fast intra coding, to reach an
improved configurable trade-off between coding performance and computational
complexity. Firstly, we design a low-complex shallow Asymmetric-Kernel CNN
(AK-CNN) to efficiently extract the local directional texture features of each
block for both fast CU partition and fast intra-mode decision. Secondly, we
introduce the concept of Minimum Number of RDO Candidates (MNRC) into fast mode
decision, which utilizes AK-CNN to predict the minimum number of best
candidates for RDO calculation, to further reduce computation of intra mode
selection. Thirdly, an Evolution Optimized Threshold Decision (EOTD) scheme is
designed to achieve configurable complexity-efficiency trade-offs. Finally, we
propose an interpolation-based prediction scheme that allows our framework to
be generalized to all quantization parameters (QPs), without the need of
training the network on each QP. The experimental results demonstrate that the
LFHI framework has a high degree of parallelism and achieves much better
complexity-efficiency trade-off, achieving up to 75.2% intra mode encoding
complexity reduction with negligible rate-distortion performance degradation,
superior to the existing fast intra coding schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02314</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02314</id><created>2019-07-04</created><authors><author><keyname>Kosaraju</keyname><forenames>Krishna Chaitanya</forenames></author><author><keyname>de Jong</keyname><forenames>Matthijs C.</forenames></author><author><keyname>Scherpen</keyname><forenames>Jacquelien M. A.</forenames></author></authors><title>A novel passivity based controller for a piezoelectric beam</title><categories>eess.SY cs.SY</categories><journal-ref>2019 18th European Control Conference (ECC), Napoli, Italy, June
  25-28, 2019</journal-ref><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This paper presents a new passivity property for distributed piezoelectric
devices with integrable port-variables. We present two new control
methodologies by exploiting the integrability property of the port-variables.
The derived controllers have a Proportional-Integral (PI) like structure.
Finally, we present the simulation results and in-depth analysis on the tuning
gains explaining their transient and steady-state behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02329</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02329</id><created>2019-07-04</created><updated>2019-07-05</updated><authors><author><keyname>Kasebzadeh</keyname><forenames>Parinaz</forenames></author><author><keyname>Hendeby</keyname><forenames>Gustaf</forenames></author><author><keyname>Gustafsson</keyname><forenames>Fredrik</forenames></author></authors><title>Asynchronous Averaging of Gait Cycles for Classification of Gait and
  Device Modes</title><categories>eess.SP cs.LG</categories><comments>Submitted to IEEE Sensors Journal</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  An approach for computing unique gait signature using measurements collected
from body-worn inertial measurement units (IMUs) is proposed. The gait
signature represents one full cycle of the human gait, and is suitable for
off-line or on-line classification of the gait mode. The signature can also be
used to jointly classify the gait mode and the device mode. The device mode
identifies how the IMU-equipped device is being carried by the user. The method
is based on precise segmentation and resampling of the measured IMU signal, as
an initial step, further tuned by minimizing the variability of the obtained
signature within each gait cycle. Finally, a Fourier series expansion of the
gait signature is introduced which provides a low-dimensional feature vector
well suited for classification purposes. The proposed method is evaluated on a
large dataset involving several subjects, each one containing two different
gait modes and four different device modes. The gait signatures enable a high
classification rate for each step cycle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02350</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02350</id><created>2019-07-04</created><updated>2019-07-08</updated><authors><author><keyname>Campo</keyname><forenames>Pablo Pascual</forenames></author><author><keyname>Brihuega</keyname><forenames>Alberto</forenames></author><author><keyname>Anttila</keyname><forenames>Lauri</forenames></author><author><keyname>Turunen</keyname><forenames>Matias</forenames></author><author><keyname>Korpi</keyname><forenames>Dani</forenames></author><author><keyname>All&#xe9;n</keyname><forenames>Markus</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>Reduced-Complexity Digital Predistortion: Adaptive Spline-Based
  Hammerstein Approach</title><categories>eess.SP</categories><comments>This manuscript has been submitted to IEEE Transactions on Microwave
  Theory and Techniques (TMTT). 13 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel digital predistorter concept for power amplifier (PA)
linearization is proposed, with particular emphasis on reduced processing
complexity in future 5G and beyond wideband radio systems. The proposed method
builds on a complex spline interpolated look-up table (LUT) followed by a
linear finite impulse response (FIR) filter, comprising essentially a
Hammerstein-type nonlinear system. For reliable parameter learning,
gradient-descent based adaptive learning rules are derived, allowing for the
estimation of the spline control points and the FIR filter parameters in a
decoupled manner. Large set of experimental results are provided, with specific
focus on 5G New Radio (NR) systems, showing successful linearization of
multiple sub-6 GHz PA samples as well as a 28 GHz active antenna array,
incorporating channel bandwidths up to 200 MHz. Explicit performance-complexity
comparisons are also reported against two known reference solutions, namely a
memory polynomial (MP) based DPD and a linear interpolated LUT. The results
show that the linearization performance of the proposed method is very close to
that of a memory polynomial while clearly outperforming the linear interpolated
LUT. Additionally, it is shown that the processing complexity of the proposed
DPD is commonly some 60 % lower than that of the MP based DPD, offering thus a
very good complexity-performance tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02355</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02355</id><created>2019-07-04</created><authors><author><keyname>Puyo</keyname><forenames>L.</forenames></author><author><keyname>Paques</keyname><forenames>M.</forenames></author><author><keyname>Fink</keyname><forenames>M.</forenames></author><author><keyname>Sahel</keyname><forenames>J-A</forenames></author><author><keyname>Atlan</keyname><forenames>M.</forenames></author></authors><title>Analysis of retinal and choroidal images measured by laser Doppler
  holography</title><categories>physics.med-ph eess.IV physics.optics</categories><comments>Conference proceedings</comments><doi>10.1117/12.2530151</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Laser Doppler holography (LDH) is a full-field imaging technique that was
recently used in the human eye to reveal blood flow contrasts in the retinal
and choroidal vasculature non-invasively, and with high temporal resolution. We
here demonstrate that the ability of LDH to perform quantitative flow
measurements with high temporal resolution enables arteriovenous
differentiation in the retina and choroid. In the retina, arteries and veins
can be differentiated on the basis of their respective power Doppler waveforms.
Choroidal arteries and veins can instead be discriminated by computing low and
high frequency power Doppler images to reveal low and high blood flow images,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02371</identifier>
 <datestamp>2019-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02371</id><created>2019-07-04</created><updated>2019-11-06</updated><authors><author><keyname>P&#xe9;rez-R&#xfa;a</keyname><forenames>Juan-Andr&#xe9;s</forenames></author><author><keyname>Das</keyname><forenames>Kaushik</forenames></author><author><keyname>Stolpe</keyname><forenames>Mathias</forenames></author><author><keyname>Cutululis</keyname><forenames>Nicolaos A.</forenames></author></authors><title>Global Optimization of Offshore Wind Farm Collection Systems</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mathematical program for global optimization of the cable layout of
Offshore Wind Farms (OWFs) is presented. The model consists on a Mixed Integer
Linear Program (MILP). Modern branch-and-cut solvers are able to solve
large-scale instances, defined by more than hundred Wind Turbines (WTs), and a
reasonable number of Offshore Substations (OSSs). In addition to the MILP model
to optimize total cable length or initial investment, a pre-processing strategy
is proposed in order to incorporate total electrical power losses into the
objective function. High fidelity models are adapted to calculate cables
current capacities, spatial currents. The MILP model is embedded in an
iterative algorithmic framework, consisting in solving a sequence of problems
with increasing size of the search space. The search space is defined as a set
of underlying candidate arcs. The applicability of the method is illustrated
through 10 case studies of real-world large-scale wind farms. Results show
that: (i) feasible points can quickly be obtained in seconds, (ii) points near
the global optimum with an imposed maximum tolerance, are calculable in
reasonable computational time in the order of hours, and (iii) the proposed
method compares favorably against a state-of-the art method available in
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02404</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02404</id><created>2019-07-04</created><authors><author><keyname>Leplat</keyname><forenames>Valentin</forenames></author><author><keyname>Gillis</keyname><forenames>Nicolas</forenames></author><author><keyname>Ang</keyname><forenames>Man Shun</forenames></author></authors><title>Blind Audio Source Separation with Minimum-Volume Beta-Divergence NMF</title><categories>eess.SP cs.LG cs.SD eess.AS stat.ML</categories><comments>24 pages, 10 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering a mixed signal composed of various audio sources and recorded
with a single microphone, we consider on this paper the blind audio source
separation problem which consists in isolating and extracting each of the
sources. To perform this task, nonnegative matrix factorization (NMF) based on
the Kullback-Leibler and Itakura-Saito $\beta$-divergences is a standard and
state-of-the-art technique that uses the time-frequency representation of the
signal. We present a new NMF model better suited for this task. It is based on
the minimization of $\beta$-divergences along with a penalty term that promotes
the columns of the dictionary matrix to have a small volume. Under some mild
assumptions and in noiseless conditions, we prove that this model is provably
able to identify the sources. In order to solve this problem, we propose
multiplicative updates whose derivations are based on the standard
majorization-minimization framework. We show on several numerical experiments
that our new model is able to obtain more interpretable results than standard
NMF models. Moreover, we show that it is able to recover the sources even when
the number of sources present into the mixed signal is overestimated. In fact,
our model automatically sets sources to zero in this situation, hence performs
model order selection automatically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02431</identifier>
 <datestamp>2019-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02431</id><created>2019-07-03</created><authors><author><keyname>Beliy</keyname><forenames>Roman</forenames></author><author><keyname>Gaziv</keyname><forenames>Guy</forenames></author><author><keyname>Hoogi</keyname><forenames>Assaf</forenames></author><author><keyname>Strappini</keyname><forenames>Francesca</forenames></author><author><keyname>Golan</keyname><forenames>Tal</forenames></author><author><keyname>Irani</keyname><forenames>Michal</forenames></author></authors><title>From voxels to pixels and back: Self-supervision in natural-image
  reconstruction from fMRI</title><categories>eess.IV cs.LG q-bio.NC stat.ML</categories><comments>*First two authors contributed equally. NeurIPS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconstructing observed images from fMRI brain recordings is challenging.
Unfortunately, acquiring sufficient &quot;labeled&quot; pairs of {Image, fMRI} (i.e.,
images with their corresponding fMRI responses) to span the huge space of
natural images is prohibitive for many reasons. We present a novel approach
which, in addition to the scarce labeled data (training pairs), allows to train
fMRI-to-image reconstruction networks also on &quot;unlabeled&quot; data (i.e., images
without fMRI recording, and fMRI recording without images). The proposed model
utilizes both an Encoder network (image-to-fMRI) and a Decoder network
(fMRI-to-image). Concatenating these two networks back-to-back (Encoder-Decoder
&amp; Decoder-Encoder) allows augmenting the training with both types of unlabeled
data. Importantly, it allows training on the unlabeled test-fMRI data. This
self-supervision adapts the reconstruction network to the new input test-data,
despite its deviation from the statistics of the scarce training data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02477</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02477</id><created>2019-07-04</created><updated>2019-08-15</updated><authors><author><keyname>Subramanian</keyname><forenames>Vinod</forenames></author><author><keyname>Benetos</keyname><forenames>Emmanouil</forenames></author><author><keyname>Xu</keyname><forenames>Ning</forenames></author><author><keyname>McDonald</keyname><forenames>SKoT</forenames></author><author><keyname>Sandler</keyname><forenames>Mark</forenames></author></authors><title>Adversarial Attacks in Sound Event Classification</title><categories>cs.LG cs.CR cs.SD eess.AS</categories><comments>Fixed Freesound data reference to FSDKaggle2018</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Adversarial attacks refer to a set of methods that perturb the input to a
classification model in order to fool the classifier. In this paper we apply
different gradient based adversarial attack algorithms on five deep learning
models trained for sound event classification. Four of the models use
mel-spectrogram input and one model uses raw audio input. The models represent
standard architectures such as convolutional, recurrent and dense networks. The
dataset used for training is the Freesound dataset released for task 2 of the
DCASE 2018 challenge and the models used are from participants of the challenge
who open sourced their code. Our experiments show that adversarial attacks can
be generated with high confidence and low perturbation. In addition, we show
that the adversarial attacks are very effective across the different models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02479</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02479</id><created>2019-07-04</created><authors><author><keyname>Klimkov</keyname><forenames>Viacheslav</forenames></author><author><keyname>Ronanki</keyname><forenames>Srikanth</forenames></author><author><keyname>Rohnke</keyname><forenames>Jonas</forenames></author><author><keyname>Drugman</keyname><forenames>Thomas</forenames></author></authors><title>Fine-grained robust prosody transfer for single-speaker neural
  text-to-speech</title><categories>eess.AS cs.CL</categories><comments>5 pages, 7 figures, Accepted for Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a neural text-to-speech system for fine-grained prosody transfer
from one speaker to another. Conventional approaches for end-to-end prosody
transfer typically use either fixed-dimensional or variable-length prosody
embedding via a secondary attention to encode the reference signal. However,
when trained on a single-speaker dataset, the conventional prosody transfer
systems are not robust enough to speaker variability, especially in the case of
a reference signal coming from an unseen speaker. Therefore, we propose
decoupling of the reference signal alignment from the overall system. For this
purpose, we pre-compute phoneme-level time stamps and use them to aggregate
prosodic features per phoneme, injecting them into a sequence-to-sequence
text-to-speech system. We incorporate a variational auto-encoder to further
enhance the latent representation of prosody embeddings. We show that our
proposed approach is significantly more stable and achieves reliable prosody
transplantation from an unseen speaker. We also propose a solution to the use
case in which the transcription of the reference signal is absent. We evaluate
all our proposed methods using both objective and subjective listening tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02484</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02484</id><created>2019-07-04</created><authors><author><keyname>Reddy</keyname><forenames>Yeduri Sreenivasa</forenames></author><author><keyname>Dubey</keyname><forenames>Ankit</forenames></author><author><keyname>Kumar</keyname><forenames>Abhinav</forenames></author><author><keyname>Panigrahi</keyname><forenames>Trilochan</forenames></author></authors><title>A Probabilistic Approach to Model SIC based RACH mechanism for Massive
  Machine Type Communications in Cellular Networks</title><categories>cs.NI eess.SP</categories><comments>12 pages, 11 figures, under review with IEEE Transaction on Vehicular
  Technology with paper number (VT-2019-00387)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a cellular Internet of Things, burst transmissions from millions of
machine type communications (MTC) devices can result in channel congestion. The
main bottleneck in such scenario is inefficient random access channel (RACH)
mechanism that is used to attach MTC devices to a base station (BS). To address
this issue of congestion in RACH mechanism, 3GPP has proposed an extended
access barring (3GPP-EAB) mechanism. However, several works indicate that the
performance of the 3GPP-EAB mechanism can be further improved. In this work, a
successive interference cancellation (SIC) based RACH mechanism is considered
to significantly increase the success rate and reduce congestion. In the
proposed mechanism, the devices are allowed to transmit repeatedly for a finite
number of times in a given cycle, and thereafter, the success rate is improved
by applying back-and-forth SIC at the BS. A novel probabilistic approach of the
proposed mechanism is presented with all transition and steady-state
probabilities. Further, the probability of SIC for a given slot is derived.
Through extensive numerical results, it is shown that the proposed mechanism
significantly outperforms the existing ones in terms of the success rate.
Moreover, to obtain the maximum success rate, the optimum number of devices to
be entered in a cycle is also calculated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02511</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02511</id><created>2019-07-04</created><authors><author><keyname>Tsiligianni</keyname><forenames>Evaggelia</forenames></author><author><keyname>Deligiannis</keyname><forenames>Nikos</forenames></author></authors><title>Deep Coupled-Representation Learning for Sparse Linear Inverse Problems
  with Side Information</title><categories>cs.LG eess.SP stat.ML</categories><comments>6 pages, 4 figures</comments><doi>10.1109/LSP.2019.2929869</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In linear inverse problems, the goal is to recover a target signal from
undersampled, incomplete or noisy linear measurements. Typically, the recovery
relies on complex numerical optimization methods; recent approaches perform an
unfolding of a numerical algorithm into a neural network form, resulting in a
substantial reduction of the computational complexity. In this paper, we
consider the recovery of a target signal with the aid of a correlated signal,
the so-called side information (SI), and propose a deep unfolding model that
incorporates SI. The proposed model is used to learn coupled representations of
correlated signals from different modalities, enabling the recovery of
multimodal data at a low computational cost. As such, our work introduces the
first deep unfolding method with SI, which actually comes from a different
modality. We apply our model to reconstruct near-infrared images from
undersampled measurements given RGB images as SI. Experimental results
demonstrate the superior performance of the proposed framework against
single-modal deep learning methods that do not use SI, multimodal deep learning
designs, and optimization algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02514</identifier>
 <datestamp>2019-07-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02514</id><created>2019-07-03</created><authors><author><keyname>Borcea</keyname><forenames>Liliana</forenames></author><author><keyname>Garnier</keyname><forenames>Josselin</forenames></author></authors><title>High-Resolution Interferometric Synthetic Aperture Imaging in scattering
  media</title><categories>eess.IV eess.SP</categories><comments>20 pages, 5 figures</comments><msc-class>35Q93, 58J90, 45Q05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of synthetic aperture imaging is to estimate the reflectivity of a
remote region of interest by processing data gathered with a moving sensor
which emits periodically a signal and records the backscattered wave. We
introduce and analyze a high-resolution interferometric method for synthetic
aperture imaging through an unknown scattering medium which distorts the wave.
The method builds on the coherent interferometric (CINT) approach which uses
empirical cross-correlations of the measurements to mitigate the distortion, at
the expense of a loss of resolution of the image. The new method shows that,
while mitigating the wave distortion, it is possible to obtain a robust and
sharp estimate of the modulus of the Fourier transform of the reflectivity
function. A high-resolution image can then be obtained by a phase retrieval
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02526</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02526</id><created>2019-07-03</created><authors><author><keyname>Mamun</keyname><forenames>Nursadul</forenames></author><author><keyname>Khorram</keyname><forenames>Soheil</forenames></author><author><keyname>Hansen</keyname><forenames>John H. L.</forenames></author></authors><title>Convolutional Neural Network-based Speech Enhancement for Cochlear
  Implant Recipients</title><categories>cs.SD cs.LG eess.AS</categories><comments>Interspeech 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Attempts to develop speech enhancement algorithms with improved speech
intelligibility for cochlear implant (CI) users have met with limited success.
To improve speech enhancement methods for CI users, we propose to perform
speech enhancement in a cochlear filter-bank feature space, a feature-set
specifically designed for CI users based on CI auditory stimuli. We leverage a
convolutional neural network (CNN) to extract both stationary and
non-stationary components of environmental acoustics and speech. We propose
three CNN architectures: (1) vanilla CNN that directly generates the enhanced
signal; (2) spectral-subtraction-style CNN (SS-CNN) that first predicts noise
and then generates the enhanced signal by subtracting noise from the noisy
signal; (3) Wiener-style CNN (Wiener-CNN) that generates an optimal mask for
suppressing noise. An important problem of the proposed networks is that they
introduce considerable delays, which limits their real-time application for CI
users. To address this, this study also considers causal variations of these
networks. Our experiments show that the proposed networks (both causal and
non-causal forms) achieve significant improvement over existing baseline
systems. We also found that causal Wiener-CNN outperforms other networks, and
leads to the best overall envelope coefficient measure (ECM). The proposed
algorithms represent a viable option for implementation on the CCi-MOBILE
research platform as a pre-processor for CI users in naturalistic environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02559</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02559</id><created>2019-07-04</created><authors><author><keyname>Dam</keyname><forenames>Shimul K</forenames></author><author><keyname>John</keyname><forenames>Vinod</forenames></author></authors><title>A Soft-switched Fast Cell-to-Cell Voltage Equalizer for Electrochemical
  Energy Storage</title><categories>eess.SY cs.SY</categories><comments>15 pages, 20 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Batteries are connected in series to meet the voltage requirement in many
applications. A voltage equalizer circuit is necessary to ensure that none of
the batteries is over-charged or over-discharged.
  A novel fast soft-switched cell-to-cell voltage equalizer topology is
proposed in this work. This topology can transfer charge from multiple
over-charged batteries to multiple under-charged batteries simultaneously
avoiding any unnecessary charging or discharging of a battery to achieve fast
voltage equalization. The proposed circuit topology and modulation method
ensure zero voltage switching under all battery conditions. The circuit
operation and soft-switching are analyzed and experimentally verified with a
four battery voltage equalizer prototype. The prototype is tested with a
battery bank and a hybrid ultra-capacitor bank, and a high conversion
efficiency is verified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02567</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02567</id><created>2019-07-04</created><authors><author><keyname>Lu</keyname><forenames>Jen-Tang</forenames></author><author><keyname>Brooks</keyname><forenames>Rupert</forenames></author><author><keyname>Hahn</keyname><forenames>Stefan</forenames></author><author><keyname>Chen</keyname><forenames>Jin</forenames></author><author><keyname>Buch</keyname><forenames>Varun</forenames></author><author><keyname>Kotecha</keyname><forenames>Gopal</forenames></author><author><keyname>Andriole</keyname><forenames>Katherine P.</forenames></author><author><keyname>Ghoshhajra</keyname><forenames>Brian</forenames></author><author><keyname>Pinto</keyname><forenames>Joel</forenames></author><author><keyname>Vozila</keyname><forenames>Paul</forenames></author><author><keyname>Michalski</keyname><forenames>Mark</forenames></author><author><keyname>Tenenholtz</keyname><forenames>Neil A.</forenames></author></authors><title>DeepAAA: clinically applicable and generalizable detection of abdominal
  aortic aneurysm using deep learning</title><categories>eess.IV cs.CV</categories><comments>Accepted for publication at MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a deep learning-based technique for detection and quantification
of abdominal aortic aneurysms (AAAs). The condition, which leads to more than
10,000 deaths per year in the United States, is asymptomatic, often detected
incidentally, and often missed by radiologists. Our model architecture is a
modified 3D U-Net combined with ellipse fitting that performs aorta
segmentation and AAA detection. The study uses 321 abdominal-pelvic CT
examinations performed by Massachusetts General Hospital Department of
Radiology for training and validation. The model is then further tested for
generalizability on a separate set of 57 examinations with differing patient
demographics and acquisition characteristics than the original dataset. DeepAAA
achieves high performance on both sets of data (sensitivity/specificity
0.91/0.95 and 0.85 / 1.0 respectively), on contrast and non-contrast CT scans
and works with image volumes with varying numbers of images. We find that
DeepAAA exceeds literature-reported performance of radiologists on incidental
AAA detection. It is expected that the model can serve as an effective
background detector in routine CT examinations to prevent incidental AAAs from
being missed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02576</identifier>
 <datestamp>2019-10-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02576</id><created>2019-07-04</created><updated>2019-07-08</updated><authors><author><keyname>Guerrero</keyname><forenames>Diego Barrag&#xe1;n</forenames></author><author><keyname>Au</keyname><forenames>Minh</forenames></author><author><keyname>Gagnon</keyname><forenames>Ghyslain</forenames></author><author><keyname>Gagnon</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Giard</keyname><forenames>Pascal</forenames></author></authors><title>Early Detection for Optimal-Latency Communications in Multi-Hop Links</title><categories>cs.IT eess.SP math.IT</categories><comments>6 pages, to be presented at the International Symposium on Wireless
  Communication Systems (ISWCS) 2019; Fixed some references</comments><doi>10.1109/ISWCS.2019.8877294</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern wireless machine-to-machine-type communications aim to provide both
ultra reliability and low latency, stringent requirements that appear to be
mutually exclusive. From the noisy channel coding theorem, we know that
reliable communications mandate transmission rates that are lower than the
channel capacity. To guarantee arbitrarily-low error probability, this implies
the use of messages whose lengths tend to infinity. However, long messages are
not suitable for low-latency communications. In this paper, we propose an
early-detection scheme for wireless communications under a finite-blocklength
regime that employs a sequential-test technique to reduce latency while
maintaining reliability. We prove that our scheme leads to an average detection
time smaller than the symbol duration. Furthermore, in multi-hop low-traffic or
continuous-transmission links, we show that our scheme can reliably detect
symbols before the end of their transmission, significantly reducing the
latency, while keeping the error probability below a predefined threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02585</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02585</id><created>2019-07-04</created><updated>2019-07-25</updated><authors><author><keyname>Fouda</keyname><forenames>Abdurrahman</forenames></author><author><keyname>Ibrahim</keyname><forenames>Ahmed S.</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Ghosh</keyname><forenames>Monisha</forenames></author></authors><title>Interference Management in UAV-assisted Integrated Access and Backhaul
  Cellular Networks</title><categories>eess.SP</categories><comments>IEEE Access, Jun. 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An integrated access and backhaul (IAB) network architecture can enable
flexible and fast deployment of next-generation cellular networks. However,
mutual interference between access and backhaul links, small inter-site
distance and spatial dynamics of user distribution pose major challenges in the
practical deployment of IAB networks. To tackle these problems, we leverage the
flying capabilities of unmanned aerial vehicles (UAVs) as hovering IAB-nodes
and propose an interference management algorithm to maximize the overall sum
rate of the IAB network. In particular, we jointly optimize the user and base
station associations, the downlink power allocations for access and backhaul
transmissions, and the spatial configurations of UAVs. We consider two spatial
configuration modes of UAVs: distributed UAVs and drone antenna array (DAA),
and show how they are intertwined with the spatial distribution of ground
users. Our numerical results show that the proposed algorithm achieves an
average of $2.9\times$ and $6.7\times$ gains in the received downlink
signal-to-interference-plus-noise ratio (SINR) and overall network sum rate,
respectively. Finally, the numerical results reveal that UAVs cannot only be
used for coverage improvement but also for capacity boosting in IAB cellular
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02589</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02589</id><created>2019-06-30</created><authors><author><keyname>Elnashar</keyname><forenames>Ayman</forenames></author></authors><title>IoT evolution towards a super-connected world</title><categories>eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1606.04171 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet of Things (IoT) is one of the key components of Digital
Transformation, along with big data and analytics. IoT, together with the
cloud, big data, analytics, machine learning (ML), and deep ML, can help create
numerous possibilities and new opportunities. These possibilities will impact
our daily lives substantially and open new business models for consumers and
enterprises where the number of connected IoT devices could go up to 50 Billion
by 2022. The ecosystem of IoT consists mainly of sensors/devices layer,
connectivity layer and IoT platform. The main value of IoT is in creating use
cases for efficiency, monitoring and management of the things/devices. IoT
connects the things through the Internet to the IoT platform which equipped
with device management and with the possibility of creating new use cases along
with data analytics and ML that provide 360 view through data insight
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02595</identifier>
 <datestamp>2019-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02595</id><created>2019-07-02</created><updated>2019-12-12</updated><authors><author><keyname>Mazur</keyname><forenames>Mikael</forenames></author><author><keyname>Fontaine</keyname><forenames>Nicolas K.</forenames></author><author><keyname>Chen</keyname><forenames>Haoshuo</forenames></author><author><keyname>Ryf</keyname><forenames>Roland</forenames></author><author><keyname>Neilson</keyname><forenames>David T.</forenames></author><author><keyname>Raybon</keyname><forenames>Gregory</forenames></author><author><keyname>Adamiecki</keyname><forenames>Andrew</forenames></author><author><keyname>Corteselli</keyname><forenames>Steve</forenames></author><author><keyname>Schr&#xf6;der</keyname><forenames>Jochen</forenames></author></authors><title>Multi-wavelength arbitrary waveform generation through spectro-temporal
  unitary transformations</title><categories>eess.SP physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Temporal waveform manipulation is a fundamental functionality in optics and
crucial for applications like optical communications, microwave photonics and
quantum optics. Traditional IQ- or phase-amplitude modulators shape light by
carving energy from the input lightwave and are thus fundamentally lossy, and
cannot apply independent modulation to multiple input wavelengths
simultaneously. Taking inspiration from the space-time duality, we produce
arbitrary unitary spectro-temporal transformations on multiple temporal input
vectors with a modulation structure comprising of only lossless phase
modulation and dispersive allpass filtering. The bandwidth of the output
waveforms is not restricted by the driving electronics and independent
transformations can be performed simultaneously on multiple orthogonal inputs
such as spectrally separated frequency tones. This overcomes the main
limitations of traditional electro-optic modulators and offers fundamental new
insight into temporal wave manipulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02596</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02596</id><created>2019-07-03</created><authors><author><keyname>Chahid</keyname><forenames>Abderrazak</forenames></author><author><keyname>Albalawi</keyname><forenames>Fahad</forenames></author><author><keyname>Alotaiby</keyname><forenames>Turky Nayef</forenames></author><author><keyname>Al-Hameed</keyname><forenames>Majed Hamad</forenames></author><author><keyname>Alshebeili</keyname><forenames>Saleh</forenames></author><author><keyname>Laleg-Kirati</keyname><forenames>Taous-Meriem</forenames></author></authors><title>QuPWM: Feature Extraction Method for MEG Epileptic Spike Detection</title><categories>eess.SP cs.LG q-bio.NC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Epilepsy is a neurological disorder classified as the second most serious
neurological disease known to humanity, after stroke. Localization of the
epileptogenic zone is an important step for epileptic patient treatment, which
starts with epileptic spike detection. The common practice for spike detection
of brain signals is via visual scanning of the recordings, which is a
subjective and a very time-consuming task. Motivated by that, this paper
focuses on using machine learning for automatic detection of epileptic spikes
in magnetoencephalography (MEG) signals. First, we used the Position Weight
Matrix (PWM) method combined with a uniform quantizer to generate useful
features. Second, the extracted features are classified using a Support Vector
Machine (SVM) for the purpose of epileptic spikes detection. The proposed
technique shows great potential in improving the spike detection accuracy and
reducing the feature vector size. Specifically, the proposed technique achieved
average accuracy up to 98\% in using 5-folds cross-validation applied to a
balanced dataset of 3104 samples. These samples are extracted from 16 subjects
where eight are healthy and eight are epileptic subjects using a sliding frame
of size of 100 samples-points with a step-size of 2 sample-points
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02602</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02602</id><created>2019-07-04</created><authors><author><keyname>Singhal</keyname><forenames>Parth</forenames></author><author><keyname>Masih</keyname><forenames>Siddharth</forenames></author></authors><title>MetaAnalysis of Methods for Scaling Blockchain Technology for Automotive
  Uses</title><categories>cs.CR cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The automotive industry has seen an increased need for connectivity, both as
a result of the advent of autonomous driving and the rise of connected cars and
truck fleets. This shift has led to issues such as trusted coordination and a
wider attack surface have come to light, leading to higher costs and
bureaucratic interventions. Due to the increasing adoption of connected
vehicles, as well as other connected infrastructure, trustless peer to peer
systems including blockchain are being explored as potential solution to this
efficiency problem. All the while, scalability is still a significant concern
for industry players. Current blockchain based systems have difficulty scaling:
Bitcoin can only process seven transactions per second (tx/s) whereas
Ethereum's fifteen tx/s is not a major improvement. Combined with the high cost
of consensus and low throughput, such platforms are unusable with the mobility
sector. This paper will address the latest advances in the field that aim to
resolve parts of this problem as well as inform its readers about the
scalability technologies that could push blockchain automotive infrastructure
into the mainstream. This paper will also introduce the theoretical tools and
advancements that, if implemented, could bring the mobility industry closer
toward adopting efficient, scalable, and cost effective decentralized
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02603</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02603</id><created>2019-07-04</created><authors><author><keyname>Perez</keyname><forenames>Alberto</forenames></author><author><keyname>Fouda</keyname><forenames>Abdurrahman</forenames></author><author><keyname>Ibrahim</keyname><forenames>Ahmed S.</forenames></author></authors><title>Ray Tracing Analysis for UAV-assisted Integrated Access and Backhaul
  Millimeter Wave Networks</title><categories>eess.SP</categories><comments>in Proc. IEEE WoWMoM Workshop Wireless Netw. Planning Comput. UAV
  Swarms, Washington, DC, USA, Jun.2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of Millimeter-wave (mmWave) spectrum in cellular communications has
recently attracted growing interest to support the expected massive increase in
traffic demands. However, the high path-loss at mmWave frequencies poses severe
challenges. In this paper, we analyze the potential coverage gains of using
unmanned aerial vehicles (UAVs), as hovering relays, in integrated access and
backhaul (IAB) mmWave cellular scenarios. Specifically, we utilize the WinProp
software package, which employs ray tracing methodology, to study the
propagation characteristics of outdoor mmWave channels at 30 and 60 GHz
frequency bands in a Manhattan-like environment. In doing so, we propose the
implementation of amplify-and-forward (AF) and decode-and-forward (DF) relaying
mechanisms in the WinProp software. We show how the 3D deployment of UAVs can
be defined based on the coverage ray tracing maps at access and backhaul links.
Furthermore, we propose an adaptive UAV transmission power for the AF relaying.
We demonstrate, with the aid of ray tracing simulations, the performance gains
of the proposed relaying modes in terms of downlink coverage, and the received
signal to interference and noise ratio (SINR).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02622</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02622</id><created>2019-07-04</created><authors><author><keyname>Ahmadzadeh</keyname><forenames>Armin</forenames></author><author><keyname>Hajihassani</keyname><forenames>Omid</forenames></author><author><keyname>Taheri</keyname><forenames>Pooria</forenames></author><author><keyname>Khasteh</keyname><forenames>Seyed Hossein</forenames></author></authors><title>Low-power and Reliable Solid-state Drive with Inverted Limited Weight
  Coding</title><categories>cs.IT eess.SP math.IT</categories><comments>14 pages, 20 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a novel coding scheme which based on the
characteristics of NAND flash cells, generates codewords that reduce the energy
consumption and improve the reliability of solid-state drives. This novel
coding scheme, namely Inverted Limited Weight Coding (ILWC), favors a greater
number of '1's appearing in its generated codewords at the cost of added
information redundancy, as a form of flag bits. This increase in the number of
bits valued as logical '1', in the generated codewords, will increase the
number of cells that have lower threshold voltages. Through cells with lower
threshold voltages, ILWC fruitfully reduces the SSD's program operation energy
consumption. Moreover, it increases the SSD's data retention rate and
reliability by decreasing the threshold voltage of the cells. The evaluation of
our proposed coding method on three different SSDs, indicates more than 20%
reduction in the SSD's program operation energy consumption. In addition, ILWC
improves the cells' data retention rate by decreasing their intrinsic electric
field by more than 18%. Moreover, the SSD's cell-to-cell coupling noise is
diminished with the help of 35% reduction in the worst-case threshold voltage
shift in a cell's adjacent cells. All this leads to 5.3% reduction in the MLC's
cell error rate. In addition, ILWC achieves 37.5% improvement in the
performance of the SSD program operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02634</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02634</id><created>2019-07-04</created><authors><author><keyname>Siegel</keyname><forenames>Joshua E.</forenames></author><author><keyname>Beemer</keyname><forenames>Maria F.</forenames></author><author><keyname>Shepard</keyname><forenames>Steven M.</forenames></author></authors><title>Automated Non-Destructive Inspection of Fused Filament Fabrication
  Components Using Thermographic Signal Reconstruction</title><categories>eess.IV cs.CV</categories><doi>10.1016/j.addma.2019.100923</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manufacturers struggle to produce low-cost, robust and complex components at
manufacturing lot-size one. Additive processes like Fused Filament Fabrication
(FFF) inexpensively produce complex geometries, but defects limit viability in
critical applications. We present an approach to high-accuracy, high-throughput
and low-cost automated non-destructive testing (NDT) for FFF interlayer
delamination using Flash Thermography (FT) data processed with Thermographic
Signal Reconstruction (TSR) and Artificial Intelligence (AI). A Deep Neural
Network (DNN) attains 95.4% per-pixel accuracy when differentiating four
delamination thicknesses 5mm subsurface in PolyLactic Acid (PLA) widgets, and
98.6% accuracy in differentiating acceptable from unacceptable condition for
the same components. Automated inspection enables time- and cost-efficient 100%
inspection for delamination defects, supporting FFF's use in critical and
small-batch applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02637</identifier>
 <datestamp>2019-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02637</id><created>2019-07-04</created><updated>2019-11-13</updated><authors><author><keyname>Aouameur</keyname><forenames>Cyran</forenames></author><author><keyname>Esling</keyname><forenames>Philippe</forenames></author><author><keyname>Hadjeres</keyname><forenames>Ga&#xeb;tan</forenames></author></authors><title>Neural Drum Machine : An Interactive System for Real-time Synthesis of
  Drum Sounds</title><categories>cs.SD cs.LG eess.AS</categories><comments>8 pages, accepted at the International Conference on Computational
  Creativity 2019</comments><msc-class>68T99</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this work, we introduce a system for real-time generation of drum sounds.
This system is composed of two parts: a generative model for drum sounds
together with a Max4Live plugin providing intuitive controls on the generative
process. The generative model consists of a Conditional Wasserstein autoencoder
(CWAE), which learns to generate Mel-scaled magnitude spectrograms of short
percussion samples, coupled with a Multi-Head Convolutional Neural Network
(MCNN) which estimates the corresponding audio signal from the magnitude
spectrogram. The design of this model makes it lightweight, so that it allows
one to perform real-time generation of novel drum sounds on an average CPU,
removing the need for the users to possess dedicated hardware in order to use
this system. We then present our Max4Live interface designed to interact with
this generative model. With this setup, the system can be easily integrated
into a studio-production environment and enhance the creative process. Finally,
we discuss the advantages of our system and how the interaction of music
producers with such tools could change the way drum tracks are composed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02642</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02642</id><created>2019-07-03</created><authors><author><keyname>Shukla</keyname><forenames>Ankita</forenames></author><author><keyname>Cheema</keyname><forenames>Gullal Singh</forenames></author><author><keyname>Anand</keyname><forenames>Saket</forenames></author><author><keyname>Qureshi</keyname><forenames>Qamar</forenames></author><author><keyname>Jhala</keyname><forenames>Yadvendradev</forenames></author></authors><title>Primate Face Identification in the Wild</title><categories>cs.CV eess.IV</categories><comments>arXiv admin note: text overlap with arXiv:1811.00743</comments><journal-ref>PRICAI 2019, The 16th Pacific Rim International Conference on
  Artificial Intelligence</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ecological imbalance owing to rapid urbanization and deforestation has
adversely affected the population of several wild animals. This loss of habitat
has skewed the population of several non-human primate species like chimpanzees
and macaques and has constrained them to co-exist in close proximity of human
settlements, often leading to human-wildlife conflicts while competing for
resources. For effective wildlife conservation and conflict management, regular
monitoring of population and of conflicted regions is necessary. However,
existing approaches like field visits for data collection and manual analysis
by experts is resource intensive, tedious and time consuming, thus
necessitating an automated, non-invasive, more efficient alternative like image
based facial recognition. The challenge in individual identification arises due
to unrelated factors like pose, lighting variations and occlusions due to the
uncontrolled environments, that is further exacerbated by limited training
data. Inspired by human perception, we propose to learn representations that
are robust to such nuisance factors and capture the notion of similarity over
the individual identity sub-manifolds. The proposed approach, Primate Face
Identification (PFID), achieves this by training the network to distinguish
between positive and negative pairs of images. The PFID loss augments the
standard cross entropy loss with a pairwise loss to learn more discriminative
and generalizable features, thus making it appropriate for other related
identification tasks like open-set, closed set and verification. We report
state-of-the-art accuracy on facial recognition of two primate species, rhesus
macaques and chimpanzees under the four protocols of classification,
verification, closed-set identification and open-set recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02644</identifier>
 <datestamp>2020-02-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02644</id><created>2019-07-04</created><updated>2020-01-31</updated><authors><author><keyname>Quiros</keyname><forenames>Adalberto Claudio</forenames></author><author><keyname>Murray-Smith</keyname><forenames>Roderick</forenames></author><author><keyname>Yuan</keyname><forenames>Ke</forenames></author></authors><title>Pathology GAN: Learning deep representations of cancer tissue</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply Generative Adversarial Networks (GANs) to the domain of digital
pathology. Current machine learning research for digital pathology focuses on
diagnosis, but we suggest a different approach and advocate that generative
models could drive forward the understanding of morphological characteristics
of cancer tissue. In this paper, we develop a framework which allows GANs to
capture key tissue features and uses these characteristics to give structure to
its latent space. To this end, we trained our model on 249K H&amp;E breast cancer
tissue images. We show that our model generates high quality images, with a
Frechet Inception Distance (FID) of 16.65. We additionally assess the quality
of the images with cancer tissue characteristics (e.g. count of cancer,
lymphocytes, or stromal cells), using quantitative information to calculate the
FID and showing consistent performance of 9.86. Additionally, the latent space
of our model shows an interpretable structure and allows semantic vector
operations that translate into tissue feature transformations. Furthermore,
ratings from two expert pathologists found no significant difference between
our generated tissue images from real ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02648</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02648</id><created>2019-07-03</created><authors><author><keyname>Le</keyname><forenames>Mai T. P.</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Di Benedetto</keyname><forenames>Maria-Gabriella</forenames></author></authors><title>What is the Benefit of Code-domain NOMA in Massive MIMO?</title><categories>cs.IT eess.SP math.IT</categories><comments>To appear at the 2019 IEEE International Symposium on Personal,
  Indoor and Mobile Radio Communications (IEEE PIMRC 2019), 5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In overloaded Massive MIMO systems, wherein the number K of user equipments
(UEs) exceeds the number of base station antennas M, it has recently been shown
that non-orthogonal multiple access (NOMA) can increase performance. This paper
aims at identifying cases of the classical operating regime K &lt; M, where
code-domain NOMA can also improve the spectral efficiency of Massive MIMO.
Particular attention is given to use cases in which poor favorable propagation
conditions are experienced. Numerical results show that Massive MIMO with
planar antenna arrays can benefit from NOMA in practical scenarios where the
UEs are spatially close to each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02663</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02663</id><created>2019-07-04</created><authors><author><keyname>Cai</keyname><forenames>Weicheng</forenames></author><author><keyname>Wu</keyname><forenames>Haiwei</forenames></author><author><keyname>Cai</keyname><forenames>Danwei</forenames></author><author><keyname>Li</keyname><forenames>Ming</forenames></author></authors><title>The DKU Replay Detection System for the ASVspoof 2019 Challenge: On Data
  Augmentation, Feature Representation, Classification, and Fusion</title><categories>eess.AS cs.CR cs.LG cs.MM cs.SD</categories><comments>Accepted for INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes our DKU replay detection system for the ASVspoof 2019
challenge. The goal is to develop spoofing countermeasure for automatic speaker
recognition in physical access scenario. We leverage the countermeasure system
pipeline from four aspects, including the data augmentation, feature
representation, classification, and fusion. First, we introduce an
utterance-level deep learning framework for anti-spoofing. It receives the
variable-length feature sequence and outputs the utterance-level scores
directly. Based on the framework, we try out various kinds of input feature
representations extracted from either the magnitude spectrum or phase spectrum.
Besides, we also perform the data augmentation strategy by applying the speed
perturbation on the raw waveform. Our best single system employs a residual
neural network trained by the speed-perturbed group delay gram. It achieves EER
of 1.04% on the development set, as well as EER of 1.08% on the evaluation set.
Finally, using the simple average score from several single systems can further
improve the performance. EER of 0.24% on the development set and 0.66% on the
evaluation set is obtained for our primary system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02665</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02665</id><created>2019-07-04</created><authors><author><keyname>Zhang</keyname><forenames>Weixia</forenames></author><author><keyname>Ma</keyname><forenames>Kede</forenames></author><author><keyname>Yan</keyname><forenames>Jia</forenames></author><author><keyname>Deng</keyname><forenames>Dexiang</forenames></author><author><keyname>Wang</keyname><forenames>Zhou</forenames></author></authors><title>Blind Image Quality Assessment Using A Deep Bilinear Convolutional
  Neural Network</title><categories>eess.IV cs.CV cs.MM</categories><doi>10.1109/TCSVT.2018.2886771</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a deep bilinear model for blind image quality assessment (BIQA)
that handles both synthetic and authentic distortions. Our model consists of
two convolutional neural networks (CNN), each of which specializes in one
distortion scenario. For synthetic distortions, we pre-train a CNN to classify
image distortion type and level, where we enjoy large-scale training data. For
authentic distortions, we adopt a pre-trained CNN for image classification. The
features from the two CNNs are pooled bilinearly into a unified representation
for final quality prediction. We then fine-tune the entire model on target
subject-rated databases using a variant of stochastic gradient descent.
Extensive experiments demonstrate that the proposed model achieves superior
performance on both synthetic and authentic databases. Furthermore, we verify
the generalizability of our method on the Waterloo Exploration Database using
the group maximum differentiation competition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02670</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02670</id><created>2019-07-05</created><authors><author><keyname>Choi</keyname><forenames>Jeong</forenames></author><author><keyname>Lee</keyname><forenames>Jongpil</forenames></author><author><keyname>Park</keyname><forenames>Jiyoung</forenames></author><author><keyname>Nam</keyname><forenames>Juhan</forenames></author></authors><title>Zero-shot Learning for Audio-based Music Classification and Tagging</title><categories>cs.LG cs.MM cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audio-based music classification and tagging is typically based on
categorical supervised learning with a fixed set of labels. This intrinsically
cannot handle unseen labels such as newly added music genres or semantic words
that users arbitrarily choose for music retrieval. Zero-shot learning can
address this problem by leveraging an additional semantic space of labels where
side information about the labels is used to unveil the relationship between
each other. In this work, we investigate the zero-shot learning in the music
domain and organize two different setups of side information. One is using
human-labeled attribute information based on Free Music Archive and
OpenMIC-2018 datasets. The other is using general word semantic information
based on Million Song Dataset and Last.fm tag annotations. Considering a music
track is usually multi-labeled in music classification and tagging datasets, we
also propose a data split scheme and associated evaluation settings for the
multi-label zero-shot learning. Finally, we report experimental results and
discuss the effectiveness and new possibilities of zero-shot learning in the
music domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02674</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02674</id><created>2019-07-05</created><authors><author><keyname>Golder</keyname><forenames>Anupam</forenames></author><author><keyname>Das</keyname><forenames>Debayan</forenames></author><author><keyname>Danial</keyname><forenames>Josef</forenames></author><author><keyname>Ghosh</keyname><forenames>Santosh</forenames></author><author><keyname>Sen</keyname><forenames>Shreyas</forenames></author><author><keyname>Raychowdhury</keyname><forenames>Arijit</forenames></author></authors><title>Practical Approaches Towards Deep-Learning Based Cross-Device Power Side
  Channel Attack</title><categories>eess.SP</categories><comments>Article has been accepted for Publication in IEEE Transactions for
  VLSI Systems</comments><doi>10.1109/TVLSI.2019.2926324</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power side-channel analysis (SCA) has been of immense interest to most
embedded designers to evaluate the physical security of the system. This work
presents profiling-based cross-device power SCA attacks using deep learning
techniques on 8-bit AVR microcontroller devices running AES-128. Firstly, we
show the practical issues that arise in these profiling-based cross-device
attacks due to significant device-to-device variations. Secondly, we show that
utilizing Principal Component Analysis (PCA) based pre-processing and
multi-device training, a Multi-Layer Perceptron (MLP) based 256-class
classifier can achieve an average accuracy of 99.43% in recovering the first
key byte from all the 30 devices in our data set, even in the presence of
significant inter-device variations. Results show that the designed MLP with
PCA-based pre-processing outperforms a Convolutional Neural Network (CNN) with
4-device training by ~20%in terms of the average test accuracy of cross-device
attack for the aligned traces captured using the ChipWhisperer
hardware.Finally, to extend the practicality of these cross-device attacks,
another pre-processing step, namely, Dynamic Time Warping (DTW) has been
utilized to remove any misalignment among the traces, before performing PCA.
DTW along with PCA followed by the 256-class MLP classifier provides &gt;=10.97%
higher accuracy than the CNN based approach for cross-device attack even in the
presence of up to 50 time-sample misalignments between the traces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02696</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02696</id><created>2019-07-05</created><authors><author><keyname>Bitar</keyname><forenames>Glenn</forenames></author><author><keyname>Vestad</keyname><forenames>Vegard N.</forenames></author><author><keyname>Lekkas</keyname><forenames>Anastasios M.</forenames></author><author><keyname>Breivik</keyname><forenames>Morten</forenames></author></authors><title>Warm-Started Optimized Trajectory Planning for ASVs</title><categories>eess.SY cs.RO cs.SY math.OC</categories><comments>Accepted to the 12th IFAC Conference on Control Applications in
  Marine Systems, Robotics, and Vehicles (CAMS 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider warm-started optimized trajectory planning for autonomous surface
vehicles (ASVs) by combining the advantages of two types of planners: an A*
implementation that quickly finds the shortest piecewise linear path, and an
optimal control-based trajectory planner. A nonlinear 3-degree-of-freedom
underactuated model of an ASV is considered, along with an objective functional
that promotes energy-efficient and readily observable maneuvers. The A*
algorithm is guaranteed to find the shortest piecewise linear path to the goal
position based on a uniformly decomposed map. Dynamic information is
constructed and added to the A*-generated path, and provides an initial guess
for warm starting the optimal control-based planner. The run time for the
optimal control planner is greatly reduced by this initial guess and outputs a
dynamically feasible and locally optimal trajectory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02698</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02698</id><created>2019-07-05</created><authors><author><keyname>Park</keyname><forenames>Jonggwon</forenames></author><author><keyname>Choi</keyname><forenames>Kyoyun</forenames></author><author><keyname>Jeon</keyname><forenames>Sungwook</forenames></author><author><keyname>Kim</keyname><forenames>Dokyun</forenames></author><author><keyname>Park</keyname><forenames>Jonghun</forenames></author></authors><title>A Bi-directional Transformer for Musical Chord Recognition</title><categories>cs.SD cs.LG eess.AS</categories><comments>20th International Society for Music Information Retrieval Conference
  (ISMIR), Delft, The Netherlands, 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Chord recognition is an important task since chords are highly abstract and
descriptive features of music. For effective chord recognition, it is essential
to utilize relevant context in audio sequence. While various machine learning
models such as convolutional neural networks (CNNs) and recurrent neural
networks (RNNs) have been employed for the task, most of them have limitations
in capturing long-term dependency or require training of an additional model.
In this work, we utilize a self-attention mechanism for chord recognition to
focus on certain regions of chords. Training of the proposed bi-directional
Transformer for chord recognition (BTC) consists of a single phase while
showing competitive performance. Through an attention map analysis, we have
visualized how attention was performed. It turns out that the model was able to
divide segments of chords by utilizing adaptive receptive field of the
attention mechanism. Furthermore, it was observed that the model was able to
effectively capture long-term dependencies, making use of essential information
regardless of distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02699</identifier>
 <datestamp>2019-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02699</id><created>2019-07-05</created><updated>2019-10-16</updated><authors><author><keyname>Hu</keyname><forenames>Sha</forenames></author></authors><title>Spherical Large Intelligent Surfaces</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As an emerging technology and evolution that goes beyond massive multi-input
multi-output (MIMO), large intelligent surface (LIS) has gained much interest
recently. LIS acts as an electromagnetic surface and can transmit, redirect,
and receive radiating signals across its entire contiguous surface. It allows
for unprecedented energy-focusing, data-transmission and terminal-positioning,
and can fulfill the most grand visions for future communication systems.
Earlier proposed LISs are in two-dimensional (2D), i.e., planar shapes. In this
paper, we extend LIS to be three-dimensional (3D) and deployed as spherical
surfaces. Compared to 2D shapes, spherical LISs have advantages of wide
coverage, simple positioning techniques, and flexible deployments as
reflectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02742</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02742</id><created>2019-07-05</created><authors><author><keyname>Akram</keyname><forenames>Farhan</forenames></author><author><keyname>Singh</keyname><forenames>Vivek Kumar</forenames></author><author><keyname>Rashwan</keyname><forenames>Hatem A.</forenames></author><author><keyname>Abdel-Nasser</keyname><forenames>Mohamed</forenames></author><author><keyname>Sarker</keyname><forenames>Md. Mostafa Kamal</forenames></author><author><keyname>Pandey</keyname><forenames>Nidhi</forenames></author><author><keyname>Puig</keyname><forenames>Domenec</forenames></author></authors><title>Adversarial Learning with Multiscale Features and Kernel Factorization
  for Retinal Blood Vessel Segmentation</title><categories>eess.IV cs.CV</categories><comments>9 pages, 4 figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In this paper, we propose an efficient blood vessel segmentation method for
the eye fundus images using adversarial learning with multiscale features and
kernel factorization. In the generator network of the adversarial framework,
spatial pyramid pooling, kernel factorization and squeeze excitation block are
employed to enhance the feature representation in spatial domain on different
scales with reduced computational complexity. In turn, the discriminator
network of the adversarial framework is formulated by combining convolutional
layers with an additional squeeze excitation block to differentiate the
generated segmentation mask from its respective ground truth. Before feeding
the images to the network, we pre-processed them by using edge sharpening and
Gaussian regularization to reach an optimized solution for vessel segmentation.
The output of the trained model is post-processed using morphological
operations to remove the small speckles of noise. The proposed method
qualitatively and quantitatively outperforms state-of-the-art vessel
segmentation methods using DRIVE and STARE datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02766</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02766</id><created>2019-07-05</created><updated>2019-08-12</updated><authors><author><keyname>Ouyang</keyname><forenames>Cheng</forenames></author><author><keyname>Kamnitsas</keyname><forenames>Konstantinos</forenames></author><author><keyname>Biffi</keyname><forenames>Carlo</forenames></author><author><keyname>Duan</keyname><forenames>Jinming</forenames></author><author><keyname>Rueckert</keyname><forenames>Daniel</forenames></author></authors><title>Data Efficient Unsupervised Domain Adaptation for Cross-Modality Image
  Segmentation</title><categories>eess.IV cs.CV</categories><comments>Accepted by MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning models trained on medical images from a source domain (e.g.
imaging modality) often fail when deployed on images from a different target
domain, despite imaging common anatomical structures. Deep unsupervised domain
adaptation (UDA) aims to improve the performance of a deep neural network model
on a target domain, using solely unlabelled target domain data and labelled
source domain data. However, current state-of-the-art methods exhibit reduced
performance when target data is scarce. In this work, we introduce a new data
efficient UDA method for multi-domain medical image segmentation. The proposed
method combines a novel VAE-based feature prior matching, which is
data-efficient, and domain adversarial training to learn a shared
domain-invariant latent space which is exploited during segmentation. Our
method is evaluated on a public multi-modality cardiac image segmentation
dataset by adapting from the labelled source domain (3D MRI) to the unlabelled
target domain (3D CT). We show that by using only one single unlabelled 3D CT
scan, the proposed architecture outperforms the state-of-the-art in the same
setting. Finally, we perform ablation studies on prior matching and domain
adversarial training to shed light on the theoretical grounding of the proposed
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02779</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02779</id><created>2019-07-05</created><updated>2019-08-20</updated><authors><author><keyname>Han</keyname><forenames>Bin</forenames></author><author><keyname>Zhu</keyname><forenames>Yao</forenames></author><author><keyname>Jiang</keyname><forenames>Zhiyuan</forenames></author><author><keyname>hu</keyname><forenames>Yulin</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Optimal Blocklength Allocation towards Reduced Age of Information in
  Wireless Sensor Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted by IEEE GLOBECOM 2019 Workshop on Wireless Edge Intelligence
  on 19. August, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The freshness or timeliness of data at server is a significant key
performance indicator of sensor networks, especially in tolerance critical
applications such as factory automation. As an effective and intuitive
measurement to data timeliness, the metric of Age of Information (AoI) has
attracted an intensive recent interest of research. This paper initiates a
study on the AoI of wireless sensor networks working in the finite blocklength
(FBL) regime as a resource allocation problem, and proposes to minimize the
long-term discounted system AoI as a Markov decision process (MDP). The
proposed method with its optimum solved by Reinforced Learning technique is
verified by simulations to outperform benchmarks, including the conventional
error rate minimizing policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02784</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02784</id><created>2019-07-05</created><authors><author><keyname>Tits</keyname><forenames>No&#xe9;</forenames></author></authors><title>A Methodology for Controlling the Emotional Expressiveness in Synthetic
  Speech -- a Deep Learning approach</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this project, we aim to build a Text-to-Speech system able to produce
speech with a controllable emotional expressiveness. We propose a methodology
for solving this problem in three main steps. The first is the collection of
emotional speech data. We discuss the various formats of existing datasets and
their usability in speech generation. The second step is the development of a
system to automatically annotate data with emotion/expressiveness features. We
compare several techniques using transfer learning to extract such a
representation through other tasks and propose a method to visualize and
interpret the correlation between vocal and emotional features. The third step
is the development of a deep learning-based system taking text and
emotion/expressiveness as input and producing speech as output. We study the
impact of fine tuning from a neutral TTS towards an emotional TTS in terms of
intelligibility and perception of the emotion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02787</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02787</id><created>2019-07-05</created><updated>2019-08-30</updated><authors><author><keyname>Ravi</keyname><forenames>Daniele</forenames></author><author><keyname>Alexander</keyname><forenames>Daniel C.</forenames></author><author><keyname>Oxtoby</keyname><forenames>Neil P.</forenames></author></authors><title>Degenerative Adversarial NeuroImage Nets: Generating Images that Mimic
  Disease Progression</title><categories>eess.IV cs.AI cs.CV</categories><comments>Paper accepted for MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simulating images representative of neurodegenerative diseases is important
for predicting patient outcomes and for validation of computational models of
disease progression. This capability is valuable for secondary prevention
clinical trials where outcomes and screening criteria involve neuroimaging.
Traditional computational methods are limited by imposing a parametric model
for atrophy and are extremely resource-demanding. Recent advances in deep
learning have yielded data-driven models for longitudinal studies (e.g., face
ageing) that are capable of generating synthetic images in real-time. Similar
solutions can be used to model trajectories of atrophy in the brain, although
new challenges need to be addressed to ensure accurate disease progression
modelling. Here we propose Degenerative Adversarial NeuroImage Net (DaniNet)
--- a new deep learning approach that learns to emulate the effect of
neurodegeneration on MRI by simulating atrophy as a function of ages, and
disease progression. DaniNet uses an underlying set of Support Vector
Regressors (SVRs) trained to capture the patterns of regional intensity changes
that accompany disease progression. DaniNet produces whole output images,
consisting of 2D-MRI slices that are constrained to match regional predictions
from the SVRs. DaniNet is also able to maintain the unique brain morphology of
individuals. Adversarial training ensures realistic brain images and smooth
temporal progression. We train our model using 9652 T1-weighted (longitudinal)
MRI extracted from the Alzheimer's Disease Neuroimaging Initiative (ADNI)
dataset. We perform quantitative and qualitative evaluations on a separate test
set of 1283 images (also from ADNI) demonstrating the ability of DaniNet to
produce accurate and convincing synthetic images that emulate disease
progression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02789</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02789</id><created>2019-07-05</created><authors><author><keyname>Shanbog</keyname><forenames>Niteesh S</forenames></author><author><keyname>R</keyname><forenames>Pushpa K</forenames></author></authors><title>Double Input Boost/Y-Source DC-DC Converter for Renewable Energy Sources</title><categories>eess.SY cs.SY eess.SP physics.app-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing adoption of renewable energy sources by domestic users,
decentralisation of the grid is fast becoming a reality. Distributed generation
is an important part of a decentralised grid. This approach employs several
small-scale technologies to produce electrical energy close to the end users or
consumers. The higher reliability of these systems proves to be of advantage
when compared to traditional generation systems. Multi-Input Converters (MICs)
perform a decisive function in Distributed Energy Resources (DERs). Making use
of such MICs prove to be beneficial in terms of size, cost, number of
components used, efficiency and reliability as compared to using several
independent converters. This thesis proposes a double input DC-DC converter
which makes use of a quasi Y-source converter in tandem with a boost converter.
The quasi Y-source converter has the advantage of having a very high gain for
low duty cycles. The associated operating modes are analysed and the operation
of the MIC is verified using simulation result. A hardware prototype is built
for large signal analysis in open loop. Different loads are applied and the
efficiency of the MIC as a whole as well as the load sharing between the
different sources is investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02796</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02796</id><created>2019-07-04</created><updated>2019-07-11</updated><authors><author><keyname>Zimmerer</keyname><forenames>David</forenames></author><author><keyname>Isensee</keyname><forenames>Fabian</forenames></author><author><keyname>Petersen</keyname><forenames>Jens</forenames></author><author><keyname>Kohl</keyname><forenames>Simon</forenames></author><author><keyname>Maier-Hein</keyname><forenames>Klaus</forenames></author></authors><title>Unsupervised Anomaly Localization using Variational Auto-Encoders</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An assumption-free automatic check of medical images for potentially overseen
anomalies would be a valuable assistance for a radiologist. Deep learning and
especially Variational Auto-Encoders (VAEs) have shown great potential in the
unsupervised learning of data distributions. In principle, this allows for such
a check and even the localization of parts in the image that are most
suspicious. Currently, however, the reconstruction-based localization by design
requires adjusting the model architecture to the specific problem looked at
during evaluation. This contradicts the principle of building assumption-free
models. We propose complementing the localization part with a term derived from
the Kullback-Leibler (KL)-divergence. For validation, we perform a series of
experiments on FashionMNIST as well as on a medical task including &gt;1000
healthy and &gt;250 brain tumor patients. Results show that the proposed formalism
outperforms the state of the art VAE-based localization of anomalies across
many hyperparameter settings and also shows a competitive max performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02801</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02801</id><created>2019-07-05</created><authors><author><keyname>Palati</keyname><forenames>Madhu</forenames></author><author><keyname>D</keyname><forenames>Manjunath R</forenames></author><author><keyname>L</keyname><forenames>Nagesh</forenames></author><author><keyname>Shanbog</keyname><forenames>Niteesh S</forenames></author><author><keyname>C</keyname><forenames>Prashanth</forenames></author></authors><title>PV Source Integrated Micro-Grid for Power Quality Improvement using MPPT
  Technique</title><categories>eess.SY cs.SY eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The demand for Electrical energy is increasing day by day as it can be easily
converted to another form of energy. All consumers expect Electrical energy
with high power quality. Most of the commercial and industrial loads are
inductive in nature and need power electronic circuits/ controllers to get
smooth control of the equipment. This, in turn, leads to the injection of
harmonics into the system, hence the power quality is affected. The above
problem needs to be addressed and eliminated. In this paper, a shunt active
power filter is used to mitigate the harmonics. Id-Iq control is used to
analyse the performance of the filter and is simulated using MATLAB software.
The MPPT controller is used to improving the power quality of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02805</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02805</id><created>2019-07-05</created><authors><author><keyname>Shahid</keyname><forenames>Arsalan</forenames></author><author><keyname>Fahad</keyname><forenames>Muhammad</forenames></author><author><keyname>Manumachu</keyname><forenames>Ravi Reddy</forenames></author><author><keyname>Lastovetsky</keyname><forenames>Alexey</forenames></author></authors><title>Energy of Computing on Multicore CPUs: Predictive Models and Energy
  Conservation Law</title><categories>cs.DC cs.PF cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy is now a first-class design constraint along with performance in all
computing settings. Energy predictive modelling based on performance monitoring
counts (PMCs) is the leading method used for prediction of energy consumption
during an application execution. We use a model-theoretic approach to formulate
the assumed properties of existing models in a mathematical form. We extend the
formalism by adding properties, heretofore unconsidered, that account for a
limited form of energy conservation law. The extended formalism defines our
theory of energy of computing. By applying the basic practical implications of
the theory, we improve the prediction accuracy of state-of-the-art energy
models from 31% to 18%. We also demonstrate that use of state-of-the-art
measurement tools for energy optimisation may lead to significant losses of
energy (ranging from 56% to 65% for applications used in experiments) since
they do not take into account the energy conservation properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02813</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02813</id><created>2019-07-05</created><authors><author><keyname>Efremova</keyname><forenames>Natalia</forenames></author><author><keyname>West</keyname><forenames>Dennis</forenames></author><author><keyname>Zausaev</keyname><forenames>Dmitry</forenames></author></authors><title>AI-based evaluation of the SDGs: The case of crop detection with earth
  observation data</title><categories>cs.CV eess.IV</categories><comments>ICLR workshop &quot;AI for Social Good&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The framework of the seventeen sustainable development goals is a challenge
for developers and researchers applying artificial intelligence (AI). AI and
earth observations (EO) can provide reliable and disaggregated data for better
monitoring of the sustainable development goals (SDGs). In this paper, we
present an overview of SDG targets, which can be effectively measured with AI
tools. We identify indicators with the most significant contribution from the
AI and EO and describe an application of state-of-the-art machine learning
models to one of the indicators. We describe an application of U-net with SE
blocks for efficient segmentation of satellite imagery for crop detection.
Finally, we demonstrate how AI can be more effectively applied in solutions
directly contributing towards specific SDGs and propose further research on an
AI-based evaluative infrastructure for SDGs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02843</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02843</id><created>2019-07-05</created><authors><author><keyname>Sun</keyname><forenames>Xiaopeng</forenames></author><author><keyname>Lu</keyname><forenames>Wen</forenames></author><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Bai</keyname><forenames>Furui</forenames></author></authors><title>Distilling with Residual Network for Single Image Super Resolution</title><categories>cs.CV eess.IV</categories><comments>6 pages; Accepted to ICME2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the deep convolutional neural network (CNN) has made remarkable
progress in single image super resolution(SISR). However, blindly using the
residual structure and dense structure to extract features from LR images, can
cause the network to be bloated and difficult to train. To address these
problems, we propose a simple and efficient distilling with residual
network(DRN) for SISR. In detail, we propose residual distilling block(RDB)
containing two branches, while one branch performs a residual operation and the
other branch distills effective information. To further improve efficiency, we
design residual distilling group(RDG) by stacking some RDBs and one long skip
connection, which can effectively extract local features and fuse them with
global features. These efficient features beneficially contribute to image
reconstruction. Experiments on benchmark datasets demonstrate that our DRN is
superior to the state-of-the-art methods, specifically has a better trade-off
between performance and model size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02846</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02846</id><created>2019-07-05</created><authors><author><keyname>Fehenberger</keyname><forenames>Tobias</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author></authors><title>Analysis and Optimisation of Distribution Matching for the Nonlinear
  Fibre Channel</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enhanced Gaussian noise models are used to demonstrate that the per-block SNR
after fibre transmission varies significantly due to the variable-composition
nature of modern probabilistic shaping schemes. We propose a
nonlinearity-optimised distribution matcher that improves the average and
worst-case SNR by 0.14 and 0.22 dB, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02862</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02862</id><created>2019-06-14</created><authors><author><keyname>Seraj</keyname><forenames>Esmaeil</forenames></author><author><keyname>Mahalingam</keyname><forenames>Karthiga</forenames></author></authors><title>Essential Motor Cortex Signal Processing: an ERP and functional
  connectivity MATLAB toolbox -- User Guide</title><categories>eess.SP cs.CE eess.IV q-bio.NC q-bio.QM</categories><comments>37 pages, 12 figures</comments><report-no>v01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this document is to help individuals use the &quot;Essential Motor
Cortex Signal Processing MATLAB Toolbox&quot;. The toolbox implements various
methods for three major aspects of investigating human motor cortex from
Neuroscience view point: (1) ERP estimation and quantification, (2) Cortical
Functional Connectivity analysis and (3) EMG quantification. The toolbox --
which is distributed under the terms of the GNU GENERAL PUBLIC LICENSE as a set
of MATLAB R routines -- can be downloaded directly at the address:
http://oset.ir/category.php?dir=Tools or from the public repository on GitHub,
at address below: https://github.com/EsiSeraj/ERP Connectivity EMG Analysis
  The purpose of this toolbox is threefold: 1. Extract the
event-related-potential (ERP) from preprocessed cerebral signals (i.e. EEG,
MEG, etc.), identify and then quantify the event-related
synchronization/desynchronization (ERS/ERD) events. Both time-course dynamics
and time-frequency (TF) analyzes are included. 2. Measure, quantify and
demonstrate the cortical functional connectivity (CFC) across scalp electrodes.
These set of functions can also be applied to various types of cerebral signals
(i.e. electric and magnetic). 3. Quantify electromyogram (EMG) recorded from
active muscles during performing motor tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02864</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02864</id><created>2019-07-05</created><authors><author><keyname>Elsner</keyname><forenames>Daniel</forenames></author><author><keyname>Langer</keyname><forenames>Stefan</forenames></author><author><keyname>Ritz</keyname><forenames>Fabian</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Robert</forenames></author><author><keyname>Illium</keyname><forenames>Steffen</forenames></author></authors><title>Deep Neural Baselines for Computational Paralinguistics</title><categories>cs.SD cs.CL eess.AS</categories><comments>5 pages, 3 figures; This paper was accepted at INTERSPEECH 2019,
  Graz, 15-19th September 2019. DOI will be added after publishment of the
  accepted paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting sleepiness from spoken language is an ambitious task, which is
addressed by the Interspeech 2019 Computational Paralinguistics Challenge
(ComParE). We propose an end-to-end deep learning approach to detect and
classify patterns reflecting sleepiness in the human voice. Our approach is
based solely on a moderately complex deep neural network architecture. It may
be applied directly on the audio data without requiring any specific feature
engineering, thus remaining transferable to other audio classification tasks.
Nevertheless, our approach performs similar to state-of-the-art machine
learning models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02865</identifier>
 <datestamp>2019-08-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02865</id><created>2019-07-05</created><updated>2019-08-26</updated><authors><author><keyname>Painchaud</keyname><forenames>Nathan</forenames></author><author><keyname>Skandarani</keyname><forenames>Youssef</forenames></author><author><keyname>Judge</keyname><forenames>Thierry</forenames></author><author><keyname>Bernard</keyname><forenames>Olivier</forenames></author><author><keyname>Lalande</keyname><forenames>Alain</forenames></author><author><keyname>Jodoin</keyname><forenames>Pierre-Marc</forenames></author></authors><title>Cardiac MRI Segmentation with Strong Anatomical Guarantees</title><categories>eess.IV cs.CV</categories><comments>9 pages, accepted for MICCAI 2019; camera ready corrections,
  acknowledgments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent publications have shown that the segmentation accuracy of modern-day
convolutional neural networks (CNN) applied on cardiac MRI can reach the
inter-expert variability, a great achievement in this area of research.
However, despite these successes, CNNs still produce anatomically inaccurate
segmentations as they provide no guarantee on the anatomical plausibility of
their outcome, even when using a shape prior. In this paper, we propose a
cardiac MRI segmentation method which always produces anatomically plausible
results. At the core of the method is an adversarial variational autoencoder
(aVAE) whose latent space encodes a smooth manifold on which lies a large
spectrum of valid cardiac shapes. This aVAE is used to automatically warp
anatomically inaccurate cardiac shapes towards a close but correct shape. Our
method can accommodate any cardiac segmentation method and convert its
anatomically implausible results to plausible ones without affecting its
overall geometric and clinical metrics. With our method, CNNs can now produce
results that are both within the inter-expert variability and always
anatomically plausible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02873</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02873</id><created>2019-07-05</created><authors><author><keyname>Alidousti</keyname><forenames>Zahra</forenames></author><author><keyname>Dehkordi</keyname><forenames>Maryam Taghizadeh</forenames></author></authors><title>A new method for determining the filled point of the tooth by Bit-Plane
  Algorithm</title><categories>eess.IV cs.CV</categories><comments>2019 IEEE 4th Conference on Technology In Electrical and Computer
  Engineering (ETECH 2019) Information and Communication Technology (ICT)
  Tehran, Iran</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Up to now, researchers have applied segmentation techniques in their studies
on teeth images, with construction on tooth root length and depth. In this
paper, a new approach to the exact identification of the filled points of the
tooth is proposed. In this method, the filled teeth are detection by applying
the Bit-Plane algorithm on the OPG images. The novelty of the proposed method
is that we can use it in medicine for the detection of dental filling and we
calculate and present the area of the filled points which may help dentists to
assess the filled point of the tooth. The experimental results, confirmed by
the dentists, clearly indicate that this method is able to separate the filled
points from the rest of healthy teeth completely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02877</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02877</id><created>2019-07-05</created><authors><author><keyname>Raurale</keyname><forenames>Sumit A.</forenames></author><author><keyname>Nalband</keyname><forenames>Saif</forenames></author><author><keyname>Boylan</keyname><forenames>Geraldine B.</forenames></author><author><keyname>Lightbody</keyname><forenames>Gordon</forenames></author><author><keyname>O'Toole</keyname><forenames>John M.</forenames></author></authors><title>Suitability of an inter-burst detection method for grading
  hypoxic-ischemic encephalopathy in newborn EEG</title><categories>eess.SP cs.LG</categories><comments>4 pages, to be appearing in upcoming 2019 EMBC conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electroencephalography (EEG) is an important clinical tool for grading injury
caused by lack of oxygen or blood to the brain during birth. Characteristics of
low-voltage waveforms, known as inter-bursts, are related to different grades
of injury. This study assesses the suitability of an existing inter-burst
detection method, developed from preterm infants born &lt;30 weeks of gestational
age, to detect inter-bursts in term infants. Different features from the
temporal organisation of the inter-bursts are combined using a multi-layer
perceptron (MLP) machine learning algorithm to classify four grades of injury
in the EEG. We find that the best performing feature, percentage of
inter-bursts, has an accuracy of 59.3%. Combining this with the maximum
duration of inter-bursts in the MLP produces a testing accuracy of 77.8%, with
similar performance to existing multi-feature methods. These results validate
the use of the preterm detection method in term EEG and show how simple
measures of the inter-burst interval can be used to classify different grades
of injury.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02886</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02886</id><created>2019-07-05</created><authors><author><keyname>Onen</keyname><forenames>Murat</forenames></author><author><keyname>Butters</keyname><forenames>Brenden A.</forenames></author><author><keyname>Toomey</keyname><forenames>Emily</forenames></author><author><keyname>Gokmen</keyname><forenames>Tayfun</forenames></author><author><keyname>Berggren</keyname><forenames>Karl K.</forenames></author></authors><title>Design and Characterization of Superconducting Nanowire-Based Processors
  for Acceleration of Deep Neural Network Training</title><categories>cs.ET cs.SY eess.SY</categories><doi>10.1088/1361-6528/ab47bc</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Training of deep neural networks (DNNs) is a computationally intensive task
and requires massive volumes of data transfer. Performing these operations with
the conventional von Neumann architectures creates unmanageable time and power
costs. Recent studies have shown that mixed-signal designs involving crossbar
architectures are capable of achieving acceleration factors as high as 30,000x
over the state of the art digital processors. These approaches involve
utilization of non-volatile memory (NVM) elements as local processors. However,
no technology has been developed to-date that can satisfy the strict device
requirements for the unit cell. This paper presents the superconducting
nanowire-based processing element as a cross-point device. The unit cell has
many programmable non-volatile states that can be used to perform analog
multiplication. Importantly, these states are intrinsically discrete due to
quantization of flux, which provides symmetric switching characteristics.
Operation of these devices in a crossbar is described and verified with
electro-thermal circuit simulations. Finally, validation of the concept in an
actual DNN training task is shown using an emulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02891</identifier>
 <datestamp>2019-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02891</id><created>2019-07-05</created><updated>2019-10-15</updated><authors><author><keyname>Bar&#xe1;</keyname><forenames>Salvador</forenames></author><author><keyname>Falchi</keyname><forenames>Fabio</forenames></author><author><keyname>Furgoni</keyname><forenames>Riccardo</forenames></author><author><keyname>Lima</keyname><forenames>Raul C.</forenames></author></authors><title>Fast Fourier-transform calculation of artificial night sky brightness
  maps</title><categories>astro-ph.IM eess.IV</categories><comments>Author formatted text of the accepted version of the paper published
  in Journal of Quantitative Spectroscopy &amp; Radiative Transfer 240 (2020)
  106658</comments><journal-ref>Journal of Quantitative Spectroscopy &amp; Radiative Transfer 240
  (2020) 106658</journal-ref><doi>10.1016/j.jqsrt.2019.106658</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Light pollution poses a growing threat to optical astronomy, in addition to
its detrimental impacts on the natural environment, the intangible heritage of
humankind related to the contemplation of the starry sky and, potentially, on
human health. The computation of maps showing the spatial distribution of
several light pollution related functions (e.g. the anthropogenic zenithal
night sky brightness, or the average brightness of the celestial hemisphere) is
a key tool for light pollution monitoring and control, providing the scientific
rationale for the adoption of informed decisions on public lighting and
astronomical site preservation. The calculation of such maps from satellite
radiance data for wide regions of the planet with sub-kilometric spatial
resolution often implies a huge amount of basic pixel operations, requiring in
many cases extremely large computation times. In this paper we show that, using
adequate geographical projections, a wide set of light pollution map
calculations can be reframed in terms of two-dimensional convolutions that can
be easily evaluated using conventional fast Fourier-transform (FFT) algorithms,
with typical computation times smaller than 10^-6 s per output pixel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02940</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02940</id><created>2019-07-05</created><authors><author><keyname>Seo</keyname><forenames>Jae Duk</forenames></author></authors><title>Visualizing Uncertainty and Saliency Maps of Deep Convolutional Neural
  Networks for Medical Imaging Applications</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning models are now used in many different industries, while in
certain domains safety is not a critical issue in the medical field it is a
huge concern. Not only, we want the models to generalize well but we also want
to know the models confidence respect to its decision and which features matter
the most. Our team aims to develop a full pipeline in which not only displays
the uncertainty of the models decision but also, the saliency map to show which
sets of pixels of the input image contribute most to the predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02942</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02942</id><created>2019-07-02</created><authors><author><keyname>Yang</keyname><forenames>Qianqian</forenames></author><author><keyname>Mashhadi</keyname><forenames>Mahdi Boloursaz</forenames></author><author><keyname>G&#xfc;nd&#xfc;z</keyname><forenames>Deniz</forenames></author></authors><title>Deep Convolutional Compression for Massive MIMO CSI Feedback</title><categories>cs.IT cs.LG eess.SP math.IT</categories><comments>Submitted to MLSP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coded caching provides significant gains over conventional uncoded caching by
creating multicasting opportunities among distinct requests.
  Massive multiple-input multiple-output (MIMO) systems require downlink
channel state information (CSI) at the base station (BS) to better utilize the
available spatial diversity and multiplexing gains. However, in a frequency
division duplex (FDD) massive MIMO system, the huge CSI feedback overhead
becomes restrictive and degrades the overall spectral efficiency. In this
paper, we propose a deep learning based channel state matrix compression
scheme, called DeepCMC, composed of convolutional layers followed by
quantization and entropy coding blocks. In comparison with previous works, the
main contributions of DeepCMC are two-fold: i) DeepCMC is fully convolutional,
and it can be used in a wide range of scenarios with various numbers of
sub-channels and transmit antennas; ii) DeepCMC includes quantization and
entropy coding blocks and minimizes a cost function that accounts for both the
rate of compression and the reconstruction quality of the channel matrix at the
BS. Simulation results demonstrate that DeepCMC significantly outperforms the
state of the art compression schemes in terms of the reconstruction quality of
the channel state matrix for the same compression rate, measured in bits per
channel dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02959</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02959</id><created>2019-07-05</created><authors><author><keyname>Valsesia</keyname><forenames>Diego</forenames></author><author><keyname>Magli</keyname><forenames>Enrico</forenames></author></authors><title>High-throughput Onboard Hyperspectral Image Compression with
  Ground-based CNN Reconstruction</title><categories>eess.IV cs.CV cs.LG</categories><doi>10.1109/TGRS.2019.2927434</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compression of hyperspectral images onboard of spacecrafts is a tradeoff
between the limited computational resources and the ever-growing spatial and
spectral resolution of the optical instruments. As such, it requires
low-complexity algorithms with good rate-distortion performance and high
throughput. In recent years, the Consultative Committee for Space Data Systems
(CCSDS) has focused on lossless and near-lossless compression approaches based
on predictive coding, resulting in the recently published CCSDS 123.0-B-2
recommended standard. While the in-loop reconstruction of quantized prediction
residuals provides excellent rate-distortion performance for the near-lossless
operating mode, it significantly constrains the achievable throughput due to
data dependencies. In this paper, we study the performance of a faster method
based on prequantization of the image followed by a lossless predictive
compressor. While this is well known to be suboptimal, one can exploit powerful
signal models to reconstruct the image at the ground segment, recovering part
of the suboptimality. In particular, we show that convolutional neural networks
can be used for this task and that they can recover the whole SNR drop incurred
at a bitrate of 2 bits per pixel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02994</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.02994</id><created>2019-07-05</created><updated>2019-07-29</updated><authors><author><keyname>van Sloun</keyname><forenames>Ruud JG</forenames></author><author><keyname>Cohen</keyname><forenames>Regev</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C</forenames></author></authors><title>Deep learning in ultrasound imaging</title><categories>eess.SP cs.LG eess.IV</categories><comments>Accepted for publication in the Proceedings of the IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider deep learning strategies in ultrasound systems, from the
front-end to advanced applications. Our goal is to provide the reader with a
broad understanding of the possible impact of deep learning methodologies on
many aspects of ultrasound imaging. In particular, we discuss methods that lie
at the interface of signal acquisition and machine learning, exploiting both
data structure (e.g. sparsity in some domain) and data dimensionality (big
data) already at the raw radio-frequency channel stage. As some examples, we
outline efficient and effective deep learning solutions for adaptive
beamforming and adaptive spectral Doppler through artificial agents, learn
compressive encodings for color Doppler, and provide a framework for structured
signal recovery by learning fast approximations of iterative minimization
problems, with applications to clutter suppression and super-resolution
ultrasound. These emerging technologies may have considerable impact on
ultrasound imaging, showing promise across key components in the receive
processing chain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03029</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03029</id><created>2019-07-05</created><authors><author><keyname>Helou</keyname><forenames>Majed El</forenames></author><author><keyname>Susstrunk</keyname><forenames>Sabine</forenames></author></authors><title>Blind Universal Bayesian Image Denoising with Gaussian Noise Level
  Learning</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind and universal image denoising consists of a unique model that denoises
images with any level of noise. It is especially practical as noise levels do
not need to be known when the model is developed or at test time. We propose a
theoretically-grounded blind and universal deep learning image denoiser for
Gaussian noise. Our network is based on an optimal denoising solution, which we
call fusion denoising. It is derived theoretically with a Gaussian image prior
assumption. Synthetic experiments show our network's generalization strength to
unseen noise levels. We also adapt the fusion denoising network architecture
for real image denoising. Our approach improves real-world grayscale image
denoising PSNR results by up to $0.7dB$ for training noise levels and by up to
$2.82dB$ on noise levels not seen during training. It also improves
state-of-the-art color image denoising performance on every single noise level,
by an average of $0.1dB$, whether trained on or not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03042</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03042</id><created>2019-07-05</created><authors><author><keyname>Wu</keyname><forenames>Zongshen</forenames></author><author><keyname>Huang</keyname><forenames>Chin-Ya</forenames></author><author><keyname>Ramanathan</keyname><forenames>Parameswaran</forenames></author></authors><title>Coded Taking and Giving (COTAG): Enhancing Transport Layer Performance
  over Millimeter Wave Access Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) access networks have the potential to meet the
high-throughput and low-latency needs of immersive applications. However, due
to the highly directional nature of the mmWave beams and due to their
susceptibility to human-induced blockage, the associated wireless communication
links are vulnerable to large fluctuations in channel quality. These large
fluctuations result in disproportionately adverse effects on performance of
transport layer protocols such as Transmission Control Protocol (TCP).
Furthermore, we show in this paper, that TCP continues to significantly under
perform even when dual-connectivity is used to combat the effects of channel
quality fluctuations. To overcome this challenge, we propose a network layer
solution, Coded Taking and Giving (COTAG) scheme to sustain low-latency and
high-throughput end-to-end TCP performance. In particular, COTAG creates
network encoded packets at the network gateway and each mmWave access point
(AP) aiming to adaptively take the spare bandwidth on each link in the network
for packet transmission. Further, if one link does not have enough bandwidth,
COTAG actively gives up the transmission opportunity via conditionally dropping
packets. Consequently, the proposed COTAG actively adapts to changes in mmWave
link quality and enhances the TCP performance without jeopardizing the latency
of immersive connect delivery. To evaluate the effectiveness of the proposed
COTAG, we conduct experiments and simulations using off-the-shelf APs and NS-2.
The evaluation results show the proposed COTAG significantly improves
end-to-end TCP performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03043</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03043</id><created>2019-07-05</created><authors><author><keyname>Zhao</keyname><forenames>Yuxin</forenames></author><author><keyname>Yin</keyname><forenames>Feng</forenames></author><author><keyname>Gunnarsson</keyname><forenames>Fredrik</forenames></author><author><keyname>Hultkrantz</keyname><forenames>Fredrik</forenames></author></authors><title>Gaussian Processes for Analyzing Positioned Trajectories in Sports</title><categories>cs.LG eess.SP stat.ML</categories><comments>31pages, 28 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kernel-based machine learning approaches are gaining increasing interest for
exploring and modeling large dataset in recent years. Gaussian process (GP) is
one example of such kernel-based approaches, which can provide very good
performance for nonlinear modeling problems. In this work, we first propose a
grey-box modeling approach to analyze the forces in cross country skiing races.
To be more precise, a disciplined set of kinetic motion model formulae is
combined with data-driven Gaussian process regression model, which accounts for
everything unknown in the system. Then, a modeling approach is proposed to
analyze the kinetic flow of both individual and clusters of skiers. The
proposed approaches can be generally applied to use cases where positioned
trajectories and kinetic measurements are available. The proposed approaches
are evaluated using data collected from the Falun Nordic World Ski
Championships 2015, in particular the Men's cross country $4\times10$ km relay.
Forces during the cross country skiing races are analyzed and compared.
Velocity models for skiers at different competition stages are also evaluated.
Finally, the comparisons between the grey-box and black-box approach are
carried out, where the grey-box approach can reduce the predictive uncertainty
by $30\%$ to $40\%$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03050</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03050</id><created>2019-07-05</created><updated>2019-07-18</updated><authors><author><keyname>Khorram</keyname><forenames>Soheil</forenames></author><author><keyname>McInnis</keyname><forenames>Melvin G</forenames></author><author><keyname>Provost</keyname><forenames>Emily Mower</forenames></author></authors><title>Jointly Aligning and Predicting Continuous Emotion Annotations</title><categories>cs.LG cs.HC eess.AS stat.ML</categories><comments>IEEE Transactions on Affective Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time-continuous dimensional descriptions of emotions (e.g., arousal, valence)
allow researchers to characterize short-time changes and to capture long-term
trends in emotion expression. However, continuous emotion labels are generally
not synchronized with the input speech signal due to delays caused by
reaction-time, which is inherent in human evaluations. To deal with this
challenge, we introduce a new convolutional neural network (multi-delay sinc
network) that is able to simultaneously align and predict labels in an
end-to-end manner. The proposed network is a stack of convolutional layers
followed by an aligner network that aligns the speech signal and emotion
labels. This network is implemented using a new convolutional layer that we
introduce, the delayed sinc layer. It is a time-shifted low-pass (sinc) filter
that uses a gradient-based algorithm to learn a single delay. Multiple delayed
sinc layers can be used to compensate for a non-stationary delay that is a
function of the acoustic space. We test the efficacy of this system on two
common emotion datasets, RECOLA and SEWA, and show that this approach obtains
state-of-the-art speech-only results by learning time-varying delays while
predicting dimensional descriptors of emotions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03063</identifier>
 <datestamp>2020-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03063</id><created>2019-07-05</created><authors><author><keyname>Lyu</keyname><forenames>Qing</forenames></author><author><keyname>Shan</keyname><forenames>Hongming</forenames></author><author><keyname>Wang</keyname><forenames>Ge</forenames></author></authors><title>MRI Super-Resolution with Ensemble Learning and Complementary Priors</title><categories>eess.IV cs.LG physics.med-ph</categories><journal-ref>IEEE Transactions on Computational Imaging, vol. 6, pp. 615-624,
  2020</journal-ref><doi>10.1109/TCI.2020.2964201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance imaging (MRI) is a widely used medical imaging modality.
However, due to the limitations in hardware, scan time, and throughput, it is
often clinically challenging to obtain high-quality MR images. The
super-resolution approach is potentially promising to improve MR image quality
without any hardware upgrade. In this paper, we propose an ensemble learning
and deep learning framework for MR image super-resolution. In our study, we
first enlarged low resolution images using 5 commonly used super-resolution
algorithms and obtained differentially enlarged image datasets with
complementary priors. Then, a generative adversarial network (GAN) is trained
with each dataset to generate super-resolution MR images. Finally, a
convolutional neural network is used for ensemble learning that synergizes the
outputs of GANs into the final MR super-resolution images. According to our
results, the ensemble learning results outcome any one of GAN outputs. Compared
with some state-of-the-art deep learning-based super-resolution methods, our
approach is advantageous in suppressing artifacts and keeping more image
details.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03064</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03064</id><created>2019-07-05</created><authors><author><keyname>Biswas</keyname><forenames>Astik</forenames></author><author><keyname>Menon</keyname><forenames>Raghav</forenames></author><author><keyname>van der Westhuizen</keyname><forenames>Ewald</forenames></author><author><keyname>Niesler</keyname><forenames>Thomas</forenames></author></authors><title>Improved low-resource Somali speech recognition by semi-supervised
  acoustic and language model training</title><categories>cs.CL cs.LG eess.AS</categories><comments>5 pages, 6 Tables, 3 figures, 22 references (Accepted at Interspeech
  2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present improvements in automatic speech recognition (ASR) for Somali, a
currently extremely under-resourced language. This forms part of a continuing
United Nations (UN) effort to employ ASR-based keyword spotting systems to
support humanitarian relief programmes in rural Africa. Using just 1.57 hours
of annotated speech data as a seed corpus, we increase the pool of training
data by applying semi-supervised training to 17.55 hours of untranscribed
speech. We make use of factorised time-delay neural networks (TDNN-F) for
acoustic modelling, since these have recently been shown to be effective in
resource-scarce situations. Three semi-supervised training passes were
performed, where the decoded output from each pass was used for acoustic model
training in the subsequent pass. The automatic transcriptions from the best
performing pass were used for language model augmentation. To ensure the
quality of automatic transcriptions, decoder confidence is used as a threshold.
The acoustic and language models obtained from the semi-supervised approach
show significant improvement in terms of WER and perplexity compared to the
baseline. Incorporating the automatically generated transcriptions yields a
6.55\% improvement in language model perplexity. The use of 17.55 hour of
Somali acoustic data in semi-supervised training shows an improvement of 7.74\%
relative over the baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03075</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03075</id><created>2019-07-06</created><authors><author><keyname>Mahapatra</keyname><forenames>Dwarikanath</forenames></author></authors><title>AMD Severity Prediction And Explainability Using Image Registration And
  Deep Embedded Clustering</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method to predict severity of age related macular degeneration
(AMD) from input optical coherence tomography (OCT) images. Although there is
no standard clinical severity scale for AMD, we leverage deep learning (DL)
based image registration and clustering methods to identify diseased cases and
predict their severity. Experiments demonstrate our approach's disease
classification performance matches state of the art methods. The predicted
disease severity performs well on previously unseen data. Registration output
provides better explainability than class activation maps regarding label and
severity decisions
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03080</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03080</id><created>2019-07-06</created><authors><author><keyname>D</keyname><forenames>Venkatramanan</forenames></author><author><keyname>John</keyname><forenames>Vinod</forenames></author></authors><title>A Reconfigurable Solar Photovoltaic Grid-Tied Inverter Architecture for
  Enhanced Energy Access in Backup Power Applications</title><categories>eess.SY cs.SY</categories><comments>8 pages, 10 figures. This manuscript is under review in IEEE
  Transactions</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, a photovoltaic (PV) reconfigurable grid-tied inverter (RGTI)
scheme is proposed. Unlike a conventional GTI that ceases operation during a
power outage, the RGTI is designed to act as a regular GTI in the on-grid mode
but it is reconfigured to function as a DC-DC charge-controller that continues
operation during a grid outage. During this period, the RGTI is tied to the
battery-bank of an external UPS based backup power system to augment it with
solar power. Such an operation in off-grid mode without employing communication
with the UPS is challenging, as the control of RGTI must not conflict with the
battery management system of the UPS. The hardware and control design aspects
of this requirement are discussed in this paper. A battery emulation control
scheme is proposed for the RGTI that facilitates seamless functioning of the
RGTI in parallel with the physical UPS battery to reduce its discharge current.
A system-level control scheme for overall operation and power management is
presented to handle the dynamic variations in solar irradiation and UPS loads
during the day, such that the battery discharge burden is minimized. The design
and operation of the proposed RGTI system are independent of the external UPS
and can be integrated with an UPS supplied by any manufacturer. Experimental
results on a 4~kVA hardware setup validate the proposed RGTI concept, its
operation and control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03095</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03095</id><created>2019-07-06</created><authors><author><keyname>Yang</keyname><forenames>Qianqian</forenames></author><author><keyname>Yuan</keyname><forenames>Qiangqiang</forenames></author><author><keyname>Yue</keyname><forenames>Linwei</forenames></author><author><keyname>Shen</keyname><forenames>Huanfeng</forenames></author><author><keyname>Zhang</keyname><forenames>Liangpei</forenames></author></authors><title>Mapping PM2.5 concentration at sub-km level resolution: a dual-scale
  retrieval method</title><categories>physics.ao-ph eess.IV physics.geo-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Satellite-based retrieval has become a popular PM2.5 monitoring method
currently. To improve the retrieval performance, multiple variables are usually
introduced as auxiliary variable in addition to aerosol optical depth (AOD).
Different kinds of variables are usually at different resolutions varying from
sub-kilometers to dozens of kilometers. Generally, when doing the retrieval,
variables at different resolutions are resampled to the same resolution as the
AOD product to keep the scale consistency. A deficiency of doing this is that
the information contained in the scale difference is discarded. To fully
utilize the information contained at different scales, a dual-scale retrieval
method is proposed in this study. At the first stage, variables which influence
PM2.5 concentration at large scale were used for PM2.5 retrieval at coarse
resolution. Then at the second stage, variables which affect PM2.5 distribution
in finer scale, were used for the further PM2.5 retrieval at high resolution
(sub-km level resolution) with the retrieved PM2.5 at the first stage at
coarser resolution also as input. In this study, four different retrieval
models including multiple linear regression (MLR), geographically weighted
regression (GWR), random forest (RF) and generalized regression neural network
(GRNN) are adopted to test the performance of the dual-scale retrieval method.
Compared with the traditional retrieval method, the proposed dual-scale
retrieval method can achieve PM2.5 mapping at finer resolution and with higher
accuracy. Dual-scale retrieval can fully utilize the information contained at
different scales, thus achieving a higher resolution and accuracy. It can be
used for the generation of quantitative remote sensing products in various
fields, and promote the improvement of the quality of quantitative remote
sensing products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03104</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03104</id><created>2019-07-06</created><authors><author><keyname>Shevkunov</keyname><forenames>Igor</forenames></author><author><keyname>Katkovnik</keyname><forenames>Vladimir</forenames></author><author><keyname>Claus</keyname><forenames>Daniel</forenames></author><author><keyname>Pedrini</keyname><forenames>Giancarlo</forenames></author><author><keyname>Petrov</keyname><forenames>Nikolay</forenames></author><author><keyname>Egiazarian</keyname><forenames>Karen</forenames></author></authors><title>Hyperspectral phase imaging based on denoising in complex-valued
  eigensubspace</title><categories>eess.IV physics.optics</categories><doi>10.1016/j.optlaseng.2019.105973</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new denoising algorithm for hyperspectral complex domain data has been
developed and studied. This algorithm is based on the complex domain
block-matching 3D filter including the 3D Wiener filtering stage. The developed
algorithm is applied and tuned to work in the singular value decomposition
(SVD) eigenspace of reduced dimension. The accuracy and quantitative advantage
of the new algorithm are demonstrated in simulation tests and in the processing
of the experimental data. It is shown that the algorithm is effective and
provides reliable results even for highly noisy data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03109</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03109</id><created>2019-07-06</created><authors><author><keyname>Gheshlaghi</keyname><forenames>Saba Heidari</forenames></author><author><keyname>Ranjbar</keyname><forenames>Amin</forenames></author><author><keyname>Suratgar</keyname><forenames>Amir Abolfazl</forenames></author><author><keyname>Menhaj</keyname><forenames>Mohammad Bagher</forenames></author><author><keyname>Faraji</keyname><forenames>Fardin</forenames></author></authors><title>A Superpixel Segmentation Based Technique for Multiple Sclerosis Lesion
  Detection</title><categories>eess.IV</categories><comments>11 Pages, Journal Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Superpixel Segmentation Based Technique for Multiple Sclerosis Lesion
Detection
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03117</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03117</id><created>2019-07-06</created><authors><author><keyname>Pattanayak</keyname><forenames>Dipti R.</forenames></author><author><keyname>Dwivedi</keyname><forenames>Vivek K.</forenames></author><author><keyname>Karwal</keyname><forenames>Vikram</forenames></author><author><keyname>Ansari</keyname><forenames>Imran Shafique</forenames></author><author><keyname>Lei</keyname><forenames>Hongjiang</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>On the Physical Layer Security of a Decode and Forward Based Mixed
  FSO/RF Cooperative System</title><categories>eess.SP</categories><comments>7 pages, 6 figures, Submitted to IEEE Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, the secrecy performance of a mixed free space optics (FSO)
and radio frequency (RF) system is analyzed from physical layer security (PHY)
perspective. In this scenario, one or more eavesdroppers are trying to
intercept the confidential signal in a mixed FSO/RF system. The faded FSO links
are modeled by Malaga ($\mathcal{M} $) distribution and RF link is
characterized by Nakagami-$m$ distribution. Exact closed form expressions for
secrecy performance metrics such as secrecy outage probability and strictly
positive secrecy capacity are derived and analyzed for the proposed system in
terms of Fox's H-function. Furthermore, the asymptotic expressions for these
performance metrics are analyzed. Finally, all the results are verified by
Monte-Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03118</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03118</id><created>2019-07-06</created><authors><author><keyname>An</keyname><forenames>Jie</forenames></author><author><keyname>Xiong</keyname><forenames>Haoyi</forenames></author><author><keyname>Luo</keyname><forenames>Jiebo</forenames></author><author><keyname>Huan</keyname><forenames>Jun</forenames></author><author><keyname>Ma</keyname><forenames>Jinwen</forenames></author></authors><title>Fast Universal Style Transfer for Artistic and Photorealistic Rendering</title><categories>cs.CV cs.GR eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Universal style transfer is an image editing task that renders an input
content image using the visual style of arbitrary reference images, including
both artistic and photorealistic stylization. Given a pair of images as the
source of content and the reference of style, existing solutions usually first
train an auto-encoder (AE) to reconstruct the image using deep features and
then embeds pre-defined style transfer modules into the AE reconstruction
procedure to transfer the style of the reconstructed image through modifying
the deep features. While existing methods typically need multiple rounds of
time-consuming AE reconstruction for better stylization, our work intends to
design novel neural network architectures on top of AE for fast style transfer
with fewer artifacts and distortions all in one pass of end-to-end inference.
To this end, we propose two network architectures named ArtNet and PhotoNet to
improve artistic and photo-realistic stylization, respectively. Extensive
experiments demonstrate that ArtNet generates images with fewer artifacts and
distortions against the state-of-the-art artistic transfer algorithms, while
PhotoNet improves the photorealistic stylization results by creating sharp
images faithfully preserving rich details of the input content. Moreover,
ArtNet and PhotoNet can achieve 3X to 100X speed-up over the state-of-the-art
algorithms, which is a major advantage for large content images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03128</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03128</id><created>2019-07-06</created><authors><author><keyname>Liu</keyname><forenames>Pengju</forenames></author><author><keyname>Zhang</keyname><forenames>Hongzhi</forenames></author><author><keyname>Lian</keyname><forenames>Wei</forenames></author><author><keyname>Zuo</keyname><forenames>Wangmeng</forenames></author></authors><title>Multi-level Wavelet Convolutional Neural Networks</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In computer vision, convolutional networks (CNNs) often adopts pooling to
enlarge receptive field which has the advantage of low computational
complexity. However, pooling can cause information loss and thus is detrimental
to further operations such as features extraction and analysis. Recently,
dilated filter has been proposed to trade off between receptive field size and
efficiency. But the accompanying gridding effect can cause a sparse sampling of
input images with checkerboard patterns. To address this problem, in this
paper, we propose a novel multi-level wavelet CNN (MWCNN) model to achieve
better trade-off between receptive field size and computational efficiency. The
core idea is to embed wavelet transform into CNN architecture to reduce the
resolution of feature maps while at the same time, increasing receptive field.
Specifically, MWCNN for image restoration is based on U-Net architecture, and
inverse wavelet transform (IWT) is deployed to reconstruct the high resolution
(HR) feature maps. The proposed MWCNN can also be viewed as an improvement of
dilated filter and a generalization of average pooling, and can be applied to
not only image restoration tasks, but also any CNNs requiring a pooling
operation. The experimental results demonstrate effectiveness of the proposed
MWCNN for tasks such as image denoising, single image super-resolution, JPEG
image artifacts removal and object classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03133</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03133</id><created>2019-07-06</created><updated>2019-12-30</updated><authors><author><keyname>Yang</keyname><forenames>Gang</forenames></author><author><keyname>Xu</keyname><forenames>Xinyue</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author></authors><title>Intelligent Reflecting Surface Assisted Non-Orthogonal Multiple Access</title><categories>cs.IT eess.SP math.IT</categories><comments>32 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surface (IRS) is a new and disruptive technology to
achieve spectrum- and energy-efficient as well as cost-efficient wireless
networks. This paper considers an IRS-assisted downlink
non-orthogonal-multiple-access (NOMA) system. To optimize the rate performance
and ensure user fairness, we maximize the minimum decoding
signal-to-interference-plus-noise-ratio (i.e., equivalently the rate) of all
users, by jointly optimizing the (active) transmit beamforming at the base
station (BS) and the phase shifts (i.e., passive beamforming) at the IRS. A
combined-channel-strength based user ordering scheme is first proposed to
decouple the user-ordering design and the joint beamforming design. Efficient
algorithms are further proposed to solve the formulated non-convex problem for
the cases of a single-antenna BS and a multi-antenna BS, respectively, by
leveraging the block coordinated decent and semidefinite relaxation (SDR)
techniques. For the single-antenna BS case, the optimal solution for the power
allocation at the BS and the asymptotically optimal solution for the phase
shifts at the IRS are obtained in closed forms. For the multi-antenna BS case,
it is shown that the rank of the SDR solution to the transmit beamforming
design is upper bounded by two. Also, the convergence proof and the complexity
analysis are given for the proposed algorithms. Simulation results show that
the IRS-assisted downlink NOMA system can enhance the rate performance
significantly, compared to traditional NOMA without IRS and traditional
orthogonal multiple access with/without IRS. In addition, numerical results
demonstrate that the rate degradation due to the IRS's finite phase resolution
is slight, and good rate fairness among users can be always guaranteed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03138</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03138</id><created>2019-07-06</created><authors><author><keyname>Nguyen</keyname><forenames>Bang L. H.</forenames></author><author><keyname>Vu</keyname><forenames>Tuyen V.</forenames></author><author><keyname>Ngo</keyname><forenames>Tuan A.</forenames></author></authors><title>Decentralized Dynamic State Estimation in Microgrids</title><categories>eess.SY cs.SY</categories><comments>6 pages, 10 figures, Electric Ship Conference 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper proposes a decentralized dynamic state estimation scheme for
microgrids. The approach employs the voltage and current measurements in the
dq0 reference frame through phasor synchronization to be able to exclude
orthogonal functions from their relationship formulas. Based on that premise,
we utilize a Kalman filter to dynamically estimate states of microgrids. The
decoupling of measurement values to state and input vectors reduces the
computational complexity. The Kalman filter considers the process noise
covariances, which are modified with respect to the covariance of measured
input values. Theoretical analysis and simulation results are provided for
validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03164</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03164</id><created>2019-07-06</created><authors><author><keyname>Soomro</keyname><forenames>Bilal</forenames></author><author><keyname>Kanervisto</keyname><forenames>Anssi</forenames></author><author><keyname>Trong</keyname><forenames>Trung Ngo</forenames></author><author><keyname>Hautam&#xe4;ki</keyname><forenames>Ville</forenames></author></authors><title>Towards Debugging Deep Neural Networks by Generating Speech Utterances</title><categories>cs.LG eess.AS stat.ML</categories><comments>Accepted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks (DNN) are able to successfully process and classify
speech utterances. However, understanding the reason behind a classification by
DNN is difficult. One such debugging method used with image classification DNNs
is activation maximization, which generates example-images that are classified
as one of the classes. In this work, we evaluate applicability of this method
to speech utterance classifiers as the means to understanding what DNN &quot;listens
to&quot;. We trained a classifier using the speech command corpus and then use
activation maximization to pull samples from the trained model. Then we
synthesize audio from features using WaveNet vocoder for subjective analysis.
We measure the quality of generated samples by objective measurements and
crowd-sourced human evaluations. Results show that when combined with the prior
of natural speech, activation maximization can be used to generate examples of
different classes. Based on these results, activation maximization can be used
to start opening up the DNN black-box in speech tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03196</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03196</id><created>2019-07-06</created><authors><author><keyname>Ortega</keyname><forenames>Juan D. S.</forenames></author><author><keyname>Senoussaoui</keyname><forenames>Mohammed</forenames></author><author><keyname>Granger</keyname><forenames>Eric</forenames></author><author><keyname>Pedersoli</keyname><forenames>Marco</forenames></author><author><keyname>Cardinal</keyname><forenames>Patrick</forenames></author><author><keyname>Koerich</keyname><forenames>Alessandro L.</forenames></author></authors><title>Multimodal Fusion with Deep Neural Networks for Audio-Video Emotion
  Recognition</title><categories>cs.CV eess.AS eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel deep neural network (DNN) for multimodal fusion
of audio, video and text modalities for emotion recognition. The proposed DNN
architecture has independent and shared layers which aim to learn the
representation for each modality, as well as the best combined representation
to achieve the best prediction. Experimental results on the AVEC Sentiment
Analysis in the Wild dataset indicate that the proposed DNN can achieve a
higher level of Concordance Correlation Coefficient (CCC) than other
state-of-the-art systems that perform early fusion of modalities at
feature-level (i.e., concatenation) and late fusion at score-level (i.e.,
weighted average) fusion. The proposed DNN has achieved CCCs of 0.606, 0.534,
and 0.170 on the development partition of the dataset for predicting arousal,
valence and liking, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03217</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03217</id><created>2019-07-06</created><authors><author><keyname>He</keyname><forenames>Da</forenames></author><author><keyname>Cai</keyname><forenames>De</forenames></author><author><keyname>Zhou</keyname><forenames>Jiasheng</forenames></author><author><keyname>Luo</keyname><forenames>Jiajia</forenames></author><author><keyname>Chen</keyname><forenames>Sung-Liang</forenames></author></authors><title>Adaptive Weighting Depth-variant Deconvolution of Fluorescence
  Microscopy Images with Convolutional Neural Network</title><categories>eess.IV cs.CV</categories><comments>16 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluorescence microscopy plays an important role in biomedical research. The
depth-variant point spread function (PSF) of a fluorescence microscope produces
low-quality images especially in the out-of-focus regions of thick specimens.
Traditional deconvolution to restore the out-of-focus images is usually
insufficient since a depth-invariant PSF is assumed. This article aims at
handling fluorescence microscopy images by learning-based depth-variant PSF and
reducing artifacts. We propose adaptive weighting depth-variant deconvolution
(AWDVD) with defocus level prediction convolutional neural network (DelpNet) to
restore the out-of-focus images. Depth-variant PSFs of image patches can be
obtained by DelpNet and applied in the afterward deconvolution. AWDVD is
adopted for a whole image which is patch-wise deconvolved and appropriately
cropped before deconvolution. DelpNet achieves the accuracy of 98.2%, which
outperforms the best-ever one using the same microscopy dataset. Image patches
of 11 defocus levels after deconvolution are validated with maximum improvement
in the peak signal-to-noise ratio and structural similarity index of 6.6 dB and
11%, respectively. The adaptive weighting of the patch-wise deconvolved image
can eliminate patch boundary artifacts and improve deconvolved image quality.
The proposed method can accurately estimate depth-variant PSF and effectively
recover out-of-focus microscopy images. To our acknowledge, this is the first
study of handling out-of-focus microscopy images using learning-based
depth-variant PSF. Facing one of the most common blurs in fluorescence
microscopy, the novel method provides a practical technology to improve the
image quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03220</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03220</id><created>2019-07-07</created><updated>2019-08-03</updated><authors><author><keyname>Chaturvedi</keyname><forenames>Saket S.</forenames></author><author><keyname>Gupta</keyname><forenames>Kajol</forenames></author><author><keyname>Prasad</keyname><forenames>Prakash. S.</forenames></author></authors><title>Skin Lesion Analyser: An Efficient Seven-Way Multi-Class Skin Cancer
  Classification Using MobileNet</title><categories>eess.IV cs.CV</categories><comments>12 pages, 4 figures, and 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Skin cancer, a major form of cancer, is a critical public health problem with
123,000 newly diagnosed melanoma cases and between 2 and 3 million non-melanoma
cases worldwide each year. The leading cause of skin cancer is high exposure of
skin cells to UV radiation, which can damage the DNA inside skin cells leading
to uncontrolled growth of skin cells. Skin cancer is primarily diagnosed
visually employing clinical screening, a biopsy, dermoscopic analysis, and
histopathological examination. It has been demonstrated that the dermoscopic
analysis in the hands of inexperienced dermatologists may cause a reduction in
diagnostic accuracy. Early detection and screening of skin cancer have the
potential to reduce mortality and morbidity. Previous studies have shown Deep
Learning ability to perform better than human experts in several visual
recognition tasks. In this paper, we propose an efficient seven-way automated
multi-class skin cancer classification system having performance comparable
with expert dermatologists. We used a pretrained MobileNet model to train over
HAM10000 dataset using transfer learning. The model classifies skin lesion
image with a categorical accuracy of 83.1 percent, top2 accuracy of 91.36
percent and top3 accuracy of 95.34 percent. The weighted average of precision,
recall, and f1-score were found to be 0.89, 0.83, and 0.83 respectively. The
model has been deployed as a web application for public use at
(https://saketchaturvedi.github.io). This fast, expansible method holds the
potential for substantial clinical impact, including broadening the scope of
primary care practice and augmenting clinical decision-making for dermatology
specialists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03221</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03221</id><created>2019-07-07</created><updated>2019-07-09</updated><authors><author><keyname>Zhao</keyname><forenames>Xiaole</forenames></author><author><keyname>Liao</keyname><forenames>Ying</forenames></author><author><keyname>Li</keyname><forenames>Ye</forenames></author><author><keyname>Zhang</keyname><forenames>Tao</forenames></author><author><keyname>Zou</keyname><forenames>Xueming</forenames></author></authors><title>FC$^2$N: Fully Channel-Concatenated Network for Single Image
  Super-Resolution</title><categories>eess.IV cs.CV</categories><comments>19 pages, 14 figures and 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most current image super-resolution (SR) methods based on deep convolutional
neural networks (CNNs) use residual learning in network structural design,
which contributes to effective back propagation, thus improving SR performance
by increasing model scale. However, deep residual network suffers some
redundancy in model representational capacity by introducing short paths, thus
hindering the full mining of model capacity. In addition, blindly enlarging the
model scale will cause more problems in model training, even with residual
learning. In this work, a novel network architecture is introduced to fully
exploit the representational capacity of the model, where all skip connections
are implemented by weighted channel concatenation, followed by a 1$\times$1
conv layer. Based on this weighted skip connection, we construct the building
modules of our model, and improve the global feature fusion (GFF). Unlike most
previous models, all skip connections in our network are channel-concatenated
and no residual connection is adopted. It is therefore termed as fully
channel-concatenated network (FC$^2$N). Due to the full exploitation of model
capacity, the proposed FC$^2$N achieves better performance than other advanced
models with fewer model parameters. Extensive experiments demonstrate the
superiority of our method to other methods, in terms of both quantitative
metrics and visual quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03225</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03225</id><created>2019-07-07</created><authors><author><keyname>Yin</keyname><forenames>He</forenames></author><author><keyname>Arcak</keyname><forenames>Murat</forenames></author><author><keyname>Packard</keyname><forenames>Andrew</forenames></author><author><keyname>Seiler</keyname><forenames>Peter</forenames></author></authors><title>Backward Reachability for Polynomial Systems on A Finite Horizon</title><categories>eess.SY cs.SY</categories><comments>Submitted to IEEE TAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is presented to obtain an inner-approximation of the backward
reachable set (BRS) of a given target tube, along with an admissible controller
that maintains trajectories inside this tube. The proposed optimization
algorithms are formulated as nonlinear optimization problems, which are
decoupled into tractable subproblems and solved by an iterative algorithm using
the polynomial S-procedure and sum-of-squares techniques. This framework is
also extended to uncertain nonlinear systems with L_2 disturbances and
L_{\infty} parametric uncertainties. The effectiveness of the method is
demonstrated on several nonlinear robotics and aircraft systems with control
saturation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03233</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03233</id><created>2019-07-07</created><authors><author><keyname>Hsu</keyname><forenames>I-Hung</forenames></author><author><keyname>Jaiswal</keyname><forenames>Ayush</forenames></author><author><keyname>Natarajan</keyname><forenames>Premkumar</forenames></author></authors><title>NIESR: Nuisance Invariant End-to-end Speech Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>To appear in Proceedings of Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural network models for speech recognition have achieved great success
recently, but they can learn incorrect associations between the target and
nuisance factors of speech (e.g., speaker identities, background noise, etc.),
which can lead to overfitting. While several methods have been proposed to
tackle this problem, existing methods incorporate additional information about
nuisance factors during training to develop invariant models. However,
enumeration of all possible nuisance factors in speech data and the collection
of their annotations is difficult and expensive. We present a robust training
scheme for end-to-end speech recognition that adopts an unsupervised
adversarial invariance induction framework to separate out essential factors
for speech-recognition from nuisances without using any supplementary labels
besides the transcriptions. Experiments show that the speech recognition model
trained with the proposed training scheme achieves relative improvements of
5.48% on WSJ0, 6.16% on CHiME3, and 6.61% on TIMIT dataset over the base model.
Additionally, the proposed method achieves a relative improvement of 14.44% on
the combined WSJ0+CHiME3 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03244</identifier>
 <datestamp>2019-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03244</id><created>2019-07-07</created><updated>2019-10-12</updated><authors><author><keyname>Analooee</keyname><forenames>Ali</forenames></author><author><keyname>Azadi</keyname><forenames>Shahram</forenames></author><author><keyname>Kazemi</keyname><forenames>Reza</forenames></author></authors><title>Time Distance: A Novel Collision Prediction and Path Planning Method</title><categories>cs.RO cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motion planning is an active field of research in robot navigation and
autonomous driving. There are plenty of classical and heuristic motion planning
methods applicable to mobile robots and ground vehicles. This paper is
dedicated to introducing a novel method for collision prediction and path
planning. The method is called Time Distance (TD), and its basis returns to the
swept volume idea. However, there are considerable differences between the TD
method and existing methods associated with the swept volume concept. In this
method, time is obtained as a dependent variable in TD functions. TD functions
are functions of location, velocity, and geometry of objects, determining the
TD of objects with respect to any location. Known as a relative concept, TD is
defined as the time interval that must be spent in order for an object to reach
a certain location. It is firstly defined for the one-dimensional case and then
generalized to 2D space. The collision prediction algorithm consists of
obtaining the TD of different points of an object (the vehicle) with respect to
all objects of the environment using an explicit function which is a function
of TD functions. The path planning algorithm uses TD functions and two other
functions called Z-Infinity and Route Function to create the collision-free
path in a dynamic environment. Both the collision prediction and the path
planning algorithms are evaluated in simulations. Comparisons indicate the
capability of the method to generate length optimal paths as the most effective
methods do.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03246</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03246</id><created>2019-07-07</created><authors><author><keyname>Wang</keyname><forenames>Yan</forenames></author><author><keyname>Song</keyname><forenames>Wei</forenames></author><author><keyname>Fortino</keyname><forenames>Giancarlo</forenames></author><author><keyname>Qi</keyname><forenames>Lizhe</forenames></author><author><keyname>Zhang</keyname><forenames>Wenqiang</forenames></author><author><keyname>Liotta</keyname><forenames>Antonio</forenames></author></authors><title>An Experimental-based Review of Image Enhancement and Image Restoration
  Methods for Underwater Imaging</title><categories>eess.IV cs.CV cs.MM</categories><comments>19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Underwater images play a key role in ocean exploration, but often suffer from
severe quality degradation due to light absorption and scattering in water
medium. Although major breakthroughs have been made recently in the general
area of image enhancement and restoration, the applicability of new methods for
improving the quality of underwater images has not specifically been captured.
In this paper, we review the image enhancement and restoration methods that
tackle typical underwater image impairments, including some extreme
degradations and distortions. Firstly, we introduce the key causes of quality
reduction in underwater images, in terms of the underwater image formation
model (IFM). Then, we review underwater restoration methods, considering both
the IFM-free and the IFM-based approaches. Next, we present an
experimental-based comparative evaluation of state-of-the-art IFM-free and
IFM-based methods, considering also the prior-based parameter estimation
algorithms of the IFM-based methods, using both subjective and objective
analysis (the used code is freely available at
https://github.com/wangyanckxx/Single-Underwater-Image-Enhancement-and-Color-Restoration).
Starting from this study, we pinpoint the key shortcomings of existing methods,
drawing recommendations for future research in this area. Our review of
underwater image enhancement and restoration provides researchers with the
necessary background to appreciate challenges and opportunities in this
important field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03252</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03252</id><created>2019-07-07</created><authors><author><keyname>Jeddi</keyname><forenames>Babak</forenames></author><author><keyname>Mishra</keyname><forenames>Yateendra</forenames></author><author><keyname>Ledwich</keyname><forenames>Gerard</forenames></author></authors><title>Multiobjective Home Appliances Scheduling Considering Customer Thermal
  Discomfort: A Multistep Look-ahead ADP-Based Approach</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a multiobjective home energy management unit (MO_HEMU) to
balance the electricity payment and thermal discomfort of a household by
properly scheduling devices in a time varying price environment. The thermal
discomfort is measured by the deviation of indoor and hot water temperature
from the users ideal temperature. The home devices include solar Photovoltaics,
a battery storage system, deferrable, and thermal appliances. The proposed
MOHEMU is formulated as a dynamic program and a method based on the
approximated dynamic programming is used as the scheduling algorithm. The
developed method, called multistep look ahead algorithm, is an iterative
algorithm that overcomes the curse of dimensionality of the exact DP by
choosing a decision based on a limited number of stages ahead. The
effectiveness of the proposed model is investigated through numerical
simulations. The proposed MO_HEMU enables customers to find the desired trade
off between electricity payment and a discomfort level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03278</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03278</id><created>2019-07-07</created><authors><author><keyname>Bhowick</keyname><forenames>Debjani</forenames></author><author><keyname>Gupta</keyname><forenames>Deepak K.</forenames></author><author><keyname>Maiti</keyname><forenames>Saumen</forenames></author><author><keyname>Shankar</keyname><forenames>Uma</forenames></author></authors><title>Stacked autoencoders based machine learning for noise reduction and
  signal reconstruction in geophysical data</title><categories>eess.SP physics.geo-ph</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autoencoders are neural network formulations where the input and output of
the network are identical and the goal is to identify the hidden representation
in the provided datasets. Generally, autoencoders project the data nonlinearly
onto a lower dimensional hidden space, where the important features get
highlighted and interpretation of the data becomes easier. Recent studies have
shown that even in the presence of noise in the input data, autoencoders can be
trained to reconstruct the noisefree component of the data from the
reduced-dimensional hidden space.
  In this paper, we explore the application of autoencoders within the scope of
denoising geophysical datasets using a data-driven methodology. The autoencoder
formulation is discussed, and a stacked variant of deep autoencoders is
proposed. The proposed method involves locally training the weights first using
basic autoencoders, each comprising a single hidden layer. Using these
initialized weights as starting points in the optimization model, the full
autoencoder network is then trained in the second step. The applicability of
denoising autoencoders has been demonstrated on a basic mathematical example
and several geophysical examples. For all the cases, autoencoders are found to
significantly reduce the noise in the input data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03279</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03279</id><created>2019-07-07</created><authors><author><keyname>Secer</keyname><forenames>Gorkem</forenames></author></authors><title>Modeling, Analysis, and Control of Mechanical Systems under Power
  Constraints</title><categories>eess.SY cs.SY math.OC</categories><comments>Submitted to IEEE Transactions on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Significant improvements have been achieved in motion control systems with
the availability of high speed power switches and microcomputers on the market.
Even though motor drivers are able to provide high torque control bandwidth
under nominal conditions, they suffer from various physical constraints which
degrade both output amplitude and bandwidth of torque control loop. In this
context, peak power limit of a power source, as one of those constraints, has
not been fully explored from the control perspective so far. A conventional and
practical way of considering peak power limit in control systems is to model it
as a trivial torque saturation derived from the allowable torque at maximum
speed satisfying the constraint. However, this model is overly conservative
leading to poor closed loop performance when actuators operate below their
maximum speed. In this paper, novel ways of incorporating peak power limits
into both classical and optimal controllers are presented upon a theoretical
analysis revealing its effects on stability and performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03297</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03297</id><created>2019-07-07</created><authors><author><keyname>Nie</keyname><forenames>Dong</forenames></author><author><keyname>Xiang</keyname><forenames>Lei</forenames></author><author><keyname>Wang</keyname><forenames>Qian</forenames></author><author><keyname>Shen</keyname><forenames>Dinggang</forenames></author></authors><title>Dual Adversarial Learning with Attention Mechanism for Fine-grained
  Medical Image Synthesis</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical imaging plays a critical role in various clinical applications.
However, due to multiple considerations such as cost and risk, the acquisition
of certain image modalities could be limited. To address this issue, many
cross-modality medical image synthesis methods have been proposed. However, the
current methods cannot well model the hard-to-synthesis regions (e.g., tumor or
lesion regions). To address this issue, we propose a simple but effective
strategy, that is, we propose a dual-discriminator (dual-D) adversarial
learning system, in which, a global-D is used to make an overall evaluation for
the synthetic image, and a local-D is proposed to densely evaluate the local
regions of the synthetic image. More importantly, we build an adversarial
attention mechanism which targets at better modeling hard-to-synthesize regions
(e.g., tumor or lesion regions) based on the local-D. Experimental results show
the robustness and accuracy of our method in synthesizing fine-grained target
images from the corresponding source images. In particular, we evaluate our
method on two datasets, i.e., to address the tasks of generating T2 MRI from T1
MRI for the brain tumor images and generating MRI from CT. Our method
outperforms the state-of-the-art methods under comparison in all datasets and
tasks. And the proposed difficult-region-aware attention mechanism is also
proved to be able to help generate more realistic images, especially for the
hard-to-synthesize regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03305</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03305</id><created>2019-07-07</created><authors><author><keyname>Hoang</keyname><forenames>Van Truong</forenames></author><author><keyname>Phung</keyname><forenames>Manh Duong</forenames></author><author><keyname>Dinh</keyname><forenames>Tran Hiep</forenames></author><author><keyname>Ha</keyname><forenames>Quang P.</forenames></author></authors><title>System Architecture for Real-time Surface Inspection Using Multiple UAVs</title><categories>cs.RO cs.SY eess.SY</categories><journal-ref>IEEE Systems Journal, pp.1-12, 2019</journal-ref><doi>10.1109/JSYST.2019.2922290</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a real-time control system for surface inspection using
multiple unmanned aerial vehicles (UAVs). The UAVs are coordinated in a
specific formation to collect data of the inspecting objects. The communication
platform for data transmission is based on the Internet of Things (IoT). In the
proposed architecture, the UAV formation is established via using the
angle-encoded particle swarm optimisation to generate an inspecting path and
redistribute it to each UAV where communication links are embedded with an IoT
board for network and data processing capabilities. Data collected are
transmitted in real time through the network to remote computational units. To
detect potential damage or defects, an online image processing technique is
proposed and implemented based on histograms. Extensive simulation, experiments
and comparisons have been conducted to verify the validity and performance of
the proposed system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03327</identifier>
 <datestamp>2019-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03327</id><created>2019-07-07</created><authors><author><keyname>Dorent</keyname><forenames>Reuben</forenames></author><author><keyname>Li</keyname><forenames>Wenqi</forenames></author><author><keyname>Ekanayake</keyname><forenames>Jinendra</forenames></author><author><keyname>Ourselin</keyname><forenames>Sebastien</forenames></author><author><keyname>Vercauteren</keyname><forenames>Tom</forenames></author></authors><title>Learning joint lesion and tissue segmentation from task-specific
  hetero-modal datasets</title><categories>eess.IV cs.CV</categories><comments>Accepted as an oral presentation at MIDL 2019 [arXiv:1907.08612]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brain tissue segmentation from multimodal MRI is a key building block of many
neuroscience analysis pipelines. It could also play an important role in many
clinical imaging scenarios. Established tissue segmentation approaches have
however not been developed to cope with large anatomical changes resulting from
pathology. The effect of the presence of brain lesions, for example, on their
performance is thus currently uncontrolled and practically unpredictable.
Contrastingly, with the advent of deep neural networks (DNNs), segmentation of
brain lesions has matured significantly and is achieving performance levels
making it of interest for clinical use. However, few existing approaches allow
for jointly segmenting normal tissue and brain lesions. Developing a DNN for
such joint task is currently hampered by the fact that annotated datasets
typically address only one specific task and rely on a task-specific
hetero-modal imaging protocol. In this work, we propose a novel approach to
build a joint tissue and lesion segmentation model from task-specific
hetero-modal and partially annotated datasets. Starting from a variational
formulation of the joint problem, we show how the expected risk can be
decomposed and optimised empirically. We exploit an upper-bound of the risk to
deal with missing imaging modalities. For each task, our approach reaches
comparable performance than task-specific and fully-supervised models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03338</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03338</id><created>2019-07-07</created><updated>2019-10-11</updated><authors><author><keyname>Jungo</keyname><forenames>Alain</forenames></author><author><keyname>Reyes</keyname><forenames>Mauricio</forenames></author></authors><title>Assessing Reliability and Challenges of Uncertainty Estimations for
  Medical Image Segmentation</title><categories>eess.IV cs.CV</categories><comments>Appears in Medical Image Computing and Computer Assisted
  Interventions (MICCAI), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the recent improvements in overall accuracy, deep learning systems
still exhibit low levels of robustness. Detecting possible failures is critical
for a successful clinical integration of these systems, where each data point
corresponds to an individual patient. Uncertainty measures are a promising
direction to improve failure detection since they provide a measure of a
system's confidence. Although many uncertainty estimation methods have been
proposed for deep learning, little is known on their benefits and current
challenges for medical image segmentation. Therefore, we report results of
evaluating common voxel-wise uncertainty measures with respect to their
reliability, and limitations on two medical image segmentation datasets.
Results show that current uncertainty methods perform similarly and although
they are well-calibrated at the dataset level, they tend to be miscalibrated at
subject-level. Therefore, the reliability of uncertainty estimates is
compromised, highlighting the importance of developing subject-wise uncertainty
estimations. Additionally, among the benchmarked methods, we found auxiliary
networks to be a valid alternative to common uncertainty methods since they can
be applied to any previously trained segmentation model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03378</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03378</id><created>2019-07-07</created><authors><author><keyname>Dong</keyname><forenames>Ming</forenames></author><author><keyname>Sun</keyname><forenames>Jessie</forenames></author></authors><title>Partial Discharge Detection on Aerial Covered Conductors Using
  Time-Series Decomposition and Long Short-term Memory Network</title><categories>eess.SP</categories><comments>21 pages,13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, aerial covered conductors (CC) are increasingly used in many places
of the world due to their higher operational reliability, reduced construction
space and effective protection for wildlife animals. In spite of these
advantages, a major challenge of using CC is that the ordinary upstream
protection devices are not able to detect the phase-to-ground faults and the
frequent tree/tree branch hitting conductor events on such conductors. This is
because these events only lead to partial discharge (PD) activities rather than
overcurrent signatures typically seen on bare conductors. To solve this
problem, in recent years, ENET Center in Czech Republic (ENET) devised a simple
meter to measure the voltage signal of the electric stray field along CC,
aiming to detect the above hazardous PD activities. In 2018, ENET shared a
large amount of waveform data recorded by their meter on Kaggle, the world's
largest data science collaboration platform, encouraging worldwide experts to
develop an effective pattern recognition method for the acquired signals. In
response, we developed a unique method based on time-series decomposition and
Long Short-Term Memory Network (LSTM) in addition to unique feature engineering
process to recognize PD activities on CC. The proposed method is tested on the
ENET public dataset and compared to various traditional classification methods.
It demonstrated superior performance and great practicality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03405</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03405</id><created>2019-07-08</created><authors><author><keyname>Sarwar</keyname><forenames>Muhammad</forenames></author><author><keyname>Dawood</keyname><forenames>Atiqa</forenames></author><author><keyname>Maheen</keyname></author><author><keyname>Saleem</keyname><forenames>Ujyara</forenames></author><author><keyname>Abubakar</keyname><forenames>Muhammad</forenames></author></authors><title>Smart Switching and Control of a Distributed Generator Synchronized With
  National Grid</title><categories>eess.SY cs.SY eess.SP</categories><comments>6 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed generation is widely being utilized, so the basic theme of this
research is to have a hands-on experience to synchronize a Distributed Energy
Resource (DER) to the Mains Grid. A control algorithm is implemented for energy
supply from both sources i.e. DER and Mains Grid, according to the cost and
availability of each source. When load changes, so that the synchronization
does not lose. LabVIEW software is used for the implementation of the desired
system. Validation is done by experimenting in the lab. In order to keep the
system stable, the algorithm has been developed to shift the load from one bus
to the other depending upon the load requirements. The project is a test bed
and can be used for further experimentation and prove helpful in developing a
basic understanding of Smart Switching using LabVIEW.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03421</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03421</id><created>2019-07-08</created><authors><author><keyname>Sarwar</keyname><forenames>Muhammad</forenames></author><author><keyname>Ramzan</keyname><forenames>Anas</forenames></author><author><keyname>Naseer</keyname><forenames>Muhammad Usman</forenames></author><author><keyname>Asad</keyname><forenames>Bilal</forenames></author></authors><title>Real Time Control and Performance Analysis of A Smart Multi-Machine
  System through Hardware-in-the-Loop Simulation</title><categories>eess.SY cs.SY eess.SP</categories><comments>6 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an implementation of a smart power system using
inter-device communication and supervisory control through Simulink integrated
with the physical system. This control includes features of real-time control,
load management, fault detection and self-healing. The prototype is designed in
hardware which takes in required parameter via sensors to PC via RS-232 power
meter interface and actuator interfaced with Arduino microcontroller board
which is integrated with Simulink. Simulink simulates the model and predict
control signals depending upon input parameters and it sends control signal
back to Arduino which then control the hardware through hardware in the loop
(HIL) simulation. In the case of a severe fault, these control techniques
detect system variation and compensate for this variation or remove the faulty
part by using relays, which represents the self-healing nature of the developed
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03424</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03424</id><created>2019-07-08</created><authors><author><keyname>Huai</keyname><forenames>Jianzhu</forenames></author><author><keyname>Qin</keyname><forenames>Yusen</forenames></author><author><keyname>Pang</keyname><forenames>Fumin</forenames></author><author><keyname>Chen</keyname><forenames>Zichong</forenames></author></authors><title>Segway DRIVE Benchmark: Place Recognition and SLAM Data Collected by A
  Fleet of Delivery Robots</title><categories>cs.RO cs.CV eess.IV</categories><comments>8 pages, 4 figures, 4 tables, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual place recognition and simultaneous localization and mapping (SLAM)
have recently begun to be used in real-world autonomous navigation tasks like
food delivery. Existing datasets for SLAM research are often not representative
of in situ operations, leaving a gap between academic research and real-world
deployment. In response, this paper presents the Segway DRIVE benchmark, a
novel and challenging dataset suite collected by a fleet of Segway delivery
robots. Each robot is equipped with a global-shutter fisheye camera, a
consumer-grade IMU synced to the camera on chip, two low-cost wheel encoders,
and a removable high-precision lidar for generating reference solutions. As
they routinely carry out tasks in office buildings and shopping malls while
collecting data, the dataset spanning a year is characterized by planar
motions, moving pedestrians in scenes, and changing environment and lighting.
Such factors typically pose severe challenges and may lead to failures for SLAM
algorithms. Moreover, several metrics are proposed to evaluate metric place
recognition algorithms. With these metrics, sample SLAM and metric place
recognition methods were evaluated on this benchmark.
  The first release of our benchmark has hundreds of sequences, covering more
than 50 km of indoor floors. More data will be added as the robot fleet
continues to operate in real life. The benchmark is available at
http://drive.segwayrobotics.com/#/dataset/download.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03432</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03432</id><created>2019-07-08</created><authors><author><keyname>Xu</keyname><forenames>Pengfei</forenames></author><author><keyname>Jia</keyname><forenames>Yinjie</forenames></author><author><keyname>Wang</keyname><forenames>Zhijian</forenames></author></authors><title>Blind source separation using Fast-ICA with a novel nonlinear function</title><categories>eess.SP</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind source separation(BSS) is a hotspot in signal processing, and
independent component analysis (ICA) is a very effective tool for solving the
BSS problem. In order to improve the performance of the separation, a new
nonlinear function sin was introduced. It can replace the commonly used
classical functions (tanh, gauss and pow3) and does not need to select
different nonlinear functions according to the Gauss property of signals. The
two Matlab simulation results show that the improved Fast-ICA algorithm with
the proposed nonlinearity can not only improve the separation accuracy but also
speed up the convergence of blind source separation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03444</identifier>
 <datestamp>2019-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03444</id><created>2019-07-08</created><updated>2019-08-28</updated><authors><author><keyname>Papadopoulos</keyname><forenames>Athanasios</forenames></author><author><keyname>Chatzidiamantis</keyname><forenames>Nestor D.</forenames></author><author><keyname>Georgiadis</keyname><forenames>Leonidas</forenames></author></authors><title>Capacity and Algorithms for a Cognitive Network with Primary-Secondary
  User Cooperation</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we examine cognitive radio networks, where secondary users may
act as relays for messages sent by the primary user, hence offering performance
improvement of primary transmissions, while at the same time obtaining more
transmission opportunities for their own data. In particular, assuming the
broadcast packet erasure model with feedback, we investigate the capacity of
the fundamental cooperative cognitive radio network which consists of one
primary and one secondary transmitter-receiver pairs. The primary transmitter
is the owner of the channel and as such, we intend to keep its operations
simple and to avoid increasing its storage requirements. Specifically, the
primary transmitter does not receive data sent by the secondary transmitter and
does not perform any coding operations. On the other hand, the secondary
transmitter can overhear primary transmissions and is allowed to perform any
coding operations. We develop an outer bound to the capacity of the fundamental
cooperative cognitive radio network under consideration. Then, we propose a
coding-scheduling algorithm suitable for this type of networks, which involves
only XOR network coding operations. The complexity of the scheduling decisions
of the proposed algorithm depends on the channel statistical parameters and
three cases, depending on the relations between channel erasure probabilities,
are distinguished. For the first two cases the rate region of the proposed
algorithm coincides with the developed capacity outer bound, hence the
algorithm is capacity achieving. For the third case, the rate region of the
proposed algorithm is not identical to the outer bound; however, numerical
results show that it is fairly close to the derived outer bound for a wide
range of the statistical parameters of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03448</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03448</id><created>2019-07-08</created><authors><author><keyname>suiyi</keyname><forenames>Ling</forenames></author><author><keyname>Jing</keyname><forenames>Li</forenames></author><author><keyname>Patrick</keyname><forenames>Le Callet</forenames></author><author><keyname>Junle</keyname><forenames>Wang</forenames></author></authors><title>Perceptual representations of structural information in images:
  application to quality assessment of synthesized view in FTV scenario</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the immersive multimedia techniques like Free-viewpoint TV (FTV) develop
at an astonishing rate, user's demand for high-quality immersive contents
increases dramatically. Unlike traditional uniform artifacts, the distortions
within immersive contents could be non-uniform structure-related and thus are
challenging for commonly used quality metrics. Recent studies have demonstrated
that the representation of visual features can be extracted from multiple
levels of the hierarchy. Inspired by the hierarchical representation mechanism
in the human visual system (HVS), in this paper, we explore to adopt structural
representations to quantitatively measure the impact of such structure-related
distortion on perceived quality in FTV scenario. More specifically, a
bio-inspired full reference image quality metric is proposed based on 1)
low-level contour descriptor; 2) mid-level contour category descriptor; and 3)
task-oriented non-natural structure descriptor. The experimental results show
that the proposed model outperforms significantly the state-of-the-art metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03454</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03454</id><created>2019-07-08</created><authors><author><keyname>Nautsch</keyname><forenames>Andreas</forenames></author><author><keyname>Patino</keyname><forenames>Jose</forenames></author><author><keyname>Treiber</keyname><forenames>Amos</forenames></author><author><keyname>Stafylakis</keyname><forenames>Themos</forenames></author><author><keyname>Mizera</keyname><forenames>Petr</forenames></author><author><keyname>Todisco</keyname><forenames>Massimiliano</forenames></author><author><keyname>Schneider</keyname><forenames>Thomas</forenames></author><author><keyname>Evans</keyname><forenames>Nicholas</forenames></author></authors><title>Privacy-Preserving Speaker Recognition with Cohort Score Normalisation</title><categories>eess.AS cs.CR</categories><journal-ref>Proc. Interspeech 2019</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In many voice biometrics applications there is a requirement to preserve
privacy, not least because of the recently enforced General Data Protection
Regulation (GDPR). Though progress in bringing privacy preservation to voice
biometrics is lagging behind developments in other biometrics communities,
recent years have seen rapid progress, with secure computation mechanisms such
as homomorphic encryption being applied successfully to speaker recognition.
Even so, the computational overhead incurred by processing speech data in the
encrypted domain is substantial. While still tolerable for single biometric
comparisons, most state-of-the-art systems perform some form of cohort-based
score normalisation, requiring many thousands of biometric comparisons. The
computational overhead is then prohibitive, meaning that one must accept either
degraded performance (no score normalisation) or potential for privacy
violations. This paper proposes the first computationally feasible approach to
privacy-preserving cohort score normalisation. Our solution is a cohort pruning
scheme based on secure multi-party computation which enables privacy-preserving
score normalisation using probabilistic linear discriminant analysis (PLDA)
comparisons. The solution operates upon binary voice representations. While the
binarisation is lossy in biometric rank-1 performance, it supports
computationally-feasible biometric rank-n comparisons in the encrypted domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03455</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03455</id><created>2019-07-08</created><authors><author><keyname>Hezaveh</keyname><forenames>Hoomaan</forenames></author><author><keyname>Javadzadeh</keyname><forenames>Milad</forenames></author><author><keyname>Kahaei</keyname><forenames>MohammadHossein</forenames></author></authors><title>Signal Reconstruction using Blind Super-resolution with Arbitrary
  Sampling</title><categories>eess.SP</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the problem of blind super-resolution of sparse signals using
arbitrary sampling scheme and atomic lift is discussed. After comprehensive
description on blind superresolution problem, it is shown that using Prolate
Spheroidal Wave Functions (PSWFs), it is possible to derive a new SemiDefinite
Program (SDP) for the blind super-resolution problem. Unlike the previous
results, the newly proposed SDP can localize spikes without magnitude recovery.
Several numerical simulations were conducted to compare the performance of the
proposed method with the recent related research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03458</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03458</id><created>2019-07-08</created><authors><author><keyname>Nautsch</keyname><forenames>Andreas</forenames></author><author><keyname>Jasserand</keyname><forenames>Catherine</forenames></author><author><keyname>Kindt</keyname><forenames>Els</forenames></author><author><keyname>Todisco</keyname><forenames>Massimiliano</forenames></author><author><keyname>Trancoso</keyname><forenames>Isabel</forenames></author><author><keyname>Evans</keyname><forenames>Nicholas</forenames></author></authors><title>The GDPR &amp; Speech Data: Reflections of Legal and Technology Communities,
  First Steps towards a Common Understanding</title><categories>eess.AS cs.CY</categories><journal-ref>Proc. Interspeech 2019</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Privacy preservation and the protection of speech data is in high demand, not
least as a result of recent regulation, e.g. the General Data Protection
Regulation (GDPR) in the EU. While there has been a period with which to
prepare for its implementation, its implications for speech data is poorly
understood. This assertion applies to both the legal and technology
communities, and is hardly surprising since there is no universal definition of
'privacy', let alone a clear understanding of when or how the GDPR applies to
the capture, storage and processing of speech data. In aiming to initiate the
discussion that is needed to establish a level of harmonisation that is thus
far lacking, this contribution presents some reflections of both legal and
technology communities on the implications of the GDPR as regards speech data.
The article outlines the need for taxonomies at the intersection of speech
technology and data privacy - a discussion that is still very much in its
infancy - and describes the ways to safeguards and priorities for future
research. In being agnostic to any specific application, the treatment should
be of interest to the speech communication community at large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03467</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03467</id><created>2019-07-08</created><updated>2019-08-12</updated><authors><author><keyname>Stankovic</keyname><forenames>Ljubisa</forenames></author><author><keyname>Mandic</keyname><forenames>Danilo</forenames></author><author><keyname>Dakovic</keyname><forenames>Milos</forenames></author><author><keyname>Brajovic</keyname><forenames>Milos</forenames></author><author><keyname>Scalzo</keyname><forenames>Bruno</forenames></author><author><keyname>Constantinides</keyname><forenames>Tony</forenames></author></authors><title>Graph Signal Processing -- Part I: Graphs, Graph Spectra, and Spectral
  Clustering</title><categories>cs.IT eess.SP math.IT</categories><comments>49 pages, 40 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The area of Data Analytics on graphs promises a paradigm shift as we approach
information processing of classes of data, which are typically acquired on
irregular but structured domains (social networks, various ad-hoc sensor
networks). Yet, despite its long history, current approaches mostly focus on
the optimization of graphs themselves, rather than on directly inferring
learning strategies, such as detection, estimation, statistical and
probabilistic inference, clustering and separation from signals and data
acquired on graphs. To fill this void, we first revisit graph topologies from a
Data Analytics point of view, and establish a taxonomy of graph networks
through a linear algebraic formalism of graph topology (vertices, connections,
directivity). This serves as a basis for spectral analysis of graphs, whereby
the eigenvalues and eigenvectors of graph Laplacian and adjacency matrices are
shown to convey physical meaning related to both graph topology and
higher-order graph properties, such as cuts, walks, paths, and neighborhoods.
Next, to illustrate estimation strategies performed on graph signals, spectral
analysis of graphs is introduced through eigenanalysis of mathematical
descriptors of graphs and in a generic way. Finally, a framework for vertex
clustering and graph segmentation is established based on graph spectral
representation (eigenanalysis) which illustrates the power of graphs in various
data association tasks. The supporting examples demonstrate the promise of
Graph Data Analytics in modeling structural and functional/semantic inferences.
At the same time, Part I serves as a basis for Part II and Part III which deal
with theory, methods and applications of processing Data on Graphs and Graph
Topology Learning from data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03470</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03470</id><created>2019-07-08</created><authors><author><keyname>Fanitabasi</keyname><forenames>Farzam</forenames></author><author><keyname>Pournaras</keyname><forenames>Evangelos</forenames></author></authors><title>Appliance-level Flexible Scheduling for Socio-technical Smart Grid
  Optimisation</title><categories>eess.SY cs.MA cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Participation in energy demand response programs requires an active role by
users of residential appliances: they contribute flexibility in appliance usage
as the means to adjust energy consumption and improve Smart Grid reliability.
Understanding the collective potential that appliance-level flexibility has on
Smart Grid reliability is challenging and complex. Physical characteristics of
appliances, usage preferences, habits, and lifestyle are socio-technical
factors that influence system-wide reliability coming often at the expense of
users' comfort, i.e. thermal. This paper studies appliance-level flexible
scheduling and specifically the following research questions: (i) How flexible
are users in scheduling their appliances to improve Smart Grid reliability?
(ii) How do users' comfort requirements affect the contributions of flexibility
and as a result the collective action of improving Smart Grid reliability?
(iii) Which appliances have the highest regulatory impact on Smart Grid? (iv)
Can flexibility further improve Smart Grid reliability compared to simply
operating individual appliances more efficiently? And finally, (v) what is the
impact of varying users' participation on the collective action of improving
reliability? To address these questions, a distributed optimisation scheme is
studied to coordinate the selection of multiple appliance-level schedules
representing users' self-determined flexibility. Experimental evaluation using
a novel dataset shows that higher user flexibility significantly improves Smart
Grid reliability with the oven having the highest system-wide potential for
this. Compared to an existing efficiency scheme for kettles, flexible
coordinated scheduling shows further improvements in reliability. These new
findings have implications for the design of more cost-effective and granular
demand response programs in participatory and decentralised Smart Grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03471</identifier>
 <datestamp>2019-12-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03471</id><created>2019-07-08</created><updated>2019-12-26</updated><authors><author><keyname>Stankovic</keyname><forenames>Ljubisa</forenames></author><author><keyname>Mandic</keyname><forenames>Danilo P.</forenames></author><author><keyname>Dakovic</keyname><forenames>Milos</forenames></author><author><keyname>Scalzo</keyname><forenames>Bruno</forenames></author><author><keyname>Brajovic</keyname><forenames>Milos</forenames></author><author><keyname>Sejdic</keyname><forenames>Ervin</forenames></author><author><keyname>Constantinides</keyname><forenames>Anthony G.</forenames></author></authors><title>Vertex-Frequency Graph Signal Processing: A review</title><categories>eess.SP cs.IT math.IT</categories><comments>16 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph signal processing deals with signals which are observed on an irregular
graph domain. While many approaches have been developed in classical graph
theory to cluster vertices and segment large graphs in a signal independent
way, signal localization based approaches to the analysis of data on graph
represent a new research direction which is also a key to big data analytics on
graphs. To this end, after an overview of the basic definitions in graphs and
graph signals, we present and discuss a localized form of the graph Fourier
transform. To establish an analogy with classical signal processing, spectral-
and vertex-domain definitions of the localization window are given next. The
spectral and vertex localization kernels are then related to the wavelet
transform, followed by a study of filtering and inversion of the localized
graph Fourier transform. For rigour, the analysis of energy representation and
frames in the localized graph Fourier transform is extended to the energy forms
of vertex-frequency distributions, which operate even without the need to apply
localization windows. Another link with classical signal processing is
established through the concept of local smoothness, which is subsequently
related to the particular paradigm of signal smoothness on graphs. This all
represents a comprehensive account of the relation of general vertex-frequency
analysis with classical time-frequency analysis, and important but missing link
for more advanced applications of graphs signal processing. The theory is
supported by illustrative and practically relevant examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03495</identifier>
 <datestamp>2019-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03495</id><created>2019-07-08</created><authors><author><keyname>Hajianfar</keyname><forenames>Ghasem</forenames></author><author><keyname>Shiri</keyname><forenames>Isaac</forenames></author><author><keyname>Maleki</keyname><forenames>Hassan</forenames></author><author><keyname>Oveisi</keyname><forenames>Niki</forenames></author><author><keyname>Haghparast</keyname><forenames>Abbass</forenames></author><author><keyname>Abdollahi</keyname><forenames>Hamid</forenames></author><author><keyname>Oveisi</keyname><forenames>Mehrdad</forenames></author></authors><title>Non-Invasive MGMT Status Prediction in GBM Cancer Using Magnetic
  Resonance Images (MRI) Radiomics Features: Univariate and Multivariate
  Machine Learning Radiogenomics Analysis</title><categories>physics.med-ph cs.LG eess.IV q-bio.GN</categories><comments>28 Pages, 5 Figures, 3 Tables, 6 Supplemental Figure</comments><journal-ref>https://doi.org/10.1016/j.wneu.2019.08.232</journal-ref><doi>10.1016/j.wneu.2019.08.232</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background and aim: This study aimed to predict methylation status of the O-6
methyl guanine-DNA methyl transferase (MGMT) gene promoter status by using MRI
radiomics features, as well as univariate and multivariate analysis.
  Material and Methods: Eighty-two patients who had a MGMT methylation status
were include in this study. Tumor were manually segmented in the four regions
of MR images, a) whole tumor, b) active/enhanced region, c) necrotic regions
and d) edema regions (E). About seven thousand radiomics features were
extracted for each patient. Feature selection and classifier were used to
predict MGMT status through different machine learning algorithms. The area
under the curve (AUC) of receiver operating characteristic (ROC) curve was used
for model evaluations.
  Results: Regarding univariate analysis, the Inverse Variance feature from
gray level co-occurrence matrix (GLCM) in Whole Tumor segment with 4.5 mm Sigma
of Laplacian of Gaussian filter with AUC: 0.71 (p-value: 0.002) was found to be
the best predictor. For multivariate analysis, the decision tree classifier
with Select from Model feature selector and LOG filter in Edema region had the
highest performance (AUC: 0.78), followed by Ada Boost classifier with Select
from Model feature selector and LOG filter in Edema region (AUC: 0.74).
  Conclusion: This study showed that radiomics using machine learning
algorithms is a feasible, noninvasive approach to predict MGMT methylation
status in GBM cancer patients
  Keywords: Radiomics, Radiogenomics, GBM, MRI, MGMT
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03511</identifier>
 <datestamp>2020-01-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03511</id><created>2019-07-08</created><authors><author><keyname>Scheiner</keyname><forenames>Nicolas</forenames></author><author><keyname>Appenrodt</keyname><forenames>Nils</forenames></author><author><keyname>Dickmann</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Sick</keyname><forenames>Bernhard</forenames></author></authors><title>A Multi-Stage Clustering Framework for Automotive Radar Data</title><categories>cs.LG cs.RO eess.IV eess.SP stat.ML</categories><comments>8 pages, 5 figures, accepted paper for 2019 IEEE 22nd Intelligent
  Transportation Systems Conference (ITSC), Auckland, New Zealand, October 2019</comments><doi>10.1109/ITSC.2019.8916873</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radar sensors provide a unique method for executing environmental perception
tasks towards autonomous driving. Especially their capability to perform well
in adverse weather conditions often makes them superior to other sensors such
as cameras or lidar. Nevertheless, the high sparsity and low dimensionality of
the commonly used detection data level is a major challenge for subsequent
signal processing. Therefore, the data points are often merged in order to form
larger entities from which more information can be gathered. The merging
process is often implemented in form of a clustering algorithm. This article
describes a novel approach for first filtering out static background data
before applying a twostage clustering approach. The two-stage clustering
follows the same paradigm as the idea for data association itself: First,
clustering what is ought to belong together in a low dimensional parameter
space, then, extracting additional features from the newly created clusters in
order to perform a final clustering step. Parameters are optimized for
filtering and both clustering steps. All techniques are assessed both
individually and as a whole in order to demonstrate their effectiveness. Final
results indicate clear benefits of the first two methods and also the cluster
merging process under specific circumstances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03530</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03530</id><created>2019-07-08</created><authors><author><keyname>Casciano</keyname><forenames>Gianluca</forenames></author><author><keyname>Baracca</keyname><forenames>Paolo</forenames></author><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author></authors><title>Enabling Ultra Reliable Wireless Communications for Factory Automation
  with Distributed MIMO</title><categories>cs.IT eess.SP math.IT</categories><comments>Accepted at the IEEE Vehicular Technology Conference (VTC-Fall),
  Honolulu (HI), Sep. 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Factory automation is one of the most challenging use cases for 5G-and-beyond
mobile networks due to strict latency, availability and reliability
constraints. In this work, an indoor factory scenario is considered, and
distributed multiple-input multiple-output (MIMO) schemes are investigated in
order to enable reliable communication to the actuators (ACs) active in the
factory. Different levels of coordination among the access points serving the
ACs and several beamforming schemes are considered and analyzed. To enforce
system reliability, a max-min power allocation (MPA) algorithm is proposed,
aimed at improving the signal to interference plus noise ratio (SINR) of the
ACs with the worst channel conditions. Extensive system simulations are
performed in a realistic scenario, which includes a new path-loss model based
on recent measurements in factory scenarios, and, also, the presence of
non-Gaussian impulsive noise. Numerical results show that distributed MIMO
schemes with zero-forcing (ZF) beamforming and MPA have the potential of
providing SINR gains in the order of tens of dB with respect to a centralized
MIMO deployment, as well as that the impulsive noise can strongly degrade the
system performance and thus requires specific detection and mitigation
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03540</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03540</id><created>2019-07-08</created><updated>2019-09-24</updated><authors><author><keyname>Dudziak</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Abdelfattah</keyname><forenames>Mohamed S.</forenames></author><author><keyname>Vipperla</keyname><forenames>Ravichander</forenames></author><author><keyname>Laskaridis</keyname><forenames>Stefanos</forenames></author><author><keyname>Lane</keyname><forenames>Nicholas D.</forenames></author></authors><title>ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning</title><categories>cs.LG cs.AI eess.AS stat.ML</categories><comments>INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end automatic speech recognition (ASR) models are increasingly large
and complex to achieve the best possible accuracy. In this paper, we build an
AutoML system that uses reinforcement learning (RL) to optimize the per-layer
compression ratios when applied to a state-of-the-art attention based
end-to-end ASR model composed of several LSTM layers. We use singular value
decomposition (SVD) low-rank matrix factorization as the compression method.
For our RL-based AutoML system, we focus on practical considerations such as
the choice of the reward/punishment functions, the formation of an effective
search space, and the creation of a representative but small data set for quick
evaluation between search steps. Finally, we present accuracy results on
LibriSpeech of the model compressed by our AutoML system, and we compare it to
manually-compressed models. Our results show that in the absence of retraining
our RL-based search is an effective and practical method to compress a
production-grade ASR system. When retraining is possible, we show that our
AutoML system can select better highly-compressed seed models compared to
manually hand-crafted rank selection, thus allowing for more compression than
previously possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03547</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03547</id><created>2019-06-29</created><authors><author><keyname>Pinilla</keyname><forenames>Samuel</forenames></author><author><keyname>Bacca</keyname><forenames>Jorge</forenames></author><author><keyname>Vargas</keyname><forenames>Cesar</forenames></author><author><keyname>Poveda-Jaramillo</keyname><forenames>Juan Carlos</forenames></author><author><keyname>Arguello</keyname><forenames>Henry</forenames></author></authors><title>Exact Crystalline Structure Recovery in X-ray Crystallography from Coded
  Diffraction Patterns</title><categories>eess.IV physics.chem-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  X-ray crystallography (XC) is an experimental technique used to determine
three-dimensional crystalline structures. The acquired data in XC, called
diffraction patterns, is the Fourier magnitudes of the unknown crystalline
structure. To estimate the crystalline structure from its diffraction patterns,
we propose to modify the traditional system by including an optical element
called coded aperture which modulates the diffracted field to acquire coded
diffraction patterns (CDP). For the proposed coded system, in contrast with the
traditional, we derive exact reconstruction guarantees for the crystalline
structure from CDP (up to a global shift phase). Additionally, exploiting the
fact that the crystalline structure can be sparsely represented in the Fourier
domain, we develop an algorithm to estimate the crystal structure from CDP. We
show that this method requires 50% fewer measurements to estimate the crystal
structure in comparison with its competitive alternatives. Specifically, the
proposed method is able to reduce the exposition time of the crystal, implying
that under the proposed setup, its structural integrity is less affected in
comparison with the traditional. We discuss further implementation of imaging
devices that exploits this theoretical coded system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03548</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03548</id><created>2019-07-08</created><authors><author><keyname>Yuan</keyname><forenames>Wenguang</forenames></author><author><keyname>Wei</keyname><forenames>Jia</forenames></author><author><keyname>Wang</keyname><forenames>Jiabing</forenames></author><author><keyname>Ma</keyname><forenames>Qianli</forenames></author><author><keyname>Tasdizen</keyname><forenames>Tolga</forenames></author></authors><title>Unified Attentional Generative Adversarial Network for Brain Tumor
  Segmentation From Multimodal Unpaired Images</title><categories>cs.CV eess.IV</categories><comments>9 pages, 4 figures, Accepted by MICCAI2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In medical applications, the same anatomical structures may be observed in
multiple modalities despite the different image characteristics. Currently,
most deep models for multimodal segmentation rely on paired registered images.
However, multimodal paired registered images are difficult to obtain in many
cases. Therefore, developing a model that can segment the target objects from
different modalities with unpaired images is significant for many clinical
applications. In this work, we propose a novel two-stream translation and
segmentation unified attentional generative adversarial network (UAGAN), which
can perform any-to-any image modality translation and segment the target
objects simultaneously in the case where two or more modalities are available.
The translation stream is used to capture modality-invariant features of the
target anatomical structures. In addition, to focus on segmentation-related
features, we add attentional blocks to extract valuable features from the
translation stream. Experiments on three-modality brain tumor segmentation
indicate that UAGAN outperforms the existing methods in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03560</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03560</id><created>2019-07-01</created><authors><author><keyname>Wang</keyname><forenames>Jiaquan</forenames></author><author><keyname>Zeng</keyname><forenames>Yang</forenames></author><author><keyname>Jiang</keyname><forenames>Xinchao</forenames></author><author><keyname>Wang</keyname><forenames>Hu</forenames></author><author><keyname>Li</keyname><forenames>Enying</forenames></author><author><keyname>Li</keyname><forenames>Guangyao</forenames></author></authors><title>Variational Auto-Encoder Based Approximate Bayesian Computation
  Uncertian Inverse Method for Sheet Metal Forming Problem</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, an image-assisted Approximate Bayesian Computation (ABC)
parameter inverse method is proposed to identify the design parameters. In the
proposed method, the images are mapped to a low-dimensional latent space by
Variational Auto-Encoder (VAE), and the information loss is minimized by
network training. Therefore, an effective trade-off between information loss
and computational cost can be achieved by using the latent variables of VAE as
summary statistics of ABC, which overcomes the difficulty of selecting summary
statistics in the ABC. Besides, for some practical engineering problems,
processing the images as objective function can effective show the response
result. Meanwhile, the relationship between design parameters and the latent
variables is constructed by Least Squares Support Vector Regression (LSSVR)
surrogate model. With the well-constructed LSSVR model, the simulation
coefficient vectors under given parameters will be determined effectively.
Then, the parameters to be identified are determined by comparing the simulated
and observed coefficient vectors in ABC. Finally, a sheet forming problem is
investgated by the suggested method. The material parameters of the blank and
the process parameters of the forming process are identified. Results show that
the method is feasibility and effective for the identification of sheet forming
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03564</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03564</id><created>2019-07-08</created><authors><author><keyname>Mufid</keyname><forenames>Muhammad Syifa'ul</forenames></author><author><keyname>Adzkiya</keyname><forenames>Dieky</forenames></author><author><keyname>Abate</keyname><forenames>Alessandro</forenames></author></authors><title>Bounded Model Checking of Max-Plus Linear Systems via Predicate
  Abstractions</title><categories>cs.LO cs.SY eess.SY</categories><comments>19 pages, accepted in FORMATS 19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the abstraction of max-plus linear (MPL) systems via
predicates. Predicates are automatically selected from system matrix, as well
as from the specifications under consideration. We focus on verifying
time-difference specifications, which encompass the relation between successive
events in MPL systems. We implement a bounded model checking (BMC) procedure
over a predicate abstraction of the given MPL system, to verify the
satisfaction of time-difference specifications. Our predicate abstractions are
experimentally shown to improve on existing MPL abstractions algorithms.
Furthermore, with focus on the BMC algorithm, we can provide an explicit upper
bound on the completeness threshold by means of the transient and the cyclicity
of the underlying MPL system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03576</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03576</id><created>2019-07-03</created><authors><author><keyname>Samani</keyname><forenames>Ekta U.</forenames></author><author><keyname>Guo</keyname><forenames>Wei</forenames></author><author><keyname>Banerjee</keyname><forenames>Ashis G.</forenames></author></authors><title>Deep Learning-Based Semantic Segmentation of Microscale Objects</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>A condensed version of the paper is published in the Proceedings of
  the 2019 International Conference on Manipulation, Automation and Robotics at
  Small Scales</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate estimation of the positions and shapes of microscale objects is
crucial for automated imaging-guided manipulation using a non-contact technique
such as optical tweezers. Perception methods that use traditional computer
vision algorithms tend to fail when the manipulation environments are crowded.
In this paper, we present a deep learning model for semantic segmentation of
the images representing such environments. Our model successfully performs
segmentation with a high mean Intersection Over Union score of 0.91.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03588</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03588</id><created>2019-07-05</created><authors><author><keyname>Mitra</keyname><forenames>Aritra</forenames></author><author><keyname>Richards</keyname><forenames>John A.</forenames></author><author><keyname>Sundaram</keyname><forenames>Shreyas</forenames></author></authors><title>A New Approach to Distributed Hypothesis Testing and Non-Bayesian
  Learning: Improved Learning Rate and Byzantine-Resilience</title><categories>eess.SY cs.IT cs.LG cs.SY math.IT</categories><comments>arXiv admin note: text overlap with arXiv:1903.05817</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a setting where a group of agents, each receiving partially
informative private signals, seek to collaboratively learn the true underlying
state of the world (from a finite set of hypotheses) that generates their joint
observation profiles. To solve this problem, we propose a distributed learning
rule that differs fundamentally from existing approaches, in that it does not
employ any form of &quot;belief-averaging&quot;. Instead, agents update their beliefs
based on a min-rule. Under standard assumptions on the observation model and
the network structure, we establish that each agent learns the truth
asymptotically almost surely. As our main contribution, we prove that with
probability 1, each false hypothesis is ruled out by every agent exponentially
fast at a network-independent rate that is strictly larger than existing rates.
We then develop a computationally-efficient variant of our learning rule that
is provably resilient to agents who do not behave as expected (as represented
by a Byzantine adversary model) and deliberately try to spread misinformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03591</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03591</id><created>2019-07-04</created><authors><author><keyname>Chen</keyname><forenames>Junyu</forenames></author><author><keyname>Frey</keyname><forenames>Eric C.</forenames></author></authors><title>Feature-Based Image Clustering and Segmentation Using Wavelets</title><categories>eess.IV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pixel intensity is a widely used feature for clustering and segmentation
algorithms, the resulting segmentation using only intensity values might suffer
from noises and lack of spatial context information. Wavelet transform is often
used for image denoising and classification. We proposed a novel method to
incorporate Wavelet features in segmentation and clustering algorithms. The
conventional K-means, Fuzzy c-means (FCM), and Active contour without edges
(ACWE) algorithms were modified to adapt Wavelet features, leading to robust
clustering/segmentation algorithms. A weighting parameter to control the weight
of low-frequency sub-band information was also introduced. The new algorithms
showed the capability to converge to different segmentation results based on
the frequency information derived from the Wavelet sub-bands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03641</identifier>
 <datestamp>2019-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03641</id><created>2019-07-08</created><authors><author><keyname>Rouzbahani</keyname><forenames>Hossein Mohammadi</forenames></author><author><keyname>Rahimnezhad</keyname><forenames>Abolfazl</forenames></author><author><keyname>Karimipour</keyname><forenames>Hadis</forenames></author></authors><title>Smart Households Demand Response Management with Micro Grid</title><categories>eess.SY cs.LG cs.SY</categories><comments>ISGT 2018</comments><doi>10.1109/ISGT.2019.8791595</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays the emerging smart grid technology opens up the possibility of
two-way communication between customers and energy utilities. Demand Response
Management (DRM) offers the promise of saving money for commercial customers
and households while helps utilities operate more efficiently. In this paper,
an Incentive-based Demand Response Optimization (IDRO) model is proposed to
efficiently schedule household appliances for minimum usage during peak hours.
The proposed method is a multi-objective optimization technique based on
Nonlinear Auto-Regressive Neural Network (NAR-NN) which considers energy
provided by the utility and rooftop installed photovoltaic (PV) system. The
proposed method is tested and verified using 300 case studies (household). Data
analysis for a period of one year shows a noticeable improvement in power
factor and customers bill.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03697</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03697</id><created>2019-06-05</created><authors><author><keyname>Efremova</keyname><forenames>Natalia</forenames></author><author><keyname>Zausaev</keyname><forenames>Dmitry</forenames></author><author><keyname>Antipov</keyname><forenames>Gleb</forenames></author></authors><title>Prediction of Soil Moisture Content Based On Satellite Data and
  Sequence-to-Sequence Networks</title><categories>eess.IV cs.CV cs.LG</categories><comments>Presented on NeurIPS 2018 WiML workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main objective of this study is to combine remote sensing and machine
learning to detect soil moisture content. Growing population and food
consumption has led to the need to improve agricultural yield and to reduce
wastage of natural resources. In this paper, we propose a neural network
architecture, based on recent work by the research community, that can make a
strong social impact and aid United Nations Sustainable Development Goal of
Zero Hunger. The main aims here are to: improve efficiency of water usage;
reduce dependence on irrigation; increase overall crop yield; minimise risk of
crop loss due to drought and extreme weather conditions. We achieve this by
applying satellite imagery, crop segmentation, soil classification and NDVI and
soil moisture prediction on satellite data, ground truth and climate data
records. By applying machine learning to sensor data and ground data, farm
management systems can evolve into a real time AI enabled platform that can
provide actionable recommendations and decision support tools to the farmers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03728</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03728</id><created>2019-07-08</created><authors><author><keyname>Xu</keyname><forenames>Ziyue</forenames></author><author><keyname>Wang</keyname><forenames>Xiaosong</forenames></author><author><keyname>Shin</keyname><forenames>Hoo-Chang</forenames></author><author><keyname>Yang</keyname><forenames>Dong</forenames></author><author><keyname>Roth</keyname><forenames>Holger</forenames></author><author><keyname>Milletari</keyname><forenames>Fausto</forenames></author><author><keyname>Zhang</keyname><forenames>Ling</forenames></author><author><keyname>Xu</keyname><forenames>Daguang</forenames></author></authors><title>Correlation via synthesis: end-to-end nodule image generation and
  radiogenomic map learning based on generative adversarial network</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radiogenomic map linking image features and gene expression profiles is
useful for noninvasively identifying molecular properties of a particular type
of disease. Conventionally, such map is produced in three separate steps: 1)
gene-clustering to &quot;metagenes&quot;, 2) image feature extraction, and 3) statistical
correlation between metagenes and image features. Each step is independently
performed and relies on arbitrary measurements. In this work, we investigate
the potential of an end-to-end method fusing gene data with image features to
generate synthetic image and learn radiogenomic map simultaneously. To achieve
this goal, we develop a generative adversarial network (GAN) conditioned on
both background images and gene expression profiles, synthesizing the
corresponding image. Image and gene features are fused at different scales to
ensure the realism and quality of the synthesized image. We tested our method
on non-small cell lung cancer (NSCLC) dataset. Results demonstrate that the
proposed method produces realistic synthetic images, and provides a promising
way to find gene-image relationship in a holistic end-to-end manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03798</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03798</id><created>2019-07-08</created><authors><author><keyname>Najgebauer</keyname><forenames>Patryk</forenames></author><author><keyname>Scherer</keyname><forenames>Rafal</forenames></author></authors><title>Fully Convolutional Network for Removing DCT Artefacts From Images</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning methods achieve excellent results in image transformations as
well as image noise reduction or super-resolution methods. Based on these
solutions, we present a deep-learning method of block reconstruction of images
compressed with the JPEG format. Images compressed with the discrete cosine
transform (DCT) contain visible artefacts in the form of blocks, which in some
cases spoil the aesthetics of the image mostly on the edges of the contrasting
elements. This is unavoidable, and the discernibility of the block artefacts
can be adjusted by the degree of image compression, which profoundly affects
the output image size. We use a fully convolutional network which operates
directly on 8x8-pixel blocks in the same way as the JPEG encoder. Thanks to
that, we do not modify the input image; we only divide it into separately
processed blocks. The purpose of our neural model is to modify the pixels in
the blocks to reduce artefact visibility %against the background of the
neighbouring image and to recreate the original pattern of the image distorted
by the DCT transform. We trained our model on a dataset created from vector
images transformed to the JPEG and PNG formats, as the input and output data,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03862</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03862</id><created>2019-07-08</created><authors><author><keyname>Hu</keyname><forenames>Xiaoyan</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author><author><keyname>Yang</keyname><forenames>Kun</forenames></author><author><keyname>Zheng</keyname><forenames>Zhongbin</forenames></author></authors><title>Task and Bandwidth Allocation for UAV-Assisted Mobile Edge Computing
  with Trajectory Design</title><categories>eess.SP</categories><comments>6 pages, 3 figures, conference. arXiv admin note: substantial text
  overlap with arXiv:1812.02658</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate a mobile edge computing (MEC) architecture with
the assistance of an unmanned aerial vehicle (UAV). The UAV acts as a computing
server to help the user equipment (UEs) compute their tasks as well as a relay
to further offload the UEs' tasks to the access point (AP) for computing. The
total energy consumption of the UAV and UEs is minimized by jointly optimizing
the task allocation, the bandwidth allocation and the UAV's trajectory, subject
to the task constraints, the information-causality constraints, the bandwidth
allocation constraints, and the UAV's trajectory constraints. The formulated
optimization problem is nonconvex, and we propose an alternating algorithm to
optimize the parameters iteratively. The effectiveness of the algorithm is
verified by the simulation results, where great performance gain is achieved in
comparison with some practical baselines, especially in handling the
computation-intensive and latency-critical tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03865</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03865</id><created>2019-07-08</created><authors><author><keyname>Alkhimova</keyname><forenames>S. M.</forenames></author><author><keyname>Krenevych</keyname><forenames>A. P.</forenames></author></authors><title>Brain Tissues Segmentation on MR Perfusion Images Using CUSUM Filter for
  Boundary Pixels</title><categories>eess.IV cs.CV</categories><journal-ref>International Journal of Computing (2019), V. 18, N 2., P. 127-134</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fully automated and relatively accurate method of brain tissues
segmentation on T2-weighted magnetic resonance perfusion images is proposed.
Segmentation with this method provides a possibility to obtain perfusion region
of interest on images with abnormal brain anatomy that is very important for
perfusion analysis. In the proposed method the result is presented as a binary
mask, which marks two regions: brain tissues pixels with unity values and
skull, extracranial soft tissue and background pixels with zero values. The
binary mask is produced based on the location of boundary between two studied
regions. Each boundary point is detected with CUSUM filter as a change point
for iteratively accumulated points at time of moving on a sinusoidal-like path
along the boundary from one region to another. The evaluation results for 20
clinical cases showed that proposed segmentation method could significantly
reduce the time and efforts required to obtain desirable results for perfusion
region of interest detection on T2-weighted magnetic resonance perfusion images
with abnormal brain anatomy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03898</identifier>
 <datestamp>2019-09-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03898</id><created>2019-07-08</created><authors><author><keyname>Likhite</keyname><forenames>Rugved</forenames></author><author><keyname>Banerjee</keyname><forenames>Aishwaryadev</forenames></author><author><keyname>Majumder</keyname><forenames>Apratim</forenames></author><author><keyname>and</keyname><forenames>Hanseup Kim</forenames></author><author><keyname>Mastrangelo</keyname><forenames>Carlos H.</forenames></author></authors><title>Parametrically Amplified Low-Power MEMS Capacitive Humidity Sensor</title><categories>physics.app-ph cs.SY eess.SY</categories><doi>10.3390/s19183954</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the design, fabrication, and response of a polymer-based Laterally
Amplified Chemo-Mechanical (LACM) humidity sensor based on mechanical
leveraging and parametric amplification. The device consists of a sense
cantilever asymmetrically patterned with a polymer and flanked by two
stationary electrodes on the sides. When exposed to a humidity change, the
polymer swells after absorbing the analyte and causes the central cantilever to
bend laterally towards one side, causing a change in the measured capacitance.
The device features an intrinsic gain due to parametric amplification resulting
in an enhanced signal-to-noise ratio (SNR). 11-fold magnification in sensor
response was observed via voltage biasing of the side electrodes without the
use of conventional electronic amplifiers. The sensor showed a repeatable and
recoverable capacitance change of 11% when exposed to a change in relative
humidity from 25-85%. The dynamic characterization of the device also revealed
a response time ~1s and demonstrated a competitive response with respect to a
commercially available reference chip.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03912</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03912</id><created>2019-07-08</created><updated>2019-07-12</updated><authors><author><keyname>Krijestorac</keyname><forenames>Enes</forenames></author><author><keyname>Hanna</keyname><forenames>Samer</forenames></author><author><keyname>Cabric</keyname><forenames>Danijela</forenames></author></authors><title>UAV Access Point Placement for Connectivity to a User with Unknown
  Location Using Deep RL</title><categories>eess.SP cs.SY eess.SY</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, unmanned aerial vehicles (UAVs) have been considered for
telecommunications purposes as relays, caches, or IoT data collectors. In
addition to being easy to deploy, their maneuverability allows them to adjust
their location to optimize the capacity of the link to the user equipment on
the ground or of the link to the basestation. The majority of the previous work
that analyzes the optimal placement of such a UAV makes at least one of two
assumptions: the channel can be predicted using a simple model or the locations
of the users on the ground are known. In this paper, we use deep reinforcement
learning (deep RL) to optimally place a UAV serving a ground user in an urban
environment, without the previous knowledge of the channel or user location.
Our algorithm relies on signal-to-interference-plus-noise ratio (SINR)
measurements and a 3D map of the topology to account for blockage and
scatterers. Furthermore, it is designed to operate in any urban environment.
Results in conditions simulated by a ray tracing software show that with the
constraint on the maximum number of iterations our algorithm has a 90% success
rate in converging to a target SINR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03929</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03929</id><created>2019-07-08</created><updated>2019-07-10</updated><authors><author><keyname>Joneidi</keyname><forenames>Mohsen</forenames></author></authors><title>Functional Brain Networks Discovery Using Dictionary Learning with
  Correlated Sparsity</title><categories>eess.SP eess.IV q-bio.NC stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of data from functional magnetic resonance imaging (fMRI) results in
constructing functional brain networks. Principal component analysis (PCA) and
independent component analysis (ICA) are widely used to generate functional
brain networks. Moreover, dictionary learning and sparse representation provide
some latent patterns that rules brain activities and they can be interpreted as
brain networks. However, these methods lack modeling dependencies of the
discovered networks. In this study an alternative to these conventional methods
is presented in which dependencies of the networks are considered via
correlated sparsity patterns. We formulate this challenge as a new dictionary
learning problem and propose two approaches to solve the problem effectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03957</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03957</id><created>2019-07-08</created><authors><author><keyname>Aragon-Calvo</keyname><forenames>Miguel A.</forenames></author></authors><title>Self-supervised Learning with Physics-aware Neural Networks I: Galaxy
  Model Fitting</title><categories>astro-ph.GA astro-ph.IM eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating the parameters of a model describing a set of observations using a
neural network is in general solved in a supervised way. In cases when we do
not have access to the model's true parameters this approach can not be
applied. Standard unsupervised learning techniques on the other hand, do not
produce meaningful or semantic representations that can be associated to the
model's parameters. Here we introduce a self-supervised hybrid network that
combines traditional neural network elements with analytic or numerical models
which represent a physical process to be learned by the system. Self-supervised
learning is achieved by generating an internal representation equivalent to the
parameters of the physical model. This semantic representation is used to
evaluate the model and compare it to the input data during training. The
Semantic Autoencoder architecture described here shares the robustness of
neural networks while including an explicit model of the data, learns in an
unsupervised way and estimates, by construction, parameters with direct
physical interpretation. As an illustrative application we perform unsupervised
learning for 2D model fitting of exponential light profiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03960</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03960</id><created>2019-07-08</created><authors><author><keyname>Abousamra</keyname><forenames>Shahira</forenames></author><author><keyname>Hou</keyname><forenames>Le</forenames></author><author><keyname>Gupta</keyname><forenames>Rajarsi</forenames></author><author><keyname>Chen</keyname><forenames>Chao</forenames></author><author><keyname>Samaras</keyname><forenames>Dimitris</forenames></author><author><keyname>Kurc</keyname><forenames>Tahsin</forenames></author><author><keyname>Batiste</keyname><forenames>Rebecca</forenames></author><author><keyname>Zhao</keyname><forenames>Tianhao</forenames></author><author><keyname>Kenneth</keyname><forenames>Shroyer</forenames></author><author><keyname>Saltz</keyname><forenames>Joel</forenames></author></authors><title>Learning from Thresholds: Fully Automated Classification of Tumor
  Infiltrating Lymphocytes for Multiple Cancer Types</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning classifiers for characterization of whole slide tissue
morphology require large volumes of annotated data to learn variations across
different tissue and cancer types. As is well known, manual generation of
digital pathology training data is time consuming and expensive. In this paper,
we propose a semi-automated method for annotating a group of similar instances
at once, instead of collecting only per-instance manual annotations. This
allows for a much larger training set, that reflects visual variability across
multiple cancer types and thus training of a single network which can be
automatically applied to each cancer type without human adjustment. We apply
our method to the important task of classifying Tumor Infiltrating Lymphocytes
(TILs) in H&amp;E images. Prior approaches were trained for individual cancer
types, with smaller training sets and human-in-the-loop threshold adjustment.
We utilize these thresholded results as large scale &quot;semi-automatic&quot;
annotations. Combined with existing manual annotations, our trained deep
networks are able to automatically produce better TIL prediction results in 12
cancer types, compared to the human-in-the-loop approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03981</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03981</id><created>2019-07-09</created><authors><author><keyname>Dai</keyname><forenames>Xunhua</forenames></author><author><keyname>Ke</keyname><forenames>Chenxu</forenames></author><author><keyname>Quan</keyname><forenames>Quan</forenames></author><author><keyname>Cai</keyname><forenames>Kai-Yuan</forenames></author></authors><title>Simulation Credibility Assessment Methodology with FPGA-based
  Hardware-in-the-loop Platform</title><categories>eess.SY cs.SY</categories><comments>8 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electronic control systems are becoming more and more complicated, which
makes it difficult to test them sufficiently only through experiments.
Simulation is an efficient way in the development and testing of complex
electronic systems, but the simulation results are always doubtful by people
due to the lack of credible simulation platforms and assessment methods. This
paper proposes a credible simulation platform based on real-time FPGA-based
hardware-in-the-loop (HIL) simulation, and then an assessment method is
proposed to quantitatively assess its simulation credibility. By using the FPGA
to simulate all sensor chips, the simulation platform can ensure that the
tested electronic system maintains the same hardware and software operating
environment in both simulations and experiments, which makes it possible to
perform the same tests in the simulation platform and the real experiment to
compare and analyze the simulation errors. Then, the testing methods and
assessment indices are proposed to assess the simulation platform from various
perspectives, such as performance, time-domain response, and frequency-domain
response. These indices are all normalized to the same scale (from 0 to 1) and
mapped to a uniform assessment criterion, which makes it convenient to compare
and synthesize different assessment indices. Finally, an overall assessment
index is proposed by combining all assessment indices obtained from different
tests to assess the simulation credibility of the whole simulation platform.
The simulation platform and the proposed assessment method are applied to a
multicopter system, where the effectiveness and practicability are verified by
simulations and experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03988</identifier>
 <datestamp>2020-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03988</id><created>2019-07-09</created><updated>2020-02-10</updated><authors><author><keyname>Tang</keyname><forenames>Zhenyu</forenames></author><author><keyname>Chen</keyname><forenames>Lianwu</forenames></author><author><keyname>Wu</keyname><forenames>Bo</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author><author><keyname>Manocha</keyname><forenames>Dinesh</forenames></author></authors><title>Improving Reverberant Speech Training Using Diffuse Acoustic Simulation</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted to ICASSP 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an efficient and realistic geometric acoustic simulation approach
for generating and augmenting training data in speech-related machine learning
tasks. Our physically-based acoustic simulation method is capable of modeling
occlusion, specular and diffuse reflections of sound in complicated acoustic
environments, whereas the classical image method can only model specular
reflections in simple room settings. We show that by using our synthetic
training data, the same neural networks gain significant performance
improvement on real test sets in far-field speech recognition by 1.58% and
keyword spotting by 21%, without fine-tuning using real impulse responses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.03994</identifier>
 <datestamp>2019-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.03994</id><created>2019-07-09</created><updated>2019-08-10</updated><authors><author><keyname>Zeng</keyname><forenames>Youwei</forenames></author><author><keyname>Wu</keyname><forenames>Dan</forenames></author><author><keyname>Xiong</keyname><forenames>Jie</forenames></author><author><keyname>Yi</keyname><forenames>Enze</forenames></author><author><keyname>Gao</keyname><forenames>Ruiyang</forenames></author><author><keyname>Zhang</keyname><forenames>Daqing</forenames></author></authors><title>FarSense: Pushing the Range Limit of WiFi-based Respiration Sensing with
  CSI Ratio of Two Antennas</title><categories>eess.SP cs.HC</categories><comments>This work is a pre-print version to appear at UbiComp 2019</comments><doi>10.1145/3351279</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The past few years have witnessed the great potential of exploiting channel
state information retrieved from commodity WiFi devices for respiration
monitoring. However, existing approaches only work when the target is close to
the WiFi transceivers and the performance degrades significantly when the
target is far away. On the other hand, most home environments only have one
WiFi access point and it may not be located in the same room as the target.
This sensing range constraint greatly limits the application of the proposed
approaches in real life.
  This paper presents FarSense--the first real-time system that can reliably
monitor human respiration when the target is far away from the WiFi transceiver
pair. FarSense works well even when one of the transceivers is located in
another room, moving a big step towards real-life deployment. We propose two
novel schemes to achieve this goal: (1) Instead of applying the raw CSI
readings of individual antenna for sensing, we employ the ratio of CSI readings
from two antennas, whose noise is mostly canceled out by the division operation
to significantly increase the sensing range; (2) The division operation further
enables us to utilize the phase information which is not usable with one single
antenna for sensing. The orthogonal amplitude and phase are elaborately
combined to address the &quot;blind spots&quot; issue and further increase the sensing
range. Extensive experiments show that FarSense is able to accurately monitor
human respiration even when the target is 8 meters away from the transceiver
pair, increasing the sensing range by more than 100%. We believe this is the
first system to enable through-wall respiration sensing with commodity WiFi
devices and the proposed method could also benefit other sensing applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04008</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04008</id><created>2019-07-09</created><authors><author><keyname>Ahmed</keyname><forenames>Nisar R.</forenames></author></authors><title>Decentralized Gaussian Mixture Fusion through Unified Quotient
  Approximations</title><categories>eess.SP cs.RO cs.SY eess.SY stat.CO</categories><comments>submitted for journal review to Information Fusion; conference
  version published in IEEE MFI 2015 conference: N. Ahmed, &quot;What's One Mixture
  Divided by Another? A unified approach to high-fidelity distributed data
  fusion with mixture models&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work examines the problem of using finite Gaussian mixtures (GM)
probability density functions in recursive Bayesian peer-to-peer decentralized
data fusion (DDF). It is shown that algorithms for both exact and approximate
GM DDF lead to the same problem of finding a suitable GM approximation to a
posterior fusion pdf resulting from the division of a `naive Bayes' fusion GM
(representing direct combination of possibly dependent information sources) by
another non-Gaussian pdf (representing removal of either the actual or
estimated `common information' between the information sources). The resulting
quotient pdf for general GM fusion is naturally a mixture pdf, although the
fused mixands are non-Gaussian and are not analytically tractable for recursive
Bayesian updates. Parallelizable importance sampling algorithms for both direct
local approximation and indirect global approximation of the quotient mixture
are developed to find tractable GM approximations to the non-Gaussian `sum of
quotients' mixtures. Practical application examples for multi-platform static
target search and maneuverable range-based target tracking demonstrate the
higher fidelity of the resulting approximations compared to existing GM DDF
techniques, as well as their favorable computational features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04057</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04057</id><created>2019-07-09</created><updated>2019-07-09</updated><authors><author><keyname>Zhang</keyname><forenames>Xiaoxiang</forenames></author><author><keyname>Fu</keyname><forenames>Hao</forenames></author><author><keyname>Dai</keyname><forenames>Bin</forenames></author></authors><title>Lidar-based Object Classification with Explicit Occlusion Modeling</title><categories>cs.RO cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LIDAR is one of the most important sensors for Unmanned Ground Vehicles
(UGV). Object detection and classification based on lidar point cloud is a key
technology for UGV. In object detection and classification, the mutual
occlusion between neighboring objects is an important factor affecting the
accuracy. In this paper, we consider occlusion as an intrinsic property of the
point cloud data. We propose a novel approach that explicitly model the
occlusion. The occlusion property is then taken into account in the subsequent
classification step. We perform experiments on the KITTI dataset. Experimental
results indicate that by utilizing the occlusion property that we modeled, the
classifier obtains much better performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04060</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04060</id><created>2019-07-09</created><authors><author><keyname>Renner</keyname><forenames>Alpha</forenames></author><author><keyname>Evanusa</keyname><forenames>Matthew</forenames></author><author><keyname>Sandamirskaya</keyname><forenames>Yulia</forenames></author></authors><title>Event-based attention and tracking on neuromorphic hardware</title><categories>cs.NE eess.IV</categories><comments>IEEE Conference on Computer Vision and Pattern Recognition Workshops
  (CVPRW), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a fully event-driven vision and processing system for selective
attention and tracking, realized on a neuromorphic processor Loihi interfaced
to an event-based Dynamic Vision Sensor DAVIS. The attention mechanism is
realized as a recurrent spiking neural network that implements
attractor-dynamics of dynamic neural fields. We demonstrate capability of the
system to create sustained activation that supports object tracking when
distractors are present or when the object slows down or stops, reducing the
number of generated events.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04062</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04062</id><created>2019-07-09</created><authors><author><keyname>Rikos</keyname><forenames>Apostolos I.</forenames></author><author><keyname>Hadjicostis</keyname><forenames>Christoforos N.</forenames></author></authors><title>Distributed Integer Balancing under Weight Constraints in the Presence
  of Transmission Delays and Packet Drops</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the distributed weight balancing problem in networks of nodes
that are interconnected via directed edges, each of which is able to admit a
positive integer weight within a certain interval, captured by individual lower
and upper limits. A digraph with positive integer weights on its (directed)
edges is weight-balanced if, for each node, the sum of the weights of the
incoming edges equals the sum of the weights of the outgoing edges. In this
work, we develop a distributed iterative algorithm which solves the integer
weight balancing problem in the presence of arbitrary (time-varying and
inhomogeneous) time delays that might affect transmissions at particular links.
We assume that communication between neighboring nodes is bidirectional, but
unreliable since it may be affected from bounded or unbounded delays (packet
drops), independently between different links and link directions. We show
that, even when communication links are affected from bounded delays or
occasional packet drops (but not permanent communication link failures), the
proposed distributed algorithm allows the nodes to converge to a set of weight
values that solves the integer weight balancing problem, after a finite number
of iterations with probability one, as long as the necessary and sufficient
circulation conditions on the lower and upper edge weight limits are satisfied.
Finally, we provide examples to illustrate the operation and performance of the
proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04064</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04064</id><created>2019-07-09</created><authors><author><keyname>Petersen</keyname><forenames>Jens</forenames></author><author><keyname>J&#xe4;ger</keyname><forenames>Paul F.</forenames></author><author><keyname>Isensee</keyname><forenames>Fabian</forenames></author><author><keyname>Kohl</keyname><forenames>Simon A. A.</forenames></author><author><keyname>Neuberger</keyname><forenames>Ulf</forenames></author><author><keyname>Wick</keyname><forenames>Wolfgang</forenames></author><author><keyname>Debus</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Heiland</keyname><forenames>Sabine</forenames></author><author><keyname>Bendszus</keyname><forenames>Martin</forenames></author><author><keyname>Kickingereder</keyname><forenames>Philipp</forenames></author><author><keyname>Maier-Hein</keyname><forenames>Klaus H.</forenames></author></authors><title>Deep Probabilistic Modeling of Glioma Growth</title><categories>eess.IV cs.CV cs.LG</categories><comments>MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing approaches to modeling the dynamics of brain tumor growth,
specifically glioma, employ biologically inspired models of cell diffusion,
using image data to estimate the associated parameters. In this work, we
propose an alternative approach based on recent advances in probabilistic
segmentation and representation learning that implicitly learns growth dynamics
directly from data without an underlying explicit model. We present evidence
that our approach is able to learn a distribution of plausible future tumor
appearances conditioned on past observations of the same tumor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04067</identifier>
 <datestamp>2019-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04067</id><created>2019-07-09</created><updated>2019-12-17</updated><authors><author><keyname>Kozarcanin</keyname><forenames>S.</forenames></author><author><keyname>Hanna</keyname><forenames>R.</forenames></author><author><keyname>Staffell</keyname><forenames>I.</forenames></author><author><keyname>Gross</keyname><forenames>R.</forenames></author><author><keyname>Andresen</keyname><forenames>G. B.</forenames></author></authors><title>Impact of climate change on the cost-optimal mix of decentralised heat
  pump and gas boiler technologies in Europe</title><categories>eess.SY cs.SY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Residential demands for space heating and hot water account for 31% of the
total European energy demand. Space heating is highly dependent on ambient
conditions and susceptible to climate change. We adopt a techno-economic
standpoint and assess the impact of climate change on decentralised heating
demand and the cost-optimal mix of heat pump and gas boiler technologies.
Temperature data with high spatial resolution from nine climate models
implementing three Representative Concentration Pathways from IPCC are used to
estimate climate induced changes in the European demand side for heating. The
demand side is modelled by the proxy of heating-degree days. The supply side is
modelled by using a screening curve approach to the economics of heat
generation. We find that space heating demand decreases by about 16%, 24% and
42% in low, intermediate and extreme global warming scenarios. When considering
historic weather data, we find a heterogeneous mix of technologies are
cost-optimal, depending on the heating load factor (number of full-load hours
per year). Increasing ambient temperatures toward the end-century improve the
economic performance of heat pumps in all concentration pathways. Cost optimal
technologies broadly correspond to heat markets and policies in Europe, with
some exceptions
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04070</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04070</id><created>2019-07-09</created><authors><author><keyname>Marchese</keyname><forenames>Davide</forenames></author><author><keyname>Coraggio</keyname><forenames>Marco</forenames></author><author><keyname>Hogan</keyname><forenames>S. John</forenames></author><author><keyname>di Bernardo</keyname><forenames>Mario</forenames></author></authors><title>Control of Painlev\'e Paradox in a Robotic System</title><categories>eess.SY cs.RO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Painlev\'e paradox is a phenomenon that causes instability in mechanical
systems subjects to unilateral constraints. While earlier studies were mostly
focused on abstract theoretical settings, recent work confirmed the occurrence
of the paradox in realistic set-ups. In this paper, we investigate the dynamics
and presence of the Painlev\'e phenomenon in a twolinks robot in contact with a
moving belt, through a bifurcation study. Then, we use the results of this
analysis to inform the design of control strategies able to keep the robot
sliding on the belt and avoid the onset of undesired lift-off. To this aim,
through numerical simulations, we synthesise and compare a PID strategy and a
hybrid force/motion control scheme, finding that the latter is able to
guarantee better performance and avoid the onset of bouncing motion due to the
Painlev\'e phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04080</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04080</id><created>2019-07-09</created><authors><author><keyname>Khaleghzadeh</keyname><forenames>Hamidreza</forenames></author><author><keyname>Fahad</keyname><forenames>Muhammad</forenames></author><author><keyname>Shahid</keyname><forenames>Arsalan</forenames></author><author><keyname>Manumachu</keyname><forenames>Ravi Reddy</forenames></author><author><keyname>Lastovetsky</keyname><forenames>Alexey</forenames></author></authors><title>Bi-objective Optimisation of Data-parallel Applications on Heterogeneous
  Platforms for Performance and Energy via Workload Distribution</title><categories>cs.DC cs.PF cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance and energy are the two most important objectives for optimisation
on modern parallel platforms. Latest research demonstrated the importance of
workload distribution as a decision variable in the bi-objective optimisation
for performance and energy on homogeneous multicore clusters. We show in this
work that bi-objective optimisation for performance and energy on heterogeneous
processors results in a large number of Pareto-optimal optimal solutions
(workload distributions) even in the simple case of linear performance and
energy profiles. We then study performance and energy profiles of real-life
data-parallel applications and find that their shapes are non-linear, complex
and non-smooth. We, therefore, propose an efficient and exact global
optimisation algorithm, which takes as an input most general discrete
performance and dynamic energy profiles of the heterogeneous processors and
solves the bi-objective optimisation problem. The algorithm is also used as a
building block to solve the bi-objective optimisation problem for performance
and total energy. We also propose a novel methodology to build discrete dynamic
energy profiles of individual computing devices, which are input to the
algorithm. The methodology is based purely on system-level measurements and
addresses the fundamental challenge of accurate component-level energy
modelling of a hybrid data-parallel application running on a heterogeneous
platform integrating CPUs and accelerators. We experimentally validate the
proposed method using two data-parallel applications, matrix multiplication and
2D fast Fourier transform (2D-FFT).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04100</identifier>
 <datestamp>2019-08-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04100</id><created>2019-07-09</created><updated>2019-08-15</updated><authors><author><keyname>Rojtberg</keyname><forenames>Pavel</forenames></author><author><keyname>Gorschl&#xfc;ter</keyname><forenames>Felix</forenames></author></authors><title>calibDB: enabling web based computer vision through on-the-fly camera
  calibration</title><categories>cs.CV cs.NI eess.IV</categories><doi>10.1145/3329714.3338132</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  For many computer vision applications, the availability of camera calibration
data is crucial as overall quality heavily depends on it. While calibration
data is available on some devices through Augmented Reality (AR) frameworks
like ARCore and ARKit, for most cameras this information is not available.
Therefore, we propose a web based calibration service that not only aggregates
calibration data, but also allows calibrating new cameras on-the-fly. We build
upon a novel camera calibration framework that enables even novice users to
perform a precise camera calibration in about 2 minutes. This allows general
deployment of computer vision algorithms on the web, which was previously not
possible due to lack of calibration data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04102</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04102</id><created>2019-07-09</created><authors><author><keyname>Wachinger</keyname><forenames>Christian</forenames></author><author><keyname>Becker</keyname><forenames>Benjamin Gutierrez</forenames></author><author><keyname>Rieckmann</keyname><forenames>Anna</forenames></author><author><keyname>P&#xf6;lsterl</keyname><forenames>Sebastian</forenames></author></authors><title>Quantifying Confounding Bias in Neuroimaging Datasets with Causal
  Inference</title><categories>cs.LG cs.CV eess.IV stat.ML</categories><comments>MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neuroimaging datasets keep growing in size to address increasingly complex
medical questions. However, even the largest datasets today alone are too small
for training complex machine learning models. A potential solution is to
increase sample size by pooling scans from several datasets. In this work, we
combine 12,207 MRI scans from 15 studies and show that simple pooling is often
ill-advised due to introducing various types of biases in the training data.
First, we systematically define these biases. Second, we detect bias by
experimentally showing that scans can be correctly assigned to their respective
dataset with 73.3% accuracy. Finally, we propose to tell causal from
confounding factors by quantifying the extent of confounding and causality in a
single dataset using causal inference. We achieve this by finding the simplest
graphical model in terms of Kolmogorov complexity. As Kolmogorov complexity is
not directly computable, we employ the minimum description length to
approximate it. We empirically show that our approach is able to estimate
plausible causal relationships from real neuroimaging data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04124</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04124</id><created>2019-07-09</created><updated>2019-07-11</updated><authors><author><keyname>Mahmoudzadeh</keyname><forenames>Ahmadreza</forenames></author><author><keyname>Yeganeh</keyname><forenames>Sayna Firoozi</forenames></author><author><keyname>Golroo</keyname><forenames>Amir</forenames></author></authors><title>3D pavement surface reconstruction using an RGB-D sensor</title><categories>cs.CV eess.IV</categories><comments>5 pages, 7 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A core procedure of pavement management systems is data collection. The
modern technologies which are used for this purpose, such as point-based lasers
and laser scanners, are too expensive to purchase, operate, and maintain. Thus,
it is rarely feasible for city officials in developing countries to conduct
data collection using these devices. This paper aims to introduce a
cost-effective technology which can be used for pavement distress data
collection and 3D pavement surface reconstruction. The applied technology in
this research is the Kinect sensor which is not only cost-effective but also
sufficiently precise. The Kinect sensor can register both depth and color
images simultaneously. A cart is designed to mount an array of Kinect sensors.
The cameras are calibrated and the slopes of collected surfaces are corrected
via the Singular Value Decomposition (SVD) algorithm. Then, a procedure is
proposed for stitching the RGB-D (Red Green Blue Depth) images using SURF
(Speeded-up Robust Features) and MSAC (M-estimator SAmple Consensus) algorithms
in order to create a 3D-structure of the pavement surface. Finally, transverse
profiles are extracted and some field experiments are conducted to evaluate the
reliability of the proposed approach for detecting pavement surface defects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04133</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04133</id><created>2019-07-09</created><authors><author><keyname>Kadam</keyname><forenames>Sachin</forenames></author><author><keyname>Y.</keyname><forenames>Sesha Vivek</forenames></author><author><keyname>Prasad</keyname><forenames>P. Hari</forenames></author><author><keyname>Kumar</keyname><forenames>Rajesh</forenames></author><author><keyname>Kasbekar</keyname><forenames>Gaurav S.</forenames></author></authors><title>Rapid Node Cardinality Estimation in Heterogeneous Machine-to-Machine
  Networks</title><categories>eess.SP</categories><comments>14 pages, 21 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine-to-Machine (M2M) networks are an emerging technology with
applications in various fields, including smart grids, healthcare, vehicular
telematics and smart cities. Heterogeneous M2M networks contain different types
of nodes, e.g., nodes that send emergency, periodic, and normal type data. An
important problem is to rapidly estimate the number of active nodes of each
node type in every time frame in such a network. In this paper, we design two
schemes for estimating the active node cardinalities of each node type in a
heterogeneous M2M network with $T$ types of nodes, where $T \ge 2$ is an
arbitrary integer. Our schemes consist of two phases-- in phase 1, coarse
estimates are computed, and in phase 2, these estimates are used to compute the
final estimates to the required accuracy. We analytically derive a condition
for one of our schemes that can be used to decide as to which of two possible
approaches should be used in phase 2 to minimize its execution time. The
expected number of time slots required to execute and the expected energy
consumption of each active node under one of our schemes are analysed. Using
simulations, we show that our proposed schemes require significantly fewer time
slots to execute compared to estimation schemes designed for a heterogeneous
M2M network in prior work, and also, compared to separately executing a
well-known estimation protocol designed for a homogeneous network in prior work
$T$ times to estimate the cardinalities of the $T$ node types, even though all
these schemes obtain estimates with the same accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04136</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04136</id><created>2019-06-21</created><authors><author><keyname>Bi</keyname><forenames>Huibo</forenames></author><author><keyname>Gelenbe</keyname><forenames>Erol</forenames></author></authors><title>Emergency Management Systems and Algorithms: a Comprehensive Survey</title><categories>cs.OH cs.SY eess.SY</categories><comments>33 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Owing to the increasing frequency and destruction of natural and manmade
disasters to modern highly-populated societies, emergency management, which
provides solutions to prevent or address disasters, have drawn considerable
research over the last few decades and become a multidisciplinary area. Because
of its open and inclusive nature, new technologies always tend to influence,
change or even revolutionise this research area. Hence, it is imperative to
consolidate the state-of-the-art studies and knowledge to meet the research
needs and identify the future research directions. The paper presents a
comprehensive and systemic review of the existing research in the field of
emergency management from both the system design aspect and algorithm
engineering aspect. We begin with the history and evolution of the emergency
management research. Then the two main research topics of this area, &quot;emergency
navigation&quot; and &quot;emergency search and rescue planning&quot;, are introduced and
discussed. Finally, we suggest the emerging challenges and opportunities from
system optimisation, evacuee behaviour modelling and optimisation, computing
patterns, data analysis, energy and cyber security aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04186</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04186</id><created>2019-07-08</created><authors><author><keyname>Nikitin</keyname><forenames>Alexei V.</forenames></author><author><keyname>Davidchack</keyname><forenames>Ruslan L.</forenames></author></authors><title>Bandwidth Is Not Enough: &quot;Hidden&quot; Outlier Noise and Its Mitigation</title><categories>eess.SP</categories><comments>9 pages, 12 figures. arXiv admin note: substantial text overlap with
  arXiv:1905.10476, arXiv:1906.01456</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In addition to ever-present thermal noise, communication and sensor systems
can contain significant amounts of interference with outlier (e.g. impulsive)
characteristics. Such outlier interference (including that caused by nonlinear
signal distortions, e.g. clipping) can be efficiently mitigated in real-time
using intermittently nonlinear filters. Depending on the interference nature
and composition, improvements in the quality of the signal of interest achieved
by such filtering will vary from &quot;no harm&quot; to substantial. In this tutorial, we
explain in detail why the underlying outlier nature of interference often
remains obscured, discussing the many challenges and misconceptions associated
with state-of-art analog and/or digital nonlinear mitigation techniques,
especially when addressing complex practical interference scenarios. We then
focus on the methodology and tools for real-time outlier noise mitigation,
demonstrating how the &quot;excess band&quot; observation of outlier noise enables its
efficient in-band mitigation. We introduce the basic real-time nonlinear
components that are used for outlier noise filtering and provide examples of
their implementation. We further describe complementary nonlinear filtering
arrangements for wide- and narrow-band outlier noise reduction, providing
illustrations of their performance and the effect on channel capacity. Finally,
we outline &quot;effectively analog&quot; digital implementations of these filtering
structures, discuss their broader applications, and comment on the ongoing
development of the platform for their demonstration and testing. To emphasize
the effectiveness and versatility of this approach, in our examples we use
particularly challenging waveforms that severely obscure low-amplitude outlier
noise, such as broadband chirp signals (e.g. used in radar, sonar, and
spread-spectrum communications) and &quot;bursty,&quot; high crest factor signals (e.g.
OFDM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04202</identifier>
 <datestamp>2019-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04202</id><created>2019-07-07</created><updated>2019-10-06</updated><authors><author><keyname>Okada</keyname><forenames>Masashi</forenames></author><author><keyname>Taniguchi</keyname><forenames>Tadahiro</forenames></author></authors><title>Variational Inference MPC for Bayesian Model-based Reinforcement
  Learning</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><comments>Accepted to CoRL2019. Camera-ready ver</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent studies on model-based reinforcement learning (MBRL), incorporating
uncertainty in forward dynamics is a state-of-the-art strategy to enhance
learning performance, making MBRLs competitive to cutting-edge model free
methods, especially in simulated robotics tasks. Probabilistic ensembles with
trajectory sampling (PETS) is a leading type of MBRL, which employs Bayesian
inference to dynamics modeling and model predictive control (MPC) with
stochastic optimization via the cross entropy method (CEM). In this paper, we
propose a novel extension to the uncertainty-aware MBRL. Our main contributions
are twofold: Firstly, we introduce a variational inference MPC, which
reformulates various stochastic methods, including CEM, in a Bayesian fashion.
Secondly, we propose a novel instance of the framework, called probabilistic
action ensembles with trajectory sampling (PaETS). As a result, our Bayesian
MBRL can involve multimodal uncertainties both in dynamics and optimal
trajectories. In comparison to PETS, our method consistently improves
asymptotic performance on several challenging locomotion tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04213</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04213</id><created>2019-07-06</created><authors><author><keyname>Paulen</keyname><forenames>Radoslav</forenames></author><author><keyname>Fikar</keyname><forenames>Miroslav</forenames></author></authors><title>Dynamic Real-time Optimization of Batch Processes using Pontryagin's
  Minimum Principle and Set-membership Adaptation</title><categories>eess.SY cs.SY math.OC</categories><comments>arXiv admin note: text overlap with arXiv:1906.08546</comments><doi>10.1016/j.compchemeng.2019.06.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a dynamic real-time optimization in the context of
model-based time-optimal operation of batch processes under parametric model
mismatch. In order to tackle the model-mismatch issue, a receding-horizon
policy is usually followed with frequent re-optimization. The main problem
addressed in this study is the high computational burden that is usually
required by such schemes. We propose an approach that uses parameterized
conditions of optimality in the adaptive predictive-control fashion. The
uncertainty in the model predictions is treated explicitly using reachable sets
that are projected into the optimality conditions. Adaptation of model
parameters is performed online using set-membership estimation. A class of
batch membrane separation processes is in the scope of the presented
applications, where the benefits of the presented approach are outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04222</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04222</id><created>2019-07-07</created><authors><author><keyname>Neeluru</keyname><forenames>Vijay Kumar</forenames></author><author><keyname>Ahuja</keyname><forenames>Vikas</forenames></author></authors><title>Void region segmentation in ball grid array using u-net approach and
  synthetic data</title><categories>eess.IV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quality inspection of solder balls by detecting and measuring the void is
important to improve the board yield issues in electronic circuits. In general,
the inspection is carried out manually, based on 2D or 3D X-ray images. For
high quality inspection, it is difficult to detect and measure voids accurately
with high repeatability through the manual inspection and the process is time
consuming. In need of high quality and fast inspection, various approaches were
proposed, but, due to the various challenges like vias, reflections from the
plating or vias, inconsistent lighting, noise and void-like artifacts makes
these approaches difficult to work in all these challenging conditions. In
recent times, deep learning approaches are providing the outstanding accuracy
in various computer vision tasks. Considering the need of high quality and fast
inspection, in this paper, we applied U-Net to segment the void regions in
soldering balls. As it is difficult to get the annotated dataset covering all
the variations of void, we proposed an approach to generated the synthetic
dataset. The proposed approach is able to segment the voids and can be easily
scaled to various electronic products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04224</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04224</id><created>2019-07-09</created><authors><author><keyname>Belinkov</keyname><forenames>Yonatan</forenames></author><author><keyname>Ali</keyname><forenames>Ahmed</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Analyzing Phonetic and Graphemic Representations in End-to-End Automatic
  Speech Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>Interspeech 2019 (slightly expanded version)</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end neural network systems for automatic speech recognition (ASR) are
trained from acoustic features to text transcriptions. In contrast to modular
ASR systems, which contain separately-trained components for acoustic modeling,
pronunciation lexicon, and language modeling, the end-to-end paradigm is both
conceptually simpler and has the potential benefit of training the entire
system on the end task. However, such neural network models are more opaque: it
is not clear how to interpret the role of different parts of the network and
what information it learns during training. In this paper, we analyze the
learned internal representations in an end-to-end ASR model. We evaluate the
representation quality in terms of several classification tasks, comparing
phonemes and graphemes, as well as different articulatory features. We study
two languages (English and Arabic) and three datasets, finding remarkable
consistency in how different properties are represented in different layers of
the deep neural network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04239</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04239</id><created>2019-07-08</created><authors><author><keyname>Baidoo-Williams</keyname><forenames>Henry Ernest</forenames></author><author><keyname>Rahman</keyname><forenames>Muhammad Mahboob Ur</forenames></author><author><keyname>Abbasi</keyname><forenames>Qammer Hussain</forenames></author></authors><title>Channel Impulse Response-based Source Localization in a Diffusion-based
  Molecular Communication System</title><categories>eess.SP cs.IT math.IT</categories><comments>17 pages, 4 figures, submitted to Elsevier Nano Communication
  Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work localizes a molecular source in a diffusion based molecular
communication (DbMC) system via a set of passive sensors and a fusion center.
Molecular source localization finds its applications in future healthcare
systems, including proactive diagnostics. In this paper, we propose two
distinct methods which both utilize (the peak of) the channel impulse response
measurements to uniquely localize the source, under assumption that the
molecular source of interest lies within the open convex-hull of the
sensor/anchor nodes. The first method is a one-shot, triangulation-based
approach which estimates the unknown location of the molecular source using
least-squares method. The corresponding Cramer-Rao bound (CRB) is also derived.
The second method is an iterative approach, which utilizes gradient descent law
to minimize a non-convex cost function. Simulation results reveal that the
triangulation-based method performs very close to the CRB, for any given
signal- to-noise ratio. Additionally, the gradient descent-based method
converges to the true optima/source location uniformly (in less than hundred
iterations).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04240</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04240</id><created>2019-07-08</created><authors><author><keyname>Luo</keyname><forenames>Xihaier</forenames></author><author><keyname>Kareem</keyname><forenames>Ahsan</forenames></author></authors><title>Bayesian deep learning with hierarchical prior: Predictions from limited
  and noisy data</title><categories>stat.ML cs.LG eess.SP physics.comp-ph</categories><comments>33 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Datasets in engineering applications are often limited and contaminated,
mainly due to unavoidable measurement noise and signal distortion. Thus, using
conventional data-driven approaches to build a reliable discriminative model,
and further applying this identified surrogate to uncertainty analysis remains
to be very challenging. A deep learning approach is presented to provide
predictions based on limited and noisy data. To address noise perturbation, the
Bayesian learning method that naturally facilitates an automatic updating
mechanism is considered to quantify and propagate model uncertainties into
predictive quantities. Specifically, hierarchical Bayesian modeling (HBM) is
first adopted to describe model uncertainties, which allows the prior
assumption to be less subjective, while also makes the proposed surrogate more
robust. Next, the Bayesian inference is seamlessly integrated into the DL
framework, which in turn supports probabilistic programming by yielding a
probability distribution of the quantities of interest rather than their point
estimates. Variational inference (VI) is implemented for the posterior
distribution analysis where the intractable marginalization of the likelihood
function over parameter space is framed in an optimization format, and
stochastic gradient descent method is applied to solve this optimization
problem. Finally, Monte Carlo simulation is used to obtain an unbiased
estimator in the predictive phase of Bayesian inference, where the proposed
Bayesian deep learning (BDL) scheme is able to offer confidence bounds for the
output estimation by analyzing propagated uncertainties. The effectiveness of
Bayesian shrinkage is demonstrated in improving predictive performance using
contaminated data, and various examples are provided to illustrate concepts,
methodologies, and algorithms of this proposed BDL modeling technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04258</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04258</id><created>2019-07-06</created><authors><author><keyname>Farzaneh</keyname><forenames>Majid</forenames></author><author><keyname>Toroghi</keyname><forenames>Rahil Mahdian</forenames></author></authors><title>Melody Generation using an Interactive Evolutionary Algorithm</title><categories>cs.NE cs.SD eess.AS</categories><comments>5 pages, 4 images, submitted to MEDPRAI2019 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music generation with the aid of computers has been recently grabbed the
attention of many scientists in the area of artificial intelligence. Deep
learning techniques have evolved sequence production methods for this purpose.
Yet, a challenging problem is how to evaluate generated music by a machine. In
this paper, a methodology has been developed based upon an interactive
evolutionary optimization method, with which the scoring of the generated
melodies is primarily performed by human expertise, during the training. This
music quality scoring is modeled using a Bi-LSTM recurrent neural network.
Moreover, the innovative generated melody through a Genetic algorithm will then
be evaluated using this Bi-LSTM network. The results of this mechanism clearly
show that the proposed method is able to create pleasurable melodies with
desired styles and pieces. This method is also quite fast, compared to the
state-of-the-art data-oriented evolutionary systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04273</identifier>
 <datestamp>2019-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04273</id><created>2019-07-09</created><updated>2019-11-27</updated><authors><author><keyname>P&#xe9;rez-Roca</keyname><forenames>Sergio</forenames></author><author><keyname>Marzat</keyname><forenames>Julien</forenames></author><author><keyname>Flayac</keyname><forenames>Emilien</forenames></author><author><keyname>Piet-Lahanier</keyname><forenames>Helene</forenames></author><author><keyname>Langlois</keyname><forenames>Nicolas</forenames></author><author><keyname>Farago</keyname><forenames>Francois</forenames></author><author><keyname>Galeotta</keyname><forenames>Marco</forenames></author><author><keyname>Gonidec</keyname><forenames>Serge Le</forenames></author></authors><title>An MPC Approach to Transient Control of Liquid-Propellant Rocket Engines</title><categories>eess.SY cs.SY physics.space-ph</categories><comments>IFAC ACA 2019, Cranfield, UK. 6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current context of launchers reusability requires the improvement of
control algorithms for their liquid-propellant rocket engines. Their transient
phases are generally still performed in open loop. In this paper, it is aimed
at enhancing the control performance and robustness during the fully continuous
phase of the start-up transient of a generic gas-generator cycle. The main
control goals concern end-state tracking in terms of combustion-chamber
pressure and chambers mixture ratios, as well as the verification of a set of
hard operational constraints. A controller based on a nonlinear preprocessor
and on linear MPC (Model-Predictive Control) has been synthesised, making use
of nonlinear state-space models of the engine. The former generates the
full-state reference to be tracked while the latter achieves the aforementioned
goals with sufficient accuracy and verifying constraints for the required
pressure levels. Robustness considerations are included in the MPC algorithm
via an epigraph formulation of the minimax robust optimisation problem, where a
finite set of perturbation scenarios is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04281</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04281</id><created>2019-07-09</created><authors><author><keyname>Gadaleta</keyname><forenames>Matteo</forenames></author><author><keyname>Cisotto</keyname><forenames>Giulia</forenames></author><author><keyname>Rossi</keyname><forenames>Michele</forenames></author><author><keyname>Rehman</keyname><forenames>Rana Zia Ur</forenames></author><author><keyname>Rochester</keyname><forenames>Lynn</forenames></author><author><keyname>Del Din</keyname><forenames>Silvia</forenames></author></authors><title>Deep Learning Techniques for Improving Digital Gait Segmentation</title><categories>eess.SP cs.LG cs.NE eess.IV q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wearable technology for the automatic detection of gait events has recently
gained growing interest, enabling advanced analyses that were previously
limited to specialist centres and equipment (e.g., instrumented walkway). In
this study, we present a novel method based on dilated convolutions for an
accurate detection of gait events (initial and final foot contacts) from
wearable inertial sensors. A rich dataset has been used to validate the method,
featuring 71 people with Parkinson's disease (PD) and 67 healthy control
subjects. Multiple sensors have been considered, one located on the fifth
lumbar vertebrae and two on the ankles. The aims of this study were: (i) to
apply deep learning (DL) techniques on wearable sensor data for gait
segmentation and quantification in older adults and in people with PD; (ii) to
validate the proposed technique for measuring gait against traditional gold
standard laboratory reference and a widely used algorithm based on wavelet
transforms (WT); (iii) to assess the performance of DL methods in assessing
high-level gait characteristics, with focus on stride, stance and swing related
features. The results showed a high reliability of the proposed approach, which
achieves temporal errors considerably smaller than WT, in particular for the
detection of final contacts, with an inter-quartile range below 70 ms in the
worst case. This study showes encouraging results, and paves the road for
further research, addressing the effectiveness and the generalization of
data-driven learning systems for accurate event detection in challenging
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04294</identifier>
 <datestamp>2019-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04294</id><created>2019-07-09</created><authors><author><keyname>Gururani</keyname><forenames>Siddharth</forenames></author><author><keyname>Sharma</keyname><forenames>Mohit</forenames></author><author><keyname>Lerch</keyname><forenames>Alexander</forenames></author></authors><title>An Attention Mechanism for Musical Instrument Recognition</title><categories>cs.IR cs.SD eess.AS</categories><comments>To appear in: Proceedings of the International Society for Music
  Information Retrieval Conference (ISMIR), Delft, 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  While the automatic recognition of musical instruments has seen significant
progress, the task is still considered hard for music featuring multiple
instruments as opposed to single instrument recordings. Datasets for polyphonic
instrument recognition can be categorized into roughly two categories. Some,
such as MedleyDB, have strong per-frame instrument activity annotations but are
usually small in size. Other, larger datasets such as OpenMIC only have weak
labels, i.e., instrument presence or absence is annotated only for long
snippets of a song. We explore an attention mechanism for handling weakly
labeled data for multi-label instrument recognition. Attention has been found
to perform well for other tasks with weakly labeled data. We compare the
proposed attention model to multiple models which include a baseline binary
relevance random forest, recurrent neural network, and fully connected neural
networks. Our results show that incorporating attention leads to an overall
improvement in classification accuracy metrics across all 20 instruments in the
OpenMIC dataset. We find that attention enables models to focus on (or `attend
to') specific time segments in the audio relevant to each instrument label
leading to interpretable results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04305</identifier>
 <datestamp>2020-01-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04305</id><created>2019-07-09</created><updated>2020-01-23</updated><authors><author><keyname>Hasan</keyname><forenames>Md. Kamrul</forenames></author><author><keyname>Dahal</keyname><forenames>Lavsen</forenames></author><author><keyname>Samarakoon</keyname><forenames>Prasad N.</forenames></author><author><keyname>Tushar</keyname><forenames>Fakrul Islam</forenames></author><author><keyname>Marly</keyname><forenames>Robert Marti</forenames></author></authors><title>DSNet: Automatic Dermoscopic Skin Lesion Segmentation</title><categories>eess.IV cs.CV</categories><comments>25 pages</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Automatic segmentation of skin lesion is considered a crucial step in
Computer Aided Diagnosis (CAD) for melanoma diagnosis. Despite its
significance, skin lesion segmentation remains a challenging task due to their
diverse color, texture, and indistinguishable boundaries and forms an open
problem. Through this study, we present a new and automatic semantic
segmentation network for robust skin lesion segmentation named Dermoscopic Skin
Network (DSNet). In order to reduce the number of parameters to make the
network lightweight, we used depth-wise separable convolution in lieu of
standard convolution to project the learned discriminating features onto the
pixel space at different stages of the encoder. Additionally, we implemented
U-Net and Fully Convolutional Network (FCN8s) to compare against the proposed
DSNet. We evaluate our proposed model on two publicly available datasets,
namely ISIC-2017 and PH2. The obtained mean Intersection over Union (mIoU) is
77.5 % and 87.0 % respectively for ISIC-2017 and PH2 datasets which
outperformed the ISIC-2017 challenge winner by 1.0 % with respect to mIoU. Our
proposed network also outperformed U-Net and FCN8s respectively by 3.6 % and
6.8 % with respect to mIoU on the ISIC-2017 dataset. Our network for skin
lesion segmentation outperforms other methods and can provide better segmented
masks on two different test datasets which can lead to better performance in
melanoma detection. Our trained model along with the source code and predicted
masks are made publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04352</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04352</id><created>2019-07-09</created><updated>2019-08-03</updated><authors><author><keyname>Meade</keyname><forenames>Nicholas</forenames></author><author><keyname>Barreyre</keyname><forenames>Nicholas</forenames></author><author><keyname>Lowe</keyname><forenames>Scott C.</forenames></author><author><keyname>Oore</keyname><forenames>Sageev</forenames></author></authors><title>Exploring Conditioning for Generative Music Systems with
  Human-Interpretable Controls</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance RNN is a machine-learning system designed primarily for the
generation of solo piano performances using an event-based (rather than audio)
representation. More specifically, Performance RNN is a long short-term memory
(LSTM) based recurrent neural network that models polyphonic music with
expressive timing and dynamics (Oore et al., 2018). The neural network uses a
simple language model based on the Musical Instrument Digital Interface (MIDI)
file format. Performance RNN is trained on the e-Piano Junior Competition
Dataset (International Piano e-Competition, 2018), a collection of solo piano
performances by expert pianists. As an artistic tool, one of the limitations of
the original model has been the lack of useable controls. The standard form of
Performance RNN can generate interesting pieces, but little control is provided
over what specifically is generated. This paper explores a set of
conditioning-based controls used to influence the generation process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04353</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04353</id><created>2019-07-09</created><authors><author><keyname>Wu</keyname><forenames>Jui-Yi</forenames></author><author><keyname>Kim</keyname><forenames>Jonghyun</forenames></author></authors><title>Prescription AR: A Fully-Customized Prescription-Embedded Augmented
  Reality Display</title><categories>cs.GR eess.IV</categories><comments>17 pages, 16 figures, Optica</comments><doi>10.1364/OE.380945</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a fully-customized AR display design that considers
the user's prescription, interpupillary distance, and taste of fashion. A
free-form image combiner embedded inside the prescription lens provides
augmented images onto the vision-corrected real world. We establish a
prescription-embedded AR display optical design method as well as the
customization method for individual users. Our design can cover myopia,
hyperopia, astigmatism, and presbyopia, and allows the eye-contact interaction
with privacy protection. A 169$g$ dynamic prototype showed a 40$^\circ$
$\times$ 20 $^\circ$ virtual image with a 23 cpd resolution at center field and
6 mm $\times$ 4 mm eye box, with the vision-correction and varifocal (0.5-3$m$)
capability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04355</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04355</id><created>2019-07-09</created><authors><author><keyname>Hsu</keyname><forenames>Wei-Ning</forenames></author><author><keyname>Harwath</keyname><forenames>David</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Transfer Learning from Audio-Visual Grounding to Speech Recognition</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Accepted to Interspeech 2019. 4 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transfer learning aims to reduce the amount of data required to excel at a
new task by re-using the knowledge acquired from learning other related tasks.
This paper proposes a novel transfer learning scenario, which distills robust
phonetic features from grounding models that are trained to tell whether a pair
of image and speech are semantically correlated, without using any textual
transcripts. As semantics of speech are largely determined by its lexical
content, grounding models learn to preserve phonetic information while
disregarding uncorrelated factors, such as speaker and channel. To study the
properties of features distilled from different layers, we use them as input
separately to train multiple speech recognition models. Empirical results
demonstrate that layers closer to input retain more phonetic information, while
following layers exhibit greater invariance to domain shift. Moreover, while
most previous studies include training data for speech recognition for feature
extractor training, our grounding models are not trained on any of those data,
indicating more universal applicability to new domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04378</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04378</id><created>2019-07-09</created><authors><author><keyname>Ma</keyname><forenames>Shuang</forenames></author><author><keyname>McDuff</keyname><forenames>Daniel</forenames></author><author><keyname>Song</keyname><forenames>Yale</forenames></author></authors><title>M3D-GAN: Multi-Modal Multi-Domain Translation with Universal Attention</title><categories>cs.CV cs.CL cs.LG eess.AS eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative adversarial networks have led to significant advances in
cross-modal/domain translation. However, typically these networks are designed
for a specific task (e.g., dialogue generation or image synthesis, but not
both). We present a unified model, M3D-GAN, that can translate across a wide
range of modalities (e.g., text, image, and speech) and domains (e.g.,
attributes in images or emotions in speech). Our model consists of modality
subnets that convert data from different modalities into unified
representations, and a unified computing body where data from different
modalities share the same network architecture. We introduce a universal
attention module that is jointly trained with the whole network and learns to
encode a large range of domain information into a highly structured latent
space. We use this to control synthesis in novel ways, such as producing
diverse realistic pictures from a sketch or varying the emotion of synthesized
speech. We evaluate our approach on extensive benchmark tasks, including
image-to-image, text-to-image, image captioning, text-to-speech, speech
recognition, and machine translation. Our results show state-of-the-art
performance on some of the tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04423</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04423</id><created>2019-07-09</created><authors><author><keyname>Anjinappa</keyname><forenames>Chethan Kumar</forenames></author><author><keyname>Gurbuz</keyname><forenames>Ali Cafer</forenames></author><author><keyname>Yapici</keyname><forenames>Yavuz</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Off-Grid Aware Channel and Covariance Estimation in mmWave Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spectrum scarcity at sub-6 GHz spectrum has made millimeter-wave (mmWave)
frequency band a key component of the next-generation wireless networks. While
mmWave spectrum offers extremely large transmission bandwidths to accommodate
ever-increasing data rates, unique characteristics of this new spectrum need
special consideration to achieve the promised network throughput. In this work,
we consider the off-grid problem for mmWave communications, which has a
significant impact on basic network functionalities involving beam steering and
tracking. The off-grid effect naturally appears in compressed sensing (CS)
techniques adopting a discretization approach for representing the angular
domain. This approach yields a finite set of discrete angle points, which are
an approximation to the continuous angular space, and hence degrade the
accuracy of related parameter estimation. In order to cope with the off-grid
effect, we present a novel parameter-perturbation framework to efficiently
estimate the channel and the covariance for mmWave networks. The proposed
algorithms employ a smart perturbation mechanism in conjunction with a
low-complexity greedy framework of simultaneous orthogonal matching pursuit
(SOMP), and jointly solve for the off-grid parameters and weights. Numerical
results show a significant performance improvement through our novel framework
as a result of handling the off-grid effects, which is totally ignored in the
conventional sparse mmWave channel or covariance estimation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04427</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04427</id><created>2019-07-09</created><authors><author><keyname>Anjinappa</keyname><forenames>Chethan Kumar</forenames></author><author><keyname>Zhou</keyname><forenames>You</forenames></author><author><keyname>Yapici</keyname><forenames>Yavuz</forenames></author><author><keyname>Baron</keyname><forenames>Dror</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author></authors><title>Channel Estimation in mmWave Hybrid MIMO System via Off-Grid Dirichlet
  Kernels</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we tackle channel estimation in millimeter-wave hybrid
multiple-input multiple-output systems by considering off-grid effects. In
particular, we assume that spatial parameters can take any value in the angular
domain, and need not fall on predefined discretized angles. Instead of
increasing the number of discretized points to combat off-grid effects, we use
implicit Dirichlet kernel structure in the Fourier domain, which conventional
compressed sensing methods do not use. We propose greedy low-complexity
algorithms based on orthogonal matching pursuit (OMP); our core idea is to
traverse the Dirichlet kernel peak using estimates of the discrete Fourier
transform. We demonstrate the efficacy of our proposed algorithms compared to
standard OMP reconstruction. Numerical results show that our proposed
algorithms obtain smaller reconstruction errors when off-grid effects are
accounted for.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04448</identifier>
 <datestamp>2019-07-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04448</id><created>2019-07-09</created><updated>2019-07-24</updated><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Weiss</keyname><forenames>Ron J.</forenames></author><author><keyname>Zen</keyname><forenames>Heiga</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Chen</keyname><forenames>Zhifeng</forenames></author><author><keyname>Skerry-Ryan</keyname><forenames>RJ</forenames></author><author><keyname>Jia</keyname><forenames>Ye</forenames></author><author><keyname>Rosenberg</keyname><forenames>Andrew</forenames></author><author><keyname>Ramabhadran</keyname><forenames>Bhuvana</forenames></author></authors><title>Learning to Speak Fluently in a Foreign Language: Multilingual Speech
  Synthesis and Cross-Language Voice Cloning</title><categories>cs.CL cs.SD eess.AS</categories><comments>5 pages, submitted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a multispeaker, multilingual text-to-speech (TTS) synthesis model
based on Tacotron that is able to produce high quality speech in multiple
languages. Moreover, the model is able to transfer voices across languages,
e.g. synthesize fluent Spanish speech using an English speaker's voice, without
training on any bilingual or parallel examples. Such transfer works across
distantly related languages, e.g. English and Mandarin.
  Critical to achieving this result are: 1. using a phonemic input
representation to encourage sharing of model capacity across languages, and 2.
incorporating an adversarial loss term to encourage the model to disentangle
its representation of speaker identity (which is perfectly correlated with
language in the training data) from the speech content. Further scaling up the
model by training on multiple speakers of each language, and incorporating an
autoencoding input to help stabilize attention during training, results in a
model which can be used to consistently synthesize intelligible speech for
training speakers in all languages seen during training, and in native or
foreign accents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04462</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04462</id><created>2019-07-09</created><authors><author><keyname>Park</keyname><forenames>Jihyun</forenames></author><author><keyname>Zhao</keyname><forenames>Kexin</forenames></author><author><keyname>Peng</keyname><forenames>Kainan</forenames></author><author><keyname>Ping</keyname><forenames>Wei</forenames></author></authors><title>Multi-Speaker End-to-End Speech Synthesis</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we extend ClariNet (Ping et al., 2019), a fully end-to-end
speech synthesis model (i.e., text-to-wave), to generate high-fidelity speech
from multiple speakers. To model the unique characteristic of different voices,
low dimensional trainable speaker embeddings are shared across each component
of ClariNet and trained together with the rest of the model. We demonstrate
that the multi-speaker ClariNet outperforms state-of-the-art systems in terms
of naturalness, because the whole model is jointly optimized in an end-to-end
manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04474</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04474</id><created>2019-07-09</created><authors><author><keyname>Kim</keyname><forenames>Kwang Soon</forenames></author><author><keyname>Kim</keyname><forenames>Dong Ku</forenames></author><author><keyname>Chae</keyname><forenames>Chan-Byoung</forenames></author><author><keyname>Choi</keyname><forenames>Sunghyun</forenames></author><author><keyname>Ko</keyname><forenames>Young-Chai</forenames></author><author><keyname>Kim</keyname><forenames>Jonghyun</forenames></author><author><keyname>Lim</keyname><forenames>Yeon-Geun</forenames></author><author><keyname>Yang</keyname><forenames>Minho</forenames></author><author><keyname>Kim</keyname><forenames>Sundo</forenames></author><author><keyname>Lim</keyname><forenames>Byungju</forenames></author><author><keyname>Lee</keyname><forenames>Kwanghoon</forenames></author><author><keyname>Ryu</keyname><forenames>Kyung Lin</forenames></author></authors><title>Ultrareliable and Low-Latency Communication Techniques for Tactile
  Internet Services</title><categories>cs.IT eess.SP math.IT</categories><journal-ref>Proc. IEEE, vol. 107, no. 2, pp. 376-393, Feb. 2019</journal-ref><doi>10.1109/JPROC.2018.2868995</doi><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  This paper presents novel ultrareliable and low-latency communication (URLLC)
techniques for URLLC services, such as Tactile Internet services. Among typical
use-cases of URLLC services are tele-operation, immersive virtual reality,
cooperative automated driving, and so on. In such URLLC services, new kinds of
traffic such as haptic information including kinesthetic information and
tactile information need to be delivered in addition to high-quality video and
audio traffic in traditional multimedia services. Further, such a variety of
traffic has various characteristics in terms of packet sizes and data rates
with a variety of requirements of latency and reliability. Furthermore, some
traffic may occur in a sporadic manner but require reliable delivery of packets
of medium to large sizes within a low latency, which is not supported by
current state-of-the-art wireless communication systems and is very challenging
for future wireless communication systems. Thus, to meet such a variety of
tight traffic requirements in a wireless communication system, novel
technologies from the physical layer to the network layer need to be devised.
In this paper, some novel physical layer technologies such as waveform
multiplexing, multiple access scheme, channel code design, synchronization, and
full-duplex transmission for spectrally-efficient URLLC are introduced. In
addition, a novel performance evaluation approach, which combines a ray-tracing
tool and system-level simulation, is suggested for evaluating the performance
of the proposed schemes. Simulation results show the feasibility of the
proposed schemes providing realistic URLLC services in realistic geographical
environments, which encourages further efforts to substantiate the proposed
work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04478</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04478</id><created>2019-07-09</created><authors><author><keyname>Kim</keyname><forenames>Jonghyun</forenames></author><author><keyname>Ryu</keyname><forenames>Kyung Lin</forenames></author><author><keyname>Kim</keyname><forenames>Kwang Soon</forenames></author></authors><title>User Detection Performance Analysis for Grant-Free Uplink Transmission
  in Large-Scale Antenna Systems</title><categories>cs.IT eess.SP math.IT</categories><journal-ref>2018 Tenth International Conference on Ubiquitous and Future
  Networks (ICUFN)</journal-ref><doi>10.1109/ICUFN.2018.8436958</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, user detection performance of a grant-free uplink transmission
in a large scale antenna system is analyzed, in which a general grant-free
multiple access is considered as the system model and Zadoff-Chu sequence is
used for the uplink pilot. The false alarm probabilities of various user
detection schemes under the target detection probabilities are evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04489</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04489</id><created>2019-07-09</created><updated>2019-08-03</updated><authors><author><keyname>Lutter</keyname><forenames>Michael</forenames></author><author><keyname>Listmann</keyname><forenames>Kim</forenames></author><author><keyname>Peters</keyname><forenames>Jan</forenames></author></authors><title>Deep Lagrangian Networks for end-to-end learning of energy-based control
  for under-actuated systems</title><categories>cs.RO cs.LG cs.SY eess.SY</categories><comments>Published at IROS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applying Deep Learning to control has a lot of potential for enabling the
intelligent design of robot control laws. Unfortunately common deep learning
approaches to control, such as deep reinforcement learning, require an
unrealistic amount of interaction with the real system, do not yield any
performance guarantees, and do not make good use of extensive insights from
model-based control. In particular, common black-box approaches -- that abandon
all insight from control -- are not suitable for complex robot systems. We
propose a deep control approach as a bridge between the solid theoretical
foundations of energy-based control and the flexibility of deep learning. To
accomplish this goal, we extend Deep Lagrangian Networks (DeLaN) to not only
adhere to Lagrangian Mechanics but also ensure conservation of energy and
passivity of the learned representation. This novel extension is embedded
within generic model-based control laws to enable energy control of
under-actuated systems. The resulting DeLaN for energy control (DeLaN 4EC) is
the first model learning approach using generic function approximation that is
capable of learning energy control. DeLaN 4EC exhibits excellent real-time
control on the physical Furuta Pendulum and learns to swing-up the pendulum
while the control law using system identification does not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04490</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04490</id><created>2019-07-09</created><authors><author><keyname>Lutter</keyname><forenames>Michael</forenames></author><author><keyname>Ritter</keyname><forenames>Christian</forenames></author><author><keyname>Peters</keyname><forenames>Jan</forenames></author></authors><title>Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning</title><categories>cs.LG cs.RO cs.SY eess.SY stat.ML</categories><comments>Published at ICLR 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has achieved astonishing results on many tasks with large
amounts of data and generalization within the proximity of training data. For
many important real-world applications, these requirements are unfeasible and
additional prior knowledge on the task domain is required to overcome the
resulting problems. In particular, learning physics models for model-based
control requires robust extrapolation from fewer samples - often collected
online in real-time - and model errors may lead to drastic damages of the
system. Directly incorporating physical insight has enabled us to obtain a
novel deep model learning approach that extrapolates well while requiring fewer
samples. As a first example, we propose Deep Lagrangian Networks (DeLaN) as a
deep network structure upon which Lagrangian Mechanics have been imposed. DeLaN
can learn the equations of motion of a mechanical system (i.e., system
dynamics) with a deep network efficiently while ensuring physical plausibility.
The resulting DeLaN network performs very well at robot tracking control. The
proposed method did not only outperform previous model learning approaches at
learning speed but exhibits substantially improved and more robust
extrapolation to novel trajectories and learns online in real-time
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04494</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04494</id><created>2019-07-09</created><authors><author><keyname>Yan</keyname><forenames>Shuchang</forenames></author></authors><title>Controlling Power and Virtual Inertia from Storage for Frequency
  Response</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, power imbalance happens more frequently due to the more integration
of renewable energy sources. Energy storage is a kind of devices that can
charge energy at one time and discharge energy at another time. This function
makes that storage is widely envolved into promoting power balance of power
system. Besides this function, storage can also emulate virtual inertia to
respond to frequency deviations in the system. This work provides a generalized
optimization framework to analyze how to control power and virtual inertia from
storage to participate in frequency response when a large disturbance happens.
Centralized and distributed model predictive control is employed here, and case
study verifies the effectiveness of our optimization framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04500</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04500</id><created>2019-07-09</created><authors><author><keyname>Xu</keyname><forenames>Junshen</forenames></author><author><keyname>Zhang</keyname><forenames>Molin</forenames></author><author><keyname>Turk</keyname><forenames>Esra Abaci</forenames></author><author><keyname>Zhang</keyname><forenames>Larry</forenames></author><author><keyname>Grant</keyname><forenames>Ellen</forenames></author><author><keyname>Ying</keyname><forenames>Kui</forenames></author><author><keyname>Golland</keyname><forenames>Polina</forenames></author><author><keyname>Adalsteinsson</keyname><forenames>Elfar</forenames></author></authors><title>Fetal Pose Estimation in Volumetric MRI using a 3D Convolution Neural
  Network</title><categories>eess.IV cs.CV</categories><comments>MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance and diagnostic utility of magnetic resonance imaging (MRI) in
pregnancy is fundamentally constrained by fetal motion. Motion of the fetus,
which is unpredictable and rapid on the scale of conventional imaging times,
limits the set of viable acquisition techniques to single-shot imaging with
severe compromises in signal-to-noise ratio and diagnostic contrast, and
frequently results in unacceptable image quality. Surprisingly little is known
about the characteristics of fetal motion during MRI and here we propose and
demonstrate methods that exploit a growing repository of MRI observations of
the gravid abdomen that are acquired at low spatial resolution but relatively
high temporal resolution and over long durations (10-30 minutes). We estimate
fetal pose per frame in MRI volumes of the pregnant abdomen via deep learning
algorithms that detect key fetal landmarks. Evaluation of the proposed method
shows that our framework achieves quantitatively an average error of 4.47 mm
and 96.4\% accuracy (with error less than 10 mm). Fetal pose estimation in MRI
time series yields novel means of quantifying fetal movements in health and
disease, and enables the learning of kinematic models that may enhance
prospective mitigation of fetal motion artifacts during MRI acquisition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04509</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04509</id><created>2019-07-10</created><authors><author><keyname>Rehman</keyname><forenames>Naveed ur</forenames></author><author><keyname>Aftab</keyname><forenames>Hania</forenames></author></authors><title>Multivariate Variational Mode Decomposition</title><categories>eess.SP</categories><comments>13 pages</comments><doi>10.1109/TSP.2019.2951223</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a generic extension of variational mode decomposition (VMD)
algorithm for multivariate or multichannel data sets is presented. We first
define a model for multivariate modulated oscillations that is based on the
presence of a joint or common frequency component among all channels of input
data. Using that model for multivariate oscillations, we construct a
variational optimization problem that aims to extract an ensemble of
band-limited modes containing inherent multivariate modulated oscillations
present in multivariate input signal. The cost function to be minimized is the
sum of bandwidths of all signal modes across all input data channels, which is
a generic extension of the cost function used in standard VMD to multivariate
data. Minimization of the resulting variational model is achieved through the
alternate direction method of multipliers (ADMM) approach. That yields an
optimal set of multivariate modes in terms of narrow bandwidth and
corresponding center frequencies that are assumed to be commonly present among
all channels of a multivariate modulated oscillation. We demonstrate the
effectiveness of the proposed method through results obtained from extensive
simulations involving test (synthetic) and real world multivariate data sets.
Specifically, we focus on the ability of the proposed method to yield joint
oscillatory modes in multivariate data which is a prerequisite in many real
world applications involving nonstationary multivariate data. We also highlight
the utility of the proposed method in two real world applications which include
the separation of alpha rhythms in multivariate electroencephalogram (EEG) data
and the decomposition of bivariate cardiotocographic signals that consist of
fetal heart rate and maternal uterine contraction (FHR-UC) as its two channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04514</identifier>
 <datestamp>2020-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04514</id><created>2019-07-10</created><updated>2020-01-29</updated><authors><author><keyname>Wang</keyname><forenames>Tianming</forenames></author><author><keyname>Lu</keyname><forenames>Wenjie</forenames></author><author><keyname>Yan</keyname><forenames>Zheng</forenames></author><author><keyname>Liu</keyname><forenames>Dikai</forenames></author></authors><title>DOB-Net: Actively Rejecting Unknown Excessive Time-Varying Disturbances</title><categories>cs.RO cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an observer-integrated Reinforcement Learning (RL)
approach, called Disturbance OBserver Network (DOB-Net), for robots operating
in environments where disturbances are unknown and time-varying, and may
frequently exceed robot control capabilities. The DOB-Net integrates a
disturbance dynamics observer network and a controller network. Originated from
conventional DOB mechanisms, the observer is built and enhanced via Recurrent
Neural Networks (RNNs), encoding estimation of past values and prediction of
future values of unknown disturbances in RNN hidden state. Such encoding allows
the controller generate optimal control signals to actively reject
disturbances, under the constraints of robot control capabilities. The observer
and the controller are jointly learned within policy optimization by advantage
actor critic. Numerical simulations on position regulation tasks have
demonstrated that the proposed DOB-Net significantly outperforms a conventional
feedback controller and classical RL algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04536</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04536</id><created>2019-07-10</created><authors><author><keyname>Luo</keyname><forenames>Ruisen</forenames></author><author><keyname>Sun</keyname><forenames>Tianran</forenames></author><author><keyname>Wang</keyname><forenames>Chen</forenames></author><author><keyname>Du</keyname><forenames>Miao</forenames></author><author><keyname>Tang</keyname><forenames>Zuodong</forenames></author><author><keyname>Zhou</keyname><forenames>Kai</forenames></author><author><keyname>Gong</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Yang</keyname><forenames>Xiaomei</forenames></author></authors><title>Multi-layer Attention Mechanism for Speech Keyword Recognition</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  As an important part of speech recognition technology, automatic speech
keyword recognition has been intensively studied in recent years. Such
technology becomes especially pivotal under situations with limited
infrastructures and computational resources, such as voice command recognition
in vehicles and robot interaction. At present, the mainstream methods in
automatic speech keyword recognition are based on long short-term memory (LSTM)
networks with attention mechanism. However, due to inevitable information
losses for the LSTM layer caused during feature extraction, the calculated
attention weights are biased. In this paper, a novel approach, namely
Multi-layer Attention Mechanism, is proposed to handle the inaccurate attention
weights problem. The key idea is that, in addition to the conventional
attention mechanism, information of layers prior to feature extraction and LSTM
are introduced into attention weights calculations. Therefore, the attention
weights are more accurate because the overall model can have more precise and
focused areas. We conduct a comprehensive comparison and analysis on the
keyword spotting performances on convolution neural network, bi-directional
LSTM cyclic neural network, and cyclic neural network with the proposed
attention mechanism on Google Speech Command datasets V2 datasets. Experimental
results indicate favorable results for the proposed method and demonstrate the
validity of the proposed method. The proposed multi-layer attention methods can
be useful for other researches related to object spotting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04539</identifier>
 <datestamp>2019-09-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04539</id><created>2019-07-10</created><updated>2019-09-26</updated><authors><author><keyname>Marjaninejad</keyname><forenames>Ali</forenames></author><author><keyname>Urbina-Mel&#xe9;ndez</keyname><forenames>Dar&#xed;o</forenames></author><author><keyname>Valero-Cuevas</keyname><forenames>Francisco J.</forenames></author></authors><title>Simple Kinematic Feedback Enhances Autonomous Learning in Bio-Inspired
  Tendon-Driven Systems</title><categories>cs.RO cs.LG cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Error feedback is known to improve performance by correcting control signals
in response to perturbations. Here we show how adding simple error feedback can
also accelerate and robustify autonomous learning in a tendon-driven robot. We
implemented two versions of the General-to-Particular (G2P) autonomous learning
algorithm to produce multiple movement tasks using a tendon-driven leg with two
joints and three tendons: one with and one without kinematic feedback. As
expected, feedback improved performance in simulation and hardware. However, we
see these improvements even in the presence of sensory delays of up to 100 ms
and when experiencing substantial contact collisions. Importantly, feedback
accelerates learning and enhances G2P's continual refinement of the initial
inverse map by providing the system with more relevant data to train on. This
allows the system to perform well even after only 60 seconds of initial motor
babbling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04655</identifier>
 <datestamp>2019-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04655</id><created>2019-07-03</created><authors><author><keyname>Deleforge</keyname><forenames>Antoine</forenames></author><author><keyname>Di Carlo</keyname><forenames>Diego</forenames></author><author><keyname>Strauss</keyname><forenames>Martin</forenames></author><author><keyname>Serizel</keyname><forenames>Romain</forenames></author><author><keyname>Marcenaro</keyname><forenames>Lucio</forenames></author></authors><title>Audio-Based Search and Rescue with a Drone: Highlights from the IEEE
  Signal Processing Cup 2019 Student Competition</title><categories>eess.SP cs.SD eess.AS</categories><proxy>ccsd</proxy><journal-ref>IEEE Signal Processing Magazine, Institute of Electrical and
  Electronics Engineers, In press</journal-ref><doi>10.1109/MSP.2019.2924687</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAV), commonly referred to as drones, have raised
increasing interest in recent years. Search and rescue scenarios where humans
in emergency situations need to be quickly found in areas difficult to access
constitute an important field of application for this technology. While
research efforts have mostly focused on developing video-based solutions for
this task \cite{lopez2017cvemergency}, UAV-embedded audio-based localization
has received relatively less attention. Though, UAVs equipped with a microphone
array could be of critical help to localize people in emergency situations, in
particular when video sensors are limited by a lack of visual feedback due to
bad lighting conditions or obstacles limiting the field of view. This motivated
the topic of the 6th edition of the IEEE Signal Processing Cup (SP Cup): a
UAV-embedded sound source localization challenge for search and rescue. In this
article, we share an overview of the IEEE SP Cup experience including the
competition tasks, participating teams, technical approaches and statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04681</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04681</id><created>2019-07-10</created><authors><author><keyname>Brieu</keyname><forenames>Nicolas</forenames></author><author><keyname>Meier</keyname><forenames>Armin</forenames></author><author><keyname>Kapil</keyname><forenames>Ansh</forenames></author><author><keyname>Schoenmeyer</keyname><forenames>Ralf</forenames></author><author><keyname>Gavriel</keyname><forenames>Christos G.</forenames></author><author><keyname>Caie</keyname><forenames>Peter D.</forenames></author><author><keyname>Schmidt</keyname><forenames>G&#xfc;nter</forenames></author></authors><title>Domain Adaptation-based Augmentation for Weakly Supervised Nuclei
  Detection</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The detection of nuclei is one of the most fundamental components of
computational pathology. Current state-of-the-art methods are based on deep
learning, with the prerequisite that extensive labeled datasets are available.
The increasing number of patient cohorts to be analyzed, the diversity of
tissue stains and indications, as well as the cost of dataset labeling
motivates the development of novel methods to reduce labeling effort across
domains. We introduce in this work a weakly supervised 'inter-domain' approach
that (i) performs stain normalization and unpaired image-to-image translation
to transform labeled images on a source domain to synthetic labeled images on
an unlabeled target domain and (ii) uses the resulting synthetic labeled images
to train a detection network on the target domain. Extensive experiments show
the superiority of the proposed approach against the state-of-the-art
'intra-domain' detection based on fully-supervised learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04691</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04691</id><created>2019-07-09</created><authors><author><keyname>Chamanbaz</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Notarstefano</keyname><forenames>Giuseppe</forenames></author><author><keyname>Sasso</keyname><forenames>Francesco</forenames></author><author><keyname>Bouffanais</keyname><forenames>Roland</forenames></author></authors><title>Randomized Constraints Consensus for Distributed Robust Mixed-Integer
  Programming</title><categories>math.OC cs.DC cs.SY eess.SY</categories><comments>Submitted for publication. arXiv admin note: text overlap with
  arXiv:1706.00488</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a network of processors aiming at cooperatively
solving mixed-integer convex programs subject to uncertainty. Each node only
knows a common cost function and its local uncertain constraint set. We propose
a randomized, distributed algorithm working under asynchronous, unreliable and
directed communication. The algorithm is based on a local computation and
communication paradigm. At each communication round, nodes perform two updates:
(i) a verification in which they check---in a randomized fashion---the robust
feasibility of a candidate optimal point, and (ii) an optimization step in
which they exchange their candidate basis (the minimal set of constraints
defining a solution) with neighbors and locally solve an optimization problem.
As main result, we show that processors can stop the algorithm after a finite
number of communication rounds (either because verification has been successful
for a sufficient number of rounds or because a given threshold has been
reached), so that candidate optimal solutions are consensual. The common
solution is proven to be---with high confidence---feasible and hence optimal
for the entire set of uncertainty except a subset having an arbitrary small
probability measure. We show the effectiveness of the proposed distributed
algorithm using two examples: a random, uncertain mixed-integer linear program
and a distributed localization in wireless sensor networks. The distributed
algorithm is implemented on a multi-core platform in which the nodes
communicate asynchronously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04693</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04693</id><created>2019-07-09</created><authors><author><keyname>Donglin</keyname><forenames>Wang</forenames></author><author><keyname>Sattiraju</keyname><forenames>Raja R.</forenames></author><author><keyname>Anjie</keyname><forenames>Qiu</forenames></author><author><keyname>Partani</keyname><forenames>Sanket</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Methodologies of Link-Level Simulator and System-Level Simulator for
  C-V2X Communication</title><categories>eess.SP cs.PF</categories><comments>7 pages, 8 figures, VTC 2019 fall. arXiv admin note: substantial text
  overlap with arXiv:1904.07962</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At the time of the development, standardization, and further improvement are
vital to the modern cellular systems such as the next generation wireless
communication (5G). Simulations are essential to test and optimize algorithms
and procedures prior to their implementation process of the equipment
manufactures. In order to evaluate system performance at different levels,
accurate simulations of simple setups, as well as simulations of more complex
systems via abstracted models are necessary. In this work, two new simulators
for the sidelink Cooperative-Vehicle-to-Everything (C-V2X) communication have
been implemented and carried out on both the physical layer (Link-Level (LL))
and network layer (System-Level (SL)). Detailed methodologies of the LL and SL
simulators for C-V2X communication have been illustrated. In the LL simulator,
we get the mapping curves of BLER and Signal-to-Noise-Ratio (SNR), which are
used as a baseline for measuring the performance of the LL simulation. In
addition, these mapping curves are used as the important Link-to-System (L2S)
interfaces. The SL simulator is utilized for measuring the performance of cell
networking and simulating large networks comprising of multiple eNBs and UEs.
Finally, the simulation results of both simulators for CV2X communication are
presented, which shows that different objectives can be met by using LL or SL
simulations types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04699</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04699</id><created>2019-07-10</created><updated>2019-07-13</updated><authors><author><keyname>Li</keyname><forenames>Yunyi</forenames></author><author><keyname>Gui</keyname><forenames>Guan</forenames></author><author><keyname>Cheng</keyname><forenames>Xiefeng</forenames></author></authors><title>Generalized Rank Minimization based Group Sparse Coding for Low-level
  Image Restoration via Dictionary Learning</title><categories>eess.IV cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, low-rank matrix recovery theory has been emerging as a significant
progress for various image processing problems. Meanwhile, the group sparse
coding (GSC) theory has led to great successes in image restoration with group
contains low-rank property. In this paper, we introduce a novel GSC framework
using generalized rank minimization for image restoration tasks via an
effective adaptive dictionary learning scheme. For a more accurate
approximation of the rank of group matrix, we proposed a generalized rank
minimization model with a generalized and flexible weighted scheme and the
generalized nonconvex nonsmooth relaxation function. Then an efficient
generalized iteratively reweighted singular-value function thresholding
(GIR-SFT) algorithm is proposed to handle the resulting minimization problem of
GSC. Our proposed model is connected to image restoration (IR) problems via an
alternating direction method of multipliers (ADMM) strategy. Extensive
experiments on typical IR problems of image compressive sensing (CS)
reconstruction, inpainting, deblurring and impulsive noise removal demonstrate
that our proposed GSC framework can enhance the image restoration quality
compared with many state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04700</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04700</id><created>2019-07-10</created><authors><author><keyname>Wu</keyname><forenames>Yibo</forenames></author><author><keyname>Peng</keyname><forenames>Bile</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Seco-Granados</keyname><forenames>Gonzalo</forenames></author><author><keyname>Kakkavas</keyname><forenames>Anastasios</forenames></author><author><keyname>Garcia</keyname><forenames>Mario H. Casta&#xf1;eda</forenames></author><author><keyname>Stirling-Gallacher</keyname><forenames>Richard A.</forenames></author></authors><title>Cooperative Localization with Angular Measurements and Posterior
  Linearization</title><categories>eess.SP cs.IT cs.SY eess.SY math.IT</categories><comments>Submitted for possible publication to an IEEE conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The application of cooperative localization in vehicular networks is
attractive to improve accuracy and coverage. Conventional distance measurements
between vehicles are limited by the need for synchronization and provide no
heading information of the vehicle. To address this, we present a cooperative
localization algorithm using posterior linearization belief propagation (PLBP)
utilizing angle-of-arrival (AoA)-only measurements. Simulation results show
that both directional and positional root mean squared error (RMSE) of vehicles
can be decreased significantly and converge to a low value in a few iterations.
Furthermore, the influence of parameters for the vehicular network, such as
vehicle density, communication radius, prior uncertainty and AoA measurements
noise, is analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04743</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04743</id><created>2019-07-10</created><authors><author><keyname>Korzekwa</keyname><forenames>Daniel</forenames></author><author><keyname>Barra-Chicote</keyname><forenames>Roberto</forenames></author><author><keyname>Kostek</keyname><forenames>Bozena</forenames></author><author><keyname>Drugman</keyname><forenames>Thomas</forenames></author><author><keyname>Lajszczak</keyname><forenames>Mateusz</forenames></author></authors><title>Interpretable Deep Learning Model for the Detection and Reconstruction
  of Dysarthric Speech</title><categories>eess.AS cs.CL cs.SD</categories><comments>5 pages, 5 figures, Accepted for Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposed a novel approach for the detection and reconstruction of
dysarthric speech. The encoder-decoder model factorizes speech into a
low-dimensional latent space and encoding of the input text. We showed that the
latent space conveys interpretable characteristics of dysarthria, such as
intelligibility and fluency of speech. MUSHRA perceptual test demonstrated that
the adaptation of the latent space let the model generate speech of improved
fluency. The multi-task supervised approach for predicting both the probability
of dysarthric speech and the mel-spectrogram helps improve the detection of
dysarthria with higher accuracy. This is thanks to a low-dimensional latent
space of the auto-encoder as opposed to directly predicting dysarthria from a
highly dimensional mel-spectrogram.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04774</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04774</id><created>2019-07-10</created><authors><author><keyname>Mekala</keyname><forenames>Rohan Reddy</forenames></author><author><keyname>Magnusson</keyname><forenames>Gudjon Einar</forenames></author><author><keyname>Porter</keyname><forenames>Adam</forenames></author><author><keyname>Lindvall</keyname><forenames>Mikael</forenames></author><author><keyname>Diep</keyname><forenames>Madeline</forenames></author></authors><title>Metamorphic Detection of Adversarial Examples in Deep Learning Models
  With Affine Transformations</title><categories>cs.CV cs.LG eess.IV</categories><doi>10.1109/MET.2019.00016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial attacks are small, carefully crafted perturbations, imperceptible
to the naked eye; that when added to an image cause deep learning models to
misclassify the image with potentially detrimental outcomes. With the rise of
artificial intelligence models in consumer safety and security intensive
industries such as self-driving cars, camera surveillance and face recognition,
there is a growing need for guarding against adversarial attacks. In this
paper, we present an approach that uses metamorphic testing principles to
automatically detect such adversarial attacks. The approach can detect image
manipulations that are so small, that they are impossible to detect by a human
through visual inspection. By applying metamorphic relations based on distance
ratio preserving affine image transformations which compare the behavior of the
original and transformed image; we show that our proposed approach can
determine whether or not the input image is adversarial with a high degree of
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04775</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04775</id><created>2019-07-10</created><authors><author><keyname>Garc&#xed;a-Cerezo</keyname><forenames>&#xc1;lvaro</forenames></author><author><keyname>Baringo</keyname><forenames>Luis</forenames></author><author><keyname>Garc&#xed;a-Bertrand</keyname><forenames>Raquel</forenames></author></authors><title>Robust Transmission Network Expansion Planning Problem Considering
  Storage Units</title><categories>math.OC cs.SY eess.SY</categories><comments>6 pages, 2 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the transmission network expansion planning problem
considering storage units under uncertain demand and generation capacity. A
two-stage adaptive robust optimization framework is adopted whereby short- and
long-term uncertainties are accounted for. This work differs from previously
reported solutions in an important aspect, namely, we include binary recourse
variables to avoid the simultaneous charging and discharging of storage units
once uncertainty is revealed. Two-stage robust optimization with discrete
recourse problems is a challenging task, so we propose using a nested
column-and-constraint generation algorithm to solve the resulting problem. This
algorithm guarantees convergence to the global optimum in a finite number of
iterations. The performance of the proposed algorithm is illustrated using the
Garver's test system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04784</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04784</id><created>2019-07-10</created><authors><author><keyname>Ye</keyname><forenames>Tong</forenames></author><author><keyname>Ding</keyname><forenames>Jingjie</forenames></author><author><keyname>Lee</keyname><forenames>Tony Tong</forenames></author><author><keyname>Maier</keyname><forenames>Guido</forenames></author></authors><title>AWG-based Nonblocking Shuffle-Exchange Networks</title><categories>cs.NI eess.SP</categories><comments>13 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optical shuffle-exchange networks (SENs) have wide application in different
kinds of interconnection networks. This paper proposes an approach to construct
modular optical SENs, using a set of arrayed waveguide gratings (AWGs) and
tunable wavelength converters (TWCs). According to the wavelength routing
property of AWGs, we demonstrate for the first time that an AWG is functionally
equivalent to a classical shuffle network by nature. Based on this result, we
devise a systematic method to design a large-scale
wavelength-division-multiplexing (WDM) shuffle network using a set of
small-size AWGs associated with the same wavelength set. Combining the
AWG-based WDM shuffle networks and the TWCs with small conversion range, we
finally obtain an AWG-based WDM SEN, which not only is scalable in several
ways, but also can achieve 100% utilization when the input wavelength channels
are all busy. We also study the routing and wavelength assignment (RWA) problem
of the AWG-based WDM SEN, and prove that the self-routing property and the
nonblocking routing conditions of classical SENs are preserved in such
AWG-based WDM SEN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04787</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04787</id><created>2019-07-09</created><authors><author><keyname>Martini</keyname><forenames>Eduardo</forenames></author><author><keyname>Cavalieri</keyname><forenames>Andr&#xe9; V. G.</forenames></author><author><keyname>Jordan</keyname><forenames>Peter</forenames></author><author><keyname>Lesshafft</keyname><forenames>Lutz</forenames></author></authors><title>Accurate Frequency Domain Identification of ODEs with Arbitrary Signals</title><categories>eess.SP physics.data-an</categories><comments>9 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The control of physical systems, governed by differential equations,
frequently requires the identification of dynamical systems. Frequency domain
identification has seen much progress over the last decades. Errors due to the
usage of arbitrary signals and finite samples, originally understood as leakage
errors, were identified as transient effects that can be corrected exactly on
discrete systems and asymptotically on sampled continuous system. We present an
alternative exploration of frequency domain identifications errors, by
regarding them as spurious inputs which arise as artifacts of signal windowing.
A correction procedure for these effects is proposed. Two families of windowing
functions are considered, one leading to polynomial, the other to
non-polynomial error convergence. The approach resembles the modulating
function technique, filtering out the effects of initial conditions, while
retaining the spectral interpretation of frequency domain methods and the low
computational cost of computing FFTs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04788</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04788</id><created>2019-07-05</created><authors><author><keyname>Wu</keyname><forenames>Tong</forenames></author><author><keyname>Gu</keyname><forenames>Yang</forenames></author><author><keyname>Chen</keyname><forenames>Yiqiang</forenames></author><author><keyname>Xiao</keyname><forenames>Yunlong</forenames></author><author><keyname>Wang</keyname><forenames>Jiwei</forenames></author></authors><title>A Mobile Cloud Collaboration Fall Detection System Based on Ensemble
  Learning</title><categories>eess.SP cs.LG</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Falls are one of the important causes of accidental or unintentional injury
death worldwide. Therefore, this paper presents a reliable fall detection
algorithm and a mobile cloud collaboration system for fall detection. The
algorithm is an ensemble learning method based on decision tree, named
Falldetection Ensemble Decision Tree (FEDT). The mobile cloud collaboration
system can be divided into three stages: 1) mobile stage: use a light-weighted
threshold method to filter out the activities of daily livings (ADLs), 2)
collaboration stage: transmit data to cloud and meanwhile extract features in
the cloud, 3) cloud stage: deploy the model trained by FEDT to give the final
detection result with the extracted features. Experiments show that the
performance of the proposed FEDT outperforms the others' over 1-3% both on
sensitivity and specificity, and more importantly, the system can provide
reliable fall detection in practical scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04789</identifier>
 <datestamp>2019-11-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04789</id><created>2019-07-08</created><updated>2019-11-02</updated><authors><author><keyname>Zhao</keyname><forenames>Jun</forenames></author></authors><title>A Survey of Intelligent Reflecting Surfaces (IRSs): Towards 6G Wireless
  Communication Networks</title><categories>eess.SP cs.IT cs.NI math.IT</categories><comments>Intelligent reflecting surface, 6G communications, massive MIMO,
  wireless networks</comments><msc-class>Intelligent reflecting surface, 6G communications, massive MIMO,
  wireless networks</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surfaces (IRSs) tune wireless environments to increase
spectrum and energy efficiencies. In view of much recent attention to the IRS
concept as a promising technology for 6G wireless communications, we present a
survey of IRSs in this paper. Specifically, we categorize recent research
studies of IRSs as follows. For IRS-aided communications, the summary includes
capacity/data rate analyses, power/spectral optimizations, channel estimation,
deep learning-based design, and reliability analysis. Then we review IRSs
implementations as well as the use of IRSs in secure communications,
terminal-positioning, and other novel applications. We further identify future
research directions for IRSs, with an envision of the IRS technology playing a
critical role in 6G communication networks similar to that of massive MIMO in
5G networks. As a timely summary of IRSs, our work will be of interest to both
researchers and practitioners working on IRSs for 6G networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04793</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04793</id><created>2019-07-10</created><authors><author><keyname>Hmedi</keyname><forenames>Hassan</forenames></author><author><keyname>Arapostathis</keyname><forenames>Ari</forenames></author><author><keyname>Pang</keyname><forenames>Guodong</forenames></author></authors><title>On uniform stability of certain parallel server networks with no
  abandonment in the Halfin-Whitt regime</title><categories>math.OC cs.SY eess.SY math.PR</categories><comments>30 pages</comments><msc-class>90B22 (Primary), 60K25, 49L20, 90B36 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show that a large class of parallel server networks, with
$\sqrt n$-safety staffing, and no abandonment, in the Halfin-Whitt regime are
exponentially ergodic and their invariant probability distributions are tight.
This includes all networks with a single nonleaf server pool, such as the 'N'
and 'M' models, as well as networks with class-dependent service rates.
  We first give a simple algebraic characterization of a parameter that plays
the role of the spare capacity (safety staffing) for the diffusion limit. We
show that if the spare capacity parameter is negative, the controlled diffusion
is transient under any stationary Markov control, and it cannot be positive
recurrent when this parameter is zero. On the other hand, if this parameter is
positive, then, for the aforementioned classes of networks, the limiting
diffusion is uniformly exponentially ergodic over all Markov controls.
  We establish the analogous stability properties for the prelimit
diffusion-scaled queueing processes. We use a unified approach in which the
Lyapunov function employed in the study of the diffusion limit paves the way.
As well known, joint work conservation, that is, keeping all servers busy
unless all queues are empty, cannot be always enforced in multiclass multi-pool
networks, and as a result the diffusion limit and the prelimit do not &quot;match&quot;
on the entire state space. We introduce the concept of &quot;system-wide work
conserving policies,&quot; which are defined as policies that minimize the number of
idle servers at all times. This is a natural extension of work conservation for
multiclass multi-pool networks. We show that, provided that the spare capacity
parameter is positive, the diffusion-scaled processes are geometrically ergodic
and the invariant distributions are tight, uniformly over system-wide work
conserving policies. This also results in an interchange of limits property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04807</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04807</id><created>2019-07-10</created><updated>2019-08-29</updated><authors><author><keyname>Zvezdakova</keyname><forenames>Anastasia</forenames></author><author><keyname>Zvezdakov</keyname><forenames>Sergey</forenames></author><author><keyname>Kulikov</keyname><forenames>Dmitriy</forenames></author><author><keyname>Vatolin</keyname><forenames>Dmitriy</forenames></author></authors><title>Hacking VMAF with Video Color and Contrast Distortion</title><categories>cs.MM cs.GR eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video quality measurement takes an important role in many applications.
Full-reference quality metrics which are usually used in video codecs
comparisons are expected to reflect any changes in videos. In this article, we
consider different color corrections of compressed videos which increase the
values of full-reference metric VMAF and almost don't decrease other
widely-used metric SSIM. The proposed video contrast enhancement approach shows
the metric inapplicability in some cases for video codecs comparisons, as it
may be used for cheating in the comparisons via tuning to improve this metric
values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04811</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04811</id><created>2019-07-09</created><authors><author><keyname>Liaskos</keyname><forenames>C.</forenames></author><author><keyname>Pirialakos</keyname><forenames>G.</forenames></author><author><keyname>Pitilakis</keyname><forenames>A.</forenames></author><author><keyname>Abadal</keyname><forenames>S.</forenames></author><author><keyname>Tsioliaridou</keyname><forenames>A.</forenames></author><author><keyname>Tasolamprou</keyname><forenames>A.</forenames></author><author><keyname>Tsilipakos</keyname><forenames>O.</forenames></author><author><keyname>Kantartzis</keyname><forenames>N.</forenames></author><author><keyname>Ioannidis</keyname><forenames>S.</forenames></author><author><keyname>Alarcon</keyname><forenames>E.</forenames></author><author><keyname>Cabellos</keyname><forenames>A.</forenames></author><author><keyname>Kafesaki</keyname><forenames>M.</forenames></author><author><keyname>Pitsillides</keyname><forenames>A.</forenames></author><author><keyname>Kossifos</keyname><forenames>K.</forenames></author><author><keyname>Georgiou</keyname><forenames>J.</forenames></author><author><keyname>Akyildiz</keyname><forenames>I. F.</forenames></author></authors><title>ABSense: Sensing Electromagnetic Waves on Metasurfaces via Ambient
  Compilation of Full Absorption</title><categories>eess.SP</categories><comments>Publication: Proceedings of ACM NANOCOM 2019. This work was funded by
  the European Union via the Horizon 2020: Future Emerging Topics call
  (FETOPEN), grant EU736876, project VISORSURF (http://www.visorsurf.eu)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metasurfaces constitute effective media for manipulating and transforming
impinging EM waves. Related studies have explored a series of impactful MS
capabilities and applications in sectors such as wireless communications,
medical imaging and energy harvesting. A key-gap in the existing body of work
is that the attributes of the EM waves to-be-controlled (e.g., direction,
polarity, phase) are known in advance. The present work proposes a practical
solution to the EM wave sensing problem using the intelligent and networked MS
counterparts-the HyperSurfaces (HSFs), without requiring dedicated field
sensors. An nano-network embedded within the HSF iterates over the possible MS
configurations, finding the one that fully absorbs the impinging EM wave, hence
maximizing the energy distribution within the HSF. Using a distributed
consensus approach, the nano-network then matches the found configuration to
the most probable EM wave traits, via a static lookup table that can be created
during the HSF manufacturing. Realistic simulations demonstrate the potential
of the proposed scheme. Moreover, we show that the proposed workflow is the
first-of-its-kind embedded EM compiler, i.e., an autonomic HSF that can
translate high-level EM behavior objectives to the corresponding, low-level EM
actuation commands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04822</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04822</id><created>2019-07-10</created><authors><author><keyname>Zhang</keyname><forenames>Yucheng</forenames></author><author><keyname>Lobo-Mueller</keyname><forenames>Edrise M.</forenames></author><author><keyname>Karanicolas</keyname><forenames>Paul</forenames></author><author><keyname>Gallinger</keyname><forenames>Steven</forenames></author><author><keyname>Haider</keyname><forenames>Masoom A.</forenames></author><author><keyname>Khalvati</keyname><forenames>Farzad</forenames></author></authors><title>Improving Prognostic Performance in Resectable Pancreatic Ductal
  Adenocarcinoma using Radiomics and Deep Learning Features Fusion in CT Images</title><categories>q-bio.QM cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As an analytic pipeline for quantitative imaging feature extraction and
analysis, radiomics has grown rapidly in the past a few years. Recent studies
in radiomics aim to investigate the relationship between tumors imaging
features and clinical outcomes. Open source radiomics feature banks enable the
extraction and analysis of thousands of predefined features. On the other hand,
recent advances in deep learning have shown significant potential in the
quantitative medical imaging field, raising the research question of whether
predefined radiomics features have predictive information in addition to deep
learning features. In this study, we propose a feature fusion method and
investigate whether a combined feature bank of deep learning and predefined
radiomics features can improve the prognostics performance. CT images from
resectable Pancreatic Adenocarcinoma (PDAC) patients were used to compare the
prognosis performance of common feature reduction and fusion methods and the
proposed risk-score based feature fusion method for overall survival. It was
shown that the proposed feature fusion method significantly improves the
prognosis performance for overall survival in resectable PDAC cohorts,
elevating the area under ROC curve by 51% compared to predefined radiomics
features alone, by 16% compared to deep learning features alone, and by 32%
compared to existing feature fusion and reduction methods for a combination of
deep learning and predefined radiomics features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04831</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04831</id><created>2019-07-10</created><authors><author><keyname>Li</keyname><forenames>Tian-Hao</forenames></author><author><keyname>Khandaker</keyname><forenames>Muhammad R. A.</forenames></author><author><keyname>Tariq</keyname><forenames>Faisal</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author><author><keyname>Khan</keyname><forenames>Risala T.</forenames></author></authors><title>Learning the Wireless V2I Channels Using Deep Neural Networks</title><categories>eess.SP cs.IT cs.LG math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For high data rate wireless communication systems, developing an efficient
channel estimation approach is extremely vital for channel detection and signal
recovery. With the trend of high-mobility wireless communications between
vehicles and vehicles-to-infrastructure (V2I), V2I communications pose
additional challenges to obtaining real-time channel measurements. Deep
learning (DL) techniques, in this context, offer learning ability and
optimization capability that can approximate many kinds of functions. In this
paper, we develop a DL-based channel prediction method to estimate channel
responses for V2I communications. We have demonstrated how fast neural networks
can learn V2I channel properties and the changing trend. The network is trained
with a series of channel responses and known pilots, which then speculates the
next channel response based on the acquired knowledge. The predicted channel is
then used to evaluate the system performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04835</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04835</id><created>2019-07-10</created><updated>2019-07-15</updated><authors><author><keyname>Wang</keyname><forenames>Jiancong</forenames></author><author><keyname>Chen</keyname><forenames>Yuhua</forenames></author><author><keyname>Wu</keyname><forenames>Yifan</forenames></author><author><keyname>Shi</keyname><forenames>Jianbo</forenames></author><author><keyname>Gee</keyname><forenames>James</forenames></author></authors><title>Enhanced generative adversarial network for 3D brain MRI
  super-resolution</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single image super-resolution (SISR) reconstruction for magnetic resonance
imaging (MRI) has generated significant interest because of its potential to
not only speed up imaging but to improve quantitative processing and analysis
of available image data. Generative Adversarial Networks (GAN) have proven to
perform well in recovering image texture detail, and many variants have
therefore been proposed for SISR. In this work, we develop an enhancement to
tackle GAN-based 3D SISR by introducing a new residual-in-residual dense block
(RRDG) generator that is both memory efficient and achieves state-of-the-art
performance in terms of PSNR (Peak Signal to Noise Ratio), SSIM (Structural
Similarity) and NRMSE (Normalized Root Mean Squared Error) metrics. We also
introduce a patch GAN discriminator with improved convergence behavior to
better model brain image texture. We proposed a novel the anatomical fidelity
evaluation of the results using a pre-trained brain parcellation network.
Finally, these developments are combined through a simple and efficient method
to balance etween image and texture quality in the final output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04868</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04868</id><created>2019-07-10</created><authors><author><keyname>Donahue</keyname><forenames>Chris</forenames></author><author><keyname>Mao</keyname><forenames>Huanru Henry</forenames></author><author><keyname>Li</keyname><forenames>Yiting Ethan</forenames></author><author><keyname>Cottrell</keyname><forenames>Garrison W.</forenames></author><author><keyname>McAuley</keyname><forenames>Julian</forenames></author></authors><title>LakhNES: Improving multi-instrumental music generation with cross-domain
  pre-training</title><categories>cs.SD cs.LG cs.MM eess.AS stat.ML</categories><comments>Published as a conference paper at ISMIR 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We are interested in the task of generating multi-instrumental music scores.
The Transformer architecture has recently shown great promise for the task of
piano score generation; here we adapt it to the multi-instrumental setting.
Transformers are complex, high-dimensional language models which are capable of
capturing long-term structure in sequence data, but require large amounts of
data to fit. Their success on piano score generation is partially explained by
the large volumes of symbolic data readily available for that domain. We
leverage the recently-introduced NES-MDB dataset of four-instrument scores from
an early video game sound synthesis chip (the NES), which we find to be
well-suited to training with the Transformer architecture. To further improve
the performance of our model, we propose a pre-training technique to leverage
the information in a large collection of heterogeneous music, namely the Lakh
MIDI dataset. Despite differences between the two corpora, we find that this
transfer learning procedure improves both quantitative and qualitative
performance for our primary task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04877</identifier>
 <datestamp>2019-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04877</id><created>2019-07-10</created><authors><author><keyname>Eriksen</keyname><forenames>Bj&#xf8;rn-Olav H.</forenames></author><author><keyname>Breivik</keyname><forenames>Morten</forenames></author></authors><title>Short-term ASV Collision Avoidance with Static and Moving Obstacles</title><categories>eess.SY cs.SY</categories><comments>Submitted to Modeling, Identification and Control</comments><journal-ref>Modeling, Identification and Control: 40 (2019), pp. 177-187</journal-ref><doi>10.4173/mic.2019.3.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article considers collision avoidance (COLAV) for both static and moving
obstacles using the branching-course model predictive control (BC-MPC)
algorithm, which is designed for use by autonomous surface vehicles (ASVs). The
BC-MPC algorithm originally only considered COLAV of moving obstacles, so in
order to make the algorithm also be able to avoid static obstacles, we
introduce an extra term in the objective function based on an occupancy grid.
In addition, other improvements are made to the algorithm resulting in
trajectories with less wobbling. The modified algorithm is verified through
full-scale experiments in the Trondheimsfjord in Norway with both virtual
static obstacles and a physical moving obstacle. A radar-based tracking system
is used to detect and track the moving obstacle, which enables the algorithm to
avoid obstacles without depending on vessel-to-vessel communication. The
experiments show that the algorithm is able to simultaneously avoid both static
and moving obstacles, while providing clear and readily observable maneuvers.
The BC-MPC algorithm is compliant with rules 8, 13 and 17 of the the
International Regulations for Preventing Collisions at Sea (COLREGs), and
favors maneuvers following rules 14 and 15.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04882</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04882</id><created>2019-07-10</created><authors><author><keyname>Cui</keyname><forenames>Xiaodong</forenames></author><author><keyname>Picheny</keyname><forenames>Michael</forenames></author></authors><title>Acoustic Model Optimization Based On Evolutionary Stochastic Gradient
  Descent with Anchors for Automatic Speech Recognition</title><categories>cs.CL cs.LG eess.AS</categories><comments>Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evolutionary stochastic gradient descent (ESGD) was proposed as a
population-based approach that combines the merits of gradient-aware and
gradient-free optimization algorithms for superior overall optimization
performance. In this paper we investigate a variant of ESGD for optimization of
acoustic models for automatic speech recognition (ASR). In this variant, we
assume the existence of a well-trained acoustic model and use it as an anchor
in the parent population whose good &quot;gene&quot; will propagate in the evolution to
the offsprings. We propose an ESGD algorithm leveraging the anchor models such
that it guarantees the best fitness of the population will never degrade from
the anchor model. Experiments on 50-hour Broadcast News (BN50) and 300-hour
Switchboard (SWB300) show that the ESGD with anchors can further improve the
loss and ASR performance over the existing well-trained acoustic models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04887</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04887</id><created>2019-07-10</created><authors><author><keyname>Mac</keyname><forenames>Khoi-Nguyen C.</forenames></author><author><keyname>Cui</keyname><forenames>Xiaodong</forenames></author><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Picheny</keyname><forenames>Michael</forenames></author></authors><title>Large-Scale Mixed-Bandwidth Deep Neural Network Acoustic Modeling for
  Automatic Speech Recognition</title><categories>eess.AS cs.CL cs.SD</categories><comments>Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In automatic speech recognition (ASR), wideband (WB) and narrowband (NB)
speech signals with different sampling rates typically use separate acoustic
models. Therefore mixed-bandwidth (MB) acoustic modeling has important
practical values for ASR system deployment. In this paper, we extensively
investigate large-scale MB deep neural network acoustic modeling for ASR using
1,150 hours of WB data and 2,300 hours of NB data. We study various MB
strategies including downsampling, upsampling and bandwidth extension for MB
acoustic modeling and evaluate their performance on 8 diverse WB and NB test
sets from various application domains. To deal with the large amounts of
training data, distributed training is carried out on multiple GPUs using
synchronous data parallelism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04909</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04909</id><created>2019-07-10</created><authors><author><keyname>Prakash</keyname><forenames>Pavana</forenames></author><author><keyname>Abdelhadi</keyname><forenames>Ahmed</forenames></author><author><keyname>Pan</keyname><forenames>Miao</forenames></author></authors><title>Secure Authentication of ADS-B Aircraft Communications using Retroactive
  Key Publication</title><categories>eess.SP cs.SY eess.SY</categories><comments>4 pages, 4 figures, 1 algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic Dependent Surveillance-Broadcast(ADSB), is the next generation Air
Traffic management system to monitor the airspace for air traffic communication
and traffic information. While the ADS-B empowers aircraft to broadcast their
location information automatically and provide situational awareness, it is
susceptible to attacks and security issues. In this paper, we introduce a
method to secure the ADS-B protocol in aircraft communication using Retroactive
Key Publication where senders publish their keys retroactively, which is
different from the traditional asymmetric cryptography. The deduced solution
does not rely on a connection or two-way packets exchange to establish
security. It compensates for the loss of packets owing to huge air traffic, yet
preserving the open and broadcast nature of ADS-B. Our proposed protocol uses
the existing ADS-B system and same hardware with no modifications but still
adds security. Our secure system has low impact on current operations and
retains the operational efficiency of the current aircraft system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04916</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04916</id><created>2019-07-08</created><authors><author><keyname>Weninger</keyname><forenames>Felix</forenames></author><author><keyname>Andr&#xe9;s-Ferrer</keyname><forenames>Jes&#xfa;s</forenames></author><author><keyname>Li</keyname><forenames>Xinwei</forenames></author><author><keyname>Zhan</keyname><forenames>Puming</forenames></author></authors><title>Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence
  ASR</title><categories>eess.AS cs.CL cs.LG cs.SD stat.ML</categories><comments>To appear in INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence-to-sequence (seq2seq) based ASR systems have shown state-of-the-art
performances while having clear advantages in terms of simplicity. However,
comparisons are mostly done on speaker independent (SI) ASR systems, though
speaker adapted conventional systems are commonly used in practice for
improving robustness to speaker and environment variations. In this paper, we
apply speaker adaptation to seq2seq models with the goal of matching the
performance of conventional ASR adaptation. Specifically, we investigate
Kullback-Leibler divergence (KLD) as well as Linear Hidden Network (LHN) based
adaptation for seq2seq ASR, using different amounts (up to 20 hours) of
adaptation data per speaker. Our SI models are trained on large amounts of
dictation data and achieve state-of-the-art results. We obtained 25% relative
word error rate (WER) improvement with KLD adaptation of the seq2seq model vs.
18.7% gain from acoustic model adaptation in the conventional system. We also
show that the WER of the seq2seq model decreases log-linearly with the amount
of adaptation data. Finally, we analyze adaptation based on the minimum WER
criterion and adapting the language model (LM) for score fusion with the
speaker adapted seq2seq model, which result in further improvements of the
seq2seq system performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04917</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04917</id><created>2019-07-04</created><authors><author><keyname>Giridhar</keyname><forenames>Lalitha</forenames></author><author><keyname>and</keyname><forenames>Aishwarya Dharani</forenames></author><author><keyname>Guruviah</keyname><forenames>Velmathi</forenames></author></authors><title>A Novel Approach to OCR using Image Recognition based Classification for
  Ancient Tamil Inscriptions in Temples</title><categories>cs.CV eess.IV</categories><comments>7 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recognition of ancient Tamil characters has always been a challenge for
epigraphers. This is primarily because the language has evolved over the
several centuries and the character set over this time has both expanded and
diversified. This proposed work focuses on improving optical character
recognition techniques for ancient Tamil script which was in use between the
7th and 12th centuries. While comprehensively curating a functional data set
for ancient Tamil characters is an arduous task, in this work, a data set has
been curated using cropped images of characters found on certain temple
inscriptions, specific to this time as a case study. After using Otsu
thresholding method for binarization of the image a two dimensional convolution
neural network is defined and used to train, classify and, recognize the
ancient Tamil characters. To implement the optical character recognition
techniques, the neural network is linked to the Tesseract using the pytesseract
library of Python. As an added feature, the work also incorporates Google's
text to speech voice engine to produce an audio output of the digitized text.
Various samples for both modern and ancient Tamil were collected and passed
through the system. It is found that for Tamil inscriptions studied over the
considered time period, a combined efficiency of 77.7 percent can be achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04926</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04926</id><created>2019-07-05</created><authors><author><keyname>Sanz</keyname><forenames>Javier</forenames></author><author><keyname>Wulff-Abramsson</keyname><forenames>Andreas</forenames></author><author><keyname>Aguilar-Paredes</keyname><forenames>Carlos</forenames></author><author><keyname>Bruni</keyname><forenames>Luis Emilio</forenames></author><author><keyname>Sanchez</keyname><forenames>Lydia</forenames></author></authors><title>Synchronizing Audio-Visual Film Stimuli in Unity (version 5.5.1f1): Game
  Engines as a Tool for Research</title><categories>eess.AS cs.MM cs.SD eess.IV</categories><comments>13 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unity is a software specifically designed for the development of video games.
However, due to its programming possibilities and the polyvalence of its
architecture, it can prove to be a versatile tool for stimuli presentation in
research experiments. Nevertheless, it also has some limitations and conditions
that need to be taken into account to ensure optimal performance in particular
experimental situations. Such is the case if we want to use it in an
experimental design that includes the acquisition of biometric signals
synchronized with the broadcasting of video and audio in real time. In the
present paper, we analyse how Unity (version 5.5.1f1) reacts in one such
experimental design that requires the execution of audio-visual material. From
the analysis of an experimental procedure in which the video was executed
following the standard software specifications, we have detected the following
problems desynchronization between the emission of the video and the audio;
desynchronization between the temporary counter and the video; a delay in the
execution of the screenshot; and depending on the encoding of the video a bad
fluency in the video playback, which even though it maintains the total
playback time, it causes Unity to freeze frames and proceed to compensate with
little temporary jumps in the video. Finally, having detected all the problems,
a compensation and verification process is designed to be able to work with
audio-visual material in Unity (version 5.5.1f1) in an accurate way. We present
a protocol for checks and compensations that allows solving these problems to
ensure the execution of robust experiments in terms of reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04927</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04927</id><created>2019-07-05</created><authors><author><keyname>Gupta</keyname><forenames>Archit</forenames></author><author><keyname>Shillingford</keyname><forenames>Brendan</forenames></author><author><keyname>Assael</keyname><forenames>Yannis</forenames></author><author><keyname>Walters</keyname><forenames>Thomas C.</forenames></author></authors><title>Speech bandwidth extension with WaveNet</title><categories>eess.AS cs.LG cs.SD eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale mobile communication systems tend to contain legacy transmission
channels with narrowband bottlenecks, resulting in characteristic
&quot;telephone-quality&quot; audio. While higher quality codecs exist, due to the scale
and heterogeneity of the networks, transmitting higher sample rate audio with
modern high-quality audio codecs can be difficult in practice. This paper
proposes an approach where a communication node can instead extend the
bandwidth of a band-limited incoming speech signal that may have been passed
through a low-rate codec. To this end, we propose a WaveNet-based model
conditioned on a log-mel spectrogram representation of a bandwidth-constrained
speech audio signal of 8 kHz and audio with artifacts from GSM full-rate (FR)
compression to reconstruct the higher-resolution signal. In our experimental
MUSHRA evaluation, we show that a model trained to upsample to 24kHz speech
signals from audio passed through the 8kHz GSM-FR codec is able to reconstruct
audio only slightly lower in quality to that of the Adaptive Multi-Rate
Wideband audio codec (AMR-WB) codec at 16kHz, and closes around half the gap in
perceptual quality between the original encoded signal and the original speech
sampled at 24kHz. We further show that when the same model is passed 8kHz audio
that has not been compressed, is able to again reconstruct audio of slightly
better quality than 16kHz AMR-WB, in the same MUSHRA evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04928</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04928</id><created>2019-07-06</created><authors><author><keyname>Senoussaoui</keyname><forenames>Mohammed</forenames></author><author><keyname>Cardinal</keyname><forenames>Patrick</forenames></author><author><keyname>Koerich</keyname><forenames>Alessandro Lameiras</forenames></author></authors><title>Bag-of-Audio-Words based on Autoencoder Codebook for Continuous Emotion
  Prediction</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a novel approach for extracting a Bag-of-Words (BoW)
representation based on a Neural Network codebook. The conventional BoW model
is based on a dictionary (codebook) built from elementary representations which
are selected randomly or by using a clustering algorithm on a training dataset.
A metric is then used to assign unseen elementary representations to the
closest dictionary entries in order to produce a histogram. In the proposed
approach, an autoencoder (AE) encompasses the role of both the dictionary
creation and the assignment metric. The dimension of the encoded layer of the
AE corresponds to the size of the dictionary and the output of its neurons
represents the assignment metric. Experimental results for the continuous
emotion prediction task on the AVEC 2017 audio dataset have shown an
improvement of the Concordance Correlation Coefficient (CCC) from 0.225 to
0.322 for arousal dimension and from 0.244 to 0.368 for valence dimension
relative to the conventional BoW version implemented in a baseline system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04935</identifier>
 <datestamp>2020-01-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04935</id><created>2019-07-10</created><updated>2020-01-17</updated><authors><author><keyname>Liu</keyname><forenames>Zexiang</forenames></author><author><keyname>Ozay</keyname><forenames>Necmiye</forenames></author></authors><title>Safety Control with Preview Automaton</title><categories>eess.SY cs.SY</categories><comments>10 pages, 7 figures, accepted by CDC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of safety controller synthesis for systems
equipped with sensor modalities that can provide preview information. We
consider switched systems where switching mode is an external signal for which
preview information is available. In particular, it is assumed that the sensors
can notify the controller about an upcoming mode switch before the switch
occurs. We propose preview automaton, a mathematical construct that captures
both the preview information and the possible constraints on switching signals.
Then, we study safety control synthesis problem with preview information. An
algorithm that computes the maximal invariant set in a given mode-dependent
safe set is developed. These ideas are demonstrated on two case studies from
autonomous driving domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04975</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04975</id><created>2019-07-10</created><authors><author><keyname>Afouras</keyname><forenames>Triantafyllos</forenames></author><author><keyname>Chung</keyname><forenames>Joon Son</forenames></author><author><keyname>Zisserman</keyname><forenames>Andrew</forenames></author></authors><title>My lips are concealed: Audio-visual speech enhancement through
  obstructions</title><categories>cs.CV cs.SD eess.AS</categories><comments>Accepted to Interspeech 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our objective is an audio-visual model for separating a single speaker from a
mixture of sounds such as other speakers and background noise. Moreover, we
wish to hear the speaker even when the visual cues are temporarily absent due
to occlusion. To this end we introduce a deep audio-visual speech enhancement
network that is able to separate a speaker's voice by conditioning on both the
speaker's lip movements and/or a representation of their voice. The voice
representation can be obtained by either (i) enrollment, or (ii) by
self-enrollment -- learning the representation on-the-fly given sufficient
unobstructed visual input. The model is trained by blending audios, and by
introducing artificial occlusions around the mouth region that prevent the
visual modality from dominating. The method is speaker-independent, and we
demonstrate it on real examples of speakers unheard (and unseen) during
training. The method also improves over previous models in particular for cases
of occlusion in the visual modality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04980</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04980</id><created>2019-07-10</created><updated>2019-08-31</updated><authors><author><keyname>Teng</keyname><forenames>Chieh-Fang</forenames></author><author><keyname>Ou</keyname><forenames>Han-Mo</forenames></author><author><keyname>Wu</keyname><forenames>An-Yeu</forenames></author></authors><title>Neural Network-based Equalizer by Utilizing Coding Gain in Advance</title><categories>eess.SP cs.LG</categories><comments>5 pages, 4 figures, accepted by the 2019 Seventh IEEE Global
  Conference on Signal and Information Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, deep learning has been exploited in many fields with revolutionary
breakthroughs. In the light of this, deep learning-assisted communication
systems have also attracted much attention in recent years and have potential
to break down the conventional design rule for communication systems. In this
work, we propose two kinds of neural network-based equalizers to exploit
different characteristics between convolutional neural networks and recurrent
neural networks. The equalizer in conventional block-based design may destroy
the code structure and degrade the capacity of coding gain for decoder. On the
contrary, our proposed approach not only eliminates channel fading, but also
exploits the code structure with utilization of coding gain in advance, which
can effectively increase the overall utilization of coding gain with more than
1.5 dB gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04984</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04984</id><created>2019-07-10</created><authors><author><keyname>Masuyama</keyname><forenames>Yoshiki</forenames></author><author><keyname>Togami</keyname><forenames>Masahito</forenames></author><author><keyname>Komatsu</keyname><forenames>Tatsuya</forenames></author></authors><title>Multichannel Loss Function for Supervised Speech Source Separation by
  Mask-based Beamforming</title><categories>cs.SD eess.AS</categories><comments>5 pages, Accepted at INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose two mask-based beamforming methods using a deep
neural network (DNN) trained by multichannel loss functions. Beamforming
technique using time-frequency (TF)-masks estimated by a DNN have been applied
to many applications where TF-masks are used for estimating spatial covariance
matrices. To train a DNN for mask-based beamforming, loss functions designed
for monaural speech enhancement/separation have been employed. Although such a
training criterion is simple, it does not directly correspond to the
performance of mask-based beamforming. To overcome this problem, we use
multichannel loss functions which evaluate the estimated spatial covariance
matrices based on the multichannel Itakura--Saito divergence. DNNs trained by
the multichannel loss functions can be applied to construct several
beamformers. Experimental results confirmed their effectiveness and robustness
to microphone configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.04986</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.04986</id><created>2019-07-10</created><authors><author><keyname>Ye</keyname><forenames>Dengpan</forenames></author><author><keyname>Jiang</keyname><forenames>Shunzhi</forenames></author><author><keyname>Huang</keyname><forenames>Jiaqin</forenames></author></authors><title>Heard More Than Heard: An Audio Steganography Method Based on GAN</title><categories>cs.MM cs.CR eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audio steganography is a collection of techniques for concealing the
existence of information by embedding it within a non-secret audio, which is
referred to as carrier. Distinct from cryptography, the steganography put
emphasis on the hiding of the secret existence. The existing audio
steganography methods mainly depend on human handcraft, while we proposed an
audio steganography algorithm which automatically generated from adversarial
training. The method consists of three neural networks: encoder which embeds
the secret message in the carrier, decoder which extracts the message, and
discriminator which determine the carriers contain secret messages. All the
networks are simultaneously trained to create embedding, extracting and
discriminating process. The system is trained with different training settings
on two datasets. Competed the majority of audio steganographic schemes, the
proposed scheme could produce high fidelity steganographic audio which contains
secret audio. Besides, the additional experiments verify the robustness and
security of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05009</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05009</id><created>2019-07-11</created><authors><author><keyname>Myers</keyname><forenames>Nitin Jonathan</forenames></author><author><keyname>Kaleva</keyname><forenames>Jarkko</forenames></author><author><keyname>T&#xf6;lli</keyname><forenames>Antti</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Message passing-based link configuration in short range millimeter wave
  systems</title><categories>eess.SP cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) communication in typical wearable and data center
settings is short range. As the distance between the transmitter and the
receiver in short range scenarios can be comparable to the length of the
antenna arrays, the common far field approximation for the channel may not be
applicable. As a result, dictionaries that result in a sparse channel
representation in the far field setting may not be appropriate for short
distances. In this paper, we develop a novel framework to exploit the structure
in short range mmWave channels. The proposed method splits the channel into
several subchannels for which the far field approximation can be applied. Then,
the structure within and across different subchannels is leveraged using
message passing. We show how information about the antenna array geometry can
be used to design message passing factors that incorporate structure across
successive subchannels. Simulation results indicate that our framework can be
used to achieve better beam alignment with fewer channel measurements when
compared to standard compressed sensing-based techniques that do not exploit
structure across subchannels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05036</identifier>
 <datestamp>2019-09-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05036</id><created>2019-07-11</created><authors><author><keyname>Okada</keyname><forenames>Daigo</forenames></author><author><keyname>Nakamura</keyname><forenames>Naotoshi</forenames></author><author><keyname>Wada</keyname><forenames>Takuya</forenames></author><author><keyname>Iwasaki</keyname><forenames>Ayako</forenames></author><author><keyname>Yamada</keyname><forenames>Ryo</forenames></author></authors><title>Extension of Sinkhorn Method: Optimal Movement Estimation of Agents
  Moving at Constant Velocity</title><categories>eess.IV cs.CV q-bio.CB</categories><comments>12 pages, 7 figures, 2 tables</comments><msc-class>92C55</msc-class><journal-ref>Transactions of the Japanese Society for Artificial Intelligence
  34.5 (2019) D-J13_1-7</journal-ref><doi>10.1527/tjsai.D-J13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the field of bioimaging, an important part of analyzing the motion of
objects is tracking. We propose a method that applies the Sinkhorn distance for
solving the optimal transport problem to track objects. The advantage of this
method is that it can flexibly incorporate various assumptions in tracking as a
cost matrix. First, we extend the Sinkhorn distance from two dimensions to
three dimensions. Using this three-dimensional distance, we compare the
performance of two types of tracking technique, namely tracking that associates
objects that are close to each other, which conventionally uses the
nearest-neighbor method, and tracking that assumes that the object is moving at
constant velocity, using three types of simulation data. The results suggest
that when tracking objects moving at constant velocity, our method is superior
to conventional nearest-neighbor tracking as long as the added noise is not
excessively large. We show that the Sinkhorn method can be applied effectively
to object tracking. Our simulation data analysis suggests that when objects are
moving at constant velocity, our method, which sets acceleration as a cost,
outperforms the traditional nearest-neighbor method in terms of tracking
objects. To apply the proposed method to real bioimaging data, it is necessary
to set an appropriate cost indicator based on the movement features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05043</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05043</id><created>2019-07-11</created><authors><author><keyname>Elayan</keyname><forenames>Hadeel</forenames></author><author><keyname>Amin</keyname><forenames>Osama</forenames></author><author><keyname>Shihada</keyname><forenames>Basem</forenames></author><author><keyname>Shubair</keyname><forenames>Raed M.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Terahertz Band: The Last Piece of RF Spectrum Puzzle for Communication
  Systems</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultra-high bandwidth, negligible latency and seamless communication for
devices and applications are envisioned as major milestones that will
revolutionize the way by which societies create, distribute and consume
information. The remarkable expansion of wireless data traffic that we are
witnessing recently has advocated the investigation of suitable regimes in the
radio spectrum to satisfy users' escalating requirements and allow the
development and exploitation of both massive capacity and massive connectivity
of heterogeneous infrastructures. To this end, the Terahertz (THz) frequency
band (0.1-10 THz) has received noticeable attention in the research community
as an ideal choice for scenarios involving high-speed transmission.
Particularly, with the evolution of technologies and devices, advancements in
THz communication is bridging the gap between the millimeter wave (mmW) and
optical frequency ranges. Moreover, the IEEE 802.15 suite of standards has been
issued to shape regulatory frameworks that will enable innovation and provide a
complete solution that crosses between wired and wireless boundaries at 100
Gbps. Nonetheless, despite the expediting progress witnessed in THz wireless
research, the THz band is still considered one of the least probed frequency
bands. As such, in this work, we present an up-to-date review paper to analyze
the fundamental elements and mechanisms associated with the THz system
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05050</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05050</id><created>2019-07-11</created><authors><author><keyname>Bin</keyname><forenames>Michelangelo</forenames></author><author><keyname>Bernard</keyname><forenames>Pauline</forenames></author><author><keyname>Marconi</keyname><forenames>Lorenzo</forenames></author></authors><title>Approximate Nonlinear Regulation via Identification-Based Adaptive
  Internal Models</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the problem of adaptive output regulation for
multivariable nonlinear systems in normal form. We present a regulator
employing an adaptive internal model of the exogenous signals based on the
theory of nonlinear Luenberger observers. Adaptation is performed by means of
discrete-time system identification schemes where any algorithm fulfilling some
optimality and stability conditions can be used. Practical and approximate
regulation results are given relating the prediction capabilities of the
identified model to the asymptotic bound on the regulated variable, which
become asymptotic whenever a &quot;right&quot; internal model exists in the identifier's
model set. The proposed approach, moreover, does not require &quot;high-gain&quot;
stabilization actions, thus qualifying as a suitable solution for practical
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05062</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05062</id><created>2019-07-11</created><authors><author><keyname>Wang</keyname><forenames>Chengjia</forenames></author><author><keyname>Papanastasiou</keyname><forenames>Giorgos</forenames></author><author><keyname>Chartsias</keyname><forenames>Agisilaos</forenames></author><author><keyname>Jacenkow</keyname><forenames>Grzegorz</forenames></author><author><keyname>Tsaftaris</keyname><forenames>Sotirios A.</forenames></author><author><keyname>Zhang</keyname><forenames>Heye</forenames></author></authors><title>FIRE: Unsupervised bi-directional inter-modality registration using deep
  networks</title><categories>cs.CV eess.IV</categories><comments>We submitted this paper to a top medical imaging conference,
  srebuttal responded by the meta-reviewer. We were told that this work is not
  important and will not have big impact as the &quot;reviewers were not
  enthusiastic&quot;. Here I publish the paper online for an open discussion. I will
  publish the code, the pre-trained model, the results, especially the reviews,
  and the meta reviews on github</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inter-modality image registration is an critical preprocessing step for many
applications within the routine clinical pathway. This paper presents an
unsupervised deep inter-modality registration network that can learn the
optimal affine and non-rigid transformations simultaneously.
Inverse-consistency is an important property commonly ignored in recent deep
learning based inter-modality registration algorithms. We address this issue
through the proposed multi-task architecture and the new comprehensive
transformation network. Specifically, the proposed model learns a
modality-independent latent representation to perform cycle-consistent
cross-modality synthesis, and use an inverse-consistent loss to learn a pair of
transformations to align the synthesized image with the target. We name this
proposed framework as FIRE due to the shape of its structure. Our method shows
comparable and better performances with the popular baseline method in
experiments on multi-sequence brain MR data and intra-modality 4D cardiac
Cine-MR data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05085</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05085</id><created>2019-07-11</created><authors><author><keyname>Amer</keyname><forenames>Ramy</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Marchetti</keyname><forenames>Nicola</forenames></author></authors><title>Towards a Connected Sky: Performance of Beamforming with Down-tilted
  Antennas for Ground and UAV User Co-existence</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing connectivity to aerial users such as cellular connected unmanned
aerial vehicles is a key challenge for future cellular systems. In this paper,
the use of conjugate beamforming for simultaneous content delivery to an AU
coexisting with multiple ground users is investigated. In particular, a content
delivery network of uniformly distributed massive MIMO enabled ground base
stations serving both aerial and ground users through spatial multiplexing is
considered. For this model, the successful content delivery probability is
derived as a function of the system parameters. The effects of various system
parameters such as antenna down-tilt angle, AU altitude, number of scheduled
users, and number of antennas on the achievable performance are then
investigated. Results reveal that whenever the AU altitude is below the BS
height, the antennas down-tilt angles yield an inherent tradeoff between the
performance of the AU and the GUs. However, if the AU altitude exceeds the BS
height, down-tilting the BS antennas with a considerably large angle improves
the performance of both the AU and the GUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05089</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05089</id><created>2019-07-11</created><authors><author><keyname>Tiulpin</keyname><forenames>Aleksei</forenames></author><author><keyname>Finnil&#xe4;</keyname><forenames>Mikko</forenames></author><author><keyname>Lehenkari</keyname><forenames>Petri</forenames></author><author><keyname>Nieminen</keyname><forenames>Heikki J.</forenames></author><author><keyname>Saarakkala</keyname><forenames>Simo</forenames></author></authors><title>Deep-Learning for Tidemark Segmentation in Human Osteochondral Tissues
  Imaged with Micro-computed Tomography</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Three-dimensional (3D) semi-quantitative grading of pathological features in
articular cartilage (AC) offers significant improvements in basic research of
osteoarthritis (OA). We have earlier developed the 3D protocol for imaging of
AC and its structures which includes staining of the sample with a contrast
agent (phosphotungstic acid, PTA) and a consequent scanning with micro-computed
tomography. Such a protocol was designed to provide X-ray attenuation contrast
to visualize AC structure. However, at the same time, this protocol has one
major disadvantage: the loss of contrast at the tidemark (calcified cartilage
interface, CCI). An accurate segmentation of CCI can be very important for
understanding the etiology of OA and ex-vivo evaluation of tidemark condition
at early OA stages. In this paper, we present the first application of Deep
Learning to PTA-stained osteochondral samples that allows to perform tidemark
segmentation in a fully-automatic manner. Our method is based on U-Net trained
using a combination of binary cross-entropy and soft Jaccard loss. On
cross-validation, this approach yielded intersection over the union of 0.59,
0.70, 0.79, 0.83 and 0.86 within 15 {\mu}m, 30 {\mu}m, 45 {\mu}m, 60 {\mu}m and
75 {\mu}m padded zones around the tidemark, respectively. Our codes and the
dataset that consisted of 35 PTA-stained human AC samples are made publicly
available together with the segmentation masks to facilitate the development of
biomedical image segmentation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05122</identifier>
 <datestamp>2019-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05122</id><created>2019-07-11</created><updated>2019-08-01</updated><authors><author><keyname>Pankajakshan</keyname><forenames>Arjun</forenames></author><author><keyname>Bear</keyname><forenames>Helen L.</forenames></author><author><keyname>Benetos</keyname><forenames>Emmanouil</forenames></author></authors><title>Polyphonic Sound Event and Sound Activity Detection: A Multi-task
  approach</title><categories>eess.AS cs.SD</categories><comments>Accepted to WASPAA 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polyphonic Sound Event Detection (SED) in real-world recordings is a
challenging task because of the dynamic polyphony level, intensity, and
duration of sound events. Current polyphonic SED systems fail to model the
temporal structure of sound events explicitly and instead attempt to look at
which sound events are present at each audio frame. Consequently, the
event-wise detection performance is much lower than the segment-wise detection
performance. In this work, we propose a joint model approach to improve the
temporal localization of sound events using a multi-task learning setup. The
first task predicts which sound events are present at each time frame; we call
this branch 'Sound Event Detection (SED) model', while the second task predicts
if a sound event is present or not at each frame; we call this branch 'Sound
Activity Detection (SAD) model'. We verify the proposed joint model by
comparing it with a separate implementation of both tasks aggregated together
from individual task predictions. Our experiments on the URBAN-SED dataset show
that the proposed joint model can alleviate False Positive (FP) and False
Negative (FN) errors and improve both the segment-wise and the event-wise
metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05123</identifier>
 <datestamp>2019-11-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05123</id><created>2019-07-11</created><updated>2019-11-15</updated><authors><author><keyname>Mohammadi</keyname><forenames>Ammar</forenames></author><author><keyname>Nakhkash</keyname><forenames>Mansor</forenames></author></authors><title>Reversible Data Hiding in Encrypted Images using Local Difference of
  Neighboring Pixels</title><categories>eess.IV cs.CR cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a reversible data hiding in encrypted image (RDHEI),
which divides image into non-overlapping blocks. In each block, central pixel
of the block is considered as leader pixel and others as follower ones. The
prediction errors between the intensity of follower pixels and leader ones are
calculated and analyzed to determine a feature for block embedding capacity.
This feature indicates the amount of data that can be embedded in a block.
Using this pre-process for whole blocks, we vacate rooms before the encryption
of the original image to achieve high embedding capacity. Also, using the
features of all blocks, embedded data is extracted and the original image is
perfectly reconstructed at the decoding phase. In effect, comparing to existent
RDHEI algorithms, embedding capacity is significantly increased in the proposed
algorithm. Experimental results confirm that the proposed algorithm outperforms
state of the art ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05126</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05126</id><created>2019-07-11</created><authors><author><keyname>Schram</keyname><forenames>Viktoria</forenames></author><author><keyname>Bereyhi</keyname><forenames>Ali</forenames></author><author><keyname>Zaech</keyname><forenames>Jan-Nico</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Ralf R.</forenames></author><author><keyname>Gerstacker</keyname><forenames>Wolfgang H.</forenames></author></authors><title>Approximate Message Passing for Indoor THz Channel Estimation</title><categories>eess.SP</categories><comments>6 pages,7 figures, conference: presented at BalkanCom 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing (CS) deals with the problem of reconstructing a sparse
vector from an under-determined set of observations. Approximate message
passing (AMP) is a technique used in CS based on iterative thresholding and
inspired by belief propagation in graphical models. Due to the high
transmission rate and a high molecular absorption, spreading loss and
reflection loss, the discrete-time channel impulse response (CIR) of a typical
indoor THz channel is very long and exhibits an approximately sparse
characteristic. In this paper, we develop AMP based channel estimation
algorithms for indoor THz communications. The performance of these algorithms
is compared to the state of the art. We apply AMP with soft- and
hard-thresholding. Unlike the common applications in which AMP with
hard-thresholding diverges, the properties of the THz channel favor this
approach. It is shown that THz channel estimation via hard-thresholding AMP
outperforms all previously proposed methods and approaches the oracle based
performance closely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05129</identifier>
 <datestamp>2019-12-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05129</id><created>2019-07-11</created><updated>2019-12-26</updated><authors><author><keyname>Mohammadi</keyname><forenames>Ammar</forenames></author><author><keyname>Nakhkash</keyname><forenames>Mansour</forenames></author></authors><title>Sorting Methods and Adaptive Thresholding for Histogram Based Reversible
  Data Hiding</title><categories>eess.IV cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a histogram based reversible data hiding (RDH) scheme,
which divides image pixels into different cell frequency bands to sort them for
data embedding. Data hiding is more efficient in lower cell frequency bands
because it provides more accurate prediction. Using pixel existence probability
in some pixels of ultra-low cell frequency band, another sorting is performed.
Employing these two novel sorting methods in combination with the hiding
intensity analysis that determines optimum prediction error, we improve the
quality of the marked image especially for low embedding capacities. In effect,
comparing to existent RDH algorithms, the hiding capacity is increased for a
specific level of the distortion for the marked image. Experimental results
confirm that the proposed algorithm outperforms state of the art ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05161</identifier>
 <datestamp>2019-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05161</id><created>2019-07-11</created><updated>2019-10-03</updated><authors><author><keyname>Zakeri</keyname><forenames>Abulfazl</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author></authors><title>Joint Radio Resource Allocation and 3D Beam-forming in MISO-NOMA-based
  Network with Profit Maximization for Mobile Virtual Network Operators</title><categories>eess.SP</categories><comments>13 pages, 8 Figures, 8 Tables, in Journal, IEEE TVT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive connections and high data rate services are key players in 5G
ecosystem and beyond. To satisfy the requirements of these types of services,
non orthogonal multiple Access (NOMA) and 3-dimensional beam-forming (3DBF) can
be exploited. In this paper, we devise a novel joint radio resource allocation
and 3D multiple input single output (MISO) BF algorithm in NOMA-based
heterogeneous networks (HetNets) at which our main aim is to maximize the
profit of mobile virtual network operators (MVNOs). To this end, we consider
multiple infrastructure providers (InPs) and MVNOs serving multiple users. Each
InP has multiple access points as base stations (BSs) with specified spectrum
and multi-beam antenna array in each transmitter that share its spectrum with
users by employing NOMA. To realize this, we formulate a novel optimization
problem at which the main aim is to maximize the revenue of MVNOs, subject to
resource limitations and quality of service (QoS) constraints. Since our
proposed optimization problem is non-convex, NP-hard and mathematically
intractable, we transform it into a convex one by introducing a new
optimization variable and converting the variables with adopting successive
convex approximation. More importantly, the proposed solution is assessed and
compared with the alternative search method and the optimal solution that is
obtained with adopting the exhaustive search method. In addition, the proposed
algorithm is studied from the computational complexity, convergence, and
performance perspective. Our simulation results demonstrate that NOMA-3DBF has
better performance and increases system throughput and revenue of MVNOs
compared to orthogonal multiple access with 2DBF by approximately 64%.
Especially, by exploiting 3DBF the revenue of MVNOs is improved by nearly 27%
in contrast to 2DBF in a high order of antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05164</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05164</id><created>2019-07-11</created><authors><author><keyname>Bhatia</keyname><forenames>Kanwal K.</forenames></author><author><keyname>Graham</keyname><forenames>Mark S.</forenames></author><author><keyname>Terry</keyname><forenames>Louise</forenames></author><author><keyname>Wood</keyname><forenames>Ashley</forenames></author><author><keyname>Tranos</keyname><forenames>Paris</forenames></author><author><keyname>Trikha</keyname><forenames>Sameer</forenames></author><author><keyname>Jaccard</keyname><forenames>Nicolas</forenames></author></authors><title>Disease classification of macular Optical Coherence Tomography scans
  using deep learning software: validation on independent, multi-centre data</title><categories>eess.IV cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To evaluate Pegasus-OCT, a clinical decision support software for
the identification of features of retinal disease from macula OCT scans, across
heterogenous populations involving varying patient demographics, device
manufacturers, acquisition sites and operators.
  Methods: 5,588 normal and anomalous macular OCT volumes (162,721 B-scans),
acquired at independent centres in five countries, were processed using the
software. Results were evaluated against ground truth provided by the dataset
owners.
  Results: Pegasus-OCT performed with AUROCs of at least 98% for all datasets
in the detection of general macular anomalies. For scans of sufficient quality,
the AUROCs for general AMD and DME detection were found to be at least 99% and
98%, respectively.
  Conclusions: The ability of a clinical decision support system to cater for
different populations is key to its adoption. Pegasus-OCT was shown to be able
to detect AMD, DME and general anomalies in OCT volumes acquired across
multiple independent sites with high performance. Its use thus offers
substantial promise, with the potential to alleviate the burden of growing
demand in eye care services caused by retinal disease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05178</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05178</id><created>2019-07-11</created><authors><author><keyname>Yang</keyname><forenames>Dongfang</forenames></author><author><keyname>&#xd6;zg&#xfc;ner</keyname><forenames>&#xdc;mit</forenames></author></authors><title>Combining Social Force Model with Model Predictive Control for Vehicle's
  Longitudinal Speed Regulation in Pedestrian-Dense Scenarios</title><categories>eess.SY cs.SY</categories><comments>This paper has been accepted and presented on The 8th Biennial
  Workshop on Digital Signal Processing for In-Vehicle Systems, Oct 7-9, 2018,
  at Nagoya University, Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In pedestrian-dense traffic scenarios, an autonomous vehicle may have to
safely drive through a crowd of pedestrians while the vehicle tries to keep the
desired speed as much as possible. This requires a model that can predict the
motion of crowd pedestrians and a method for the vehicle to predictively adjust
its speed. In this study, the model-based predictive control (MPC) was combined
with a social-force based vehicle-crowd interaction (VCI) model to regulate the
longitudinal speed of the autonomous vehicle. The predictive feature of the VCI
model can be precisely utilized by the MPC. A criterion for simultaneously
guaranteeing pedestrian safety and keeping the desired speed was designed, and
consequently, the MPC was formulated as a standard quadratic programming (QP)
problem, which can be easily solved by standard QP toolbox. The proposed
approach was compared with the traditional proportional-integral-derivative
(PID) control approach for regulating longitudinal speed. Scenarios of
different pedestrian density were evaluated in simulation. The results
demonstrated the merits of the proposed method to address this type of problem.
It also shows the potential of extending the method to address more complex
vehicle-pedestrian interaction situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05185</identifier>
 <datestamp>2019-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05185</id><created>2019-07-11</created><authors><author><keyname>Zheng</keyname><forenames>Shuai</forenames></author><author><keyname>Zhu</keyname><forenames>Zhenfeng</forenames></author><author><keyname>Cheng</keyname><forenames>Jian</forenames></author><author><keyname>Guo</keyname><forenames>Yandong</forenames></author><author><keyname>Zhao</keyname><forenames>Yao</forenames></author></authors><title>Edge Heuristic GAN for Non-uniform Blind Deblurring</title><categories>eess.IV cs.CV</categories><comments>5 pages, 3 figures</comments><doi>10.1109/LSP.2019.2939752</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-uniform blur, mainly caused by camera shake and motions of multiple
objects, is one of the most common causes of image quality degradation.
However, the traditional blind deblurring methods based on blur kernel
estimation do not perform well on complicated non-uniform motion blurs. Recent
studies show that GAN-based approaches achieve impressive performance on
deblurring tasks. In this letter, to further improve the performance of
GAN-based methods on deblurring tasks, we propose an edge heuristic multi-scale
generative adversarial network(GAN), which uses the &quot;coarse-to-fine&quot; scheme to
restore clear images in an end-to-end manner. In particular, an edge-enhanced
network is designed to generate sharp edges as auxiliary information to guide
the deblurring process. Furthermore, We propose a hierarchical content loss
function for deblurring tasks. Extensive experiments on different datasets show
that our method achieves state-of-the-art performance in dynamic scene
deblurring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05195</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05195</id><created>2019-07-11</created><authors><author><keyname>Odaibo</keyname><forenames>Stephen G.</forenames></author></authors><title>retina-VAE: Variationally Decoding the Spectrum of Macular Disease</title><categories>eess.IV cs.LG q-bio.TO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we seek a clinically-relevant latent code for representing the
spectrum of macular disease. Towards this end, we construct retina-VAE, a
variational autoencoder-based model that accepts a patient profile vector
(pVec) as input. The pVec components include clinical exam findings and
demographic information. We evaluate the model on a subspectrum of the retinal
maculopathies, in particular, exudative age-related macular degeneration,
central serous chorioretinopathy, and polypoidal choroidal vasculopathy. For
these three maculopathies, a database of 3000 6-dimensional pVecs (1000 each)
was synthetically generated based on known disease statistics in the
literature. The database was then used to train the VAE and generate latent
vector representations. We found training performance to be best for a
3-dimensional latent vector architecture compared to 2 or 4 dimensional
latents. Additionally, for the 3D latent architecture, we discovered that the
resulting latent vectors were strongly clustered spontaneously into one of 14
clusters. Kmeans was then used only to identify members of each cluster and to
inspect cluster properties. These clusters suggest underlying disease subtypes
which may potentially respond better or worse to particular pharmaceutical
treatments such as anti-vascular endothelial growth factor variants. The
retina-VAE framework will potentially yield new fundamental insights into the
mechanisms and manifestations of disease. And will potentially facilitate the
development of personalized pharmaceuticals and gene therapies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05205</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05205</id><created>2019-06-30</created><authors><author><keyname>Sadhu</keyname><forenames>Vidyasagar</forenames></author><author><keyname>Devaraj</keyname><forenames>Sanjana</forenames></author><author><keyname>Pompili</keyname><forenames>Dario</forenames></author></authors><title>Towards Ultra-low-power Realization of Analog Joint Source-Channel
  Coding using MOSFETs</title><categories>cs.ET cs.NI eess.SP</categories><comments>5 pages, IEEE ISCAS 2019. arXiv admin note: text overlap with
  arXiv:1907.00968</comments><journal-ref>2019 IEEE International Symposium on Circuits and Systems (ISCAS),
  Sapporo, Japan, 2019, pp. 1-5</journal-ref><doi>10.1109/ISCAS.2019.8702302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Certain sensing applications such as Internet of Things (IoTs), where the
sensing phenomenon may change rapidly in both time and space, requires sensors
that consume ultra-low power (so that they do not need to be put to sleep
leading to loss of temporal and spatial resolution) and have low costs (for
high density deployment). A novel encoding based on Metal Oxide Semiconductor
Field Effect Transistors (MOSFETs) is proposed to realize Analog Joint Source
Channel Coding (AJSCC), a low-complexity technique to compress two (or more)
signals into one with controlled distortion. In AJSCC, the y-axis is quantized
while the x-axis is continuously captured. A power-efficient design to support
multiple quantization levels is presented so that the digital receiver can
decide the optimum quantization and the analog transmitter circuit is able to
realize that. The approach is verified via Spice and MATLAB simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05208</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05208</id><created>2019-07-09</created><authors><author><keyname>Genchel</keyname><forenames>Benjamin</forenames></author><author><keyname>Pati</keyname><forenames>Ashis</forenames></author><author><keyname>Lerch</keyname><forenames>Alexander</forenames></author></authors><title>Explicitly Conditioned Melody Generation: A Case Study with
  Interdependent RNNs</title><categories>cs.SD cs.AI eess.AS</categories><comments>In Proceedings of the 7th International Workshop on Musical
  Meta-creation (MUME). Charlotte, North Carolina 2019</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Deep generative models for symbolic music are typically designed to model
temporal dependencies in music so as to predict the next musical event given
previous events. In many cases, such models are expected to learn abstract
concepts such as harmony, meter, and rhythm from raw musical data without any
additional information. In this study, we investigate the effects of explicitly
conditioning deep generative models with musically relevant information.
Specifically, we study the effects of four different conditioning inputs on the
performance of a recurrent monophonic melody generation model. Several
combinations of these conditioning inputs are used to train different model
variants which are then evaluated using three objective evaluation paradigms
across two genres of music. The results indicate musically relevant
conditioning significantly improves learning and performance, and reveal how
this information affects learning of musical features related to pitch and
rhythm. An informal subjective evaluation suggests a corresponding improvement
in the aesthetic quality of generations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05210</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05210</id><created>2019-06-26</created><authors><author><keyname>She</keyname><forenames>Changyang</forenames></author><author><keyname>Duan</keyname><forenames>Yifan</forenames></author><author><keyname>Zhao</keyname><forenames>Guodong</forenames></author><author><keyname>Quek</keyname><forenames>Tony Q. S.</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Cross-layer Design for Mission-Critical IoT in Mobile Edge Computing
  Systems</title><categories>cs.NI eess.SP</categories><comments>To appear on IEEE Internet of Things Journal (accepted with minor
  revision)</comments><doi>10.1109/JIOT.2019.2930983</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a cross-layer framework for optimizing user
association, packet offloading rates, and bandwidth allocation for
Mission-Critical Internet-of-Things (MC-IoT) services with short packets in
Mobile Edge Computing (MEC) systems, where enhanced Mobile BroadBand (eMBB)
services with long packets are considered as background services. To reduce
communication delay, the 5th generation new radio is adopted in radio access
networks. To avoid long queueing delay for short packets from MC-IoT,
Processor-Sharing (PS) servers are deployed at MEC systems, where the service
rate of the server is equally allocated to all the packets in the buffer. We
derive the distribution of latency experienced by short packets in closed-form,
and minimize the overall packet loss probability subject to the end-to-end
delay requirement. To solve the non-convex optimization problem, we propose an
algorithm that converges to a near optimal solution when the throughput of eMBB
services is much higher than MC-IoT services, and extend it into more general
scenarios. Furthermore, we derive the optimal solutions in two asymptotic
cases: communication or computing is the bottleneck of reliability. Simulation
and numerical results validate our analysis and show that the PS server
outperforms first-come-first-serve servers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05273</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05273</id><created>2019-07-06</created><updated>2019-07-11</updated><authors><author><keyname>Xu</keyname><forenames>Xiaowei</forenames></author><author><keyname>Wang</keyname><forenames>Tianchen</forenames></author><author><keyname>Zeng</keyname><forenames>Dewen</forenames></author><author><keyname>Shi</keyname><forenames>Yiyu</forenames></author><author><keyname>Jia</keyname><forenames>Qianjun</forenames></author><author><keyname>Yuan</keyname><forenames>Haiyun</forenames></author><author><keyname>Huang</keyname><forenames>Meiping</forenames></author><author><keyname>Zhuang</keyname><forenames>Jian</forenames></author></authors><title>Accurate Congenital Heart Disease Model Generation for 3D Printing</title><categories>eess.IV cs.CV</categories><comments>6 figures, 2 tables, accepted by the IEEE International Workshop on
  Signal Processing Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3D printing has been widely adopted for clinical decision making and
interventional planning of Congenital heart disease (CHD), while whole heart
and great vessel segmentation is the most significant but time-consuming step
in the model generation for 3D printing. While various automatic whole heart
and great vessel segmentation frameworks have been developed in the literature,
they are ineffective when applied to medical images in CHD, which have
significant variations in heart structure and great vessel connections. To
address the challenge, we leverage the power of deep learning in processing
regular structures and that of graph algorithms in dealing with large
variations and propose a framework that combines both for whole heart and great
vessel segmentation in CHD. Particularly, we first use deep learning to segment
the four chambers and myocardium followed by the blood pool, where variations
are usually small. We then extract the connection information and apply graph
matching to determine the categories of all the vessels. Experimental results
using 683D CT images covering 14 types of CHD show that our method can increase
Dice score by 11.9% on average compared with the state-of-the-art whole heart
and great vessel segmentation method in normal anatomy. The segmentation
results are also printed out using 3D printers for validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05274</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05274</id><created>2019-07-06</created><authors><author><keyname>Liu</keyname><forenames>Letao</forenames></author><author><keyname>Saerbeck</keyname><forenames>Martin</forenames></author><author><keyname>Dauwels</keyname><forenames>Justin</forenames></author></authors><title>Affine Disentangled GAN for Interpretable and Robust AV Perception</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous vehicles (AV) have progressed rapidly with the advancements in
computer vision algorithms. The deep convolutional neural network as the main
contributor to this advancement has boosted the classification accuracy
dramatically. However, the discovery of adversarial examples reveals the
generalization gap between dataset and the real world. Furthermore, affine
transformations may also confuse computer vision based object detectors. The
degradation of the perception system is undesirable for safety critical systems
such as autonomous vehicles. In this paper, a deep learning system is proposed:
Affine Disentangled GAN (ADIS-GAN), which is robust against affine
transformations and adversarial attacks. It is demonstrated that conventional
data augmentation for affine transformation and adversarial attacks are
orthogonal, while ADIS-GAN can handle both attacks at the same time. Useful
information such as image rotation angle and scaling factor are also generated
in ADIS-GAN. On MNIST dataset, ADIS-GAN can achieve over 98 percent
classification accuracy within 30 degrees rotation, and over 90 percent
classification accuracy against FGSM and PGD adversarial attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05275</identifier>
 <datestamp>2019-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05275</id><created>2019-07-05</created><updated>2019-11-18</updated><authors><author><keyname>Xie</keyname><forenames>Yaohua</forenames></author></authors><title>Improving the resolution of microscope by deconvolution after dense scan</title><categories>eess.IV cs.CV cs.HC</categories><comments>This work has been patented, thereby is not open-source</comments><doi>10.5281/zenodo.3353772</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Super-resolution microscopes (such as STED) illuminate samples with a tiny
spot, and achieve very high resolution. But structures smaller than the spot
cannot be resolved in this way. Therefore, we propose a technique to solve this
problem. It is termed &quot;Deconvolution after Dense Scan (DDS)&quot;. First, a
preprocessing stage is introduced to eliminate the optical uncertainty of the
peripheral areas around the sample's ROI (Region of Interest). Then, the ROI is
scanned densely together with its peripheral areas. Finally, the high
resolution image is recovered by deconvolution. The proposed technique does not
need to modify the apparatus much, and is mainly performed by algorithm.
Simulation experiments show that the technique can further improve the
resolution of super-resolution microscopes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05276</identifier>
 <datestamp>2019-11-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05276</id><created>2019-07-05</created><updated>2019-11-08</updated><authors><author><keyname>Groh</keyname><forenames>Matthew</forenames></author><author><keyname>Epstein</keyname><forenames>Ziv</forenames></author><author><keyname>Obradovich</keyname><forenames>Nick</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Rahwan</keyname><forenames>Iyad</forenames></author></authors><title>Human detection of machine manipulated media</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in neural networks for content generation enable artificial
intelligence (AI) models to generate high-quality media manipulations. Here we
report on a randomized experiment designed to study the effect of exposure to
media manipulations on over 15,000 individuals' ability to discern
machine-manipulated media. We engineer a neural network to plausibly and
automatically remove objects from images, and we deploy this neural network
online with a randomized experiment where participants can guess which image
out of a pair of images has been manipulated. The system provides participants
feedback on the accuracy of each guess. In the experiment, we randomize the
order in which images are presented, allowing causal identification of the
learning curve surrounding participants' ability to detect fake content. We
find sizable and robust evidence that individuals learn to detect fake content
through exposure to manipulated media when provided iterative feedback on their
detection attempts. Over a succession of only ten images, participants increase
their rating accuracy by over ten percentage points. Our study provides initial
evidence that human ability to detect fake, machine-generated content may
increase alongside the prevalence of such media online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05277</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05277</id><created>2019-07-09</created><updated>2019-07-21</updated><authors><author><keyname>Hoppe</keyname><forenames>Elisabeth</forenames><affiliation>Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universit&#xe4;t Erlangen-N&#xfc;rnberg, Erlangen, Germany</affiliation></author><author><keyname>Thamm</keyname><forenames>Florian</forenames><affiliation>Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universit&#xe4;t Erlangen-N&#xfc;rnberg, Erlangen, Germany</affiliation></author><author><keyname>K&#xf6;rzd&#xf6;rfer</keyname><forenames>Gregor</forenames><affiliation>MR Application Development, Siemens Healthcare, Erlangen, Germany</affiliation></author><author><keyname>Syben</keyname><forenames>Christopher</forenames><affiliation>Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universit&#xe4;t Erlangen-N&#xfc;rnberg, Erlangen, Germany</affiliation></author><author><keyname>Schirrmacher</keyname><forenames>Franziska</forenames><affiliation>Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universit&#xe4;t Erlangen-N&#xfc;rnberg, Erlangen, Germany</affiliation></author><author><keyname>Nittka</keyname><forenames>Mathias</forenames><affiliation>MR Application Development, Siemens Healthcare, Erlangen, Germany</affiliation></author><author><keyname>Pfeuffer</keyname><forenames>Josef</forenames><affiliation>MR Application Development, Siemens Healthcare, Erlangen, Germany</affiliation></author><author><keyname>Meyer</keyname><forenames>Heiko</forenames><affiliation>MR Application Development, Siemens Healthcare, Erlangen, Germany</affiliation></author><author><keyname>Maier</keyname><forenames>Andreas</forenames><affiliation>Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universit&#xe4;t Erlangen-N&#xfc;rnberg, Erlangen, Germany</affiliation></author></authors><title>RinQ Fingerprinting: Recurrence-informed Quantile Networks for Magnetic
  Resonance Fingerprinting</title><categories>eess.IV cs.CV</categories><comments>Accepted for MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Magnetic Resonance Fingerprinting (MRF) was proposed as a
quantitative imaging technique for the simultaneous acquisition of tissue
parameters such as relaxation times $T_1$ and $T_2$. Although the acquisition
is highly accelerated, the state-of-the-art reconstruction suffers from long
computation times: Template matching methods are used to find the most similar
signal to the measured one by comparing it to pre-simulated signals of possible
parameter combinations in a discretized dictionary. Deep learning approaches
can overcome this limitation, by providing the direct mapping from the measured
signal to the underlying parameters by one forward pass through a network. In
this work, we propose a Recurrent Neural Network (RNN) architecture in
combination with a novel quantile layer. RNNs are well suited for the
processing of time-dependent signals and the quantile layer helps to overcome
the noisy outliers by considering the spatial neighbors of the signal. We
evaluate our approach using in-vivo data from multiple brain slices and several
volunteers, running various experiments. We show that the RNN approach with
small patches of complex-valued input signals in combination with a quantile
layer outperforms other architectures, e.g. previously proposed CNNs for the
MRF reconstruction reducing the error in $T_1$ and $T_2$ by more than 80%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05280</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05280</id><created>2019-07-03</created><authors><author><keyname>Bachl</keyname><forenames>Maximilian</forenames></author><author><keyname>Ferreira</keyname><forenames>Daniel C.</forenames></author></authors><title>City-GAN: Learning architectural styles using a custom Conditional GAN
  architecture</title><categories>cs.CV cs.GR cs.LG eess.IV stat.ML</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Generative Adversarial Networks (GANs) are a well-known technique that is
trained on samples (e.g. pictures of fruits) and which after training is able
to generate realistic new samples. Conditional GANs (CGANs) additionally
provide label information for subclasses (e.g. apple, orange, pear) which
enables the GAN to learn more easily and increase the quality of its output
samples. We use GANs to learn architectural features of major cities and to
generate images of buildings which do not exist. We show that currently
available GAN and CGAN architectures are unsuited for this task and propose a
custom architecture and demonstrate that our architecture has superior
performance for this task and verify its capabilities with extensive
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05281</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05281</id><created>2019-07-02</created><authors><author><keyname>Dargazany</keyname><forenames>Aras R.</forenames></author></authors><title>Human Body Parts Tracking: Applications to Activity Recognition</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As cameras and computers became popular, the applications of computer vision
techniques attracted attention enormously. One of the most important
applications in the computer vision community is human activity recognition. In
order to recognize human activities, we propose a human body parts tracking
system that tracks human body parts such as head, torso, arms and legs in order
to perform activity recognition tasks in real time. This thesis presents a
real-time human body parts tracking system (i.e. HBPT) from video sequences.
Our body parts model is mostly represented by body components such as legs,
head, torso and arms. The body components are modeled using torso location and
size which are obtained by a torso tracking method in each frame. In order to
track the torso, we are using a blob tracking module to find the approximate
location and size of the torso in each frame. By tracking the torso, we will be
able to track other body parts based on their location with respect to the
torso on the detected silhouette. In the proposed method for human body part
tracking, we are also using a refining module to improve the detected
silhouette by refining the foreground mask (i.e. obtained by background
subtraction) in order to detect the body parts with respect to torso location
and size. Having found the torso size and location, the region of each human
body part on the silhouette will be modeled by a 2D-Gaussian blob in each frame
in order to show its location, size and pose. The proposed approach described
in this thesis tracks accurately the body parts in different illumination
conditions and in the presence of partial occlusions. The proposed approach is
applied to activity recognition tasks such as approaching an object, carrying
an object and opening a box or suitcase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05282</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05282</id><created>2019-07-03</created><authors><author><keyname>Li</keyname><forenames>Zhuangzi</forenames></author></authors><title>Image Super-Resolution Using Attention Based DenseNet with Residual
  Deconvolution</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image super-resolution is a challenging task and has attracted increasing
attention in research and industrial communities. In this paper, we propose a
novel end-to-end Attention-based DenseNet with Residual Deconvolution named as
ADRD. In our ADRD, a weighted dense block, in which the current layer receives
weighted features from all previous levels, is proposed to capture valuable
features rely in dense layers adaptively. And a novel spatial attention module
is presented to generate a group of attentive maps for emphasizing informative
regions. In addition, we design an innovative strategy to upsample residual
information via the deconvolution layer, so that the high-frequency details can
be accurately upsampled. Extensive experiments conducted on publicly available
datasets demonstrate the promising performance of the proposed ADRD against the
state-of-the-arts, both quantitatively and qualitatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05283</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05283</id><created>2019-07-08</created><authors><author><keyname>Koester</keyname><forenames>Evan</forenames></author><author><keyname>Sahin</keyname><forenames>Cem Safak</forenames></author></authors><title>A Comparison of Super-Resolution and Nearest Neighbors Interpolation
  Applied to Object Detection on Satellite Data</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As Super-Resolution (SR) has matured as a research topic, it has been applied
to additional topics beyond image reconstruction. In particular, combining
classification or object detection tasks with a super-resolution preprocessing
stage has yielded improvements in accuracy especially with objects that are
small relative to the scene. While SR has shown promise, a study comparing SR
and naive upscaling methods such as Nearest Neighbors (NN) interpolation when
applied as a preprocessing step for object detection has not been performed. We
apply the topic to satellite data and compare the Multi-scale Deep
Super-Resolution (MDSR) system to NN on the xView challenge dataset. To do so,
we propose a pipeline for processing satellite data that combines multi-stage
image tiling and upscaling, the YOLOv2 object detection architecture, and label
stitching. We compare the effects of training models using an upscaling factor
of 4, upscaling images from 30cm Ground Sample Distance (GSD) to an effective
GSD of 7.5cm. Upscaling by this factor significantly improves detection
results, increasing Average Precision (AP) of a generalized vehicle class by 23
percent. We demonstrate that while SR produces upscaled images that are more
visually pleasing than their NN counterparts, object detection networks see
little difference in accuracy with images upsampled using NN obtaining nearly
identical results to the MDSRx4 enhanced images with a difference of 0.0002 AP
between the two methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05284</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05284</id><created>2019-07-01</created><authors><author><keyname>Islam</keyname><forenames>Mhafuzul</forenames></author><author><keyname>Rahman</keyname><forenames>Mizanur</forenames></author><author><keyname>Chowdhury</keyname><forenames>Mashrur</forenames></author><author><keyname>Comert</keyname><forenames>Gurcan</forenames></author><author><keyname>Sood</keyname><forenames>Eshaa Deepak</forenames></author><author><keyname>Apon</keyname><forenames>Amy</forenames></author></authors><title>Vision-based Pedestrian Alert Safety System (PASS) for Signalized
  Intersections</title><categories>cs.CV eess.IV</categories><comments>23 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although Vehicle-to-Pedestrian (V2P) communication can significantly improve
pedestrian safety at a signalized intersection, this safety is hindered as
pedestrians often do not carry hand-held devices (e.g., Dedicated short-range
communication (DSRC) and 5G enabled cell phone) to communicate with connected
vehicles nearby. To overcome this limitation, in this study, traffic cameras at
a signalized intersection were used to accurately detect and locate pedestrians
via a vision-based deep learning technique to generate safety alerts in
real-time about possible conflicts between vehicles and pedestrians. The
contribution of this paper lies in the development of a system using a
vision-based deep learning model that is able to generate personal safety
messages (PSMs) in real-time (every 100 milliseconds). We develop a pedestrian
alert safety system (PASS) to generate a safety alert of an imminent
pedestrian-vehicle crash using generated PSMs to improve pedestrian safety at a
signalized intersection. Our approach estimates the location and velocity of a
pedestrian more accurately than existing DSRC-enabled pedestrian hand-held
devices. A connected vehicle application, the Pedestrian in Signalized
Crosswalk Warning (PSCW), was developed to evaluate the vision-based PASS.
Numerical analyses show that our vision-based PASS is able to satisfy the
accuracy and latency requirements of pedestrian safety applications in a
connected vehicle environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05337</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05337</id><created>2019-07-08</created><authors><author><keyname>Shafey</keyname><forenames>Laurent El</forenames></author><author><keyname>Soltau</keyname><forenames>Hagen</forenames></author><author><keyname>Shafran</keyname><forenames>Izhak</forenames></author></authors><title>Joint Speech Recognition and Speaker Diarization via Sequence
  Transduction</title><categories>cs.CL cs.SD eess.AS</categories><journal-ref>Proc. Interspeech 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech applications dealing with conversations require not only recognizing
the spoken words, but also determining who spoke when. The task of assigning
words to speakers is typically addressed by merging the outputs of two separate
systems, namely, an automatic speech recognition (ASR) system and a speaker
diarization (SD) system. The two systems are trained independently with
different objective functions. Often the SD systems operate directly on the
acoustics and are not constrained to respect word boundaries and this
deficiency is overcome in an ad hoc manner. Motivated by recent advances in
sequence to sequence learning, we propose a novel approach to tackle the two
tasks by a joint ASR and SD system using a recurrent neural network transducer.
Our approach utilizes both linguistic and acoustic cues to infer speaker roles,
as opposed to typical SD systems, which only use acoustic cues. We evaluated
the performance of our approach on a large corpus of medical conversations
between physicians and patients. Compared to a competitive conventional
baseline, our approach improves word-level diarization error rate from 15.8% to
2.2%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05351</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05351</id><created>2019-07-11</created><authors><author><keyname>Arslan</keyname><forenames>M. Tun&#xe7;</forenames></author><author><keyname>Yorulmaz</keyname><forenames>Onur</forenames></author><author><keyname>At&#x131;lgan</keyname><forenames>Erdin&#xe7; L.</forenames></author></authors><title>Optimized Sharing of Coefficients in Parallel Filter Banks</title><categories>eess.SP cs.SD eess.AS eess.IV</categories><comments>10 pages, submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Filters are the basic and most important blocks of most signal processing
applications. In many applications, a group of parallel filters are used as
filter banks. Parallel filter banks naturally require much more computations.
Especially on chip applications, the resources are limited and shared among
many algorithms. For this purpose, many filter optimization schemes are
proposed to reduce the number of resources that filtering operations require.
In this work, a novel optimization algorithm is proposed to decrease the number
of operations in a group of parallel filters. The filter coefficients are
grouped in a two stage process which enables increased coefficient sharing
between different filters. The algorithm is capable of decreasing the number of
registers, look-up tables and DSP48s by up to 50\% of a regular parallel filter
bank, without requiring increased sampling rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05358</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05358</id><created>2019-07-09</created><authors><author><keyname>Gupta</keyname><forenames>Ankit</forenames></author></authors><title>StrokeSave: A Novel, High-Performance Mobile Application for Stroke
  Diagnosis using Deep Learning and Computer Vision</title><categories>cs.CV cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to the WHO, Cerebrovascular Stroke, or CS, is the second largest
cause of death worldwide. Current diagnosis of CS relies on labor and cost
intensive neuroimaging techniques, unsuitable for areas with inadequate access
to quality medical facilities. Thus, there is a great need for an efficient
diagnosis alternative. StrokeSave is a platform for users to self-diagnose for
prevalence to stroke. The mobile app is continuously updated with heart rate,
blood pressure, and blood oxygen data from sensors on the patient wrist. Once
these measurements reach a threshold for possible stroke, the patient takes
facial images and vocal recordings to screen for paralysis attributed to
stroke. A custom designed lens attached to a phone's camera then takes retinal
images for the deep learning model to classify based on presence of retinopathy
and sends a comprehensive diagnosis. The deep learning model, which consists of
a RNN trained on 100 voice slurred audio files, a SVM trained on 410 vascular
data points, and a CNN trained on 520 retinopathy images, achieved a holistic
accuracy of 95.0 percent when validated on 327 samples. This value exceeds that
of clinical examination accuracy, which is around 40 to 89 percent, further
demonstrating the vital utility of such a medical device. Through this
automated platform, users receive efficient, highly accurate diagnosis without
professional medical assistance, revolutionizing medical diagnosis of CS and
potentially saving millions of lives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05376</identifier>
 <datestamp>2019-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05376</id><created>2019-07-11</created><updated>2019-11-05</updated><authors><author><keyname>Amelard</keyname><forenames>Robert</forenames></author><author><keyname>Murray</keyname><forenames>Kevin R</forenames></author><author><keyname>Hedge</keyname><forenames>Eric T</forenames></author><author><keyname>Cleworth</keyname><forenames>Taylor W</forenames></author><author><keyname>Noguchi</keyname><forenames>Mamiko</forenames></author><author><keyname>Laing</keyname><forenames>Andrew</forenames></author><author><keyname>Hughson</keyname><forenames>Richard L</forenames></author></authors><title>Monocular 3D Sway Tracking for Assessing Postural Instability in
  Cerebral Hypoperfusion During Quiet Standing</title><categories>eess.IV cs.CV physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Postural instability is prevalent in aging and neurodegenerative disease,
decreasing quality of life and independence. Quantitatively monitoring balance
control is important for assessing treatment efficacy and rehabilitation
progress. However, existing technologies for assessing postural sway are
complex and expensive, limiting their widespread utility. Here, we propose a
monocular imaging system capable of assessing sub-millimeter 3D sway dynamics
during quiet standing. Two anatomical targets with known feature geometries
were placed on the lumbar and shoulder. Upper and lower trunk 3D kinematic
motion was automatically assessed from a set of 2D frames through geometric
feature tracking and an inverse motion model. Sway was tracked in 3D and
compared between control and hypoperfusion conditions in 14 healthy young
adults. The proposed system demonstrated high agreement with a commercial
motion capture system (error $1.5 \times 10^{-4}~\text{mm}$, [$-0.52$,
$0.52$]). Between-condition differences in sway dynamics were observed in
anterior-posterior sway during early and mid stance, and medial-lateral sway
during mid stance commensurate with decreased cerebral perfusion, followed by
recovered sway dynamics during late stance with cerebral perfusion recovery.
This inexpensive single-camera system enables quantitative 3D sway monitoring
for assessing neuromuscular balance control in weakly constrained environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05386</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05386</id><created>2019-07-03</created><authors><author><keyname>Lavancier</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>P&#xe9;cot</keyname><forenames>Thierry</forenames></author><author><keyname>Zengzhen</keyname><forenames>Liu</forenames></author><author><keyname>Kervrann</keyname><forenames>Charles</forenames></author></authors><title>Testing independence between two random sets for the analysis of
  colocalization in bio-imaging</title><categories>stat.AP eess.IV stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colocalization aims at characterizing spatial associations between two
fluorescently-tagged biomolecules by quantifying the co-occurrence and
correlation between the two channels acquired in fluorescence microscopy.
Colocalization is presented either as the degree of overlap between the two
channels or the overlays of the red and green images, with areas of yellow
indicating colocalization of the molecules. This problem remains an open issue
in diffraction-limited microscopy and raises new challenges with the emergence
of super-resolution imaging, a microscopic technique awarded by the 2014 Nobel
prize in chemistry. We propose GcoPS, for Geo-coPositioning System, an original
method that exploits the random sets structure of the tagged molecules to
provide an explicit testing procedure. Our simulation study shows that GcoPS
unequivocally outperforms the best competitive methods in adverse situations
(noise, irregularly shaped fluorescent patterns, different optical
resolutions). GcoPS is also much faster, a decisive advantage to face the huge
amount of data in super-resolution imaging. We demonstrate the performances of
GcoPS on two biological real datasets, obtained by conventional
diffraction-limited microscopy technique and by super-resolution technique,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05395</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05395</id><created>2019-07-11</created><authors><author><keyname>Parvathaneni</keyname><forenames>Prasanna</forenames></author><author><keyname>Bao</keyname><forenames>Shunxing</forenames></author><author><keyname>Nath</keyname><forenames>Vishwesh</forenames></author><author><keyname>Woodward</keyname><forenames>Neil D.</forenames></author><author><keyname>Claassen</keyname><forenames>Daniel O.</forenames></author><author><keyname>Cascio</keyname><forenames>Carissa J.</forenames></author><author><keyname>Zald</keyname><forenames>David H.</forenames></author><author><keyname>Huo</keyname><forenames>Yuankai</forenames></author><author><keyname>Landman</keyname><forenames>Bennett A.</forenames></author><author><keyname>Lyu</keyname><forenames>Ilwoo</forenames></author></authors><title>Cortical Surface Parcellation using Spherical Convolutional Neural
  Networks</title><categories>q-bio.NC eess.IV q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present cortical surface parcellation using spherical deep convolutional
neural networks. Traditional multi-atlas cortical surface parcellation requires
inter-subject surface registration using geometric features with high
processing time on a single subject (2-3 hours). Moreover, even optimal surface
registration does not necessarily produce optimal cortical parcellation as
parcel boundaries are not fully matched to the geometric features. In this
context, a choice of training features is important for accurate cortical
parcellation. To utilize the networks efficiently, we propose cortical
parcellation-specific input data from an irregular and complicated structure of
cortical surfaces. To this end, we align ground-truth cortical parcel
boundaries and use their resulting deformation fields to generate new pairs of
deformed geometric features and parcellation maps. To extend the capability of
the networks, we then smoothly morph cortical geometric features and
parcellation maps using the intermediate deformation fields. We validate our
method on 427 adult brains for 49 labels. The experimental results show that
our method out-performs traditional multi-atlas and naive spherical U-Net
approaches, while achieving full cortical parcellation in less than a minute.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05408</identifier>
 <datestamp>2019-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05408</id><created>2019-07-11</created><authors><author><keyname>Arafa</keyname><forenames>Ahmed</forenames></author><author><keyname>Yates</keyname><forenames>Roy D.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Timely Cloud Computing: Preemption and Waiting</title><categories>cs.IT cs.NI eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of timely status updating is investigated in the context of cloud
computing. Measurements of a time-varying process of interest are acquired by a
sensor node, and uploaded to a cloud server to undergo some required
computations. These computations consume random amounts of service time that
are independent and identically distributed across different uploads. After the
computations are done, the results are delivered to a monitor, constituting an
update. The goal is to keep the monitor continuously fed with fresh updates
over time, which is assessed by an age-of-information (AoI) metric. A scheduler
is employed to optimize the measurement acquisition times. Following an update,
an idle waiting period may be imposed by the scheduler before acquiring a new
measurement. The scheduler also has the capability to preempt a measurement in
progress if its service time grows above a certain cutoff time, and upload a
fresher measurement in its place. Focusing on stationary deterministic
policies, in which waiting times are deterministic functions of the
instantaneous AoI and the cutoff time is fixed for all uploads, it is shown
that the optimal waiting policy that minimizes the long term average AoI has a
threshold structure, in which a new measurement is uploaded following an update
only if the AoI grows above a certain threshold that is a function of the
service time distribution and the cutoff time. The optimal cutoff is then found
for standard and shifted exponential service times. While it has been
previously reported that waiting before updating can be beneficial for AoI, it
is shown in this work that preemption of late updates can be even more
beneficial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05464</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05464</id><created>2019-07-11</created><authors><author><keyname>Jamshidnejad</keyname><forenames>Anahita</forenames></author><author><keyname>Gomes</keyname><forenames>Gabriel</forenames></author><author><keyname>Bayen</keyname><forenames>Alexandre M.</forenames></author><author><keyname>De Schutter</keyname><forenames>Bart</forenames></author></authors><title>Integrated Offline and Online Optimization-Based Control in a
  Base-Parallel Architecture</title><categories>eess.SY cs.SY</categories><msc-class>49-XX</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an integrated control architecture to address the gap that
currently exists for efficient real-time implementation of MPC-based control
approaches for highly nonlinear systems with fast dynamics and a large number
of control constraints. The proposed architecture contains two types of
controllers: base controllers that are tuned or optimized offline, and parallel
controllers that solve an optimization-based control problem online. The
control inputs computed by the base controllers provide starting points for the
optimization problem of the parallel controllers, which operate in parallel
within a limited time budget that does not exceed the control sampling time.
The resulting control system is very flexible and its architecture can easily
be modified or changed online, e.g., by adding or eliminating controllers, for
online improvement of the performance of the controlled system. In a case
study, the proposed control architecture is implemented for highway traffic,
which is characterized by nonlinear, fast dynamics with multiple control
constraints, to minimize the overall travel time of the vehicles, while
increasing their total traveled distance within the fixed simulation time
window. The results of the simulation show the excellent real-time (i.e.,
within the given time budget) performance of the proposed control architecture,
with the least realized value of the overall cost function. Moreover, among the
online control approaches considered for the case study, the average cost per
vehicle for the base-parallel control approach is the closest to the online
MPC-based controllers, which have excellent performance but may involve
computation times that exceed the given time budget.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05514</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05514</id><created>2019-07-11</created><authors><author><keyname>Muqeet</keyname><forenames>Abdul</forenames></author><author><keyname>Iqbal</keyname><forenames>Md Tauhid Bin</forenames></author><author><keyname>Bae</keyname><forenames>Sung-Ho</forenames></author></authors><title>Hybrid Residual Attention Network for Single Image Super Resolution</title><categories>cs.CV cs.LG eess.IV</categories><comments>12 pages, 5 figures</comments><doi>10.1109/ACCESS.2019.2942346</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The extraction and proper utilization of convolution neural network (CNN)
features have a significant impact on the performance of image super-resolution
(SR). Although CNN features contain both the spatial and channel information,
current deep techniques on SR often suffer to maximize performance due to using
either the spatial or channel information. Moreover, they integrate such
information within a deep or wide network rather than exploiting all the
available features, eventually resulting in high computational complexity. To
address these issues, we present a binarized feature fusion (BFF) structure
that utilizes the extracted features from residual groups (RG) in an effective
way. Each residual group (RG) consists of multiple hybrid residual attention
blocks (HRAB) that effectively integrates the multiscale feature extraction
module and channel attention mechanism in a single block. Furthermore, we use
dilated convolutions with different dilation factors to extract multiscale
features. We also propose to adopt global, short and long skip connections and
residual groups (RG) structure to ease the flow of information without losing
important features details. In the paper, we call this overall network
architecture as hybrid residual attention network (HRAN). In the experiment, we
have observed the efficacy of our method against the state-of-the-art methods
for both the quantitative and qualitative comparisons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05530</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05530</id><created>2019-07-11</created><authors><author><keyname>Li</keyname><forenames>Ang</forenames></author><author><keyname>Spano</keyname><forenames>Danilo</forenames></author><author><keyname>Krivochiza</keyname><forenames>Jevgenij</forenames></author><author><keyname>Domouchtsidis</keyname><forenames>Stavros</forenames></author><author><keyname>Tsinos</keyname><forenames>Christos G.</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author><author><keyname>Ottersten</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>Interference Exploitation via Symbol-Level Precoding: Overview,
  State-of-the-Art and Future Directions</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference is traditionally viewed as a performance limiting factor in
wireless communication systems, which is to be minimized or mitigated.
Nevertheless, a recent line of work has shown that by manipulating the
interfering signals such that they add up constructively at the receiver side,
known interference can be made beneficial and further improve the system
performance in a variety of wireless scenarios, achieved by symbol-level
precoding (SLP). This paper aims to provide a tutorial on interference
exploitation techniques from the perspective of precoding design in a
multi-antenna wireless communication system, by beginning with the
classification of constructive interference (CI) and destructive interference
(DI). The definition for CI is presented and the corresponding mathematical
characterization is formulated for popular modulation types, based on which
optimization-based precoding techniques are discussed. In addition, the
extension of CI precoding to other application scenarios as well as for
hardware efficiency is also described. Proof-of-concept testbeds are
demonstrated for the potential practical implementation of CI precoding, and
finally a list of open problems and practical challenges are presented to
inspire and motivate further research directions in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05532</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05532</id><created>2019-07-11</created><authors><author><keyname>Smith</keyname><forenames>Kevin D.</forenames></author><author><keyname>Jafarpour</keyname><forenames>Saber</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Transient Stability of Droop-Controlled Inverter Networks with Operating
  Constraints</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the rise of distributed energy resources, the control of networks of
grid-forming inverters is now a pressing issue for power system operation.
Droop control is a popular control strategy in the literature for frequency
control of these inverters. In this paper, we analyze transient stability in
droop-controlled inverter networks that are subject to multiple operating
constraints. Using two physically-meaningful Lyapunov-like functions, we
provide two sets of criteria (one mathematical and one computational) to
certify that a post-fault trajectory achieves frequency synchronization while
respecting operating constraints. We demonstrate two applications of these
results on a modified IEEE RTS 24 test case: estimating the scale of
disturbances with respect to which the system is robust, and screening for
contingencies that threaten transient stability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05571</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05571</id><created>2019-07-12</created><authors><author><keyname>Hou</keyname><forenames>Tianwei</forenames></author><author><keyname>Liu</keyname><forenames>Yuanwei</forenames></author><author><keyname>Song</keyname><forenames>Zhengyu</forenames></author><author><keyname>Sun</keyname><forenames>Xin</forenames></author><author><keyname>Chen</keyname><forenames>Yue</forenames></author></authors><title>Non-Orthogonal Multiple Access in UAV-to-Everything (U2X) Networks</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article investigates the non-orthogonal multiple access (NOMA) enhanced
unmanned aerial vehicle (UAV)-to-Everything (U2X) frameworks. A novel
3-Dimension framework for providing wireless services to randomly roaming NOMA
receivers (Rxs) in the sphere space is proposed by utilizing stochastic
geometry tools. In an effort to evaluate the performance of the proposed
framework, we first derive closed-form expressions for the outage probability
and the ergodic rate of paired NOMA Rxs. For obtaining more insights, we
investigate the diversity order and the high signal-to-noise (SNR) slope of
NOMA enhanced U2X frameworks. We also derive the spectrum efficiency in both
NOMA and orthogonal multiple access (OMA) enhanced U2X frameworks. Our
analytical results demonstrate that the diversity order and the high SNR slope
of the proposed framework are $m$ and one, respectively. Numerical results are
provided to confirm that: i) the proposed NOMA enhanced U2X frameworks have
superior outage performance and spectrum efficiency compared with the
OMA-enhanced U2X frameworks; and ii) for the case of fixed LoS probability, the
outage performance of paired NOMA Rxs mainly depends on users with poor channel
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05572</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05572</id><created>2019-07-12</created><authors><author><keyname>Wang</keyname><forenames>Zhiwei</forenames></author><author><keyname>Ma</keyname><forenames>Yao</forenames></author><author><keyname>Liu</keyname><forenames>Zitao</forenames></author><author><keyname>Tang</keyname><forenames>Jiliang</forenames></author></authors><title>R-Transformer: Recurrent Neural Network Enhanced Transformer</title><categories>cs.LG cs.CL cs.CV eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent Neural Networks have long been the dominating choice for sequence
modeling. However, it severely suffers from two issues: impotent in capturing
very long-term dependencies and unable to parallelize the sequential
computation procedure. Therefore, many non-recurrent sequence models that are
built on convolution and attention operations have been proposed recently.
Notably, models with multi-head attention such as Transformer have demonstrated
extreme effectiveness in capturing long-term dependencies in a variety of
sequence modeling tasks. Despite their success, however, these models lack
necessary components to model local structures in sequences and heavily rely on
position embeddings that have limited effects and require a considerable amount
of design efforts. In this paper, we propose the R-Transformer which enjoys the
advantages of both RNNs and the multi-head attention mechanism while avoids
their respective drawbacks. The proposed model can effectively capture both
local structures and global long-term dependencies in sequences without any use
of position embeddings. We evaluate R-Transformer through extensive experiments
with data from a wide range of domains and the empirical results show that
R-Transformer outperforms the state-of-the-art methods by a large margin in
most of the tasks. We have made the code publicly available at
\url{https://github.com/DSE-MSU/R-transformer}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05584</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05584</id><created>2019-07-12</created><authors><author><keyname>Dubey</keyname><forenames>Harishchandra</forenames></author><author><keyname>Sangwan</keyname><forenames>Abhijeet</forenames></author><author><keyname>Hansen</keyname><forenames>John</forenames></author></authors><title>Toeplitz Inverse Covariance based Robust Speaker Clustering for
  Naturalistic Audio Streams</title><categories>cs.SD cs.LG eess.AS</categories><comments>6 Pages, 3 Fiigures, 5 Equations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speaker diarization determines who spoke and when? in an audio stream. In
this study, we propose a model-based approach for robust speaker clustering
using i-vectors. The ivectors extracted from different segments of same speaker
are correlated. We model this correlation with a Markov Random Field (MRF)
network. Leveraging the advancements in MRF modeling, we used Toeplitz Inverse
Covariance (TIC) matrix to represent the MRF correlation network for each
speaker. This approaches captures the sequential structure of i-vectors (or
equivalent speaker turns) belonging to same speaker in an audio stream. A
variant of standard Expectation Maximization (EM) algorithm is adopted for
deriving closed-form solution using dynamic programming (DP) and the
alternating direction method of multiplier (ADMM). Our diarization system has
four steps: (1) ground-truth segmentation; (2) i-vector extraction; (3)
post-processing (mean subtraction, principal component analysis, and
length-normalization) ; and (4) proposed speaker clustering. We employ cosine
K-means and movMF speaker clustering as baseline approaches. Our evaluation
data is derived from: (i) CRSS-PLTL corpus, and (ii) two meetings subset of the
AMI corpus. Relative reduction in diarization error rate (DER) for CRSS-PLTL
corpus is 43.22% using the proposed advancements as compared to baseline. For
AMI meetings IS1000a and IS1003b, relative DER reduction is 29.37% and 9.21%,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05594</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05594</id><created>2019-07-12</created><authors><author><keyname>Chiu</keyname><forenames>Wei-Yu</forenames></author><author><keyname>Hsieh</keyname><forenames>Jui-Ting</forenames></author><author><keyname>Chen</keyname><forenames>Chia-Ming</forenames></author></authors><title>Pareto Optimal Demand Response Based on Energy Costs and Load Factor in
  Smart Grid</title><categories>eess.SY cs.SY eess.SP</categories><doi>10.1109/TII.2019.2928520</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Demand response for residential users is essential to the realization of
modern smart grids. This paper proposes a multiobjective approach to designing
a demand response program that considers the energy costs of residential users
and the load factor of the underlying grid. A multiobjective optimization
problem (MOP) is formulated and Pareto optimality is adopted. Stochastic search
methods of generating feasible values for decision variables are proposed.
Theoretical analysis is performed to show that the proposed methods can
effectively generate and preserve feasible points during the solution process,
which comparable methods can hardly achieve. A multiobjective evolutionary
algorithm is developed to solve the MOP, producing a Pareto optimal demand
response (PODR) program. Simulations reveal that the proposed method
outperforms the comparable methods in terms of energy costs while producing a
satisfying load factor. The proposed PODR program is able to systematically
balance the needs of the grid and residential users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05595</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05595</id><created>2019-07-12</created><authors><author><keyname>Ding</keyname><forenames>Xueyan</forenames></author><author><keyname>Wang</keyname><forenames>Yafei</forenames></author><author><keyname>Yan</keyname><forenames>Yang</forenames></author><author><keyname>Liang</keyname><forenames>Zheng</forenames></author><author><keyname>Mi</keyname><forenames>Zetian</forenames></author><author><keyname>Fu</keyname><forenames>Xianping</forenames></author></authors><title>Jointly Adversarial Network to Wavelength Compensation and Dehazing of
  Underwater Images</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Severe color casts, low contrast and blurriness of underwater images caused
by light absorption and scattering result in a difficult task for exploring
underwater environments. Different from most of previous underwater image
enhancement methods that compute light attenuation along object-camera path
through hazy image formation model, we propose a novel jointly wavelength
compensation and dehazing network (JWCDN) that takes into account the
wavelength attenuation along surface-object path and the scattering along
object-camera path simultaneously. By embedding a simplified underwater
formation model into generative adversarial network, we can jointly estimates
the transmission map, wavelength attenuation and background light via different
network modules, and uses the simplified underwater image formation model to
recover degraded underwater images. Especially, a multi-scale densely connected
encoder-decoder network is proposed to leverage features from multiple layers
for estimating the transmission map. To further improve the recovered image, we
use an edge preserving network module to enhance the detail of the recovered
image. Moreover, to train the proposed network, we propose a novel underwater
image synthesis method that generates underwater images with inherent optical
properties of different water types. The synthesis method can simulate the
color, contrast and blurriness appearance of real-world underwater environments
simultaneously. Extensive experiments on synthetic and real-world underwater
images demonstrate that the proposed method yields comparable or better results
on both subjective and objective assessments, compared with several
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05598</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05598</id><created>2019-07-12</created><authors><author><keyname>Feng</keyname><forenames>Chun-Mei</forenames></author><author><keyname>Wang</keyname><forenames>Kai</forenames></author><author><keyname>Lu</keyname><forenames>Shijian</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Kong</keyname><forenames>Heng</forenames></author><author><keyname>Shao</keyname><forenames>Ling</forenames></author></authors><title>Coupled-Projection Residual Network for MRI Super-Resolution</title><categories>eess.IV cs.CV</categories><comments>Our source code will be publicly available at
  http://www.yongxu.org/lunwen.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic Resonance Imaging(MRI) has been widely used in clinical application
and pathology research by helping doctors make more accurate diagnoses. On the
other hand, accurate diagnosis by MRI remains a great challenge as images
obtained via present MRI techniques usually have low resolutions. Improving MRI
image quality and resolution thus becomes a critically important task. This
paper presents an innovative Coupled-Projection Residual Network (CPRN) for MRI
super-resolution. The CPRN consists of two complementary sub-networks: a
shallow network and a deep network that keep the content consistency while
learning high frequency differences between low-resolution and high-resolution
images. The shallow sub-network employs coupled-projection for better retaining
the MRI image details, where a novel feedback mechanism is introduced to guide
the reconstruction of high-resolution images. The deep sub-network learns from
the residuals of the high-frequency image information, where multiple residual
blocks are cascaded to magnify the MRI images at the last network layer.
Finally, the features from the shallow and deep sub-networks are fused for the
reconstruction of high-resolution MRI images. For effective fusion of features
from the deep and shallow sub-networks, a step-wise connection (CPRN S) is
designed as inspired by the human cognitive processes (from simple to complex).
Experiments over three public MRI datasets show that our proposed CPRN achieves
superior MRI super-resolution performance as compared with the
state-of-the-art. Our source code will be publicly available at
http://www.yongxu.org/lunwen.html.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05599</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05599</id><created>2019-07-12</created><authors><author><keyname>Zhao</keyname><forenames>Tianyu</forenames></author><author><keyname>Kawahara</keyname><forenames>Tatsuya</forenames></author></authors><title>Effective Incorporation of Speaker Information in Utterance Encoding in
  Dialog</title><categories>eess.AS cs.CL cs.LG cs.SD</categories><comments>8+1 pages, 3 figures, and 5 tables. Rejected by SIGDIAL 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In dialog studies, we often encode a dialog using a hierarchical encoder
where each utterance is converted into an utterance vector, and then a sequence
of utterance vectors is converted into a dialog vector. Since knowing who
produced which utterance is essential to understanding a dialog, conventional
methods tried integrating speaker labels into utterance vectors. We found the
method problematic in some cases where speaker annotations are inconsistent
among different dialogs. A relative speaker modeling method is proposed to
address the problem. Experimental evaluations on dialog act recognition and
response generation show that the proposed method yields superior and more
consistent performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05606</identifier>
 <datestamp>2019-12-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05606</id><created>2019-07-12</created><updated>2019-12-24</updated><authors><author><keyname>Song</keyname><forenames>Peiyang</forenames></author><author><keyname>Gong</keyname><forenames>Fengkui</forenames></author><author><keyname>Li</keyname><forenames>Qiang</forenames></author></authors><title>Deep Learning based Blind Symbol Packing Ratio Estimation for
  Faster-than-Nyquist Signaling</title><categories>eess.SP</categories><comments>Accepted by Electronics Letters</comments><journal-ref>Electronics Letters 55.21 (2019): 1155-1157</journal-ref><doi>10.1049/el.2019.2379</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter proposes a blind symbol packing rartio estimation for
faster-than-Nyquist (FTN) signaling based on state-of-the-art deep learning
(DL) technology. The symbol packing rartio is a vital parameter to obtain the
real symbol rate and recover the origin symbols from the received symbols by
calculating the intersymbol interference (ISI). To the best of our knowledge,
this is the first effective estimation approach for symbol packing rartio in
FTN signaling and has shown its fast convergence and robustness to
signal-to-noise ratio (SNR) by numerical simulations. Benefiting from the
proposed blind estimation, the packing-ratio-based adaptive FTN transmission
without dedicate channel or control frame becomes available. Also, the secure
FTN communications based on secret symbol packing rartio can be easily cracked.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05636</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05636</id><created>2019-07-12</created><updated>2019-07-25</updated><authors><author><keyname>Burgess</keyname><forenames>Mark</forenames></author></authors><title>From Observability to Significance in Distributed Information Systems</title><categories>cs.MA cs.AI cs.DC cs.SY eess.SY</categories><comments>Some typos fixed</comments><acm-class>I.2.8; I.2.11; C.2.3; C.2.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To understand and explain process behaviour we need to be able to see it, and
decide its significance, i.e. be able to tell a story about its behaviours.
This paper describes a few of the modelling challenges that underlie monitoring
and observation of processes in IT, by human or by software. The topic of the
observability of systems has been elevated recently in connection with computer
monitoring and tracing of processes for debugging and forensics. It raises the
issue of well-known principles of measurement, in bounded contexts, but these
issues have been left implicit in the Computer Science literature. This paper
aims to remedy this omission, by laying out a simple promise theoretic model,
summarizing a long standing trail of work on the observation of distributed
systems, based on elementary distinguishability of observations, and classical
causality, with history. Three distinct views of a system are sought, across a
number of scales, that described how information is transmitted (and lost) as
it moves around the system, aggregated into journals and logs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05657</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05657</id><created>2019-07-12</created><authors><author><keyname>Salman</keyname><forenames>H.</forenames></author><author><keyname>Balatiah</keyname><forenames>R.</forenames></author><author><keyname>Masri</keyname><forenames>A.</forenames></author><author><keyname>Dama</keyname><forenames>Y. A. S.</forenames></author></authors><title>Energy Aware Wireless System based Software Defined Radio</title><categories>eess.SP</categories><comments>5 Pages, 6 Figures, 4 Tables, 2019 IEEE 89th Vehicular Technology
  Conference (VTC2019-Spring)</comments><doi>10.1109/VTCSpring.2019.8746664</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Development of green telecommunication systems is already being considered
highly attractive by standard bodies and recently is attracting research
attention. While most of the research focuses on modeling and simulation, in
this work we implement a lab setup to test an energy aware wireless system
based on software defined radio and solar energy power system. In addition, we
proposed an energy aware adaptive modulation algorithm that considers the state
of charge of the solar energy batteries before setting up the modulation order.
Moreover, the algorithm adapts to user preferences between the connectivity
mode and the quality mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05671</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05671</id><created>2019-07-12</created><authors><author><keyname>Spinks</keyname><forenames>Graham</forenames></author><author><keyname>Moens</keyname><forenames>Marie-Francine</forenames></author></authors><title>Justifying Diagnosis Decisions by Deep Neural Networks</title><categories>cs.LG cs.CL cs.HC eess.IV stat.ML</categories><doi>10.1016/j.jbi.2019.103248</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An integrated approach is proposed across visual and textual data to both
determine and justify a medical diagnosis by a neural network. As deep learning
techniques improve, interest grows to apply them in medical applications. To
enable a transition to workflows in a medical context that are aided by machine
learning, the need exists for such algorithms to help justify the obtained
outcome so human clinicians can judge their validity. In this work, deep
learning methods are used to map a frontal X-Ray image to a continuous textual
representation. This textual representation is decoded into a diagnosis and the
associated textual justification that will help a clinician evaluate the
outcome. Additionally, more explanatory data is provided for the diagnosis by
generating a realistic X-Ray that belongs to the nearest alternative diagnosis.
With a clinical expert opinion study on a subset of the X-Ray data set from the
Indiana University hospital network, we demonstrate that our justification
mechanism significantly outperforms existing methods that use saliency maps.
While performing multi-task training with multiple loss functions, our method
achieves excellent diagnosis accuracy and captioning quality when compared to
current state-of-the-art single-task methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05673</identifier>
 <datestamp>2019-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05673</id><created>2019-07-12</created><updated>2019-12-03</updated><authors><author><keyname>Adam</keyname><forenames>Karen</forenames></author><author><keyname>Scholefield</keyname><forenames>Adam</forenames></author><author><keyname>Vetterli</keyname><forenames>Martin</forenames></author></authors><title>Sampling and Reconstruction of Bandlimited Signals with Multi-Channel
  Time Encoding</title><categories>eess.SP</categories><comments>16 pages, 11 figures. Submitted to Transactions of Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampling is classically performed by recording the amplitude of an input
signal at given time instants; however, sampling and reconstructing a signal
using multiple devices in parallel becomes a more difficult problem to solve
when the devices have an unknown shift in their clocks.
  Alternatively, one can record the times at which a signal (or its integral)
crosses given thresholds. This can model integrate-and-fire neurons, for
example, and has been studied by Lazar and T\'oth under the name of ``Time
Encoding Machines''. This sampling method is closer to what is found in nature.
  In this paper, we show that, when using time encoding machines,
reconstruction from multiple channels has a more intuitive solution, and does
not require the knowledge of the shifts between machines. We show that, if
single-channel time encoding can sample and perfectly reconstruct a
$\mathbf{2\Omega}$-bandlimited signal, then $\mathbf{M}$-channel time encoding
with shifted integrators can sample and perfectly reconstruct a signal with
$\mathbf{M}$ times the bandwidth.
  Furthermore, we present an algorithm to perform this reconstruction and prove
that it converges to the correct unique solution, in the noiseless case,
without knowledge of the relative shifts between the integrators of the
machines. This is quite unlike classical multi-channel sampling, where unknown
shifts between sampling devices pose a problem for perfect reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05674</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05674</id><created>2019-07-12</created><authors><author><keyname>Yay&#x131;k</keyname><forenames>Apdullah</forenames></author><author><keyname>Kutlu</keyname><forenames>Yakup</forenames></author><author><keyname>Altan</keyname><forenames>G&#xf6;khan</forenames></author></authors><title>Deep Learning with ConvNET Predicts Imagery Tasks Through EEG</title><categories>eess.SP cs.HC cs.LG</categories><comments>5 pages, 2 figures, springer</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Deep learning with convolutional neural networks (ConvNets) have dramatically
improved learning capabilities of computer vision applications just through
considering raw data without any prior feature extraction. Nowadays, there is
rising curiosity in interpreting and analyzing electroencephalography (EEG)
dynamics with ConvNets. Our study focused on ConvNets of different structures,
constructed for predicting imagined left and right movements on a
subject-independent basis through raw EEG data. Results showed that recently
advanced methods in machine learning field, i.e. adaptive moments and batch
normalization together with dropout strategy, improved ConvNets predicting
ability, outperforming that of conventional fully-connected neural networks
with widely-used spectral features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05692</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05692</id><created>2019-07-12</created><authors><author><keyname>Khan</keyname><forenames>M. Sibgath Ali</forenames></author><author><keyname>Amuru</keyname><forenames>Sai Dhiraj</forenames></author><author><keyname>Kuchi</keyname><forenames>Kiran</forenames></author></authors><title>Low PAPR Reference Signal Transceiver Design for 3GPP 5G NR Uplink</title><categories>eess.SP cs.IT math.IT</categories><comments>12 pages , Journal Paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low peak-to-average-power ratio (PAPR) transmissions significantly improve
the cell coverage as they enable high power transmissions without saturating
the power amplifier. A new modulation scheme, namely, pi/2-BPSK was introduced
in the Rel-15 3GPP 5G NR specifications to support low PAPR transmissions using
the DFT-spread-OFDM waveform in the uplink transmissions. To enable data
demodulation using this modulation scheme, Zadoff-Chu sequences are used as
reference signals. However, the PAPR of Zadoff-Chu sequences is higher when
compared to the pi/2-BPSK data. Therefore, even though the data transmissions
have low PAPR, the high PAPR of the reference signal limits the cell coverage
in the uplink of Rel-15 3GPP 5G NR design. In this paper we propose a
transceiver design which minimizes the PAPR of the reference signals to avoid
the aforementioned issues. We show via simulations that the proposed
architecture results in more than 2 dB PAPR reduction when compared to the
existing design. In addition, when multiple stream transmission is supported,
we show that PAPR of the reference signal transmission remains the same for any
stream (also referred to as baseband antenna port in 3GPP terminology) when the
proposed transceiver design is employed, which is not the case for the current
3GPP 5G NR design
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05695</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05695</id><created>2019-07-02</created><authors><author><keyname>Tang</keyname><forenames>Wen-Jun</forenames></author><author><keyname>Lee</keyname><forenames>Xian-Long</forenames></author><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Yang</keyname><forenames>Hong-Tzer</forenames></author></authors><title>Leveraging Socioeconomic Information and Deep Learning for Residential
  Load Pattern Prediction</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advanced metering infrastructure systems record a high volume of residential
load data, opening up an opportunity for utilities to understand consumer
energy consumption behaviors. Existing studies have focused on load profiling
and prediction, but neglected the role of socioeconomic characteristics of
consumers in their energy consumption behaviors. In this paper, we develop a
prediction model using deep neural networks to predict load patterns of
consumers based on their socioeconomic information. We analyze load patterns
using the K-means clustering method and use an entropy-based feature selection
method to select the key socioeconomic characteristics that affect consumers'
load patterns. Our prediction method with feature selection achieves a higher
prediction accuracy compared with the benchmark schemes, e.g. 80% reduction in
the prediction error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05698</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05698</id><created>2019-07-09</created><authors><author><keyname>You</keyname><forenames>Zhao</forenames></author><author><keyname>Su</keyname><forenames>Dan</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>Teach an all-rounder with experts in different domains</title><categories>eess.AS cs.CL cs.SD</categories><comments>5 pages and 2 figures; accepted by 2019 IEEE International Conference
  on Acoustics, Speech and Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many automatic speech recognition (ASR) tasks, an ideal model has to be
applicable over multiple domains. In this paper, we propose to teach an
all-rounder with experts in different domains. Concretely, we build a
multi-domain acoustic model by applying the teacher-student training framework.
First, for each domain, a teacher model (domain-dependent model) is trained by
fine-tuning a multi-condition model with domain-specific subset. Then all these
teacher models are used to teach one single student model simultaneously. We
perform experiments on two predefined domain setups. One is domains with
different speaking styles, the other is nearfield, far-field and far-field with
noise. Moreover, two types of models are examined: deep feedforward sequential
memory network (DFSMN) and long short term memory (LSTM). Experimental results
show that the model trained with this framework outperforms not only
multi-condition model but also domain-dependent model. Specially, our training
method provides up to 10.4% relative character error rate improvement over
baseline model (multi-condition model).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05700</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05700</id><created>2019-07-10</created><updated>2019-10-20</updated><authors><author><keyname>He</keyname><forenames>Zichang</forenames></author><author><keyname>Cui</keyname><forenames>Weilong</forenames></author><author><keyname>Cui</keyname><forenames>Chunfeng</forenames></author><author><keyname>Sherwood</keyname><forenames>Timothy</forenames></author><author><keyname>Zhang</keyname><forenames>Zheng</forenames></author></authors><title>Efficient Uncertainty Modeling for System Design via Mixed Integer
  Programming</title><categories>eess.SP cs.AR cs.NA math.NA</categories><comments>International Conf. Computer Aided Design (ICCAD), 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The post-Moore era casts a shadow of uncertainty on many aspects of computer
system design. Managing that uncertainty requires new algorithmic tools to make
quantitative assessments. While prior uncertainty quantification methods, such
as generalized polynomial chaos (gPC), show how to work precisely under the
uncertainty inherent to physical devices, these approaches focus solely on
variables from a continuous domain. However, as one moves up the system stack
to the architecture level many parameters are constrained to a discrete
(integer) domain. This paper proposes an efficient and accurate uncertainty
modeling technique, named mixed generalized polynomial chaos (M-gPC), for
architectural uncertainty analysis. The M-gPC technique extends the generalized
polynomial chaos (gPC) theory originally developed in the uncertainty
quantification community, such that it can efficiently handle the mixed-type
(i.e., both continuous and discrete) uncertainties in computer architecture
design. Specifically, we employ some stochastic basis functions to capture the
architecture-level impact caused by uncertain parameters in a simulator. We
also develop a novel mixed-integer programming method to select a small number
of uncertain parameter samples for detailed simulations. With a few highly
informative simulation samples, an accurate surrogate model is constructed in
place of cycle-level simulators for various architectural uncertainty analysis.
In the chip-multiprocessor (CMP) model, we are able to estimate the propagated
uncertainties with only 95 samples whereas Monte Carlo requires 5*10^4 samples
to achieve the similar accuracy. We also demonstrate the efficiency and
effectiveness of our method on a detailed DRAM subsystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05701</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05701</id><created>2019-07-10</created><authors><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Cui</keyname><forenames>Xiaodong</forenames></author><author><keyname>Finkler</keyname><forenames>Ulrich</forenames></author><author><keyname>Saon</keyname><forenames>George</forenames></author><author><keyname>Kayi</keyname><forenames>Abdullah</forenames></author><author><keyname>Buyuktosunoglu</keyname><forenames>Alper</forenames></author><author><keyname>Kingsbury</keyname><forenames>Brian</forenames></author><author><keyname>Kung</keyname><forenames>David</forenames></author><author><keyname>Picheny</keyname><forenames>Michael</forenames></author></authors><title>A Highly Efficient Distributed Deep Learning System For Automatic Speech
  Recognition</title><categories>eess.AS cs.DC cs.LG cs.SD stat.ML</categories><journal-ref>INTERSPEECH 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern Automatic Speech Recognition (ASR) systems rely on distributed deep
learning to for quick training completion. To enable efficient distributed
training, it is imperative that the training algorithms can converge with a
large mini-batch size. In this work, we discovered that Asynchronous
Decentralized Parallel Stochastic Gradient Descent (ADPSGD) can work with much
larger batch size than commonly used Synchronous SGD (SSGD) algorithm. On
commonly used public SWB-300 and SWB-2000 ASR datasets, ADPSGD can converge
with a batch size 3X as large as the one used in SSGD, thus enable training at
a much larger scale. Further, we proposed a Hierarchical-ADPSGD (H-ADPSGD)
system in which learners on the same computing node construct a super learner
via a fast allreduce implementation, and super learners deploy ADPSGD algorithm
among themselves. On a 64 Nvidia V100 GPU cluster connected via a 100Gb/s
Ethernet network, our system is able to train SWB-2000 to reach a 7.6% WER on
the Hub5-2000 Switchboard (SWB) test-set and a 13.2% WER on the Call-home (CH)
test-set in 5.2 hours. To the best of our knowledge, this is the fastest ASR
training system that attains this level of model accuracy for SWB-2000 task to
be ever reported in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05702</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05702</id><created>2019-07-12</created><authors><author><keyname>Routray</keyname><forenames>Sudhir K.</forenames></author><author><keyname>Sarangi</keyname><forenames>Susanta K.</forenames></author><author><keyname>Javali</keyname><forenames>Abhishek</forenames></author></authors><title>Smart Cities: The Hopes and Hypes</title><categories>eess.SP cs.CY</categories><comments>Conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart cities are being planned for several advanced applications and services
for the inhabitants. Smart cities initiative promise many new services which
are not possible in the traditional city frameworks. In the smart city
framework, the basic aim is to provide all the essential services through
sensor based systems which does not need much human intervention. This system
is designed to operate on its own in a self-organizing manner. Therefore, the
hopes are really big from the smart cities to enhance the quality of lives and
the economy. However, some of the promises in the smart cities are very much
over hyped. In this article, we analyse the realities of the smart cities and
their practical significances based on the technological aspects of these
projects. We also address the false promises that are around which are just the
hypes. We clarify these hypes with appropriate logical explanations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05708</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05708</id><created>2019-07-11</created><authors><author><keyname>Perna</keyname><forenames>Diego</forenames></author><author><keyname>Tagarelli</keyname><forenames>Andrea</forenames></author></authors><title>Deep auscultation: Predicting respiratory anomalies and diseases via
  recurrent neural networks</title><categories>eess.AS cs.LG cs.SD eess.SP</categories><comments>Paper accepted for publication with Procs. of the 32th IEEE CBMS
  International Symposium on Computer-Based Medical Systems (CBMS 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Respiratory diseases are among the most common causes of severe illness and
death worldwide. Prevention and early diagnosis are essential to limit or even
reverse the trend that characterizes the diffusion of such diseases. In this
regard, the development of advanced computational tools for the analysis of
respiratory auscultation sounds can become a game changer for detecting
disease-related anomalies, or diseases themselves. In this work, we propose a
novel learning framework for respiratory auscultation sound data. Our approach
combines state-of-the-art feature extraction techniques and advanced
deep-neural-network architectures. Remarkably, to the best of our knowledge, we
are the first to model a recurrent-neural-network based learning framework to
support the clinician in detecting respiratory diseases, at either level of
abnormal sounds or pathology classes. Results obtained on the ICBHI benchmark
dataset show that our approach outperforms competing methods on both
anomaly-driven and pathology-driven prediction tasks, thus advancing the
state-of-the-art in respiratory disease analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05709</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05709</id><created>2019-07-11</created><authors><author><keyname>Kath</keyname><forenames>Niclas</forenames></author><author><keyname>Handels</keyname><forenames>Heinz</forenames></author><author><keyname>Mastmeyer</keyname><forenames>Andre</forenames></author></authors><title>Robust GPU-based Virtual Reality Simulation of Radio Frequency Ablations
  for Various Needle Geometries and Locations</title><categories>physics.med-ph cs.CV eess.IV</categories><comments>18 pages, 14 figures, 1 table, 2 algorithms, 2 movies</comments><journal-ref>International Journal of Computer Assisted Radiology and Surgery,
  2019</journal-ref><doi>10.1007/s11548-019-02033-w</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: Radio-frequency ablations play an important role in the therapy of
malignant liver lesions. The navigation of a needle to the lesion poses a
challenge for both the trainees and intervening physicians. Methods: This
publication presents a new GPU-based, accurate method for the simulation of
radio-frequency ablations for lesions at the needle tip in general and for an
existing visuo-haptic 4D VR simulator. The method is implemented real-time
capable with Nvidia CUDA. Results: It performs better than a literature method
concerning the theoretical characteristic of monotonic convergence of the
bioheat PDE and a in vitro gold standard with significant improvements (p &lt;
0.05) in terms of Pearson correlations. It shows no failure modes or
theoretically inconsistent individual simulation results after the initial
phase of 10 seconds. On the Nvidia 1080 Ti GPU it achieves a very high frame
rendering performance of &gt;480 Hz. Conclusion: Our method provides a more robust
and safer real-time ablation planning and intraoperative guidance technique,
especially avoiding the over-estimation of the ablated tissue death zone, which
is risky for the patient in terms of tumor recurrence. Future in vitro
measurements and optimization shall further improve the conservative estimate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05711</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05711</id><created>2019-07-12</created><authors><author><keyname>Riaza</keyname><forenames>Ricardo</forenames></author></authors><title>Associate submersions and qualitative properties of nonlinear circuits
  with implicit characteristics</title><categories>eess.SY cs.SY</categories><msc-class>94C05, 94C15, 37G10, 53A04</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce in this paper an equivalence notion for submersions $U \to \R$,
$U$ open in $\R^2$, which makes it possible to identify a smooth planar curve
with a unique class of submersions. This idea, which extends to the nonlinear
setting the construction of a dual projective space, provides a systematic way
to handle global implicit descriptions of smooth planar curves. We then apply
this framework to model nonlinear electrical devices as {\em classes of
equivalent functions}. In this setting, linearization naturally accommodates
incremental resistances (and other analogous notions) in homogeneous terms.
This approach, combined with a projectively-weighted version of the matrix-tree
theorem, makes it possible to formulate and address in great generality several
problems in nonlinear circuit theory. In particular, we tackle unique
solvability problems in resistive circuits, and discuss a general expression
for the characteristic polynomial of dynamic circuits at equilibria. Previously
known results, which were derived in the literature under unnecessarily
restrictive working assumptions, are simply obtained here by using
dehomogenization. Our results are shown to apply also to circuits with
memristors. We finally present a detailed, graph-theoretic study of certain
stationary bifurcations in nonlinear circuits using the formalism here
introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05720</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05720</id><created>2019-07-11</created><authors><author><keyname>Allison</keyname><forenames>Sam</forenames></author><author><keyname>Bai</keyname><forenames>He</forenames></author><author><keyname>Jayaraman</keyname><forenames>Balaji</forenames></author></authors><title>Wind Estimation Using Quadcopter Motion: A Machine Learning Approach</title><categories>eess.SP cs.LG cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we study the well known problem of wind estimation in
atmospheric turbulence using small unmanned aerial systems (sUAS). We present a
machine learning approach to wind velocity estimation based on quadcopter state
measurements without a wind sensor. We accomplish this by training a long
short-term memory (LSTM) neural network (NN) on roll and pitch angles and
quadcopter position inputs with forcing wind velocities as the targets. The
datasets are generated using a simulated quadcopter in turbulent wind fields.
The trained neural network is deployed to estimate the turbulent winds as
generated by the Dryden gust model as well as a realistic large eddy simulation
(LES) of a near-neutral atmospheric boundary layer (ABL) over flat terrain. The
resulting NN predictions are compared to a wind triangle approach that uses
tilt angle as an approximation of airspeed. Results from this study indicate
that the LSTM-NN based approach predicts lower errors in both the mean and
variance of the local wind field as compared to the wind triangle approach. The
work reported in this article demonstrates the potential of machine learning
for sensor-less wind estimation and has strong implications to large-scale
low-altitude atmospheric sensing using sUAS for environmental and autonomous
navigation applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05738</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05738</id><created>2019-07-12</created><authors><author><keyname>Hecker</keyname><forenames>Simon</forenames></author><author><keyname>Liniger</keyname><forenames>Alexander</forenames></author><author><keyname>Maurenbrecher</keyname><forenames>Henrik</forenames></author><author><keyname>Dai</keyname><forenames>Dengxin</forenames></author><author><keyname>Van Gool</keyname><forenames>Luc</forenames></author></authors><title>Learning a Curve Guardian for Motorcycles</title><categories>cs.CV cs.RO cs.SY eess.SY</categories><comments>8 pages, to be presented at IEEE-ITSC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Up to 17% of all motorcycle accidents occur when the rider is maneuvering
through a curve and the main cause of curve accidents can be attributed to
inappropriate speed and wrong intra-lane position of the motorcycle. Existing
curve warning systems lack crucial state estimation components and do not scale
well. We propose a new type of road curvature warning system for motorcycles,
combining the latest advances in computer vision, optimal control and mapping
technologies to alleviate these shortcomings. Our contributes are fourfold: 1)
we predict the motorcycle's intra-lane position using a convolutional neural
network (CNN), 2) we predict the motorcycle roll angle using a CNN, 3) we use
an upgraded controller model that incorporates road incline for a more
realistic model and prediction, 4) we design a scale-able system by utilizing
HERE Technologies map database to obtain the accurate road geometry of the
future path. In addition, we present two datasets that are used for training
and evaluating of our system respectively, both datasets will be made publicly
available. We test our system on a diverse set of real world scenarios and
present a detailed case-study. We show that our system is able to predict more
accurate and safer curve trajectories, and consequently warn and improve the
safety for motorcyclists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05753</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05753</id><created>2019-07-12</created><authors><author><keyname>Jameel</keyname><forenames>Furqan</forenames></author><author><keyname>Khan</keyname><forenames>Wali Ullah</forenames></author><author><keyname>Chang</keyname><forenames>Zheng</forenames></author><author><keyname>Ristaniemi</keyname><forenames>Tapani</forenames></author><author><keyname>Liu</keyname><forenames>Ju</forenames></author></authors><title>Secrecy Analysis and Learning-based Optimization of Cooperative NOMA
  SWIPT Systems</title><categories>eess.SP cs.NI</categories><comments>6 Pages, Decode-and-forward (DF), Deep learning, Non-orthogonal
  multiple access (NOMA), Power-splitting</comments><journal-ref>Conference: IEEE International Conference on Communications (ICC)
  2019</journal-ref><doi>10.1109/ICCW.2019.8756894</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-orthogonal multiple access (NOMA) is considered to be one of the best
candidates for future networks due to its ability to serve multiple users using
the same resource block. Although early studies have focused on transmission
reliability and energy efficiency, recent works are considering cooperation
among the nodes. The cooperative NOMA techniques allow the user with a better
channel (near user) to act as a relay between the source and the user
experiencing poor channel (far user). This paper considers the link security
aspect of energy harvesting cooperative NOMA users. In particular, the near
user applies the decode-and-forward (DF) protocol for relaying the message of
the source node to the far user in the presence of an eavesdropper. Moreover,
we consider that all the devices use power-splitting architecture for energy
harvesting and information decoding. We derive the analytical expression of
intercept probability. Next, we employ deep learning based optimization to find
the optimal power allocation factor. The results show the robustness and
superiority of deep learning optimization over conventional iterative search
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05813</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05813</id><created>2019-07-12</created><updated>2019-07-15</updated><authors><author><keyname>Bouritsas</keyname><forenames>Giorgos</forenames></author><author><keyname>Daveas</keyname><forenames>Stelios</forenames></author><author><keyname>Danelakis</keyname><forenames>Antonios</forenames></author><author><keyname>Rizogiannis</keyname><forenames>Constantinos</forenames></author><author><keyname>Thomopoulos</keyname><forenames>Stelios C. A.</forenames></author></authors><title>Automated Real-time Anomaly Detection in Human Trajectories using
  Sequence to Sequence Networks</title><categories>cs.LG cs.CV eess.IV</categories><comments>AVSS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection of anomalous trajectories is an important problem with potential
applications to various domains, such as video surveillance, risk assessment,
vessel monitoring and high-energy physics. Modeling the distribution of
trajectories with statistical approaches has been a challenging task due to the
fact that such time series are usually non stationary and highly dimensional.
However, modern machine learning techniques provide robust approaches for
data-driven modeling and critical information extraction. In this paper, we
propose a Sequence to Sequence architecture for real-time detection of
anomalies in human trajectories, in the context of risk-based security. Our
detection scheme is tested on a synthetic dataset of diverse and realistic
trajectories generated by the ISL iCrowd simulator. The experimental results
indicate that our scheme accurately detects motion patterns that deviate from
normal behaviors and is promising for future real-world applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05851</identifier>
 <datestamp>2019-07-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05851</id><created>2019-07-10</created><authors><author><keyname>Guri</keyname><forenames>Mordechai</forenames></author><author><keyname>Zadov</keyname><forenames>Boris</forenames></author><author><keyname>Bykhovsky</keyname><forenames>Dima</forenames></author><author><keyname>Elovici</keyname><forenames>Yuval</forenames></author></authors><title>CTRL-ALT-LED: Leaking Data from Air-Gapped Computers via Keyboard LEDs</title><categories>cs.CR eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1706.01140</comments><journal-ref>2019 IEEE 43rd Annual Computer Software and Applications
  Conference (COMPSAC)</journal-ref><doi>10.1109/COMPSAC.2019.00118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the keyboard LEDs to send data optically was proposed in 2002 by
Loughry and Umphress [1] (Appendix A). In this paper we extensively explore
this threat in the context of a modern cyber-attack with current hardware and
optical equipment. In this type of attack, an advanced persistent threat (APT)
uses the keyboard LEDs (Caps-Lock, Num-Lock and Scroll-Lock) to encode
information and exfiltrate data from airgapped computers optically. Notably,
this exfiltration channel is not monitored by existing data leakage prevention
(DLP) systems. We examine this attack and its boundaries for today's keyboards
with USB controllers and sensitive optical sensors. We also introduce
smartphone and smartwatch cameras as components of malicious insider and 'evil
maid' attacks. We provide the necessary scientific background on optical
communication and the characteristics of modern USB keyboards at the hardware
and software level, and present a transmission protocol and modulation schemes.
We implement the exfiltration malware, discuss its design and implementation
issues, and evaluate it with different types of keyboards. We also test various
receivers, including light sensors, remote cameras, 'extreme' cameras, security
cameras, and smartphone cameras. Our experiment shows that data can be leaked
from air-gapped computers via the keyboard LEDs at a maximum bit rate of 3000
bit/sec per LED given a light sensor as a receiver, and more than 120 bit/sec
if smartphones are used. The attack doesn't require any modification of the
keyboard at hardware or firmware levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05888</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05888</id><created>2019-07-12</created><authors><author><keyname>Yay&#x131;k</keyname><forenames>Apdullah</forenames></author><author><keyname>Kutlu</keyname><forenames>Yakup</forenames></author><author><keyname>Altan</keyname><forenames>G&#xf6;khan</forenames></author></authors><title>Regularized HessELM and Inclined Entropy Measurement for Congestive
  Heart Failure Prediction</title><categories>cs.LG cs.HC cs.NA eess.SP math.NA physics.med-ph</categories><comments>9 pages, 3 figures, neuroprocessing letter</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Our study concerns with automated predicting of congestive heart failure
(CHF) through the analysis of electrocardiography (ECG) signals. A novel
machine learning approach, regularized hessenberg decomposition based extreme
learning machine (R-HessELM), and feature models; squared, circled, inclined
and grid entropy measurement were introduced and used for prediction of CHF.
This study proved that inclined entropy measurements features well represent
characteristics of ECG signals and together with R-HessELM approach overall
accuracy of 98.49% was achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05905</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05905</id><created>2019-07-12</created><authors><author><keyname>Harar</keyname><forenames>Pavol</forenames></author><author><keyname>Alonso-Hernandez</keyname><forenames>Jesus B.</forenames></author><author><keyname>Mekyska</keyname><forenames>Jiri</forenames></author><author><keyname>Galaz</keyname><forenames>Zoltan</forenames></author><author><keyname>Burget</keyname><forenames>Radim</forenames></author><author><keyname>Smekal</keyname><forenames>Zdenek</forenames></author></authors><title>Voice Pathology Detection Using Deep Learning: a Preliminary Study</title><categories>eess.AS cs.LG cs.SD</categories><comments>4 pages, 1 figure, 5 tables</comments><journal-ref>In 2017 international conference and workshop on bioinspired
  intelligence (IWOBI), pp. 1-4. IEEE, 2017</journal-ref><doi>10.1109/IWOBI.2017.7985525</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a preliminary investigation of Voice Pathology Detection
using Deep Neural Networks (DNN). We used voice recordings of sustained vowel
/a/ produced at normal pitch from German corpus Saarbruecken Voice Database
(SVD). This corpus contains voice recordings and electroglottograph signals of
more than 2 000 speakers. The idea behind this experiment is the use of
convolutional layers in combination with recurrent Long-Short-Term-Memory
(LSTM) layers on raw audio signal. Each recording was split into 64 ms Hamming
windowed segments with 30 ms overlap. Our trained model achieved 71.36%
accuracy with 65.04% sensitivity and 77.67% specificity on 206 validation files
and 68.08% accuracy with 66.75% sensitivity and 77.89% specificity on 874
testing files. This is a promising result in favor of this approach because it
is comparable to similar previously published experiment that used different
methodology. Further investigation is needed to achieve the state-of-the-art
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05919</identifier>
 <datestamp>2019-10-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05919</id><created>2019-07-12</created><updated>2019-10-10</updated><authors><author><keyname>Wentzel</keyname><forenames>A.</forenames></author><author><keyname>Hanula</keyname><forenames>P.</forenames></author><author><keyname>Luciani</keyname><forenames>T.</forenames></author><author><keyname>Elgohari</keyname><forenames>B.</forenames></author><author><keyname>Elhalawani</keyname><forenames>H.</forenames></author><author><keyname>Canahuate</keyname><forenames>G.</forenames></author><author><keyname>Vock</keyname><forenames>D.</forenames></author><author><keyname>Fuller</keyname><forenames>C. D.</forenames></author><author><keyname>Marai</keyname><forenames>G. E.</forenames></author></authors><title>Cohort-based T-SSIM Visual Computing for Radiation Therapy Prediction
  and Exploration</title><categories>physics.med-ph eess.IV</categories><comments>IEEE VIS (SciVis) 2019</comments><acm-class>J.7</acm-class><doi>10.1109/TVCG.2019.2934546</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a visual computing approach to radiation therapy (RT) planning,
based on spatial similarity within a patient cohort. In radiotherapy for head
and neck cancer treatment, dosage to organs at risk surrounding a tumor is a
large cause of treatment toxicity. Along with the availability of patient
repositories, this situation has lead to clinician interest in understanding
and predicting RT outcomes based on previously treated similar patients. To
enable this type of analysis, we introduce a novel topology-based spatial
similarity measure, T-SSIM, and a predictive algorithm based on this similarity
measure. We couple the algorithm with a visual steering interface that
intertwines visual encodings for the spatial data and statistical results,
including a novel parallel-marker encoding that is spatially aware. We report
quantitative results on a cohort of 165 patients, as well as a qualitative
evaluation with domain experts in radiation oncology, data management,
biostatistics, and medical imaging, who are collaborating remotely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05955</identifier>
 <datestamp>2019-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05955</id><created>2019-07-12</created><updated>2019-10-23</updated><authors><author><keyname>Lu</keyname><forenames>Liang</forenames></author><author><keyname>Xiao</keyname><forenames>Xiong</forenames></author><author><keyname>Chen</keyname><forenames>Zhuo</forenames></author><author><keyname>Gong</keyname><forenames>Yifan</forenames></author></authors><title>PyKaldi2: Yet another speech toolkit based on Kaldi and PyTorch</title><categories>cs.CL eess.AS</categories><comments>5 pages, 2 figures, submitted to ICASSP 2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce PyKaldi2 speech recognition toolkit implemented based on Kaldi
and PyTorch. While similar toolkits are available built on top of the two, a
key feature of PyKaldi2 is sequence training with criteria such as MMI, sMBR
and MPE. In particular, we implemented the sequence training module with
on-the-fly lattice generation during model training in order to simplify the
training pipeline. To address the challenging acoustic environments in real
applications, PyKaldi2 also supports on-the-fly noise and reverberation
simulation to improve the model robustness. With this feature, it is possible
to backpropogate the gradients from the sequence-level loss to the front-end
feature extraction module, which, hopefully, can foster more research in the
direction of joint front-end and backend learning. We performed benchmark
experiments on Librispeech, and show that PyKaldi2 can achieve reasonable
recognition accuracy. The toolkit is released under the MIT license.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05982</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05982</id><created>2019-07-12</created><authors><author><keyname>Lattner</keyname><forenames>Stefan</forenames></author><author><keyname>D&#xf6;rfler</keyname><forenames>Monika</forenames></author><author><keyname>Arzt</keyname><forenames>Andreas</forenames></author></authors><title>Learning Complex Basis Functions for Invariant Representations of Audio</title><categories>cs.SD cs.CV cs.LG eess.AS</categories><comments>Paper accepted at the 20th International Society for Music
  Information Retrieval Conference, ISMIR 2019, Delft, The Netherlands,
  November 4-8; 8 pages, 4 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning features from data has shown to be more successful than using
hand-crafted features for many machine learning tasks. In music information
retrieval (MIR), features learned from windowed spectrograms are highly variant
to transformations like transposition or time-shift. Such variances are
undesirable when they are irrelevant for the respective MIR task. We propose an
architecture called Complex Autoencoder (CAE) which learns features invariant
to orthogonal transformations. Mapping signals onto complex basis functions
learned by the CAE results in a transformation-invariant &quot;magnitude space&quot; and
a transformation-variant &quot;phase space&quot;. The phase space is useful to infer
transformations between data pairs. When exploiting the invariance-property of
the magnitude space, we achieve state-of-the-art results in audio-to-score
alignment and repeated section discovery for audio. A PyTorch implementation of
the CAE, including the repeated section discovery method, is available online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05988</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.05988</id><created>2019-07-12</created><authors><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author><author><keyname>Vermehren</keyname><forenames>V. V.</forenames></author></authors><title>ND-Wavelets Derived from Anti-symmetric Systems of Isolated Particles
  using the Determinant of Slater</title><categories>eess.IV cs.NA math-ph math.MP math.NA</categories><comments>4 pages, no figures</comments><msc-class>42C40</msc-class><acm-class>I.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wavelets are known to be closely related to atomic orbital. A new approach of
2D, 3D and multidimensional wavelet system is proposed from a paralell with
anti-symmetric systems of several isolated particles. The theory of fermionic
states is used to generate new \textit{n}-dimensions wavelets, $n\ge2$, by the
determinant of Slater. As pioneering paper in exchanging formalism between
particle wave-functions and wavelets, it opens some perspectives for further
adaptations derived from the physics of particles in the wavelet analysis
scope.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06002</identifier>
 <datestamp>2020-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06002</id><created>2019-07-12</created><updated>2020-02-25</updated><authors><author><keyname>Abeywickrama</keyname><forenames>Samith</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author></authors><title>Intelligent Reflecting Surface: Practical Phase Shift Model and
  Beamforming Optimization</title><categories>eess.SP cs.IT math.IT</categories><comments>To appear at IEEE International Conference on Communications (ICC)
  2020. A more comprehensive version of this work has been submitted for
  possible journal publication (Online Available: arXiv:2002.10112)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent reflecting surface (IRS) that enables the control of the wireless
propagation environment has been looked upon as a promising technology for
boosting the spectrum and energy efficiency in future wireless communication
systems. Prior works on IRS are mainly based on the ideal phase shift model
assuming the full signal reflection by each of the elements regardless of its
phase shift, which, however, is practically difficult to realize. In contrast,
we propose in this paper a practical phase shift model that captures the
phase-dependent amplitude variation in the element-wise reflection coefficient.
Applying this new model to an IRS-aided wireless system, we formulate a problem
to maximize its achievable rate by jointly optimizing the transmit beamforming
and the IRS reflect beamforming. The formulated problem is non-convex and
difficult to be optimally solved in general, for which we propose a
low-complexity suboptimal solution based on the alternating optimization (AO)
technique. Simulation results unveil a substantial performance gain achieved by
the joint beamforming optimization based on the proposed phase shift model as
compared to the conventional ideal model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06005</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06005</id><created>2019-07-12</created><authors><author><keyname>Gu</keyname><forenames>Yu</forenames></author><author><keyname>Zhang</keyname><forenames>Xiang</forenames></author><author><keyname>Liu</keyname><forenames>Zhi</forenames></author><author><keyname>Ren</keyname><forenames>Fuji</forenames></author></authors><title>BeSense: Leveraging WiFi Channel Data and Computational Intelligence for
  Behavior</title><categories>cs.HC eess.SP</categories><comments>21 pages accepted by IEEE Computational Intelligence Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ever evolving informatics technology has gradually bounded human and
computer in a compact way. Understanding user behavior becomes a key enabler in
many fields such as sedentary-related healthcare, human-computer interaction
(HCI) and affective computing. Traditional sensor-based and vision-based user
behavior analysis approaches are obtrusive in general, hindering their usage in
realworld. Therefore, in this article, we first introduce WiFi signal as a new
source instead of sensor and vision for unobtrusive user behaviors analysis.
Then we design BeSense, a contactless behavior analysis system leveraging
signal processing and computational intelligence over WiFi channel state
information (CSI). We prototype BeSense on commodity low-cost WiFi devices and
evaluate its performance in realworld environments. Experimental results have
verified its effectiveness in recognizing user behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06014</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06014</id><created>2019-07-13</created><updated>2019-10-22</updated><authors><author><keyname>Mei</keyname><forenames>Qipei</forenames></author><author><keyname>G&#xfc;l</keyname><forenames>Mustafa</forenames></author></authors><title>A Cost Effective Solution for Road Crack Inspection using Cameras and
  Deep Neural Networks</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic crack detection on pavement surfaces is an important research field
in the scope of developing an intelligent transportation infrastructure system.
In this paper, a cost effective solution for road crack inspection by mounting
commercial grade sport camera, GoPro, on the rear of the moving vehicle is
introduced. Also, a novel method called ConnCrack combining conditional
Wasserstein generative adversarial network and connectivity maps is proposed
for road crack detection. In this method, a 121-layer densely connected neural
network with deconvolution layers for multi-level feature fusion is used as
generator, and a 5-layer fully convolutional network is used as discriminator.
To overcome the scattered output issue related to deconvolution layers,
connectivity maps are introduced to represent the crack information within the
proposed ConnCrack. The proposed method is tested on a publicly available
dataset as well our collected data. The results show that the proposed method
achieves state-of-the-art performance compared with other existing methods in
terms of precision, recall and F1 score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06017</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06017</id><created>2019-07-13</created><authors><author><keyname>Bai</keyname><forenames>Ye</forenames></author><author><keyname>Yi</keyname><forenames>Jiangyan</forenames></author><author><keyname>Tao</keyname><forenames>Jianhua</forenames></author><author><keyname>Tian</keyname><forenames>Zhengkun</forenames></author><author><keyname>Wen</keyname><forenames>Zhengqi</forenames></author></authors><title>Learn Spelling from Teachers: Transferring Knowledge from Language
  Models to Sequence-to-Sequence Speech Recognition</title><categories>eess.AS cs.CL</categories><comments>5 pages, 3 figures, accepted by INTERSPEECH 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integrating an external language model into a sequence-to-sequence speech
recognition system is non-trivial. Previous works utilize linear interpolation
or a fusion network to integrate external language models. However, these
approaches introduce external components, and increase decoding computation. In
this paper, we instead propose a knowledge distillation based training approach
to integrating external language models into a sequence-to-sequence model. A
recurrent neural network language model, which is trained on large scale
external text, generates soft labels to guide the sequence-to-sequence model
training. Thus, the language model plays the role of the teacher. This approach
does not add any external component to the sequence-to-sequence model during
testing. And this approach is flexible to be combined with shallow fusion
technique together for decoding. The experiments are conducted on public
Chinese datasets AISHELL-1 and CLMAD. Our approach achieves a character error
rate of 9.3%, which is relatively reduced by 18.42% compared with the vanilla
sequence-to-sequence model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06022</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06022</id><created>2019-07-13</created><authors><author><keyname>Wei</keyname><forenames>Yantao</forenames></author><author><keyname>Yu</keyname><forenames>Shujian</forenames></author><author><keyname>Principe</keyname><forenames>Jose C.</forenames></author></authors><title>Multiscale Principle of Relevant Information for Hyperspectral Image
  Classification</title><categories>cs.LG eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel architecture, termed multiscale principle of
relevant information (MPRI), to learn discriminative spectral-spatial features
for hyperspectral image (HSI) classification. MPRI inherits the merits of the
principle of relevant information (PRI) to effectively extract multiscale
information embedded in the given data, and also takes advantage of the
multilayer structure to learn representations in a coarse-to-fine manner.
Specifically, MPRI performs spectral-spatial pixel characterization (using PRI)
and feature dimensionality reduction (using regularized linear discriminant
analysis) iteratively and successively. Extensive experiments on four benchmark
data sets demonstrate that MPRI outperforms existing state-of-the-art HSI
classification methods (including deep learning based ones) qualitatively and
quantitatively, especially in the scenario of limited training samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06029</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06029</id><created>2019-07-13</created><authors><author><keyname>Smaldone</keyname><forenames>Filippo M.</forenames></author><author><keyname>Scianca</keyname><forenames>Nicola</forenames></author><author><keyname>Modugno</keyname><forenames>Valerio</forenames></author><author><keyname>Lanari</keyname><forenames>Leonardo</forenames></author><author><keyname>Oriolo</keyname><forenames>Giuseppe</forenames></author></authors><title>Gait Generation using Intrinsically Stable MPC in the Presence of
  Persistent Disturbances</title><categories>eess.SY cs.SY</categories><comments>7 pages, 10 figures, submitted to 2019 IEEE-RAS International
  Conference on Humanoid Robots</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maintaining balance while walking is not a simple task for a humanoid robot
because of its complex dynamics. The presence of a persistent disturbance makes
this task even more challenging, as it can cause a loss of balance and
ultimately lead the the robot to a fall. In this paper, we extend our
previously proposed Intrinsically Stable MPC (IS-MPC), which guarantees
boundedness of the CoM with respect to the ZMP, to the case of persistent
disturbances. This is achieved by designing a disturbance observer whose
estimate is used to compute a modified stability constraint included in the QP
problem formulation. The method is validated by MATLAB simulations for the LIP
as well as dynamic simulations for a NAO humanoid in DART.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06064</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06064</id><created>2019-07-13</created><authors><author><keyname>Gafuroglu</keyname><forenames>Can</forenames></author><author><keyname>Rekik</keyname><forenames>Islem</forenames></author></authors><title>Image Evolution Trajectory Prediction and Classification from Baseline
  using Learning-based Patch Atlas Selection for Early Diagnosis</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Patients initially diagnosed with early mild cognitive impairment (eMCI) are
known to be a clinically heterogeneous group with very subtle patterns of brain
atrophy. To examine the boarders between normal controls (NC) and eMCI,
Magnetic Resonance Imaging (MRI) was extensively used as a non-invasive imaging
modality to pin-down subtle changes in brain images of MCI patients. However,
eMCI research remains limited by the number of available MRI acquisition
timepoints. Ideally, one would learn how to diagnose MCI patients in an early
stage from MRI data acquired at a single timepoint, while leveraging
'non-existing' follow-up observations. To this aim, we propose novel supervised
and unsupervised frameworks that learn how to jointly predict and label the
evolution trajectory of intensity patches, each seeded at a specific brain
landmark, from a baseline intensity patch. Specifically, both strategies aim to
identify the best training atlas patches at baseline timepoint to predict and
classify the evolution trajectory of a given testing baseline patch. The
supervised technique learns how to select the best atlas patches by training
bidirectional mappings from the space of pairwise patch similarities to their
corresponding prediction errors -when one patch was used to predict the other.
On the other hand, the unsupervised technique learns a manifold of baseline
atlas and testing patches using multiple kernels to well capture patch
distributions at multiple scales. Once the best baseline atlas patches are
selected, we retrieve their evolution trajectories and average them to predict
the evolution trajectory of the testing baseline patch. Next, we input the
predicted trajectories to an ensemble of linear classifiers, each trained at a
specific landmark. Our classification accuracy increased by up to 10% points in
comparison to single timepoint-based classification methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06066</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06066</id><created>2019-07-13</created><authors><author><keyname>S&#xe4;rkk&#xe4;</keyname><forenames>Simo</forenames></author></authors><title>The Use of Gaussian Processes in System Identification</title><categories>stat.ML cs.LG cs.SY eess.SY</categories><comments>To appear in Encyclopedia of systems and control, 2nd edition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian processes are used in machine learning to learn input-output
mappings from observed data. Gaussian process regression is based on imposing a
Gaussian process prior on the unknown regressor function and statistically
conditioning it on the observed data. In system identification, Gaussian
processes are used to form time series prediction models such as non-linear
finite-impulse response (NFIR) models as well as non-linear autoregressive
(NARX) models. Gaussian process state-space models (GPSS) can be used to learn
the dynamic and measurement models for a state-space representation of the
input-output data. Temporal and spatio-temporal Gaussian processes can be
directly used to form regressor on the data in the time domain. The aim of this
article is to briefly outline the main directions in system identification
methods using Gaussian processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06071</identifier>
 <datestamp>2019-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06071</id><created>2019-07-13</created><updated>2019-08-29</updated><authors><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Chen</keyname><forenames>Weihai</forenames></author><author><keyname>Hu</keyname><forenames>Chao</forenames></author><author><keyname>Wu</keyname><forenames>Xingming</forenames></author><author><keyname>Li</keyname><forenames>Zhengguo</forenames></author></authors><title>S&amp;CNet: Monocular Depth Completion for Autonomous Systems and 3D
  Reconstruction</title><categories>eess.IV cs.CV</categories><comments>10 pages,8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dense depth completion is essential for autonomous systems and 3D
reconstruction. In this paper, a lightweight yet efficient network (S\&amp;CNet) is
proposed to obtain a good trade-off between efficiency and accuracy for the
dense depth completion. A dual-stream attention module (S\&amp;C enhancer) is
introduced to measure both spatial-wise and the channel-wise global-range
relationship of extracted features so as to improve the performance. A
coarse-to-fine network is designed and the proposed S\&amp;C enhancer is plugged
into the coarse estimation network between its encoder and decoder network.
Experimental results demonstrate that our approach achieves competitive
performance with existing works on KITTI dataset but almost four times faster.
The proposed S\&amp;C enhancer can be plugged into other existing works and boost
their performance significantly with a negligible additional computational
cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06078</identifier>
 <datestamp>2019-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06078</id><created>2019-07-13</created><updated>2019-11-20</updated><authors><author><keyname>Latif</keyname><forenames>Siddique</forenames></author><author><keyname>Rana</keyname><forenames>Rajib</forenames></author><author><keyname>Khalifa</keyname><forenames>Sara</forenames></author><author><keyname>Jurdak</keyname><forenames>Raja</forenames></author><author><keyname>Epps</keyname><forenames>Julien</forenames></author><author><keyname>Schuller</keyname><forenames>Bj&#xf6;rn W.</forenames></author></authors><title>Multi-Task Semi-Supervised Adversarial Autoencoding for Speech Emotion</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the widespread use of supervised deep learning methods for affect
recognition from speech, they are severely limited by the lack of a sufficient
amount of labelled speech data. Considering the abundant availability of
unlabelled data, this paper proposed a semi-supervised model that can
effectively utilise the unlabelled data in multi-task learning way in order to
improve the performance of speech emotion recognition. The proposed model
adversarialy learns a shared representation for two auxiliary tasks along with
emotion identification as the main task. We consider speaker and gender
identification as auxiliary tasks in order to operate the model on any large
audio corpus. We demonstrate that in a scenario with limited labelled training
samples, one can significantly improve the performance of a supervised
classification task by simultaneously training with additional auxiliary tasks
having an availability of large amount of data. The proposed model is
rigorously evaluated for both categorical and dimensional emotion
classification tasks. Experimental results demonstrate that the proposed model
achieves state-of-the-art performance on two publicly available datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06081</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06081</id><created>2019-07-13</created><updated>2019-07-16</updated><authors><author><keyname>An</keyname><forenames>Yi</forenames></author><author><keyname>Hou</keyname><forenames>Tianyue</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author><author><keyname>Huang</keyname><forenames>Liangjin</forenames></author><author><keyname>Leng</keyname><forenames>Jinyong</forenames></author><author><keyname>Yang</keyname><forenames>Lijia</forenames></author><author><keyname>Zhou</keyname><forenames>Pu</forenames></author></authors><title>Preliminary study on the modal decomposition of Hermite Gaussian beams
  via deep learning</title><categories>physics.optics eess.IV</categories><comments>6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hermite-Gaussian (HG) modes make up a complete and orthonormal basis,
which have been extensively used to describe optical fields. Here, we
demonstrate, for the first time to our knowledge, deep learning-based modal
decomposition (MD) of HG beams. This method offers a fast, economical and
robust way to acquire both the power content and phase information through a
single-shot beam intensity image, which will be beneficial for the beam
shaping, beam quality assessment, studies of resonator perturbations, and other
further research on the HG beams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06083</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06083</id><created>2019-07-13</created><updated>2019-07-19</updated><authors><author><keyname>Latif</keyname><forenames>Siddique</forenames></author><author><keyname>Qadir</keyname><forenames>Junaid</forenames></author><author><keyname>Bilal</keyname><forenames>Muhammad</forenames></author></authors><title>Unsupervised Adversarial Domain Adaptation for Cross-Lingual Speech
  Emotion Recognition</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cross-lingual speech emotion recognition (SER) is a crucial task for many
real-world applications. The performance of SER systems is often degraded by
the differences in the distributions of training and test data. These
differences become more apparent when training and test data belong to
different languages, which cause a significant performance gap between the
validation and test scores. It is imperative to build more robust models that
can fit in practical applications of SER systems. Therefore, in this paper, we
propose a Generative Adversarial Network (GAN)-based model for multilingual
SER. Our choice of using GAN is motivated by their great success in learning
the underlying data distribution. The proposed model is designed in such a way
that can learn language invariant representations without requiring
target-language data labels. We evaluate our proposed model on four different
language emotional datasets, including an Urdu-language dataset to also
incorporate alternative languages for which labelled data is difficult to find
and which have not been studied much by the mainstream community. Our results
show that our proposed model can significantly improve the baseline
cross-lingual SER performance for all the considered datasets including the
non-mainstream Urdu language data without requiring any labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06087</identifier>
 <datestamp>2019-11-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06087</id><created>2019-07-13</created><updated>2019-11-08</updated><authors><author><keyname>Frey</keyname><forenames>Felix</forenames></author><author><keyname>Fischer</keyname><forenames>Johannes K.</forenames></author><author><keyname>Fischer</keyname><forenames>Robert F. H.</forenames></author></authors><title>On Discrete-Time/Frequency-Periodic End-to-End Fiber-Optical Channel
  Models</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A discrete-time end-to-end fiber-optical channel model is derived based on
the first-order perturbation approach. The model relates the discrete-time
input symbol sequences of co-propagating wavelength channels to the received
symbol sequence after matched filtering and T-spaced sampling. To that end, the
interference from both self- and cross-channel nonlinear interactions of the
continuous-time optical signal is represented by a single discrete-time
perturbative term. Two equivalent models can be formulated---one in the
discrete-time domain, the other in the 1/T-periodic continuous-frequency
domain. The time-domain formulation coincides with the pulse-collision picture
and its correspondence to the frequency-domain description is derived. The
latter gives rise to a novel perspective on the end-to-end input/output
relation of optical transmission systems. Both views can be extended from a
regular, i.e., solely additive model, to a combined regular-logarithmic model
to take the multiplicative nature of certain degenerate distortions into
consideration. We provide an alternative formulation of the Gaussian Noise
model and derive a novel algorithm with potential application in fiber
nonlinearity compensation. The derived end-to-end model requires only a single
computational step and shows good agreement in the mean-squared error sense
compared to the oversampled and inherently sequential split-step Fourier
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06098</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06098</id><created>2019-07-13</created><authors><author><keyname>Gaudet</keyname><forenames>Brian</forenames></author><author><keyname>Linares</keyname><forenames>Richard</forenames></author><author><keyname>Furfaro</keyname><forenames>Roberto</forenames></author></authors><title>Seeker based Adaptive Guidance via Reinforcement Meta-Learning Applied
  to Asteroid Close Proximity Operations</title><categories>eess.SY astro-ph.IM cs.LG cs.SY</categories><comments>Accepted for 2020 AAS Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current practice for asteroid close proximity maneuvers requires extremely
accurate characterization of the environmental dynamics and precise spacecraft
positioning prior to the maneuver. This creates a delay of several months
between the spacecraft's arrival and the ability to safely complete close
proximity maneuvers. In this work we develop an adaptive integrated guidance,
navigation, and control system that can complete these maneuvers in
environments with unknown dynamics, with initial conditions spanning a large
deployment region, and without a shape model of the asteroid. The system is
implemented as a policy optimized using reinforcement meta-learning. The
spacecraft is equipped with an optical seeker that locks to either a terrain
feature, back-scattered light from a targeting laser, or an active beacon, and
the policy maps observations consisting of seeker angles and LIDAR range
readings directly to engine thrust commands. The policy implements a recurrent
network layer that allows the deployed policy to adapt real time to both
environmental forces acting on the agent and internal disturbances such as
actuator failure and center of mass variation. We validate the guidance system
through simulated landing maneuvers in a six degrees-of-freedom simulator. The
simulator randomizes the asteroid's characteristics such as solar radiation
pressure, density, spin rate, and nutation angle, requiring the guidance and
control system to adapt to the environment. We also demonstrate robustness to
actuator failure, sensor bias, and changes in the spacecraft's center of mass
and inertia tensor. Finally, we suggest a concept of operations for asteroid
close proximity maneuvers that is compatible with the guidance system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06099</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06099</id><created>2019-07-13</created><authors><author><keyname>Jin</keyname><forenames>Yueming</forenames></author><author><keyname>Li</keyname><forenames>Huaxia</forenames></author><author><keyname>Dou</keyname><forenames>Qi</forenames></author><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Qin</keyname><forenames>Jing</forenames></author><author><keyname>Fu</keyname><forenames>Chi-Wing</forenames></author><author><keyname>Heng</keyname><forenames>Pheng-Ann</forenames></author></authors><title>Multi-Task Recurrent Convolutional Network with Correlation Loss for
  Surgical Video Analysis</title><categories>cs.CV cs.LG eess.IV</categories><comments>Minor Revision at Medical Image Analysis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Surgical tool presence detection and surgical phase recognition are two
fundamental yet challenging tasks in surgical video analysis and also very
essential components in various applications in modern operating rooms. While
these two analysis tasks are highly correlated in clinical practice as the
surgical process is well-defined, most previous methods tackled them
separately, without making full use of their relatedness. In this paper, we
present a novel method by developing a multi-task recurrent convolutional
network with correlation loss (MTRCNet-CL) to exploit their relatedness to
simultaneously boost the performance of both tasks. Specifically, our proposed
MTRCNet-CL model has an end-to-end architecture with two branches, which share
earlier feature encoders to extract general visual features while holding
respective higher layers targeting for specific tasks. Given that temporal
information is crucial for phase recognition, long-short term memory (LSTM) is
explored to model the sequential dependencies in the phase recognition branch.
More importantly, a novel and effective correlation loss is designed to model
the relatedness between tool presence and phase identification of each video
frame, by minimizing the divergence of predictions from the two branches.
Mutually leveraging both low-level feature sharing and high-level prediction
correlating, our MTRCNet-CL method can encourage the interactions between the
two tasks to a large extent, and hence can bring about benefits to each other.
Extensive experiments on a large surgical video dataset (Cholec80) demonstrate
outstanding performance of our proposed method, consistently exceeding the
state-of-the-art methods by a large margin (e.g., 89.1% v.s. 81.0% for the mAP
in tool presence detection and 87.4% v.s. 84.5% for F1 score in phase
recognition). The code can be found on our project website.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06111</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06111</id><created>2019-07-13</created><authors><author><keyname>Maghsoodi</keyname><forenames>Nooshin</forenames></author><author><keyname>Sameti</keyname><forenames>Hossein</forenames></author><author><keyname>Zeinali</keyname><forenames>Hossein</forenames></author><author><keyname>Themos~Stafylakis</keyname></author></authors><title>Speaker Recognition with Random Digit Strings Using Uncertainty
  Normalized HMM-based i-vectors</title><categories>eess.AS cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we combine Hidden Markov Models (HMMs) with i-vector
extractors to address the problem of text-dependent speaker recognition with
random digit strings. We employ digit-specific HMMs to segment the utterances
into digits, to perform frame alignment to HMM states and to extract Baum-Welch
statistics. By making use of the natural partition of input features into
digits, we train digit-specific i-vector extractors on top of each HMM and we
extract well-localized i-vectors, each modelling merely the phonetic content
corresponding to a single digit. We then examine ways to perform channel and
uncertainty compensation, and we propose a novel method for using the
uncertainty in the i-vector estimates. The experiments on RSR2015 part III show
that the proposed method attains 1.52\% and 1.77\% Equal Error Rate (EER) for
male and female respectively, outperforming state-of-the-art methods such as
x-vectors, trained on vast amounts of data. Furthermore, these results are
attained by a single system trained entirely on RSR2015, and by a simple
score-normalized cosine distance. Moreover, we show that the omission of
channel compensation yields only a minor degradation in performance, meaning
that the system attains state-of-the-art results even without recordings from
multiple handsets per speaker for training or enrolment. Similar conclusions
are drawn from our experiments on the RedDots corpus, where the same method is
evaluated on phrases. Finally, we report results with bottleneck features and
show that further improvement is attained when fusing them with spectral
features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06112</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06112</id><created>2019-07-13</created><authors><author><keyname>Zeinali</keyname><forenames>Hossein</forenames></author><author><keyname>Mat&#x11b;jka</keyname><forenames>Pavel</forenames></author><author><keyname>Mo&#x161;ner</keyname><forenames>Ladislav</forenames></author><author><keyname>Plchot</keyname><forenames>Old&#x159;ich</forenames></author><author><keyname>Silnova</keyname><forenames>Anna</forenames></author><author><keyname>Novotn&#xfd;</keyname><forenames>Ond&#x159;ej</forenames></author><author><keyname>Profant</keyname><forenames>J&#xe1;n</forenames></author><author><keyname>Glembek</keyname><forenames>Ond&#x159;ej</forenames></author><author><keyname>Burget</keyname><forenames>Luk&#xe1;&#x161;</forenames></author></authors><title>BUT VOiCES 2019 System Description</title><categories>eess.AS cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a description of our effort in VOiCES 2019 Speaker Recognition
challenge. All systems in the fixed condition are based on the x-vector
paradigm with different features and DNN topologies. The single best system
reaches 1.2% EER and a fusion of 3 systems yields 1.0% EER, which is 15%
relative improvement. The open condition allowed us to use external data which
we did for the PLDA adaptation and achieved less than ~10% relative
improvement. In the submission to open condition, we used 3 x-vector systems
and also one i-vector based system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06128</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06128</id><created>2019-07-13</created><authors><author><keyname>Huang</keyname><forenames>Yunhan</forenames></author><author><keyname>Kavitha</keyname><forenames>Veeraruna</forenames></author><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author></authors><title>Continuous-Time Markov Decision Processes with Controlled Observations</title><categories>math.OC cs.SY eess.SY</categories><comments>8 pages, 5 figures. Submitted to 57th Annual Allerton Conference on
  Communication, Control, and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study a continuous-time discounted jump Markov decision
process with both controlled actions and observations. The observation is only
available for a discrete set of time instances. At each time of observation,
one has to select an optimal timing for the next observation and a control
trajectory for the time interval between two observation points. We provide a
theoretical framework that the decision maker can utilize to find the optimal
observation epochs and the optimal actions jointly. Two cases are investigated.
One is gated queueing systems in which we explicitly characterize the optimal
action and the optimal observation where the optimal observation is shown to be
independent of the state. Another is the inventory control problem with Poisson
arrival process in which we obtain numerically the optimal action and
observation. The results show that it is optimal to observe more frequently at
a region of states where the optimal action adapts constantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06129</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06129</id><created>2019-07-13</created><authors><author><keyname>Harar</keyname><forenames>Pavol</forenames></author><author><keyname>Galaz</keyname><forenames>Zoltan</forenames></author><author><keyname>Alonso-Hernandez</keyname><forenames>Jesus B.</forenames></author><author><keyname>Mekyska</keyname><forenames>Jiri</forenames></author><author><keyname>Burget</keyname><forenames>Radim</forenames></author><author><keyname>Smekal</keyname><forenames>Zdenek</forenames></author></authors><title>Towards Robust Voice Pathology Detection</title><categories>cs.SD cs.LG eess.AS</categories><comments>11 pages, 1 figure, 10 tables. Keywords: Voice pathology detection,
  deep learning, gradient boosting, anomaly detection</comments><journal-ref>Neural Computing and Applications (2018): 1-11</journal-ref><doi>10.1007/s00521-018-3464-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic objective non-invasive detection of pathological voice based on
computerized analysis of acoustic signals can play an important role in early
diagnosis, progression tracking and even effective treatment of pathological
voices. In search towards such a robust voice pathology detection system we
investigated 3 distinct classifiers within supervised learning and anomaly
detection paradigms. We conducted a set of experiments using a variety of input
data such as raw waveforms, spectrograms, mel-frequency cepstral coefficients
(MFCC) and conventional acoustic (dysphonic) features (AF). In comparison with
previously published works, this article is the first to utilize combination of
4 different databases comprising normophonic and pathological recordings of
sustained phonation of the vowel /a/ unrestricted to a subset of vocal
pathologies. Furthermore, to our best knowledge, this article is the first to
explore gradient boosted trees and deep learning for this application. The
following best classification performances measured by F1 score on dedicated
test set were achieved: XGBoost (0.733) using AF and MFCC, DenseNet (0.621)
using MFCC, and Isolation Forest (0.610) using AF. Even though these results
are of exploratory character, conducted experiments do show promising potential
of gradient boosting and deep learning methods to robustly detect voice
pathologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06134</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06134</id><created>2019-07-13</created><authors><author><keyname>Zhuang</keyname><forenames>Peiye</forenames></author><author><keyname>Schwing</keyname><forenames>Alexander G.</forenames></author><author><keyname>Koyejo</keyname><forenames>Sanmi</forenames></author></authors><title>FMRI data augmentation via synthesis</title><categories>cs.CV cs.LG eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an empirical evaluation of fMRI data augmentation via synthesis.
For synthesis we use generative mod-els trained on real neuroimaging data to
produce novel task-dependent functional brain images. Analyzed generative
mod-els include classic approaches such as the Gaussian mixture model (GMM),
and modern implicit generative models such as the generative adversarial
network (GAN) and the variational auto-encoder (VAE). In particular, the
proposed GAN and VAE models utilize 3-dimensional convolutions, which enables
modeling of high-dimensional brain image tensors with structured spatial
correlations. The synthesized datasets are then used to augment classifiers
designed to predict cognitive and behavioural outcomes. Our results suggest
that the proposed models are able to generate high-quality synthetic brain
images which are diverse and task-dependent. Perhaps most importantly, the
performance improvements of data aug-mentation via synthesis are shown to be
complementary to the choice of the predictive model. Thus, our results suggest
that data augmentation via synthesis is a promising approach to address the
limited availability of fMRI data, and to improve the quality of predictive
fMRI models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06141</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06141</id><created>2019-07-13</created><authors><author><keyname>Quadri</keyname><forenames>Adnan</forenames></author><author><keyname>Zeng</keyname><forenames>Huacheng</forenames></author><author><keyname>Hou</keyname><forenames>Y. Thomas</forenames></author></authors><title>A Real-Time mmWave Communication Testbed with Phase Noise Cancellation</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the spectrum under 6 GHz is being depleted, pushing wireless
communications onto millimeter wave (mmWave) frequencies is a trend that
promises multi-Gbps data rate. mmWave is therefore considered as a key
technology for 5G wireless systems and has attracted tremendous research
efforts. The booming research on mmWave necessitates a reconfigurable mmWave
testbed that can be used to prototype and validate new research ideas in real
wireless environments. In this paper, we develop an easy-to-use mmWave testbed
using commercial off-the-shelf devices (USRP and 60 GHz Tx/Rx RF frontends) and
open-source software package (GNU Radio). A key component of our testbed is a
phase noise cancellation (PNC) scheme, which can significantly reduce the phase
noise at the receiver by leveraging the pilot signal inserted at the
transmitter. We have implemented a simplified version of IEEE 802.11 PHY on
this mmWave testbed. Experimental results show that, with the PNC scheme, our
testbed can achieve -20 dB EVM data transmission for real-time video streaming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06158</identifier>
 <datestamp>2019-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06158</id><created>2019-07-13</created><updated>2019-09-09</updated><authors><author><keyname>Liu</keyname><forenames>Chun-Hung</forenames></author><author><keyname>Shen</keyname><forenames>Yu-Han</forenames></author><author><keyname>Lee</keyname><forenames>Chia-Han</forenames></author></authors><title>Energy-Efficient Activation and Uplink Transmission for Cellular IoT</title><categories>eess.SP cs.IT math.IT</categories><comments>15pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a large-scale cellular network in which base stations (BSs) serve
massive Internet-of-Things (IoT) devices. Since IoT devices are powered by a
capacity-limited battery, how to prolong their working lifetime is a paramount
problem for the success of cellular IoT systems. This paper proposes how to use
BSs to manage the active and dormant operating modes of the IoT devices via
downlink signaling in an energy-efficient fashion and how the IoT devices
perform energy-efficient uplink power control to improve their uplink coverage.
We first investigate the fundamental statistical properties of an activation
signaling process induced by BSs that would like to activate the devices in
their cells, which helps to derive the neat expressions of the true, false and
total activation probabilities that reveal joint downlink power control and BS
coordination is an effective means to significantly improve the activation
performance. We then propose an energy-efficient uplink power control for IoT
devices which is shown to save power and ameliorate the uplink coverage
probability at the same time. We also propose an energy-efficient downlink
power control and BS coordination scheme, which is shown to remarkably improve
the activation and uplink coverage performances at the same time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06179</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06179</id><created>2019-07-14</created><authors><author><keyname>Bai</keyname><forenames>Yuanchao</forenames></author><author><keyname>Wang</keyname><forenames>Fen</forenames></author><author><keyname>Cheung</keyname><forenames>Gene</forenames></author><author><keyname>Nakatsukasa</keyname><forenames>Yuji</forenames></author><author><keyname>Gao</keyname><forenames>Wen</forenames></author></authors><title>Fast Graph Sampling Set Selection Using Gershgorin Disc Alignment</title><categories>eess.SP</categories><comments>Very fast deterministic graph sampling set selection algorithm
  without explicit eigen-decomposition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph sampling set selection, where a subset of nodes are chosen to collect
samples to reconstruct a bandlimited or smooth graph signal, is a fundamental
problem in graph signal processing (GSP). Previous works employ an unbiased
least square (LS) signal reconstruction scheme and select samples via expensive
extreme eigenvector computation. Instead, we assume a biased graph Laplacian
regularization (GLR) based scheme that solves a system of linear equations for
reconstruction. We then choose samples to minimize the condition number of the
coefficient matrix---specifically, maximize the smallest eigenvalue
$\lambda_{\min}$. Circumventing explicit eigenvalue computation, we maximize
instead the lower bound of $\lambda_{\min}$, designated by the smallest
left-end of all Gershgorin discs of the matrix. To achieve this efficiently, we
first convert the optimization to a dual problem, where we minimize the number
of samples needed to align all Gershgorin disc left-ends at a chosen
lower-bound target $T$. Algebraically, the dual problem amounts to optimizing
two disc operations: i) shifting of disc centers due to sampling, and ii)
scaling of disc radii due to a similarity transformation of the matrix. We
further reinterpret the dual to an intuitive disc coverage problem bearing
strong resemblance to the famous NP-hard set cover (SC) problem. The
reinterpretation enables us to derive a fast approximation algorithm from a
known SC error-bounded approximation algorithm. We find the appropriate target
$T$ efficiently via binary search. Experiments on real graph data show that our
disc-based sampling algorithm runs substantially faster than existing sampling
schemes and outperforms other eigen-decomposition-free sampling schemes in
reconstruction error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06189</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06189</id><created>2019-07-14</created><authors><author><keyname>Liu</keyname><forenames>Ye</forenames></author><author><keyname>Shen</keyname><forenames>Chen</forenames></author><author><keyname>Song</keyname><forenames>Yankan</forenames></author><author><keyname>Yan</keyname><forenames>Jun</forenames></author></authors><title>Emergency DC Power Support Strategy Based on Coordinated Droop Control
  in Multi-Infeed HVDC System</title><categories>eess.SY cs.SY</categories><comments>5 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the complex hybrid AC-DC power system in China coming into being, the
HVDC faults, such as DC block faults, have an enormous effect on the frequency
stability of the AC side. In multi-infeed HVDC (MIDC) system, to improve the
frequency stability of the receiving-end system, this paper proposes an
emergency DC power support (EDCPS) strategy, which is based on a designed droop
characteristic between the active power of LCC-HVDC lines and the receiving-end
system frequency. Then, a coordinated optimization method is proposed to
determine the droop coefficients of the MIDC lines. To test the proposed EDCPS
method, the electromagnetic transient (EMT) model of a MIDC system is built on
the CloudPSS platform, and the test results verify the effectiveness of the
proposed EDCPS strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06194</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06194</id><created>2019-07-14</created><authors><author><keyname>Fu</keyname><forenames>Weilin</forenames></author><author><keyname>Breininger</keyname><forenames>Katharina</forenames></author><author><keyname>Schaffert</keyname><forenames>Roman</forenames></author><author><keyname>Ravikumar</keyname><forenames>Nishant</forenames></author><author><keyname>Maier</keyname><forenames>Andreas</forenames></author></authors><title>A Divide-and-Conquer Approach towards Understanding Deep Networks</title><categories>cs.LG cs.CV eess.IV</categories><comments>This paper is accepted in MICCAI 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks have achieved tremendous success in various fields
including medical image segmentation. However, they have long been criticized
for being a black-box, in that interpretation, understanding and correcting
architectures is difficult as there is no general theory for deep neural
network design. Previously, precision learning was proposed to fuse deep
architectures and traditional approaches. Deep networks constructed in this way
benefit from the original known operator, have fewer parameters, and improved
interpretability. However, they do not yield state-of-the-art performance in
all applications. In this paper, we propose to analyze deep networks using
known operators, by adopting a divide-and-conquer strategy to replace network
components, whilst retaining its performance. The task of retinal vessel
segmentation is investigated for this purpose. We start with a high-performance
U-Net and show by step-by-step conversion that we are able to divide the
network into modules of known operators. The results indicate that a
combination of a trainable guided filter and a trainable version of the Frangi
filter yields a performance at the level of U-Net (AUC 0.974 vs. 0.972) with a
tremendous reduction in parameters (111,536 vs. 9,575). In addition, the
trained layers can be mapped back into their original algorithmic
interpretation and analyzed using standard tools of signal processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06206</identifier>
 <datestamp>2019-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06206</id><created>2019-07-14</created><authors><author><keyname>Nguyen</keyname><forenames>Thanh Huy</forenames></author><author><keyname>Daniel</keyname><forenames>Sylvie</forenames></author><author><keyname>Gueriot</keyname><forenames>Didier</forenames></author><author><keyname>Sintes</keyname><forenames>Christophe</forenames></author><author><keyname>Caillec</keyname><forenames>Jean-Marc Le</forenames></author></authors><title>Unsupervised Automatic Building Extraction Using Active Contour Model on
  Unregistered Optical Imagery and Airborne LiDAR Data</title><categories>cs.CV eess.IV</categories><comments>PIA19 - Photogrammetric Image Analysis 2019 which will be held in
  conjunction with MRSS19 - Munich Remote Sensing Symposium 2019 on September
  18th-20th, 2019 in Munich, Germany. Proceeding: The International Archives of
  the Photogrammetry, Remote Sensing and Spatial Information Sciences</comments><journal-ref>Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci. XLII-2/W16
  (2019) 181-188</journal-ref><doi>10.5194/isprs-archives-XLII-2-W16-181-2019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic extraction of buildings in urban scenes has become a subject of
growing interest in the domain of photogrammetry and remote sensing,
particularly with the emergence of LiDAR systems since mid-1990s. However, in
reality, this task is still very challenging due to the complexity of building
size and shapes, as well as its surrounding environment. Active contour model,
colloquially called snake model, which has been extensively used in many
applications in computer vision and image processing, is also applied to
extract buildings from aerial/satellite imagery. Motivated by the limitations
of existing snake models addressing to the building extraction, this paper
presents an unsupervised and fully automatic snake model to extract buildings
using optical imagery and an unregistered airborne LiDAR dataset, without
manual initial points or training data. The proposed method is shown to be
capable of extracting buildings with varying color from complex environments,
and yielding high overall accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06212</identifier>
 <datestamp>2019-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06212</id><created>2019-07-14</created><updated>2019-08-13</updated><authors><author><keyname>Zakeri</keyname><forenames>Abulfazl</forenames></author><author><keyname>Gholipoor</keyname><forenames>Narges</forenames></author><author><keyname>Javan</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Jorswieck</keyname><forenames>Eduard A.</forenames></author></authors><title>Energy Cost Minimization by Joint Radio and NFV Resource Allocation: E2E
  QoS Framework</title><categories>eess.SP cs.NI</categories><comments>5G, NFV, Radio, Resource Allocation, E2E QoS, 8 Figure, 36 Pages</comments><journal-ref>IEEE Transactions on Wireless Communications (TWC) 2019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an end to end radio and network function
virtualization (NFV) resource allocation for next generation networks providing
different types of services with different requirements in terms of latency and
data rate. We consider both the access and core parts of the network, and
formulate a novel optimization problem whose aim is to perform the radio
resource allocation jointly with virtual network function (VNF) embedding,
scheduling, and resource allocation such that the network cost, defined as the
consumed energy and the number of utilized network servers, is minimized. The
proposed optimization problem is non-convex, NP-hard, and mathematically
intractable, and hence, we adopt the alternative search method (ASM) to
decouple the main problem into low complex subproblems. Moreover, we propose a
novel heuristic algorithm for NFV resource allocation by proposing a novel
admission control algorithm. Then, we compare the performance of the proposed
algorithm with a greedy-based solution in terms of the acceptance ratio and the
number of active servers. Our simulation results show that the proposed
heuristic algorithm outperforms the conventional ones by approximately 8%
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06227</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06227</id><created>2019-07-14</created><authors><author><keyname>Wang</keyname><forenames>Yongchao</forenames></author><author><keyname>Wang</keyname><forenames>Jiangtao</forenames></author></authors><title>Designing Unimodular Sequences with Optimized Auto/cross-correlation
  Properties via Consensus-ADMM/PDMM Approaches</title><categories>eess.SP</categories><comments>13pages, 12figures. This paper was partically presented in IEEE ICC
  2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unimodular sequences with good auto/cross-correlation properties are
favorable in wireless communication and radar applications. In this paper, we
focus on designing these kinds of sequences. The main content is as follows:
first, we formulate the designing problem as a quartic polynomial minimization
problem with constant modulus constraints; second, by introducing auxiliary
phase variables, the polynomial minimization problem is equivalent to a
consensus nonconvex optimization problem; third, to achieve its good
approximate solution efficiently, we propose two efficient algorithms based on
alternating direction method of multipliers (ADMM) and parallel direction
method of multipliers (PDMM); fourth, we prove that the consensus-ADMM
algorithm can converge to some stationary point of the original nonconvex
problem and consensus-PDMM's output is some stationary point of the original
nonconvex problem if it is convergent. Moreover, we also analyze the nonconvex
optimization model's local optimality and computational complexity of the
proposed consensus-ADMM/PDMM approaches. Simulation results demonstrate that
the proposed ADMM/PDMM approaches outperform state-of-the-art ones in either
computational cost or correlation properties of the designed unimodular
sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06266</identifier>
 <datestamp>2020-02-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06266</id><created>2019-07-14</created><updated>2020-02-03</updated><authors><author><keyname>Marton</keyname><forenames>Apolo Silva</forenames></author><author><keyname>Fioravanti</keyname><forenames>Andr&#xe9; Ricardo</forenames></author><author><keyname>Azinheira</keyname><forenames>Jos&#xe9; Raul</forenames></author><author><keyname>de Paiva</keyname><forenames>Ely Carneiro</forenames></author></authors><title>Hybrid Model-Based and Data-Driven Wind Velocity Estimator for an
  Autonomous Robotic Airship</title><categories>eess.SY cs.RO cs.SY</categories><comments>This is a pre-print submitted for a Springer Journal (accepted for
  publication). It contains 12 pages (in two column format) and 15 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In the context of autonomous airships, several works in control and guidance
use wind velocity to design a control law. However, in general, this
information is not directly measured in robotic airships. This paper presents
three alternative versions for estimation of wind velocity. Firstly, an
Extended Kalman Filter is designed as a model-based approach. Then a Neural
Network is designed as a data-driven approach. Finally, a hybrid estimator is
proposed by performing a fusion between the previous designed estimators:
model-based and data-driven. All approaches consider only Global Positioning
System (GPS), Inertial Measurement Unit (IMU) and a one dimensional Pitot tube
as available sensors. Simulations in a realistic nonlinear model of the airship
suggest that the cooperation between these two techniques increases the
estimation performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06268</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06268</id><created>2019-07-14</created><authors><author><keyname>Keipour</keyname><forenames>Azarakhsh</forenames></author><author><keyname>Mousaei</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Scherer</keyname><forenames>Sebastian</forenames></author></authors><title>ALFA: A Dataset for UAV Fault and Anomaly Detection</title><categories>eess.SY cs.RO cs.SY</categories><comments>5 figures, 1 table - Submitted to the International Journal of
  Robotics Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a dataset of several fault types in control surfaces of a
fixed-wing Unmanned Aerial Vehicle (UAV) for use in Fault Detection and
Isolation (FDI) and Anomaly Detection (AD) research. Currently, the dataset
includes processed data for 47 autonomous flights with scenarios for eight
different types of control surface (actuator and engine) faults, with a total
of 66 minutes of flight in normal conditions and 13 minutes of post-fault
flight time. It additionally includes many hours of raw data of
fully-autonomous, autopilot-assisted and manual flights with tens of fault
scenarios. The ground truth of the time and type of faults is provided in each
scenario to enable evaluation of the methods using the dataset. We have also
provided the helper tools in several programming languages to load and work
with the data and to help the evaluation of a detection method using the
dataset. A set of metrics is proposed to help to compare different methods
using the dataset. Most of the current fault detection methods are evaluated in
simulation and as far as we know, this dataset is the only one providing the
real flight data with faults in such capacity. We hope it will help advance the
state-of-the-art in Anomaly Detection or FDI research for Autonomous Aerial
Vehicles and mobile robots to enhance the safety of autonomous and remote
flight operations further. The dataset and the provided tools can be accessed
from http://theairlab.org/alfa-dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06286</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06286</id><created>2019-07-14</created><authors><author><keyname>T&#xf3;th</keyname><forenames>Viktor</forenames></author><author><keyname>Parkkonen</keyname><forenames>Lauri</forenames></author></authors><title>Autoencoding sensory substitution</title><categories>q-bio.NC cs.CV cs.LG cs.SD eess.AS</categories><doi>10.13140/RG.2.2.10576.87048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tens of millions of people live blind, and their number is ever increasing.
Visual-to-auditory sensory substitution (SS) encompasses a family of cheap,
generic solutions to assist the visually impaired by conveying visual
information through sound. The required SS training is lengthy: months of
effort is necessary to reach a practical level of adaptation. There are two
reasons for the tedious training process: the elongated substituting audio
signal, and the disregard for the compressive characteristics of the human
hearing system. To overcome these obstacles, we developed a novel class of SS
methods, by training deep recurrent autoencoders for image-to-sound conversion.
We successfully trained deep learning models on different datasets to execute
visual-to-auditory stimulus conversion. By constraining the visual space, we
demonstrated the viability of shortened substituting audio signals, while
proposing mechanisms, such as the integration of computational hearing models,
to optimally convey visual features in the substituting stimulus as
perceptually discernible auditory components. We tested our approach in two
separate cases. In the first experiment, the author went blindfolded for 5
days, while performing SS training on hand posture discrimination. The second
experiment assessed the accuracy of reaching movements towards objects on a
table. In both test cases, above-chance-level accuracy was attained after a few
hours of training. Our novel SS architecture broadens the horizon of
rehabilitation methods engineered for the visually impaired. Further
improvements on the proposed model shall yield hastened rehabilitation of the
blind and a wider adaptation of SS devices as a consequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06299</identifier>
 <datestamp>2019-07-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06299</id><created>2019-07-14</created><updated>2019-07-24</updated><authors><author><keyname>Rodriguez-Silva</keyname><forenames>Alejandro</forenames></author><author><keyname>Makonin</keyname><forenames>Stephen</forenames></author></authors><title>Universal Non-Intrusive Load Monitoring (UNILM) Using Filter Pipelines,
  Probabilistic Knapsack, and Labelled Partition Maps</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Being able to track appliances energy usage without the need of sensors can
help occupants reduce their energy consumption to help save the environment all
while saving money. Non-intrusive load monitoring (NILM) tries to do just that.
One of the hardest problems NILM faces is the ability to run unsupervised --
discovering appliances without prior knowledge -- and to run independent of the
differences in appliance mixes and operational characteristics found in various
countries and regions. We propose a solution that can do this with the use of
an advanced filter pipeline to preprocess the data, a Gaussian appliance model
with a probabilistic knapsack algorithm to disaggregate the aggregate smart
meter signal, and partition maps to label which appliances were found and how
much energy they use no matter the country/region. Experimental results show
that relatively complex appliance signals can be tracked accounting for 93.7%
of the total aggregate energy consumed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06302</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06302</id><created>2019-07-14</created><authors><author><keyname>Manjunath</keyname><forenames>Sreelakshmi</forenames></author><author><keyname>Raina</keyname><forenames>Gaurav</forenames></author></authors><title>Compound TCP with Random Early Detection (RED): stability, bifurcation
  and performance analyses</title><categories>cs.NI cs.SY eess.SY</categories><comments>46 pages, 19 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of increased queueing delays in the Internet motivates the study
of currently implemented transport protocols and active queue management (AQM)
policies. We study Compound TCP (default protocol in Windows) with Random Early
Detection (RED). RED uses an exponentially weighted moving average of the queue
size to make packet-dropping decisions, aiming to control the queue size. One
must study RED with current protocols in order to explore its viability in the
context of increased queueing delays.
  We derive a non-linear time-delayed model for Compound TCP-RED. We derive a
sufficient condition for local stability of this model, and examine the impact
of (i) round-trip time (RTT) of the TCP flows, (ii) queue averaging parameter
and (iii) packet-dropping thresholds. Further, we establish that the system
undergoes a Hopf bifurcation as any of the above parameters is varied. This
suggests the emergence of limit cycles in the queue size, which may lead to
synchronisation of TCP flows and loss of link utilisation. Next, we study a
regime where queue size averaging is not performed, and packet-dropping
decisions are based on instantaneous queue size. In this regime, we derive the
necessary and sufficient condition for local stability. A comparison of the
stability results for Compound TCP-RED in the two regimes--with and without
queue size averaging--reveals that averaging may not be beneficial to system
stability. Packet-level simulations show that the queue size indeed exhibits
limit cycle oscillations as system parameters are varied. We then outline a
simple threshold-based queue policy, that could ensure stable low-latency
operation. We show that the threshold policy outperforms RED in terms of
queueing delay, flow completion time and packet loss. We highlight that the
threshold-based policy could mitigate the issue of increased queueing delays in
the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06319</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06319</id><created>2019-07-14</created><updated>2020-02-22</updated><authors><author><keyname>Nath</keyname><forenames>Vishwesh</forenames></author><author><keyname>Lyu</keyname><forenames>Ilwoo</forenames></author><author><keyname>Schilling</keyname><forenames>Kurt G.</forenames></author><author><keyname>Parvathaneni</keyname><forenames>Prasanna</forenames></author><author><keyname>Hansen</keyname><forenames>Colin B.</forenames></author><author><keyname>Tang</keyname><forenames>Yucheng</forenames></author><author><keyname>Huo</keyname><forenames>Yuankai</forenames></author><author><keyname>Janve</keyname><forenames>Vaibhav A.</forenames></author><author><keyname>Gao</keyname><forenames>Yurui</forenames></author><author><keyname>Stepniewska</keyname><forenames>Iwona</forenames></author><author><keyname>Anderson</keyname><forenames>Adam W.</forenames></author><author><keyname>Landman</keyname><forenames>Bennett A.</forenames></author></authors><title>Enabling Multi-Shell b-Value Generalizability of Data-Driven Diffusion
  Models with Deep SHORE</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intra-voxel models of the diffusion signal are essential for interpreting
organization of the tissue environment at micrometer level with data at
millimeter resolution. Recent advances in data driven methods have enabled
direct compari-son and optimization of methods for in-vivo data with externally
validated histological sections with both 2-D and 3-D histology. Yet, all
existing methods make limiting assumptions of either (1) model-based linkages
between b-values or (2) limited associations with single shell data. We
generalize prior deep learning models that used single shell spherical harmonic
transforms to integrate the re-cently developed simple harmonic oscillator
reconstruction (SHORE) basis. To enable learning on the SHORE manifold, we
present an alternative formulation of the fiber orientation distribution (FOD)
object using the SHORE basis while rep-resenting the observed diffusion
weighted data in the SHORE basis. To ensure consistency of hyper-parameter
optimization for SHORE, we present our Deep SHORE approach to learn on a
data-optimized manifold. Deep SHORE is evalu-ated with eight-fold
cross-validation of a preclinical MRI-histology data with four b-values.
Generalizability of in-vivo human data is evaluated on two separate 3T MRI
scanners. Specificity in terms of angular correlation (ACC) with the
preclinical data improved on single shell: 0.78 relative to 0.73 and 0.73,
multi-shell: 0.80 relative to 0.74 (p &lt; 0.001). In the in-vivo human data, Deep
SHORE was more consistent across scanners with 0.63 relative to other
multi-shell methods 0.39, 0.52 and 0.57 in terms of ACC. In conclusion, Deep
SHORE is a promising method to enable data driven learning with DW-MRI under
conditions with varying b-values, number of diffusion shells, and gradient
directions per shell.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06327</identifier>
 <datestamp>2020-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06327</id><created>2019-07-15</created><updated>2020-02-20</updated><authors><author><keyname>Lekhwani</keyname><forenames>Rohan</forenames></author><author><keyname>Singh</keyname><forenames>Bhupendra</forenames></author></authors><title>FastV2C-HandNet: Fast Voxel to Coordinate Hand Pose Estimation with 3D
  Convolutional Neural Networks</title><categories>cs.CV cs.HC cs.LG eess.IV</categories><comments>13 pages, 5 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hand pose estimation from monocular depth images has been an important and
challenging problem in the Computer Vision community. In this paper, we present
a novel approach to estimate 3D hand joint locations from 2D depth images.
Unlike most of the previous methods, our model captures the 3D spatial
information from a depth image thereby giving it a greater understanding of the
input. We voxelize the input depth map to capture the 3D features of the input
and perform 3D data augmentations to make our network robust to real-world
images. Our network is trained in an end-to-end manner which reduces time and
space complexity significantly when compared to other methods. Through
extensive experiments, we show that our model outperforms state-of-the-art
methods with respect to the time it takes to train and predict 3D hand joint
locations. This makes our method more suitable for real-world hand pose
estimation scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06340</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06340</id><created>2019-07-15</created><authors><author><keyname>Thakallapelli</keyname><forenames>Abilash</forenames></author><author><keyname>Kamalasadan</keyname><forenames>Sukumar</forenames></author></authors><title>Alternating Direction Method of Multipliers (ADMMs) Based Distributed
  Approach For Wide-Area Control</title><categories>eess.SY cs.SY</categories><journal-ref>IEEE Trans. on Industrial Applications, Volume: 55, No: 3, pp.
  3215-3227, Feb. 2019</journal-ref><doi>10.1109/TIA.2019.2896837</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an alternating direction method of multipliers based novel
distributed wide-area control architecture is proposed for damping the
interarea oscillations. In this approach, first, an interconnected power system
is divided into areas based on coherency grouping. Second, local processors are
assigned on each area that estimate a black-box transfer function model based
on Lagrange multipliers using measurements. These local area processors are
then used to estimate a global transfer function model of the power system
based on a consensus algorithm through a global processor. After convergence, a
transfer function residue corresponding to the interarea mode of interest is
derived, to determine optimal wide area control loop. Finally, a wide-area
damping controller is designed based on this information. The efficacy of the
controller is validated using two area and IEEE-39 bus test systems on
RTDS/RSCAD and MATLAB cosimulation platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06342</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06342</id><created>2019-07-15</created><authors><author><keyname>Ganji</keyname><forenames>Sreeram</forenames></author><author><keyname>Dhawan</keyname><forenames>Kunal</forenames></author><author><keyname>Priyadarshi</keyname><forenames>Kumar</forenames></author><author><keyname>Sinha</keyname><forenames>Rohit</forenames></author></authors><title>Joint Language Identification of Code-Switching Speech using Attention
  based E2E Network</title><categories>cs.CL cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Language identification (LID) has relevance in many speech processing
applications. For the automatic recognition of code-switching speech, the
conventional approaches often employ an LID system for detecting the languages
present within an utterance. In the existing works, the LID on code-switching
speech involves modelling of the underlying languages separately. In this work,
we propose a joint modelling based LID system for code-switching speech. To
achieve the same, an attention-based end-to-end (E2E) network has been
explored. For the development and evaluation of the proposed approach, a
recently created Hindi-English code-switching corpus has been used. For the
contrast purpose, an LID system employing the connectionist temporal
classification-based E2E network is also developed. On comparing both the LID
systems, the attention based approach is noted to result in better LID
accuracy. The effective location of code-switching boundaries within the
utterance by the proposed approach has been demonstrated by plotting the
attention weights of E2E network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06356</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06356</id><created>2019-07-15</created><updated>2019-07-16</updated><authors><author><keyname>Mihaita</keyname><forenames>Adriana-Simona</forenames></author><author><keyname>Li</keyname><forenames>Haowen</forenames></author><author><keyname>He</keyname><forenames>Zongyang</forenames></author><author><keyname>Rizoiu</keyname><forenames>Marian-Andrei</forenames></author></authors><title>Motorway Traffic Flow Prediction using Advanced Deep Learning</title><categories>cs.LG eess.SP stat.ML</categories><comments>Published in the Proceedings of the 22nd IEEE Intelligent
  Transportation Systems Conference (ITSC'19). Auckland, New Zealand</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Congestion prediction represents a major priority for traffic management
centres around the world to ensure timely incident response handling. The
increasing amounts of generated traffic data have been used to train machine
learning predictors for traffic, however this is a challenging task due to
inter-dependencies of traffic flow both in time and space. Recently, deep
learning techniques have shown significant prediction improvements over
traditional models, however open questions remain around their applicability,
accuracy and parameter tuning. This paper proposes an advanced deep learning
framework for simultaneously predicting the traffic flow on a large number of
monitoring stations along a highly circulated motorway in Sydney, Australia,
including exit and entry loop count stations, and over varying training and
prediction time horizons. The spatial and temporal features extracted from the
36.34 million data points are used in various deep learning architectures that
exploit their spatial structure (convolutional neuronal networks), their
temporal dynamics (recurrent neuronal networks), or both through a hybrid
spatio-temporal modelling (CNN-LSTM). We show that our deep learning models
consistently outperform traditional methods, and we conduct a comparative
analysis of the optimal time horizon of historical data required to predict
traffic flow at different time points in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06358</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06358</id><created>2019-07-15</created><updated>2019-07-22</updated><authors><author><keyname>Li</keyname><forenames>Ziqiang</forenames></author><author><keyname>Tao</keyname><forenames>Rentuo</forenames></author><author><keyname>Wu</keyname><forenames>Qianrun</forenames></author><author><keyname>Li</keyname><forenames>Bin</forenames></author></authors><title>DA-RefineNet:A Dual Input Whole Slide Image Segmentation Algorithm Based
  on Attention</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the high resolution of pathological images, the automated semantic
segmentation in the medical pathological images has shown greater challenges
than that in natural images. Sliding Window method has shown its effect on
solving problem caused by the high resolution of whole slide images (WSI).
However, owing to its localization, Sliding Window method also suffers from
lack of global information. In this paper, a dual input semantic segmentation
network based on attention is proposed, in which, one input provides
small-scale fine information, the other input provides large-scale coarse
information. Compared with single input methods, our method based on dual
inputs and attention: DA-RefineNet exhibits a dramatic performance improvement
on ICIAR2018 breast cancer segmentation task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06414</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06414</id><created>2019-07-15</created><authors><author><keyname>Fountoukidou</keyname><forenames>Tatiana</forenames></author><author><keyname>Sznitman</keyname><forenames>Raphael</forenames></author></authors><title>Concept-Centric Visual Turing Tests for Method Validation</title><categories>cs.LG eess.IV stat.ML</categories><comments>9 pages, 8 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Recent advances in machine learning for medical imaging have led to
impressive increases in model complexity and overall capabilities. However, the
ability to discern the precise information a machine learning method is using
to make decisions has lagged behind and it is often unclear how these
performances are in fact achieved. Conventional evaluation metrics that reduce
method performance to a single number or a curve only provide limited insights.
Yet, systems used in clinical practice demand thorough validation that such
crude characterizations miss. To this end, we present a framework to evaluate
classification methods based on a number of interpretable concepts that are
crucial for a clinical task. Our approach is inspired by the Turing Test
concept and how to devise a test that adaptively questions a method for its
ability to interpret medical images. To do this, we make use of a Twenty
Questions paradigm whereby we use a probabilistic model to characterize the
method's capacity to grasp task-specific concepts, and we introduce a strategy
to sequentially query the method according to its previous answers. The results
show that the probabilistic model is able to expose both the dataset's and the
method's biases, and can be used to reduced the number of queries needed for
confident performance evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06417</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06417</id><created>2019-07-15</created><updated>2019-10-23</updated><authors><author><keyname>Fernandez-Fernandez</keyname><forenames>Raul</forenames></author><author><keyname>Victores</keyname><forenames>Juan G.</forenames></author><author><keyname>Estevez</keyname><forenames>David</forenames></author><author><keyname>Balaguer</keyname><forenames>Carlos</forenames></author></authors><title>Quick, Stat!: A Statistical Analysis of the Quick, Draw! Dataset</title><categories>cs.CV cs.DB eess.IV</categories><comments>12 pages, Eurosim 2019</comments><msc-class>68T30</msc-class><acm-class>I.2.6; I.5.1; I.3.4</acm-class><doi>10.11128/arep.58</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The Quick, Draw! Dataset is a Google dataset with a collection of 50 million
drawings, divided in 345 categories, collected from the users of the game
Quick, Draw!. In contrast with most of the existing image datasets, in the
Quick, Draw! Dataset, drawings are stored as time series of pencil positions
instead of a bitmap matrix composed by pixels. This aspect makes this dataset
the largest doodle dataset available at the time. The Quick, Draw! Dataset is
presented as a great opportunity to researchers for developing and studying
machine learning techniques. Due to the size of this dataset and the nature of
its source, there is a scarce of information about the quality of the drawings
contained. In this paper, a statistical analysis of three of the classes
contained in the Quick, Draw! Dataset is depicted: mountain, book and whale.
The goal is to give to the reader a first impression of the data collected in
this dataset. For the analysis of the quality of the drawings, a Classification
Neural Network was trained to obtain a classification score. Using this
classification score and the parameters provided by the dataset, a statistical
analysis of the quality and nature of the drawings contained in this dataset is
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06426</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06426</id><created>2019-07-15</created><authors><author><keyname>Jeong</keyname><forenames>Eunjeong</forenames></author><author><keyname>Oh</keyname><forenames>Seungeun</forenames></author><author><keyname>Park</keyname><forenames>Jihong</forenames></author><author><keyname>Kim</keyname><forenames>Hyesung</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author><author><keyname>Kim</keyname><forenames>Seong-Lyun</forenames></author></authors><title>Multi-hop Federated Private Data Augmentation with Sample Compression</title><categories>cs.LG cs.NI eess.SP stat.ML</categories><comments>to be presented at the 28th International Joint Conference on
  Artificial Intelligence (IJCAI-19), 1st International Workshop on Federated
  Machine Learning for User Privacy and Data Confidentiality (FML'19), Macao,
  China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On-device machine learning (ML) has brought about the accessibility to a
tremendous amount of data from the users while keeping their local data private
instead of storing it in a central entity. However, for privacy guarantee, it
is inevitable at each device to compensate for the quality of data or learning
performance, especially when it has a non-IID training dataset. In this paper,
we propose a data augmentation framework using a generative model: multi-hop
federated augmentation with sample compression (MultFAug). A multi-hop protocol
speeds up the end-to-end over-the-air transmission of seed samples by enhancing
the transport capacity. The relaying devices guarantee stronger privacy
preservation as well since the origin of each seed sample is hidden in those
participants. For further privatization on the individual sample level, the
devices compress their data samples. The devices sparsify their data samples
prior to transmissions to reduce the sample size, which impacts the
communication payload. This preprocessing also strengthens the privacy of each
sample, which corresponds to the input perturbation for preserving sample
privacy. The numerical evaluations show that the proposed framework
significantly improves privacy guarantee, transmission delay, and local
training performance with adjustment to the number of hops and compression
rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06483</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06483</id><created>2019-07-15</created><authors><author><keyname>~Savchik</keyname><forenames>A.</forenames></author><author><keyname>~Ershov</keyname><forenames>E.</forenames></author><author><keyname>~Karpenko</keyname><forenames>S.</forenames></author></authors><title>Color Cerberus</title><categories>cs.CV cs.LG eess.IV</categories><doi>10.1109/ISPA.2019.8868425</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simple convolutional neural network was able to win ISISPA color constancy
competition. Partial reimplementation of (Bianco, 2017) neural architecture
would have shown even better results in this setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06490</identifier>
 <datestamp>2020-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06490</id><created>2019-07-15</created><updated>2020-01-15</updated><authors><author><keyname>Molini</keyname><forenames>Andrea Bordone</forenames></author><author><keyname>Valsesia</keyname><forenames>Diego</forenames></author><author><keyname>Fracastoro</keyname><forenames>Giulia</forenames></author><author><keyname>Magli</keyname><forenames>Enrico</forenames></author></authors><title>DeepSUM: Deep neural network for Super-resolution of Unregistered
  Multitemporal images</title><categories>eess.IV cs.LG</categories><doi>10.1109/TGRS.2019.2959248</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, convolutional neural networks (CNN) have been successfully applied
to many remote sensing problems. However, deep learning techniques for
multi-image super-resolution from multitemporal unregistered imagery have
received little attention so far. This work proposes a novel CNN-based
technique that exploits both spatial and temporal correlations to combine
multiple images. This novel framework integrates the spatial registration task
directly inside the CNN, and allows to exploit the representation learning
capabilities of the network to enhance registration accuracy. The entire
super-resolution process relies on a single CNN with three main stages: shared
2D convolutions to extract high-dimensional features from the input images; a
subnetwork proposing registration filters derived from the high-dimensional
feature representations; 3D convolutions for slow fusion of the features from
multiple images. The whole network can be trained end-to-end to recover a
single high resolution image from multiple unregistered low resolution images.
The method presented in this paper is the winner of the PROBA-V
super-resolution challenge issued by the European Space Agency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06515</identifier>
 <datestamp>2019-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06515</id><created>2019-07-15</created><updated>2019-10-15</updated><authors><author><keyname>Zhang</keyname><forenames>Xu</forenames></author><author><keyname>Karaman</keyname><forenames>Svebor</forenames></author><author><keyname>Chang</keyname><forenames>Shih-Fu</forenames></author></authors><title>Detecting and Simulating Artifacts in GAN Fake Images</title><categories>cs.CV eess.IV</categories><comments>This is an extended version of our original AutoGAN paper which will
  be appeared in WIFS 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To detect GAN generated images, conventional supervised machine learning
algorithms require collection of a number of real and fake images from the
targeted GAN model. However, the specific model used by the attacker is often
unavailable. To address this, we propose a GAN simulator, AutoGAN, which can
simulate the artifacts produced by the common pipeline shared by several
popular GAN models. Additionally, we identify a unique artifact caused by the
up-sampling component included in the common GAN pipeline. We show
theoretically such artifacts are manifested as replications of spectra in the
frequency domain and thus propose a classifier model based on the spectrum
input, rather than the pixel input. By using the simulated images to train a
spectrum based classifier, even without seeing the fake images produced by the
targeted GAN model during training, our approach achieves state-of-the-art
performances on detecting fake images generated by popular GAN models such as
CycleGAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06543</identifier>
 <datestamp>2019-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06543</id><created>2019-07-15</created><authors><author><keyname>Bano</keyname><forenames>Sophia</forenames></author><author><keyname>Vasconcelos</keyname><forenames>Francisco</forenames></author><author><keyname>Amo</keyname><forenames>Marcel Tella</forenames></author><author><keyname>Dwyer</keyname><forenames>George</forenames></author><author><keyname>Gruijthuijsen</keyname><forenames>Caspar</forenames></author><author><keyname>Deprest</keyname><forenames>Jan</forenames></author><author><keyname>Ourselin</keyname><forenames>Sebastien</forenames></author><author><keyname>Poorten</keyname><forenames>Emmanuel Vander</forenames></author><author><keyname>Vercauteren</keyname><forenames>Tom</forenames></author><author><keyname>Stoyanov</keyname><forenames>Danail</forenames></author></authors><title>Deep Sequential Mosaicking of Fetoscopic Videos</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>Accepted at MICCAI 2019</comments><doi>10.1007/978-3-030-32239-7_35</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Twin-to-twin transfusion syndrome treatment requires fetoscopic laser
photocoagulation of placental vascular anastomoses to regulate blood flow to
both fetuses. Limited field-of-view (FoV) and low visual quality during
fetoscopy make it challenging to identify all vascular connections. Mosaicking
can align multiple overlapping images to generate an image with increased FoV,
however, existing techniques apply poorly to fetoscopy due to the low visual
quality, texture paucity, and hence fail in longer sequences due to the drift
accumulated over time. Deep learning techniques can facilitate in overcoming
these challenges. Therefore, we present a new generalized Deep Sequential
Mosaicking (DSM) framework for fetoscopic videos captured from different
settings such as simulation, phantom, and real environments. DSM extends an
existing deep image-based homography model to sequential data by proposing
controlled data augmentation and outlier rejection methods. Unlike existing
methods, DSM can handle visual variations due to specular highlights and
reflection across adjacent frames, hence reducing the accumulated drift. We
perform experimental validation and comparison using 5 diverse fetoscopic
videos to demonstrate the robustness of our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06553</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06553</id><created>2019-07-15</created><authors><author><keyname>Lopez</keyname><forenames>Brett T.</forenames></author><author><keyname>Slotine</keyname><forenames>Jean-Jacques E.</forenames></author><author><keyname>How</keyname><forenames>Jonathan P.</forenames></author></authors><title>Dynamic Tube MPC for Nonlinear Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling error or external disturbances can severely degrade the performance
of Model Predictive Control (MPC) in real-world scenarios. Robust MPC (RMPC)
addresses this limitation by optimizing over feedback policies but at the
expense of increased computational complexity. Tube MPC is an approximate
solution strategy in which a robust controller, designed offline, keeps the
system in an invariant tube around a desired nominal trajectory, generated
online. Naturally, this decomposition is suboptimal, especially for systems
with changing objectives or operating conditions. In addition, many tube MPC
approaches are unable to capture state-dependent uncertainty due to the
complexity of calculating invariant tubes, resulting in overly-conservative
approximations. This work presents the Dynamic Tube MPC (DTMPC) framework for
nonlinear systems where both the tube geometry and open-loop trajectory are
optimized simultaneously. By using boundary layer sliding control, the tube
geometry can be expressed as a simple relation between control parameters and
uncertainty bound; enabling the tube geometry dynamics to be added to the
nominal MPC optimization with minimal increase in computational complexity. In
addition, DTMPC is able to leverage state-dependent uncertainty to reduce
conservativeness and improve optimization feasibility. DTMPC is demonstrated to
robustly perform obstacle avoidance and modify the tube geometry in response to
obstacle proximity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06557</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06557</id><created>2019-07-15</created><authors><author><keyname>Ren</keyname><forenames>Hong</forenames></author><author><keyname>Pan</keyname><forenames>Cunhua</forenames></author><author><keyname>Wang</keyname><forenames>Kezhi</forenames></author><author><keyname>Deng</keyname><forenames>Yansha</forenames></author><author><keyname>Elkashlan</keyname><forenames>Maged</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author></authors><title>Achievable Data Rate for URLLC-Enabled UAV Systems with 3-D Channel
  Model</title><categories>eess.SP</categories><comments>Accepted in IEEE Wireless Communications Letter</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we investigate the average achievable data rate (AADR) of the
control information delivery from the ground control station (GCS) to
unmanned-aerial-vehicle (UAV) under a 3-D channel, which requires
ultra-reliable and low-latency communications (URLLC) to avoid collision. The
value of AADR can give insights on the packet size design. Achievable data rate
under short channel blocklength is adopted to characterize the system
performance. The UAV is assumed to be uniformly distributed within a restricted
space. We first adopt the Gaussian-Chebyshev quadrature (GCQ) to approximate
the exact AADR. The tight lower bound of AADR is derived in a closed form.
Numerical results verify the correctness and tightness of our derived results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06565</identifier>
 <datestamp>2019-08-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06565</id><created>2019-07-15</created><updated>2019-08-07</updated><authors><author><keyname>Dhaliwal</keyname><forenames>Jasjeet</forenames></author><author><keyname>Hambrook</keyname><forenames>Kyle</forenames></author></authors><title>Recovery Guarantees for Compressible Signals with Adversarial Noise</title><categories>cs.CV cs.CR cs.DS cs.LG eess.SP stat.ML</categories><comments>Theorem 1 updated, \ell_\infty defense added, Lemma 9 added, comp.
  section updated, abstract updated, and other minor writing edits</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide recovery guarantees for compressible signals that have been
corrupted with noise and extend the framework introduced in
\cite{bafna2018thwarting} to defend neural networks against $\ell_0$-norm,
$\ell_2$-norm, and $\ell_{\infty}$-norm attacks. Our results are general as
they can be applied to most unitary transforms used in practice and hold for
$\ell_0$-norm, $\ell_2$-norm, and $\ell_\infty$-norm bounded noise. In the case
of $\ell_0$-norm noise, we prove recovery guarantees for Iterative Hard
Thresholding (IHT) and Basis Pursuit (BP). For $\ell_2$-norm bounded noise, we
provide recovery guarantees for BP and for the case of $\ell_\infty$-norm
bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These
guarantees theoretically bolster the defense framework introduced in
\cite{bafna2018thwarting} for defending neural networks against adversarial
inputs. Finally, we experimentally demonstrate the effectiveness of this
defense framework against an array of $\ell_0$, $\ell_2$ and $\ell_\infty$ norm
attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06566</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06566</id><created>2019-07-15</created><authors><author><keyname>Fu</keyname><forenames>Haisheng</forenames></author><author><keyname>Liang</keyname><forenames>Feng</forenames></author><author><keyname>Lei</keyname><forenames>Bo</forenames></author><author><keyname>Bian</keyname><forenames>Nai</forenames></author><author><keyname>zhang</keyname><forenames>Qian</forenames></author><author><keyname>Akbari</keyname><forenames>Mohammad</forenames></author><author><keyname>Liang</keyname><forenames>Jie</forenames></author><author><keyname>Tu</keyname><forenames>Chengjie</forenames></author></authors><title>Improved Hybrid Layered Image Compression using Deep Learning and
  Traditional Codecs</title><categories>eess.IV cs.LG stat.ML</categories><comments>Submitted to Signal Processing: Image Communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently deep learning-based methods have been applied in image compression
and achieved many promising results. In this paper, we propose an improved
hybrid layered image compression framework by combining deep learning and the
traditional image codecs. At the encoder, we first use a convolutional neural
network (CNN) to obtain a compact representation of the input image, which is
losslessly encoded by the FLIF codec as the base layer of the bit stream. A
coarse reconstruction of the input is obtained by another CNN from the
reconstructed compact representation. The residual between the input and the
coarse reconstruction is then obtained and encoded by the H.265/HEVC-based BPG
codec as the enhancement layer of the bit stream. Experimental results using
the Kodak and Tecnick datasets show that the proposed scheme outperforms the
state-of-the-art deep learning-based layered coding scheme and traditional
codecs including BPG in both PSNR and MS-SSIM metrics across a wide range of
bit rates, when the images are coded in the RGB444 domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06568</identifier>
 <datestamp>2019-07-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06568</id><created>2019-07-15</created><updated>2019-07-18</updated><authors><author><keyname>Vides</keyname><forenames>Fredy</forenames></author></authors><title>On Cyclic Finite-State Approximation of Data-Driven Systems</title><categories>math.OC cs.SY eess.SY math.OA</categories><msc-class>93B28, 47N70 (primary) and 93C57, 93B40 (secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this document, some novel theoretical and computational techniques for
constrained approximation of data-driven systems, are presented. The motivation
for the development of these techniques came from structure-preserving matrix
approximation problems that appear in the fields of system identification and
model predictive control, for data-driven systems and processes. The research
reported in this document is focused on finite-state approximation of
data-driven systems.
  Some numerical implementations of the aforementioned techniques in the
simulation and model predictive control of some generic data-driven systems,
that are related to electrical signal transmission models, are outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06581</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06581</id><created>2019-07-10</created><authors><author><keyname>Pandey</keyname><forenames>Shalini</forenames></author><author><keyname>Karypis</keyname><forenames>George</forenames></author></authors><title>Structured Dictionary Learning for Energy Disaggregation</title><categories>eess.SY cs.SY eess.SP</categories><comments>10 Pages</comments><doi>10.1145/3307772.3328301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increased awareness regarding the impact of energy consumption on the
environment has led to an increased focus on reducing energy consumption.
Feedback on the appliance level energy consumption can help in reducing the
energy demands of the consumers. Energy disaggregation techniques are used to
obtain the appliance level energy consumption from the aggregated energy
consumption of a house. These techniques extract the energy consumption of an
individual appliance as features and hence face the challenge of distinguishing
two similar energy consuming devices. To address this challenge we develop
methods that leverage the fact that some devices tend to operate concurrently
at specific operation modes. The aggregated energy consumption patterns of a
subgroup of devices allow us to identify the concurrent operating modes of
devices in the subgroup. Thus, we design hierarchical methods to replace the
task of overall energy disaggregation among the devices with a recursive
disaggregation task involving device subgroups. Experiments on two real-world
datasets show that our methods lead to improved performance as compared to
baseline. One of our approaches, Greedy based Device Decomposition Method
(GDDM) achieved up to 23.8%, 10% and 59.3% improvement in terms of
micro-averaged f score, macro-averaged f score and Normalized Disaggregation
Error (NDE), respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06583</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06583</id><created>2019-06-30</created><authors><author><keyname>Zhao</keyname><forenames>Xueyuan</forenames></author><author><keyname>Sadhu</keyname><forenames>Vidyasagar</forenames></author><author><keyname>Pompili</keyname><forenames>Dario</forenames></author></authors><title>Low-power All-analog Circuit for Rectangular-type Analog Joint Source
  Channel Coding</title><categories>eess.SP cs.ET cs.NI</categories><comments>4 pages ISCAS 2016. arXiv admin note: text overlap with
  arXiv:1701.05599, arXiv:1907.01442</comments><journal-ref>2016 IEEE International Symposium on Circuits and Systems (ISCAS),
  Montreal, QC, 2016, pp. 1410-1413</journal-ref><doi>10.1109/ISCAS.2016.7527514</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A low-complexity all-analog circuit is proposed to perform efficiently Analog
Joint Source Channel Coding (AJSCC), which can compress two or more sensor
signals into one with controlled distortion while also being robust against
wireless channel impairments. The idea is to realize the rectangular-type AJSCC
using Voltage Controlled Voltage Sources (VCVS). The proposal is verified by
Spice simulations as well as breadboard and Printed Circuit Board (PCB)
implementations. Results indicate that the design is feasible for
low-complexity systems like persistent wireless sensor networks requiring low
circuit power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06625</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06625</id><created>2019-07-15</created><authors><author><keyname>Hett</keyname><forenames>Kilian</forenames></author><author><keyname>Ta</keyname><forenames>Vinh-Thong</forenames></author><author><keyname>Manj&#xf3;n</keyname><forenames>Jos&#xe9; V.</forenames></author><author><keyname>Coup&#xe9;</keyname><forenames>Pierrick</forenames></author></authors><title>Multi-scale Graph-based Grading for Alzheimer's Disease Prediction</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prediction of subjects with mild cognitive impairment (MCI) who will
progress to Alzheimer's disease (AD) is clinically relevant, and may above all
have a significant impact on accelerate the development of new treatments. In
this paper, we present a new MRI-based biomarker that enables us to predict
conversion of MCI subjects to AD accurately. In order to better capture the AD
signature, we introduce two main contributions. First, we present a new
graph-based grading framework to combine inter-subject similarity features and
intra-subject variability features. This framework involves patch-based grading
of anatomical structures and graph-based modeling of structure alteration
relationships. Second, we propose an innovative multiscale brain analysis to
capture alterations caused by AD at different anatomical levels. Based on a
cascade of classifiers, this multiscale approach enables the analysis of
alterations of whole brain structures and hippocampus subfields at the same
time. During our experiments using the ADNI-1 dataset, the proposed multiscale
graph-based grading method obtained an area under the curve (AUC) of 81% to
predict conversion of MCI subjects to AD within three years. Moreover, when
combined with cognitive scores, the proposed method obtained 85% of AUC. These
results are competitive in comparison to state-of-the-art methods evaluated on
the same dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06633</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06633</id><created>2019-07-14</created><authors><author><keyname>Yay&#x131;k</keyname><forenames>Apdullah</forenames></author><author><keyname>Kutlu</keyname><forenames>Yakup</forenames></author><author><keyname>Altan</keyname><forenames>G&#xf6;khan</forenames></author></authors><title>On improving learning capability of ELM and an application to
  brain-computer interface</title><categories>cs.LG eess.SP stat.ML</categories><comments>11 pages, 6 figures, Neural Computing and Application, Springer
  (under-review)</comments><doi>10.13140/RG.2.2.30778.34248</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As a type of pseudoinverse learning, extreme learning machine (ELM) is able
to achieve high performances in a rapid pace on benchmark datasets. However,
when it is applied to real life large data, decline related to low-convergence
of singular value decomposition (SVD) method occurs. Our study aims to resolve
this issue via replacing SVD with theoretically and empirically much efficient
5 number of methods: lower upper triangularization, Hessenberg decomposition,
Schur decomposition, modified Gram Schmidt algorithm and Householder
reflection. Comparisons were made on electroencephalography based
brain-computer interface classification problem to decide which method is the
most useful. Results of subject-based classifications suggested that if
priority was given to training pace, Hessenberg decomposition method, whereas
if priority was given to performances Householder reflection method should be
preferred.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06637</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06637</id><created>2019-07-14</created><authors><author><keyname>Huang</keyname><forenames>Cheng-Zhi Anna</forenames></author><author><keyname>Hawthorne</keyname><forenames>Curtis</forenames></author><author><keyname>Roberts</keyname><forenames>Adam</forenames></author><author><keyname>Dinculescu</keyname><forenames>Monica</forenames></author><author><keyname>Wexler</keyname><forenames>James</forenames></author><author><keyname>Hong</keyname><forenames>Leon</forenames></author><author><keyname>Howcroft</keyname><forenames>Jacob</forenames></author></authors><title>The Bach Doodle: Approachable music composition with machine learning at
  scale</title><categories>cs.SD cs.HC cs.LG eess.AS stat.ML</categories><comments>Proceedings of the 18th International Society for Music Information
  Retrieval Conference, ISMIR 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To make music composition more approachable, we designed the first AI-powered
Google Doodle, the Bach Doodle, where users can create their own melody and
have it harmonized by a machine learning model Coconet (Huang et al., 2017) in
the style of Bach. For users to input melodies, we designed a simplified
sheet-music based interface. To support an interactive experience at scale, we
re-implemented Coconet in TensorFlow.js (Smilkov et al., 2019) to run in the
browser and reduced its runtime from 40s to 2s by adopting dilated depth-wise
separable convolutions and fusing operations. We also reduced the model
download size to approximately 400KB through post-training weight quantization.
We calibrated a speed test based on partial model evaluation time to determine
if the harmonization request should be performed locally or sent to remote TPU
servers. In three days, people spent 350 years worth of time playing with the
Bach Doodle, and Coconet received more than 55 million queries. Users could
choose to rate their compositions and contribute them to a public dataset,
which we are releasing with this paper. We hope that the community finds this
dataset useful for applications ranging from ethnomusicological studies, to
music education, to improving machine learning models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06639</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06639</id><created>2019-07-15</created><authors><author><keyname>Chen</keyname><forenames>Hangting</forenames></author><author><keyname>Liu</keyname><forenames>Zuozhen</forenames></author><author><keyname>Liu</keyname><forenames>Zongming</forenames></author><author><keyname>Zhang</keyname><forenames>Pengyuan</forenames></author><author><keyname>Yan</keyname><forenames>Yonghong</forenames></author></authors><title>Integrating the Data Augmentation Scheme with Various Classifiers for
  Acoustic Scene Modeling</title><categories>eess.AS cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical report describes the IOA team's submission for TASK1A of
DCASE2019 challenge. Our acoustic scene classification (ASC) system adopts a
data augmentation scheme employing generative adversary networks. Two major
classifiers, 1D deep convolutional neural network integrated with scalogram
features and 2D fully convolutional neural network integrated with Mel filter
bank features, are deployed in the scheme. Other approaches, such as adversary
city adaptation, temporal module based on discrete cosine transform and hybrid
architectures, have been developed for further fusion. The results of our
experiments indicates that the final fusion systems A-D could achieve an
accuracy higher than 85% on the officially provided fold 1 evaluation dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06664</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06664</id><created>2019-07-15</created><authors><author><keyname>Nguyen</keyname><forenames>Ly V.</forenames></author><author><keyname>Nguyen</keyname><forenames>Duy H. N.</forenames></author></authors><title>Linear Receivers for Massive MIMO Systems with One-Bit ADCs</title><categories>eess.SP</categories><comments>4 pages, 3 figures, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we propose three linear receivers including Bussgang-based
Maximal Ratio Combining (BMRC), Bussgang-based Zero-Forcing (BZF), and
Bussgang-based Minimum Mean Squared Error (BMMSE) for massive MIMO systems with
one-bit analog-to-digital converters (ADCs). Closed-form expressions of the
proposed receivers are obtained by using the Bussgang decomposition to cope
with the non-linear effect of the one-bit ADCs. Simulation results show
significantly lower bit error rate floors obtained by the proposed receivers
than those of conventional linear receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06690</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06690</id><created>2019-07-15</created><authors><author><keyname>Ge</keyname><forenames>Shihao</forenames></author><author><keyname>Isah</keyname><forenames>Haruna</forenames></author><author><keyname>Zulkernine</keyname><forenames>Farhana</forenames></author><author><keyname>Khan</keyname><forenames>Shahzad</forenames></author></authors><title>A Scalable Framework for Multilevel Streaming Data Analytics using Deep
  Learning</title><categories>eess.SY cs.LG cs.SY</categories><doi>10.1109/COMPSAC.2019.10205</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid growth of data in velocity, volume, value, variety, and veracity
has enabled exciting new opportunities and presented big challenges for
businesses of all types. Recently, there has been considerable interest in
developing systems for processing continuous data streams with the increasing
need for real-time analytics for decision support in the business, healthcare,
manufacturing, and security. The analytics of streaming data usually relies on
the output of offline analytics on static or archived data. However, businesses
and organizations like our industry partner Gnowit, strive to provide their
customers with real time market information and continuously look for a unified
analytics framework that can integrate both streaming and offline analytics in
a seamless fashion to extract knowledge from large volumes of hybrid streaming
data. We present our study on designing a multilevel streaming text data
analytics framework by comparing leading edge scalable open-source,
distributed, and in-memory technologies. We demonstrate the functionality of
the framework for a use case of multilevel text analytics using deep learning
for language understanding and sentiment analysis including data indexing and
query processing. Our framework combines Spark streaming for real time text
processing, the Long Short Term Memory (LSTM) deep learning model for higher
level sentiment analysis, and other tools for SQL-based analytical processing
to provide a scalable solution for multilevel streaming text analytics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06691</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06691</id><created>2019-07-15</created><authors><author><keyname>Ahmed-Ali</keyname><forenames>Tarek</forenames></author><author><keyname>Karafyllis</keyname><forenames>Iasson</forenames></author><author><keyname>Giri</keyname><forenames>Fouad</forenames></author></authors><title>Sampled-Data Observers for Delay Systems and Hyperbolic PDE-ODE Loops</title><categories>math.OC cs.SY eess.SY</categories><comments>32 pages, submitted for possible publication to SIAM Journal on
  Control and Optimization</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of designing sampled-data observers and
observer-based, sampled-data, output feedback stabilizers for systems with both
discrete and distributed, state and output time-delays. The obtained results
can be applied to time delay systems of strict-feedback structure, transport
Partial Differential Equations (PDEs) with nonlocal terms, and feedback
interconnections of Ordinary Differential Equations with a transport PDE. The
proposed design approach consists in exploiting an existing observer, which
features robust exponential convergence of the error when continuous-time
output measurements are available. The observer is then modified, mainly by
adding an inter-sample output predictor, to compensate for the effect of
data-sampling. Using Lyapunov stability tools and small-gain analysis, we show
that robust exponential stability of the error is preserved, provided the
sampling period is not too large. The general result is illustrated with
different examples including state observation and output-feedback
stabilization of a chemical reactor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06727</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06727</id><created>2019-07-15</created><authors><author><keyname>Liu</keyname><forenames>Tairan</forenames></author><author><keyname>Wei</keyname><forenames>Zhensong</forenames></author><author><keyname>Rivenson</keyname><forenames>Yair</forenames></author><author><keyname>de Haan</keyname><forenames>Kevin</forenames></author><author><keyname>Zhang</keyname><forenames>Yibo</forenames></author><author><keyname>Wu</keyname><forenames>Yichen</forenames></author><author><keyname>Ozcan</keyname><forenames>Aydogan</forenames></author></authors><title>Deep learning-based color holographic microscopy</title><categories>eess.IV cs.CV cs.LG physics.optics</categories><comments>25 pages, 8 Figures, 2 Tables</comments><msc-class>68T01, 68T05, 68U10, 62M45, 78M32, 92C55, 94A08</msc-class><acm-class>I.2; I.2.1; I.2.6; I.2.10; I.4.5; I.4.9</acm-class><journal-ref>Journal of Biophotonics (2019)</journal-ref><doi>10.1002/jbio.201900107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a framework based on a generative adversarial network (GAN) that
performs high-fidelity color image reconstruction using a single hologram of a
sample that is illuminated simultaneously by light at three different
wavelengths. The trained network learns to eliminate missing-phase-related
artifacts, and generates an accurate color transformation for the reconstructed
image. Our framework is experimentally demonstrated using lung and prostate
tissue sections that are labeled with different histological stains. This
framework is envisaged to be applicable to point-of-care histopathology, and
presents a significant improvement in the throughput of coherent microscopy
systems given that only a single hologram of the specimen is required for
accurate color imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06747</identifier>
 <datestamp>2020-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06747</id><created>2019-07-15</created><updated>2020-01-29</updated><authors><author><keyname>Bu</keyname><forenames>Fankun</forenames></author><author><keyname>Dehghanpour</keyname><forenames>Kaveh</forenames></author><author><keyname>Yuan</keyname><forenames>Yuxuan</forenames></author><author><keyname>Wang</keyname><forenames>Zhaoyu</forenames></author><author><keyname>Zhang</keyname><forenames>Yingchen</forenames></author></authors><title>A Data-Driven Game-Theoretic Approach for Behind-the-Meter PV Generation
  Disaggregation</title><categories>eess.SP</categories><doi>10.1109/TPWRS.2020.2966732</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rooftop solar photovoltaic (PV) power generator is a widely used distributed
energy resource (DER) in distribution systems. Currently, the majority of PVs
are installed behind-the-meter (BTM), where only customers' net demand is
recorded by smart meters. Disaggregating BTM PV generation from net demand is
critical to utilities for enhancing grid-edge observability. In this paper, a
data-driven approach is proposed for BTM PV generation disaggregation using
solar and demand exemplars. First, a data clustering procedure is developed to
construct a library of candidate load/solar exemplars. To handle the volatility
of BTM resources, a novel game-theoretic learning process is proposed to
adaptively generate optimal composite exemplars using the constructed library
of candidate exemplars, through repeated evaluation of disaggregation
residuals. Finally, the composite native demand and solar exemplars are
employed to disaggregate solar generation from net demand using a
semi-supervised source separator. The proposed methodology has been verified
using real smart meter data and feeder models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06751</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06751</id><created>2019-07-15</created><updated>2019-07-27</updated><authors><author><keyname>Yue</keyname><forenames>Chengfei</forenames></author><author><keyname>Shen</keyname><forenames>Qiang</forenames></author><author><keyname>Cao</keyname><forenames>Xibin</forenames></author><author><keyname>Wang</keyname><forenames>Feng</forenames></author><author><keyname>Goh</keyname><forenames>Cher Hiang</forenames></author><author><keyname>Lee</keyname><forenames>Tong Heng</forenames></author></authors><title>Development of a General Momentum Exchange Devices Fault Model for
  Spacecraft Fault-Tolerant Control System Design</title><categories>eess.SY cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the mechanism of various faults of momentum exchange
devices. These devices are modeled as a cascade electric motor EM - variable
speed drive VSD system. Considering the mechanical part of the EM and the VSD
system, the potential faults are reviewed and summarized. Thus with a clear
understanding of these potential faults, a general fault model in a cascade
multiplicative structure is established for momentum exchange devices. Based on
this general model, various fault scenarios can be simulated, and the possible
output can be appropriately visualized. In this paper, six types of working
condition are identified and the corresponding fault models are constructed.
Using this fault model, the control responses using reaction wheels and single
gimbal control moment gyros under various fault conditions are demonstrated.
The simulation results show the severities of the faults and demonstrate that
the additive fault is more serious than the multiplicative fault from the
viewpoint of control accuracy. Finally, existing fault-tolerant control
strategies are brief summarized and potential approaches including both passive
and active ones to accommodate gimbal fault of single gimbal control moment
gyro is demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06795</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06795</id><created>2019-07-15</created><authors><author><keyname>Koren</keyname><forenames>Mark</forenames></author><author><keyname>Kochenderfer</keyname><forenames>Mykel</forenames></author></authors><title>Efficient Autonomy Validation in Simulation with Adaptive Stress Testing</title><categories>cs.LG cs.RO cs.SE cs.SY eess.SY stat.ML</categories><comments>Submitted to IEEE ITSC 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the development of autonomous systems such as driverless cars, it is
important to characterize the scenarios that are most likely to result in
failure. Adaptive Stress Testing (AST) provides a way to search for the
most-likely failure scenario as a Markov decision process (MDP). Our previous
work used a deep reinforcement learning (DRL) solver to identify likely failure
scenarios. However, the solver's use of a feed-forward neural network with a
discretized space of possible initial conditions poses two major problems.
First, the system is not treated as a black box, in that it requires analyzing
the internal state of the system, which leads to considerable implementation
complexities. Second, in order to simulate realistic settings, a new instance
of the solver needs to be run for each initial condition. Running a new solver
for each initial condition not only significantly increases the computational
complexity, but also disregards the underlying relationship between similar
initial conditions. We provide a solution to both problems by employing a
recurrent neural network that takes a set of initial conditions from a
continuous space as input. This approach enables robust and efficient detection
of failures because the solution generalizes across the entire space of initial
conditions. By simulating an instance where an autonomous car drives while a
pedestrian is crossing a road, we demonstrate the solver is now capable of
finding solutions for problems that would have previously been intractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06803</identifier>
 <datestamp>2019-07-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06803</id><created>2019-07-15</created><updated>2019-07-19</updated><authors><author><keyname>Aguirre</keyname><forenames>Luis Antonio</forenames></author></authors><title>A Bird's Eye View of Nonlinear System Identification</title><categories>eess.SY cs.SY</categories><comments>62 pages, 15 figures</comments><msc-class>93-02</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This text aims at providing a bird's eye view of system identification with
special attention to nonlinear systems. The driving force is to give a feeling
for the philosophical problems facing those that build mathematical models from
data. Special attention will be given to grey-box approaches in nonlinear
system identification. In this text, grey-box methods use auxiliary information
such as the system steady-state data, possible symmetries, some bifurcations
and the presence of hysteresis. The text ends with a sample of applications. No
attempt is made to be thorough nor to survey such an extensive and mature field
as system identification. In most parts references will be provided for a more
detailed study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06817</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06817</id><created>2019-07-15</created><authors><author><keyname>Sun</keyname><forenames>Linlin</forenames></author><author><keyname>Li</keyname><forenames>Jiayu</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Yuntian</forenames></author><author><keyname>Gui</keyname><forenames>Linqing</forenames></author><author><keyname>Li</keyname><forenames>Fanyuan</forenames></author><author><keyname>Li</keyname><forenames>Haochen</forenames></author><author><keyname>Zhuang</keyname><forenames>Zhihong</forenames></author><author><keyname>Shu</keyname><forenames>Feng</forenames></author></authors><title>Energy-efficient Alternating Iterative Secure Structure of Maximizing
  Secrecy Rate for Directional Modulation Networks</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a directional modulation (DM) network, the issues of security and privacy
have taken on an increasingly important role. Since the power allocation of
confidential message and artificial noise will make a constructive effect on
the system performance, it is important to jointly consider the relationship
between the beamforming vectors and the power allocation (PA) factors. To
maximize the secrecy rate (SR), an alternating iterative structure (AIS)
between the beamforming and PA is proposed. With only two or three iterations,
it can rapidly converge to its rate ceil. Simulation results indicate that the
SR performance of proposed AIS is much better than the null-space projection
(NSP) based PA strategy in the medium and large signal-to-noise ratio (SNR)
regions, especially when the number of antennas at the DM transmitter is small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06823</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06823</id><created>2019-07-15</created><authors><author><keyname>Dargazany</keyname><forenames>Aras R.</forenames></author></authors><title>Stereo-based terrain traversability analysis using normal-based
  segmentation and superpixel surface analysis</title><categories>cs.CV cs.RO eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an stereo-based traversability analysis approach for all
terrains in off-road mobile robotics, e.g. Unmanned Ground Vehicles (UGVs) is
proposed. This approach reformulates the problem of terrain traversability
analysis into two main problems: (1) 3D terrain reconstruction and (2) terrain
all surfaces detection and analysis. The proposed approach is using stereo
camera for perception and 3D reconstruction of the terrain. In order to detect
all the existing surfaces in the 3D reconstructed terrain as superpixel
surfaces (i.e. segments), an image segmentation technique is applied using
geometry-based features (pixel-based surface normals). Having detected all the
surfaces, Superpixel Surface Traversability Analysis approach (SSTA) is applied
on all of the detected surfaces (superpixel segments) in order to classify them
based on their traversability index. The proposed SSTA approach is based on:
(1) Superpixel surface normal and plane estimation, (2) Traversability analysis
using superpixel surface planes. Having analyzed all the superpixel surfaces
based on their traversability, these surfaces are finally classified into five
main categories as following: traversable, semi-traversable, non-traversable,
unknown and undecided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06826</identifier>
 <datestamp>2019-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06826</id><created>2019-07-16</created><updated>2019-08-20</updated><authors><author><keyname>Cao</keyname><forenames>Yulong</forenames></author><author><keyname>Xiao</keyname><forenames>Chaowei</forenames></author><author><keyname>Cyr</keyname><forenames>Benjamin</forenames></author><author><keyname>Zhou</keyname><forenames>Yimeng</forenames></author><author><keyname>Park</keyname><forenames>Won</forenames></author><author><keyname>Rampazzi</keyname><forenames>Sara</forenames></author><author><keyname>Chen</keyname><forenames>Qi Alfred</forenames></author><author><keyname>Fu</keyname><forenames>Kevin</forenames></author><author><keyname>Mao</keyname><forenames>Z. Morley</forenames></author></authors><title>Adversarial Sensor Attack on LiDAR-based Perception in Autonomous
  Driving</title><categories>cs.CR cs.CV eess.SP stat.ML</categories><comments>Accepted at the ACM Conference on Computer and Communications
  Security (CCS), 2019</comments><doi>10.1145/3319535.3339815</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Autonomous Vehicles (AVs), one fundamental pillar is perception, which
leverages sensors like cameras and LiDARs (Light Detection and Ranging) to
understand the driving environment. Due to its direct impact on road safety,
multiple prior efforts have been made to study its the security of perception
systems. In contrast to prior work that concentrates on camera-based
perception, in this work we perform the first security study of LiDAR-based
perception in AV settings, which is highly important but unexplored. We
consider LiDAR spoofing attacks as the threat model and set the attack goal as
spoofing obstacles close to the front of a victim AV. We find that blindly
applying LiDAR spoofing is insufficient to achieve this goal due to the machine
learning-based object detection process. Thus, we then explore the possibility
of strategically controlling the spoofed attack to fool the machine learning
model. We formulate this task as an optimization problem and design modeling
methods for the input perturbation function and the objective function. We also
identify the inherent limitations of directly solving the problem using
optimization and design an algorithm that combines optimization and global
sampling, which improves the attack success rates to around 75%. As a case
study to understand the attack impact at the AV driving decision level, we
construct and evaluate two attack scenarios that may damage road safety and
mobility. We also discuss defense directions at the AV system, sensor, and
machine learning model levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06834</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06834</id><created>2019-07-16</created><updated>2019-12-29</updated><authors><author><keyname>Lee</keyname><forenames>Chang Sik</forenames></author><author><keyname>Yu</keyname><forenames>Hyeong Geun</forenames></author><author><keyname>Park</keyname><forenames>Dong Jo</forenames></author><author><keyname>Chang</keyname><forenames>Dong Eui</forenames></author><author><keyname>Nam</keyname><forenames>Hyunwoo</forenames></author><author><keyname>Park</keyname><forenames>Byeong Hwang</forenames></author></authors><title>Noise Removal of FTIR Hyperspectral Images via MMSE</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fourier transform infrared (FTIR) hyperspectral imaging systems are deployed
in various fields where spectral information is exploited. Chemical warfare
agent (CWA) detection is one of such fields and it requires a fast and accurate
process from the measurement to the visualization of detection results,
including noise removal. A general concern of existing noise removal algorithms
is a trade-off between time and performance. This paper suggests a minimum mean
square error (MMSE) approach as an efficient noise removal algorithm for FTIR
hyperspectral images. The experimental result shows that the MMSE estimator
spends less time to achieve comparable performance to the existing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06838</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06838</id><created>2019-07-16</created><authors><author><keyname>Wang</keyname><forenames>Tianqi</forenames></author><author><keyname>Chang</keyname><forenames>Dong Eui</forenames></author></authors><title>Improved Reinforcement Learning through Imitation Learning Pretraining
  Towards Image-based Autonomous Driving</title><categories>cs.LG cs.AI cs.CV eess.IV</categories><comments>5 pages, 2019 19th International Conference on Control, Automation
  and Systems (ICCAS 2019)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a training pipeline for the autonomous driving task given the
current camera image and vehicle speed as the input to produce the throttle,
brake, and steering control output. The simulator Airsim's convenient weather
and lighting API provides a sufficient diversity during training which can be
very helpful to increase the trained policy's robustness. In order to not limit
the possible policy's performance, we use a continuous and deterministic
control policy setting. We utilize ResNet-34 as our actor and critic networks
with some slight changes in the fully connected layers. Considering human's
mastery of this task and the high-complexity nature of this task, we first use
imitation learning to mimic the given human policy and leverage the trained
policy and its weights to the reinforcement learning phase for which we use
DDPG. This combination shows a considerable performance boost comparing to both
pure imitation learning and pure DDPG for the autonomous driving task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06844</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06844</id><created>2019-07-16</created><authors><author><keyname>Liu</keyname><forenames>Liangchen</forenames></author><author><keyname>Zhang</keyname><forenames>Teng</forenames></author><author><keyname>Zhao</keyname><forenames>Kun</forenames></author><author><keyname>Wiliem</keyname><forenames>Arnold</forenames></author><author><keyname>Astin-Walmsley</keyname><forenames>Kieren</forenames></author><author><keyname>Lovell</keyname><forenames>Brian</forenames></author></authors><title>Deep inspection: an electrical distribution pole parts study via deep
  neural networks</title><categories>cs.CV eess.IV</categories><comments>electrical distribution pole inspection, integrated inspection
  system, object detection, imbalanced data classification, To appear in
  Proceeding of ICIP 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electrical distribution poles are important assets in electricity supply.
These poles need to be maintained in good condition to ensure they protect
community safety, maintain reliability of supply, and meet legislative
obligations. However, maintaining such a large volumes of assets is an
expensive and challenging task. To address this, recent approaches utilise
imagery data captured from helicopter and/or drone inspections. Whilst reducing
the cost for manual inspection, manual analysis on each image is still
required. As such, several image-based automated inspection systems have been
proposed. In this paper, we target two major challenges: tiny object detection
and extremely imbalanced datasets, which currently hinder the wide deployment
of the automatic inspection. We propose a novel two-stage zoom-in detection
method to gradually focus on the object of interest. To address the imbalanced
dataset problem, we propose the resampling as well as reweighting schemes to
iteratively adapt the model to the large intra-class variation of major class
and balance the contributions to the loss from each class. Finally, we
integrate these components together and devise a novel automatic inspection
framework. Extensive experiments demonstrate that our proposed approaches are
effective and can boost the performance compared to the baseline methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06846</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06846</id><created>2019-07-16</created><authors><author><keyname>Thakallapelli</keyname><forenames>Abilash</forenames></author><author><keyname>Hossain</keyname><forenames>S J</forenames></author><author><keyname>Kamalasadan</keyname><forenames>Sukumar</forenames></author></authors><title>Coherency and Online Signal Selection Based Wide Area Control of Wind
  Integrated Power Grid</title><categories>eess.SY cs.SY</categories><journal-ref>IEEE Trans. on Industrial Applications, Volume: 54, No: 4, pp.
  3712 - 3722, Mar. 2018</journal-ref><doi>10.1109/TIA.2018.2814561</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel method of designing wide area control (WAC)
based on a discrete linear quadratic regulator and Kalman filtering based
state-estimation that can be applied for real-time damping of interarea
oscillations of wind integrated power grid. The main advantages of the proposed
method are that the architecture provides online coherency grouping that
properly characterizes real-time changes in the power grid and online wide-area
signal selection based on residue method for proper selection of the WAC
signals. The proposed architecture can, thus, accurately monitors changes in
the power grid and select the appropriate control signal for more effectively
damping the interarea oscillation when compared to the conventional local
signal based power system stabilizers or offline based WAC designs. The
architecture is tested on a wind integrated two-area system and the IEEE 39 bus
system in order to show the capability of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06852</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06852</id><created>2019-07-16</created><authors><author><keyname>Qin</keyname><forenames>Yulei</forenames></author><author><keyname>Chen</keyname><forenames>Mingjian</forenames></author><author><keyname>Zheng</keyname><forenames>Hao</forenames></author><author><keyname>Gu</keyname><forenames>Yun</forenames></author><author><keyname>Shen</keyname><forenames>Mali</forenames></author><author><keyname>Yang</keyname><forenames>Jie</forenames></author><author><keyname>Huang</keyname><forenames>Xiaolin</forenames></author><author><keyname>Zhu</keyname><forenames>Yue-Min</forenames></author><author><keyname>Yang</keyname><forenames>Guang-Zhong</forenames></author></authors><title>AirwayNet: A Voxel-Connectivity Aware Approach for Accurate Airway
  Segmentation Using Convolutional Neural Networks</title><categories>eess.IV cs.CV</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Airway segmentation on CT scans is critical for pulmonary disease diagnosis
and endobronchial navigation. Manual extraction of airway requires strenuous
efforts due to the complicated structure and various appearance of airway. For
automatic airway extraction, convolutional neural networks (CNNs) based methods
have recently become the state-of-the-art approach. However, there still
remains a challenge for CNNs to perceive the tree-like pattern and comprehend
the connectivity of airway. To address this, we propose a voxel-connectivity
aware approach named AirwayNet for accurate airway segmentation. By
connectivity modeling, conventional binary segmentation task is transformed
into 26 tasks of connectivity prediction. Thus, our AirwayNet learns both
airway structure and relationship between neighboring voxels. To take advantage
of context knowledge, lung distance map and voxel coordinates are fed into
AirwayNet as additional semantic information. Compared to existing approaches,
AirwayNet achieved superior performance, demonstrating the effectiveness of the
network's awareness of voxel connectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06859</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06859</id><created>2019-07-16</created><authors><author><keyname>Dhawan</keyname><forenames>Kunal</forenames></author><author><keyname>Vaz</keyname><forenames>Colin</forenames></author><author><keyname>Travadi</keyname><forenames>Ruchir</forenames></author><author><keyname>Narayanan</keyname><forenames>Shrikanth</forenames></author></authors><title>Towards Adapting NMF Dictionaries Using Total Variability Modeling for
  Noise-Robust Acoustic Features</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an algorithm to extract noise-robust acoustic features from noisy
speech. We use Total Variability Modeling in combination with Non-negative
Matrix Factorization (NMF) to learn a total variability subspace and adapt NMF
dictionaries for each utterance. Unlike several other approaches for extracting
noise-robust features, our algorithm does not require a training corpus of
parallel clean and noisy speech. Furthermore, the proposed features are
produced by an utterance-specific transform, allowing the features to be robust
to the noise occurring in each utterance. Preliminary results on the Aurora 4 +
DEMAND noise corpus show that our proposed features perform comparably to
baseline acoustic features, including features calculated from a convolutive
NMF (CNMF) model. Moreover, on unseen noises, our proposed features gives the
most similar word error rate to clean speech compared to the baseline features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06876</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06876</id><created>2019-07-16</created><authors><author><keyname>Pfeuffer</keyname><forenames>Andreas</forenames></author><author><keyname>Dietmayer</keyname><forenames>Klaus</forenames></author></authors><title>Separable Convolutional LSTMs for Faster Video Segmentation</title><categories>cs.CV eess.IV</categories><journal-ref>2019 22st International Conference on Intelligent Transportation
  Systems (ITSC)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic Segmentation is an important module for autonomous robots such as
self-driving cars. The advantage of video segmentation approaches compared to
single image segmentation is that temporal image information is considered, and
their performance increases due to this. Hence, single image segmentation
approaches are extended by recurrent units such as convolutional LSTM
(convLSTM) cells, which are placed at suitable positions in the basic network
architecture. However, a major critique of video segmentation approaches based
on recurrent neural networks is their large parameter count and their
computational complexity, and so, their inference time of one video frame takes
up to 66 percent longer than their basic version. Inspired by the success of
the spatial and depthwise separable convolutional neural networks, we
generalize these techniques for convLSTMs in this work, so that the number of
parameters and the required FLOPs are reduced significantly. Experiments on
different datasets show that the segmentation approaches using the proposed,
modified convLSTM cells achieve similar or slightly worse accuracy, but are up
to 15 percent faster on a GPU than the ones using the standard convLSTM cells.
Furthermore, a new evaluation metric is introduced, which measures the amount
of flickering pixels in the segmented video sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06884</identifier>
 <datestamp>2019-09-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06884</id><created>2019-07-16</created><updated>2019-09-05</updated><authors><author><keyname>Xing</keyname><forenames>Xiaowei</forenames></author><author><keyname>Chang</keyname><forenames>Dong Eui</forenames></author></authors><title>Deep Reinforcement Learning Based Robot Arm Manipulation with Efficient
  Training Data through Simulation</title><categories>cs.RO cs.SY eess.SY</categories><comments>Appearing in The 19th International Conference on Control, Automation
  and Systems, Jeju, Korea, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep reinforcement learning trains neural networks using experiences sampled
from the replay buffer, which is commonly updated at each time step. In this
paper, we propose a method to update the replay buffer adaptively and
selectively to train a robot arm to accomplish a suction task in simulation.
The response time of the agent is thoroughly taken into account. The state
transitions that remain stuck at the boundary of constraint are not stored. The
policy trained with our method works better than the one with the common replay
buffer update method. The result is demonstrated both by simulation and by
experiment with a real robot arm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06930</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06930</id><created>2019-07-16</created><authors><author><keyname>Kettner</keyname><forenames>Andreas Martin</forenames></author><author><keyname>Paolone</keyname><forenames>Mario</forenames></author></authors><title>Performance Assessment of Kron Reduction in the Numerical Analysis of
  Polyphase Power Systems</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the impact of Kron reduction on the performance of
numerical methods applied to the analysis of unbalanced polyphase power
systems. Specifically, this paper focuses on power-flow study, state
estimation, and voltage stability assessment. For these applications, the
standard Newton-Raphson method, linear weighted-least-squares regression, and
homotopy continuation method are used, respectively. The performance of the
said numerical methods is assessed in a series of simulations, in which the
zero-injection nodes of a test system are successively eliminated through Kron
reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06943</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06943</id><created>2019-07-16</created><authors><author><keyname>O'Toole</keyname><forenames>John M.</forenames></author><author><keyname>Boylan</keyname><forenames>Geraldine B.</forenames></author></authors><title>Machine learning without a feature set for detecting bursts in the EEG
  of preterm infants</title><categories>eess.SP cs.LG physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks enable learning directly on the data without the domain
knowledge needed to construct a feature set. This approach has been extremely
successful in almost all machine learning applications. We propose a new
framework that also learns directly from the data, without extracting a feature
set. We apply this framework to detecting bursts in the EEG of premature
infants. The EEG is recorded within days of birth in a cohort of infants
without significant brain injury and born &lt;30 weeks of gestation. The method
first transforms the time-domain signal to the time--frequency domain and then
trains a machine learning method, a gradient boosting machine, on each
time-slice of the time--frequency distribution. We control for oversampling the
time--frequency distribution with a significant reduction (&lt;1%) in memory and
computational complexity. The proposed method achieves similar accuracy to an
existing multi-feature approach: area under the characteristic curve of 0.98
(with 95% confidence interval of 0.96 to 0.99), with a median sensitivity of
95% and median specificity of 94%. The proposed framework presents an accurate,
simple, and computational efficient implementation as an alternative to both
the deep learning approach and to the manual generation of a feature set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06959</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06959</id><created>2019-05-07</created><authors><author><keyname>Moussilli</keyname><forenames>Mariam M.</forenames></author><author><keyname>Falou</keyname><forenames>Abdul Rahman El</forenames></author><author><keyname>Shubair</keyname><forenames>Raed M.</forenames></author></authors><title>Exploring Graphene Effect on Fiber Optic Surface Plasmon Resonance
  Biosensor</title><categories>physics.app-ph eess.SP</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report investigates design enhancements of Fiber Optic Surface Plasmon
Resonance (FO-SPR) biosensors with Gold and Silver metallic films. The effect
of adding a Graphene coating on the sensitivity and detection accuracy of
FO-SPR biosensors is studied. We also compare the results for the addition of
five layers of Graphene on both Gold-based and Silver-based FO-SPR biosensors
in order to determine the optimum sensor design. Our results indicate that the
sensitivity of the biosensor increases when a Graphene coating is added, while
the detection accuracy decreases. Results also demonstrate that the sensitivity
due to adding Graphene sheets increases more for Silver-based biosensor when
compared to Gold-based biosensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06972</identifier>
 <datestamp>2019-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06972</id><created>2019-07-16</created><updated>2019-09-24</updated><authors><author><keyname>Garc&#xed;a-Cerezo</keyname><forenames>&#xc1;lvaro</forenames></author><author><keyname>Baringo</keyname><forenames>Luis</forenames></author></authors><title>Representative Days for Expansion Decisions in Power Systems</title><categories>math.OC cs.SY eess.SY</categories><comments>36 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short-term uncertainty should be properly modeled when the expansion planning
problem in a power system is analyzed. Since the use of all available
historical data may lead to intractability, clustering algorithms should be
applied in order to reduce computer workload without renouncing accuracy
representation of historical data. In this paper, we propose a modified version
of the traditional K-means method that seeks to attain the representation of
maximum and minimum values of input data, namely, the electric load and the
renewable production in several locations of an electric energy system. The
crucial role of depicting extreme values of these parameters lies in the fact
that they can have a great impact on the expansion and operation decisions
taken. The proposed method is based on the traditional K-means algorithm that
represents the correlation between electric load and wind-power production.
Chronology of historical data, which influences the performance of some
technologies, is characterized though representative days, each one composed of
24 operating conditions. A realistic case study based on the generation and
transmission expansion planning of the IEEE 24-bus Reliability Test System is
analyzed applying representative days and comparing the results obtained using
the traditional K-means technique and the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06989</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.06989</id><created>2019-07-16</created><authors><author><keyname>Rill</keyname><forenames>R&#xf3;bert-Adrian</forenames></author></authors><title>Speed estimation evaluation on the KITTI benchmark based on motion and
  monocular depth information</title><categories>cs.CV eess.IV</categories><comments>technical report with 16 pages, 3 figures, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this technical report we investigate speed estimation of the ego-vehicle
on the KITTI benchmark using state-of-the-art deep neural network based optical
flow and single-view depth prediction methods. Using a straightforward
intuitive approach and approximating a single scale factor, we evaluate several
application schemes of the deep networks and formulate meaningful conclusions
such as: combining depth information with optical flow improves speed
estimation accuracy as opposed to using optical flow alone; the quality of the
deep neural network methods influences speed estimation performance; using the
depth and optical flow results from smaller crops of wide images degrades
performance. With these observations in mind, we achieve a RMSE of less than 1
m/s for vehicle speed estimation using monocular images as input from
recordings of the KITTI benchmark. Limitations and possible future directions
are discussed as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07000</identifier>
 <datestamp>2020-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07000</id><created>2019-07-16</created><updated>2019-12-30</updated><authors><author><keyname>Qi</keyname><forenames>Kehan</forenames></author><author><keyname>Yang</keyname><forenames>Hao</forenames></author><author><keyname>Li</keyname><forenames>Cheng</forenames></author><author><keyname>Liu</keyname><forenames>Zaiyi</forenames></author><author><keyname>Wang</keyname><forenames>Meiyun</forenames></author><author><keyname>Liu</keyname><forenames>Qiegen</forenames></author><author><keyname>Wang</keyname><forenames>Shanshan</forenames></author></authors><title>X-Net: Brain Stroke Lesion Segmentation Based on Depthwise Separable
  Convolution and Long-range Dependencies</title><categories>eess.IV cs.CV</categories><comments>MICCAI 2019</comments><doi>10.1007/978-3-030-32248-9_28</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The morbidity of brain stroke increased rapidly in the past few years. To
help specialists in lesion measurements and treatment planning, automatic
segmentation methods are critically required for clinical practices. Recently,
approaches based on deep learning and methods for contextual information
extraction have served in many image segmentation tasks. However, their
performances are limited due to the insufficient training of a large number of
parameters, which sometimes fail in capturing long-range dependencies. To
address these issues, we propose a depthwise separable convolution based X-Net
that designs a nonlocal operation namely Feature Similarity Module (FSM) to
capture long-range dependencies. The adopted depthwise convolution allows to
reduce the network size, while the developed FSM provides a more effective,
dense contextual information extraction and thus facilitates better
segmentation. The effectiveness of X-Net was evaluated on an open dataset
Anatomical Tracings of Lesions After Stroke (ATLAS) with superior performance
achieved compared to other six state-of-the-art approaches. We make our code
and models available at https://github.com/Andrewsher/X-Net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07008</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07008</id><created>2019-07-16</created><updated>2019-07-16</updated><authors><author><keyname>Yang</keyname><forenames>Hao</forenames></author><author><keyname>Huang</keyname><forenames>Weijian</forenames></author><author><keyname>Qi</keyname><forenames>Kehan</forenames></author><author><keyname>Li</keyname><forenames>Cheng</forenames></author><author><keyname>Liu</keyname><forenames>Xinfeng</forenames></author><author><keyname>Wang</keyname><forenames>Meiyun</forenames></author><author><keyname>Zheng</keyname><forenames>Hairong</forenames></author><author><keyname>Wang</keyname><forenames>Shanshan</forenames></author></authors><title>CLCI-Net: Cross-Level fusion and Context Inference Networks for Lesion
  Segmentation of Chronic Stroke</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmenting stroke lesions from T1-weighted MR images is of great value for
large-scale stroke rehabilitation neuroimaging analyses. Nevertheless, there
are great challenges with this task, such as large range of stroke lesion
scales and the tissue intensity similarity. The famous encoder-decoder
convolutional neural network, which although has made great achievements in
medical image segmentation areas, may fail to address these challenges due to
the insufficient uses of multi-scale features and context information. To
address these challenges, this paper proposes a Cross-Level fusion and Context
Inference Network (CLCI-Net) for the chronic stroke lesion segmentation from
T1-weighted MR images. Specifically, a Cross-Level feature Fusion (CLF)
strategy was developed to make full use of different scale features across
different levels; Extending Atrous Spatial Pyramid Pooling (ASPP) with CLF, we
have enriched multi-scale features to handle the different lesion sizes; In
addition, convolutional long short-term memory (ConvLSTM) is employed to infer
context information and thus capture fine structures to address the intensity
similarity issue. The proposed approach was evaluated on an open-source
dataset, the Anatomical Tracings of Lesions After Stroke (ATLAS) with the
results showing that our network outperforms five state-of-the-art methods. We
make our code and models available at https://github.com/YH0517/CLCI_Net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07018</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07018</id><created>2019-07-16</created><authors><author><keyname>Zoppi</keyname><forenames>Samuele</forenames></author><author><keyname>Soleymani</keyname><forenames>Touraj</forenames></author><author><keyname>Kl&#xfc;gel</keyname><forenames>Markus</forenames></author><author><keyname>Vilgelm</keyname><forenames>Mikhail</forenames></author><author><keyname>Hirche</keyname><forenames>Sandra</forenames></author><author><keyname>Kellerer</keyname><forenames>Wolfgang</forenames></author></authors><title>Transmission Power Control for Remote State Estimation in Industrial
  Wireless Sensor Networks</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Novel low-power wireless technologies and IoT applications open the door to
the Industrial Internet of Things (IIoT). In this new paradigm, Wireless Sensor
Networks (WSNs) must fulfil, despite energy and transmission power limitations,
the challenging communication requirements of advanced manufacturing processes
and technologies. In industrial networks, this is possible thanks to the
availability of network infrastructure and the presence of a network
coordinator that efficiently allocates the available radio resources. In this
work, we consider a WSN that simultaneously transmits measurements of Networked
Control Systems' (NCSs) dynamics to remote state estimators over a shared
packet-erasure channel. We develop a minimum transmission power control (TPC)
policy for the coordination of the wireless medium by formulating an infinite
horizon Markov decision process (MDP) optimization problem. We compute the
policy using an approximate value iteration algorithm and provide an extensive
evaluation of its parameters in different interference scenarios and NCSs
dynamics. The evaluation results present a comprehensive characterization of
the algorithm's performance, proving that it can flexibly adapt to arbitrary
use cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07035</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07035</id><created>2019-07-16</created><authors><author><keyname>Melchior</keyname><forenames>Silvan</forenames></author><author><keyname>Berkenkamp</keyname><forenames>Felix</forenames></author><author><keyname>Curi</keyname><forenames>Sebastian</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author></authors><title>Structured Variational Inference in Unstable Gaussian Process State
  Space Models</title><categories>cs.LG cs.SY eess.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian processes are expressive, non-parametric statistical models that are
well-suited to learn nonlinear dynamical systems. However, large-scale
inference in these state space models is a challenging problem. In this paper,
we propose CBF-SSM a scalable model that employs a structured variational
approximation to maintain temporal correlations. In contrast to prior work, our
approach applies to the important class of unstable systems, where state
uncertainty grows unbounded over time. For these systems, our method contains a
probabilistic, model-based backward pass that infers latent states during
training. We demonstrate state-of-the-art performance in our experiments.
Moreover, we show that CBF-SSM can be combined with physical models in the form
of ordinary differential equations to learn a reliable model of a physical
flying robotic vehicle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07077</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07077</id><created>2019-07-16</created><authors><author><keyname>Bert&#xf2;</keyname><forenames>Giulia</forenames></author><author><keyname>Avesani</keyname><forenames>Paolo</forenames></author><author><keyname>Pestilli</keyname><forenames>Franco</forenames></author><author><keyname>Bullock</keyname><forenames>Daniel</forenames></author><author><keyname>Caron</keyname><forenames>Bradley</forenames></author><author><keyname>Olivetti</keyname><forenames>Emanuele</forenames></author></authors><title>Anatomically-Informed Multiple Linear Assignment Problems for White
  Matter Bundle Segmentation</title><categories>eess.IV cs.CV</categories><journal-ref>2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI
  2019)</journal-ref><doi>10.1109/ISBI.2019.8759174</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmenting white matter bundles from human tractograms is a task of interest
for several applications. Current methods for bundle segmentation consider
either only prior knowledge about the relative anatomical position of a bundle,
or only its geometrical properties. Our aim is to improve the results of
segmentation by proposing a method that takes into account information about
both the underlying anatomy and the geometry of bundles at the same time. To
achieve this goal, we extend a state-of-the-art example-based method based on
the Linear Assignment Problem (LAP) by including prior anatomical information
within the optimization process. The proposed method shows a significant
improvement with respect to the original method, in particular on small
bundles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07083</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07083</id><created>2019-07-11</created><authors><author><keyname>Safi</keyname><forenames>Hossein</forenames></author><author><keyname>Montazeri</keyname><forenames>A. M</forenames></author><author><keyname>Rostampoor</keyname><forenames>Javane</forenames></author><author><keyname>Parsaeefard</keyname><forenames>Saeedeh</forenames></author></authors><title>Spectrum Sensing and Resource Allocation for 5G Heterogeneous Cloud
  Radio Access Networks</title><categories>eess.SP math.OC</categories><comments>31 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of opportunistic spectrum sharing for the next
generation of wireless systems empowered by the cloud radio access network
(C-RAN) is studied. More precisely, low-priority users employ cooperative
spectrum sensing to detect a vacant portion of the spectrum that is not
currently used by high-priority users. The design of the scheme is to maximize
the overall throughput of the low-priority users while guaranteeing the quality
of service of the high-priority users. This objective is attained by optimally
adjusting spectrum sensing time with respect to imposed target probabilities of
detection and false alarm as well as dynamically allocating and assigning C-RAN
resources, i.e., transmit powers, sub-carriers, remote radio heads (RRHs), and
base-band units. The presented optimization problem is non-convex and NP-hard
that is extremely hard to tackle directly. To solve the problem, a low-complex
iterative approach is proposed in which sensing time, user association
parameters and transmit powers of RRHs are alternatively assigned and optimized
at every step. Numerical results are then provided to demonstrate the necessity
of performing sensing time adjustment in such systems as well as balancing the
sensing-throughput tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07091</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07091</id><created>2019-07-16</created><authors><author><keyname>Jacobsson</keyname><forenames>Sven</forenames></author><author><keyname>Aabel</keyname><forenames>Lise</forenames></author><author><keyname>Coldrey</keyname><forenames>Mikael</forenames></author><author><keyname>Sezgin</keyname><forenames>Ibrahim Can</forenames></author><author><keyname>Fager</keyname><forenames>Christian</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>Massive MU-MIMO-OFDM Uplink with Direct RF-Sampling and 1-Bit ADCs</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advances in analog-to-digital converter (ADC) technology have opened up the
possibility to directly digitize wideband radio frequency (RF) signals,
avoiding the need for analog down-conversion. In this work, we consider an
orthogonal frequency-division multiplexing (OFDM)-based massive multi-user (MU)
multiple-input multiple-output (MIMO) uplink system that relies on direct
RF-sampling at the base station and digitizes the received RF signals with
1-bit ADCs. Using Bussgang's theorem, we provide an analytical expression for
the error-vector magnitude (EVM) achieved by digital down-conversion and
zero-forcing combining. Our results demonstrate that direct RF-sampling 1-bit
ADCs enables low EVM and supports high-order constellations in the massive
MU-MIMO-OFDM uplink.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07103</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07103</id><created>2019-07-15</created><authors><author><keyname>Barbier</keyname><forenames>Jean</forenames></author></authors><title>Concentration of the matrix-valued minimum mean-square error in optimal
  Bayesian inference</title><categories>cs.IT cs.LG eess.SP math.IT math.PR</categories><comments>arXiv admin note: text overlap with arXiv:1904.02808</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Bayesian inference of signals with vector-valued entries.
Extending concentration techniques from the mathematical physics of spin
glasses, we show that the matrix-valued minimum mean-square error concentrates
when the size of the problem increases. Such results are often crucial for
proving single-letter formulas for the mutual information when they exist. Our
proof is valid in the optimal Bayesian inference setting, meaning that it
relies on the assumption that the model and all its hyper-parameters are known.
Examples of inference and learning problems covered by our results are spiked
matrix and tensor models, the committee machine neural network with few hidden
neurons in the teacher-student scenario, or multi-layers generalized linear
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07127</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07127</id><created>2019-07-13</created><authors><author><keyname>Zeinali</keyname><forenames>Hossein</forenames></author><author><keyname>Burget</keyname><forenames>Luk&#xe1;&#x161;</forenames></author><author><keyname>&#x10c;ernock&#xfd;</keyname><forenames>Jan &quot;Honza''</forenames></author></authors><title>Acoustic Scene Classification Using Fusion of Attentive Convolutional
  Neural Networks for DCASE2019 Challenge</title><categories>eess.AS cs.SD</categories><comments>arXiv admin note: text overlap with arXiv:1810.04273</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, the Brno University of Technology (BUT) team submissions for
Task 1 (Acoustic Scene Classification, ASC) of the DCASE-2019 challenge are
described. Also, the analysis of different methods is provided. The proposed
approach is a fusion of three different Convolutional Neural Network (CNN)
topologies. The first one is a VGG like two-dimensional CNNs. The second one is
again a two-dimensional CNN network which uses Max-Feature-Map activation and
called Light-CNN (LCNN). The third network is a one-dimensional CNN which
mainly used for speaker verification and called x-vector topology. All proposed
networks use self-attention mechanism for statistic pooling. As a feature, we
use a 256-dimensional log Mel-spectrogram. Our submissions are a fusion of
several networks trained on 4-folds generated evaluation setup using different
fusion strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07131</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07131</id><created>2019-07-15</created><updated>2019-07-26</updated><authors><author><keyname>Da Wang</keyname><forenames>Ying</forenames></author><author><keyname>Armstrong</keyname><forenames>Ryan T.</forenames></author><author><keyname>Mostaghimi</keyname><forenames>Peyman</forenames></author></authors><title>Boosting Resolution and Recovering Texture of micro-CT Images with Deep
  Learning</title><categories>eess.IV cs.CV cs.LG stat.ML</categories><comments>\keywords{Digital Rock Imaging \and Super Resolution \and
  Convolutional Neural Networks \and Generative Adversarial Networks}</comments><doi>10.1029/2019WR026052</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital Rock Imaging is constrained by detector hardware, and a trade-off
between the image field of view (FOV) and the image resolution must be made.
This can be compensated for with super resolution (SR) techniques that take a
wide FOV, low resolution (LR) image, and super resolve a high resolution (HR),
high FOV image. The Enhanced Deep Super Resolution Generative Adversarial
Network (EDSRGAN) is trained on the Deep Learning Digital Rock Super Resolution
Dataset, a diverse compilation 12000 of raw and processed uCT images. The
network shows comparable performance of 50% to 70% reduction in relative error
over bicubic interpolation. GAN performance in recovering texture shows
superior visual similarity compared to SRCNN and other methods. Difference maps
indicate that the SRCNN section of the SRGAN network recovers large scale edge
(grain boundaries) features while the GAN network regenerates perceptually
indistinguishable high frequency texture. Network performance is generalised
with augmentation, showing high adaptability to noise and blur. HR images are
fed into the network, generating HR-SR images to extrapolate network
performance to sub-resolution features present in the HR images themselves.
Results show that under-resolution features such as dissolved minerals and thin
fractures are regenerated despite the network operating outside of trained
specifications. Comparison with Scanning Electron Microscope images shows
details are consistent with the underlying geometry of the sample. Recovery of
textures benefits the characterisation of digital rocks with a high proportion
of under-resolution micro-porous features, such as carbonate and coal samples.
Images that are normally constrained by the mineralogy of the rock (coal), by
fast transient imaging (waterflooding), or by the energy of the source
(microporosity), can be super resolved accurately for further analysis
downstream.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07136</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07136</id><created>2019-07-10</created><authors><author><keyname>Sarajli&#x107;</keyname><forenames>Muris</forenames></author><author><keyname>Liu</keyname><forenames>Liang</forenames></author><author><keyname>Sj&#xf6;land</keyname><forenames>Henrik</forenames></author><author><keyname>Edfors</keyname><forenames>Ove</forenames></author></authors><title>Low Power Receiver Front Ends: Scaling Laws and Applications</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we combine communication-theoretic laws with known,
practically verified results from circuit theory. As a result, we obtain
closed-form theoretical expressions linking fundamental system design and
environment parameters with the power consumption of analog front ends for
communication receivers. This collection of scaling laws and bounds is meant to
serve as a theoretical reference for practical low power front end design. In
one set of results, we first find that the front end power consumption scales
at least as SNDR^3/2 if environment parameters (fading and blocker levels) are
static. The obtained scaling law is subsequently used to derive relations
between front end power consumption and several other important communication
system parameters, namely, digital modulation constellation size, symbol error
probability, error control coding gain and coding rate. Such relations, in
turn, can be used when deciding which system design strategies to adopt for
low-power applications. For example, if error control coding is employed, the
most energy-efficient strategy for the entire receiver is to use codes with
moderate coding gain and simple decoding algorithms, such as convolutional
codes. In another collection of results, we find how front end power scales
with environment parameters if the performance is kept constant. This yields
bounds on average power reduction of receivers that adapt to the communication
environment. For instance, if a receiver front end adapts to fading
fluctuations while keeping the performance above some given minimum
requirement, power can theoretically be reduced at least 20x compared to a
non-adaptive front end.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07158</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07158</id><created>2019-07-16</created><authors><author><keyname>Sekander</keyname><forenames>Silvia</forenames></author><author><keyname>Tabassum</keyname><forenames>Hina</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author></authors><title>On the Performance of Renewable Energy-Powered UAV-Assisted Wireless
  Communications</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop novel statistical models of the harvested energy from renewable
energy sources (such as solar and wind energy) considering
harvest-store-consume (HSC) architecture. We consider three renewable energy
harvesting scenarios, i.e. (i) harvesting from the solar power, (ii) harvesting
from the wind power, and (iii) hybrid solar and wind power. In this context, we
first derive the closed-form expressions for the probability density function
(PDF) and cumulative density function (CDF) of the harvested power from the
solar and wind energy sources. Based on the derived expressions, we calculate
the probability of energy outage at UAVs and signal-to-noise ratio (SNR) outage
at ground cellular users. We derive novel closed-form expressions for the
moment generating function (MGF) of the harvested solar power and wind power.
Then, we apply Gil-Pelaez inversion to evaluate the energy outage at the UAV
and signal-to-noise-ratio (SNR) outage at the ground users. We formulate the
SNR outage minimization problem and obtain closed-form solutions for the
transmit power and flight time of the UAV. In addition, we derive novel
closed-form expressions for the moments of the solar power and wind power and
demonstrate their applications in computing novel performance metrics
considering the stochastic nature of the amount of harvested energy as well as
energy arrival time. These performance metrics include the probability of
charging the UAV battery within the flight time, average UAV battery charging
time, probability of energy outage at UAVs, and the probability of eventual
energy outage (i.e. the probability of energy outage in a finite duration of
time) at UAVs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07160</identifier>
 <datestamp>2019-07-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07160</id><created>2019-07-16</created><authors><author><keyname>Chen</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Guan</forenames></author></authors><title>EnforceNet: Monocular Camera Localization in Large Scale Indoor Sparse
  LiDAR Point Cloud</title><categories>cs.CV cs.RO eess.IV</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Pose estimation is a fundamental building block for robotic applications such
as autonomous vehicles, UAV, and large scale augmented reality. It is also a
prohibitive factor for those applications to be in mass production, since the
state-of-the-art, centimeter-level pose estimation often requires long mapping
procedures and expensive localization sensors, e.g. LiDAR and high precision
GPS/IMU, etc. To overcome the cost barrier, we propose a neural network based
solution to localize a consumer degree RGB camera within a prior sparse LiDAR
map with comparable centimeter-level precision. We achieved it by introducing a
novel network module, which we call resistor module, to enforce the network
generalize better, predicts more accurately, and converge faster. Such results
are benchmarked by several datasets we collected in the large scale indoor
parking garage scenes. We plan to open both the data and the code for the
community to join the effort to advance this field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07181</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07181</id><created>2019-07-15</created><authors><author><keyname>Nagarajan</keyname><forenames>Radhakrishnan</forenames></author></authors><title>Deciphering Dynamical Nonlinearities in Short Time Series Using
  Recurrent Neural Networks</title><categories>eess.SP cs.LG q-bio.QM stat.ML</categories><comments>18 pages, 7 Figures, 1 Table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Surrogate testing techniques have been used widely to investigate the
presence of dynamical nonlinearities, an essential ingredient of deterministic
chaotic processes. Traditional surrogate testing subscribes to statistical
hypothesis testing and investigates potential differences in discriminant
statistics between the given empirical sample and its surrogate counterparts.
The choice and estimation of the discriminant statistics can be challenging
across short time series. Also, conclusion based on a single empirical sample
is an inherent limitation. The present study proposes a recurrent neural
network classification framework that uses the raw time series obviating the
need for discriminant statistic while accommodating multiple time series
realizations for enhanced generalizability of the findings. The results are
demonstrated on short time series with lengths (L = 32, 64, 128) from
continuous and discrete dynamical systems in chaotic regimes, nonlinear
transform of linearly correlated noise and experimental data. Accuracy of the
classifier is shown to be markedly higher than &gt;&gt; 50% for the processes in
chaotic regimes whereas those of nonlinearly correlated noise were around ~50%
similar to that of random guess from a one-sample binomial test. These results
are promising and elucidate the usefulness of the proposed framework in
identifying potential dynamical nonlinearities from short experimental time
series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07201</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07201</id><created>2019-07-16</created><updated>2020-01-24</updated><authors><author><keyname>Nayak</keyname><forenames>Nancy</forenames></author><author><keyname>Raj</keyname><forenames>Vishnu</forenames></author><author><keyname>Kalyani</keyname><forenames>Sheetal</forenames></author></authors><title>Leveraging online learning for CSS in frugal IoT network</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel method for centralized collaborative spectrum sensing for
IoT network leveraging cognitive radio network. Based on an online learning
framework, we propose an algorithm to efficiently combine the individual
sensing results based on the past performance of each detector. Additionally,
we show how to utilize the learned normalized weights as a proxy metric of
detection accuracy and selectively enable the sensing at detectors. Our results
show improved performance in terms of inter-user collision and misdetection.
Further, by selectively enabling some of the devices in the network, we propose
a strategy to extend the field life of devices without compromising on
detection accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07206</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07206</id><created>2019-07-16</created><authors><author><keyname>Wang</keyname><forenames>Yue</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Tian</keyname><forenames>Zhi</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author><author><keyname>Zhang</keyname><forenames>Gong</forenames></author></authors><title>Super-Resolution Channel Estimation for Arbitrary Arrays in Hybrid
  Millimeter-Wave Massive MIMO Systems</title><categories>eess.SP</categories><comments>13 pages, 10 figures</comments><doi>10.1109/JSTSP.2019.2937632</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops efficient channel estimation techniques for
millimeter-wave (mmWave) massive multiple-input multiple-output (MIMO) systems
under practical hardware limitations, including an arbitrary array geometry and
a hybrid hardware structure. Taking on an angle-based approach, this work
adopts a generalized array manifold separation approach via Jacobi-Anger
approximation, which transforms a non-ideal, non-uniform array manifold into a
virtual array domain with a desired uniform geometric structure to facilitate
super-resolution angle estimation and channel acquisition. Accordingly,
structure-based optimization techniques are developed to effectively estimate
both the channel covariance and the instantaneous channel state information
(CSI) within a short sensing time. In particular, the difference in
time-variation of channel path angles and path gains is capitalized to design a
two-step CSI estimation scheme that can quickly sense fading channels.
Theoretical results are provided on the fundamental limits of the proposed
technique in terms of sample efficiency. For computational efficiency, a fast
iterative algorithm is developed via the alternating direction method of
multipliers. Other related issues such as spurious-peak cancellation in
nonuniform linear arrays and extensions to higher-dimensional cases are also
discussed. Simulations testify the effectiveness of the proposed approaches in
hybrid mmWave massive MIMO systems with arbitrary arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07232</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07232</id><created>2019-07-16</created><authors><author><keyname>Bottos</keyname><forenames>Stephen</forenames></author><author><keyname>Balasingam</keyname><forenames>Balakumar</forenames></author></authors><title>A Novel Slip-Kalman Filter to Track the Progression of Reading Through
  Eye-Gaze Measurements</title><categories>cs.HC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an approach to track the progression of eye-gaze
while reading a block of text on computer screen. The proposed approach will
help to accurately quantify reading, e.g., identifying the lines of text that
were read/skipped and estimating the time spent on each line, based on
commercially available inexpensive eye-tracking devices. The proposed approach
is based on a novel Slip Kalman filter that is custom designed to track the
progression of reading. The performance of the proposed method is demonstrated
using 25 pages eye-tracking data collected using a commercial desk-mounted
eye-tracking device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07239</identifier>
 <datestamp>2019-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07239</id><created>2019-07-16</created><updated>2019-10-23</updated><authors><author><keyname>Cicilio</keyname><forenames>Phylicia</forenames></author><author><keyname>Cotilla-Sanchez</keyname><forenames>Eduardo</forenames></author></authors><title>Evaluating Measurement-Based Dynamic Load Modeling Techniques and
  Metrics</title><categories>eess.SP</categories><comments>IEEE Transactions on Power Systems, in press, 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wide-area data and algorithms in large power systems are creating new
opportunities for implementation of measurement-based dynamic load modeling
techniques. These techniques improve the accuracy of dynamic load models, which
are an integral part of transient stability analysis. Measurement-based load
modeling techniques commonly assume response error is correlated to system or
model accuracy. Response error is the difference between simulation output and
phasor measurement units (PMUs) samples. This paper investigates similarity
measures, output types, simulation time spans, and disturbance types used to
generate response error and the correlation of the response error to system
accuracy. This paper aims to address two hypotheses: 1) can response error
determine the total system accuracy? and 2) can response error indicate if a
dynamic load model being used at a bus is sufficiently accurate? The results of
the study show only specific combinations of metrics yield statistically
significant correlations, and there is a lack of pattern of combinations of
metrics that deliver significant correlations. Less than 20% of all simulated
tests in this study resulted in statistically significant correlations. These
outcomes highlight concerns with common measurement-based load modeling
techniques, raising awareness to the importance of careful selection and
validation of similarity measures and response output metrics. Naive or
untested selection of metrics can deliver inaccurate and misleading results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07241</identifier>
 <datestamp>2020-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07241</id><created>2019-07-13</created><authors><author><keyname>Al-Nahhal</keyname><forenames>Ibrahim</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Basar</keyname><forenames>Ertugrul</forenames></author><author><keyname>Moloney</keyname><forenames>Cecilia</forenames></author><author><keyname>Ikki</keyname><forenames>Salama</forenames></author></authors><title>A Fast, Accurate, and Separable Method for Fitting a Gaussian Function</title><categories>eess.SP</categories><comments>12 pages, 4 figures, To appear in IEEE Signal Processing Magazines</comments><doi>10.1109/MSP.2019.2927685</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Gaussian function (GF) is widely used to explain the behavior or
statistical distribution of many natural phenomena as well as industrial
processes in different disciplines of engineering and applied science. For
example, the GF can be used to model an approximation of the Airy disk in image
processing, laser heat source in laser transmission welding [1], practical
microscopic applications [2], and fluorescence dispersion in flow cytometric
DNA histograms [3]. In applied sciences, the noise that corrupts the signal can
be modeled by the Gaussian distribution according to the central limit theorem.
Thus, by fitting the GF, the corresponding process/phenomena behavior can be
well interpreted. This article introduces a novel fast, accurate, and separable
algorithm for estimating the GF parameters to fit observed data points. A
simple mathematical trick can be used to calculate the area under the GF in two
different ways. Then, by equating these two areas, the GF parameters can be
easily obtained from the observed data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07242</identifier>
 <datestamp>2019-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07242</id><created>2019-07-13</created><updated>2019-07-18</updated><authors><author><keyname>Al-Nahhal</keyname><forenames>Ibrahim</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Basar</keyname><forenames>Ertugrul</forenames></author><author><keyname>Ikki</keyname><forenames>Salama</forenames></author></authors><title>Low-Cost Uplink Sparse Code Multiple Access for Spatial Modulation</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 4 figures, To appear in IEEE Transactions on Vehicular
  Technology, 2019</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Spatial modulation (SM)-sparse code multiple access (SCMA) systems provide
high spectral efficiency (SE) at the expense of using a high number of transmit
antennas. To overcome this drawback, this letter proposes a novel SM-SCM A
system operating in uplink transmission, referred to as rotational generalized
SM-SCMA (RGSM-SCMA). For the proposed system, the following are introduced: a)
transmitter design and its formulation, b) maximum likelihood and maximum a
posteriori probability decoders, and c) practical low-complexity message
passing algorithm and its complexity analysis. Simulation results and
complexity analysis show that the proposed RGSM-SCMA system delivers the same
SE with significant savings in the number of transmit antennas, at the expense
of close bit error rate and a negligible increase in the decoding complexity,
when compared with SM-SCMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07243</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07243</id><created>2019-07-14</created><authors><author><keyname>Khan</keyname><forenames>Sakib Mahmud</forenames></author><author><keyname>Chowdhury</keyname><forenames>Mashrur</forenames></author></authors><title>Connected Vehicle Supported Adaptive Traffic Control for Near-congested
  Condition in a Mixed Traffic Stream</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connected Vehicles (CVs) have the potential to significantly increase the
safety, mobility, and environmental benefits of transportation applications. In
this research, we have developed a real time adaptive traffic signal control
algorithm that utilizes only CV data to compute the signal timing parameters
for an urban arterial in the near congested condition. We have used a machine
learning based short term traffic forecasting model to predict the overall
traffic counts in CV based platoons. Using a multi objective optimization
technique, we compute the green interval time for each intersection using CV
based platoons. Later, we dynamically adjust intersection offsets in real time,
so the vehicles in the major street can experience improved operational
conditions compared to loop detector based actuated coordinated signal control.
Using a 3 mile long simulated corridor of US 29 in Greenville, SC, we have
evaluated the performance of our CV based adaptive signal control. For the next
time interval, using only 5% CV data, the Root Mean Square Error of the machine
learning based prediction is 10 vehicles. Our analysis reveals that the CV
based adaptive signal control improves operational conditions in the major
street compared to the actuated coordinated scenario. Also, using only CV data,
the operational performance improves even for a low CV penetration (5% CV), and
the benefit increases with increasing CV penetration. We can provide
operational benefits to both CVs and non CVs with the limited data from 5% CVs,
with 5.6% average speed increase, and 66.7% and 32.4% reduction in average
maximum queue length and stopped delay, respectively, in major street
coordinated direction compared to the actuated coordinated scenario in the same
direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07251</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07251</id><created>2019-07-16</created><authors><author><keyname>Alevizos</keyname><forenames>Panos N.</forenames></author><author><keyname>Bletsas</keyname><forenames>Aggelos</forenames></author></authors><title>Inference-Based Resource Allocation for Multi-Cell Backscatter Sensor
  Networks</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies inference-based resource allocation in ultra low-power,
large-scale backscatter sensor networks (BSNs). Several ultra-low cost and
power sensor devices (tags) are illuminated by a carrier and reflect the
measured information towards a wireless core that uses conventional Marconi
radio technology. The development of multi-cell BSNs requires few multi-antenna
cores and several low-cost scatter radio devices, targeting at maximum possible
coverage.
  The average signal-to-interference-plus-noise ratio (SINR) of maximum-ratio
combining (MRC) and zero-forcing (ZF) linear detectors is found and harnessed
for frequency sub-channel allocation at tags, exploiting long-term SINR
information. The resource allocation problem is formulated as an integer
programming optimization problem and solved through the Max-Sum message-passing
algorithm. The proposed algorithm is fully parallelizable and adheres to simple
message-passing update rules, requiring mainly addition and comparison
operations. In addition, the convergence to the optimal solution is attained
within very few iteration steps.
  Judicious simulation study reveals that ZF detector is more suitable for
large scale BSNs, capable to cancel out the intra-cell interference. It is also
found that the proposed algorithm offers at least an order of magnitude
decrease in execution time compared to conventional convex optimization
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07312</identifier>
 <datestamp>2019-10-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07312</id><created>2019-07-16</created><updated>2019-10-25</updated><authors><author><keyname>Xu</keyname><forenames>Shaofu</forenames></author><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Chen</keyname><forenames>Jianping</forenames></author><author><keyname>Yu</keyname><forenames>Lei</forenames></author><author><keyname>Zou</keyname><forenames>Weiwen</forenames></author></authors><title>Deep learning scheme for recovery of broadband microwave photonic
  receiving systems in transceivers without expert knowledge and system priors</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In regular microwave photonic (MWP) receiving systems, broadband signals are
processed in the analog domain before they are transformed to the digital
domain for further processing and storage. However, the quality of the signals
may be degraded by defective photonic analog links, especially in a complicated
MWP system. Here, we show a unified deep learning scheme that recovers the
distorted broadband signals as they are transformed to the digital domain. The
neural network could automatically learn the end-to-end inverse responses of
the distortion effects of actual photonic analog links from data without expert
knowledge and system priors. Hence, by shifting or augmenting the datasets, the
neural network is potential to be generalized to various MWP receiving systems.
We conduct experiments by nontrivial MWP systems with complicated waveforms.
Results validate the effectiveness, general applicability and the
noise-robustness of the proposed scheme, showing its superior performance in
practical MWP systems. Therefore, the proposed deep learning scheme facilitates
the low-cost performance improvement of MWP receiving systems, as well as the
next-generation broadband transceivers, including radars, communications, and
microwave imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07321</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07321</id><created>2019-07-15</created><authors><author><keyname>Ye</keyname><forenames>Ziyu</forenames></author><author><keyname>Gilman</keyname><forenames>Andrew</forenames></author><author><keyname>Peng</keyname><forenames>Qihang</forenames></author><author><keyname>Levick</keyname><forenames>Kelly</forenames></author><author><keyname>Cosman</keyname><forenames>Pamela</forenames></author><author><keyname>Milstein</keyname><forenames>Larry</forenames></author></authors><title>Comparison of Neural Network Architectures for Spectrum Sensing</title><categories>eess.SP cs.LG stat.ML</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different neural network (NN) architectures have different advantages.
Convolutional neural networks (CNNs) achieved enormous success in computer
vision, while recurrent neural networks (RNNs) gained popularity in speech
recognition. It is not known which type of NN architecture is the best fit for
classification of communication signals. In this work, we compare the behavior
of fully-connected NN (FC), CNN, RNN, and bi-directional RNN (BiRNN) in a
spectrum sensing task. The four NN architectures are compared on their
detection performance, requirement of training data, computational complexity,
and memory requirement. Given abundant training data and computational and
memory resources, CNN, RNN, and BiRNN are shown to achieve similar performance.
The performance of FC is worse than that of the other three types, except in
the case where computational complexity is stringently limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07324</identifier>
 <datestamp>2019-07-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07324</id><created>2019-07-16</created><authors><author><keyname>Goo&#xdf;en</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Deshpande</keyname><forenames>Hrishikesh</forenames></author><author><keyname>Harder</keyname><forenames>Tim</forenames></author><author><keyname>Schwab</keyname><forenames>Evan</forenames></author><author><keyname>Baltruschat</keyname><forenames>Ivo</forenames></author><author><keyname>Mabotuwana</keyname><forenames>Thusitha</forenames></author><author><keyname>Cross</keyname><forenames>Nathan</forenames></author><author><keyname>Saalbach</keyname><forenames>Axel</forenames></author></authors><title>Deep Learning for Pneumothorax Detection and Localization in Chest
  Radiographs</title><categories>eess.IV cs.CV cs.LG</categories><comments>MIDL 2019 [arXiv:1907.08612]</comments><report-no>MIDL/2019/ExtendedAbstract/SkxvPEqIwV</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pneumothorax is a critical condition that requires timely communication and
immediate action. In order to prevent significant morbidity or patient death,
early detection is crucial. For the task of pneumothorax detection, we study
the characteristics of three different deep learning techniques: (i)
convolutional neural networks, (ii) multiple-instance learning, and (iii) fully
convolutional networks. We perform a five-fold cross-validation on a dataset
consisting of 1003 chest X-ray images. ROC analysis yields AUCs of 0.96, 0.93,
and 0.92 for the three methods, respectively. We review the classification and
localization performance of these approaches as well as an ensemble of the
three aforementioned techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07325</identifier>
 <datestamp>2019-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07325</id><created>2019-07-17</created><authors><author><keyname>de Lima</keyname><forenames>Thomas Ferreira</forenames></author><author><keyname>Tait</keyname><forenames>Alexander N.</forenames></author><author><keyname>Saeidi</keyname><forenames>Hooman</forenames></author><author><keyname>Nahmias</keyname><forenames>Mitchell A.</forenames></author><author><keyname>Peng</keyname><forenames>Hsuan-Tung</forenames></author><author><keyname>Abbaslou</keyname><forenames>Siamak</forenames></author><author><keyname>Shastri</keyname><forenames>Bhavin J.</forenames></author><author><keyname>Prucnal</keyname><forenames>Paul R.</forenames></author></authors><title>Noise Analysis of Photonic Modulator Neurons</title><categories>physics.app-ph cs.NE eess.SP</categories><comments>8 pages, 7 figures, 1 table</comments><doi>10.1109/JSTQE.2019.2931252</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neuromorphic photonics relies on efficiently emulating analog neural networks
at high speeds. Prior work showed that transducing signals from the optical to
the electrical domain and back with transimpedance gain was an efficient
approach to implementing analog photonic neurons and scalable networks. Here,
we examine modulator-based photonic neuron circuits with passive and active
transimpedance gains, with special attention to the sources of noise
propagation. We find that a modulator nonlinear transfer function can suppress
noise, which is necessary to avoid noise propagation in hardware neural
networks. In addition, while efficient modulators can reduce power for an
individual neuron, signal-to-noise ratios must be traded off with power
consumption at a system level. Active transimpedance amplifiers may help relax
this tradeoff for conventional p-n junction silicon photonic modulators, but a
passive transimpedance circuit is sufficient when very efficient modulators
(i.e. low C and low V-pi) are employed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07326</identifier>
 <datestamp>2019-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07326</id><created>2019-07-15</created><updated>2019-08-06</updated><authors><author><keyname>Ye</keyname><forenames>Ziyu</forenames></author><author><keyname>Peng</keyname><forenames>Qihang</forenames></author><author><keyname>Levick</keyname><forenames>Kelly</forenames></author><author><keyname>Rong</keyname><forenames>Hui</forenames></author><author><keyname>Gilman</keyname><forenames>Andrew</forenames></author><author><keyname>Cosman</keyname><forenames>Pamela</forenames></author><author><keyname>Milstein</keyname><forenames>Larry</forenames></author></authors><title>A Neural Network Detector for Spectrum Sensing under Uncertainties</title><categories>eess.SP cs.IT cs.LG math.IT stat.ML</categories><comments>6 pages, 4 figures, submitted to ICNC2020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing is of critical importance in any cognitive radio system.
When the primary user's signal has uncertain parameters, the likelihood ratio
test, which is the theoretically optimal detector, generally has no closed-form
expression. As a result, spectrum sensing under parameter uncertainty remains
an open question, though many detectors exploiting specific features of a
primary signal have been proposed and have achieved reasonably good
performance. In this paper, a neural network is trained as a detector for
modulated signals. The result shows by training on an appropriate dataset, the
neural network gains robustness under uncertainties in system parameters
including the carrier frequency offset, carrier phase offset, and symbol time
offset. The result displays the neural network's potential in exploiting
implicit and incomplete knowledge about the signal's structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07345</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07345</id><created>2019-07-17</created><authors><author><keyname>Podlesnyy</keyname><forenames>Sergey</forenames></author></authors><title>Towards Data-Driven Automatic Video Editing</title><categories>cs.CV cs.MM eess.IV</categories><comments>2019 15th International Conference on Natural Computation, Fuzzy
  Systems and Knowledge Discovery, Kunming, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic video editing involving at least the steps of selecting the most
valuable footage from points of view of visual quality and the importance of
action filmed; and cutting the footage into a brief and coherent visual story
that would be interesting to watch is implemented in a purely data-driven
manner. Visual semantic and aesthetic features are extracted by the
ImageNet-trained convolutional neural network, and the editing controller is
trained by an imitation learning algorithm. As a result, at test time the
controller shows the signs of observing basic cinematography editing rules
learned from the corpus of motion pictures masterpieces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07398</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07398</id><created>2019-07-17</created><authors><author><keyname>Shi</keyname><forenames>Ziqiang</forenames></author><author><keyname>Liu</keyname><forenames>Liu</forenames></author><author><keyname>Lin</keyname><forenames>Huibin</forenames></author><author><keyname>Liu</keyname><forenames>Rujie</forenames></author><author><keyname>Shi</keyname><forenames>Anyan</forenames></author></authors><title>HODGEPODGE: Sound event detection based on ensemble of semi-supervised
  learning methods</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a method called HODGEPODGE\footnotemark[1] for
large-scale detection of sound events using weakly labeled, synthetic, and
unlabeled data proposed in the Detection and Classification of Acoustic Scenes
and Events (DCASE) 2019 challenge Task 4: Sound event detection in domestic
environments. To perform this task, we adopted the convolutional recurrent
neural networks (CRNN) as our backbone network. In order to deal with a small
amount of tagged data and a large amounts of unlabeled in-domain data, we aim
to focus primarily on how to apply semi-supervise learning methods efficiently
to make full use of limited data. Three semi-supervised learning principles
have been used in our system, including: 1) Consistency regularization applies
data augmentation; 2) MixUp regularizer requiring that the predictions for a
interpolation of two inputs is close to the interpolation of the prediction for
each individual input; 3) MixUp regularization applies to interpolation between
data augmentations. We also tried an ensemble of various models, which are
trained by using different semi-supervised learning principles. Our proposed
approach significantly improved the performance of the baseline, achieving the
event-based f-measure of 42.0\% compared to 25.8\% event-based f-measure of the
baseline in the provided official evaluation dataset. Our submissions ranked
third among 18 teams in the task 4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07411</identifier>
 <datestamp>2020-02-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07411</id><created>2019-07-17</created><updated>2020-01-31</updated><authors><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author></authors><title>A Fisher Information Analysis of Joint Localization and Synchronization
  in Near Field</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted to IEEE ICC 2020 Workshops</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 5G communication, arrays are used for both positioning and communication.
As the arrays become larger, the far-field assumption is increasingly being
violated and curvature of the wavefront should be taken into account. We
explicitly contrast near-field and far-field uplink localization performance in
the presence of a clock bias from a Fisher information perspective and show how
a simple algorithm can provide a coarse estimate of a user's location and clock
bias.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07420</identifier>
 <datestamp>2020-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07420</id><created>2019-07-17</created><updated>2020-01-26</updated><authors><author><keyname>Kawano</keyname><forenames>Yu</forenames></author><author><keyname>Kosaraju</keyname><forenames>Krishna Chaitanya</forenames></author><author><keyname>Scherpen</keyname><forenames>Jacquelien M. A.</forenames></author></authors><title>Krasovskii and Shifted Passivity Based Control</title><categories>eess.SY cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, our objective is to develop novel passivity based control
techniques by introducing a new passivity concept named Krasovskii passivity.
As a preliminary step, we investigate properties of Krasovskii passive systems
and establish relations among four relevant passivity concepts including
Krasovskii passivity. Then, we develop novel dynamic controllers based on
Krasovskii passivity and based on extended shifted passivity. The proposed
controllers are applicable to a class of systems for which the standard
passivity based controllers may be difficult to design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07476</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07476</id><created>2019-07-17</created><authors><author><keyname>Kharel</keyname><forenames>Binod</forenames></author><author><keyname>L&#xf3;pez</keyname><forenames>Onel L. Alcaraz</forenames></author><author><keyname>Alves</keyname><forenames>Hirley</forenames></author><author><keyname>Latva-aho</keyname><forenames>Matti</forenames></author></authors><title>Achieving Ultra-Reliable Communication via CRAN-Enabled Diversity
  Schemes</title><categories>cs.NI eess.SP stat.AP</categories><comments>5 pages,6 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet of things is in progress to build a smart society, and wireless
networks are critical enablers for many of its use cases. In this paper, we
present a multi-coordinated transmission scheme to achieve ultra-reliability
for critical machine-type wireless communication networks. We take advantage of
diversity, which is fundamental for dealing with fading channel impairments,
and for achieving ultra-reliable region of operation in order of five 9's as
defined by 3GPP standardization bodies. We evaluate an interference-limited
network composed of multiple remote radio heads that are allowed to cooperate,
by keeping silence thus reducing interference, or by performing more elaborated
strategies such as maximal ratio transmission, in order to serve a user
equipment with ultra-reliability. We provide extensive numerical analysis and
discuss the gains of cooperation by the centralized radio access network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07478</identifier>
 <datestamp>2019-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1907.07478</id><created>2019-07-17</created><authors><author><keyname>Kamran</keyname><forenames>Rashmi</forenames></author><author><keyname>Nambath</keyname><forenames>Nandakumar</forenames></author><author><keyname>Manikandan</keyname><forenames>Sarath</forenames></author><author><keyname>Ashok</keyname><forenames>Rakesh</forenames></author><author><keyname>Thaker</keyname><forenames>Nandish Bharat</forenames></author><author><keyname>Anghan</keyname><forenames>Mehul</forenames></author><author><keyname>Gupta</keyname><forenames>Shalabh</forenames></author></authors><title>Demonstration of an LO-less, DSP-free QPSK Receiver for Data Center
  Interconnects</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first demonstration of a local oscillator (LO)-less digital
signal processing (DSP)-free coherent receiver for high-capacity short distance
optical links. Experimental results with an analog domain constant modulous
algorithm (CMA)-based equalizer chip for the self-homodyne quadrature phase
shift keying (SH-QPSK) system validate the employability of an all-analog and
LO-less receiver for low-power interconnects.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="7000" completeListSize="16166">4250076|8001</resumptionToken>
</ListRecords>
</OAI-PMH>
