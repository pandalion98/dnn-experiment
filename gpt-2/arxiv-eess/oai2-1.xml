<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2020-03-01T06:55:10Z</responseDate>
<request verb="ListRecords" metadataPrefix="arXiv" set="eess">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6096</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6096</id><created>2010-10-28</created><updated>2019-09-08</updated><authors><author><keyname>Akhoundi</keyname><forenames>Mohammad Amin Ahmad</forenames></author><author><keyname>Valavi</keyname><forenames>Ehsan</forenames></author></authors><title>Multi-Sensor Fuzzy Data Fusion Using Sensors with Different
  Characteristics</title><categories>eess.SY cs.SY</categories><comments>CSI Journal in Computer Science and Engineering, published 2019
  (First Submission 2010)</comments><journal-ref>The CSI Journal on Computer Science and Engineering, vol. 16, no.
  2 (2019)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new approach to multi-sensor data fusion. It suggests
that aggregation of data from multiple sensors can be done more efficiently
when we consider information about sensors' different characteristics. Similar
to most research on effective sensors' characteristics, especially in control
systems, our focus is on sensors' accuracy and frequency response. A rule-based
fuzzy system is presented for fusion of raw data obtained from the sensors that
have complement characteristics in accuracy and bandwidth. Furthermore, a fuzzy
predictor system is suggested aiming for extreme accuracy which is a common
need in highly sensitive applications. Advantages of our proposed sensor fusion
system are shown by simulation of a control system utilizing the fusion system
for output estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3189</identifier>
 <datestamp>2017-09-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3189</id><created>2010-11-14</created><updated>2015-09-26</updated><authors><author><keyname>Fong</keyname><forenames>Chamberlain</forenames></author><author><keyname>Vogel</keyname><forenames>Brian K.</forenames></author></authors><title>Warping Peirce Quincuncial Panoramas</title><categories>cs.CV cs.GR eess.IV</categories><comments>updated source code with figures and explanation of the software
  implementation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Peirce quincuncial projection is a mapping of the surface of a sphere to
the interior of a square. It is a conformal map except for four points on the
equator. These points of non-conformality cause significant artifacts in
photographic applications. In this paper, we propose an algorithm and
user-interface to mitigate these artifacts. Moreover, in order to facilitate an
interactive user-interface, we present a fast algorithm for calculating the
Peirce quincuncial projection of spherical imagery. We then promote the Peirce
quincuncial projection as a viable alternative to the more popular
stereographic projection in some scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3127</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3127</id><created>2012-07-12</created><authors><author><keyname>Wang</keyname><forenames>Quan</forenames></author><author><keyname>Ou</keyname><forenames>Yan</forenames></author><author><keyname>Julius</keyname><forenames>A. Agung</forenames></author><author><keyname>Boyer</keyname><forenames>Kim L.</forenames></author><author><keyname>Kim</keyname><forenames>Min Jun</forenames></author></authors><title>Tracking Tetrahymena Pyriformis Cells using Decision Trees</title><categories>cs.CV cs.LG eess.IV q-bio.CB stat.ML</categories><comments>21st International Conference on Pattern Recognition, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching cells over time has long been the most difficult step in cell
tracking. In this paper, we approach this problem by recasting it as a
classification problem. We construct a feature set for each cell, and compute a
feature difference vector between a cell in the current frame and a cell in a
previous frame. Then we determine whether the two cells represent the same cell
over time by training decision trees as our binary classifiers. With the output
of decision trees, we are able to formulate an assignment problem for our cell
association task and solve it using a modified version of the Hungarian
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4028</identifier>
 <datestamp>2019-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4028</id><created>2012-07-17</created><updated>2012-09-20</updated><authors><author><keyname>Brody</keyname><forenames>Dorje C.</forenames></author><author><keyname>Hughston</keyname><forenames>Lane P.</forenames></author><author><keyname>Yang</keyname><forenames>Xun</forenames></author></authors><title>Signal processing with Levy information</title><categories>math.PR cs.IT eess.SP math.IT math.OC q-fin.GN</categories><comments>27 pages. Version to appear in: Proc. R. Soc. London A</comments><journal-ref>Proc. R. Soc. London A 469, 20120433 (2013)</journal-ref><doi>10.1098/rspa.2012.0433</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Levy processes, which have stationary independent increments, are ideal for
modelling the various types of noise that can arise in communication channels.
If a Levy process admits exponential moments, then there exists a parametric
family of measure changes called Esscher transformations. If the parameter is
replaced with an independent random variable, the true value of which
represents a &quot;message&quot;, then under the transformed measure the original Levy
process takes on the character of an &quot;information process&quot;. In this paper we
develop a theory of such Levy information processes. The underlying Levy
process, which we call the fiducial process, represents the &quot;noise type&quot;. Each
such noise type is capable of carrying a message of a certain specification. A
number of examples are worked out in detail, including information processes of
the Brownian, Poisson, gamma, variance gamma, negative binomial, inverse
Gaussian, and normal inverse Gaussian type. Although in general there is no
additive decomposition of information into signal and noise, one is led
nevertheless for each noise type to a well-defined scheme for signal detection
and enhancement relevant to a variety of practical situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1301.3605</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1301.3605</id><created>2013-01-16</created><updated>2013-03-08</updated><authors><author><keyname>Yu</keyname><forenames>Dong</forenames></author><author><keyname>Seltzer</keyname><forenames>Michael L.</forenames></author><author><keyname>Li</keyname><forenames>Jinyu</forenames></author><author><keyname>Huang</keyname><forenames>Jui-Ting</forenames></author><author><keyname>Seide</keyname><forenames>Frank</forenames></author></authors><title>Feature Learning in Deep Neural Networks - Studies on Speech Recognition
  Tasks</title><categories>cs.LG cs.CL cs.NE eess.AS</categories><comments>ICLR 2013, 9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies have shown that deep neural networks (DNNs) perform
significantly better than shallow networks and Gaussian mixture models (GMMs)
on large vocabulary speech recognition tasks. In this paper, we argue that the
improved accuracy achieved by the DNNs is the result of their ability to
extract discriminative internal representations that are robust to the many
sources of variability in speech signals. We show that these representations
become increasingly insensitive to small perturbations in the input with
increasing network depth, which leads to better speech recognition performance
with deeper networks. We also show that DNNs cannot extrapolate to test samples
that are substantially different from the training examples. If the training
data are sufficiently representative, however, internal features learned by the
DNN are relatively stable with respect to speaker differences, bandwidth
differences, and environment distortion. This enables DNN-based recognizers to
perform as well or better than state-of-the-art systems based on GMMs or
shallow networks without the need for explicit model adaptation or feature
normalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.0400</identifier>
 <datestamp>2018-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.0400</id><created>2013-08-01</created><authors><author><keyname>Huang</keyname><forenames>Tianyao</forenames></author><author><keyname>Liu</keyname><forenames>Yimin</forenames></author><author><keyname>Meng</keyname><forenames>Huadong</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author></authors><title>Cognitive Random Stepped Frequency Radar with Sparse Recovery</title><categories>eess.SP</categories><comments>29 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random stepped frequency (RSF) radar, which transmits random-frequency
pulses, can suppress the range ambiguity, improve convert detection, and
possess excellent electronic counter-countermeasures (ECCM) ability [1]. In
this paper, we apply a sparse recovery method to estimate the range and Doppler
of targets. We also propose a cognitive mechanism for RSF radar to further
enhance the performance of the sparse recovery method. The carrier frequencies
of transmitted pulses are adaptively designed in response to the observed
circumstance. We investigate the criterion to design carrier frequencies, and
efficient methods are then devised. Simulation results demonstrate that the
adaptive frequency-design mechanism significantly improves the performance of
target reconstruction in comparison with the non-adaptive mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4273</identifier>
 <datestamp>2018-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4273</id><created>2013-08-20</created><updated>2014-06-18</updated><authors><author><keyname>Huang</keyname><forenames>Tianyao</forenames></author><author><keyname>Liu</keyname><forenames>Yimin</forenames></author><author><keyname>Meng</keyname><forenames>Huadong</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author></authors><title>Adaptive matching pursuit for off-grid compressed sensing</title><categories>eess.SP cs.IT math.IT</categories><comments>24 pages. 10 figures</comments><journal-ref>EURASIP Journal on Advances in Signal Processing 2012, 2012:76</journal-ref><doi>10.1186/1687-6180-2012-76</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing (CS) can effectively recover a signal when it is sparse
in some discrete atoms. However, in some applications, signals are sparse in a
continuous parameter space, e.g., frequency space, rather than discrete atoms.
Usually, we divide the continuous parameter into finite discrete grid points
and build a dictionary from these grid points. However, the actual targets may
not exactly lie on the grid points no matter how densely the parameter is
grided, which introduces mismatch between the predefined dictionary and the
actual one. In this article, a novel method, namely adaptive matching pursuit
with constrained total least squares (AMP-CTLS), is proposed to find actual
atoms even if they are not included in the initial dictionary. In AMP-CTLS, the
grid and the dictionary are adaptively updated to better agree with
measurements. The convergence of the algorithm is discussed, and numerical
experiments demonstrate the advantages of AMP-CTLS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.5251</identifier>
 <datestamp>2018-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.5251</id><created>2013-10-19</created><updated>2014-05-15</updated><authors><author><keyname>Chepuri</keyname><forenames>Sundeep Prabhakar</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Sparsity-Promoting Sensor Selection for Non-linear Measurement Models</title><categories>cs.IT eess.SP math.IT</categories><comments>13 pages, submitted to TSP (revised Mar. 2014)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor selection is an important design problem in large-scale sensor
networks. Sensor selection can be interpreted as the problem of selecting the
best subset of sensors that guarantees a certain estimation performance. We
focus on observations that are related to a general non-linear model. The
proposed framework is valid as long as the observations are independent, and
its likelihood satisfies the regularity conditions. We use several functions of
the Cram\'er-Rao bound (CRB) as a performance measure. We formulate the sensor
selection problem as the design of a selection vector, which in its original
form is a nonconvex l0-(quasi) norm optimization problem. We present relaxed
sensor selection solvers that can be efficiently solved in polynomial time. We
also propose a projected subgradient algorithm that is attractive for
large-scale problems and also show how the algorithm can be easily distributed.
The proposed framework is illustrated with a number of examples related to
sensor placement design for localization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1410.1272</identifier>
 <datestamp>2018-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1410.1272</id><created>2014-10-06</created><updated>2015-02-05</updated><authors><author><keyname>Zhao</keyname><forenames>Tong</forenames></author><author><keyname>Huang</keyname><forenames>Tianyao</forenames></author></authors><title>Cramer-Rao Lower Bounds of Joint Delay-Doppler Estimation for an
  Extended Target</title><categories>eess.SP</categories><doi>10.1109/TSP.2015.2505681</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem on the Cramer-Rao Lower Bounds (CRLBs) for the joint time delay
and Doppler stretch estimation of an extended target is considered in this
paper. The integral representations of the CRLBs for both the time delay and
the Doppler stretch are derived. To facilitate computation and analysis, series
representations and approximations of the CRLBs are introduced. According to
these series representations, the impact of several waveform parameters on the
estimation accuracy is investigated, which reveals that the CRLB of the Doppler
stretch is inversely proportional to the effective time-bandwidth product of
the waveform. This conclusion generalizes a previous result in the narrowband
case. The popular wideband ambiguity function (WBAF) based delay-Doppler
estimator is evaluated and compared with the CRLBs through numerical
experiments. Our results indicate that the WBAF estimator, originally derived
from a single scatterer model, is not suitable for the parameter estimation of
an extended target.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1412.7725</identifier>
 <datestamp>2018-07-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1412.7725</id><created>2014-12-24</created><updated>2015-05-15</updated><authors><author><keyname>Yan</keyname><forenames>Zhicheng</forenames></author><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Wang</keyname><forenames>Baoyuan</forenames></author><author><keyname>Paris</keyname><forenames>Sylvain</forenames></author><author><keyname>Yu</keyname><forenames>Yizhou</forenames></author></authors><title>Automatic Photo Adjustment Using Deep Neural Networks</title><categories>cs.CV cs.GR cs.LG eess.IV</categories><comments>TOG minor revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photo retouching enables photographers to invoke dramatic visual impressions
by artistically enhancing their photos through stylistic color and tone
adjustments. However, it is also a time-consuming and challenging task that
requires advanced skills beyond the abilities of casual photographers. Using an
automated algorithm is an appealing alternative to manual work but such an
algorithm faces many hurdles. Many photographic styles rely on subtle
adjustments that depend on the image content and even its semantics. Further,
these adjustments are often spatially varying. Because of these
characteristics, existing automatic algorithms are still limited and cover only
a subset of these challenges. Recently, deep machine learning has shown unique
abilities to address hard problems that resisted machine algorithms for long.
This motivated us to explore the use of deep learning in the context of photo
editing. In this paper, we explain how to formulate the automatic photo
adjustment problem in a way suitable for this approach. We also introduce an
image descriptor that accounts for the local semantics of an image. Our
experiments demonstrate that our deep learning formulation applied using these
descriptors successfully capture sophisticated photographic styles. In
particular and unlike previous techniques, it can model local adjustments that
depend on the image semantics. We show on several examples that this yields
results that are qualitatively and quantitatively better than previous work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1501.07496</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1501.07496</id><created>2015-01-29</created><authors><author><keyname>Da Silva</keyname><forenames>E. L. F.</forenames></author><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author></authors><title>Implementation of an Automatic Syllabic Division Algorithm from Speech
  Files in Portuguese Language</title><categories>cs.SD cs.CL cs.DS eess.AS</categories><comments>9 pages, 7 figures, 4 tables, conference: XIX Congresso Brasileiro de
  Automatica CBA, Campina Grande, Setembro, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new algorithm for voice automatic syllabic splitting in the Portuguese
language is proposed, which is based on the envelope of the speech signal of
the input audio file. A computational implementation in MatlabTM is presented
and made available at the URL
http://www2.ee.ufpe.br/codec/divisao_silabica.html. Due to its
straightforwardness, the proposed method is very attractive for embedded
systems (e.g. i-phones). It can also be used as a screen to assist more
sophisticated methods. Voice excerpts containing more than one syllable and
identified by the same envelope are named as super-syllables and they are
subsequently separated. The results indicate which samples corresponds to the
beginning and end of each detected syllable. Preliminary tests were performed
to fifty words at an identification rate circa 70% (further improvements may be
incorporated to treat particular phonemes). This algorithm is also useful in
voice command systems, as a tool in the teaching of Portuguese language or even
for patients with speech pathology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1502.01566</identifier>
 <datestamp>2018-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1502.01566</id><created>2015-02-05</created><authors><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author><author><keyname>de Souza</keyname><forenames>R. M. Campello</forenames></author><author><keyname>de Oliveira</keyname><forenames>R. C.</forenames></author></authors><title>A Matrix Laurent Series-based Fast Fourier Transform for Blocklengths
  N=4 (mod 8)</title><categories>cs.DS cs.DM eess.SP</categories><comments>6 pages, 2 figures, 2 tables. Conference: XXVII Simposio Brasileiro
  de Telecomunicacoes - SBrT'09, 2009, Blumenau, SC, Brazil</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  General guidelines for a new fast computation of blocklength 8m+4 DFTs are
presented, which is based on a Laurent series involving matrices. Results of
non-trivial real multiplicative complexity are presented for blocklengths N=64,
achieving lower multiplication counts than previously published FFTs. A
detailed description for the cases m=1 and m=2 is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1502.03371</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1502.03371</id><created>2015-02-11</created><authors><author><keyname>de Souza</keyname><forenames>R. M. Campello</forenames></author><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author><author><keyname>Silva</keyname><forenames>D.</forenames></author></authors><title>The Z Transform over Finite Fields</title><categories>math.NT cs.NA eess.SP</categories><comments>6 pages, 5 figures, Proc. IEEE/SBrT Int. Telecomm. Symp., 2002.
  pp.362-367</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite field transforms have many applications and, in many cases, can be
implemented with a low computational complexity. In this paper, the Z Transform
over a finite field is introduced and some of its properties are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1502.03387</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1502.03387</id><created>2015-02-11</created><authors><author><keyname>Filho</keyname><forenames>R. F. B. Sotero</forenames></author><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author><author><keyname>de Souza</keyname><forenames>R. M. Campello</forenames></author></authors><title>A Full Frequency Masking Vocoder for Legal Eavesdropping Conversation
  Recording</title><categories>cs.SD eess.AS</categories><comments>7 pages, 3 figures, 3 tables, XXXV Cong. Nac. de Matematica Aplicada
  e Computacional, Natal, RN, Brazil 2014</comments><doi>10.5540/03.2015.003.01.0468</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new approach for a vocoder design based on full
frequency masking by octaves in addition to a technique for spectral filling
via beta probability distribution. Some psycho-acoustic characteristics of
human hearing - inaudibility masking in frequency and phase - are used as a
basis for the proposed algorithm. The results confirm that this technique may
be useful to save bandwidth in applications requiring intelligibility. It is
recommended for the legal eavesdropping of long voice conversations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1502.05880</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1502.05880</id><created>2015-02-20</created><authors><author><keyname>de Oliveira</keyname><forenames>R. C.</forenames></author><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author><author><keyname>de Souza</keyname><forenames>R. M. Campello</forenames></author><author><keyname>Santos</keyname><forenames>E. J. P.</forenames></author></authors><title>A Flexible Implementation of a Matrix Laurent Series-Based 16-Point Fast
  Fourier and Hartley Transforms</title><categories>cs.NA cs.DM eess.SP</categories><comments>4 pages, 4 figures. IEEE VI Southern Programmable Logic Conference
  2010</comments><doi>10.1109/SPL.2010.5483017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a flexible architecture for implementing a new fast
computation of the discrete Fourier and Hartley transforms, which is based on a
matrix Laurent series. The device calculates the transforms based on a single
bit selection operator. The hardware structure and synthesis are presented,
which handled a 16-point fast transform in 65 nsec, with a Xilinx SPARTAN 3E
device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.02577</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1503.02577</id><created>2015-03-09</created><authors><author><keyname>Silva</keyname><forenames>G. Jer&#xf4;nimo da</forenames><suffix>Jr.</suffix></author><author><keyname>de Souza</keyname><forenames>R. M. Campello</forenames></author><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author></authors><title>New Algorithms for Computing a Single Component of the Discrete Fourier
  Transform</title><categories>cs.DM cs.DS eess.SP stat.ME</categories><comments>4 pages, 3 figures, 1 table. In: 10th International Symposium on
  Communication Theory and Applications, Ambleside, UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the theory and hardware implementation of two new
algorithms for computing a single component of the discrete Fourier transform.
In terms of multiplicative complexity, both algorithms are more efficient, in
general, than the well known Goertzel Algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.05528</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1503.05528</id><created>2015-03-18</created><updated>2015-06-08</updated><authors><author><keyname>Newson</keyname><forenames>Alasdair</forenames><affiliation>LTCI</affiliation></author><author><keyname>Almansa</keyname><forenames>Andr&#xe9;s</forenames><affiliation>LTCI</affiliation></author><author><keyname>Fradet</keyname><forenames>Matthieu</forenames></author><author><keyname>Gousseau</keyname><forenames>Yann</forenames></author><author><keyname>P&#xe9;rez</keyname><forenames>Patrick</forenames></author></authors><title>Video Inpainting of Complex Scenes</title><categories>cs.CV cs.MM eess.IV math.NA</categories><proxy>ccsd</proxy><journal-ref>SIAM Journal on Imaging Sciences, Society for Industrial and
  Applied Mathematics, 2014, 7 (4), pp.1993-2019</journal-ref><doi>10.1137/140954933</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an automatic video inpainting algorithm which relies on the
optimisation of a global, patch-based functional. Our algorithm is able to deal
with a variety of challenging situations which naturally arise in video
inpainting, such as the correct reconstruction of dynamic textures, multiple
moving objects and moving background. Furthermore, we achieve this in an order
of magnitude less execution time with respect to the state-of-the-art. We are
also able to achieve good quality results on high definition videos. Finally,
we provide specific algorithmic details to make implementation of our algorithm
as easy as possible. The resulting algorithm requires no segmentation or manual
input other than the definition of the inpainting mask, and can deal with a
wider variety of situations than is handled by previous work. 1. Introduction.
Advanced image and video editing techniques are increasingly common in the
image processing and computer vision world, and are also starting to be used in
media entertainment. One common and difficult task closely linked to the world
of video editing is image and video &quot; inpainting &quot;. Generally speaking, this is
the task of replacing the content of an image or video with some other content
which is visually pleasing. This subject has been extensively studied in the
case of images, to such an extent that commercial image inpainting products
destined for the general public are available, such as Photoshop's &quot; Content
Aware fill &quot; [1]. However, while some impressive results have been obtained in
the case of videos, the subject has been studied far less extensively than
image inpainting. This relative lack of research can largely be attributed to
high time complexity due to the added temporal dimension. Indeed, it has only
very recently become possible to produce good quality inpainting results on
high definition videos, and this only in a semi-automatic manner. Nevertheless,
high-quality video inpainting has many important and useful applications such
as film restoration, professional post-production in cinema and video editing
for personal use. For this reason, we believe that an automatic, generic video
inpainting algorithm would be extremely useful for both academic and
professional communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1506.03124</identifier>
 <datestamp>2019-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1506.03124</id><created>2015-06-09</created><authors><author><keyname>Mandal</keyname><forenames>Subhamoy</forenames></author><author><keyname>Sudarshan</keyname><forenames>Viswanath Pamulakanty</forenames></author><author><keyname>Nagaraj</keyname><forenames>Yeshaswini</forenames></author><author><keyname>Ben</keyname><forenames>Xose Luis Dean</forenames></author><author><keyname>Razansky</keyname><forenames>Daniel</forenames></author></authors><title>Multiscale edge detection and parametric shape modeling for boundary
  delineation in optoacoustic images</title><categories>physics.med-ph cs.CV eess.IV</categories><comments>Engineering in Medicine and Biology Society (EMBC), 2015 37th Annual
  International Conference of the IEEE (Accepted version)</comments><journal-ref>Engineering in Medicine and Biology Society (EMBC), 2015 37th
  Annual International Conference of the IEEE , vol., no., pp.707-710, 25-29
  Aug. 2015</journal-ref><doi>10.1109/EMBC.2015.7318460</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this article, we present a novel scheme for segmenting the image boundary
(with the background) in optoacoustic small animal in vivo imaging systems. The
method utilizes a multiscale edge detection algorithm to generate a binary edge
map. A scale dependent morphological operation is employed to clean spurious
edges. Thereafter, an ellipse is fitted to the edge map through constrained
parametric transformations and iterative goodness of fit calculations. The
method delimits the tissue edges through the curve fitting model, which has
shown high levels of accuracy. Thus, this method enables segmentation of
optoacoutic images with minimal human intervention, by eliminating need of
scale selection for multiscale processing and seed point determination for
contour mapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1506.06055</identifier>
 <datestamp>2018-08-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1506.06055</id><created>2015-06-19</created><authors><author><keyname>Huang</keyname><forenames>Tianyao</forenames></author><author><keyname>Zhao</keyname><forenames>Tong</forenames></author></authors><title>Low PMEPR OFDM radar waveform design using the iterative least squares
  algorithm</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 8 figures</comments><doi>10.1109/LSP.2015.2449305</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter considers waveform design of orthogonal frequency division
multiplexing (OFDM) signal for radar applications, and aims at mitigating the
envelope fluctuation in OFDM. A novel method is proposed to reduce the
peak-to-mean envelope power ratio (PMEPR), which is commonly used to evaluate
the fluctuation. The proposed method is based on the tone reservation approach,
in which some bits or subcarriers of OFDM are allocated for decreasing PMEPR.
We introduce the coefficient of variation of envelopes (CVE) as the cost
function for waveform optimization, and develop an iterative least squares
algorithm. Minimizing CVE leads to distinct PMEPR reduction, and it is
guaranteed that the cost function monotonically decreases by applying the
iterative algorithm. Simulations demonstrate that the envelope is significantly
smoothed by the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1507.02954</identifier>
 <datestamp>2018-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1507.02954</id><created>2015-07-10</created><updated>2018-09-16</updated><authors><author><keyname>Hansen</keyname><forenames>Thomas L.</forenames></author><author><keyname>J&#xf8;rgensen</keyname><forenames>Peter B.</forenames></author><author><keyname>Badiu</keyname><forenames>Mihai-Alin</forenames></author><author><keyname>Fleury</keyname><forenames>Bernard H.</forenames></author></authors><title>An Iterative Receiver for OFDM With Sparsity-Based Parametric Channel
  Estimation</title><categories>cs.IT eess.SP math.IT stat.AP</categories><comments>Major revision, accepted for IEEE Transactions on Signal Processing</comments><journal-ref>IEEE Transactions on Signal Processing, Vol. 66, No. 20, Oct. 15,
  2018</journal-ref><doi>10.1109/TSP.2018.2868314</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we design a receiver that iteratively passes soft information
between the channel estimation and data decoding stages. The receiver
incorporates sparsity-based parametric channel estimation. State-of-the-art
sparsity-based iterative receivers simplify the channel estimation problem by
restricting the multipath delays to a grid. Our receiver does not impose such a
restriction. As a result it does not suffer from the leakage effect, which
destroys sparsity. Communication at near capacity rates in high SNR requires a
large modulation order. Due to the close proximity of modulation symbols in
such systems, the grid-based approximation is of insufficient accuracy. We show
numerically that a state-of-the-art iterative receiver with grid-based sparse
channel estimation exhibits a bit-error-rate floor in the high SNR regime. On
the contrary, our receiver performs very close to the perfect channel state
information bound for all SNR values. We also demonstrate both theoretically
and numerically that parametric channel estimation works well in dense
channels, i.e., when the number of multipath components is large and each
individual component cannot be resolved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1508.03878</identifier>
 <datestamp>2018-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1508.03878</id><created>2015-08-16</created><updated>2018-05-27</updated><authors><author><keyname>Stein</keyname><forenames>Manuel</forenames></author><author><keyname>Nossek</keyname><forenames>Josef A.</forenames></author></authors><title>A Pessimistic Approximation for the Fisher Information Measure</title><categories>cs.IT eess.SP math.IT</categories><journal-ref>IEEE Transactions on Signal Processing, vol. 65, no. 2, pp.
  386-396, 2017</journal-ref><doi>10.1109/TSP.2016.2617824</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of determining the intrinsic quality of a signal processing
system with respect to the inference of an unknown deterministic parameter
$\theta$ is considered. While the Fisher information measure $F(\theta)$ forms
a classical tool for such a problem, direct computation of the information
measure can become difficult in various situations. For the estimation
theoretic performance analysis of nonlinear measurement systems, the form of
the likelihood function can make the calculation of the information measure
$F(\theta)$ challenging. In situations where no closed-form expression of the
statistical system model is available, the analytical derivation of $F(\theta)$
is not possible at all. Based on the Cauchy-Schwarz inequality, we derive an
alternative information measure $S(\theta)$. It provides a lower bound on the
Fisher information $F(\theta)$ and has the property of being evaluated with the
mean, the variance, the skewness and the kurtosis of the system model at hand.
These entities usually exhibit good mathematical tractability or can be
determined at low-complexity by real-world measurements in a calibrated setup.
With various examples, we show that $S(\theta)$ provides a good conservative
approximation for $F(\theta)$ and outline different estimation theoretic
problems where the presented information bound turns out to be useful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1510.08174</identifier>
 <datestamp>2019-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1510.08174</id><created>2015-10-27</created><updated>2016-04-10</updated><authors><author><keyname>Mandal</keyname><forenames>Subhamoy</forenames></author><author><keyname>De&#xe1;n-Ben</keyname><forenames>Xos&#xe9; Lu&#xed;s</forenames></author><author><keyname>Razansky</keyname><forenames>Daniel</forenames></author></authors><title>Visual Quality Enhancement in Optoacoustic Tomography using Active
  Contour Segmentation Priors</title><categories>physics.med-ph cs.CV eess.IV physics.optics</categories><comments>Accepted for publication in IEEE Transactions on Medical Imaging</comments><journal-ref>IEEE Transactions on Medical Imaging, vol. 35, no. 10, pp.
  2209-2217, Oct. 2016</journal-ref><doi>10.1109/TMI.2016.2553156</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Segmentation of biomedical images is essential for studying and
characterizing anatomical structures, detection and evaluation of pathological
tissues. Segmentation has been further shown to enhance the reconstruction
performance in many tomographic imaging modalities by accounting for
heterogeneities of the excitation field and tissue properties in the imaged
region. This is particularly relevant in optoacoustic tomography, where
discontinuities in the optical and acoustic tissue properties, if not properly
accounted for, may result in deterioration of the imaging performance.
Efficient segmentation of optoacoustic images is often hampered by the
relatively low intrinsic contrast of large anatomical structures, which is
further impaired by the limited angular coverage of some commonly employed
tomographic imaging configurations. Herein, we analyze the performance of
active contour models for boundary segmentation in cross-sectional optoacoustic
tomography. The segmented mask is employed to construct a two compartment model
for the acoustic and optical parameters of the imaged tissues, which is
subsequently used to improve accuracy of the image reconstruction routines. The
performance of the suggested segmentation and modeling approach are showcased
in tissue-mimicking phantoms and small animal imaging experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1510.08983</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1510.08983</id><created>2015-10-30</created><updated>2016-01-11</updated><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Chen</keyname><forenames>Guoguo</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author><author><keyname>Yao</keyname><forenames>Kaisheng</forenames></author><author><keyname>Khudanpur</keyname><forenames>Sanjeev</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Highway Long Short-Term Memory RNNs for Distant Speech Recognition</title><categories>cs.NE cs.AI cs.CL cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we extend the deep long short-term memory (DLSTM) recurrent
neural networks by introducing gated direct connections between memory cells in
adjacent layers. These direct links, called highway connections, enable
unimpeded information flow across different layers and thus alleviate the
gradient vanishing problem when building deeper LSTMs. We further introduce the
latency-controlled bidirectional LSTMs (BLSTMs) which can exploit the whole
history while keeping the latency under control. Efficient algorithms are
proposed to train these novel networks using both frame and sequence
discriminative criteria. Experiments on the AMI distant speech recognition
(DSR) task indicate that we can train deeper LSTMs and achieve better
improvement from sequence training with highway LSTMs (HLSTMs). Our novel model
obtains $43.9/47.7\%$ WER on AMI (SDM) dev and eval sets, outperforming all
previous works. It beats the strong DNN and DLSTM baselines with $15.7\%$ and
$5.3\%$ relative improvement respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1510.08985</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1510.08985</id><created>2015-10-30</created><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Chuangsuwanich</keyname><forenames>Ekapol</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>Prediction-Adaptation-Correction Recurrent Neural Networks for
  Low-Resource Language Speech Recognition</title><categories>cs.CL cs.LG cs.NE eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the use of prediction-adaptation-correction
recurrent neural networks (PAC-RNNs) for low-resource speech recognition. A
PAC-RNN is comprised of a pair of neural networks in which a {\it correction}
network uses auxiliary information given by a {\it prediction} network to help
estimate the state probability. The information from the correction network is
also used by the prediction network in a recurrent loop. Our model outperforms
other state-of-the-art neural networks (DNNs, LSTMs) on IARPA-Babel tasks.
Moreover, transfer learning from a language that is similar to the target
language can help improve performance further.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1512.03077</identifier>
 <datestamp>2019-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1512.03077</id><created>2015-12-08</created><updated>2019-10-10</updated><authors><author><keyname>Raitoharju</keyname><forenames>Matti</forenames></author><author><keyname>Pich&#xe9;</keyname><forenames>Robert</forenames></author></authors><title>On Computational Complexity Reduction Methods for Kalman Filter
  Extensions</title><categories>eess.SY cs.SY math.OC math.PR</categories><acm-class>G.3; G.4</acm-class><journal-ref>in IEEE Aerospace and Electronic Systems Magazine, vol. 34, no.
  10, pp. 2-19, 1 Oct. 2019</journal-ref><doi>10.1109/MAES.2019.2927898</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Kalman filter and its extensions are used in a vast number of aerospace
and navigation applications for nonlinear state estimation of time series. In
the literature, different approaches have been proposed to exploit the
structure of the state and measurement models to reduce the computational
demand of the algorithms. In this tutorial, we survey existing code
optimization methods and present them using unified notation that allows them
to be used with various Kalman filter extensions. We develop the optimization
methods to cover a wider range of models, show how different structural
optimizations can be combined, and present new applications for the existing
optimizations. Furthermore, we present an example that shows that the
exploitation of the structure of the problem can lead to improved estimation
accuracy while reducing the computational load. This tutorial is intended for
persons who are familiar with Kalman filtering and want to get insights for
reducing the computational demand of different Kalman filter extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1512.03473</identifier>
 <datestamp>2020-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1512.03473</id><created>2015-12-10</created><updated>2020-02-26</updated><authors><author><keyname>Stein</keyname><forenames>Manuel S.</forenames></author></authors><title>Sensitivity Analysis for Binary Sampling Systems via Quantitative Fisher
  Information Lower Bounds</title><categories>cs.IT eess.SP math.IT</categories><comments>Former title was: Fisher Information Lower Bounds with Applications
  in Hardware-Aware Nonlinear Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article addresses the sensitivity of sensor systems with minimal signal
digitization complexity regarding the estimation of analog model parameters.
Digital measurements are exclusively available in a hard-limited form, and the
parameters of the analog received signals shall be inferred through efficient
algorithms. As a benchmark, the achievable estimation accuracy is to be
assessed based on theoretical error bounds. To this end, characterization of
the parametric likelihood is required, which forms a challenge for multivariate
binary distributions. In this context, we analyze the Fisher information matrix
of the exponential family and derive a conservative approximation for arbitrary
models. The conservative information matrix rests on a surrogate exponential
family, defined by two equivalences to the real data-generating system. This
probabilistic notion enables designing estimators that consistently achieve the
sensitivity level defined by the inverse of the conservative information matrix
without characterizing the distributions involved. For parameter estimation
with multivariate binary samples, using an equivalent quadratic exponential
distribution tames the computational complexity of the conservative information
matrix such that a quantitative assessment of the achievable error level
becomes tractable. We exploit this for the performance analysis concerning
signal parameter estimation with an array of low-complexity binary sensors by
examining the achievable sensitivity in comparison to an ideal system featuring
receivers supporting data acquisition with infinite amplitude resolution.
Additionally, we demonstrate data-driven sensitivity analysis through the
presented framework by learning the guaranteed achievable performance when
processing sensor data obtained with recursive binary sampling schemes as
implemented in $\Sigma\Delta$-modulating analog-to-digital converters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1512.07331</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1512.07331</id><created>2015-12-22</created><authors><author><keyname>Sreehari</keyname><forenames>Suhas</forenames></author><author><keyname>Venkatakrishnan</keyname><forenames>S. V.</forenames></author><author><keyname>Wohlberg</keyname><forenames>Brendt</forenames></author><author><keyname>Drummy</keyname><forenames>Lawrence F.</forenames></author><author><keyname>Simmons</keyname><forenames>Jeffrey P.</forenames></author><author><keyname>Bouman</keyname><forenames>Charles A.</forenames></author></authors><title>Plug-and-Play Priors for Bright Field Electron Tomography and Sparse
  Interpolation</title><categories>cs.CV eess.IV</categories><comments>13 pages, 11 figures</comments><doi>10.1109/TCI.2016.2599778</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many material and biological samples in scientific imaging are characterized
by non-local repeating structures. These are studied using scanning electron
microscopy and electron tomography. Sparse sampling of individual pixels in a
2D image acquisition geometry, or sparse sampling of projection images with
large tilt increments in a tomography experiment, can enable high speed data
acquisition and minimize sample damage caused by the electron beam.
  In this paper, we present an algorithm for electron tomographic
reconstruction and sparse image interpolation that exploits the non-local
redundancy in images. We adapt a framework, termed plug-and-play (P&amp;P) priors,
to solve these imaging problems in a regularized inversion setting. The power
of the P&amp;P approach is that it allows a wide array of modern denoising
algorithms to be used as a &quot;prior model&quot; for tomography and image
interpolation. We also present sufficient mathematical conditions that ensure
convergence of the P&amp;P approach, and we use these insights to design a new
non-local means denoising algorithm. Finally, we demonstrate that the algorithm
produces higher quality reconstructions on both simulated and real electron
microscope data, along with improved convergence properties compared to other
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.06756</identifier>
 <datestamp>2020-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1601.06756</id><created>2016-01-25</created><updated>2018-04-30</updated><authors><author><keyname>G&#xfc;nl&#xfc;</keyname><forenames>Onur</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author></authors><title>Privacy, Secrecy, and Storage with Multiple Noisy Measurements of
  Identifiers</title><categories>cs.IT cs.CR cs.MM eess.SP math.IT math.PR</categories><comments>To appear in IEEE Transactions on Information Forensics and Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The key-leakage-storage region is derived for a generalization of a classic
two-terminal key agreement model. The additions to the model are that the
encoder observes a hidden, or noisy, version of the identifier, and that the
encoder and decoder can perform multiple measurements. To illustrate the
behavior of the region, the theory is applied to binary identifiers and noise
modeled via binary symmetric channels. In particular, the key-leakage-storage
region is simplified by applying Mrs. Gerber's lemma twice in different
directions to a Markov chain. The growth in the region as the number of
measurements increases is quantified. The amount by which the privacy-leakage
rate reduces for a hidden identifier as compared to a noise-free (visible)
identifier at the encoder is also given. If the encoder incorrectly models the
source as visible, it is shown that substantial secrecy leakage may occur and
the reliability of the reconstructed key might decrease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07624</identifier>
 <datestamp>2018-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1601.07624</id><created>2016-01-27</created><authors><author><keyname>Zhu</keyname><forenames>Jieli</forenames></author><author><keyname>Zhao</keyname><forenames>Tong</forenames></author><author><keyname>Huang</keyname><forenames>Tianyao</forenames></author><author><keyname>Zhang</keyname><forenames>Dengfeng</forenames></author></authors><title>Analysis of Random Pulse Repetition Interval Radar</title><categories>stat.AP eess.SP</categories><comments>5 pages</comments><doi>10.1109/RADAR.2016.7485193</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random pulse repetition interval (PRI) waveform arouses great interests in
the field of modern radars due to its ability to alleviate range and Doppler
ambiguities as well as enhance electronic counter-countermeasures (ECCM)
capabilities. Theoretical results pertaining to the statistical characteristics
of ambiguity function (AF) are derived in this work, indicating that the range
and Doppler ambiguities can be effectively suppressed by increasing the number
of pulses and the range of PRI jitters. This provides an important guidance in
terms of waveform design. As is well known, the significantly lifted sidelobe
pedestal induced by PRI randomization will degrade the performance of weak
target detection. Proceeding from that, we propose to employ orthogonal
matching pursuit (OMP) to overcome this issue. Simulation results demonstrate
that the OMP method can effectively lower the sidelobe pedestal of strong
target and improve the performance of weak target estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01969</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1602.01969</id><created>2016-02-05</created><authors><author><keyname>Todescato</keyname><forenames>Marco</forenames></author><author><keyname>Simpson-Porco</keyname><forenames>John W.</forenames></author><author><keyname>D&#xf6;rfler</keyname><forenames>Florian</forenames></author><author><keyname>Carli</keyname><forenames>Ruggero</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Voltage stress minimization by optimal reactive power control</title><categories>math.OC cs.SY eess.SY</categories><comments>10 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A standard operational requirement in power systems is that the voltage
magnitudes lie within prespecified bounds. Conventional engineering wisdom
suggests that such a tightly-regulated profile, imposed for system design
purposes and good operation of the network, should also guarantee a secure
system, operating far from static bifurcation instabilities such as voltage
collapse. In general however, these two objectives are distinct and must be
separately enforced. We formulate an optimization problem which maximizes the
distance to voltage collapse through injections of reactive power, subject to
power flow and operational voltage constraints. By exploiting a linear
approximation of the power flow equations we arrive at a convex reformulation
which can be efficiently solved for the optimal injections. We also address the
planning problem of allocating the resources by recasting our problem in a
sparsity-promoting framework that allows us to choose a desired trade-off
between optimality of injections and the number of required actuators. Finally,
we present a distributed algorithm to solve the optimization problem, showing
that it can be implemented on-line as a feedback controller. We illustrate the
performance of our results with the IEEE30 bus network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1603.01739</identifier>
 <datestamp>2019-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1603.01739</id><created>2016-03-05</created><authors><author><keyname>Sudarshan</keyname><forenames>Viswanath P</forenames></author><author><keyname>Weiser</keyname><forenames>Tobias</forenames></author><author><keyname>Chintala</keyname><forenames>Phalgun</forenames></author><author><keyname>Mandal</keyname><forenames>Subhamoy</forenames></author><author><keyname>Dutta</keyname><forenames>Rahul</forenames></author></authors><title>Grading of Mammalian Cumulus Oocyte Complexes using Machine Learning for
  in Vitro Embryo Culture</title><categories>cs.CV eess.IV physics.med-ph</categories><comments>IEEE BHI 2016</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Visual observation of Cumulus Oocyte Complexes provides only limited
information about its functional competence, whereas the molecular evaluations
methods are cumbersome or costly. Image analysis of mammalian oocytes can
provide attractive alternative to address this challenge. However, it is
complex, given the huge number of oocytes under inspection and the subjective
nature of the features inspected for identification. Supervised machine
learning methods like random forest with annotations from expert biologists can
make the analysis task standardized and reduces inter-subject variability. We
present a semi-automatic framework for predicting the class an oocyte belongs
to, based on multi-object parametric segmentation on the acquired microscopic
image followed by a feature based classification using random forests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1603.03697</identifier>
 <datestamp>2018-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1603.03697</id><created>2016-03-11</created><authors><author><keyname>Chepuri</keyname><forenames>Sundeep Prabhakar</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Subsampling for Graph Power Spectrum Estimation</title><categories>cs.IT eess.SP math.IT</categories><comments>Contains 4 figures. Matlab scripts to reproduce these results can be
  downloaded from: http://cas.et.tudelft.nl/~sundeep/sw/gpsd.zip</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we focus on subsampling stationary random processes that reside
on the vertices of undirected graphs. Second-order stationary graph signals are
obtained by filtering white noise and they admit a well-defined power spectrum.
Estimating the graph power spectrum forms a central component of stationary
graph signal processing and related inference tasks. We show that by sampling a
significantly smaller subset of vertices and using simple least squares, we can
reconstruct the power spectrum of the graph signal from the subsampled
observations, without any spectral priors. In addition, a near-optimal greedy
algorithm is developed to design the subsampling scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1604.00970</identifier>
 <datestamp>2019-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1604.00970</id><created>2016-03-14</created><updated>2017-02-21</updated><authors><author><keyname>Granstrom</keyname><forenames>Karl</forenames></author><author><keyname>Baum</keyname><forenames>Marcus</forenames></author><author><keyname>Reuter</keyname><forenames>Stephan</forenames></author></authors><title>Extended Object Tracking: Introduction, Overview and Applications</title><categories>cs.CV cs.SY eess.SP</categories><comments>30 pages, 19 figures</comments><journal-ref>Journal of Advances in Information Fusion, Volume 12, Number 2,
  Pages 139-174, December 2016, ISSN 1557-6418</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article provides an elaborate overview of current research in extended
object tracking. We provide a clear definition of the extended object tracking
problem and discuss its delimitation to other types of object tracking. Next,
different aspects of extended object modelling are extensively discussed.
Subsequently, we give a tutorial introduction to two basic and well used
extended object tracking approaches - the random matrix approach and the Kalman
filter-based approach for star-convex shapes. The next part treats the tracking
of multiple extended objects and elaborates how the large number of feasible
association hypotheses can be tackled using both Random Finite Set (RFS) and
Non-RFS multi-object trackers. The article concludes with a summary of current
applications, where four example applications involving camera, X-band radar,
light detection and ranging (lidar), red-green-blue-depth (RGB-D) sensors are
highlighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1605.02324</identifier>
 <datestamp>2018-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1605.02324</id><created>2016-05-08</created><updated>2016-06-22</updated><authors><author><keyname>Jeon</keyname><forenames>Charles</forenames></author><author><keyname>Maleki</keyname><forenames>Arian</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>On the Performance of Mismatched Data Detection in Large MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>Will be presented at the 2016 IEEE International Symposium on
  Information Theory</comments><doi>10.1109/ISIT.2016.7541285</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the performance of mismatched data detection in large
multiple-input multiple-output (MIMO) systems, where the prior distribution of
the transmit signal used in the data detector differs from the true prior. To
minimize the performance loss caused by this prior mismatch, we include a
tuning stage into our recently-proposed large MIMO approximate message passing
(LAMA) algorithm, which allows us to develop mismatched LAMA algorithms with
optimal as well as sub-optimal tuning. We show that carefully-selected priors
often enable simpler and computationally more efficient algorithms compared to
LAMA with the true prior while achieving near-optimal performance. A
performance analysis of our algorithms for a Gaussian prior and a uniform prior
within a hypercube covering the QAM constellation recovers classical and recent
results on linear and non-linear MIMO data detection, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1605.06588</identifier>
 <datestamp>2019-08-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1605.06588</id><created>2016-05-21</created><updated>2018-11-06</updated><authors><author><keyname>Ganzfried</keyname><forenames>Sam</forenames></author><author><keyname>Yusuf</keyname><forenames>Farzana</forenames></author></authors><title>Optimal Number of Choices in Rating Contexts</title><categories>cs.AI cs.IT cs.SI eess.SP math.IT math.PR</categories><journal-ref>Big Data Cogn. Comput. 2019, 3, 48</journal-ref><doi>10.3390/bdcc3030048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many settings people must give numerical scores to entities from a small
discrete set. For instance, rating physical attractiveness from 1--5 on dating
sites, or papers from 1--10 for conference reviewing. We study the problem of
understanding when using a different number of options is optimal. We consider
the case when scores are uniform random and Gaussian. We study computationally
when using 2, 3, 4, 5, and 10 options out of a total of 100 is optimal in these
models (though our theoretical analysis is for a more general setting with $k$
choices from $n$ total options as well as a continuous underlying space). One
may expect that using more options would always improve performance in this
model, but we show that this is not necessarily the case, and that using fewer
choices---even just two---can surprisingly be optimal in certain situations.
While in theory for this setting it would be optimal to use all 100 options, in
practice this is prohibitive, and it is preferable to utilize a smaller number
of options due to humans' limited computational resources. Our results could
have many potential applications, as settings requiring entities to be ranked
by humans are ubiquitous. There could also be applications to other fields such
as signal or image processing where input values from a large set must be
mapped to output values in a smaller set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1605.07809</identifier>
 <datestamp>2018-07-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1605.07809</id><created>2016-05-25</created><updated>2016-07-22</updated><authors><author><keyname>Kawahara</keyname><forenames>Hideki</forenames></author><author><keyname>Agiomyrgiannakis</keyname><forenames>Yannis</forenames></author><author><keyname>Zen</keyname><forenames>Heiga</forenames></author></authors><title>Using instantaneous frequency and aperiodicity detection to estimate F0
  for high-quality speech synthesis</title><categories>cs.SD eess.AS eess.SP</categories><comments>Accepted for presentation in ISCA workshop SSW9</comments><journal-ref>9th ISCA Speech Synthesis Workshop, 2016, pp.221-228</journal-ref><doi>10.21437/SSW.2016-36</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a general and flexible framework for F0 and
aperiodicity (additive non periodic component) analysis, specifically intended
for high-quality speech synthesis and modification applications. The proposed
framework consists of three subsystems: instantaneous frequency estimator and
initial aperiodicity detector, F0 trajectory tracker, and F0 refinement and
aperiodicity extractor. A preliminary implementation of the proposed framework
substantially outperformed (by a factor of 10 in terms of RMS F0 estimation
error) existing F0 extractors in tracking ability of temporally varying F0
trajectories. The front end aperiodicity detector consists of a complex-valued
wavelet analysis filter with a highly selective temporal and spectral envelope.
This front end aperiodicity detector uses a new measure that quantifies the
deviation from periodicity. The measure is less sensitive to slow FM and AM and
closely correlates with the signal to noise ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.00325</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1607.00325</id><created>2016-07-01</created><updated>2017-01-03</updated><authors><author><keyname>Yu</keyname><forenames>Dong</forenames></author><author><keyname>Kolb&#xe6;k</keyname><forenames>Morten</forenames></author><author><keyname>Tan</keyname><forenames>Zheng-Hua</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author></authors><title>Permutation Invariant Training of Deep Models for Speaker-Independent
  Multi-talker Speech Separation</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel deep learning model, which supports permutation invariant
training (PIT), for speaker independent multi-talker speech separation,
commonly known as the cocktail-party problem. Different from most of the prior
arts that treat speech separation as a multi-class regression problem and the
deep clustering technique that considers it a segmentation (or clustering)
problem, our model optimizes for the separation regression error, ignoring the
order of mixing sources. This strategy cleverly solves the long-lasting label
permutation problem that has prevented progress on deep learning based
techniques for speech separation. Experiments on the equal-energy mixing setup
of a Danish corpus confirms the effectiveness of PIT. We believe improvements
built upon PIT can eventually solve the cocktail-party problem and enable
real-world adoption of, e.g., automatic meeting transcription and multi-party
human-computer interaction, where overlapping speech is common.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1607.04753</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1607.04753</id><created>2016-07-16</created><updated>2016-09-13</updated><authors><author><keyname>Interdonato</keyname><forenames>Giovanni</forenames></author><author><keyname>Ngo</keyname><forenames>Hien Quoc</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author><author><keyname>Frenger</keyname><forenames>P&#xe5;l</forenames></author></authors><title>How Much Do Downlink Pilots Improve Cell-Free Massive MIMO?</title><categories>cs.IT eess.SP math.IT</categories><comments>7 pages, 5 figures. IEEE Global Communications Conference 2016
  (GLOBECOM). Accepted</comments><doi>10.1109/GLOCOM.2016.7841875</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the benefits of including downlink pilots in a
cell-free massive MIMO system. We derive an approximate per-user achievable
downlink rate for conjugate beamforming processing, which takes into account
both uplink and downlink channel estimation errors, and power control. A
performance comparison is carried out, in terms of per-user net throughput,
considering cell-free massive MIMO operation with and without downlink
training, for different network densities. We take also into account the
performance improvement provided by max-min fairness power control in the
downlink. Numerical results show that, exploiting downlink pilots, the
performance can be considerably improved in low density networks over the
conventional scheme where the users rely on statistical channel knowledge only.
In high density networks, performance improvements are moderate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05121</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1608.05121</id><created>2016-08-17</created><updated>2016-09-13</updated><authors><author><keyname>Interdonato</keyname><forenames>Giovanni</forenames></author><author><keyname>Ngo</keyname><forenames>Hien Quoc</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author><author><keyname>Frenger</keyname><forenames>P&#xe5;l</forenames></author></authors><title>On the Performance of Cell-Free Massive MIMO with Short-Term Power
  Constraints</title><categories>cs.IT eess.SP math.IT</categories><comments>6 pages, 4 figures, 21st IEEE International Workshop on Computer
  Aided Modelling and Design of Communication Links and Networks (CAMAD).
  Special Session - 5Gwireless: Innovative Architectures, Wireless Technologies
  and Tools for High Capacity and Sustainable 5G Ultra-Dense Cellular Networks</comments><doi>10.1109/CAMAD.2016.7790362</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a time-division duplex cell-free massive
multiple-input multiple-output (MIMO) system where many distributed access
points (APs) simultaneously serve many users. A normalized conjugate
beamforming scheme, which satisfies short-term average power constraints at the
APs, is proposed and analyzed taking into account the effect of imperfect
channel information. We derive an approximate closed-form expression for the
per-user achievable downlink rate of this scheme. We also provide, analytically
and numerically, a performance comparison between the normalized conjugate
beamforming and the conventional conjugate beamforming scheme in [1] (which
satisfies long-term average power constraints). Normalized conjugate
beamforming scheme reduces the beamforming uncertainty gain, which comes from
the users' lack of the channel state information knowledge, and hence, it
improves the achievable downlink rate compared to the conventional conjugate
beamforming scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.03448</identifier>
 <datestamp>2018-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1609.03448</id><created>2016-09-12</created><authors><author><keyname>Chepuri</keyname><forenames>Sundeep Prabhakar</forenames></author><author><keyname>Liu</keyname><forenames>Sijia</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames><suffix>III</suffix></author></authors><title>Learning Sparse Graphs Under Smoothness Prior</title><categories>cs.LG eess.SP</categories><comments>ICASSP 2017 conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we are interested in learning the underlying graph structure
behind training data. Solving this basic problem is essential to carry out any
graph signal processing or machine learning task. To realize this, we assume
that the data is smooth with respect to the graph topology, and we parameterize
the graph topology using an edge sampling function. That is, the graph
Laplacian is expressed in terms of a sparse edge selection vector, which
provides an explicit handle to control the sparsity level of the graph. We
solve the sparse graph learning problem given some training data in both the
noiseless and noisy settings. Given the true smooth data, the posed sparse
graph learning problem can be solved optimally and is based on simple rank
ordering. Given the noisy data, we show that the joint sparse graph learning
and denoising problem can be simplified to designing only the sparse edge
selection vector, which can be solved using convex optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.03528</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1609.03528</id><created>2016-09-12</created><updated>2017-01-25</updated><authors><author><keyname>Xiong</keyname><forenames>W.</forenames></author><author><keyname>Droppo</keyname><forenames>J.</forenames></author><author><keyname>Huang</keyname><forenames>X.</forenames></author><author><keyname>Seide</keyname><forenames>F.</forenames></author><author><keyname>Seltzer</keyname><forenames>M.</forenames></author><author><keyname>Stolcke</keyname><forenames>A.</forenames></author><author><keyname>Yu</keyname><forenames>D.</forenames></author><author><keyname>Zweig</keyname><forenames>G.</forenames></author></authors><title>The Microsoft 2016 Conversational Speech Recognition System</title><categories>cs.CL eess.AS</categories><journal-ref>Proc. IEEE ICASSP, 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe Microsoft's conversational speech recognition system, in which we
combine recent developments in neural-network-based acoustic and language
modeling to advance the state of the art on the Switchboard recognition task.
Inspired by machine learning ensemble techniques, the system uses a range of
convolutional and recurrent neural networks. I-vector modeling and lattice-free
MMI training provide significant gains for all acoustic model architectures.
Language model rescoring with multiple forward and backward running RNNLMs, and
word posterior-based system combination provide a 20% boost. The best single
system uses a ResNet architecture acoustic model with RNNLM rescoring, and
achieves a word error rate of 6.9% on the NIST 2000 Switchboard task. The
combined system has an error rate of 6.2%, representing an improvement over
previously reported results on this benchmark task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.05520</identifier>
 <datestamp>2019-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1609.05520</id><created>2016-09-18</created><updated>2018-07-12</updated><authors><author><keyname>Deshpande</keyname><forenames>Aniket</forenames></author><author><keyname>Jagtap</keyname><forenames>Pushpak</forenames></author><author><keyname>Bansode</keyname><forenames>Prashant</forenames></author><author><keyname>Mahindrakar</keyname><forenames>Arun</forenames></author><author><keyname>Singh</keyname><forenames>Navadeep</forenames></author></authors><title>Complex Laplacian based Distributed Control for Multi-Agent Network</title><categories>math.OC cs.SY eess.SY</categories><comments>14 pages, 4 figures</comments><acm-class>I.2.11</acm-class><doi>10.1142/S0219525918500157</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The work done in this paper, proposes a complex Laplacian-based distributed
control scheme for convergence in the multi-agent network. The proposed scheme
has been designated as cascade formulation. The proposed technique exploits the
traditional method of organizing large scattered networks into smaller
interconnected clusters to optimize information flow within the network. The
complex Laplacian-based approach results in a hierarchical structure, with
formation of a meta-cluster leading other clusters in the network. The proposed
formulation enables flexibility to constrain the eigen spectra of the overall
closed-loop dynamics, ensuring desired convergence rate and control input
intensity. The sufficient conditions ensuring globally stable formation for
proposed formulation are also asserted. Robustness of the proposed formulation
to uncertainties like loss in communication links and actuator failure has also
been discussed. The effectiveness of the proposed approach is illustrated by
simulating a finitely large network of thirty vehicles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.09470</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1609.09470</id><created>2016-09-29</created><updated>2019-06-11</updated><authors><author><keyname>Wright</keyname><forenames>Matthew A.</forenames></author><author><keyname>Horowitz</keyname><forenames>Roberto</forenames></author><author><keyname>Kurzhanskiy</keyname><forenames>Alex A.</forenames></author></authors><title>Macroscopic Modeling, Calibration, and Simulation of Managed
  Lane-Freeway Networks, Part I: Topological and Phenomenological Modeling</title><categories>cs.SY eess.SY nlin.CG</categories><comments>The above abstract is slightly abbreviated, please see the document
  for the full abstract</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To help mitigate road congestion caused by the unrelenting growth of traffic
demand, many transit authorities have implemented managed lane policies.
Managed lanes typically run parallel to a freeway's standard, general-purpose
(GP) lanes, but are restricted to certain types of vehicles. It was originally
thought that managed lanes would improve the use of existing infrastructure
through incentivization of demand-management behaviors like carpooling, but
implementations have often been characterized by unpredicted phenomena that is
often to detrimental system performance.
  This paper presents several macroscopic traffic modeling tools we have used
for study of freeways equipped with managed lanes, or &quot;managed lane-freeway
networks.&quot; The proposed framework is based on the widely-used first-order
kinematic wave theory. In this model, the GP and the managed lanes are modeled
as parallel links connected by nodes, where certain type of traffic may switch
between GP and managed lane links. Two types of managed lane topologies are
considered: full-access, where vehicles can switch between the GP and the
managed lanes anywhere; and separated, where such switching is allowed only at
certain locations called gates.
  We also describe methods to incorporate in three phenomena into our model
that are particular to managed lane-freeway networks. The inertia effect
reflects drivers' inclination to stay in their lane as long as possible and
switch only if this would obviously improve their travel condition. The
friction effect reflects the empirically-observed driver fear of moving fast in
a managed lane while traffic in the adjacent GP lanes moves slowly due to
congestion. The smoothing effect describes how managed lanes can increase
throughput at bottlenecks by reducing lane changes. We present simple models
for each of these phenomena that fit within the general macroscopic theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1610.00227</identifier>
 <datestamp>2018-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1610.00227</id><created>2016-10-02</created><updated>2018-11-05</updated><authors><author><keyname>Jeon</keyname><forenames>Charles</forenames></author><author><keyname>Li</keyname><forenames>Zequn</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>Approximate Gram-Matrix Interpolation for Wideband Massive MU-MIMO
  Systems</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous linear and non-linear data-detection and precoding algorithms for
wideband massive multi-user (MU) multiple-input multiple-output (MIMO) wireless
systems that rely on orthogonal frequency-division multiplexing (OFDM) or
single-carrier frequency-division multiple access (SC-FDMA) require the
computation of the Gram matrix for each active subcarrier. Computing the Gram
matrix for each active subcarrier, however, results in excessively high
computational complexity. In this paper, we propose novel, approximate
algorithms that significantly reduce the complexity of Gram-matrix computation
by simultaneously exploiting correlation across subcarriers and channel
hardening. We show analytically that a small fraction of Gram-matrix
computations in combination with approximate interpolation schemes are
sufficient to achieve near-optimal error-rate performance at low computational
complexity in massive MU-MIMO systems. We also demonstrate that the proposed
methods exhibit improved robustness against channel-estimation errors compared
to exact Gram-matrix interpolation algorithms that typically require high
computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1610.00384</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1610.00384</id><created>2016-10-02</created><updated>2017-11-27</updated><authors><author><keyname>Soltani</keyname><forenames>Ramin</forenames></author><author><keyname>Bash</keyname><forenames>Boulat</forenames></author><author><keyname>Goeckel</keyname><forenames>Dennis</forenames></author><author><keyname>Guha</keyname><forenames>Saikat</forenames></author><author><keyname>Towsley</keyname><forenames>Don</forenames></author></authors><title>Covert Single-hop Communication in a Wireless Network with Distributed
  Artificial Noise Generation</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>Submitted to Allerton Conference 2014</comments><doi>10.1109/ALLERTON.2014.7028575</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Covert communication, also known as low probability of detection (LPD)
communication, prevents the adversary from knowing that a communication is
taking place. Recent work has demonstrated that, in a three-party scenario with
a transmitter (Alice), intended recipient (Bob), and adversary (Warden Willie),
the maximum number of bits that can be transmitted reliably from Alice to Bob
without detection by Willie, when additive white Gaussian noise (AWGN) channels
exist between all parties, is on the order of the square root of the number of
channel uses. In this paper, we begin consideration of network scenarios by
studying the case where there are additional &quot;friendly&quot; nodes present in the
environment that can produce artificial noise to aid in hiding the
communication. We establish achievability results by considering constructions
where the system node closest to the warden produces artificial noise and
demonstrate a significant improvement in the throughput achieved covertly,
without requiring close coordination between Alice and the noise-generating
node. Conversely, under mild restrictions on the communication strategy, we
demonstrate no higher covert throughput is possible. Extensions to the
consideration of the achievable covert throughput when multiple wardens
randomly located in the environment collaborate to attempt detection of the
transmitter are also considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1610.04815</identifier>
 <datestamp>2019-07-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1610.04815</id><created>2016-10-15</created><updated>2019-06-11</updated><authors><author><keyname>Wang</keyname><forenames>Yuh-Shyang</forenames></author><author><keyname>Matni</keyname><forenames>Nikolai</forenames></author><author><keyname>Doyle</keyname><forenames>John C.</forenames></author></authors><title>A System Level Approach to Controller Synthesis</title><categories>eess.SY cs.SY math.OC</categories><comments>arXiv admin note: substantial text overlap with arXiv:1904.01634</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biological and advanced cyberphysical control systems often have limited,
sparse, uncertain, and distributed communication and computing in addition to
sensing and actuation. Fortunately, the corresponding plants and performance
requirements are also sparse and structured, and this must be exploited to make
constrained controller design feasible and tractable. We introduce a new
&quot;system level&quot; (SL) approach involving three complementary SL elements. System
Level Parameterizations (SLPs) generalize state space and Youla
parameterizations of all stabilizing controllers and the responses they
achieve, and combine with System Level Constraints (SLCs) to parameterize the
largest known class of constrained stabilizing controllers that admit a convex
characterization, generalizing quadratic invariance (QI). SLPs also lead to a
generalization of detectability and stabilizability, suggesting the existence
of a rich separation structure, that when combined with SLCs, is naturally
applicable to structurally constrained controllers and systems. We further
provide a catalog of useful SLCs, most importantly including sparsity, delay,
and locality constraints on both communication and computing internal to the
controller, and external system performance. The resulting System Level
Synthesis (SLS) problems that arise define the broadest known class of
constrained optimal control problems that can be solved using convex
programming. An example illustrates how this system level approach can
systematically explore tradeoffs in controller performance, robustness, and
synthesis/implementation complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1610.05256</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1610.05256</id><created>2016-10-17</created><updated>2017-02-17</updated><authors><author><keyname>Xiong</keyname><forenames>W.</forenames></author><author><keyname>Droppo</keyname><forenames>J.</forenames></author><author><keyname>Huang</keyname><forenames>X.</forenames></author><author><keyname>Seide</keyname><forenames>F.</forenames></author><author><keyname>Seltzer</keyname><forenames>M.</forenames></author><author><keyname>Stolcke</keyname><forenames>A.</forenames></author><author><keyname>Yu</keyname><forenames>D.</forenames></author><author><keyname>Zweig</keyname><forenames>G.</forenames></author></authors><title>Achieving Human Parity in Conversational Speech Recognition</title><categories>cs.CL eess.AS</categories><comments>Revised for publication, updated results</comments><report-no>MSR-TR-2016-71, revised Feb. 2017</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conversational speech recognition has served as a flagship speech recognition
task since the release of the Switchboard corpus in the 1990s. In this paper,
we measure the human error rate on the widely used NIST 2000 test set, and find
that our latest automated system has reached human parity. The error rate of
professional transcribers is 5.9% for the Switchboard portion of the data, in
which newly acquainted pairs of people discuss an assigned topic, and 11.3% for
the CallHome portion where friends and family members have open-ended
conversations. In both cases, our automated system establishes a new state of
the art, and edges past the human benchmark, achieving error rates of 5.8% and
11.0%, respectively. The key to our system's performance is the use of various
convolutional and LSTM acoustic model architectures, combined with a novel
spatial smoothing method and lattice-free MMI acoustic training, multiple
recurrent neural network language modeling approaches, and a systematic use of
system combination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1610.08274</identifier>
 <datestamp>2018-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1610.08274</id><created>2016-10-26</created><authors><author><keyname>Tuladhar</keyname><forenames>Saurav R.</forenames></author><author><keyname>Buck</keyname><forenames>John R.</forenames></author></authors><title>Approximate eigenvalue distribution of a cylindrically isotropic noise
  sample covariance matrix</title><categories>cs.SY eess.SP</categories><comments>Accepted to IEEE Statistical Signal Processing Workshop 2012</comments><journal-ref>IEEE Stat.Sig.Proc.Wshp (2012), 824-827</journal-ref><doi>10.1109/SSP.2012.6319833</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The statistical behavior of the eigenvalues of the sample covariance matrix
(SCM) plays a key role in determining the performance of adaptive beamformers
(ABF) in presence of noise. This paper presents a method to compute the
approximate eigenvalue density function (EDF) for the SCM of a \cin{} field
when only a finite number of shapshots are available. The EDF of the ensemble
covariance matrix (ECM) is modeled as an atomic density with many fewer atoms
than the SCM size. The model results in substantial computational savings over
more direct methods of computing the EDF. The approximate EDF obtained from
this method agrees closely with histograms of eigenvalues obtained from
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.02721</identifier>
 <datestamp>2018-08-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1611.02721</id><created>2016-11-06</created><authors><author><keyname>Tuladhar</keyname><forenames>Saurav R</forenames></author><author><keyname>Buck</keyname><forenames>John R</forenames></author></authors><title>Unit circle MVDR beamformer</title><categories>cs.IT eess.SP math.IT</categories><comments>Accepted to ICASSP 2015</comments><doi>10.1109/ICASSP.2015.7178418</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The array polynomial is the z-transform of the array weights for a narrowband
planewave beamformer using a uniform linear array (ULA). Evaluating the array
polynomial on the unit circle in the complex plane yields the beampattern. The
locations of the polynomial zeros on the unit circle indicate the nulls of the
beampattern. For planewave signals measured with a ULA, the locations of the
ensemble MVDR polynomial zeros are constrained on the unit circle. However,
sample matrix inversion (SMI) MVDR polynomial zeros generally do not fall on
the unit circle. The proposed unit circle MVDR (UC MVDR) projects the zeros of
the SMI MVDR polynomial radially on the unit circle. This satisfies the
constraint on the zeros of ensemble MVDR polynomial. Numerical simulations show
that the UC MVDR beamformer suppresses interferers better than the SMI MVDR and
the diagonal loaded MVDR beamformer and also improves the white noise gain
(WNG).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.03130</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1611.03130</id><created>2016-11-09</created><authors><author><keyname>Cavigelli</keyname><forenames>Lukas</forenames></author><author><keyname>Bernath</keyname><forenames>Dominic</forenames></author><author><keyname>Magno</keyname><forenames>Michele</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>Computationally Efficient Target Classification in Multispectral Image
  Data with Deep Neural Networks</title><categories>cs.CV cs.AI cs.NE eess.IV eess.SP</categories><comments>Presented at SPIE Security + Defence 2016 Proc. SPIE 9997, Target and
  Background Signatures II</comments><doi>10.1117/12.2241383</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting and classifying targets in video streams from surveillance cameras
is a cumbersome, error-prone and expensive task. Often, the incurred costs are
prohibitive for real-time monitoring. This leads to data being stored locally
or transmitted to a central storage site for post-incident examination. The
required communication links and archiving of the video data are still
expensive and this setup excludes preemptive actions to respond to imminent
threats. An effective way to overcome these limitations is to build a smart
camera that transmits alerts when relevant video sequences are detected. Deep
neural networks (DNNs) have come to outperform humans in visual classifications
tasks. The concept of DNNs and Convolutional Networks (ConvNets) can easily be
extended to make use of higher-dimensional input data such as multispectral
data. We explore this opportunity in terms of achievable accuracy and required
computational effort. To analyze the precision of DNNs for scene labeling in an
urban surveillance scenario we have created a dataset with 8 classes obtained
in a field experiment. We combine an RGB camera with a 25-channel VIS-NIR
snapshot sensor to assess the potential of multispectral image data for target
classification. We evaluate several new DNNs, showing that the spectral
information fused together with the RGB frames can be used to improve the
accuracy of the system or to achieve similar accuracy with a 3x smaller
computation effort. We achieve a very high per-pixel accuracy of 99.1%. Even
for scarcely occurring, but particularly interesting classes, such as cars, 75%
of the pixels are labeled correctly with errors occurring only around the
border of the objects. This high accuracy was obtained with a training set of
only 30 labeled images, paving the way for fast adaptation to various
application scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04834</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1611.04834</id><created>2016-11-15</created><authors><author><keyname>Condo</keyname><forenames>Carlo</forenames></author><author><keyname>Leduc-Primeau</keyname><forenames>Francois</forenames></author><author><keyname>Sarkis</keyname><forenames>Gabi</forenames></author><author><keyname>Giard</keyname><forenames>Pascal</forenames></author><author><keyname>Gross</keyname><forenames>Warren</forenames></author></authors><title>Stall Pattern Avoidance in Polynomial Product Codes</title><categories>cs.IT eess.SP math.IT</categories><comments>4 pages, 2 figures, GlobalSiP 2016</comments><msc-class>94B35</msc-class><doi>10.1109/GlobalSIP.2016.7905932</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Product codes are a concatenated error-correction scheme that has been often
considered for applications requiring very low bit-error rates, which demand
that the error floor be decreased as much as possible. In this work, we
consider product codes constructed from polynomial algebraic codes, and propose
a novel low-complexity post-processing technique that is able to improve the
error-correction performance by orders of magnitude. We provide lower bounds
for the error rate achievable under post processing, and present simulation
results indicating that these bounds are tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.01884</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1612.01884</id><created>2016-12-06</created><authors><author><keyname>Liu</keyname><forenames>Entao</forenames></author><author><keyname>Zhu</keyname><forenames>Lijun</forenames></author><author><keyname>Raj</keyname><forenames>Anupama Govinda</forenames></author><author><keyname>McClellan</keyname><forenames>James H.</forenames></author><author><keyname>Al-Shuhail</keyname><forenames>Abdullatif</forenames></author><author><keyname>Kaka</keyname><forenames>SanLinn I.</forenames></author><author><keyname>Iqbal</keyname><forenames>Naveed</forenames></author></authors><title>Microseismic events enhancement and detection in sensor arrays using
  autocorrelation based filtering</title><categories>physics.geo-ph eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Passive microseismic data are commonly buried in noise, which presents a
significant challenge for signal detection and recovery. For recordings from a
surface sensor array where each trace contains a time-delayed arrival from the
event, we propose an autocorrelation-based stacking method that designs a
denoising filter from all the traces, as well as a multi-channel detection
scheme. This approach circumvents the issue of time aligning the traces prior
to stacking because every trace's autocorrelation is centered at zero in the
lag domain. The effect of white noise is concentrated near zero lag, so the
filter design requires a predictable adjustment of the zero-lag value.
Truncation of the autocorrelation is employed to smooth the impulse response of
the denoising filter. In order to extend the applicability of the algorithm, we
also propose a noise prewhitening scheme that addresses cases with colored
noise. The simplicity and robustness of this method are validated with
synthetic and real seismic traces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.03615</identifier>
 <datestamp>2018-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1612.03615</id><created>2016-12-12</created><updated>2017-05-20</updated><authors><author><keyname>Romero</keyname><forenames>Daniel</forenames></author><author><keyname>Ioannidis</keyname><forenames>Vassilis N.</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Kernel-based Reconstruction of Space-time Functions on Dynamic Graphs</title><categories>cs.LG eess.SP stat.ML</categories><comments>Submitted to IEEE Journal of Selected Topics in Signal processing,
  Oct. 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph-based methods pervade the inference toolkits of numerous disciplines
including sociology, biology, neuroscience, physics, chemistry, and
engineering. A challenging problem encountered in this context pertains to
determining the attributes of a set of vertices given those of another subset
at possibly different time instants. Leveraging spatiotemporal dynamics can
drastically reduce the number of observed vertices, and hence the cost of
sampling. Alleviating the limited flexibility of existing approaches, the
present paper broadens the existing kernel-based graph function reconstruction
framework to accommodate time-evolving functions over possibly time-evolving
topologies. This approach inherits the versatility and generality of
kernel-based methods, for which no knowledge on distributions or second-order
statistics is required. Systematic guidelines are provided to construct two
families of space-time kernels with complementary strengths. The first
facilitates judicious control of regularization on a space-time frequency
plane, whereas the second can afford time-varying topologies. Batch and online
estimators are also put forth, and a novel kernel Kalman filter is developed to
obtain these estimates at affordable computational cost. Numerical tests with
real data sets corroborate the merits of the proposed methods relative to
competing alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.07003</identifier>
 <datestamp>2019-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1612.07003</id><created>2016-12-21</created><updated>2019-12-17</updated><authors><author><keyname>Zwanenburg</keyname><forenames>Alex</forenames><affiliation>for the Image Biomarker Standardisation Initiative</affiliation></author><author><keyname>Leger</keyname><forenames>Stefan</forenames><affiliation>for the Image Biomarker Standardisation Initiative</affiliation></author><author><keyname>Valli&#xe8;res</keyname><forenames>Martin</forenames><affiliation>for the Image Biomarker Standardisation Initiative</affiliation></author><author><keyname>L&#xf6;ck</keyname><forenames>Steffen</forenames><affiliation>for the Image Biomarker Standardisation Initiative</affiliation></author></authors><title>Image biomarker standardisation initiative</title><categories>cs.CV eess.IV</categories><comments>Added figures 2.5, 2.6. Replaced figure 2.7. Added missing section
  header for the normalised dependence count non-uniformity feature. Fixed
  layout issues with small font sizes that appeared in the last half of the
  document</comments><msc-class>I.2.1, I.2.10, I.4.7, I.4.9, J.3</msc-class><acm-class>I.2.1; I.2.10; I.4.7; I.4.9; J.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The image biomarker standardisation initiative (IBSI) is an independent
international collaboration which works towards standardising the extraction of
image biomarkers from acquired imaging for the purpose of high-throughput
quantitative image analysis (radiomics). Lack of reproducibility and validation
of high-throughput quantitative image analysis studies is considered to be a
major challenge for the field. Part of this challenge lies in the scantiness of
consensus-based guidelines and definitions for the process of translating
acquired imaging into high-throughput image biomarkers. The IBSI therefore
seeks to provide image biomarker nomenclature and definitions, benchmark data
sets, and benchmark values to verify image processing and image biomarker
calculations, as well as reporting guidelines, for high-throughput image
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06724</identifier>
 <datestamp>2018-07-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1702.06724</id><created>2017-02-22</created><updated>2017-06-08</updated><authors><author><keyname>Kawahara</keyname><forenames>Hideki</forenames></author><author><keyname>Sakakibara</keyname><forenames>Ken-Ichi</forenames></author><author><keyname>Banno</keyname><forenames>Hideki</forenames></author><author><keyname>Morise</keyname><forenames>Masanori</forenames></author><author><keyname>Toda</keyname><forenames>Tomoki</forenames></author><author><keyname>Irino</keyname><forenames>Toshio</forenames></author></authors><title>A new cosine series antialiasing function and its application to
  aliasing-free glottal source models for speech and singing synthesis</title><categories>eess.AS cs.SD eess.SP</categories><comments>Submitted to Interspeech 2017</comments><journal-ref>Proc. Interspeech 2017, pp.1358-1362</journal-ref><doi>10.21437/Interspeech.2017-15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulated and implemented a procedure to generate aliasing-free
excitation source signals. It uses a new antialiasing filter in the continuous
time domain followed by an IIR digital filter for response equalization. We
introduced a cosine-series-based general design procedure for the new
antialiasing function. We applied this new procedure to implement the
antialiased Fujisaki-Ljungqvist model. We also applied it to revise our
previous implementation of the antialiased Fant-Liljencrants model. A
combination of these signals and a lattice implementation of the time varying
vocal tract model provides a reliable and flexible basis to test fo extractors
and source aperiodicity analysis methods. MATLAB implementations of these
antialiased excitation source models are available as part of our open source
tools for speech science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.05880</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1703.05880</id><created>2017-03-16</created><updated>2017-07-26</updated><authors><author><keyname>Li</keyname><forenames>Wenpeng</forenames></author><author><keyname>Zhang</keyname><forenames>BinBin</forenames></author><author><keyname>Xie</keyname><forenames>Lei</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>Empirical Evaluation of Parallel Training Algorithms on Acoustic
  Modeling</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning models (DLMs) are state-of-the-art techniques in speech
recognition. However, training good DLMs can be time consuming especially for
production-size models and corpora. Although several parallel training
algorithms have been proposed to improve training efficiency, there is no clear
guidance on which one to choose for the task in hand due to lack of systematic
and fair comparison among them. In this paper we aim at filling this gap by
comparing four popular parallel training algorithms in speech recognition,
namely asynchronous stochastic gradient descent (ASGD), blockwise model-update
filtering (BMUF), bulk synchronous parallel (BSP) and elastic averaging
stochastic gradient descent (EASGD), on 1000-hour LibriSpeech corpora using
feed-forward deep neural networks (DNNs) and convolutional, long short-term
memory, DNNs (CLDNNs). Based on our experiments, we recommend using BMUF as the
top choice to train acoustic models since it is most stable, scales well with
number of GPUs, can achieve reproducible results, and in many cases even
outperforms single-GPU SGD. ASGD can be used as a substitute in some cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.06284</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1703.06284</id><created>2017-03-18</created><updated>2017-07-11</updated><authors><author><keyname>Kolb&#xe6;k</keyname><forenames>Morten</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author><author><keyname>Tan</keyname><forenames>Zheng-Hua</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author></authors><title>Multi-talker Speech Separation with Utterance-level Permutation
  Invariant Training of Deep Recurrent Neural Networks</title><categories>cs.SD cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose the utterance-level Permutation Invariant Training
(uPIT) technique. uPIT is a practically applicable, end-to-end, deep learning
based solution for speaker independent multi-talker speech separation.
Specifically, uPIT extends the recently proposed Permutation Invariant Training
(PIT) technique with an utterance-level cost function, hence eliminating the
need for solving an additional permutation problem during inference, which is
otherwise required by frame-level PIT. We achieve this using Recurrent Neural
Networks (RNNs) that, during training, minimize the utterance-level separation
error, hence forcing separated frames belonging to the same speaker to be
aligned to the same output stream. In practice, this allows RNNs, trained with
uPIT, to separate multi-talker mixed speech without any prior knowledge of
signal duration, number of speakers, speaker identity or gender. We evaluated
uPIT on the WSJ0 and Danish two- and three-talker mixed-speech separation tasks
and found that uPIT outperforms techniques based on Non-negative Matrix
Factorization (NMF) and Computational Auditory Scene Analysis (CASA), and
compares favorably with Deep Clustering (DPCL) and the Deep Attractor Network
(DANet). Furthermore, we found that models trained with uPIT generalize well to
unseen speakers and languages. Finally, we found that a single model, trained
with uPIT, can handle both two-speaker, and three-speaker speech mixtures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.10978</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1703.10978</id><created>2017-03-31</created><updated>2018-03-05</updated><authors><author><keyname>Garcia</keyname><forenames>Nil</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Slock</keyname><forenames>Dirk</forenames></author></authors><title>Optimal Precoders for Tracking the AoD and AoA of a mm-Wave Path</title><categories>cs.IT eess.SP math.IT</categories><comments>Resubmission to IEEE Trans. on Signal Processing. 12 pages and 9
  figures</comments><doi>10.1109/TSP.2018.2870368</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In millimeter-wave channels, most of the received energy is carried by a few
paths. Traditional precoders sweep the angle-of-departure (AoD) and
angle-of-arrival (AoA) space with directional precoders to identify directions
with largest power. Such precoders are heuristic and lead to sub-optimal
AoD/AoA estimation. We derive optimal precoders, minimizing the Cram\'{e}r-Rao
bound (CRB) of the AoD/AoA, assuming a fully digital architecture at the
transmitter and spatial filtering of a single path. The precoders are found by
solving a suitable convex optimization problem. We demonstrate that the
accuracy can be improved by at least a factor of two over traditional
precoders, and show that there is an optimal number of distinct precoders
beyond which the CRB does not improve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.01985</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1704.01985</id><created>2017-03-22</created><updated>2017-06-19</updated><authors><author><keyname>Yu</keyname><forenames>Dong</forenames></author><author><keyname>Chang</keyname><forenames>Xuankai</forenames></author><author><keyname>Qian</keyname><forenames>Yanmin</forenames></author></authors><title>Recognizing Multi-talker Speech with Permutation Invariant Training</title><categories>cs.SD cs.LG eess.AS</categories><comments>5 pages, 6 figures, InterSpeech2017</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel technique for direct recognition of
multiple speech streams given the single channel of mixed speech, without first
separating them. Our technique is based on permutation invariant training (PIT)
for automatic speech recognition (ASR). In PIT-ASR, we compute the average
cross entropy (CE) over all frames in the whole utterance for each possible
output-target assignment, pick the one with the minimum CE, and optimize for
that assignment. PIT-ASR forces all the frames of the same speaker to be
aligned with the same output layer. This strategy elegantly solves the label
permutation problem and speaker tracing problem in one shot. Our experiments on
artificially mixed AMI data showed that the proposed approach is very
promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.03690</identifier>
 <datestamp>2019-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1704.03690</id><created>2017-04-12</created><updated>2019-07-09</updated><authors><author><keyname>Jagtap</keyname><forenames>Pushpak</forenames></author><author><keyname>Zamani</keyname><forenames>Majid</forenames></author></authors><title>Symbolic Models for Retarded Jump-Diffusion Systems</title><categories>math.OC cs.SY eess.SY</categories><comments>19 pages, 4 figures</comments><msc-class>93E99</msc-class><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide for the first time an automated,
correct-by-construction, controller synthesis scheme for a class of infinite
dimensional stochastic systems, namely, retarded jump-diffusion systems. First,
we construct finite abstractions approximately bisimilar to non-probabilistic
retarded systems corresponding to the original systems having some stability
property, namely, incremental input-to-state stability. Then, we provide a
result on quantifying the distance between output trajectory of the obtained
finite abstraction and that of the original retarded jump-diffusion system in a
probabilistic setting. Using the proposed result, one can refine the control
policy synthesized using finite abstractions to the original systems while
providing guarantee on the probability of satisfaction of high-level
requirements. Moreover, we provide sufficient conditions for the proposed
notion of incremental stability in terms of the existence of incremental
Lyapunov functions which reduce to some matrix inequalities for the linear
systems. Finally, the effectiveness of the proposed results is illustrated by
synthesizing a controller regulating the temperatures in a ten-room building
modelled as a delayed jump-diffusion system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.04313</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1704.04313</id><created>2017-04-13</created><updated>2017-06-21</updated><authors><author><keyname>Cavigelli</keyname><forenames>Lukas</forenames></author><author><keyname>Degen</keyname><forenames>Philippe</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>CBinfer: Change-Based Inference for Convolutional Neural Networks on
  Video Data</title><categories>cs.CV cs.AI cs.LG cs.PF eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extracting per-frame features using convolutional neural networks for
real-time processing of video data is currently mainly performed on powerful
GPU-accelerated workstations and compute clusters. However, there are many
applications such as smart surveillance cameras that require or would benefit
from on-site processing. To this end, we propose and evaluate a novel algorithm
for change-based evaluation of CNNs for video data recorded with a static
camera setting, exploiting the spatio-temporal sparsity of pixel changes. We
achieve an average speed-up of 8.6x over a cuDNN baseline on a realistic
benchmark with a negligible accuracy loss of less than 0.1% and no retraining
of the network. The resulting energy efficiency is 10x higher than that of
per-frame evaluation and reaches an equivalent of 328 GOp/s/W on the Tegra X1
platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.06209</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1704.06209</id><created>2017-04-20</created><authors><author><keyname>Wohlberg</keyname><forenames>Brendt</forenames></author></authors><title>ADMM Penalty Parameter Selection by Residual Balancing</title><categories>math.OC cs.LG eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Appropriate selection of the penalty parameter is crucial to obtaining good
performance from the Alternating Direction Method of Multipliers (ADMM). While
analytic results for optimal selection of this parameter are very limited,
there is a heuristic method that appears to be relatively successful in a
number of different problems. The contribution of this paper is to demonstrate
that their is a potentially serious flaw in this heuristic approach, and to
propose a modification that at least partially addresses it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.07661</identifier>
 <datestamp>2018-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1704.07661</id><created>2017-04-25</created><authors><author><keyname>Chepuri</keyname><forenames>Sundeep Prabhakar</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Graph Sampling for Covariance Estimation</title><categories>cs.IT eess.SP math.IT</categories><comments>Under peer review for Jour. of Sel. Topics in Signal Proc. (special
  issue on graph signal processing), Nov. 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the focus is on subsampling as well as reconstructing the
second-order statistics of signals residing on nodes of arbitrary undirected
graphs. Second-order stationary graph signals may be obtained by graph
filtering zero-mean white noise and they admit a well-defined power spectrum
whose shape is determined by the frequency response of the graph filter.
Estimating the graph power spectrum forms an important component of stationary
graph signal processing and related inference tasks such as Wiener prediction
or inpainting on graphs. The central result of this paper is that by sampling a
significantly smaller subset of vertices and using simple least squares, we can
reconstruct the second-order statistics of the graph signal from the subsampled
observations, and more importantly, without any spectral priors. To this end,
both a nonparametric approach as well as parametric approaches including moving
average and autoregressive models for the graph power spectrum are considered.
The results specialize for undirected circulant graphs in that the graph nodes
leading to the best compression rates are given by the so-called minimal sparse
rulers. A near-optimal greedy algorithm is developed to design the subsampling
scheme for the non-parametric and the moving average models, whereas a
particular subsampling scheme that allows linear estimation for the
autoregressive model is proposed. Numerical experiments on synthetic as well as
real datasets related to climatology and processing handwritten digits are
provided to demonstrate the developed theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1704.08765</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1704.08765</id><created>2017-04-20</created><authors><author><keyname>Hajdu-Szucs</keyname><forenames>Katalin</forenames></author><author><keyname>Fenyvesi</keyname><forenames>Nora</forenames></author><author><keyname>Steger</keyname><forenames>Jozsef</forenames></author><author><keyname>Vattay</keyname><forenames>Gabor</forenames></author></authors><title>Audio-based performance evaluation of squash players</title><categories>eess.AS cs.SD</categories><doi>10.1371/journal.pone.0194394</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In competitive sports it is often very hard to quantify the performance. A
player to score or overtake may depend on only millesimal of seconds or
millimeters. In racquet sports like tennis, table tennis and squash many events
will occur in a short time duration, whose recording and analysis can help
reveal the differences in performance. In this paper we show that it is
possible to architect a framework that utilizes the characteristic sound
patterns to precisely classify the types of and localize the positions of these
events. From these basic information the shot types and the ball speed along
the trajectories can be estimated. Comparing these estimates with the optimal
speed and target the precision of the shot can be defined. The detailed shot
statistics and precision information significantly enriches and improves data
available today. Feeding them back to the players and the coaches facilitates
to describe playing performance objectively and to improve strategy skills. The
framework is implemented, its hardware and software components are installed
and tested in a squash court.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.00803</identifier>
 <datestamp>2019-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1705.00803</id><created>2017-05-02</created><updated>2019-06-19</updated><authors><author><keyname>Shirazi</keyname><forenames>Mojtaba</forenames></author><author><keyname>Vosoughi</keyname><forenames>Azadeh</forenames></author></authors><title>On Bayesian Fisher Information Maximization for Distributed Vector
  Estimation</title><categories>cs.IT eess.SP math.IT</categories><comments>10 figures, 16 pages, minor revision, submitted to IEEE Transactions
  on Signal and Information Processing over Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of distributed estimation of a Gaussian vector with
linear observation model. Each sensor makes a scalar noisy observation of the
unknown vector, quantizes its observation, maps it to a digitally modulated
symbol, and transmits the symbol over orthogonal power-constrained fading
channels to a fusion center (FC). The FC is tasked with fusing the received
signals from sensors and estimating the unknown vector. We derive the Bayesian
Fisher Information Matrix (FIM) for three types of receivers: (i) coherent
receiver (ii) noncoherent receiver with known channel envelopes (iii)
noncoherent receiver with known channel statistics only. We also derive the
Weiss-Weinstein bound (WWB). We formulate two constrained optimization
problems, namely maximizing trace and log-determinant of Bayesian FIM under
network transmit power constraint, with sensors transmit powers being the
optimization variables. We show that for coherent receiver, these problems are
concave. However, for noncoherent receivers, they are not necessarily concave.
The solution to the trace of Bayesian FIM maximization problem can be
implemented in a distributed fashion. We numerically investigate how the
FIM-max power allocation across sensors depends on the sensors observation
qualities and physical layer parameters as well as the network transmit power
constraint. Moreover, we evaluate the system performance in terms of MSE using
the solutions of FIM-max schemes, and compare it with the solution obtained
from minimizing the MSE of the LMMSE estimator (MSE-min scheme), and that of
uniform power allocation. These comparisons illustrate that, although the WWB
is tighter than the inverse of Bayesian FIM, it is still suitable to use
FIM-max schemes, since the performance loss in terms of the MSE of the LMMSE
estimator is not significant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.01457</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1705.01457</id><created>2017-05-01</created><updated>2017-05-15</updated><authors><author><keyname>Zarmehi</keyname><forenames>Nematollah</forenames></author><author><keyname>Shahsavari</keyname><forenames>Sina</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Comparison of Uniform and Random Sampling for Speech and Music Signals</title><categories>eess.AS cs.MM cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we will provide a comparison between uniform and random
sampling for speech and music signals. There are various sampling and recovery
methods for audio signals. Here, we only investigate uniform and random schemes
for sampling and basic low-pass filtering and iterative method with adaptive
thresholding for recovery. The simulation results indicate that uniform
sampling with cubic spline interpolation outperforms other sampling and
recovery methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.02111</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1705.02111</id><created>2017-05-05</created><updated>2017-07-18</updated><authors><author><keyname>Giard</keyname><forenames>Pascal</forenames></author><author><keyname>Balatsoukas-Stimming</keyname><forenames>Alexios</forenames></author><author><keyname>Burg</keyname><forenames>Andreas</forenames></author></authors><title>Blind Detection of Polar Codes</title><categories>cs.IT eess.SP math.IT</categories><comments>6 pages, 8 figures, to appear at the IEEE Int. Workshop on Signal
  Process. Syst. (SiPS) 2017</comments><doi>10.1109/SiPS.2017.8109977</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes were recently chosen to protect the control channel information
in the next-generation mobile communication standard (5G) defined by the 3GPP.
As a result, receivers will have to implement blind detection of polar coded
frames in order to keep complexity, latency, and power consumption tractable.
As a newly proposed class of block codes, the problem of polar-code blind
detection has received very little attention. In this work, we propose a
low-complexity blind-detection algorithm for polar-encoded frames. We base this
algorithm on a novel detection metric with update rules that leverage the a
priori knowledge of the frozen-bit locations, exploiting the inherent
structures that these locations impose on a polar-encoded block of data. We
show that the proposed detection metric allows to clearly distinguish
polar-encoded frames from other types of data by considering the cumulative
distribution functions of the detection metric, and the receiver operating
characteristic. The presented results are tailored to the 5G standardization
effort discussions, i.e., we consider a short low-rate polar code concatenated
with a CRC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.02976</identifier>
 <datestamp>2018-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1705.02976</id><created>2017-05-08</created><authors><author><keyname>Jeon</keyname><forenames>Charles</forenames></author><author><keyname>Li</keyname><forenames>Kaipeng</forenames></author><author><keyname>Cavallaro</keyname><forenames>Joseph R.</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>On the Achievable Rates of Decentralized Equalization in Massive MU-MIMO
  Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>Will be presented at the 2017 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multi-user (MU) multiple-input multiple-output (MIMO) promises
significant gains in spectral efficiency compared to traditional, small-scale
MIMO technology. Linear equalization algorithms, such as zero forcing (ZF) or
minimum mean-square error (MMSE)-based methods, typically rely on centralized
processing at the base station (BS), which results in (i) excessively high
interconnect and chip input/output data rates, and (ii) high computational
complexity. In this paper, we investigate the achievable rates of decentralized
equalization that mitigates both of these issues. We consider two distinct BS
architectures that partition the antenna array into clusters, each associated
with independent radio-frequency chains and signal processing hardware, and the
results of each cluster are fused in a feedforward network. For both
architectures, we consider ZF, MMSE, and a novel, non-linear equalization
algorithm that builds upon approximate message passing (AMP), and we
theoretically analyze the achievable rates of these methods. Our results
demonstrate that decentralized equalization with our AMP-based methods incurs
no or only a negligible loss in terms of achievable rates compared to that of
centralized solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.02985</identifier>
 <datestamp>2018-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1705.02985</id><created>2017-05-08</created><authors><author><keyname>Ghods</keyname><forenames>Ramina</forenames></author><author><keyname>Jeon</keyname><forenames>Charles</forenames></author><author><keyname>Mirza</keyname><forenames>Gulnar</forenames></author><author><keyname>Maleki</keyname><forenames>Arian</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>Optimally-Tuned Nonparametric Linear Equalization for Massive MU-MIMO
  Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>Will be presented at the 2017 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with linear equalization in massive multi-user
multiple-input multiple-output (MU-MIMO) wireless systems. We first provide
simple conditions on the antenna configuration for which the well-known linear
minimum mean-square error (L-MMSE) equalizer provides near-optimal spectral
efficiency, and we analyze its performance in the presence of parameter
mismatches in the signal and/or noise powers. We then propose a novel,
optimally-tuned NOnParametric Equalizer (NOPE) for massive MU-MIMO systems,
which avoids knowledge of the transmit signal and noise powers altogether. We
show that NOPE achieves the same performance as that of the L-MMSE equalizer in
the large-antenna limit, and we demonstrate its efficacy in realistic,
finite-dimensional systems. From a practical perspective, NOPE is
computationally efficient and avoids dedicated training that is typically
required for parameter estimation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.04058</identifier>
 <datestamp>2018-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1705.04058</id><created>2017-05-11</created><updated>2018-10-30</updated><authors><author><keyname>Jing</keyname><forenames>Yongcheng</forenames></author><author><keyname>Yang</keyname><forenames>Yezhou</forenames></author><author><keyname>Feng</keyname><forenames>Zunlei</forenames></author><author><keyname>Ye</keyname><forenames>Jingwen</forenames></author><author><keyname>Yu</keyname><forenames>Yizhou</forenames></author><author><keyname>Song</keyname><forenames>Mingli</forenames></author></authors><title>Neural Style Transfer: A Review</title><categories>cs.CV cs.NE eess.IV stat.ML</categories><comments>Project page: https://github.com/ycjing/Neural-Style-Transfer-Papers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The seminal work of Gatys et al. demonstrated the power of Convolutional
Neural Networks (CNNs) in creating artistic imagery by separating and
recombining image content and style. This process of using CNNs to render a
content image in different styles is referred to as Neural Style Transfer
(NST). Since then, NST has become a trending topic both in academic literature
and industrial applications. It is receiving increasing attention and a variety
of approaches are proposed to either improve or extend the original NST
algorithm. In this paper, we aim to provide a comprehensive overview of the
current progress towards NST. We first propose a taxonomy of current algorithms
in the field of NST. Then, we present several evaluation methods and compare
different NST algorithms both qualitatively and quantitatively. The review
concludes with a discussion of various applications of NST and open problems
for future research. A list of papers discussed in this review, corresponding
codes, pre-trained models and more comparison results are publicly available at
https://github.com/ycjing/Neural-Style-Transfer-Papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.04407</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1705.04407</id><created>2017-05-11</created><updated>2018-02-15</updated><authors><author><keyname>Wohlberg</keyname><forenames>Brendt</forenames></author></authors><title>Convolutional Sparse Representations with Gradient Penalties</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While convolutional sparse representations enjoy a number of useful
properties, they have received limited attention for image reconstruction
problems. The present paper compares the performance of block-based and
convolutional sparse representations in the removal of Gaussian white noise.
While the usual formulation of the convolutional sparse coding problem is
slightly inferior to the block-based representations in this problem, the
performance of the convolutional form can be boosted beyond that of the
block-based form by the inclusion of suitable penalties on the gradients of the
coefficient maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05322</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1705.05322</id><created>2017-05-15</created><authors><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author><author><keyname>de Oliveira</keyname><forenames>R. C.</forenames></author></authors><title>Understanding MIDI: A Painless Tutorial on Midi Format</title><categories>cs.SD eess.AS</categories><comments>7 pages, 7 figures</comments><acm-class>H.5.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A short overview demystifying the midi audio format is presented. The goal is
to explain the file structure and how the instructions are used to produce a
music signal, both in the case of monophonic signals as for polyphonic signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06073</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1705.06073</id><created>2017-05-17</created><updated>2018-02-15</updated><authors><author><keyname>Hansen</keyname><forenames>Thomas Lundgaard</forenames></author><author><keyname>Fleury</keyname><forenames>Bernard Henri</forenames></author><author><keyname>Rao</keyname><forenames>Bhaskar D.</forenames></author></authors><title>Superfast Line Spectral Estimation</title><categories>eess.SP cs.IT math.IT stat.AP</categories><comments>16 pages, 7 figures, accepted for IEEE Transactions on Signal
  Processing</comments><doi>10.1109/TSP.2018.2807417</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of recent works have proposed to solve the line spectral estimation
problem by applying off-the-grid extensions of sparse estimation techniques.
These methods are preferable over classical line spectral estimation algorithms
because they inherently estimate the model order. However, they all have
computation times which grow at least cubically in the problem size, thus
limiting their practical applicability in cases with large dimensions. To
alleviate this issue, we propose a low-complexity method for line spectral
estimation, which also draws on ideas from sparse estimation. Our method is
based on a Bayesian view of the problem. The signal covariance matrix is shown
to have Toeplitz structure, allowing superfast Toeplitz inversion to be used.
We demonstrate that our method achieves estimation accuracy at least as good as
current methods and that it does so while being orders of magnitudes faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09412</identifier>
 <datestamp>2018-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1705.09412</id><created>2017-05-25</created><updated>2017-10-25</updated><authors><author><keyname>Sun</keyname><forenames>Haoran</forenames></author><author><keyname>Chen</keyname><forenames>Xiangyi</forenames></author><author><keyname>Shi</keyname><forenames>Qingjiang</forenames></author><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author><author><keyname>Fu</keyname><forenames>Xiao</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nicholas D.</forenames></author></authors><title>Learning to Optimize: Training Deep Neural Networks for Wireless
  Resource Management</title><categories>cs.IT eess.SP math.IT</categories><comments>Submitted to TSP</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 66, no. 20, pp.
  5438-5453, 15 Oct.15, 2018</journal-ref><doi>10.1109/TSP.2018.2866382</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the past couple of decades, numerical optimization has played a central
role in addressing wireless resource management problems such as power control
and beamformer design. However, optimization algorithms often entail
considerable complexity, which creates a serious gap between theoretical
design/analysis and real-time processing. To address this challenge, we propose
a new learning-based approach. The key idea is to treat the input and output of
a resource allocation algorithm as an unknown non-linear mapping and use a deep
neural network (DNN) to approximate it. If the non-linear mapping can be
learned accurately by a DNN of moderate size, then resource allocation can be
done in almost real time -- since passing the input through a DNN only requires
a small number of simple operations.
  In this work, we address both the thereotical and practical aspects of
DNN-based algorithm approximation with applications to wireless resource
management. We first pin down a class of optimization algorithms that are
`learnable' in theory by a fully connected DNN. Then, we focus on DNN-based
approximation to a popular power allocation algorithm named WMMSE (Shi {\it et
al} 2011). We show that using a DNN to approximate WMMSE can be fairly accurate
-- the approximation error $\epsilon$ depends mildly [in the order of
$\log(1/\epsilon)$] on the numbers of neurons and layers of the DNN. On the
implementation side, we use extensive numerical simulations to demonstrate that
DNNs can achieve orders of magnitude speedup in computational time compared to
state-of-the-art power allocation algorithms based on optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1706.00159</identifier>
 <datestamp>2018-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1706.00159</id><created>2017-05-31</created><updated>2017-09-29</updated><authors><author><keyname>Susuki</keyname><forenames>Yoshihiko</forenames></author><author><keyname>Mezic</keyname><forenames>Igor</forenames></author><author><keyname>Raak</keyname><forenames>Fredrik</forenames></author><author><keyname>Hikihara</keyname><forenames>Takashi</forenames></author></authors><title>Applied Koopman Operator Theory for Power Systems Technology</title><categories>cs.SY eess.SP math.DS nlin.CD</categories><comments>31 pages, 11 figures</comments><journal-ref>Nonlinear Theory and Its Applications, IEICE, vol.7, no.4,
  pp.430-459, October 2016</journal-ref><doi>10.1587/nolta.7.430</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Koopman operator is a composition operator defined for a dynamical system
described by nonlinear differential or difference equation. Although the
original system is nonlinear and evolves on a finite-dimensional state space,
the Koopman operator itself is linear but infinite-dimensional (evolves on a
function space). This linear operator captures the full information of the
dynamics described by the original nonlinear system. In particular, spectral
properties of the Koopman operator play a crucial role in analyzing the
original system. In the first part of this paper, we review the so-called
Koopman operator theory for nonlinear dynamical systems, with emphasis on modal
decomposition and computation that are direct to wide applications. Then, in
the second part, we present a series of applications of the Koopman operator
theory to power systems technology. The applications are established as
data-centric methods, namely, how to use massive quantities of data obtained
numerically and experimentally, through spectral analysis of the Koopman
operator: coherency identification of swings in coupled synchronous generators,
precursor diagnostic of instabilities in the coupled swing dynamics, and
stability assessment of power systems without any use of mathematical models.
Future problems of this research direction are identified in the last
concluding part of this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1706.02964</identifier>
 <datestamp>2018-07-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1706.02964</id><created>2017-06-09</created><authors><author><keyname>Kawahara</keyname><forenames>Hideki</forenames></author><author><keyname>Sakakibara</keyname><forenames>Ken-Ichi</forenames></author><author><keyname>Morise</keyname><forenames>Masanori</forenames></author><author><keyname>Banno</keyname><forenames>Hideki</forenames></author><author><keyname>Toda</keyname><forenames>Tomoki</forenames></author></authors><title>A modulation property of time-frequency derivatives of filtered phase
  and its application to aperiodicity and fo estimation</title><categories>eess.AS cs.SD eess.SP</categories><comments>8 pages 9 figures, Submitted and accepted in Interspeech2017</comments><journal-ref>Proc. Interspeech 2017, pp.424-428</journal-ref><doi>10.21437/Interspeech.2017-436</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a simple and linear SNR (strictly speaking, periodic to random
power ratio) estimator (0dB to 80dB without additional
calibration/linearization) for providing reliable descriptions of aperiodicity
in speech corpus. The main idea of this method is to estimate the background
random noise level without directly extracting the background noise. The
proposed method is applicable to a wide variety of time windowing functions
with very low sidelobe levels. The estimate combines the frequency derivative
and the time-frequency derivative of the mapping from filter center frequency
to the output instantaneous frequency. This procedure can replace the
periodicity detection and aperiodicity estimation subsystems of recently
introduced open source vocoder, YANG vocoder. Source code of MATLAB
implementation of this method will also be open sourced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1706.03261</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1706.03261</id><created>2017-06-10</created><authors><author><keyname>Aguerrebere</keyname><forenames>Cecilia</forenames></author><author><keyname>Almansa</keyname><forenames>Andr&#xe9;s</forenames></author><author><keyname>Delon</keyname><forenames>Julie</forenames></author><author><keyname>Gousseau</keyname><forenames>Yann</forenames></author><author><keyname>Mus&#xe9;</keyname><forenames>Pablo</forenames></author></authors><title>A Bayesian Hyperprior Approach for Joint Image Denoising and
  Interpolation, with an Application to HDR Imaging</title><categories>cs.CV eess.IV stat.ML</categories><comments>Some figures are reduced to comply with arxiv's size constraints.
  Full size images are available as HAL technical report hal-01107519v5, IEEE
  Transactions on Computational Imaging, 2017</comments><msc-class>62H35, 68U10, 62F15, 68Q32</msc-class><acm-class>I.4.1, I.4.4, I.2.6</acm-class><doi>10.1109/TCI.2017.2704439</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, impressive denoising results have been achieved by Bayesian
approaches which assume Gaussian models for the image patches. This improvement
in performance can be attributed to the use of per-patch models. Unfortunately
such an approach is particularly unstable for most inverse problems beyond
denoising. In this work, we propose the use of a hyperprior to model image
patches, in order to stabilize the estimation procedure. There are two main
advantages to the proposed restoration scheme: Firstly it is adapted to
diagonal degradation matrices, and in particular to missing data problems (e.g.
inpainting of missing pixels or zooming). Secondly it can deal with signal
dependent noise models, particularly suited to digital cameras. As such, the
scheme is especially adapted to computational photography. In order to
illustrate this point, we provide an application to high dynamic range imaging
from a single image taken with a modified sensor, which shows the effectiveness
of the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1706.09563</identifier>
 <datestamp>2018-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1706.09563</id><created>2017-06-28</created><updated>2017-08-30</updated><authors><author><keyname>Liu</keyname><forenames>Jialin</forenames></author><author><keyname>Garcia-Cardona</keyname><forenames>Cristina</forenames></author><author><keyname>Wohlberg</keyname><forenames>Brendt</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author></authors><title>Online Convolutional Dictionary Learning</title><categories>cs.LG cs.CV eess.IV</categories><comments>Accepted to be presented at ICIP 2017</comments><journal-ref>Proceedings of IEEE International Conference on Image Processing
  (ICIP), 2017, pp. 1707-1711</journal-ref><doi>10.1109/ICIP.2017.8296573</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While a number of different algorithms have recently been proposed for
convolutional dictionary learning, this remains an expensive problem. The
single biggest impediment to learning from large training sets is the memory
requirements, which grow at least linearly with the size of the training set
since all existing methods are batch algorithms. The work reported here
addresses this limitation by extending online dictionary learning ideas to the
convolutional context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.06527</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1707.06527</id><created>2017-07-18</created><authors><author><keyname>Qian</keyname><forenames>Yanmin</forenames></author><author><keyname>Chang</keyname><forenames>Xuankai</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author></authors><title>Single-Channel Multi-talker Speech Recognition with Permutation
  Invariant Training</title><categories>cs.SD cs.CL cs.LG eess.AS</categories><comments>11 pages, 6 figures, Submitted to IEEE/ACM Transactions on Audio,
  Speech and Language Processing. arXiv admin note: text overlap with
  arXiv:1704.01985</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although great progresses have been made in automatic speech recognition
(ASR), significant performance degradation is still observed when recognizing
multi-talker mixed speech. In this paper, we propose and evaluate several
architectures to address this problem under the assumption that only a single
channel of mixed signal is available. Our technique extends permutation
invariant training (PIT) by introducing the front-end feature separation module
with the minimum mean square error (MSE) criterion and the back-end recognition
module with the minimum cross entropy (CE) criterion. More specifically, during
training we compute the average MSE or CE over the whole utterance for each
possible utterance-level output-target assignment, pick the one with the
minimum MSE or CE, and optimize for that assignment. This strategy elegantly
solves the label permutation problem observed in the deep learning based
multi-talker mixed speech separation and recognition systems. The proposed
architectures are evaluated and compared on an artificially mixed AMI dataset
with both two- and three-talker mixed speech. The experimental results indicate
that our proposed architectures can cut the word error rate (WER) by 45.0% and
25.0% relatively against the state-of-the-art single-talker speech recognition
system across all speakers when their energies are comparable, for two- and
three-talker mixed speech, respectively. To our knowledge, this is the first
work on the multi-talker mixed speech recognition on the challenging
speaker-independent spontaneous large vocabulary continuous speech task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.06718</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1707.06718</id><created>2017-07-20</created><authors><author><keyname>Wohlberg</keyname><forenames>Brendt</forenames></author><author><keyname>Rodriguez</keyname><forenames>Paul</forenames></author></authors><title>Convolutional Sparse Coding: Boundary Handling Revisited</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two different approaches have recently been proposed for boundary handling in
convolutional sparse representations, avoiding potential boundary artifacts
arising from the circular boundary conditions implied by the use of frequency
domain solution methods by introducing a spatial mask into the convolutional
sparse coding problem. In the present paper we show that, under certain
circumstances, these methods fail in their design goal of avoiding boundary
artifacts. The reasons for this failure are discussed, a solution is proposed,
and the practical implications are illustrated in an image deblurring problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07349</identifier>
 <datestamp>2019-08-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1707.07349</id><created>2017-07-23</created><updated>2019-08-05</updated><authors><author><keyname>Holding</keyname><forenames>Thomas</forenames></author><author><keyname>Lestas</keyname><forenames>Ioannis</forenames></author></authors><title>Stability and instability in saddle point dynamics -- Part I</title><categories>math.OC cs.SY eess.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of convergence to a saddle point of a concave-convex
function via gradient dynamics. Since first introduced by Arrow, Hurwicz and
Uzawa in [1] such dynamics have been extensively used in diverse areas, there
are, however, features that render their analysis non trivial. These include
the lack of convergence guarantees when the function considered is not strictly
concave-convex and also the non-smoothness of subgradient dynamics. Our aim in
this two part paper is to provide an explicit characterization to the
asymptotic behaviour of general gradient and subgradient dynamics applied to a
general concave-convex function. We show that despite the nonlinearity and
non-smoothness of these dynamics their $\omega$-limit set is comprised of
trajectories that solve only explicit linear ODEs that are characterized within
the paper.
  More precisely, in Part I an exact characterization is provided to the
asymptotic behaviour of unconstrained gradient dynamics. We also show that when
convergence to a saddle point is not guaranteed then the system behaviour can
be problematic, with arbitrarily small noise leading to an unbounded variance.
In Part II we consider a general class of subgradient dynamics that restrict
trajectories in an arbitrary convex domain, and show that when an equilibrium
point exists their limiting trajectories are solutions of subgradient dynamics
on only affine subspaces. The latter is a smooth class of dynamics with an
asymptotic behaviour exactly characterized in Part I, as solutions to explicit
linear ODEs. These results are used to formulate corresponding convergence
criteria and are demonstrated with several examples and applications presented
in Part II.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07625</identifier>
 <datestamp>2018-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1707.07625</id><created>2017-07-21</created><updated>2018-05-11</updated><authors><author><keyname>Goulko</keyname><forenames>Olga</forenames></author><author><keyname>Prokof'ev</keyname><forenames>Nikolay</forenames></author><author><keyname>Svistunov</keyname><forenames>Boris</forenames></author></authors><title>Restoring a smooth function from its noisy integrals</title><categories>stat.OT cond-mat.other eess.SP physics.data-an</categories><comments>11 pages, 9 figures, published version</comments><journal-ref>Phys. Rev. E 97, 053305 (2018)</journal-ref><doi>10.1103/PhysRevE.97.053305</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerical (and experimental) data analysis often requires the restoration of
a smooth function from a set of sampled integrals over finite bins. We present
the bin hierarchy method that efficiently computes the maximally smooth
function from the sampled integrals using essentially all the information
contained in the data. We perform extensive tests with different classes of
functions and levels of data quality, including Monte Carlo data suffering from
a severe sign problem and physical data for the Green's function of the
Fr\&quot;ohlich polaron.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08117</identifier>
 <datestamp>2018-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1707.08117</id><created>2017-07-25</created><updated>2018-09-07</updated><authors><author><keyname>Aich</keyname><forenames>Abhishek</forenames></author><author><keyname>Palanisamy</keyname><forenames>P.</forenames></author></authors><title>A Novel Sparse recovery based DOA estimation algorithm by relaxing the
  RIP constraint</title><categories>eess.SP cs.IT math.IT</categories><comments>Work needs further analysis as pointed by a Anonymous Reviewer. We
  thank him/her for this useful insight on the results. Paper will be updated
  as and when the results are revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Direction of Arrival (DOA) estimation of mixed uncorrelated and coherent
sources is a long existing challenge in array signal processing. Application of
compressive sensing to array signal processing has opened up an exciting class
of algorithms. The authors investigated the application of orthogonal matching
pursuit (OMP) for direction of Arrival (DOA) estimation for different
scenarios, especially to tackle the case of coherent sources and observed
inconsistencies in the results. In this paper, a modified OMP algorithm is
proposed to overcome these deficiencies by exploiting maximum variance based
criterion using only one snapshot. This criterion relaxes the imposed
restricted isometry property (RIP) on the measurement matrix to obtain the
sources and hence, reduces the sparsity of the input vector to the local OMP
algorithm. Moreover, it also tackles sources irrespective of their coherency.
The condition for the weak-1 RIP on decreased sparsity is derived and it is
shown that how the algorithm gives better result than the OMP algorithm. With
an addition to this, a simple method is also presented to calculate source
distance from the reference point in a uniform linear sensor array. Numerical
analysis demonstrates the effectiveness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08243</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1707.08243</id><created>2017-07-25</created><updated>2019-04-02</updated><authors><author><keyname>Liu</keyname><forenames>Fengjiao</forenames></author><author><keyname>Morse</keyname><forenames>A. Stephen</forenames></author></authors><title>A Graphical Characterization of Structurally Controllable Linear Systems
  with Dependent Parameters</title><categories>cs.SY eess.SY</categories><journal-ref>IEEE Transactions on Automatic Control, 2019</journal-ref><doi>10.1109/TAC.2019.2908311</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One version of the concept of structural controllability defined for
single-input systems by Lin and subsequently generalized to multi-input systems
by others, states that a parameterized matrix pair $(A, B)$ whose nonzero
entries are distinct parameters, is structurally controllable if values can be
assigned to the parameters which cause the resulting matrix pair to be
controllable. In this paper the concept of structural controllability is
broadened to allow for the possibility that a parameter may appear in more than
one location in the pair $(A, B)$. Subject to a certain condition on the
parameterization called the &quot;binary assumption&quot;, an explicit graph-theoretic
characterization of such matrix pairs is derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08391</identifier>
 <datestamp>2019-01-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1707.08391</id><created>2017-07-26</created><updated>2019-01-11</updated><authors><author><keyname>Prakash</keyname><forenames>Jaya</forenames></author><author><keyname>Mandal</keyname><forenames>Subhamoy</forenames></author><author><keyname>Razansky</keyname><forenames>Daniel</forenames></author><author><keyname>Ntziachristos</keyname><forenames>Vasilis</forenames></author></authors><title>Maximum entropy based non-negative optoacoustic tomographic image
  reconstruction</title><categories>physics.med-ph cs.CV eess.IV physics.optics</categories><comments>This article has been accepted for publication in IEEE Transactions
  on Biomedical Engineering (30 Dec 2018)</comments><doi>10.1109/TBME.2019.2892842</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective:Optoacoustic (photoacoustic) tomography is aimed at reconstructing
maps of the initial pressure rise induced by the absorption of light pulses in
tissue. In practice, due to inaccurate assumptions in the forward model, noise
and other experimental factors, the images are often afflicted by artifacts,
occasionally manifested as negative values. The aim of the work is to develop
an inversion method which reduces the occurrence of negative values and
improves the quantitative performance of optoacoustic imaging. Methods: We
present a novel method for optoacoustic tomography based on an entropy
maximization algorithm, which uses logarithmic regularization for attaining
non-negative reconstructions. The reconstruction image quality is further
improved using structural prior based fluence correction. Results: We report
the performance achieved by the entropy maximization scheme on numerical
simulation, experimental phantoms and in-vivo samples. Conclusion: The proposed
algorithm demonstrates superior reconstruction performance by delivering
non-negative pixel values with no visible distortion of anatomical structures.
Significance: Our method can enable quantitative optoacoustic imaging, and has
the potential to improve pre-clinical and translational imaging applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09255</identifier>
 <datestamp>2018-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1707.09255</id><created>2017-07-28</created><updated>2018-12-11</updated><authors><author><keyname>Solomon</keyname><forenames>Oren</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Mutzafi</keyname><forenames>Maor</forenames></author><author><keyname>Segev</keyname><forenames>Mordechai</forenames></author></authors><title>SPARCOM: Sparsity Based Super-Resolution Correlation Microscopy</title><categories>physics.optics eess.SP</categories><comments>31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In traditional optical imaging systems, the spatial resolution is limited by
the physics of diffraction, which acts as a low-pass filter. The information on
sub-wavelength features is carried by evanescent waves, never reaching the
camera, thereby posing a hard limit on resolution: the so-called diffraction
limit. Modern microscopic methods enable super-resolution, by employing
florescence techniques. State-of-the-art localization based fluorescence
subwavelength imaging techniques such as PALM and STORM achieve sub-diffraction
spatial resolution of several tens of nano-meters. However, they require tens
of thousands of exposures, which limits their temporal resolution. We have
recently proposed SPARCOM (sparsity based super-resolution correlation
microscopy), which exploits the sparse nature of the fluorophores distribution,
alongside a statistical prior of uncorrelated emissions, and showed that
SPARCOM achieves spatial resolution comparable to PALM/STORM, while capturing
the data hundreds of times faster. Here, we provide a detailed mathematical
formulation of SPARCOM, which in turn leads to an efficient numerical
implementation, suitable for large-scale problems. We further extend our method
to a general framework for sparsity based super-resolution imaging, in which
sparsity can be assumed in other domains such as wavelet or discrete-cosine,
leading to improved reconstructions in a variety of physical settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05291</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1708.05291</id><created>2017-08-17</created><authors><author><keyname>Mordido</keyname><forenames>Gon&#xe7;alo</forenames></author><author><keyname>Magalh&#xe3;es</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Cavaco</keyname><forenames>Sofia</forenames></author></authors><title>Automatic Organisation and Quality Analysis of User-Generated Content
  with Audio Fingerprinting</title><categories>eess.AS cs.MM</categories><comments>EUSIPCO 2017 - 25th European Signal Processing Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increase of the quantity of user-generated content experienced in social
media has boosted the importance of analysing and organising the content by its
quality. Here, we propose a method that uses audio fingerprinting to organise
and infer the quality of user-generated audio content. The proposed method
detects the overlapping segments between different audio clips to organise and
cluster the data according to events, and to infer the audio quality of the
samples. A test setup with concert recordings manually crawled from YouTube is
used to validate the presented method. The results show that the proposed
method achieves better results than previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.05302</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1708.05302</id><created>2017-08-17</created><authors><author><keyname>Mordido</keyname><forenames>Gon&#xe7;alo</forenames></author><author><keyname>Magalh&#xe3;es</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Cavaco</keyname><forenames>Sofia</forenames></author></authors><title>Automatic Organisation, Segmentation, and Filtering of User-Generated
  Audio Content</title><categories>eess.AS cs.IR cs.MM cs.SD</categories><comments>MMSP 2017 - IEEE 19th International Workshop on Multimedia Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using solely the information retrieved by audio fingerprinting techniques, we
propose methods to treat a possibly large dataset of user-generated audio
content, that (1) enable the grouping of several audio files that contain a
common audio excerpt (i.e., are relative to the same event), and (2) give
information about how those files are correlated in terms of time and quality
inside each event. Furthermore, we use supervised learning to detect incorrect
matches that may arise from the audio fingerprinting algorithm itself, whilst
ensuring our model learns with previous predictions. All the presented methods
were further validated by user-generated recordings of several different
concerts manually crawled from YouTube.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.06336</identifier>
 <datestamp>2019-05-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1708.06336</id><created>2017-08-14</created><updated>2019-05-09</updated><authors><author><keyname>Srinivasan</keyname><forenames>Muralikrishnan</forenames></author><author><keyname>Kalyani</keyname><forenames>Sheetal</forenames></author></authors><title>Analysis of Optimal Combining in Rician Fading with Co-channel
  Interference</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximate Symbol error rate (SER), outage probability and rate expressions
are derived for receive diversity system employing optimum combining when both
the desired and the interfering signals are subjected to Rician fading, for the
cases of a) equal power uncorrelated interferers b) unequal power interferers
c) interferer correlation. The derived expressions are applicable for an
arbitrary number of receive antennas and interferers and for any quadrature
amplitude modulation (QAM) constellation. Furthermore, we derive a simple
closed form expression for SER in the interference-limited regime, for the
special case of Rayleigh faded interferers. A close match is observed between
the SER, outage probability and rate results obtained through the derived
analytical expressions and the ones obtained from Monte-Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.09038</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1708.09038</id><created>2017-08-29</created><authors><author><keyname>Wohlberg</keyname><forenames>Brendt</forenames></author></authors><title>Convolutional Sparse Coding with Overlapping Group Norms</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most widely used form of convolutional sparse coding uses an $\ell_1$
regularization term. While this approach has been successful in a variety of
applications, a limitation of the $\ell_1$ penalty is that it is homogeneous
across the spatial and filter index dimensions of the sparse representation
array, so that sparsity cannot be separately controlled across these
dimensions. The present paper considers the consequences of replacing the
$\ell_1$ penalty with a mixed group norm, motivated by recent theoretical
results for convolutional sparse representations. Algorithms are developed for
solving the resulting problems, which are quite challenging, and the impact on
the performance of the denoising problem is evaluated. The mixed group norms
are found to perform very poorly in this application. While their performance
is greatly improved by introducing a weighting strategy, such a strategy also
improves the performance obtained from the much simpler and computationally
cheaper $\ell_1$ norm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.09588</identifier>
 <datestamp>2018-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1708.09588</id><created>2017-08-31</created><authors><author><keyname>Kolb&#xe6;k</keyname><forenames>Morten</forenames></author><author><keyname>Yu</keyname><forenames>Dong</forenames></author><author><keyname>Tan</keyname><forenames>Zheng-Hua</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author></authors><title>Joint Separation and Denoising of Noisy Multi-talker Speech using
  Recurrent Neural Networks and Permutation Invariant Training</title><categories>cs.SD eess.AS</categories><comments>To appear in MLSP 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose to use utterance-level Permutation Invariant
Training (uPIT) for speaker independent multi-talker speech separation and
denoising, simultaneously. Specifically, we train deep bi-directional Long
Short-Term Memory (LSTM) Recurrent Neural Networks (RNNs) using uPIT, for
single-channel speaker independent multi-talker speech separation in multiple
noisy conditions, including both synthetic and real-life noise signals. We
focus our experiments on generalizability and noise robustness of models that
rely on various types of a priori knowledge e.g. in terms of noise type and
number of simultaneous speakers. We show that deep bi-directional LSTM RNNs
trained using uPIT in noisy environments can improve the Signal-to-Distortion
Ratio (SDR) as well as the Extended Short-Time Objective Intelligibility
(ESTOI) measure, on the speaker independent multi-talker speech separation and
denoising task, for various noise types and Signal-to-Noise Ratios (SNRs).
Specifically, we first show that LSTM RNNs can achieve large SDR and ESTOI
improvements, when evaluated using known noise types, and that a single model
is capable of handling multiple noise types with only a slight decrease in
performance. Furthermore, we show that a single LSTM RNN can handle both
two-speaker and three-speaker noisy mixtures, without a priori knowledge about
the exact number of speakers. Finally, we show that LSTM RNNs trained using
uPIT generalize well to noise types not seen during training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.00106</identifier>
 <datestamp>2018-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.00106</id><created>2017-08-31</created><updated>2018-06-16</updated><authors><author><keyname>Liu</keyname><forenames>Jialin</forenames></author><author><keyname>Garcia-Cardona</keyname><forenames>Cristina</forenames></author><author><keyname>Wohlberg</keyname><forenames>Brendt</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author></authors><title>First and Second Order Methods for Online Convolutional Dictionary
  Learning</title><categories>cs.LG cs.CV eess.IV math.OC stat.ML</categories><journal-ref>SIAM J. Imaging Sci., 11(2), 1589-1628, 2018</journal-ref><doi>10.1137/17M1145689</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional sparse representations are a form of sparse representation with
a structured, translation invariant dictionary. Most convolutional dictionary
learning algorithms to date operate in batch mode, requiring simultaneous
access to all training images during the learning process, which results in
very high memory usage and severely limits the training data that can be used.
Very recently, however, a number of authors have considered the design of
online convolutional dictionary learning algorithms that offer far better
scaling of memory and computational cost with training set size than batch
methods. This paper extends our prior work, improving a number of aspects of
our previous algorithm; proposing an entirely new one, with better performance,
and that supports the inclusion of a spatial mask for learning from incomplete
data; and providing a rigorous theoretical analysis of these methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.00237</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.00237</id><created>2017-09-01</created><authors><author><keyname>Oksanen</keyname><forenames>Jan</forenames></author><author><keyname>Koivunen</keyname><forenames>Visa</forenames></author></authors><title>An order optimal policy for exploiting idle spectrum in cognitive radio
  networks</title><categories>eess.SP cs.IT math.IT</categories><comments>IEEE transactions on signal processing, 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a spectrum sensing policy employing recency-based exploration
is proposed for cognitive radio networks. We formulate the problem of finding a
spectrum sensing policy for multi-band dynamic spectrum access as a stochastic
restless multi-armed bandit problem with stationary unknown reward
distributions. In cognitive radio networks the multi-armed bandit problem
arises when deciding where in the radio spectrum to look for idle frequencies
that could be efficiently exploited for data transmission. We consider two
models for the dynamics of the frequency bands: 1) the independent model where
the state of the band evolves randomly independently from the past and 2) the
Gilbert-Elliot model, where the states evolve according to a 2-state Markov
chain. It is shown that in these conditions the proposed sensing policy attains
asymptotically logarithmic weak regret. The policy proposed in this paper is an
index policy, in which the index of a frequency band is comprised of a sample
mean term and a recency-based exploration bonus term. The sample mean promotes
spectrum exploitation whereas the exploration bonus encourages for further
exploration for idle bands providing high data rates. The proposed recency
based approach readily allows constructing the exploration bonus such that it
will grow the time interval between consecutive sensing time instants of a
suboptimal band exponentially, which then leads to logarithmically increasing
weak regret. Simulation results confirming logarithmic weak regret are
presented and it is found that the proposed policy provides often improved
performance at low complexity over other state-of-the-art policies in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.00275</identifier>
 <datestamp>2020-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.00275</id><created>2017-09-01</created><updated>2019-04-03</updated><authors><author><keyname>G&#xfc;nl&#xfc;</keyname><forenames>Onur</forenames></author><author><keyname>&#x130;&#x15f;can</keyname><forenames>Onurcan</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author></authors><title>Code Constructions for Physical Unclonable Functions and Biometric
  Secrecy Systems</title><categories>cs.IT cs.CR cs.MM eess.SP math.IT math.PR</categories><comments>To appear in IEEE Transactions on Information Forensics and Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two-terminal key agreement problem with biometric or physical identifiers
is considered. Two linear code constructions based on Wyner-Ziv coding are
developed. The first construction uses random linear codes and achieves all
points of the key-leakage-storage regions of the generated-secret and
chosen-secret models. The second construction uses nested polar codes for
vector quantization during enrollment and for error correction during
reconstruction. Simulations show that the nested polar codes achieve
privacy-leakage and storage rates that improve on existing code designs. One
proposed code achieves a rate tuple that cannot be achieved by existing
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.01703</identifier>
 <datestamp>2019-11-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.01703</id><created>2017-09-06</created><updated>2017-09-07</updated><authors><author><keyname>Michelsanti</keyname><forenames>Daniel</forenames></author><author><keyname>Tan</keyname><forenames>Zheng-Hua</forenames></author></authors><title>Conditional Generative Adversarial Networks for Speech Enhancement and
  Noise-Robust Speaker Verification</title><categories>eess.AS cs.LG cs.SD eess.SP stat.ML</categories><comments>INTERSPEECH 2017 August 20-24, 2017, Stockholm, Sweden</comments><doi>10.21437/Interspeech.2017-1620</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Improving speech system performance in noisy environments remains a
challenging task, and speech enhancement (SE) is one of the effective
techniques to solve the problem. Motivated by the promising results of
generative adversarial networks (GANs) in a variety of image processing tasks,
we explore the potential of conditional GANs (cGANs) for SE, and in particular,
we make use of the image processing framework proposed by Isola et al. [1] to
learn a mapping from the spectrogram of noisy speech to an enhanced
counterpart. The SE cGAN consists of two networks, trained in an adversarial
manner: a generator that tries to enhance the input noisy spectrogram, and a
discriminator that tries to distinguish between enhanced spectrograms provided
by the generator and clean ones from the database using the noisy spectrogram
as a condition. We evaluate the performance of the cGAN method in terms of
perceptual evaluation of speech quality (PESQ), short-time objective
intelligibility (STOI), and equal error rate (EER) of speaker verification (an
example application). Experimental results show that the cGAN method overall
outperforms the classical short-time spectral amplitude minimum mean square
error (STSA-MMSE) SE algorithm, and is comparable to a deep neural
network-based SE approach (DNN-SE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.02242</identifier>
 <datestamp>2020-02-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.02242</id><created>2017-09-05</created><updated>2020-02-16</updated><authors><author><keyname>Zhang</keyname><forenames>Sheng</forenames></author><author><keyname>Huang</keyname><forenames>Jiang-Tao</forenames></author><author><keyname>He</keyname><forenames>Kai-Feng</forenames></author><author><keyname>Liao</keyname><forenames>Fei</forenames></author></authors><title>Variation Evolving for Optimal Control Computation, a Compact Way</title><categories>eess.SY cs.SY</categories><comments>22 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:1703.10263</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A compact version of the variation evolving method (VEM) is developed in the
primal variable space for optimal control computation. Following the idea that
originates from the Lyapunov continuous-time dynamics stability theory in the
control field, the optimal solution is analogized to the stable equilibrium
point of a dynamic system and obtained asymptotically through the variation
motion. With the introduction of a virtual dimension, namely the variation
time, the evolution partial differential equation (EPDE), which seeks the
optimal solution with a theoretical guarantee, is developed for the optimal
control problem (OCP) with free terminal states, and the equivalent optimality
conditions with no employment of costates are established in the primal space.
These conditions show that the optimal feedback control law is generally not
analytically available because the optimal control is related to the future
states. Since the derived EPDE is suitable to be computed with the
semi-discrete method in the field of PDE numerical calculation, the optimal
solution may be obtained by solving the resulting finite-dimensional
initial-value problem (IVP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.02893</identifier>
 <datestamp>2018-09-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.02893</id><created>2017-09-08</created><updated>2018-09-05</updated><authors><author><keyname>Garcia-Cardona</keyname><forenames>Cristina</forenames></author><author><keyname>Wohlberg</keyname><forenames>Brendt</forenames></author></authors><title>Convolutional Dictionary Learning: A Comparative Review and New
  Algorithms</title><categories>cs.LG eess.IV stat.ML</categories><comments>Corrected typos in Eq. (18) and (19)</comments><journal-ref>IEEE Transactions on Computational Imaging, vol. 4, no. 3, pp.
  366-381, Sep 2018</journal-ref><doi>10.1109/TCI.2018.2840334</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional sparse representations are a form of sparse representation with
a dictionary that has a structure that is equivalent to convolution with a set
of linear filters. While effective algorithms have recently been developed for
the convolutional sparse coding problem, the corresponding dictionary learning
problem is substantially more challenging. Furthermore, although a number of
different approaches have been proposed, the absence of thorough comparisons
between them makes it difficult to determine which of them represents the
current state of the art. The present work both addresses this deficiency and
proposes some new approaches that outperform existing ones in certain contexts.
A thorough set of performance comparisons indicates a very wide range of
performance differences among the existing and proposed methods, and clearly
identifies those that are the most effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.03191</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.03191</id><created>2017-09-10</created><authors><author><keyname>Sabeti</keyname><forenames>Elyas</forenames></author><author><keyname>H&#xf8;st-Madsen</keyname><forenames>Anders</forenames></author></authors><title>Data Discovery and Anomaly Detection Using Atypicality: Signal
  Processing Methods</title><categories>eess.SP cs.IT math.IT</categories><comments>13 pages, two columns</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of atypicality is to extract small, rare, unusual and interesting
pieces out of big data. This complements statistics about typical data to give
insight into data. In order to find such &quot;interesting&quot; parts of data, universal
approaches are required, since it is not known in advance what we are looking
for. We therefore base the atypicality criterion on codelength. In a prior
paper we developed the methodology for discrete-valued data, and the the
current paper extends this to real-valued data. This is done by using minimum
description length (MDL). We show that this shares a number of theoretical
properties with the discrete-valued case. We develop the methodology for a
number of &quot;universal&quot; signal processing models, and finally apply them to
recorded hydrophone data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.03943</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.03943</id><created>2017-09-11</created><authors><author><keyname>Kanjamapornkul</keyname><forenames>Kabin</forenames></author><author><keyname>Pin&#x10d;&#xe1;k</keyname><forenames>Richard</forenames></author><author><keyname>Chunithpaisan</keyname><forenames>Sanphet</forenames></author><author><keyname>Barto&#x161;</keyname><forenames>Erik</forenames></author></authors><title>Support Spinor Machine</title><categories>cs.LG eess.SP q-fin.ST stat.ML</categories><comments>18 pages, 12 figures, 6 tables</comments><journal-ref>Digital Signal Processing 70 (2017) 59-72</journal-ref><doi>10.1016/j.dsp.2017.07.023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize a support vector machine to a support spinor machine by using
the mathematical structure of wedge product over vector machine in order to
extend field from vector field to spinor field. The separated hyperplane is
extended to Kolmogorov space in time series data which allow us to extend a
structure of support vector machine to a support tensor machine and a support
tensor machine moduli space. Our performance test on support spinor machine is
done over one class classification of end point in physiology state of time
series data after empirical mode analysis and compared with support vector
machine test. We implement algorithm of support spinor machine by using
Holo-Hilbert amplitude modulation for fully nonlinear and nonstationary time
series data analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.05937</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.05937</id><created>2017-09-12</created><authors><author><keyname>Liu</keyname><forenames>Yuan</forenames></author><author><keyname>Canu</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Honeine</keyname><forenames>Paul</forenames></author><author><keyname>Ruan</keyname><forenames>Su</forenames></author></authors><title>Une v\'eritable approche $\ell_0$ pour l'apprentissage de dictionnaire</title><categories>cs.CV eess.IV</categories><comments>in French</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse representation learning has recently gained a great success in signal
and image processing, thanks to recent advances in dictionary learning. To this
end, the $\ell_0$-norm is often used to control the sparsity level.
Nevertheless, optimization problems based on the $\ell_0$-norm are non-convex
and NP-hard. For these reasons, relaxation techniques have been attracting much
attention of researchers, by priorly targeting approximation solutions (e.g.
$\ell_1$-norm, pursuit strategies). On the contrary, this paper considers the
exact $\ell_0$-norm optimization problem and proves that it can be solved
effectively, despite of its complexity. The proposed method reformulates the
problem as a Mixed-Integer Quadratic Program (MIQP) and gets the global optimal
solution by applying existing optimization software. Because the main
difficulty of this approach is its computational time, two techniques are
introduced that improve the computational speed. Finally, our method is applied
to image denoising which shows its feasibility and relevance compared to the
state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06072</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06072</id><created>2017-08-06</created><authors><author><keyname>Zarmehi</keyname><forenames>Nematollah</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Bounds on Discrete Fourier Transform of Random Mask</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes some bounds on the maximum of magnitude of a random mask
in Fourier domain. The random mask is used in random sampling scheme. Having a
bound on the maximum value of a random mask in Fourier domain is very useful
for some iterative recovery methods that use thresholding operator. In this
paper, we propose some different bounds and compare them with the empirical
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06073</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06073</id><created>2017-08-16</created><updated>2017-12-22</updated><authors><author><keyname>Kiayani</keyname><forenames>Adnan</forenames></author><author><keyname>Waheed</keyname><forenames>Muhammad Zeeshan</forenames></author><author><keyname>Anttila</keyname><forenames>Lauri</forenames></author><author><keyname>Abdelaziz</keyname><forenames>Mahmoud</forenames></author><author><keyname>Korpi</keyname><forenames>Dani</forenames></author><author><keyname>Syrj&#xe4;l&#xe4;</keyname><forenames>Ville</forenames></author><author><keyname>Kosunen</keyname><forenames>Marko</forenames></author><author><keyname>Stadius</keyname><forenames>Kari</forenames></author><author><keyname>Ryyn&#xe4;nen</keyname><forenames>Jussi</forenames></author><author><keyname>Valkama</keyname><forenames>Mikko</forenames></author></authors><title>Adaptive Nonlinear RF Cancellation for Improved Isolation in
  Simultaneous Transmit-Receive Systems</title><categories>eess.SP</categories><comments>accepted to IEEE</comments><doi>10.1109/TMTT.2017.2786729</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an active radio frequency (RF) cancellation solution to
suppress the transmitter (TX) passband leakage signal in radio transceivers
supporting simultaneous transmission and reception. The proposed technique is
based on creating an opposite-phase baseband equivalent replica of the TX
leakage signal in the transceiver digital front-end through adaptive nonlinear
filtering of the known transmit data, to facilitate highly accurate
cancellation under a nonlinear TX power amplifier (PA). The active RF
cancellation is then accomplished by employing an auxiliary transmitter chain,
to generate the actual RF cancellation signal, and combining it with the
received signal at the receiver (RX) low noise amplifier (LNA) input. A
closed-loop parameter learning approach, based on the decorrelation principle,
is also developed to efficiently estimate the coefficients of the nonlinear
cancellation filter in the presence of a nonlinear TX PA with memory, finite
passive isolation, and a nonlinear RX LNA. The performance of the proposed
cancellation technique is evaluated through comprehensive RF measurements
adopting commercial LTE-Advanced transceiver hardware components. The results
show that the proposed technique can provide an additional suppression of up to
54 dB for the TX passband leakage signal at the RX LNA input, even at
considerably high transmit power levels and with wide transmission bandwidths.
Such novel cancellation solution can therefore substantially improve the TX-RX
isolation, hence reducing the requirements on passive isolation and RF
component linearity, as well as increasing the efficiency and flexibility of
the RF spectrum use in the emerging 5G radio networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06074</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06074</id><created>2017-08-06</created><authors><author><keyname>Sifaou</keyname><forenames>Houssem</forenames></author><author><keyname>Park</keyname><forenames>Ki-Hong</forenames></author><author><keyname>Kammoun</keyname><forenames>Abla</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Optimal Linear Precoding for Indoor Visible Light Communication System</title><categories>eess.SP</categories><comments>5 pages, 4 figures, accepted for publication in ICC proceedings 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible light communication (VLC) is an emerging technique that uses
light-emitting diodes (LED) to combine communication and illumination. It is
considered as a promising scheme for indoor wireless communication that can be
deployed at reduced costs while offering high data rate performance. In this
paper, we focus on the design of the downlink of a multi-user VLC system.
Inherent to multi-user systems is the interference caused by the broadcast
nature of the medium. Linear precoding based schemes are among the most popular
solutions that have recently been proposed to mitigate inter-user interference.
This paper focuses on the design of the optimal linear precoding scheme that
solves the max-min signal-to-interference-plus-noise ratio (SINR) problem. The
performance of the proposed precoding scheme is studied under different working
conditions and compared with the classical zero-forcing precoding. Simulations
have been provided to illustrate the high gain of the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06140</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06140</id><created>2017-09-18</created><updated>2018-07-18</updated><authors><author><keyname>Li</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Tepedelenlio&#x11f;lu</keyname><forenames>Cihan</forenames></author><author><keyname>&#x15e;enol</keyname><forenames>Habib</forenames></author></authors><title>Optimal Training for Residual Self-Interference for Full Duplex One-way
  Relays</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel estimation and optimal training sequence design for full-duplex
one-way relays are investigated. We propose a training scheme to estimate the
residual self-interference (RSI) channel and the channels between nodes
simultaneously. A maximum likelihood estimator is implemented with
Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm. In the presence of RSI, the
overall source-to-destination channel becomes an inter-symbol-interference
(ISI) channel. With the help of estimates of the RSI channel, the destination
is able to cancel the ISI through equalization. We derive and analyze the
Cramer-Rao bound (CRB) in closed-form by using the asymptotic properties of
Toeplitz matrices. The optimal training sequence is obtained by minimizing the
CRB. Extensions for the fundamental one-way relay model to the
frequency-selective fading channels and the multiple relays case are also
considered. For the former, we propose a training scheme to estimate the
overall channel, and for the latter the CRB and the optimal number of relays
are derived when the distance between the source and the destination is fixed.
Simulations using LTE parameters corroborate our theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06298</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06298</id><created>2017-09-19</created><updated>2017-11-24</updated><authors><author><keyname>Dong</keyname><forenames>Hao-Wen</forenames></author><author><keyname>Hsiao</keyname><forenames>Wen-Yi</forenames></author><author><keyname>Yang</keyname><forenames>Li-Chia</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>MuseGAN: Multi-track Sequential Generative Adversarial Networks for
  Symbolic Music Generation and Accompaniment</title><categories>eess.AS cs.AI cs.LG cs.SD</categories><comments>to appear at AAAI 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generating music has a few notable differences from generating images and
videos. First, music is an art of time, necessitating a temporal model. Second,
music is usually composed of multiple instruments/tracks with their own
temporal dynamics, but collectively they unfold over time interdependently.
Lastly, musical notes are often grouped into chords, arpeggios or melodies in
polyphonic music, and thereby introducing a chronological ordering of notes is
not naturally suitable. In this paper, we propose three models for symbolic
multi-track music generation under the framework of generative adversarial
networks (GANs). The three models, which differ in the underlying assumptions
and accordingly the network architectures, are referred to as the jamming
model, the composer model and the hybrid model. We trained the proposed models
on a dataset of over one hundred thousand bars of rock music and applied them
to generate piano-rolls of five tracks: bass, drums, guitar, piano and strings.
A few intra-track and inter-track objective metrics are also proposed to
evaluate the generative results, in addition to a subjective user study. We
show that our models can generate coherent music of four bars right from
scratch (i.e. without human inputs). We also extend our models to human-AI
cooperative music generation: given a specific track composed by human, we can
generate four additional tracks to accompany it. All code, the dataset and the
rendered audio samples are available at https://salu133445.github.io/musegan/ .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06342</identifier>
 <datestamp>2019-07-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06342</id><created>2017-09-19</created><updated>2019-07-13</updated><authors><author><keyname>Xu</keyname><forenames>Mai</forenames></author><author><keyname>Li</keyname><forenames>Chen</forenames></author><author><keyname>Wang</keyname><forenames>Zulin</forenames></author><author><keyname>Chen</keyname><forenames>Zhenzhong</forenames></author><author><keyname>Guan</keyname><forenames>Zhenyu</forenames></author></authors><title>Assessing Visual Quality of Omnidirectional Videos</title><categories>eess.IV</categories><comments>[PLEASE CITE the TCSVT version instead of arxiv version!] Published
  in: IEEE Transactions on Circuits and Systems for Video Technology ( Early
  Access )</comments><journal-ref>IEEE Transactions on Circuits and Systems for Video Technology,
  2018 ( Early Access )</journal-ref><doi>10.1109/TCSVT.2018.2886277</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In contrast with traditional video, omnidirectional video enables spherical
viewing direction with support for head-mounted displays, providing an
interactive and immersive experience. Unfortunately, to the best of our
knowledge, there are few visual quality assessment (VQA) methods, either
subjective or objective, for omnidirectional video coding. This paper proposes
both subjective and objective methods for assessing quality loss in encoding
omnidirectional video. Specifically, we first present a new database, which
includes the viewing direction data from several subjects watching
omnidirectional video sequences. Then, from our database, we find a high
consistency in viewing directions across different subjects. The viewing
directions are normally distributed in the center of the front regions, but
they sometimes fall into other regions, related to video content. Given this
finding, we present a subjective VQA method for measuring difference mean
opinion score (DMOS) of the whole and regional omnidirectional video, in terms
of overall DMOS (O-DMOS) and vectorized DMOS (V-DMOS), respectively. Moreover,
we propose two objective VQA methods for encoded omnidirectional video, in
light of human perception characteristics of omnidirectional video. One method
weighs the distortion of pixels with regard to their distances to the center of
front regions, which considers human preference in a panorama. The other method
predicts viewing directions according to video content, and then the predicted
viewing directions are leveraged to allocate weights to the distortion of each
pixel in our objective VQA method. Finally, our experimental results verify
that both the subjective and objective methods proposed in this paper advance
state-of-the-art VQA for omnidirectional video.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06402</identifier>
 <datestamp>2017-09-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06402</id><created>2017-07-12</created><authors><author><keyname>Votis</keyname><forenames>Constantinos I.</forenames></author><author><keyname>Christofilakis</keyname><forenames>Vasilis</forenames></author><author><keyname>Kostarakis</keyname><forenames>Panos</forenames></author></authors><title>SIMO channel performance evaluation on indoor environment at 2.4 GHz</title><categories>eess.SP physics.app-ph</categories><comments>18 pages, 18 figures</comments><journal-ref>International Journal of Electronics, Volume 103, 2016 - Issue 4</journal-ref><doi>10.1080/00207217.2015.1036810</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents an experimental study of Single Input Multiple Output
(SIMO) channel performance in indoor radio propagation environment. Indoor
channel measurements at 2.4 GHz ISM frequency band have been performed using a
versatile channel sounder testbed platform. A single transmitting antenna, four
receiving antennas with two proposed geometries and a four-branch receiver
circuitry were used in order to achieve channel sounder measurements exploiting
baseband signal processing techniques. Deep investigation on SIMO wireless
channel performance was realized through three types of metrics which are
signal strength, gain coefficient and capacity. Performance results indicate
SIMO channel capacity enhancement and illustrate differences between the two
proposed geometries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06523</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06523</id><created>2017-09-19</created><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Avanji</keyname><forenames>Seyed Amin Ollah Izadi</forenames></author><author><keyname>Mahloojifar</keyname><forenames>Ali</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author></authors><title>Photoacoustic Imaging using Combination of Eigenspace-Based Minimum
  Variance and Delay-Multiply-and-Sum Beamformers: Simulation Study</title><categories>eess.SP cs.IT math.IT physics.med-ph</categories><comments>Submitted in 24th Iranian Conference on Biomedical Engineering (ICBME
  2017)</comments><doi>10.1109/ICBME.2017.8430221</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delay and Sum (DAS), as the most common beamforming algorithm in
Photoacoustic Imaging (PAI), having a simple implementation, results in a
low-quality image. Delay Multiply and Sum (DMAS) was introduced to improve the
quality of the reconstructed images using DAS. However, the resolution
improvement is now well enough compared to high resolution adaptive
reconstruction methods such as Eigenspace- Based Minimum Variance (EIBMV). We
proposed to integrate the EIBMV inside the DMAS formula by replacing the
existing DAS algebra inside the expansion of DMAS, called EIBMV-DMAS. It is
shown that EIBMV-DMAS outperforms DMAS in the terms of levels of sidelobes and
width of mainlobe significantly. For instance, at the depth of 35 mm,
EIBMV-DMAS outperforms DMAS and EIBMV in the term of sidelobes for about 108
dB, 98 dB and 44 dB compared to DAS, DMAS, and EIBMV, respectively. The
quantitative comparison has been conducted using Full-Width-Half-Maximum (FWHM)
and Signal-to-Noise Ratio (SNR), and it was shown that EIBMV-DMAS reduces the
FWHM about 1.65 mm and improves the SNR about 15 dB, compared to DMAS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06663</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06663</id><created>2017-09-19</created><authors><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author><author><keyname>de Oliveira</keyname><forenames>R. C.</forenames></author></authors><title>Linear Computer-Music through Sequences over Galois Fields</title><categories>cs.SD eess.AS</categories><comments>5 pages, 2 figures, 5 tables</comments><msc-class>68U07, 68W05, 11B50, 12E20</msc-class><acm-class>H.5.5; J.5; I.5.4; F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown how binary sequences can be associated with automatic composition
of monophonic pieces. We are concerned with the composition of e-music from
finite field structures. The information at the input may be either random or
information from a black-and-white, grayscale or color picture. New
e-compositions and music score are made available, including a new piece from
the famous Lenna picture: the score of the e-music &lt;&lt;Between Lenna's eyes in C
major.&gt;&gt; The corresponding stretch of music score are presented. Some
particular structures, including clock arithmetic (mod 12), GF(7), GF(8),
GF(13) and GF(17) are addressed. Further, multilevel block-codes are also used
in a new approach of e-music composition, engendering a particular style as an
e-composer. As an example, Pascal multilevel block codes recently introduced
are handled to generate a new style of electronic music over GF(13).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06883</identifier>
 <datestamp>2017-09-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06883</id><created>2017-09-18</created><authors><author><keyname>Peck</keyname><forenames>Moegamat</forenames></author><author><keyname>Alvarez</keyname><forenames>Genesis</forenames></author><author><keyname>Coleman</keyname><forenames>Benjamin</forenames></author><author><keyname>Moradi</keyname><forenames>Hadis</forenames></author><author><keyname>Forest</keyname><forenames>Mark</forenames></author><author><keyname>Aalo</keyname><forenames>Valentine</forenames></author></authors><title>Modeling and Analysis of Power Line Communications for Application in
  Smart Grid</title><categories>eess.SP</categories><comments>6 pages, 13 figures, LACCEI 2017, Boca Raton, FL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart grid is an energy infrastructure that increases energy efficiency by
using communication infrastructure, smart meters, smart appliances, automated
control and networking, and more. This paper focuses on the Power Line
Communication (PLC) aspect and technologies used in the smart grid. There are
various challenges and advancements in the smart grid; this research discusses
how PLC can improve smart grid performance. In order to provide applicable
results, practical PLC system parameters and other required data was obtained
from Florida Power and Light (FPL). Modeling of the PLC system with different
types of digital modulations was conducted using MATLAB/Simulink software and
Python. The benefits and design tradeoffs of Amplitude Shift Keying (ASK),
Frequency Shift Keying (FSK), and Phase Shift Keying (PSK) are discussed. The
modulation schemes are compared on the basis of their applicability to a
practical PLC network by comparing the results of the simulations
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06895</identifier>
 <datestamp>2019-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06895</id><created>2017-09-19</created><updated>2019-02-05</updated><authors><author><keyname>Hong</keyname><forenames>Tao</forenames></author><author><keyname>Li</keyname><forenames>Xiao</forenames></author><author><keyname>Zhu</keyname><forenames>Zhihui</forenames></author><author><keyname>Li</keyname><forenames>Qiuwei</forenames></author></authors><title>Optimized Structured Sparse Sensing Matrices for Compressive Sensing</title><categories>eess.SP cs.LG</categories><comments>2 tables, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider designing a robust structured sparse sensing matrix consisting of
a sparse matrix with a few non-zero entries per row and a dense base matrix for
capturing signals efficiently We design the robust structured sparse sensing
matrix through minimizing the distance between the Gram matrix of the
equivalent dictionary and the target Gram of matrix holding small mutual
coherence. Moreover, a regularization is added to enforce the robustness of the
optimized structured sparse sensing matrix to the sparse representation error
(SRE) of signals of interests. An alternating minimization algorithm with
global sequence convergence is proposed for solving the corresponding
optimization problem. Numerical experiments on synthetic data and natural
images show that the obtained structured sensing matrix results in a higher
signal reconstruction than a random dense sensing matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.06930</identifier>
 <datestamp>2017-09-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.06930</id><created>2017-09-15</created><authors><author><keyname>Athari</keyname><forenames>Mir Hadi</forenames></author><author><keyname>Wang</keyname><forenames>Zhifang</forenames></author></authors><title>Interdependence of Transmission Branch Parameters on the Voltage Levels</title><categories>eess.SP physics.data-an physics.soc-ph</categories><comments>To be published (Accepted) in: Proceedings of the 51st Hawaii
  International Conference on System Sciences (HICSS), Big Island, HI, USA,
  2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transformers and transmission lines are critical components of a grid
network. This paper analyzes the statistical properties of the electrical
parameters of transmission branches and especially examines their
interdependence on the voltage levels. Some interesting findings include: (a)
with appropriate conversion of MVA rating, a transformers per unit reactance
exhibits consistent statistical pattern independent of voltage levels and
capacity; (b) the distributed reactance (ohms/km) of transmission lines also
has some consistent patterns regardless of voltage levels; (c) other parameters
such as the branch resistance, the MVA ratings, the transmission line length,
etc, manifest strong interdependence on the voltage levels which can be
approximated by a power function with different power constants. The results
will be useful in both creation of synthetic power grid test cases and
validation of existing grid models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07041</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07041</id><created>2017-09-20</created><updated>2018-01-11</updated><authors><author><keyname>Gupta</keyname><forenames>Pravir Singh</forenames></author><author><keyname>Choi</keyname><forenames>Gwan Seong</forenames></author></authors><title>Image Acquisition System Using On Sensor Compressed Sampling Technique</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advances in CMOS technology have made high resolution image sensors possible.
These image sensor pose significant challenges in terms of the amount of raw
data generated, energy efficiency and frame rate. This paper presents a new
design methodology for an imaging system and a simplified novel image sensor
pixel design to be used in such system so that Compressed Sensing (CS)
technique can be implemented easily at the sensor level. This results in
significant energy savings as it not only cuts the raw data rate but also
reduces transistor count per pixel, decreases pixel size, increases fill
factor, simplifies ADC, JPEG encoder and JPEG decoder design and decreases
wiring as well as address decoder size by half. Thus CS has the potential to
increase the resolution of image sensors for a given technology and die size
while significantly decreasing the power consumption and design complexity. We
show that it has potential to reduce power consumption by about 23%-65%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07096</identifier>
 <datestamp>2018-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07096</id><created>2017-09-20</created><updated>2018-09-22</updated><authors><author><keyname>Soltani</keyname><forenames>Ramin</forenames></author><author><keyname>Goeckel</keyname><forenames>Dennis</forenames></author><author><keyname>Towsley</keyname><forenames>Don</forenames></author><author><keyname>Bash</keyname><forenames>Boulat</forenames></author><author><keyname>Guha</keyname><forenames>Saikat</forenames></author></authors><title>Covert Wireless Communication with Artificial Noise Generation</title><categories>cs.IT cs.CR cs.NI eess.SP math.IT</categories><doi>10.1109/TWC.2018.2865946</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Covert communication conceals the transmission of the message from an
attentive adversary. Recent work on the limits of covert communication in
additive white Gaussian noise (AWGN) channels has demonstrated that a covert
transmitter (Alice) can reliably transmit a maximum of
$\mathcal{O}\left(\sqrt{n}\right)$ bits to a covert receiver (Bob) without
being detected by an adversary (Warden Willie) in $n$ channel uses. This paper
focuses on the scenario where other friendly nodes distributed according to a
two-dimensional Poisson point process with density $m$ are present in the
environment. We propose a strategy where the friendly node closest to the
adversary, without close coordination with Alice, produces artificial noise. We
show that this method allows Alice to reliably and covertly send
$\mathcal{O}(\min\{{n,m^{\gamma/2}\sqrt{n}}\})$ bits to Bob in $n$ channel
uses, where $\gamma$ is the path-loss exponent. Moreover, we also consider a
setting where there are $N_{\mathrm{w}}$ collaborating adversaries uniformly
and randomly located in the environment and show that in $n$ channel uses,
Alice can reliably and covertly send
$\mathcal{O}\left(\min\left\{n,\frac{m^{\gamma/2}
\sqrt{n}}{N_{\mathrm{w}}^{\gamma}}\right\}\right)$ bits to Bob when $\gamma
&gt;2$, and $\mathcal{O}\left(\min\left\{n,\frac{m
\sqrt{n}}{N_{\mathrm{w}}^{2}\log^2 {N_{\mathrm{w}}}}\right\}\right)$ when
$\gamma = 2$. Conversely, we demonstrate that no higher covert throughput is
possible for $\gamma&gt;2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07206</identifier>
 <datestamp>2018-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07206</id><created>2017-09-21</created><updated>2018-11-14</updated><authors><author><keyname>Zhu</keyname><forenames>Hanyu</forenames></author><author><keyname>Yang</keyname><forenames>Fuqian</forenames></author><author><keyname>Zhu</keyname><forenames>Zhaowei</forenames></author><author><keyname>Luo</keyname><forenames>Xiliang</forenames></author></authors><title>Interconnection Strategies for Self-Calibration of Large Scale Antenna
  Arrays</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In time-division duplexing (TDD) systems, massive multiple-input
multiple-output (MIMO) relies on the channel reciprocity to obtain the downlink
(DL) channel state information (CSI) with the uplink (UL) CSI. In practice, the
mismatches in the radio frequency (RF) analog circuits among different antennas
at the base station (BS) break the end-to-end UL and DL channel reciprocity.
Antenna calibration is necessary to avoid the severe performance degradation
with massive MIMO. Many calibration schemes are available to compensate the RF
gain mismatches and restore the channel reciprocity in TDD massive MIMO
systems. In this paper, we focus on the internal self-calibration scheme where
different BS antennas are interconnected via hardware transmission lines.
First, we study the resulting calibration performance for an arbitrary
interconnection strategy. Next, we obtain closed-form Cramer-Rao lower bound
(CRLB) expressions for each interconnection strategy at the BS with only (M-1)
transmission lines and M denotes the total number of BS antennas. Basing on the
derived results, we further prove that the star interconnection strategy is
optimal for internal self-calibration due to its lowest CRLB. In addition, we
also put forward efficient recursive algorithms to derive the corresponding
maximum-likelihood (ML) estimates of all the calibration coefficients.
Numerical simulation results are also included to corroborate our theoretical
analyses and results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07269</identifier>
 <datestamp>2018-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07269</id><created>2017-09-21</created><updated>2017-11-08</updated><authors><author><keyname>Buerger</keyname><forenames>Michael</forenames></author><author><keyname>Hofmann</keyname><forenames>Christian</forenames></author><author><keyname>Kellermann</keyname><forenames>Walter</forenames></author></authors><title>Broadband Multizone Sound Rendering by Jointly Optimizing the Sound
  Pressure and Particle Velocity</title><categories>eess.AS cs.SD</categories><doi>10.1121/1.5026508</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a recently proposed approach to multizone sound field
synthesis, referred to as Joint Pressure and Velocity Matching (JPVM), is
investigated analytically using a spherical harmonics representation of the
sound field. The approach is motivated by the Kirchhoff-Helmholtz integral
equation and aims at controlling the sound field inside the local listening
zones by evoking the sound pressure and particle velocity on surrounding
contours. Based on the findings of the modal analysis, an improved version of
JPVM is proposed which provides both better performance and lower complexity.
In particular, it is shown analytically that the optimization of the tangential
component of the particle velocity vector, as is done in the original JPVM
approach, is very susceptible to errors and thus not pursued anymore. The
analysis furthermore provides fundamental insights as to how the spherical
harmonics used to describe the 3D variant sound field translate into 2D basis
functions as observed on the contours surrounding the zones. By means of
simulations, it is verified that discarding the tangential component of the
particle velocity vector ultimately leads to an improved performance. Finally,
the impact of sensor noise on the reproduction performance is assessed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07406</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07406</id><created>2017-08-29</created><authors><author><keyname>Thompson</keyname><forenames>Paul A.</forenames></author><author><keyname>Matloff</keyname><forenames>Norm</forenames></author><author><keyname>Fu</keyname><forenames>Alex</forenames></author><author><keyname>Shin</keyname><forenames>Ariel</forenames></author></authors><title>Having your cake and eating it too: Scripted workflows for image
  manipulation</title><categories>eess.IV</categories><comments>Written for Work17 Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reproducibility issue in science has come under increased scrutiny. One
consistent suggestion lies in the use of scripted methods or workflows for data
analysis. Image analysis is one area in science in which little can be done in
scripted methods. The SWIIM Project (Scripted Workflows to Improve Image
Manipulation) is designed to generate workflows from popular image manipulation
tools. In the project, 2 approaches are being taken to construct workflows in
the image analysis area. First, the open-source tool GIMP is being enhanced to
produce an active log (which can be run on a stand-alone basis to perform the
same manipulation). Second, the R system Shiny tool is being used to construct
a graphical user interface (GUI) which works with EBImage code to modify
images, and to produce an active log which can perform the same operations.
This process has been successful to date, but is not complete. The basic method
for each component is discussed, and example code is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07518</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07518</id><created>2017-09-21</created><updated>2018-02-24</updated><authors><author><keyname>Guo</keyname><forenames>Chunhui</forenames></author><author><keyname>Zhang</keyname><forenames>Zhan</forenames></author><author><keyname>Xie</keyname><forenames>Xin</forenames></author><author><keyname>Yang</keyname><forenames>Zhengyu</forenames></author></authors><title>Bolt Detection Signal Analysis Method Based on ICEEMD</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The construction quality of the bolt is directly related to the safety of the
project, and as such, it must be tested. In this paper, the improved complete
ensemble empirical mode decomposition (ICEEMD) method is introduced to the bolt
detection signal analysis. The ICEEMD is used in order to decompose the anchor
detection signal according to the approximate entropy of each intrinsic mode
function (IMF). The noise of the IMFs is eliminated by the wavelet soft
threshold de-noising technique. Based on the approximate entropy, and the
wavelet de-noising principle, the ICEEMD-De anchor signal analysis method is
proposed. From the analysis of the vibration analog signal, as well as the bolt
detection signal, the result shows that the ICEEMD-De method is capable of
correctly separating the different IMFs under noisy conditions, and also that
the IMF can effectively identify the reflection signal of the end of the bolt.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07552</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07552</id><created>2017-09-21</created><authors><author><keyname>Ferris</keyname><forenames>David</forenames></author></authors><title>Techniques and Challenges in Speech Synthesis</title><categories>cs.SD eess.AS</categories><comments>138 pages, 46 figures, Undergraduate Honours Thesis towards a
  Bachelor of Electrical Engineering, November 2016, The University of
  Newcastle, Australia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this project was to develop and implement an English language
Text-to-Speech synthesis system. This involved a study of mechanisms of human
speech production, a review of techniques in speech synthesis, and analysis of
tests used to evaluate the effectiveness of synthesized speech. It was
determined that a diphone synthesis system was the most effective choice for
the scope of this project. A method of automatically identifying and extracting
diphones from prompted speech was designed, allowing for the creation of a
diphone database by a speaker in less than 40 minutes. CMUdict was used to
determine the pronunciation of known words. A system for smoothing the
transitions between diphone recordings was designed and implemented. CMUdict
was then used to train a maximum-likelihood prediction system to determine the
correct pronunciation of unknown English language alphabetic words. Then, a
Part Of Speech tagger was designed to find the lexical class of words within a
sentence.
  A method of altering the pitch, duration, and volume of the produced voice
over time was designed, being a combination of the TD-PSOLA algorithm and a
novel approach referred to as Unvoiced Speech Duration Shifting. This minimises
distortion of the voice when shifting the pitch or duration, while maximising
computational efficiency by operating in the time domain. This approach was
used to add correct lexical stress to vowels within words. A text tokenisation
system was developed to handle arbitrary text input, allowing pronunciation of
numerical input tokens and use of appropriate pauses for punctuation. Methods
for further improving sentence level speech naturalness were discussed.
Finally, the system was tested with listeners for its intelligibility and
naturalness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07722</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07722</id><created>2017-09-22</created><authors><author><keyname>Verenzuela</keyname><forenames>Daniel</forenames></author><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author></authors><title>Spectral and Energy Efficiency of Superimposed Pilots in Uplink Massive
  MIMO</title><categories>eess.SP</categories><comments>32 pages, 12 figures, 3 tables. Submitted in March 2017 to IEEE
  Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next generation wireless networks aim at providing substantial improvements
in spectral efficiency (SE) and energy efficiency (EE). Massive MIMO has been
proved to be a viable technology to achieve these goals by spatially
multiplexing several users using many base station (BS) antennas. A potential
limitation of Massive MIMO in multicell systems is pilot contamination, which
arises in the channel estimation process from the interference caused by
reusing pilots in neighboring cells. A standard method to reduce pilot
contamination, known as regular pilot (RP), is to adjust the length of pilot
sequences while transmitting data and pilot symbols disjointly. An alternative
method, called superimposed pilot (SP), sends a superposition of pilot and data
symbols. This allows to use longer pilots which, in turn, reduces pilot
contamination. We consider the uplink of a multicell Massive MIMO network using
maximum ratio combining detection and compare RP and SP in terms of SE and EE.
To this end, we derive rigorous closed-form achievable rates with SP under a
practical random BS deployment. We prove that the reduction of pilot
contamination with SP is outweighed by the additional coherent and non-coherent
interference. Numerical results show that when both methods are optimized, RP
achieves comparable SE and EE to SP in practical scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07731</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07731</id><created>2017-09-22</created><authors><author><keyname>Zaki</keyname><forenames>Ahmed</forenames></author><author><keyname>Mitra</keyname><forenames>Partha P.</forenames></author><author><keyname>Rasmussen</keyname><forenames>Lars K.</forenames></author><author><keyname>Chatterjee</keyname><forenames>Saikat</forenames></author></authors><title>Estimate Exchange over Network is Good for Distributed Hard Thresholding
  Pursuit</title><categories>stat.ML eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate an existing distributed algorithm for learning sparse signals
or data over networks. The algorithm is iterative and exchanges intermediate
estimates of a sparse signal over a network. This learning strategy using
exchange of intermediate estimates over the network requires a limited
communication overhead for information transmission. Our objective in this
article is to show that the strategy is good for learning in spite of limited
communication. In pursuit of this objective, we first provide a restricted
isometry property (RIP)-based theoretical analysis on convergence of the
iterative algorithm. Then, using simulations, we show that the algorithm
provides competitive performance in learning sparse signals vis-a-vis an
existing alternate distributed algorithm. The alternate distributed algorithm
exchanges more information including observations and system parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07739</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07739</id><created>2017-09-22</created><updated>2017-10-05</updated><authors><author><keyname>Czajkowski</keyname><forenames>Krzysztof M.</forenames></author><author><keyname>Pastuszczak</keyname><forenames>Anna</forenames></author><author><keyname>Koty&#x144;ski</keyname><forenames>Rafa&#x142;</forenames></author></authors><title>Single-pixel imaging with Morlet wavelet correlated random patterns</title><categories>eess.IV cs.CV</categories><journal-ref>Sci. Rep. 8, 466 (2018)</journal-ref><doi>10.1038/s41598-017-18968-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-pixel imaging is an indirect imaging technique which utilizes
simplified optical hardware and advanced computational methods. It offers novel
solutions for hyper-spectral imaging, polarimetric imaging, three-dimensional
imaging, holographic imaging, optical encryption and imaging through scattering
media. The main limitations for its use come from relatively high measurement
and reconstruction times. In this paper we propose to reduce the required
signal acquisition time by using a novel sampling scheme based on a random
selection of Morlet wavelets convolved with white noise. While such functions
exhibit random properties, they are locally determined by Morlet wavelet
parameters. The proposed method is equivalent to random sampling of the
properly selected part of the feature space, which maps the measured images
accurately both in the spatial and spatial frequency domains. We compare both
numerically and experimentally the image quality obtained with our sampling
protocol against widely-used sampling with Walsh-Hadamard or noiselet
functions. The results show considerable improvement over the former methods,
enabling single-pixel imaging at low compression rates on the order of a few
percent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07744</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07744</id><created>2017-09-20</created><authors><author><keyname>Deligiannis</keyname><forenames>Nikos</forenames></author><author><keyname>Mota</keyname><forenames>Jo&#xe3;o F. C.</forenames></author><author><keyname>Zimos</keyname><forenames>Evangelos</forenames></author><author><keyname>Rodrigues</keyname><forenames>Miguel R. D.</forenames></author></authors><title>Heterogeneous Networked Data Recovery from Compressive Measurements
  Using a Copula Prior</title><categories>eess.SP</categories><comments>accepted to IEEE Transactions on Communications</comments><journal-ref>IEEE Transactions on Communications, 2017</journal-ref><doi>10.1109/TCOMM.2017.2746099</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale data collection by means of wireless sensor network and
internet-of-things technology poses various challenges in view of the
limitations in transmission, computation, and energy resources of the
associated wireless devices. Compressive data gathering based on compressed
sensing has been proven a well-suited solution to the problem. Existing designs
exploit the spatiotemporal correlations among data collected by a specific
sensing modality. However, many applications, such as environmental monitoring,
involve collecting heterogeneous data that are intrinsically correlated. In
this study, we propose to leverage the correlation from multiple heterogeneous
signals when recovering the data from compressive measurements. To this end, we
propose a novel recovery algorithm---built upon belief-propagation
principles---that leverages correlated information from multiple heterogeneous
signals. To efficiently capture the statistical dependencies among diverse
sensor data, the proposed algorithm uses the statistical model of copula
functions. Experiments with heterogeneous air-pollution sensor measurements
show that the proposed design provides significant performance improvements
against state-of-the-art compressive data gathering and recovery schemes that
use classical compressed sensing, compressed sensing with side information, and
distributed compressed sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07745</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07745</id><created>2017-09-18</created><authors><author><keyname>Saveljev</keyname><forenames>Vladimir</forenames></author><author><keyname>Kim</keyname><forenames>Sung-Kyu</forenames></author></authors><title>Measurement of amplitude of the moir\'e patterns in digital
  autostereoscopic 3D display</title><categories>eess.IV cs.CV</categories><comments>13 pages, 14 figures, 12 equations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article presents the experimental measurements of the amplitude of the
moir\'e patterns in a digital autostereoscopic barrier-type 3D display across a
wide angular range with a small increment. The period and orientation of the
moir\'e patterns were also measured as functions of the angle. Simultaneous
branches are observed and analyzed. The theoretical interpretation is also
given. The results can help preventing or minimizing the moir\'e effect in
displays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07747</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07747</id><created>2017-09-19</created><updated>2017-10-02</updated><authors><author><keyname>Pan</keyname><forenames>An</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author><author><keyname>Li</keyname><forenames>Maosen</forenames></author><author><keyname>Zhou</keyname><forenames>Meiling</forenames></author><author><keyname>Min</keyname><forenames>Junwei</forenames></author><author><keyname>Lei</keyname><forenames>Ming</forenames></author><author><keyname>Yao</keyname><forenames>Baoli</forenames></author></authors><title>SNR-based adaptive acquisition method for fast Fourier ptychographic
  microscopy</title><categories>eess.IV physics.optics</categories><comments>11 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fourier ptychographic microscopy (FPM) is a computational imaging technique
with both high resolution and large field-of-view. However, the effective
numerical aperture (NA) achievable with a typical LED panel is ambiguous and
usually relies on the repeated tests of different illumination NAs. The imaging
quality of each raw image usually depends on the visual assessments, which is
subjective and inaccurate especially for those dark field images. Moreover, the
acquisition process is really time-consuming.In this paper, we propose a
SNR-based adaptive acquisition method for quantitative evaluation and adaptive
collection of each raw image according to the signal-to-noise ration (SNR)
value, to improve the FPM's acquisition efficiency and automatically obtain the
maximum achievable NA, reducing the time of collection, storage and subsequent
calculation. The widely used EPRY-FPM algorithm is applied without adding any
algorithm complexity and computational burden. The performance has been
demonstrated in both USAF targets and biological samples with different imaging
sensors respectively, which have either Poisson or Gaussian noises model.
Further combined with the sparse LEDs strategy, the number of collection images
can be shorten to around 25 frames while the former needs 361 images, the
reduction ratio can reach over 90%. This method will make FPM more practical
and automatic, and can also be used in different configurations of FPM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07875</identifier>
 <datestamp>2019-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07875</id><created>2017-09-22</created><updated>2019-11-11</updated><authors><author><keyname>Fong</keyname><forenames>Chamberlain</forenames></author></authors><title>Elliptification of Rectangular Imagery</title><categories>eess.IV cs.CV</categories><comments>JMM2019 SIGMAA-ARTS; corrected typo on detJ surfaces; added
  description on bijective spherize filter</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and discuss different algorithms for converting rectangular
imagery into elliptical regions. We mainly focus on methods that use
mathematical mappings with explicit and invertible equations. The key idea is
to start with invertible mappings between the square and the circular disc then
extend it to handle rectangles and ellipses. This extension can be done by
simply removing the eccentricity and reintroducing it back after using a chosen
square-to-disc mapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07902</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07902</id><created>2017-09-22</created><authors><author><keyname>Hsu</keyname><forenames>Wei-Ning</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Glass</keyname><forenames>James</forenames></author></authors><title>Unsupervised Learning of Disentangled and Interpretable Representations
  from Sequential Data</title><categories>cs.LG cs.CL cs.SD eess.AS stat.ML</categories><comments>Accepted to NIPS 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a factorized hierarchical variational autoencoder, which learns
disentangled and interpretable representations from sequential data without
supervision. Specifically, we exploit the multi-scale nature of information in
sequential data by formulating it explicitly within a factorized hierarchical
graphical model that imposes sequence-dependent priors and sequence-independent
priors to different sets of latent variables. The model is evaluated on two
speech corpora to demonstrate, qualitatively, its ability to transform speakers
or linguistic content by manipulating different sets of latent variables; and
quantitatively, its ability to outperform an i-vector baseline for speaker
verification and reduce the word error rate by as much as 35% in mismatched
train/test scenarios for automatic speech recognition tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07908</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07908</id><created>2017-09-20</created><authors><author><keyname>Venkataramani</keyname><forenames>Shrikant</forenames></author><author><keyname>Subakan</keyname><forenames>Y. Cem</forenames></author><author><keyname>Smaragdis</keyname><forenames>Paris</forenames></author></authors><title>Neural Network Alternatives to Convolutive Audio Models for Source
  Separation</title><categories>cs.SD eess.AS</categories><comments>Published in MLSP 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutive Non-Negative Matrix Factorization model factorizes a given audio
spectrogram using frequency templates with a temporal dimension. In this paper,
we present a convolutional auto-encoder model that acts as a neural network
alternative to convolutive NMF. Using the modeling flexibility granted by
neural networks, we also explore the idea of using a Recurrent Neural Network
in the encoder. Experimental results on speech mixtures from TIMIT dataset
indicate that the convolutive architecture provides a significant improvement
in separation performance in terms of BSSeval metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07965</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07965</id><created>2017-09-22</created><updated>2018-01-29</updated><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Mahloojifar</keyname><forenames>Ali</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author><author><keyname>Kratkiewicz</keyname><forenames>Karl</forenames></author><author><keyname>Adabi</keyname><forenames>Saba</forenames></author><author><keyname>Nasiriavanaki</keyname><forenames>Mohammadreza</forenames></author></authors><title>Linear-Array Photoacoustic Imaging Using Minimum Variance-Based Delay
  Multiply and Sum Adaptive Beamforming Algorithm</title><categories>eess.SP cs.IT math.IT</categories><comments>This is the final version of this paper, which is accepted in the
  &quot;Journal of Biomedical Optics&quot;. Compared to previous versions, this version
  contains more experiments and evaluation</comments><journal-ref>J. of Biomedical Optics, 23(2), 026002 (2018)</journal-ref><doi>10.1117/1.JBO.23.2.026002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Photoacoustic imaging (PA), Delay-and-Sum (DAS) beamformer is a common
beamforming algorithm having a simple implementation. However, it results in a
poor resolution and high sidelobes. To address these challenges, a new
algorithm namely Delay-Multiply-and-Sum (DMAS) was introduced having lower
sidelobes compared to DAS. To improve the resolution of DMAS, a novel
beamformer is introduced using Minimum Variance (MV) adaptive beamforming
combined with DMAS, so-called Minimum Variance-Based DMAS (MVB-DMAS). It is
shown that expanding the DMAS equation results in multiple terms representing a
DAS algebra. It is proposed to use the MV adaptive beamformer instead of the
existing DAS. MVB-DMAS is evaluated numerically and experimentally. In
particular, at the depth of 45 mm MVB-DMAS results in about 31 dB, 18 dB and 8
dB sidelobes reduction compared to DAS, MV and DMAS, respectively. The
quantitative results of the simulations show that MVB-DMAS leads to improvement
in full-width-half-maximum about 96 %, 94 % and 45 % and signal-to-noise ratio
about 89 %, 15 % and 35 % compared to DAS, DMAS, MV, respectively. In
particular, at the depth of 33 mm of the experimental images, MVB-DMAS results
in about 20 dB sidelobes reduction in comparison with other beamformers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07970</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07970</id><created>2017-09-22</created><authors><author><keyname>Ansari</keyname><forenames>O. A.</forenames></author><author><keyname>Safar</keyname><forenames>N.</forenames></author><author><keyname>Chung</keyname><forenames>C. Y.</forenames></author></authors><title>Reliability assessment of microgrid with renewable generation and
  prioritized loads</title><categories>eess.SP</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  With the increase in awareness about the climate change, there has been a
tremendous shift towards utilizing renewable energy sources (RES). In this
regard, smart grid technologies have been presented to facilitate higher
penetration of RES. Microgrids are the key components of the smart grids.
Microgrids allow integration of various distributed energy resources (DER) such
as the distributed generation (DGs) and energy storage systems (ESSs) into the
distribution system and hence remove or delay the need for distribution
expansion. One of the crucial requirements for utilities is to ensure that the
system reliability is maintained with the inclusion of microgrid topology.
Therefore, this paper evaluates the reliability of a microgrid containing
prioritized loads and distributed RES through a hybrid analytical-simulation
method. The stochasticity of RES introduces complexity to the reliability
evaluation. The method takes into account the variability of RES through Monte-
Carlo state sampling simulation. The results indicate the reliability
enhancement of the overall system in the presence of the microgrid topology. In
particular, the highest priority load has the largest improvement in the
reliability indices. Furthermore, sensitivity analysis is performed to
understand the effects of the failure of microgrid islanding in the case of a
fault in the upstream network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.07972</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.07972</id><created>2017-09-22</created><authors><author><keyname>Breschi</keyname><forenames>Valentina</forenames></author><author><keyname>Kolmanovsky</keyname><forenames>Ilya</forenames></author><author><keyname>Bemporad</keyname><forenames>Alberto</forenames></author></authors><title>Cloud-aided collaborative estimation by ADMM-RLS algorithms for
  connected vehicle prognostics</title><categories>cs.SY cs.DC cs.MA eess.SP math.OC</categories><comments>Extended version, with complete proofs, of a submission to the
  American Control Conference 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the connectivity of consumer devices is rapidly growing and cloud
computing technologies are becoming more widespread, cloud-aided techniques for
parameter estimation can be designed to exploit the theoretically unlimited
storage memory and computational power of the cloud, while relying on
information provided by multiple sources. With the ultimate goal of developing
monitoring and diagnostic strategies, this report focuses on the design of a
Recursive Least-Squares (RLS) based estimator for identification over a group
of devices connected to the cloud. The proposed approach, that relies on
Node-to-Cloud-to-Node (N2C2N) transmissions, is designed so that: (i) estimates
of the unknown parameters are computed locally and (ii) the local estimates are
refined on the cloud. The proposed approach requires minimal changes to local
(pre-existing) RLS estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08041</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08041</id><created>2017-09-23</created><authors><author><keyname>Saito</keyname><forenames>Yuki</forenames></author><author><keyname>Takamichi</keyname><forenames>Shinnosuke</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author></authors><title>Statistical Parametric Speech Synthesis Incorporating Generative
  Adversarial Networks</title><categories>cs.SD cs.LG eess.AS</categories><comments>Preprint manuscript of IEEE/ACM Transactions on Audio, Speech and
  Language Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for statistical parametric speech synthesis incorporating generative
adversarial networks (GANs) is proposed. Although powerful deep neural networks
(DNNs) techniques can be applied to artificially synthesize speech waveform,
the synthetic speech quality is low compared with that of natural speech. One
of the issues causing the quality degradation is an over-smoothing effect often
observed in the generated speech parameters. A GAN introduced in this paper
consists of two neural networks: a discriminator to distinguish natural and
generated samples, and a generator to deceive the discriminator. In the
proposed framework incorporating the GANs, the discriminator is trained to
distinguish natural and generated speech parameters, while the acoustic models
are trained to minimize the weighted sum of the conventional minimum generation
loss and an adversarial loss for deceiving the discriminator. Since the
objective of the GANs is to minimize the divergence (i.e., distribution
difference) between the natural and generated speech parameters, the proposed
method effectively alleviates the over-smoothing effect on the generated speech
parameters. We evaluated the effectiveness for text-to-speech and voice
conversion, and found that the proposed method can generate more natural
spectral parameters and $F_0$ than conventional minimum generation error
training algorithm regardless its hyper-parameter settings. Furthermore, we
investigated the effect of the divergence of various GANs, and found that a
Wasserstein GAN minimizing the Earth-Mover's distance works the best in terms
of improving synthetic speech quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08085</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08085</id><created>2017-09-23</created><authors><author><keyname>Zou</keyname><forenames>Lianfeng</forenames></author><author><keyname>Caloz</keyname><forenames>Christophe</forenames></author></authors><title>Time-Reversal Routing for Dispersion Code Multiple Access (DCMA)
  Communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the modeling and characterization of a time-reversal routing
dispersion code multiple access (TR-DCMA) system. We show that this system
maintains the low complexity advantage of DCMA transceivers while offering
dynamic adaptivity for practial communication scenarios. We first derive the
mathematical model and explain operation principles of the system, and then
characterize its interference, signal to interference ratio, and bit error
probability characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08131</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08131</id><created>2017-09-23</created><updated>2018-08-08</updated><authors><author><keyname>Kord</keyname><forenames>Ahmed</forenames></author><author><keyname>Sounas</keyname><forenames>Dimitrios L.</forenames></author><author><keyname>Al&#xf9;</keyname><forenames>Andrea</forenames></author></authors><title>Magnetless Circulators Based on Spatiotemporal Modulation of Bandstop
  Filters in a Delta Topology</title><categories>eess.SP</categories><doi>10.1109/TMTT.2017.2757470</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we discuss the design rationale and guidelines to build
magnet-less circulators based on spatio-temporal modulation of resonant
junctions consisting of first-order bandstop filters connected in a delta
topology. Without modulation, the junction does not allow transmission between
its ports, however, when the natural oscillation frequencies of the constituent
LC filters are modulated in time with a suitable phase pattern, a synthetic
angular-momentum bias can be effectively imparted to the junction and a
transmission window opens at one of the output ports, thus realizing a
circulator. We develop a rigorous small-signal linear model and find analytical
expressions for the harmonic S-parameters of the proposed circuit, which
significantly facilitate the design process. We validate the theory with
simulations and further discuss the large signal response, including power
handling and non-linearity, and the noise performance. Finally, we present
measured results with unprecedented performance in all metrics for a PCB
prototype using a Rogers board and off-the-shelf discrete components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08133</identifier>
 <datestamp>2018-08-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08133</id><created>2017-09-23</created><updated>2018-08-08</updated><authors><author><keyname>Kord</keyname><forenames>Ahmed</forenames></author><author><keyname>Sounas</keyname><forenames>Dimitrios L.</forenames></author><author><keyname>Al&#xf9;</keyname><forenames>Andrea</forenames></author></authors><title>Pseudo-Linear Time-Invariant Magnetless Circulators Based on
  Differential Spatiotemporal Modulation of Resonant Junctions</title><categories>eess.SP</categories><doi>10.1109/TMTT.2018.2818152</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present voltage- and current-mode differential magnetless
non-reciprocal devices obtained by pairing two single-ended (SE) circulators,
each consisting of three first-order bandpass or bandstop LC filters, connected
in either a wye or a delta topology. The resonant poles of each SE circulator
are modulated in time with 120 deg phase-shifted periodic signals, resulting in
synthetic angular-momentum biasing achieved through spatiotemporal modulation
(STM). We tailor the two SE circulators to exhibit a constant 180 deg phase
difference between their STM biases. Unlike conventional differential
time-variant circuits, for which only the even or odd spurs are rejected, we
show that the proposed configuration cancels out all intermodulation (IM)
products, thus making them operate alike linear time-invariant (LTI) circuits
for an external observer. In turn, this property enhances all metrics of the
resulting circulator, overcoming the limitations of SE architectures, and
improving insertion loss, impedance matching, bandwidth and noise figure. We
show that this differential architecture also significantly relaxes the
required modulation parameters, both in frequency and amplitude. We develop a
rigorous small-signal model to guide the design of the proposed circuits and to
get insights into their pseudo-LTI characteristics. Then, we validate the
theory with simulations and measurements showing remarkable performance
compared to the current state of the art of magnetless non-reciprocal devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08182</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08182</id><created>2017-09-24</created><authors><author><keyname>Irmanova</keyname><forenames>Aidana</forenames></author><author><keyname>Krestinskaya</keyname><forenames>Olga</forenames></author><author><keyname>James</keyname><forenames>Alex Pappachen</forenames></author></authors><title>Neuromorphic adaptive edge-preserving denoising filter</title><categories>eess.IV</categories><comments>IEEE International Conference on Rebooting Computing 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present on-sensor neuromorphic vision hardware
implementation of denoising spatial filter. The mean or median spatial filters
with fixed window shape are known for its denoising ability, however, have the
drawback of blurring the object edges. The effect of blurring increases with an
increase in window size. To preserve the edge information, we propose an
adaptive spatial filter that uses neuron's ability to detect similar pixels and
calculates the mean. The analog input differences of neighborhood pixels are
converted to the chain of pulses with voltage controlled oscillator and applied
as neuron input. When the input pulses charge the neuron to equal or greater
level than its threshold, the neuron will fire, and pixels are identified as
similar. The sequence of the neuron's responses for pixels is stored in the
serial-in-parallel-out shift register. The outputs of shift registers are used
as input to the selector switches of an averaging circuit making this an
adaptive mean operation resulting in an edge preserving mean filter. System
level simulation of the hardware is conducted using 150 images from Caltech
database with added Gaussian noise to test the robustness of edge-preserving
and denoising ability of the proposed filter. Threshold values of the hardware
neuron were adjusted so that the proposed edge-preserving spatial filter
achieves optimal performance in terms of PSNR and MSE, and these results
outperforms that of the conventional mean and median filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08210</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08210</id><created>2017-09-24</created><authors><author><keyname>Fortunati</keyname><forenames>S.</forenames></author><author><keyname>Gini</keyname><forenames>F.</forenames></author><author><keyname>Greco</keyname><forenames>M. S.</forenames></author><author><keyname>Richmond</keyname><forenames>C. D.</forenames></author></authors><title>Performance Bounds for Parameter Estimation under Misspecified Models:
  Fundamental findings and applications</title><categories>eess.SP</categories><comments>To appear in the IEEE Signal Processing Magazine</comments><doi>10.1109/MSP.2017.2738017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inferring information from a set of acquired data is the main objective of
any signal processing (SP) method. In particular, the common problem of
estimating the value of a vector of parameters from a set of noisy measurements
is at the core of a plethora of scientific and technological advances in the
last decades; for example, wireless communications, radar and sonar,
biomedicine, image processing, and seismology, just to name a few. Developing
an estimation algorithm often begins by assuming a statistical model for the
measured data, i.e. a probability density function (pdf) which if correct,
fully characterizes the behaviour of the collected data/measurements.
Experience with real data, however, often exposes the limitations of any
assumed data model since modelling errors at some level are always present.
Consequently, the true data model and the model assumed to derive the
estimation algorithm could differ. When this happens, the model is said to be
mismatched or misspecified. Therefore, understanding the possible performance
loss or regret that an estimation algorithm could experience under model
misspecification is of crucial importance for any SP practitioner. Further,
understanding the limits on the performance of any estimator subject to model
misspecification is of practical interest. Motivated by the widespread and
practical need to assess the performance of a mismatched estimator, the goal of
this paper is to help to bring attention to the main theoretical findings on
estimation theory, and in particular on lower bounds under model
misspecification, that have been published in the statistical and econometrical
literature in the last fifty years. Secondly, some applications are discussed
to illustrate the broad range of areas and problems to which this framework
extends, and consequently the numerous opportunities available for SP
researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08243</identifier>
 <datestamp>2018-06-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08243</id><created>2017-09-24</created><updated>2018-05-31</updated><authors><author><keyname>Valin</keyname><forenames>Jean-Marc</forenames></author></authors><title>A Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech
  Enhancement</title><categories>cs.SD eess.AS</categories><comments>5 pages, MMSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite noise suppression being a mature area in signal processing, it
remains highly dependent on fine tuning of estimator algorithms and parameters.
In this paper, we demonstrate a hybrid DSP/deep learning approach to noise
suppression. A deep neural network with four hidden layers is used to estimate
ideal critical band gains, while a more traditional pitch filter attenuates
noise between pitch harmonics. The approach achieves significantly higher
quality than a traditional minimum mean squared error spectral estimator, while
keeping the complexity low enough for real-time operation at 48 kHz on a
low-power processor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08272</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08272</id><created>2017-09-24</created><authors><author><keyname>Zhan</keyname><forenames>Junpeng</forenames></author><author><keyname>Ansari</keyname><forenames>Osama Aslam</forenames></author><author><keyname>Chung</keyname><forenames>C. Y.</forenames></author></authors><title>Compressed Air Energy Storage-Part I: An Accurate Bi-linear Cavern Model</title><categories>eess.SP</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed air energy storage (CAES) is suitable for large-scale energy
storage and can help to increase the penetration of wind power in power
systems. A CAES plant consists of compressors, expanders, caverns, and a
motor/generator set. Currently used cavern models for CAES are either accurate
but highly non-linear or linear but inaccurate. Highly non-linear cavern models
cannot be directly utilized in power system optimization problems. In this
regard, an accurate bi-linear cavern model for CAES is proposed in this first
paper of a two-part series. The charging and discharging processes in a cavern
are divided into several virtual states and then the first law of
thermodynamics and ideal gas law are used to derive a cavern model, i.e., model
for the variation of temperature and pressure in these processes. Thereafter,
the heat transfer between the air in the cavern and the cavern wall is
considered and integrated into the cavern model. By subsequently eliminating
several negligible terms, the cavern model reduces to a bi-linear (linear)
model for CAES with multiple (single) time steps. The accuracy of the proposed
cavern model is verified via comparison with an accurate non-linear model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08275</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08275</id><created>2017-09-24</created><authors><author><keyname>Zhan</keyname><forenames>Junpeng</forenames></author><author><keyname>Wen</keyname><forenames>Yunfeng</forenames></author><author><keyname>Ansari</keyname><forenames>Osama Aslam</forenames></author><author><keyname>Chung</keyname><forenames>C. Y.</forenames></author></authors><title>Compressed Air Energy Storage-Part II: Application to Power System Unit
  Commitment</title><categories>eess.SP</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unit commitment (UC) is one of the most important power system operation
problems. To integrate higher penetration of wind power into power systems,
more compressed air energy storage (CAES) plants are being built. Existing
cavern models for the CAES used in power system optimization problems are not
accurate, which may lead to infeasible solutions, e.g., the air pressure in the
cavern is outside its operating range. In this regard, an accurate CAES model
is proposed for the UC problem based on the accurate bi-linear cavern model
proposed in the first paper of this two-part series. The minimum switch time
between the charging and discharging processes of CAES is considered. The whole
model, i.e., the UC model with an accurate CAES model, is a large-scale mixed
integer bi-linear programming problem. To reduce the complexity of the whole
model, three strategies are proposed to reduce the number of bi-linear terms
without sacrificing accuracy. McCormick relaxation and piecewise linearization
are then used to linearize the whole model. To decrease the solution time, a
method to obtain an initial solution of the linearized model is proposed. A
modified RTS-79 system is used to verify the effectiveness of the whole model
and the solution methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08278</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08278</id><created>2017-09-24</created><updated>2017-11-08</updated><authors><author><keyname>Li</keyname><forenames>Ang</forenames></author><author><keyname>Masouros</keyname><forenames>Christos</forenames></author><author><keyname>Liu</keyname><forenames>Fan</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. L.</forenames></author></authors><title>Massive MIMO 1-Bit DAC Transmission: A Low-Complexity Symbol Scaling
  Approach</title><categories>eess.SP cs.IT math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study multi-user massive multiple-input single-output (MISO) systems and
focus on downlink transmission, where the base station (BS) employs a large
antenna array with low-cost 1-bit digital-to-analog converters (DACs). The
direct combination of existing beamforming schemes with 1-bit DACs is shown to
lead to an error floor at medium-to-high SNR regime, due to the coarse
quantization of the DACs with limited precision. In this paper, based on the
constructive interference we consider both a quantized linear beamforming
scheme where we analytically obtain the optimal beamforming matrix, and a
non-linear mapping scheme where we directly design the transmit signal vector.
Due to the 1-bit quantization, the formulated optimization for the non-linear
mapping scheme is shown to be non-convex. To solve this problem, the non-convex
constraints of the 1-bit DACs are firstly relaxed, followed by an element-wise
normalization to satisfy the 1-bit DAC transmission. We further propose a
low-complexity symbol scaling scheme that consists of three stages, in which
the quantized transmit signal on each antenna element is selected sequentially.
Numerical results show that the proposed symbol scaling scheme achieves a
comparable performance to the optimization-based non-linear mapping approach,
while its corresponding complexity is negligible compared to that of the
non-linear scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08328</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08328</id><created>2017-09-25</created><authors><author><keyname>Cui</keyname><forenames>Jie</forenames></author><author><keyname>Wang</keyname><forenames>Dinghui</forenames></author></authors><title>Biosignal Analysis with Matching-Pursuit Based Adaptive Chirplet
  Transform</title><categories>eess.SP</categories><comments>27 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chirping phenomena, in which the instantaneous frequencies of a signal change
with time, are abundant in signals related to biological systems. Biosignals
are non-stationary in nature and the time-frequency analysis is a viable tool
to analyze them. It is well understood that Gaussian chirplet function is
critical in describing chirp signals. Despite the theory of adaptive chirplet
transform (ACT) has been established for more than two decades and is well
accepted in the community of signal processing, application of ACT to
bio-/biomedical signal analysis is still quite limited, probably because that
the power of ACT, as an emerging tool for biosignal analysis, has not yet been
fully appreciated by the researchers in the field of biomedical engineering. In
this paper, we describe a novel ACT algorithm based on the &quot;coarse-refinement&quot;
scheme. Namely, the initial estimate of a chirplet is implemented with the
matching-pursuit (MP) algorithm and subsequently it is refined using the
expectation-maximization (EM) algorithm, which we coin as MPEM algorithm. We
emphasize the robustness enhancement of the algorithm in face of noise, which
is important to biosignal analysis, as they are usually embedded in strong
background noise. We then demonstrate the capability of our algorithm by
applying it to the analysis of representative biosignals, including visual
evoked potentials (bioelectrical signals), audible heart sounds and bat
ultrasonic echolocation signals (bioacoustic signals), and human speech. The
results show that the MPEM algorithm provides more compact representation of
signals under investigation and clearer visualization of their time-frequency
structures, indicating considerable promise of ACT in biosignal analysis. The
MATLAB code repository is hosted on GitHub for free download
(https://github.com/jiecui/mpact).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08344</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08344</id><created>2017-09-25</created><authors><author><keyname>Solewicz</keyname><forenames>Yosef</forenames><affiliation>Israel National Police</affiliation></author><author><keyname>Orenshtein</keyname><forenames>Chagay</forenames><affiliation>Tel Hai College</affiliation></author><author><keyname>Friedland</keyname><forenames>Avital</forenames></author></authors><title>Predicting interviewee attitude and body language from speech
  descriptors</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This present research investigated the relationship between personal
impressions and the acoustic nonverbal communication conveyed by employees
being interviewed. First, we investigated the extent to which different
conversation topics addressed during the interview induced changes in the
interviewees' acoustic parameters. Next, we attempted to predict the observed
and self-assessed attitudes and body language of the interviewees based on the
acoustic data. The results showed that topicality caused significant deviations
in the acoustic parameters statistics, but the ability to predict the personal
perceptions of the interviewees based on their acoustic non-verbal
communication was relatively independent of topicality, due to the natural
redundancy inherent in acoustic attributes. Our findings suggest that joint
modeling of speech and visual cues may improve the assessment of interviewee
profiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08388</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08388</id><created>2017-09-25</created><updated>2017-12-17</updated><authors><author><keyname>Shen</keyname><forenames>Mutian</forenames></author><author><keyname>Zhang</keyname><forenames>Pan</forenames></author><author><keyname>Zhou</keyname><forenames>Hai-Jun</forenames></author></authors><title>Compressed Sensing by Shortest-Solution Guided Decimation</title><categories>eess.SP cs.IT math.IT physics.data-an</categories><comments>10 pages, 9 figures and a MATLAB code. Updated reference; Efficient
  implementation of SSD using optimized dual ascent is achieved</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing is an important problem in many fields of science and
engineering. It reconstructs signals by finding sparse solutions to
underdetermined linear equations. In this work we propose a deterministic and
non-parametric algorithm SSD (Shortest-Solution guided Decimation) to construct
support of the sparse solution under the guidance of the dense least-squares
solution of the recursively decimated linear equation. The most significant
feature of SSD is its insensitivity to correlations in the sampling matrix.
Using extensive numerical experiments we show that SSD greatly outperforms
L1-norm based methods, Orthogonal Least Squares, Orthogonal Matching Pursuit,
and Approximate Message Passing when the sampling matrix contains strong
correlations. This nice property of correlation tolerance makes SSD a versatile
and robust tool for different types of real-world signal acquisition tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08460</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08460</id><created>2017-09-25</created><authors><author><keyname>Barina</keyname><forenames>David</forenames></author><author><keyname>Zemcik</keyname><forenames>Pavel</forenames></author><author><keyname>Kula</keyname><forenames>Michal</forenames></author></authors><title>Simple Signal Extension Method for Discrete Wavelet Transform</title><categories>eess.SP cs.OH</categories><comments>preprint; presented on ICSIP 2016</comments><doi>10.1109/SIPROCESS.2016.7888319</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrete wavelet transform of finite-length signals must necessarily handle
the signal boundaries. The state-of-the-art approaches treat such boundaries in
a complicated and inflexible way, using special prolog or epilog phases. This
holds true in particular for images decomposed into a number of scales,
exemplary in JPEG 2000 coding system. In this paper, the state-of-the-art
approaches are extended to perform the treatment using a compact streaming
core, possibly in multi-scale fashion. We present the core focused on CDF 5/3
wavelet and the symmetric border extension method, both employed in the JPEG
2000. As a result of our work, every input sample is visited only once, while
the results are produced immediately, i.e. without buffering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08573</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08573</id><created>2017-09-25</created><authors><author><keyname>Labib</keyname><forenames>Mina</forenames></author><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author><author><keyname>Martone</keyname><forenames>Anthony F.</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey H.</forenames></author><author><keyname>Zaghloul</keyname><forenames>Amir I.</forenames></author></authors><title>Coexistence between Communication and Radar Systems - A Survey</title><categories>eess.SP</categories><comments>Accepted for publication in Radio Science Bulletin</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data traffic demand in cellular networks has been tremendously growing and
has led to creating congested RF environment. Accordingly, innovative
approaches for spectrum sharing have been proposed and implemented to
accommodate several systems within the same frequency band. Spectrum sharing
between radar and communication systems is one of the important research and
development areas. In this paper, we present the fundamental spectrum sharing
concepts and technologies, then we provide an updated and comprehensive survey
of spectrum sharing techniques that have been developed to enable some of the
wireless communication systems to coexist in the same band as radar systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08651</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08651</id><created>2017-09-22</created><authors><author><keyname>Ivanova</keyname><forenames>Elizaveta</forenames></author><author><keyname>Nekrutkin</keyname><forenames>Vladimir</forenames></author></authors><title>Two asymptotic approaches for the exponential signal and harmonic noise
  in Singular Spectrum Analysis</title><categories>eess.SP math.NA</categories><comments>19 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The general theoretical approach to the asymptotic extraction of the signal
series from the perturbed signal with the help of Singular Spectrum Analysis
(briefly, SSA) was already outlined in Nekrutkin 2010, SII, v. 3, 297--319.
  In this paper we consider the example of such an analysis applied to the
increasing exponential signal and the sinusoidal noise. It is proved that if
the signal rapidly tends to infinity, then the so-called reconstruction errors
of SSA do not uniformly tend to zero as the series length tends to infinity.
More precisely, in this case any finite number of last terms of the error
series do not tend to any finite or infinite values.
  On the contrary, for the &quot;discretization&quot; scheme with the bounded from above
exponential signal, all elements of the error series tend to zero.
  This effect shows that the discretization model can be an effective tool in
the theoretical SSA considerations with increasing signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08667</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08667</id><created>2017-09-25</created><authors><author><keyname>Fortunati</keyname><forenames>S.</forenames></author><author><keyname>Greco</keyname><forenames>M. S.</forenames></author><author><keyname>Gini</keyname><forenames>F.</forenames></author></authors><title>Asymptotic robustness of Kelly's GLRT and Adaptive Matched Filter
  detector under model misspecification</title><categories>eess.SP</categories><comments>ISI World Statistics Congress 2017 (ISI2017), Marrakech, Morocco,
  16-21 July 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental assumption underling any Hypothesis Testing (HT) problem is
that the available data follow the parametric model assumed to derive the test
statistic. Nevertheless, a perfect match between the true and the assumed data
models cannot be achieved in many practical applications. In all these cases,
it is advisable to use a robust decision test, i.e. a test whose statistic
preserves (at least asymptotically) the same probability density function (pdf)
for a suitable set of possible input data models under the null hypothesis.
Building upon the seminal work of Kent (1982), in this paper we investigate the
impact of the model mismatch in a recurring HT problem in radar signal
processing applications: testing the mean of a set of Complex Elliptically
Symmetric (CES) distributed random vectors under a possible misspecified,
Gaussian data model. In particular, by using this general misspecified
framework, a new look to two popular detectors, the Kelly's Generalized
Likelihood Ration Test (GLRT) and the Adaptive Matched Filter (AMF), is
provided and their robustness properties investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.08842</identifier>
 <datestamp>2017-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.08842</id><created>2017-09-26</created><authors><author><keyname>Langhabel</keyname><forenames>Jonas</forenames></author></authors><title>Learning a Predictive Model for Music Using PULSE</title><categories>cs.LG cs.SD eess.AS</categories><comments>Master's Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predictive models for music are studied by researchers of algorithmic
composition, the cognitive sciences and machine learning. They serve as base
models for composition, can simulate human prediction and provide a
multidisciplinary application domain for learning algorithms. A particularly
well established and constantly advanced subtask is the prediction of
monophonic melodies. As melodies typically involve non-Markovian dependencies
their prediction requires a capable learning algorithm. In this thesis, I apply
the recent feature discovery and learning method PULSE to the realm of symbolic
music modeling. PULSE is comprised of a feature generating operation and
L1-regularized optimization. These are used to iteratively expand and cull the
feature set, effectively exploring feature spaces that are too large for common
feature selection approaches. I design a general Python framework for PULSE,
propose task-optimized feature generating operations and various
music-theoretically motivated features that are evaluated on a standard corpus
of monophonic folk and chorale melodies. The proposed method significantly
outperforms comparable state-of-the-art models. I further discuss the free
parameters of the learning algorithm and analyze the feature composition of the
learned models. The models learned by PULSE afford an easy inspection and are
musicologically interpreted for the first time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.09219</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.09219</id><created>2017-09-26</created><authors><author><keyname>Yi</keyname><forenames>Zhehan</forenames></author><author><keyname>Dong</keyname><forenames>Wanxin</forenames></author><author><keyname>Etemadi</keyname><forenames>Amir H.</forenames></author></authors><title>A Centralized Power Control and Management Method for Grid-Connected
  Photovoltaic (PV)-Battery Systems</title><categories>math.OC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed Generation (DG) is an effective way of integrating renewable
energy sources to conventional power grid, which improves the reliability and
efficiency of power systems. Photovoltaic (PV) systems are ideal DGs thanks to
their attractive benefits, such as availability of solar energy and low
installation costs. Battery groups are used in PV systems to balance the power
flows and eliminate power fluctuations due to change of operating condition,
e.g., irradiance and temperature variation. In an attempt to effectively manage
the power flows, this paper presents a novel power control and management
system for grid-connected PV-Battery systems. The proposed system realizes the
maximum power point tracking (MPPT) of the PV panels, stabilization of the DC
bus voltage for load plug-and-play access, balance among the power flows, and
quick response of both active and reactive power demands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.09364</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.09364</id><created>2017-09-27</created><authors><author><keyname>Huang</keyname><forenames>Chengwei</forenames></author></authors><title>Research on several key technologies in practical speech emotion
  recognition</title><categories>cs.SD cs.AI eess.AS</categories><comments>in Chinese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this dissertation the practical speech emotion recognition technology is
studied, including several cognitive related emotion types, namely fidgetiness,
confidence and tiredness. The high quality of naturalistic emotional speech
data is the basis of this research. The following techniques are used for
inducing practical emotional speech: cognitive task, computer game, noise
stimulation, sleep deprivation and movie clips.
  A practical speech emotion recognition system is studied based on Gaussian
mixture model. A two-class classifier set is adopted for performance
improvement under the small sample case. Considering the context information in
continuous emotional speech, a Gaussian mixture model embedded with Markov
networks is proposed.
  A further study is carried out for system robustness analysis. First, noise
reduction algorithm based on auditory masking properties is fist introduced to
the practical speech emotion recognition. Second, to deal with the complicated
unknown emotion types under real situation, an emotion recognition method with
rejection ability is proposed, which enhanced the system compatibility against
unknown emotion samples. Third, coping with the difficulties brought by a large
number of unknown speakers, an emotional feature normalization method based on
speaker-sensitive feature clustering is proposed. Fourth, by adding the
electrocardiogram channel, a bi-modal emotion recognition system based on
speech signals and electrocardiogram signals is first introduced.
  The speech emotion recognition methods studied in this dissertation may be
extended into the cross-language speech emotion recognition and the whispered
speech emotion recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.09634</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.09634</id><created>2017-09-22</created><authors><author><keyname>Qazanfari</keyname><forenames>Kazem</forenames></author><author><keyname>Shiri</keyname><forenames>Saeed</forenames></author></authors><title>Real time text localization for Indoor Mobile Robot Navigation</title><categories>cs.RO eess.IV</categories><comments>5 pages</comments><journal-ref>IR Open Robocup Symposium, 7-9 April 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scene text is an important feature to be extracted, especially in
vision-based mobile robot navigation as many potential landmarks such as
nameplates and information signs contain text. In this paper, a novel two-step
text localization method for Indoor Mobile Robot Navigation is introduced. This
method is based on morphological operators and machine learning techniques and
can be used in real time environments. The proposed method has two steps. At
First, a new set of morphological operators is applied with a particular
sequence to extract high contrast areas that have high probability of text
existence. Using of morphological operators has many advantages such as: high
computation speed, being invariant to several geometrical transformations like
translation, rotations, and scaling, and being able to extract all areas
containing text. After extracting text candidate regions, a set of nine
features are extracted for accurate detection and deletion of the regions that
don't have text. These features are descriptors for texture properties and are
computed in real time. Then, we use a SVM classifier to detect the existence of
text in the region. Performance of the proposed algorithm is compared against a
number of widely used text localization algorithms and the results show that
this method can quickly and effectively localize and extract text regions from
real scenes and can be used in mobile robot navigation under an indoor
environment to detect text based landmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.09708</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.09708</id><created>2017-09-13</created><authors><author><keyname>Ferretti</keyname><forenames>Stefano</forenames></author></authors><title>On the Complex Network Structure of Musical Pieces: Analysis of Some Use
  Cases from Different Music Genres</title><categories>cs.SD cs.MM eess.AS</categories><comments>accepted to Multimedia Tools and Applications, Springer</comments><doi>10.1007/s11042-017-5175-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the modeling of musical melodies as networks. Notes of
a melody can be treated as nodes of a network. Connections are created whenever
notes are played in sequence. We analyze some main tracks coming from different
music genres, with melodies played using different musical instruments. We find
out that the considered networks are, in general, scale free networks and
exhibit the small world property. We measure the main metrics and assess
whether these networks can be considered as formed by sub-communities. Outcomes
confirm that peculiar features of the tracks can be extracted from this
analysis methodology. This approach can have an impact in several multimedia
applications such as music didactics, multimedia entertainment, and digital
music generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.09868</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.09868</id><created>2017-09-28</created><authors><author><keyname>Swart</keyname><forenames>Albert</forenames></author><author><keyname>Brummer</keyname><forenames>Niko</forenames></author></authors><title>A Generative Model for Score Normalization in Speaker Recognition</title><categories>stat.ML cs.LG cs.SD eess.AS</categories><journal-ref>InterSpeech 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a theoretical framework for thinking about score normalization,
which confirms that normalization is not needed under (admittedly fragile)
ideal conditions. If, however, these conditions are not met, e.g. under
data-set shift between training and runtime, our theory reveals dependencies
between scores that could be exploited by strategies such as score
normalization. Indeed, it has been demonstrated over and over experimentally,
that various ad-hoc score normalization recipes do work. We present a first
attempt at using probability theory to design a generative score-space
normalization model which gives similar improvements to ZT-norm on the
text-dependent RSR 2015 database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.09888</identifier>
 <datestamp>2018-08-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.09888</id><created>2017-09-28</created><authors><author><keyname>Meyer</keyname><forenames>Matthias</forenames></author><author><keyname>Cavigelli</keyname><forenames>Lukas</forenames></author><author><keyname>Thiele</keyname><forenames>Lothar</forenames></author></authors><title>Efficient Convolutional Neural Network For Audio Event Detection</title><categories>cs.CV eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless distributed systems as used in sensor networks, Internet-of-Things
and cyber-physical systems, impose high requirements on resource efficiency.
Advanced preprocessing and classification of data at the network edge can help
to decrease the communication demand and to reduce the amount of data to be
processed centrally. In the area of distributed acoustic sensing, the
combination of algorithms with a high classification rate and
resource-constraint embedded systems is essential. Unfortunately, algorithms
for acoustic event detection have a high memory and computational demand and
are not suited for execution at the network edge. This paper addresses these
aspects by applying structural optimizations to a convolutional neural network
for audio event detection to reduce the memory requirement by a factor of more
than 500 and the computational effort by a factor of 2.1 while performing 9.2%
better.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.09939</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.09939</id><created>2017-07-25</created><authors><author><keyname>Righini</keyname><forenames>Davide</forenames></author><author><keyname>Passerini</keyname><forenames>Federico</forenames></author><author><keyname>Tonello</keyname><forenames>Andrea M.</forenames></author></authors><title>Modeling Transmission and Radiation Effects when Exploiting Power Line
  Networks for Communication</title><categories>physics.soc-ph cs.NI eess.SP</categories><comments>A version of this article has been accepted for publication on IEEE
  Transactions on Electromagnetic Compatibility, Special Issue on &quot;Advances in
  Modeling, Measurement and Design of Discontinuities and Their EMC and SI/PI
  Effects on Wired Communication Links&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power distribution grids are exploited by Power Line Communication (PLC)
technology to convey high frequency data signals. The natural conformation of
such power line networks causes a relevant part of the high frequency signals
traveling through them to be radiated instead of being conducted. This causes
not only electromagnetic interference (EMI) with devices positioned next to
power line cables, but also a consistent deterioration of the signal integrity.
Since existing PLC channel models do not take into account losses due to
radiation phenomena, this paper responds to the need of developing accurate
network simulators. A thorough analysis is herein presented about the conducted
and radiated effects on the signal integrity, digging into differential mode to
common mode signal conversion due to network imbalances. The outcome of this
work allows each network element to be described by a mixed-mode transmission
matrix. Furthermore, the classical per-unit-length equivalent circuit of
transmission lines is extended to incorporate radiation resistances. The
results of this paper lay the foundations for future developments of
comprehensive power line network models that incorporate conducted and radiated
phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.09940</identifier>
 <datestamp>2018-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.09940</id><created>2017-09-26</created><updated>2018-02-07</updated><authors><author><keyname>Kemp</keyname><forenames>Zachary David Cleary</forenames></author></authors><title>Propagation based phase retrieval of simulated intensity measurements
  using artificial neural networks</title><categories>eess.IV physics.optics</categories><comments>Altered based on referee feedback. This is the accepted version</comments><doi>10.1088/2040-8986/aab02f</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining the phase of a wave from intensity measurements has many
applications in fields such as electron microscopy, visible light optics, and
medical imaging. Propagation based phase retrieval, where the phase is obtained
from defocused images, has shown significant promise. There are, however,
limitations in the accuracy of the retrieved phase arising from such methods.
Sources of error include shot noise, image misalignment, and diffraction
artifacts. We explore the use of artificial neural networks (ANNs) to improve
the accuracy of propagation based phase retrieval algorithms applied to
simulated intensity measurements. We employ a phase retrieval algorithm based
on the transport-of-intensity equation to obtain the phase from simulated
micrographs of procedurally generated specimens. We then train an ANN with
pairs of retrieved and exact phases, and use the trained ANN to process a test
set of retrieved phase maps. The total error in the phase is significantly
reduced using this method. We also discuss a variety of potential extensions to
this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.10246</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.10246</id><created>2017-09-29</created><updated>2018-01-15</updated><authors><author><keyname>Jha</keyname><forenames>Pranav Kumar</forenames></author><author><keyname>Shree</keyname><forenames>S Sushmitha</forenames></author><author><keyname>Kumar</keyname><forenames>D. Sriram</forenames></author></authors><title>An Opportunistic-Non Orthogonal Multiple Access based Cooperative
  Relaying system over Rician Fading Channels</title><categories>eess.SP cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1709.08224</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-orthogonal Multiple Access (NOMA) has become a salient technology for
improving the spectral efficiency of the next generation 5G wireless
communication networks. In this paper, the achievable average rate of an
Opportunistic Non-Orthogonal Multiple Access (O-NOMA) based Cooperative
Relaying System (CRS) is studied under Rician fading channels with Channel
State Information (CSI) available at the source terminal. Based on CSI, for
opportunistic transmission, the source immediately chooses either the direct
transmission or the cooperative NOMA transmission using the relay, which can
provide better achievable average rate performance than the existing
Conventional-NOMA (C-NOMA) based CRS with no CSI at the source node.
Furthermore, a mathematical expression is also derived for the achievable
average rate and the results are compared with C-NOMA based CRS with no CSI at
the transmitter end, over a range of increasing power allocation coefficients,
transmit Signal-to-Noise Ratios (SNRs) and average channel powers. Numerical
results show that the CRS using O-NOMA with CSI achieves better spectral
efficiency in terms of the achievable average rate than the Conventional-NOMA
based CRS without CSI. To check the consistency of the derived analytical
results, Monte Carlo simulations are performed which verify that the results
are consistent and matched well with the simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.10393</identifier>
 <datestamp>2018-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.10393</id><created>2017-07-26</created><updated>2017-12-21</updated><authors><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author><author><keyname>Fehenberger</keyname><forenames>Tobias</forenames></author><author><keyname>Chen</keyname><forenames>Bin</forenames></author><author><keyname>Willems</keyname><forenames>Frans M. J.</forenames></author></authors><title>Achievable Information Rates for Fiber Optics: Applications and
  Computations</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/JLT.2017.2786351</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, achievable information rates (AIR) for fiber optical
communications are discussed. It is shown that AIRs such as the mutual
information and generalized mutual information are good design metrics for
coded optical systems. The theoretical predictions of AIRs are compared to the
performance of modern codes including low-parity density check (LDPC) and polar
codes. Two different computation methods for these AIRs are also discussed:
Monte-Carlo integration and Gauss-Hermite quadrature. Closed-form ready-to-use
approximations for such computations are provided for arbitrary constellations
and the multidimensional AWGN channel. The computation of AIRs in optical
experiments and simulations is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.10396</identifier>
 <datestamp>2017-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.10396</id><created>2017-08-23</created><authors><author><keyname>Nguyen-Ly</keyname><forenames>Thien Truong</forenames></author><author><keyname>Savin</keyname><forenames>Valentin</forenames></author><author><keyname>Le</keyname><forenames>Khoa</forenames></author><author><keyname>Declercq</keyname><forenames>David</forenames></author><author><keyname>Ghaffari</keyname><forenames>Fakhreddine</forenames></author><author><keyname>Boncalo</keyname><forenames>Oana</forenames></author></authors><title>Analysis and Design of Cost-Effective, High-Throughput LDPC Decoders</title><categories>eess.SP cs.AR</categories><comments>Submitted to IEEE Transactions on VLSI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new approach to cost-effective, high-throughput
hardware designs for Low Density Parity Check (LDPC) decoders. The proposed
approach, called Non-Surjective Finite Alphabet Iterative Decoders (NS-FAIDs),
exploits the robustness of message-passing LDPC decoders to inaccuracies in the
calculation of exchanged messages, and it is shown to provide a unified
framework for several designs previously proposed in the literature. NS-FAIDs
are optimized by density evolution for regular and irregular LDPC codes, and
are shown to provide different trade-offs between hardware complexity and
decoding performance. Two hardware architectures targeting high-throughput
applications are also proposed, integrating both Min-Sum (MS) and NS-FAID
decoding kernels. ASIC post synthesis implementation results on 65nm CMOS
technology show that NS-FAIDs yield significant improvements in the throughput
to area ratio, by up to 58.75% with respect to the MS decoder, with even better
or only slightly degraded error correction performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.10401</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.10401</id><created>2017-09-27</created><updated>2019-01-19</updated><authors><author><keyname>Wimalajeewa</keyname><forenames>Thakshila</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author></authors><title>Application of Compressive Sensing Techniques in Distributed Sensor
  Networks: A Survey</title><categories>eess.SP stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this survey paper, our goal is to discuss recent advances of compressive
sensing (CS) based solutions in wireless sensor networks (WSNs) including the
main ongoing/recent research efforts, challenges and research trends in this
area. In WSNs, CS based techniques are well motivated by not only the sparsity
prior observed in different forms but also by the requirement of efficient
in-network processing in terms of transmit power and communication bandwidth
even with nonsparse signals. In order to apply CS in a variety of WSN
applications efficiently, there are several factors to be considered beyond the
standard CS framework. We start the discussion with a brief introduction to the
theory of CS and then describe the motivational factors behind the potential
use of CS in WSN applications. Then, we identify three main areas along which
the standard CS framework is extended so that CS can be efficiently applied to
solve a variety of problems specific to WSNs. In particular, we emphasize on
the significance of extending the CS framework to (i). take communication
constraints into account while designing projection matrices and reconstruction
algorithms for signal reconstruction in centralized as well in decentralized
settings, (ii) solve a variety of inference problems such as detection,
classification and parameter estimation, with compressed data without signal
reconstruction and (iii) take practical communication aspects such as
measurement quantization, physical layer secrecy constraints, and imperfect
channel conditions into account. Finally, open research issues and challenges
are discussed in order to provide perspectives for future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1709.10411</identifier>
 <datestamp>2017-10-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1709.10411</id><created>2017-08-20</created><authors><author><keyname>Zou</keyname><forenames>Jun</forenames></author></authors><title>Frequency offset tolerant synchronization signal design in NB-IoT</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timing detection is the first step and very important in wireless
communication systems. Timing detection performance is usually affected by the
frequency offset. Therefore, it is a challenge to design the synchronization
signal in massive narrowband Internet of Things (NB-IoT) scenarios where the
frequency offset is usually large due to the low cost requirement. In this
paper, we firstly proposed a new general synchronization signal structure with
a couple of sequences which are conjugated to remove the potential timing error
arose from large frequency offset. Then, we analyze the suitable sequence for
our proposed synchronization signal structure and discuss a special ZC sequence
as an example. Finally, the simulation results demonstrate our proposed
synchronization signal can work well when the frequency offset is large. It
means that our proposed synchronization signal design is very suitable for the
massive NB-IoT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00045</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00045</id><created>2017-09-15</created><updated>2018-02-10</updated><authors><author><keyname>Xue</keyname><forenames>Xiaoxiao</forenames></author><author><keyname>Xuan</keyname><forenames>Yi</forenames></author><author><keyname>Bao</keyname><forenames>Chengying</forenames></author><author><keyname>Li</keyname><forenames>Shangyuan</forenames></author><author><keyname>Zheng</keyname><forenames>Xiaoping</forenames></author><author><keyname>Zhou</keyname><forenames>Bingkun</forenames></author><author><keyname>Qi</keyname><forenames>Minghao</forenames></author><author><keyname>Weiner</keyname><forenames>Andrew M.</forenames></author></authors><title>Microcomb-based true-time-delay network for microwave beamforming with
  arbitrary beam pattern control</title><categories>physics.app-ph eess.SP</categories><comments>10 pages, 9 figures, Journal of Lightwave Technology, 2018</comments><doi>10.1109/JLT.2018.2803743</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microwave phased array antennas (PAAs) are very attractive to defense
applications and high-speed wireless communications for their abilities of fast
beam scanning and complex beam pattern control. However, traditional PAAs based
on phase shifters suffer from the beam-squint problem and have limited
bandwidths. True-time-delay (TTD) beamforming based on low-loss photonic delay
lines can solve this problem. But it is still quite challenging to build
large-scale photonic TTD beamformers due to their high hardware complexity. In
this paper, we demonstrate a photonic TTD beamforming network based on a
miniature microresonator frequency comb (microcomb) source and dispersive time
delay. A method incorporating optical phase modulation and programmable
spectral shaping is proposed for positive and negative apodization weighting to
achieve arbitrary microwave beam pattern control. The experimentally
demonstrated TTD beamforming network can support a PAA with 21 elements. The
microwave frequency range is $\mathbf{8\sim20\ {GHz}}$, and the beam scanning
range is $\mathbf{\pm 60.2^\circ}$. Detailed measurements of the microwave
amplitudes and phases are performed. The beamforming performances of Gaussian,
rectangular beams and beam notch steering are evaluated through simulations by
assuming a uniform radiating antenna array. The scheme can potentially support
larger PAAs with hundreds of elements by increasing the number of comb lines
with broadband microcomb generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00082</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00082</id><created>2017-09-29</created><authors><author><keyname>Rhodes</keyname><forenames>Anthony D.</forenames></author></authors><title>Real-Time Wind Noise Detection and Suppression with Neural-Based Signal
  Reconstruction for Mult-Channel, Low-Power Devices</title><categories>cs.SD eess.AS</categories><comments>5 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active wind noise detection and suppression techniques are a new and
essential paradigm for enhancing ASR-based functionality with smart glasses, in
addition to other wearable and smart devices in the broader IoT (Internet of
things). In this paper, we develop two separate algorithms for wind noise
detection and suppression, respectively, operational in a challenging,
low-energy regime. Together, these algorithms comprise a robust wind noise
suppression system. In the first case, we advance a real-time wind detection
algorithm (RTWD) that uses two distinct sets of low-dimensional signal features
to discriminate the presence of wind noise with high accuracy. For wind noise
suppression, we employ an additional algorithm - attentive neural wind
suppression (ANWS) - that utilizes a neural network to reconstruct the wearer
speech signal from wind-corrupted audio in the spectral regions that are most
adversely affected by wind noise. Finally, we test our algorithms through
real-time experiments using low-power, multi-microphone devices with a wind
simulator under challenging detection criteria and a variety of wind
intensities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00113</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00113</id><created>2017-09-29</created><authors><author><keyname>Bulut</keyname><forenames>Ahmet E.</forenames></author><author><keyname>Zhang</keyname><forenames>Qian</forenames></author><author><keyname>Zhang</keyname><forenames>Chunlei</forenames></author><author><keyname>Bahmaninezhad</keyname><forenames>Fahimeh</forenames></author><author><keyname>Hansen</keyname><forenames>John H. L.</forenames></author></authors><title>UTD-CRSS Submission for MGB-3 Arabic Dialect Identification: Front-end
  and Back-end Advancements on Broadcast Speech</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study presents systems submitted by the University of Texas at Dallas,
Center for Robust Speech Systems (UTD-CRSS) to the MGB-3 Arabic Dialect
Identification (ADI) subtask. This task is defined to discriminate between five
dialects of Arabic, including Egyptian, Gulf, Levantine, North African, and
Modern Standard Arabic. We develop multiple single systems with different
front-end representations and back-end classifiers. At the front-end level,
feature extraction methods such as Mel-frequency cepstral coefficients (MFCCs)
and two types of bottleneck features (BNF) are studied for an i-Vector
framework. As for the back-end level, Gaussian back-end (GB), and Generative
Adversarial Networks (GANs) classifiers are applied alternately. The best
submission (contrastive) is achieved for the ADI subtask with an accuracy of
76.94% by augmenting the randomly chosen part of the development dataset.
Further, with a post evaluation correction in the submitted system, final
accuracy is increased to 79.76%, which represents the best performance achieved
so far for the challenge on the test dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00116</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00116</id><created>2017-09-29</created><authors><author><keyname>Bulut</keyname><forenames>Ahmet E.</forenames></author><author><keyname>Demir</keyname><forenames>Hakan</forenames></author><author><keyname>Isik</keyname><forenames>Yusuf Ziya</forenames></author><author><keyname>Erdogan</keyname><forenames>Hakan</forenames></author></authors><title>PLDA-Based Diarization of Telephone Conversations</title><categories>eess.AS cs.SD</categories><journal-ref>ICASSP, IEEE International Conference on Acoustics, Speech and
  Signal Processing - Proceedings 1 (2015) 4809-4813</journal-ref><doi>10.1109/ICASSP.2015.7178884</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the application of the probabilistic linear
discriminant analysis (PLDA) to speaker diarization of telephone conversations.
We introduce using a variational Bayes (VB) approach for inference under a PLDA
model for modeling segmental i-vectors in speaker diarization. Deterministic
annealing (DA) algorithm is imposed in order to avoid local optimal solutions
in VB iterations. We compare our proposed system with a well-known system that
applies k-means clustering on principal component analysis (PCA) coefficients
of segmental i-vectors. We used summed channel telephone data from the National
Institute of Standards and Technology (NIST) 2008 Speaker Recognition
Evaluation (SRE) as the test set in order to evaluate the performance of the
proposed system. We achieve about 20% relative improvement in Diarization Error
Rate (DER) compared to the baseline system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00157</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00157</id><created>2017-09-30</created><updated>2018-01-29</updated><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Yan</keyname><forenames>Yan</forenames></author><author><keyname>Mehrmohammadi</keyname><forenames>Mohammad</forenames></author><author><keyname>Makkiabadi</keyname><forenames>Bahador</forenames></author></authors><title>Enhanced Linear-array Photoacoustic Beamforming using Modified Coherence
  Factor</title><categories>physics.med-ph cs.IT eess.SP math.IT</categories><comments>This manuscript is accepted in Journal of Biomedical Optics (JBO).
  The second edition contains Ex Vivo experimental results</comments><journal-ref>J. of Biomedical Optics, 23(2), 026005 (2018)</journal-ref><doi>10.1117/1.JBO.23.2.026005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photoacoustic imaging (PAI) is a promising medical imaging modality providing
the spatial resolution of ultrasound (US) imaging and the contrast of pure
optical imaging. For linear-array PAI, a beamformer has to be used as the
reconstruction algorithm. Delay-and-sum (DAS) is the most prevalent beamforming
algorithm in PAI. However, using DAS beamformer leads to low resolution images
along with significant effects of the off-axis signals. Coherence factor (CF)
is a weighting method in which each pixel of the reconstructed image is
weighted, based on the spatial spectrum of the aperture, to improve the
contrast. In this paper, it has been shown that the numerator of the formula of
CF contains a DAS algebra, and it was proposed to use the
delay-multiply-and-sum (DMAS) beamformer instead of the available DAS on the
numerator. The proposed weighting technique, modified CF (MCF), has been
evaluated numerically and experimentally compared to CF, and it was shown that
MCF leads to lower sidelobes and better detectable targets. The quantitative
results of the experiment (using wire targets) show that MCF leads to for about
45% and 40% improvement, in comparison with CF, in the terms of signal-to-noise
ratio and full-width-half-maximum, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00335</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00335</id><created>2017-10-01</created><authors><author><keyname>Azizzadeh</keyname><forenames>Azad</forenames></author><author><keyname>Mohammadkhani</keyname><forenames>Reza</forenames></author><author><keyname>Makki</keyname><forenames>Seyed Vahab Al-Din</forenames></author></authors><title>BER Performance of Uplink Massive MIMO With Low-Resolution ADCs</title><categories>eess.SP</categories><comments>4 pages, 9 figures; accepted for publication in iccke 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multiple-input multiple-output (MIMO) is a promising technology for
next generation wireless communication systems (5G). In this technology, Base
Station (BS) is equipped with a large number of antennas. Employing high
resolution analog-to-digital converters (ADCs) for all antennas may cause high
costs and high power consumption for the BS. By performing numerical results,
we evaluate the use of low-resolution ADCs for uplink massive MIMO by analyzing
Bit Error Rate (BER) performance for different detection techniques (MMSE, ZF)
and different modulations (QPSK, 16-QAM) to find an optimal quantization
resolution. Our results reveal that the BER performance of uplink massive MIMO
systems with a few-bit resolution ADCs is comparable to the case of having full
precision ADCs. We found that the optimum choice of quantization level (number
of bits in ADCs) depends on the modulation technique and the number of antennas
at the BS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00342</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00342</id><created>2017-10-01</created><authors><author><keyname>Mohammadi</keyname><forenames>Hamed</forenames></author><author><keyname>Mohammadkhani</keyname><forenames>Reza</forenames></author></authors><title>Beam Switching Techniques for Millimeter Wave Vehicle to Infrastructure
  Communications</title><categories>eess.SP</categories><comments>6 pages, 7 figures, accepted to be published in iccke 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beam alignment for millimeter wave (mm Wave) vehicular communications is
challenging due to the high mobility of vehicles. Recent studies have proposed
some beam switching techniques at Road Side Unit (RSU) for vehicle to
infrastructure (V2I) communications, employing initial position and speed
information of vehicles, that are sent through Dedicated Short Range
Communications (DSRC) to the RSU. However, inaccuracies of the provided
information lead to beam misalignment. Some beam design parameters are
suggested in the literature to combat this effect. But how these parameters
should be tuned? Here, we evaluate the effect of all these parameters, and
propose a beam design efficiency metric to perform beam alignment in the
presence of the estimation errors, and to improve the performance by choosing
the right design parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00343</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00343</id><created>2017-10-01</created><authors><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author><author><keyname>Wang</keyname><forenames>Wenwu</forenames></author><author><keyname>Plumbley</keyname><forenames>Mark D.</forenames></author></authors><title>Large-scale weakly supervised audio classification using gated
  convolutional neural network</title><categories>cs.SD eess.AS</categories><comments>submitted to ICASSP2018, summary on the 1st place system in DCASE2017
  task4 challenge</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a gated convolutional neural network and a temporal
attention-based localization method for audio classification, which won the 1st
place in the large-scale weakly supervised sound event detection task of
Detection and Classification of Acoustic Scenes and Events (DCASE) 2017
challenge. The audio clips in this task, which are extracted from YouTube
videos, are manually labeled with one or a few audio tags but without
timestamps of the audio events, which is called as weakly labeled data. Two
sub-tasks are defined in this challenge including audio tagging and sound event
detection using this weakly labeled data. A convolutional recurrent neural
network (CRNN) with learnable gated linear units (GLUs) non-linearity applied
on the log Mel spectrogram is proposed. In addition, a temporal attention
method is proposed along the frames to predicate the locations of each audio
event in a chunk from the weakly labeled data. We ranked the 1st and the 2nd as
a team in these two sub-tasks of DCASE 2017 challenge with F value 55.6\% and
Equal error 0.73, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00484</identifier>
 <datestamp>2018-04-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00484</id><created>2017-10-02</created><updated>2018-03-31</updated><authors><author><keyname>Jha</keyname><forenames>Pranav Kumar</forenames></author><author><keyname>Kachare</keyname><forenames>Nitin</forenames></author><author><keyname>Kalyani</keyname><forenames>K</forenames></author><author><keyname>Kumar</keyname><forenames>D. Sriram</forenames></author></authors><title>Performance analysis of FSO using relays and spatial diversity under
  log-normal fading channel</title><categories>eess.SP cs.IT math.IT</categories><comments>4 pages, 4 figures, 4th International Conference on Electrical Energy
  Systems (ICEES), Feb. 7-9, 2018, SSNCE, Chennai, TN, INDIA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance analysis of free space optical communication (FSO) system
using relays and spatial diversity at the source is studied in this paper. The
effect of atmospheric turbulence and attenuation, caused by different weather
conditions and geometric losses, has also been considered for analysis. The
exact closed-form expressions are presented for bit error rate (BER) of M-ary
quadrature amplitude modulation (M-QAM) technique for multi-hop multiple-input
single-output (MISO) FSO system under log-normal fading channel. Furthermore,
the link performance of multi-hop MISO and multi-hop single-input and
single-output (SISO) FSO systems are compared to the different systems using
on-off keying (OOK), repetition codes (RCs) and M-ary pulse amplitude
modulation (M-PAM) techniques. A significant performance enhancement in terms
of BER analysis and SNR gains is shown for multi-hop MISO and multi-hop SISO
FSO systems with M-QAM over other existing systems with different modulation
schemes. Moreover, Monte-Carlo simulations are used to validate the accuracy
and consistency of the derived analytical results. Numerical results show that
M-QAM modulated multi-hop MISO and multi-hop SISO FSO system with relays and
spatial diversity outperforms other systems while having the same spectral
efficiency of each system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00532</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00532</id><created>2017-10-02</created><authors><author><keyname>Senel</keyname><forenames>L Kerem</forenames></author><author><keyname>Kilic</keyname><forenames>Toygan</forenames></author><author><keyname>Gungor</keyname><forenames>Alper</forenames></author><author><keyname>Kopanoglu</keyname><forenames>Emre</forenames></author><author><keyname>Guven</keyname><forenames>H Emre</forenames></author><author><keyname>Saritas</keyname><forenames>Emine U</forenames></author><author><keyname>Koc</keyname><forenames>Aykut</forenames></author><author><keyname>Cukur</keyname><forenames>Tolga</forenames></author></authors><title>Statistically Segregated k-Space Sampling for Accelerating
  Multiple-Acquisition MRI</title><categories>eess.IV</categories><comments>10 pages, 9 figures. Submitted to IEEE Transactions on Medical
  Imaging</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central limitation of multiple-acquisition magnetic resonance imaging (MRI)
is the degradation in scan efficiency as the number of distinct datasets grows.
Sparse recovery techniques can alleviate this limitation via randomly
undersampled acquisitions. A frequent sampling strategy is to prescribe for
each acquisition a different random pattern drawn from a common sampling
density. However, naive random patterns often contain gaps or clusters across
the acquisition dimension that in turn can degrade reconstruction quality or
reduce scan efficiency. To address this problem, a statistically-segregated
sampling method is proposed for multiple-acquisition MRI. This method generates
multiple patterns sequentially, while adaptively modifying the sampling density
to minimize k-space overlap across patterns. As a result, it improves
incoherence across acquisitions while still maintaining similar sampling
density across the radial dimension of k-space. Comprehensive simulations and
in vivo results are presented for phase-cycled balanced steady-state free
precession and multi-echo T$_2$-weighted imaging. Segregated sampling achieves
significantly improved quality in both Fourier and compressed-sensing
reconstructions of multiple-acquisition datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00623</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00623</id><created>2017-08-22</created><updated>2017-11-08</updated><authors><author><keyname>Servin</keyname><forenames>Manuel</forenames></author><author><keyname>Padilla</keyname><forenames>Moises</forenames></author></authors><title>Shannon information storage in noisy phase-modulated fringes and
  fringe-data compression by phase-shifting algorithms</title><categories>eess.SP cs.IT math.IT physics.ins-det</categories><comments>13 pages, 13 figures and 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optical phase-modulated fringe-patterns are usually digitized with XxY pixels
and 8 bits/pixel (or higher) gray-levels. The digitized 8 bits/pixel are
raw-data bits, not Shannon information bits. Here we show that noisy
fringe-patterns store much less Shannon information than the capacity of the
digitizing camera. This means that high signal-to-noise ratio (S/N) cameras may
waste to noise most bits/pixel. For example one would not use smartphone
cameras for high quality phase-metrology, because of their lower (S/N) images.
However smartphones digitize high-resolution (12 megapixel) images, and as we
show here, the information storage of an image depends on its bandwidth and its
(S/N). The standard formalism for measuring information are the Shannon-entropy
H, and the Shannon capacity theorem (SCT). According to SCT, low (S/N) images
may be compensated with a larger fringe-bandwidth to obtain high-information
phase measurements. So broad bandwidth fringes may give high quality phase, in
spite of digitizing low (S/N) fringe images. Most real-life images are
redundant, they have smooth zones where the pixel-value do not change much, and
data compression algorithms are paramount for image transmission/storage.
Shannon's capacity theorem is used to gauge competing image compression
algorithms. Here we show that phase-modulated phase-shifted fringes are highly
correlated, and as a consequence, phase-shifting algorithms (PSAs) may be used
as fringe-data compressors. Therefore a PSA may compress a large number of
phase-shifted fringes into a single complex-valued image. This is important in
spaceborne optical/RADAR phase-telemetry where downlink is severely limited by
huge distance and low-power downlink. That is, instead of transmitting M
phase-shifted fringes, one only transmit the phase-demodulated signal as
compressed sensing data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00625</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00625</id><created>2017-08-22</created><authors><author><keyname>Golani</keyname><forenames>Ori</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author><author><keyname>Shtaif</keyname><forenames>Mark</forenames></author></authors><title>Equalization Methods for NLIN Mitigation</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the potential of adaptive equalization techniques to mitigate
inter-channel nonlinear interference noise (NLIN). We derive a lower bound on
the mutual information of a system using adaptive equalization, showing that
the channel estimation error determines the equalizer's performance. We develop
an adaptive equalization scheme which uses the statistics of the NLIN to obtain
optimal detection, based on Kalman filtering and maximum likelihood sequence
estimation (MLSE). This scheme outperforms commonly used equalizers and
significantly increases performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00683</identifier>
 <datestamp>2017-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00683</id><created>2017-09-27</created><authors><author><keyname>Yan</keyname><forenames>Xiaoyong</forenames></author><author><keyname>Minnhagen</keyname><forenames>Petter</forenames></author></authors><title>The Dependence of Frequency Distributions on Multiple Meanings of Words,
  Codes and Signs</title><categories>cs.CL eess.AS physics.soc-ph</categories><comments>10 pages, 12 figures</comments><journal-ref>Physica A 490, 554-564 (2018)</journal-ref><doi>10.1016/j.physa.2017.08.133</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dependence of the frequency distributions due to multiple meanings of
words in a text is investigated by deleting letters. By coding the words with
fewer letters the number of meanings per coded word increases. This increase is
measured and used as an input in a predictive theory. For a text written in
English, the word-frequency distribution is broad and fat-tailed, whereas if
the words are only represented by their first letter the distribution becomes
exponential. Both distribution are well predicted by the theory, as is the
whole sequence obtained by consecutively representing the words by the first
L=6,5,4,3,2,1 letters. Comparisons of texts written by Chinese characters and
the same texts written by letter-codes are made and the similarity of the
corresponding frequency-distributions are interpreted as a consequence of the
multiple meanings of Chinese characters. This further implies that the
difference of the shape for word-frequencies for an English text written by
letters and a Chinese text written by Chinese characters is due to the coding
and not to the language per se.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00770</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00770</id><created>2017-09-21</created><authors><author><keyname>Rabiei</keyname><forenames>Payam</forenames></author></authors><title>A simple and fast frequency domain analysis method for calculating the
  frequency response and linearity of electro-optic microring modulators</title><categories>eess.SP physics.app-ph</categories><comments>11 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fast and simple frequency domain method is introduced for the analysis of
microring modulator response using the Jacobi Anger expansion method. Resonance
frequency modulated microring (FMMR) modulators and coupling modulated
microring modulators (CMMR) are analyzed using this method. The linearity of
these modulators is analyzed. The third order intercept point (IP3) is
calculated for CMMR devices and compared to Mach Zehnder interferometer (MZI)
modulator devices. It is shown that CMMR devices can achieve a 12dB higher IP3
compared to MZI devices. CMMR devices have high second order nonlinearity,
while MZI devices second order nonlinearity is zero. A novel geometry based on
dual CMMR modulators is introduced to improve the second order nonlinearity of
CMMR modulators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00772</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00772</id><created>2017-09-25</created><authors><author><keyname>Janatian</keyname><forenames>Nafiseh</forenames></author><author><keyname>Stupia</keyname><forenames>Ivan</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>Optimal Resource Allocation in Ultra-low Power Fog-computing SWIPT-based
  Networks</title><categories>eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a fog computing system consisting of a
multi-antenna access point (AP), an ultra-low power (ULP) single antenna device
and a fog server. The ULP device is assumed to be capable of both energy
harvesting (EH) and information decoding (ID) using a time-switching
simultaneous wireless information and power transfer (SWIPT) scheme. The ULP
device deploys the harvested energy for ID and either local computing or
offloading the computations to the fog server depending on which strategy is
most energy efficient. In this scenario, we optimize the time slots devoted to
EH, ID and local computation as well as the time slot and power required for
the offloading to minimize the energy cost of the ULP device. Numerical results
are provided to study the effectiveness of the optimized fog computing system
and the relevant challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00773</identifier>
 <datestamp>2019-10-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00773</id><created>2017-09-28</created><updated>2017-10-14</updated><authors><author><keyname>Wang</keyname><forenames>Feiyu</forenames></author><author><keyname>Fang</keyname><forenames>Jun</forenames></author><author><keyname>Duan</keyname><forenames>Huiping</forenames></author><author><keyname>Li</keyname><forenames>Hongbin</forenames></author></authors><title>Phased Array-Based Sub-Nyquist Sampling for Joint Wideband Spectrum
  Sensing and Direction-of-Arrival Estimation</title><categories>eess.SP</categories><doi>10.1109/TSP.2018.2875420</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the problem of joint wideband spectrum sensing and
direction-of-arrival (DoA) estimation in a sub-Nyquist sampling framework.
Specifically, considering a scenario where a few uncorrelated narrowband
signals spread over a wide (say, several GHz) frequency band, our objective is
to estimate the carrier frequencies and the DoAs associated with the narrowband
sources, as well as reconstruct the power spectra of these narrowband signals.
To overcome the sampling rate bottleneck for wideband spectrum sensing, we
propose a new phased-array based sub-Nyquist sampling architecture with
variable time delays, where a uniform linear array (ULA) is employed and the
received signal at each antenna is delayed by a variable amount of time and
then sampled by a synchronized low-rate analog-digital converter (ADC). Based
on the collected sub-Nyquist samples, we calculate a set of cross-correlation
matrices with different time lags, and develop a CANDECOMP/PARAFAC (CP)
decomposition-based method for joint DoA, carrier frequency and power spectrum
recovery. Perfect recovery conditions for the associated parameters and the
power spectrum are analyzed. Our analysis reveals that our proposed method does
not require to place any sparse constraint on the wideband spectrum, only needs
the sampling rate to be greater than the bandwidth of the narrowband source
signal with the largest bandwidth among all sources. Simulation results show
that our proposed method can achieve an estimation accuracy close to the
associated Cram\'{e}r-Rao bounds (CRBs) using only a small number of data
samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00776</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00776</id><created>2017-08-25</created><authors><author><keyname>Le</keyname><forenames>Son T.</forenames></author><author><keyname>Aref</keyname><forenames>Vahid</forenames></author><author><keyname>Buelow</keyname><forenames>Henning</forenames></author></authors><title>125 Gbps Pre-Compensated Nonlinear Frequency-Division Multiplexed
  Transmission</title><categories>eess.SP</categories><comments>This paper will be presented at ECOC 2017, Gothenburg, Sweden</comments><doi>10.1109/JLT.2017.2787185</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Record-high data rate of 125 Gb/s and SE over 2 bits/s/Hz in burst-mode
single-polarization NFDM transmissions were achieved over 976 km of SSMF with
EDFA-only amplification by transmitting and processing 222 32 QAM-modulated
nonlinear subcarriers simultaneously
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00777</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00777</id><created>2017-08-30</created><authors><author><keyname>Selim</keyname><forenames>Bassant</forenames></author><author><keyname>Muhaidat</keyname><forenames>Sami</forenames></author><author><keyname>Sofotasios</keyname><forenames>Paschalis C.</forenames></author><author><keyname>Sharif</keyname><forenames>Bayan S.</forenames></author><author><keyname>Stouraitis</keyname><forenames>Thanos</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author><author><keyname>Al-Dhahir</keyname><forenames>Naofal</forenames></author></authors><title>Performance Analysis of Coherent and Noncoherent Modulation under I/Q
  Imbalance</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In-phase/quadrature-phase Imbalance (IQI) is considered a major
performance-limiting impairment in direct-conversion transceivers. Its effects
become even more pronounced at higher carrier frequencies such as the
millimeter-wave frequency bands being considered for 5G systems. In this paper,
we quantify the effects of IQI on the performance of different modulation
schemes under multipath fading channels. This is realized by developing a
general framework for the symbol error rate (SER) analysis of coherent phase
shift keying, noncoherent differential phase shift keying and noncoherent
frequency shift keying under IQI effects. In this context, the moment
generating function of the signal-to-interference-plus-noise-ratio is first
derived for both single-carrier and multi-carrier systems suffering from
transmitter (TX) IQI only, receiver (RX) IQI only and joint TX/RX IQI.
Capitalizing on this, we derive analytic expressions for the SER of the
different modulation schemes. These expressions are corroborated by comparisons
with corresponding results from computer simulations and they provide insights
into the dependence of IQI on the system parameters. We demonstrate that the
effects of IQI differ considerably depending on the considered system as some
cases of single-carrier transmission appear robust to IQI, whereas
multi-carrier systems experiencing IQI at the RX require compensation in order
to achieve a reliable communication link.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00778</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00778</id><created>2017-09-13</created><authors><author><keyname>Du</keyname><forenames>Jian</forenames></author><author><keyname>Liu</keyname><forenames>Xue</forenames></author><author><keyname>Rao</keyname><forenames>Lei</forenames></author></authors><title>Proactive Doppler Shift Compensation in Vehicular Cyber-Physical Systems</title><categories>eess.SP cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In vehicular cyber-physical systems (CPS), safety information, including
vehicular speed and location information, is shared among vehicles via wireless
waves at specific frequency. This helps control vehicle to alleviate traffic
congestion and road accidents. However, Doppler shift existing between vehicles
with high relative speed causes an apparent frequency shift for the received
wireless wave, which consequently decreases the reliability of the recovered
safety information and jeopardizes the safety of vehicular CPS. Passive
confrontation of Doppler shift at the receiver side is not applicable due to
multiple Doppler shifts at each receiver. In this paper, we provide a proactive
Doppler shift compensation algorithm based on the probabilistic graphical
model. Each vehicle pre-compensates its carrier frequency individually so that
there is no frequency shift from the desired carrier frequency between each
pair of transceiver. The pre-compensated offset for each vehicle is computed in
a distributed fashion in order to be adaptive to the distributed and dynamic
topology of vehicular CPS. Besides, the updating procedure is designed in a
broadcasting fashion to reduce communication burden. It is rigorously proved
that the proposed algorithm is convergence guaranteed even for systems with
packet drops and random communication delays. Simulations based on real map and
transportation data verify the accuracy and convergence property of the
proposed algorithm. It is shown that this method achieves almost the optimal
frequency compensation accuracy with an error approaching the Cram\'{e}r-Rao
lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00779</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00779</id><created>2017-09-04</created><updated>2017-12-06</updated><authors><author><keyname>Xu</keyname><forenames>Juncai</forenames></author><author><keyname>Shen</keyname><forenames>Zhenzhong</forenames></author><author><keyname>Ren</keyname><forenames>Qingwen</forenames></author><author><keyname>Xie</keyname><forenames>Xin</forenames></author><author><keyname>Yang</keyname><forenames>Zhengyu</forenames></author></authors><title>GPR signal de-noise method based on variational mode decomposition</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compared with traditional empirical mode decomposition (EMD) methods,
variational mode decomposition (VMD) has strong theoretical foundation and high
operational efficiency. The VMD method is introduced to ground penetrating
radar (GPR) signal processing. The characteristics of GPR signals validate the
method of signal de-noising based on the VMD principle. The validity and
accuracy of the method are further verified via Ricker wavelet and forward
model GPR de-noising experiments. The method of VMD is evaluated in comparison
with traditional wavelet transform (WT) and EEMD (ensemble EMD) methods. The
method is subsequently used to analyze a GPR signal from a practical
engineering case. The results show that the method can effectively remove the
noise in the GPR data, and can obtain high signal-to-noise ratios (SNR) even
under strong background noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00780</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00780</id><created>2017-09-11</created><authors><author><keyname>Liao</keyname><forenames>Qi</forenames></author></authors><title>Dynamic Uplink/Downlink Resource Management in Flexible Duplex-Enabled
  Wireless Networks</title><categories>eess.SP cs.CE</categories><comments>7 pages, 7 figures, ICC 2017 Workshop</comments><doi>10.1109/ICCW.2017.7962728</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flexible duplex is proposed to adapt to the channel and traffic asymmetry for
future wireless networks. In this paper, we propose two novel algorithms within
the flexible duplex framework for joint uplink and downlink resource allocation
in multi-cell scenario, named SAFP and RMDI, based on the awareness of
interference coupling among wireless links. Numerical results show significant
performance gain over the baseline system with fixed uplink/downlink resource
configuration, and over the dynamic TDD scheme that independently adapts the
configuration to time-varying traffic volume in each cell. The proposed
algorithms achieve two-fold increase when compared with the baseline scheme,
measured by the worst-case quality of service satisfaction level, under a low
level of traffic asymmetry. The gain is more significant when the traffic is
highly asymmetric, as it achieves three-fold increase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00781</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00781</id><created>2017-09-11</created><updated>2018-01-18</updated><authors><author><keyname>Liao</keyname><forenames>Qi</forenames></author><author><keyname>Cavalcante</keyname><forenames>R. L. G.</forenames></author></authors><title>Improving Resource Efficiency with Partial Resource Muting for Future
  Wireless Networks</title><categories>eess.SP</categories><comments>8 pages, 9 figures, to appear in WiMob 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose novel resource allocation algorithms that have the objective of
finding a good tradeoff between resource reuse and interference avoidance in
wireless networks. To this end, we first study properties of functions that
relate the resource budget available to network elements to the optimal utility
and to the optimal resource efficiency obtained by solving max-min utility
optimization problems. From the asymptotic behavior of these functions, we
obtain a transition point that indicates whether a network is operating in an
efficient noise-limited regime or in an inefficient interference-limited regime
for a given resource budget. For networks operating in the inefficient regime,
we propose a novel partial resource muting scheme to improve the efficiency of
the resource utilization. The framework is very general. It can be applied not
only to the downlink of 4G networks, but also to 5G networks equipped with
flexible duplex mechanisms. Numerical results show significant performance
gains of the proposed scheme compared to the solution to the max-min utility
optimization problem with full frequency reuse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00782</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00782</id><created>2017-09-13</created><authors><author><keyname>Semrau</keyname><forenames>Daniel</forenames></author><author><keyname>Lavery</keyname><forenames>Domanic</forenames></author><author><keyname>Galdino</keyname><forenames>Lidia</forenames></author><author><keyname>Killey</keyname><forenames>Robert I.</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>The Impact of Transceiver Noise on Digital Nonlinearity Compensation</title><categories>eess.SP</categories><comments>8 pages, 4 figures, 1 tables</comments><doi>10.1109/JLT.2017.2777452</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The efficiency of digital nonlinearity compensation (NLC) is analyzed in the
presence of noise arising from amplified spontaneous emission noise (ASE) as
well as from a non-ideal transceiver subsystem. Its impact on signal-to-noise
ratio (SNR) and reach increase is studied with particular emphasis on split
NLC, where the digital back-propagation algorithm is divided between
transmitter and receiver. An analytical model is presented to compute the SNR's
for non-ideal transmission systems with arbitrary split NLC configurations.
When signal-signal nonlinearities are compensated, the performance limitation
arises from residual signal-noise interactions. These interactions consist of
nonlinear beating between the signal and co-propagating ASE and transceiver
noise. While transceiver noise-signal beating is usually dominant for short
transmission distances, ASE noise-signal beating is dominant for larger
transmission distances. It is shown that both regimes behave differently with
respect to the optimal NLC split ratio and their respective reach gains.
Additionally, simple formulas for the prediction of the optimal NLC split ratio
and the reach increase in those two regimes are reported. It is found that
split NLC offers negligible gain with respect to conventional digital
back-propagation (DBP) for distances less than 1000 km using standard
single-mode fibers and a transceiver (back-to-back) SNR of 26 dB, when
transmitter and receiver inject the same amount of noise. However, when
transmitter and receiver inject an unequal amount of noise, reach gains of 56%
on top of DBP are achievable by properly tailoring the split NLC algorithm. The
theoretical findings are confirmed by numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00783</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00783</id><created>2017-08-05</created><authors><author><keyname>Abrar</keyname><forenames>Shafayat</forenames></author></authors><title>Steepest Descent Multimodulus Algorithm for Blind Signal Retrieval in
  QAM Systems</title><categories>eess.SP</categories><comments>This work was initially submitted in IET Electronics Letters on Feb.
  06, 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present steepest descent (SD) implementation of multimodulus algorithm
(MMA2-2) for blind signal retrieval in digital communication systems. In
comparison to stochastic approximate (gradient descent) realization, the
proposed SD implementation of MMA2-2 equalizer mitigates inter-symbol
interference with relatively smooth convergence and superior steady-state
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00784</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00784</id><created>2017-08-10</created><authors><author><keyname>Liu</keyname><forenames>Juan</forenames></author><author><keyname>Bai</keyname><forenames>Bo</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled B.</forenames></author></authors><title>Cache Placement in Fog-RANs: From Centralized to Distributed Algorithms</title><categories>eess.SP cs.IT math.IT</categories><comments>13 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To deal with the rapid growth of high-speed and/or ultra-low latency data
traffic for massive mobile users, fog radio access networks (Fog-RANs) have
emerged as a promising architecture for next-generation wireless networks. In
Fog-RANs, the edge nodes and user terminals possess storage, computation and
communication functionalities to various degrees, which provides high
flexibility for network operation, i.e., from fully centralized to fully
distributed operation. In this paper, we study the cache placement problem in
Fog-RANs, by taking into account flexible physical-layer transmission schemes
and diverse content preferences of different users. We develop both centralized
and distributed transmission aware cache placement strategies to minimize
users' average download delay subject to the storage capacity constraints. In
the centralized mode, the cache placement problem is transformed into a matroid
constrained submodular maximization problem, and an approximation algorithm is
proposed to find a solution within a constant factor to the optimum. In the
distributed mode, a belief propagation based distributed algorithm is proposed
to provide a suboptimal solution, with iterative updates at each BS based on
locally collected information. Simulation results show that by exploiting
caching and cooperation gains, the proposed transmission aware caching
algorithms can greatly reduce the users' average download delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00790</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00790</id><created>2017-09-20</created><authors><author><keyname>Pan</keyname><forenames>Cunhua</forenames></author><author><keyname>Elkashlan</keyname><forenames>Maged</forenames></author><author><keyname>Wang</keyname><forenames>Jiangzhou</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>User-centric C-RAN Architecture for Ultra-dense 5G Networks: Challenges
  and Methodologies</title><categories>eess.SP</categories><comments>Accepted in IEEE Communications Magazine, special issue on
  heterogeneous ultra dense networks</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Ultra-dense networks (UDN) constitute one of the most promising techniques of
supporting the 5G mobile system. By deploying more small cells in a fixed area,
the average distance between users and access points can be significantly
reduced, hence a dense spatial frequency reuse can be exploited. However,
severe interference is the major obstacle in UDN. Most of the contributions
deal with the interference by relying on cooperative game theory. This paper
advocates the application of dense user-centric C-RAN philosophy to UDN, thanks
to the recent development of cloud computing techniques. Under dense C-RAN,
centralized signal processing can be invoked for supporting CoMP transmission.
We summarize the main challenges in dense user-centric C-RANs. One of the most
challenging issues is the requirement of the global CSI for the sake of
cooperative transmission. We investigate this requirement by only relying on
partial CSI, namely, on inter-cluster large-scale CSI. Furthermore, the
estimation of the intra-cluster CSI is considered, including the pilot
allocation and robust transmission. Finally, we highlight several promising
research directions to make the dense user-centric C-RAN become a reality, with
special emphasis on the application of the `big data' techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00864</identifier>
 <datestamp>2017-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00864</id><created>2017-09-21</created><authors><author><keyname>Messaoud</keyname><forenames>Lysa Ait</forenames></author><author><keyname>Merazka</keyname><forenames>Fatiha</forenames></author><author><keyname>Massicotte</keyname><forenames>Daniel</forenames></author></authors><title>A Novel Mataheuristic based Interference Alignment for K-User
  Interference Channel : A Comparative Study</title><categories>eess.SP</categories><comments>4 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new Interference Alignment (IA) scheme for K-User
Multiple Input Multiple Output (MIMO) Interference Channel (IC) based on two
metaheuristics, namely Particle Swarm Optimization (PSO) and Artificial Bee
Colony (ABC) Algorithm. Tackling interference is an essential issue in wireless
communications to which Interference Alignment (IA) provides a promising
solution. However, IA still lacks of explicit and straightforward design
procedures. In fact, most of IA procedures aim to minimize a certain
Interference Leakage (IL) which measures the effect of the interference on the
network, this results in complex optimization tasks involving a large amount of
decision variables, together with a problem of convergence of the IA solutions.
In this paper the IA optimization is performed using PSO, ABC and their
cooperative counterparts, more suitable for large scale optimization. A
comparison between the four algorithms is also carried out. The cooperative
proposed approaches seem to be promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00865</identifier>
 <datestamp>2018-06-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00865</id><created>2017-09-21</created><authors><author><keyname>Messaoud</keyname><forenames>Lysa AIT</forenames></author><author><keyname>Merazka</keyname><forenames>Fatiha</forenames></author></authors><title>PSO and CPSO Based Interference Alignment for K-User MIMO Interference
  Channel</title><categories>eess.SP</categories><comments>9 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1710.00864</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates how to use a metaheuristic based technique, namely
Particle Swarm Optimization (PSO), in carrying out of Interference Alignment
(IA) for $K$-User MIMO Interference Channel (IC). Despite its increasing
popularity, mainly in wireless communications, IA lacks of explicit and
straightforward design procedures. Indeed, IA design results in complex
optimization tasks involving a large amount of decision variables, together
with a problem of convergence of the IA solutions. In this paper the IA
optimization is performed using PSO and Cooperative PSO (CPSO) more suitable
for large scale optimization, a comparison between the two versions is also
carried out. This approach seems to be promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.00965</identifier>
 <datestamp>2018-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.00965</id><created>2017-10-02</created><authors><author><keyname>Wang</keyname><forenames>Shulei</forenames></author><author><keyname>Arena</keyname><forenames>Ellen T.</forenames></author><author><keyname>Eliceiri</keyname><forenames>Kevin W.</forenames></author><author><keyname>Yuan</keyname><forenames>Ming</forenames></author></authors><title>Automated and Robust Quantification of Colocalization in Dual-Color
  Fluorescence Microscopy: A Nonparametric Statistical Approach</title><categories>stat.ME eess.IV q-bio.QM</categories><doi>10.1109/TIP.2017.2763821</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colocalization is a powerful tool to study the interactions between
fluorescently labeled molecules in biological fluorescence microscopy. However,
existing techniques for colocalization analysis have not undergone continued
development especially in regards to robust statistical support. In this paper,
we examine two of the most popular quantification techniques for colocalization
and argue that they could be improved upon using ideas from nonparametric
statistics and scan statistics. In particular, we propose a new colocalization
metric that is robust, easily implementable, and optimal in a rigorous
statistical testing framework. Application to several benchmark datasets, as
well as biological examples, further demonstrates the usefulness of the
proposed technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01073</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01073</id><created>2017-10-03</created><authors><author><keyname>Bear</keyname><forenames>Helen L.</forenames></author><author><keyname>Harvey</keyname><forenames>Richard</forenames></author><author><keyname>Theobald</keyname><forenames>Barry-John</forenames></author><author><keyname>Lan</keyname><forenames>Yuxuan</forenames></author></authors><title>Resolution limits on visual speech recognition</title><categories>cs.CV eess.IV</categories><journal-ref>Helen L. Bear, Richard Harvey, Barry-John Theobald, Yuxuan Lan.
  Resolution limits on visual speech recognition. International Conference on
  Image Processing (ICIP). 2014. p1371-1375</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual-only speech recognition is dependent upon a number of factors that can
be difficult to control, such as: lighting; identity; motion; emotion and
expression. But some factors, such as video resolution are controllable, so it
is surprising that there is not yet a systematic study of the effect of
resolution on lip-reading. Here we use a new data set, the Rosetta Raven data,
to train and test recognizers so we can measure the affect of video resolution
on recognition accuracy. We conclude that, contrary to common practice,
resolution need not be that great for automatic lip-reading. However it is
highly unlikely that automatic lip-reading can work reliably when the distance
between the bottom of the lower lip and the top of the upper lip is less than
four pixels at rest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01084</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01084</id><created>2017-10-03</created><authors><author><keyname>Bear</keyname><forenames>Helen L.</forenames></author><author><keyname>Owen</keyname><forenames>Gari</forenames></author><author><keyname>Harvey</keyname><forenames>Richard</forenames></author><author><keyname>Theobald</keyname><forenames>Barry-John</forenames></author></authors><title>Some observations on computer lip-reading: moving from the dream to the
  reality</title><categories>cs.CV eess.IV</categories><journal-ref>Helen L. Bear, Gari Owen, Richard Harvey, and Barry-John Theobald.
  Some observations on computer lip-reading: moving from the dream to the
  reality. International Society for Optics and Photonics- Security and
  defence. 2014. p92530G--92530G</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the quest for greater computer lip-reading performance there are a number
of tacit assumptions which are either present in the datasets (high resolution
for example) or in the methods (recognition of spoken visual units called
visemes for example). Here we review these and other assumptions and show the
surprising result that computer lip-reading is not heavily constrained by video
resolution, pose, lighting and other practical factors. However, the working
assumption that visemes, which are the visual equivalent of phonemes, are the
best unit for recognition does need further examination. We conclude that
visemes, which were defined over a century ago, are unlikely to be optimal for
a modern computer lip-reading system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01093</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01093</id><created>2017-10-03</created><authors><author><keyname>Bear</keyname><forenames>Helen L.</forenames></author><author><keyname>Harvey</keyname><forenames>Richard W.</forenames></author><author><keyname>Theobald</keyname><forenames>Barry-John</forenames></author><author><keyname>Lan</keyname><forenames>Yuxuan</forenames></author></authors><title>Which phoneme-to-viseme maps best improve visual-only computer
  lip-reading?</title><categories>cs.CV cs.CL eess.AS</categories><journal-ref>Helen L. Bear, Richard W. Harvey, Barry-John Theobald, and Yuxuan
  Lan. Which phoneme-to-viseme maps best improve visual-only computer
  lip-reading? Advances in Visual Computing 2014. p230-239</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A critical assumption of all current visual speech recognition systems is
that there are visual speech units called visemes which can be mapped to units
of acoustic speech, the phonemes. Despite there being a number of published
maps it is infrequent to see the effectiveness of these tested, particularly on
visual-only lip-reading (many works use audio-visual speech). Here we examine
120 mappings and consider if any are stable across talkers. We show a method
for devising maps based on phoneme confusions from an automated lip-reading
system, and we present new mappings that show improvements for individual
talkers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01107</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01107</id><created>2017-10-03</created><updated>2018-04-10</updated><authors><author><keyname>Argyris</keyname><forenames>Apostolos</forenames></author><author><keyname>Bueno</keyname><forenames>Juli&#xe1;n</forenames></author><author><keyname>Fischer</keyname><forenames>Ingo</forenames></author></authors><title>Photonic machine learning implementation for signal recovery in optical
  communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning techniques have proven very efficient in assorted
classification tasks. Nevertheless, processing time-dependent high-speed
signals can turn into an extremely challenging task, especially when these
signals have been nonlinearly distorted. Recently, analogue hardware concepts
using nonlinear transient responses have been gaining significant interest for
fast information processing. Here, we introduce a simplified photonic reservoir
computing scheme for data classification of severely distorted optical
communication signals after extended fibre transmission. To this end, we
convert the direct bit detection process into a pattern recognition problem.
Using an experimental implementation of our photonic reservoir computer, we
demonstrate an improvement in bit-error-rate by two orders of magnitude,
compared to directly classifying the transmitted signal. This improvement
corresponds to an extension of the communication range by over 75%. While we do
not yet reach full real-time post-processing at telecom rates, we discuss how
future designs might close the gap.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01122</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01122</id><created>2017-10-03</created><authors><author><keyname>Bear</keyname><forenames>Helen L.</forenames></author><author><keyname>Cox</keyname><forenames>Stephen J.</forenames></author><author><keyname>Harvey</keyname><forenames>Richard W.</forenames></author></authors><title>Speaker-independent machine lip-reading with speaker-dependent viseme
  classifiers</title><categories>cs.CV eess.AS</categories><journal-ref>Helen L. Bear, Stephen J. Cox, Richard W. Harvey,
  Speaker-independent machine lip-reading with speaker-dependent viseme
  classifiers. Audio-Visual Speech Processing (AVSP) 2015, p190-195</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In machine lip-reading, which is identification of speech from visual-only
information, there is evidence to show that visual speech is highly dependent
upon the speaker [1]. Here, we use a phoneme-clustering method to form new
phoneme-to-viseme maps for both individual and multiple speakers. We use these
maps to examine how similarly speakers talk visually. We conclude that broadly
speaking, speakers have the same repertoire of mouth gestures, where they
differ is in the use of the gestures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01135</identifier>
 <datestamp>2018-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01135</id><created>2017-09-29</created><updated>2018-01-29</updated><authors><author><keyname>Huang</keyname><forenames>Weiyu</forenames></author><author><keyname>Bolton</keyname><forenames>Thomas A. W.</forenames></author><author><keyname>Medaglia</keyname><forenames>John D.</forenames></author><author><keyname>Bassett</keyname><forenames>Danielle S.</forenames></author><author><keyname>Ribeiro</keyname><forenames>Alejandro</forenames></author><author><keyname>Van De Ville</keyname><forenames>Dimitri</forenames></author></authors><title>A Graph Signal Processing View on Functional Brain Imaging</title><categories>eess.IV cs.SI</categories><comments>Weiyu Huang and Thomas A. W. Bolton contributed equally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern neuroimaging techniques provide us with unique views on brain
structure and function; i.e., how the brain is wired, and where and when
activity takes place. Data acquired using these techniques can be analyzed in
terms of its network structure to reveal organizing principles at the systems
level. Graph representations are versatile models where nodes are associated to
brain regions and edges to structural or functional connections. Structural
graphs model neural pathways in white matter that are the anatomical backbone
between regions. Functional graphs are built based on functional connectivity,
which is a pairwise measure of statistical interdependency between activity
traces of regions. Therefore, most research to date has focused on analyzing
these graphs reflecting structure or function.
  Graph signal processing (GSP) is an emerging area of research where signals
recorded at the nodes of the graph are studied atop the underlying graph
structure. An increasing number of fundamental operations have been generalized
to the graph setting, allowing to analyze the signals from a new viewpoint.
Here, we review GSP for brain imaging data and discuss their potential to
integrate brain structure, contained in the graph itself, with brain function,
residing in the graph signals. We review how brain activity can be meaningfully
filtered based on concepts of spectral modes derived from brain structure. We
also derive other operations such as surrogate data generation or
decompositions informed by cognitive systems. In sum, GSP offers a novel
framework for the analysis of brain imaging data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01142</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01142</id><created>2017-10-03</created><authors><author><keyname>Bear</keyname><forenames>Helen L.</forenames></author><author><keyname>Harvey</keyname><forenames>Richard W.</forenames></author><author><keyname>Lan</keyname><forenames>Yuxuan</forenames></author></authors><title>Finding phonemes: improving machine lip-reading</title><categories>cs.CV cs.CL eess.AS</categories><journal-ref>Helen L. Bear, Richard W. Harvey, Yuxuan Lan. Finding phonemes:
  improving machine lip-reading. Audio-Visual Speech Processing (AVSP), 2015
  p115-120</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In machine lip-reading there is continued debate and research around the
correct classes to be used for recognition. In this paper we use a structured
approach for devising speaker-dependent viseme classes, which enables the
creation of a set of phoneme-to-viseme maps where each has a different quantity
of visemes ranging from two to 45. Viseme classes are based upon the mapping of
articulated phonemes, which have been confused during phoneme recognition, into
viseme groups. Using these maps, with the LiLIR dataset, we show the effect of
changing the viseme map size in speaker-dependent machine lip-reading, measured
by word recognition correctness and so demonstrate that word recognition with
phoneme classifiers is not just possible, but often better than word
recognition with viseme classifiers. Furthermore, there are intermediate units
between visemes and phonemes which are better still.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01169</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01169</id><created>2017-10-03</created><authors><author><keyname>Bear</keyname><forenames>Helen L.</forenames></author><author><keyname>Harvey</keyname><forenames>Richard</forenames></author></authors><title>Decoding visemes: improving machine lipreading</title><categories>cs.CV eess.AS</categories><journal-ref>Helen L Bear and Richard Harvey. Decoding visemes: improving
  machine lipreading. IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP), 2016. p2009-2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To undertake machine lip-reading, we try to recognise speech from a visual
signal. Current work often uses viseme classification supported by language
models with varying degrees of success. A few recent works suggest phoneme
classification, in the right circumstances, can outperform viseme
classification. In this work we present a novel two-pass method of training
phoneme classifiers which uses previously trained visemes in the first pass.
With our new training algorithm, we show classification performance which
significantly improves on previous lip-reading results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01288</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01288</id><created>2017-10-03</created><authors><author><keyname>Bear</keyname><forenames>Helen L</forenames></author></authors><title>Decoding visemes: improving machine lipreading</title><categories>cs.CV eess.AS</categories><comments>PhD thesis. Computer Vision and Pattern Recognition (CVPR), Women in
  Computer Vision (WiCV) Workshop 2017</comments><journal-ref>Helen L Bear. Decoding visemes: improving lipreading (PhD thesis).
  University of East Anglia. July 2016</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine lipreading (MLR) is speech recognition from visual cues and a niche
research problem in speech processing &amp; computer vision. Current challenges
fall into two groups: the content of the video, such as rate of speech or; the
parameters of the video recording e.g, video resolution. We show that HD video
is not needed to successfully lipread with a computer. The term &quot;viseme&quot; is
used in machine lipreading to represent a visual cue or gesture which
corresponds to a subgroup of phonemes where the phonemes are visually
indistinguishable. A phoneme is the smallest sound one can utter, because there
are more phonemes per viseme, maps between units show a many-to-one
relationship. Many maps have been presented, we compare these and our results
show Lee's is best. We propose a new method of speaker-dependent
phoneme-to-viseme maps and compare these to Lee's. Our results show the
sensitivity of phoneme clustering and we use our new knowledge to augment a
conventional MLR system. It has been observed in MLR, that classifiers need
training on test subjects to achieve accuracy. Thus machine lipreading is
highly speaker-dependent. Conversely speaker independence is robust
classification of non-training speakers. We investigate the dependence of
phoneme-to-viseme maps between speakers and show there is not a high
variability of visemes, but there is high variability in trajectory between
visemes of individual speakers with the same ground truth. This implies a
dependency upon the number of visemes within each set for each individual. We
show that prior phoneme-to-viseme maps rarely have enough visemes and the
optimal size, which varies by speaker, ranges from 11-35. Finally we decode
from visemes back to phonemes and into words. Our novel approach uses the
optimum range visemes within hierarchical training of phoneme classifiers and
demonstrates a significant increase in classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01292</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01292</id><created>2017-10-03</created><authors><author><keyname>Bear</keyname><forenames>Helen L</forenames></author><author><keyname>Taylor</keyname><forenames>Sarah</forenames></author></authors><title>Visual speech recognition: aligning terminologies for better
  understanding</title><categories>cs.CV eess.AS</categories><journal-ref>Helen L Bear and Sarah Taylor. Visual speech recognition: aligning
  terminologies for better understanding. British Machine Vision Conference
  (BMVC) Deep learning for machine lip reading workshop. 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are at an exciting time for machine lipreading. Traditional research
stemmed from the adaptation of audio recognition systems. But now, the computer
vision community is also participating. This joining of two previously
disparate areas with different perspectives on computer lipreading is creating
opportunities for collaborations, but in doing so the literature is
experiencing challenges in knowledge sharing due to multiple uses of terms and
phrases and the range of methods for scoring results.
  In particular we highlight three areas with the intention to improve
communication between those researching lipreading; the effects of
interchanging between speech reading and lipreading; speaker dependence across
train, validation, and test splits; and the use of accuracy, correctness,
errors, and varying units (phonemes, visemes, words, and sentences) to measure
system performance. We make recommendations as to how we can be more
consistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01297</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01297</id><created>2017-10-03</created><authors><author><keyname>Bear</keyname><forenames>Helen L</forenames></author></authors><title>Visual gesture variability between talkers in continuous visual speech</title><categories>cs.CV eess.AS</categories><journal-ref>Helen L Bear. Visual gesture variability between talkers in
  continuous visual speech. British Machine Vision Conference (BMVC) Deep
  learning for machine lip reading workshop. 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent adoption of deep learning methods to the field of machine lipreading
research gives us two options to pursue to improve system performance. Either,
we develop end-to-end systems holistically or, we experiment to further our
understanding of the visual speech signal. The latter option is more difficult
but this knowledge would enable researchers to both improve systems and apply
the new knowledge to other domains such as speech therapy. One challenge in
lipreading systems is the correct labeling of the classifiers. These labels map
an estimated function between visemes on the lips and the phonemes uttered.
Here we ask if such maps are speaker-dependent? Prior work investigated
isolated word recognition from speaker-dependent (SD) visemes, we extend this
to continuous speech. Benchmarked against SD results, and the isolated words
performance, we test with RMAV dataset speakers and observe that with
continuous speech, the trajectory between visemes has a greater negative effect
on the speaker differentiation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01351</identifier>
 <datestamp>2018-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01351</id><created>2017-10-03</created><authors><author><keyname>Bear</keyname><forenames>Helen L</forenames></author></authors><title>Understanding the visual speech signal</title><categories>cs.CV eess.AS</categories><comments>Computer Vision and Pattern Recognition (CVPR) Women in Computer
  Vision (WiCV) workshop. 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For machines to lipread, or understand speech from lip movement, they decode
lip-motions (known as visemes) into the spoken sounds. We investigate the
visual speech channel to further our understanding of visemes. This has
applications beyond machine lipreading; speech therapists, animators, and
psychologists can benefit from this work. We explain the influence of speaker
individuality, and demonstrate how one can use visemes to boost lipreading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01446</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01446</id><created>2017-10-03</created><authors><author><keyname>Takamoto</keyname><forenames>Ayaka</forenames></author><author><keyname>Umemura</keyname><forenames>Mayu</forenames></author><author><keyname>Yoshida</keyname><forenames>Mitsuo</forenames></author><author><keyname>Umemura</keyname><forenames>Kyoji</forenames></author></authors><title>Improving Compression Based Dissimilarity Measure for Music Score
  Analysis</title><categories>cs.SD cs.OH eess.AS</categories><comments>The 2016 International Conference On Advanced Informatics: Concepts,
  Theory And Application (ICAICTA2016)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a way to improve the compression based
dissimilarity measure, CDM. We propose to use a modified value of the file
size, where the original CDM uses an unmodified file size. Our application is a
music score analysis. We have chosen piano pieces from five different
composers. We have selected 75 famous pieces (15 pieces for each composer). We
computed the distances among all pieces by using the modified CDM. We use the
K-nearest neighbor method when we estimate the composer of each piece of music.
The modified CDM shows improved accuracy. The difference is statistically
significant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01589</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01589</id><created>2017-10-04</created><authors><author><keyname>Mitsui</keyname><forenames>Yoshiki</forenames></author><author><keyname>Kitamura</keyname><forenames>Daichi</forenames></author><author><keyname>Takamune</keyname><forenames>Norihiro</forenames></author><author><keyname>Saruwatari</keyname><forenames>Hiroshi</forenames></author><author><keyname>Takahashi</keyname><forenames>Yu</forenames></author><author><keyname>Kondo</keyname><forenames>Kazunobu</forenames></author></authors><title>Independent Low-Rank Matrix Analysis Based on Parametric
  Majorization-Equalization Algorithm</title><categories>cs.SD eess.AS</categories><comments>Preprint Manuscript of 2017 IEEE International Workshop on
  Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP 2017)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new optimization method for independent low-rank
matrix analysis (ILRMA) based on a parametric majorization-equalization
algorithm. ILRMA is an efficient blind source separation technique that
simultaneously estimates a spatial demixing matrix (spatial model) and the
power spectrograms of each estimated source (source model). In ILRMA, since
both models are alternately optimized by iterative update rules, the difference
in the convergence speeds between these models often results in a poor local
solution. To solve this problem, we introduce a new parameter that controls the
convergence speed of the source model and find the best balance between the
optimizations in the spatial and source models for ILRMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01604</identifier>
 <datestamp>2018-10-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01604</id><created>2017-10-04</created><updated>2018-10-17</updated><authors><author><keyname>Pla</keyname><forenames>Pol del Aguila</forenames></author><author><keyname>Jald&#xe9;n</keyname><forenames>Joakim</forenames></author></authors><title>Cell Detection by Functional Inverse Diffusion and Non-negative Group
  Sparsity$-$Part I: Modeling and Inverse Problems</title><categories>eess.SP</categories><comments>published, 15 pages</comments><msc-class>92C55, 94A08, 35R30, 35Q93, 46N10</msc-class><journal-ref>IEEE Transactions on Signal Processing, vol. 66, no. 20, pp.
  5407-5421, 2018</journal-ref><doi>10.1109/TSP.2018.2868258</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this two-part paper, we present a novel framework and methodology to
analyze data from certain image-based biochemical assays, e.g., ELISPOT and
Fluorospot assays. In this first part, we start by presenting a physical
partial differential equations (PDE) model up to image acquisition for these
biochemical assays. Then, we use the PDEs' Green function to derive a novel
parametrization of the acquired images. This parametrization allows us to
propose a functional optimization problem to address inverse diffusion. In
particular, we propose a non-negative group-sparsity regularized optimization
problem with the goal of localizing and characterizing the biological cells
involved in the said assays. We continue by proposing a suitable discretization
scheme that enables both the generation of synthetic data and implementable
algorithms to address inverse diffusion. We end Part I by providing a
preliminary comparison between the results of our methodology and an expert
human labeler on real data. Part II is devoted to providing an accelerated
proximal gradient algorithm to solve the proposed problem and to the empirical
validation of our methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01605</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01605</id><created>2017-10-04</created><authors><author><keyname>de Carvalho</keyname><forenames>Elisabeth</forenames></author><author><keyname>Slock</keyname><forenames>Dirk</forenames></author></authors><title>Cram\'er-Rao Bounds for Blind Multichannel Estimation</title><categories>cs.IT eess.SP math.IT</categories><comments>22 pages, 3 figures</comments><msc-class>62F10</msc-class><acm-class>G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In some estimation problems, not all the parameters can be identified, which
results in singularity of the Fisher Information Matrix (FIM). The Cram\'er-Rao
Bound (CRB), which is the inverse of the FIM, is then not defined. To
regularize the estimation problem, one can impose constraints on the parameters
and derive the corresponding CRBs. The correspondence between local
identifiability and FIM regularity is studied here. Furthermore the number of
FIM singularities is shown to be equal to the number of independent constraints
necessary to have a well-defined constrained CRB and local identifiability. In
general, many sets of constraints can render the parameters identifiable,
giving different values for the CRB, that are not always relevant. When the
constraints can be chosen, we propose a constrained CRB, the pseudo-inverse of
the FIM, which gives, for a minimum number of constraints, the lowest bound on
the mean squared estimation error. These results are applied to two approaches
to blind FIR multichannel estimation which allow identification of the channel
up to a scale or phase factor. These two approaches correspond to deterministic
and Gaussian models for the unknown channel inputs. The singularities of the
FIMs and local identifiability are studied and the corresponding constrained
CRBs are derived and interpreted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01622</identifier>
 <datestamp>2018-10-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01622</id><created>2017-10-04</created><updated>2018-10-17</updated><authors><author><keyname>Pla</keyname><forenames>Pol del Aguila</forenames></author><author><keyname>Jald&#xe9;n</keyname><forenames>Joakim</forenames></author></authors><title>Cell Detection by Functional Inverse Diffusion and Non-negative Group
  Sparsity$-$Part II: Proximal Optimization and Performance Evaluation</title><categories>eess.SP</categories><comments>published, 16 pages</comments><msc-class>92C55, 94A08, 35R30, 47-04</msc-class><journal-ref>IEEE Transactions on Signal Processing, vol. 66, no. 20, pp.
  5422-5437, 2018</journal-ref><doi>10.1109/TSP.2018.2868256</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this two-part paper, we present a novel framework and methodology to
analyze data from certain image-based biochemical assays, e.g., ELISPOT and
Fluorospot assays. In this second part, we focus on our algorithmic
contributions. We provide an algorithm for functional inverse diffusion that
solves the variational problem we posed in Part I. As part of the derivation of
this algorithm, we present the proximal operator for the non-negative
group-sparsity regularizer, which is a novel result that is of interest in
itself, also in comparison to previous results on the proximal operator of a
sum of functions. We then present a discretized approximated implementation of
our algorithm and evaluate it both in terms of operational cell-detection
metrics and in terms of distributional optimal-transport metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01703</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01703</id><created>2017-10-04</created><authors><author><keyname>Sengupta</keyname><forenames>Nandini</forenames></author><author><keyname>Sahidullah</keyname><forenames>Md</forenames></author><author><keyname>Saha</keyname><forenames>Goutam</forenames></author></authors><title>Lung sound classification using local binary pattern</title><categories>eess.SP</categories><comments>Working paper (21 pages, 12 figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lung sounds contain vital information about pulmonary pathology. In this
paper, we use short-term spectral characteristics of lung sounds to recognize
associated diseases. Motivated by the success of auditory perception based
techniques in speech signal classification, we represent time-frequency
information of lung sounds using mel-scale warped spectral coefficients, called
here as mel-frequency spectral coefficients (MFSCs). Next, we employ local
binary pattern analysis (LBP) to capture texture information of the MFSCs, and
the feature vectors are subsequently derived using histogram representation.
The proposed features are used with three well-known classifiers in this field:
k-nearest neighbor (kNN), artificial neural network (ANN), and support vector
machine (SVM). Also, the performance was tested with multiple SVM kernels. We
conduct extensive performance evaluation experiments using two databases which
include normal and adventitious sounds. Results show that the proposed features
with SVM and also with kNN classifier outperform commonly used wavelet-based
features as well as our previously investigated mel-frequency cepstral
coefficients (MFCCs) based statistical features, specifically in abnormal sound
detection. Proposed features also yield better results than morphological
features and energy features computed from rational dilation wavelet
coefficients. The Bhattacharyya kernel performs considerably better than other
kernels. Further, we optimize the configuration of the proposed feature
extraction algorithm. Finally, we have applied mRMR (minimum-redundancy
maximum-relevancy) based feature selection method to remove redundancy in the
feature vector which makes the proposed method computationally more efficient
without any degradation in the performance. The overall performance gain is up
to 24.5% as compared to the standard wavelet feature based system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01767</identifier>
 <datestamp>2018-02-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01767</id><created>2017-10-04</created><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Mahloojifar</keyname><forenames>Ali</forenames></author><author><keyname>Nasiriavanaki</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author></authors><title>Eigenspace-Based Minimum Variance Adaptive Beamformer Combined with
  Delay Multiply and Sum: Experimental Study</title><categories>eess.SP cs.IT math.IT</categories><report-no>Published in SPIE Proceedings Vol. 10467:</report-no><journal-ref>Proc. SPIE 10467, Photonics in Dermatology and Plastic Surgery
  2018, 1046717 (22 February 2018)</journal-ref><doi>10.1117/12.2291533</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delay and sum (DAS) is the most common beamforming algorithm in linear-array
photoacoustic imaging (PAI) as a result of its simple implementation. However,
it leads to a low resolution and high sidelobes. Delay multiply and sum (DMAS)
was used to address the incapabilities of DAS, providing a higher image
quality. However, the resolution improvement is not well enough compared to
eigenspace-based minimum variance (EIBMV). In this paper, the EIBMV beamformer
has been combined with DMAS algebra, called EIBMV-DMAS, using the expansion of
DMAS algorithm. The proposed method is used as the reconstruction algorithm in
linear-array PAI. EIBMV-DMAS is experimentally evaluated where the quantitative
and qualitative results show that it outperforms DAS, DMAS and EIBMV. The
proposed method degrades the sidelobes for about 365 %, 221 % and 40 %,
compared to DAS, DMAS and EIBMV, respectively. Moreover, EIBMV-DMAS improves
the SNR about 158 %, 63 % and 20 %, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01852</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01852</id><created>2017-10-04</created><updated>2018-06-05</updated><authors><author><keyname>Faradonbeh</keyname><forenames>Mohamad Kazem Shirani</forenames></author><author><keyname>Tewari</keyname><forenames>Ambuj</forenames></author><author><keyname>Michailidis</keyname><forenames>George</forenames></author></authors><title>Finite Time Identification in Unstable Linear Systems</title><categories>cs.SY econ.EM eess.SP math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identification of the parameters of stable linear dynamical systems is a
well-studied problem in the literature, both in the low and high-dimensional
settings. However, there are hardly any results for the unstable case,
especially regarding finite time bounds. For this setting, classical results on
least-squares estimation of the dynamics parameters are not applicable and
therefore new concepts and technical approaches need to be developed to address
the issue. Unstable linear systems arise in key real applications in control
theory, econometrics, and finance. This study establishes finite time bounds
for the identification error of the least-squares estimates for a fairly large
class of heavy-tailed noise distributions, and transition matrices of such
systems. The results relate the time length (samples) required for estimation
to a function of the problem dimension and key characteristics of the true
underlying transition matrix and the noise distribution. To establish them,
appropriate concentration inequalities for random matrices and for sequences of
martingale differences are leveraged.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01904</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01904</id><created>2017-10-05</created><updated>2018-03-14</updated><authors><author><keyname>Dieudonn&#xe9;</keyname><forenames>Benjamin</forenames></author><author><keyname>Francart</keyname><forenames>Tom</forenames></author></authors><title>Head shadow enhancement with low-frequency beamforming improves sound
  localization and speech perception for simulated bimodal listeners</title><categories>eess.AS cs.SD</categories><doi>10.1016/j.heares.2018.03.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many hearing-impaired listeners struggle to localize sounds due to poor
availability of binaural cues. Listeners with a cochlear implant and a
contralateral hearing aid -- so-called bimodal listeners -- are amongst the
worst performers, as both interaural time and level differences are poorly
transmitted. We present a new method to enhance head shadow in the low
frequencies. Head shadow enhancement is achieved with a fixed beamformer with
contralateral attenuation in each ear. The method results in interaural level
differences which vary monotonically with angle. It also improves low-frequency
signal-to-noise ratios in conditions with spatially separated speech and noise.
We validated the method in two experiments with acoustic simulations of bimodal
listening. In the localization experiment, performance improved from 50.5{\deg}
to 26.8{\deg} root-mean-square error compared with standard omni-directional
microphones. In the speech-in-noise experiment, speech was presented from the
frontal direction. Speech reception thresholds improved by 15.7 dB SNR when the
noise was presented from the cochlear implant side, improved by 7.6 dB SNR when
the noise was presented from the hearing aid side, and was not affected when
noise was presented from all directions. Apart from bimodal listeners, the
method might also be promising for bilateral cochlear implant or hearing aid
users. Its low computational complexity makes the method suitable for
application in current clinical devices.
  Keywords: head shadow enhancement, enhancement of interaural level
differences, sound localization, directional hearing, speech in noise, speech
intelligibility
  PACS: 43.60.Fg, 43.66.Pn, 43.66.Qp, 43.66.Rq, 43.66.Ts, 43.71.-k, 43.71.Es,
43.71.Ky
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01949</identifier>
 <datestamp>2018-11-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01949</id><created>2017-10-05</created><updated>2018-10-31</updated><authors><author><keyname>Kamper</keyname><forenames>Herman</forenames></author><author><keyname>Shakhnarovich</keyname><forenames>Gregory</forenames></author><author><keyname>Livescu</keyname><forenames>Karen</forenames></author></authors><title>Semantic speech retrieval with a visually grounded model of
  untranscribed speech</title><categories>cs.CL cs.CV eess.AS</categories><comments>10 pages, 3 figures, 5 tables; accepted to the IEEE/ACM Transactions
  on Audio, Speech and Language Processing</comments><journal-ref>IEEE/ACM Transactions on Audio, Speech and Language Processing 27
  (2019) 89-98</journal-ref><doi>10.1109/TASLP.2018.2872106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is growing interest in models that can learn from unlabelled speech
paired with visual context. This setting is relevant for low-resource speech
processing, robotics, and human language acquisition research. Here we study
how a visually grounded speech model, trained on images of scenes paired with
spoken captions, captures aspects of semantics. We use an external image tagger
to generate soft text labels from images, which serve as targets for a neural
model that maps untranscribed speech to (semantic) keyword labels. We introduce
a newly collected data set of human semantic relevance judgements and an
associated task, semantic speech retrieval, where the goal is to search for
spoken utterances that are semantically relevant to a given text query. Without
seeing any text, the model trained on parallel speech and images achieves a
precision of almost 60% on its top ten semantic retrievals. Compared to a
supervised model trained on transcriptions, our model matches human judgements
better by some measures, especially in retrieving non-verbatim semantic
matches. We perform an extensive analysis of the model and its resulting
representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01955</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01955</id><created>2017-10-05</created><authors><author><keyname>Moschitta</keyname><forenames>Antonio</forenames></author><author><keyname>De Angelis</keyname><forenames>Alessio</forenames></author><author><keyname>Dionigi</keyname><forenames>Marco</forenames></author><author><keyname>Carbone</keyname><forenames>Paolo</forenames></author></authors><title>Analysis of simultaneous 3D positioning and attitude estimation of a
  planar coil using inductive coupling</title><categories>eess.SP</categories><comments>Preprint version. Conference accepted paper</comments><journal-ref>2017 IEEE International Instrumentation and Measurement Technology
  Conference (I2MTC), Turin, 2017. doi: 10.1109/I2MTC.2017.7969848</journal-ref><doi>10.1109/I2MTC.2017.7969848</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, simultaneous estimation of 3D position and attitude of a
single coil using a set of anchors, with known position and magnetic dipole, is
analyzed. Effect of noise and geometric properties of the anchors'
constellation is considered. Several parameters are analyzed and discussed,
including placement of anchors in a single or in multiple orthogonal planes. It
is shown that adding space and orientation diversity anchors may lead to a more
robust performance when the mobile node attitude changes in time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.01998</identifier>
 <datestamp>2018-05-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.01998</id><created>2017-09-13</created><updated>2018-05-23</updated><authors><author><keyname>Besedin</keyname><forenames>Ilya</forenames></author><author><keyname>Menushenkov</keyname><forenames>Alexey P.</forenames></author></authors><title>Quality factor of a transmission line coupled coplanar waveguide
  resonator</title><categories>eess.SP</categories><comments>8 pages, 4 figures</comments><journal-ref>EPJ Quantum Technology (2018) 5: 2</journal-ref><doi>10.1140/epjqt/s40507-018-0066-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate analytically the coupling of a coplanar waveguide resonator to
a coplanar waveguide feedline. Using a conformal mapping technique we obtain an
expression for the characteristic mode impedances and coupling coefficients of
an asymmetric multi-conductor transmission line. Leading order terms for the
external quality factor and frequency shift are calculated. The obtained
analytical results are relevant for designing circuit-QED quantum systems and
frequency division multiplexing of superconducting bolometers, detectors and
similar microwave-range multi-pixel devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02005</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02005</id><created>2017-10-03</created><authors><author><keyname>Kyuregyan</keyname><forenames>A. S.</forenames></author></authors><title>About attenuation of videopulse in nonlinear transmission lines with
  ideal dielectric</title><categories>eess.SP</categories><comments>5 pages, in Russian, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The attenuation of the video pulse with monotonically increasing input
voltage in a transmission lines with an ideal dielectric can be characterized
by &quot;ohmic&quot; voltage drop $U_\sigma$ along the electrodes with finite
conductivity. The exact analytical formulas for the calculations $U_\sigma$ in
coaxial and strip lines with and without taking into account the strong skin
effect have been obtained. These formulas do not depend on the dispersion and
the degree of nonlinearity of the dielectric and therefore is suitable for
evaluating of shock electromagnetic waves attenuation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02015</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02015</id><created>2017-10-04</created><authors><author><keyname>Wang</keyname><forenames>Tianshi</forenames></author><author><keyname>Roychowdhury</keyname><forenames>Jaijeet</forenames></author></authors><title>Rigorous Q Factor Formulation and Characterization for Nonlinear
  Oscillators</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we discuss the definition of Q factor for nonlinear
oscillators. While available definitions of Q are often limited to linear
resonators or oscillators with specific topologies, our definition is
applicable to any oscillator as a figure of merit for its amplitude stability.
It can be formulated rigorously and computed numerically from oscillator
equations. With this definition, we calculate and analyze the Q factors of
several oscillators of different types. The results confirm that the proposed Q
formulation is a useful addition to the characterization techniques for
oscillators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02016</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02016</id><created>2017-10-04</created><authors><author><keyname>Flinth</keyname><forenames>Axel</forenames></author><author><keyname>Hashemi</keyname><forenames>Ali</forenames></author></authors><title>Thermal Source Localization Through Infinite-Dimensional Compressed
  Sensing</title><categories>eess.SP math.NA</categories><msc-class>65K10, 90C25, 46N99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a scheme utilizing ideas from infinite dimensional compressed
sensing for thermal source localization. Using the soft recovery framework of
one of the authors, we provide rigorous theoretical guarantees for the recovery
performance. In particular, we extend the framework in order to also include
noisy measurements. Further, we conduct numerical experiments, showing that our
proposed method has strong performance, in a wide range of settings. These
include scenarios with few sensors, off-grid source positioning and high noise
levels, both in one and two dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02051</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02051</id><created>2017-10-04</created><updated>2018-01-12</updated><authors><author><keyname>Kuchler</keyname><forenames>Klaus</forenames></author><author><keyname>Westhoff</keyname><forenames>Daniel</forenames></author><author><keyname>Feinauer</keyname><forenames>Julian</forenames></author><author><keyname>Mitsch</keyname><forenames>Tim</forenames></author><author><keyname>Manke</keyname><forenames>Ingo</forenames></author><author><keyname>Schmidt</keyname><forenames>Volker</forenames></author></authors><title>Stochastic model for the 3D microstructure of pristine and cyclically
  aged cathodes in Li-ion batteries</title><categories>cond-mat.mtrl-sci eess.IV physics.app-ph</categories><doi>10.1088/1361-651X/aaa6da</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that the microstructure of electrodes in lithium-ion
batteries strongly affects their performance. Vice versa, the microstructure
can exhibit strong changes during the usage of the battery due to aging
effects. For a better understanding of these effects, mathematical analysis and
modeling has turned out to be of great help. In particular, stochastic 3D
microstructure models have proven to be a powerful and very flexible tool to
generate various kinds of particle-based structures. Recently, such models have
been proposed for the microstructure of anodes in lithium-ion energy and power
cells. In the present paper, we describe a stochastic modeling approach for the
3D microstructure of cathodes in a lithium-ion energy cell, which differs
significantly from the one observed in anodes. The model for the cathode data
enhances the ideas of the anode models, which have been developed so far. It is
calibrated using 3D tomographic image data from pristine as well as two aged
cathodes. A validation based on morphological image characteristics shows that
the model is able to realistically describe both, the microstructure of
pristine and aged cathodes. Thus, we conclude that the model is suitable to
generate virtual, but realistic microstructures of lithium-ion cathodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02167</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02167</id><created>2017-10-05</created><authors><author><keyname>Salahieh</keyname><forenames>Basel</forenames></author><author><keyname>Hunter</keyname><forenames>Seth</forenames></author><author><keyname>Wu</keyname><forenames>Yi</forenames></author><author><keyname>Nestares</keyname><forenames>Oscar</forenames></author></authors><title>Light Field Retargeting for Multi-Panel Displays</title><categories>eess.IV</categories><comments>16 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Light fields preserve angular information which can be retargeted to
multi-panel depth displays. Due to limited aperture size and constrained
spatial-angular sampling of many light field capture systems, the displayed
light fields provide only a narrow viewing zone in which parallax views can be
supported. In addition, multi-panel displays typically have a reduced number of
panels being able to coarsely sample depth content resulting in a layered
appearance of light fields. We propose a light field retargeting technique for
multi-panel displays that enhances the perceived parallax and achieves seamless
transition over different depths and viewing angles. This is accomplished by
slicing the captured light fields according to their depth content, boosting
the parallax, and blending the results across the panels. Displayed views are
synthesized and aligned dynamically according to the position of the viewer.
The proposed technique is outlined, simulated and verified experimentally on a
three-panel aerial display.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02237</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02237</id><created>2017-10-05</created><authors><author><keyname>Gordon</keyname><forenames>Philip H.</forenames></author><author><keyname>Chen</keyname><forenames>Rex</forenames></author><author><keyname>Park</keyname><forenames>Huiju</forenames></author><author><keyname>Kan</keyname><forenames>Edwin C.</forenames></author></authors><title>Embroidered Antenna Characterization for Passive UHF RFID Tags</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For smart clothing integration with the wireless system based on radio
frequency (RF) backscattering, we demonstrate an ultra-high frequency (UHF)
antenna constructed from embroidered conductive threads. Sewn into a fabric
backing, the T-match antenna design mimics a commercial UHF RFID tag, which was
also used for comparative testing. Bonded to the fabric antenna is the
integrated circuit chip dissected from another commercial RFID tag, which
allows for testing the tags under normal EPC Gen 2 operating conditions. We
find that, despite of the high resistive loss of the antenna and inexact
impedance matching, the fabric antenna works reasonably well as a UHF antenna
both in standalone RFID testing, and during variety of ways of wearing under
sweaters or as wristbands. The embroidering pattern does not affect much the
feel and comfort from either side of the fabrics by our sewing method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02280</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02280</id><created>2017-10-06</created><authors><author><keyname>Teng</keyname><forenames>Yifei</forenames></author><author><keyname>Zhao</keyname><forenames>An</forenames></author><author><keyname>Goudeseune</keyname><forenames>Camille</forenames></author></authors><title>Generating Nontrivial Melodies for Music as a Service</title><categories>cs.SD cs.AI eess.AS</categories><comments>ISMIR 2017 Conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present a hybrid neural network and rule-based system that generates pop
music. Music produced by pure rule-based systems often sounds mechanical. Music
produced by machine learning sounds better, but still lacks hierarchical
temporal structure. We restore temporal hierarchy by augmenting machine
learning with a temporal production grammar, which generates the music's
overall structure and chord progressions. A compatible melody is then generated
by a conditional variational recurrent autoencoder. The autoencoder is trained
with eight-measure segments from a corpus of 10,000 MIDI files, each of which
has had its melody track and chord progressions identified heuristically. The
autoencoder maps melody into a multi-dimensional feature space, conditioned by
the underlying chord progression. A melody is then generated by feeding a
random sample from that space to the autoencoder's decoder, along with the
chord progression generated by the grammar. The autoencoder can make musically
plausible variations on an existing melody, suitable for recurring motifs. It
can also reharmonize a melody to a new chord progression, keeping the rhythm
and contour. The generated music compares favorably with that generated by
other academic and commercial software designed for the music-as-a-service
industry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02369</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02369</id><created>2017-10-06</created><updated>2018-01-08</updated><authors><author><keyname>Rohdin</keyname><forenames>Johan</forenames></author><author><keyname>Silnova</keyname><forenames>Anna</forenames></author><author><keyname>Diez</keyname><forenames>Mireia</forenames></author><author><keyname>Plchot</keyname><forenames>Oldrich</forenames></author><author><keyname>Matejka</keyname><forenames>Pavel</forenames></author><author><keyname>Burget</keyname><forenames>Lukas</forenames></author></authors><title>End-to-end DNN Based Speaker Recognition Inspired by i-vector and PLDA</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently several end-to-end speaker verification systems based on deep neural
networks (DNNs) have been proposed. These systems have been proven to be
competitive for text-dependent tasks as well as for text-independent tasks with
short utterances. However, for text-independent tasks with longer utterances,
end-to-end systems are still outperformed by standard i-vector + PLDA systems.
In this work, we develop an end-to-end speaker verification system that is
initialized to mimic an i-vector + PLDA baseline. The system is then further
trained in an end-to-end manner but regularized so that it does not deviate too
far from the initial system. In this way we mitigate overfitting which normally
limits the performance of end-to-end systems. The proposed system outperforms
the i-vector + PLDA baseline on both long and short duration utterances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02441</identifier>
 <datestamp>2019-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02441</id><created>2017-10-06</created><authors><author><keyname>Nataraj</keyname><forenames>Gopal</forenames></author><author><keyname>Nielsen</keyname><forenames>Jon-Fredrik</forenames></author><author><keyname>Scott</keyname><forenames>Clayton</forenames></author><author><keyname>Fessler</keyname><forenames>Jeffrey A.</forenames></author></authors><title>Dictionary-Free MRI PERK: Parameter Estimation via Regression with
  Kernels</title><categories>stat.ML eess.SP physics.med-ph</categories><comments>submitted to IEEE Transactions on Medical Imaging</comments><journal-ref>IEEE Transactions on Medical Imaging 37(9):2103-14 Sep 2018</journal-ref><doi>10.1109/TMI.2018.2817547</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a fast, general method for dictionary-free parameter
estimation in quantitative magnetic resonance imaging (QMRI) via regression
with kernels (PERK). PERK first uses prior distributions and the nonlinear MR
signal model to simulate many parameter-measurement pairs. Inspired by machine
learning, PERK then takes these parameter-measurement pairs as labeled training
points and learns from them a nonlinear regression function using kernel
functions and convex optimization. PERK admits a simple implementation as
per-voxel nonlinear lifting of MRI measurements followed by linear minimum
mean-squared error regression. We demonstrate PERK for $T_1,T_2$ estimation, a
well-studied application where it is simple to compare PERK estimates against
dictionary-based grid search estimates. Numerical simulations as well as
single-slice phantom and in vivo experiments demonstrate that PERK and grid
search produce comparable $T_1,T_2$ estimates in white and gray matter, but
PERK is consistently at least $23\times$ faster. This acceleration factor will
increase by several orders of magnitude for full-volume QMRI estimation
problems involving more latent parameters per voxel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02560</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02560</id><created>2017-10-06</created><authors><author><keyname>Ravanelli</keyname><forenames>Mirco</forenames></author><author><keyname>Omologo</keyname><forenames>Maurizio</forenames></author></authors><title>The DIRHA-English corpus and related tasks for distant-speech
  recognition in domestic environments</title><categories>eess.AS cs.CL cs.SD</categories><comments>ASRU 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the contents and the possible usage of the
DIRHA-ENGLISH multi-microphone corpus, recently realized under the EC DIRHA
project. The reference scenario is a domestic environment equipped with a large
number of microphones and microphone arrays distributed in space.
  The corpus is composed of both real and simulated material, and it includes
12 US and 12 UK English native speakers. Each speaker uttered different sets of
phonetically-rich sentences, newspaper articles, conversational speech,
keywords, and commands. From this material, a large set of 1-minute sequences
was generated, which also includes typical domestic background noise as well as
inter/intra-room reverberation effects. Dev and test sets were derived, which
represent a very precious material for different studies on multi-microphone
speech processing and distant-speech recognition. Various tasks and
corresponding Kaldi recipes have already been developed.
  The paper reports a first set of baseline results obtained using different
techniques, including Deep Neural Networks (DNN), aligned with the
state-of-the-art at international level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02571</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02571</id><created>2017-10-06</created><authors><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author><author><keyname>Nealy</keyname><forenames>Randall</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey H.</forenames></author></authors><title>LTE Spectrum Sharing Research Testbed: Integrated Hardware, Software,
  Network and Data</title><categories>eess.SP</categories><comments>In Proceeding of the 10th ACM International Workshop on Wireless
  Network Testbeds, Experimental Evaluation &amp; Characterization (WiNTECH),
  Snowbird, Utah, October 2017</comments><acm-class>C.2.1; C.1.3; D.2.2</acm-class><doi>10.1145/3131473.3131484</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents Virginia Tech's wireless testbed supporting research on
long-term evolution (LTE) signaling and radio frequency (RF) spectrum
coexistence. LTE is continuously refined and new features released. As the
communications contexts for LTE expand, new research problems arise and include
operation in harsh RF signaling environments and coexistence with other radios.
Our testbed provides an integrated research tool for investigating these and
other research problems; it allows analyzing the severity of the problem,
designing and rapidly prototyping solutions, and assessing them with
standard-compliant equipment and test procedures. The modular testbed
integrates general-purpose software-defined radio hardware, LTE-specific test
equipment, RF components, free open-source and commercial LTE software, a
configurable RF network and recorded radar waveform samples. It supports RF
channel emulated and over-the-air radiated modes. The testbed can be remotely
accessed and configured. An RF switching network allows for designing many
different experiments that can involve a variety of real and virtual radios
with support for multiple-input multiple-output (MIMO) antenna operation. We
present the testbed, the research it has enabled and some valuable lessons that
we learned and that may help designing, developing, and operating future
wireless testbeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02574</identifier>
 <datestamp>2018-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02574</id><created>2017-10-06</created><updated>2018-10-19</updated><authors><author><keyname>Thouvenin</keyname><forenames>Pierre-Antoine</forenames></author><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author><author><keyname>Tourneret</keyname><forenames>Jean-Yves</forenames></author></authors><title>Partially Asynchronous Distributed Unmixing of Hyperspectral Images</title><categories>eess.IV math.OC physics.data-an</categories><comments>13 pages, 12 figures, accepted for publication in IEEE Trans. Geosci.
  Remote Sens., 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  So far, the problem of unmixing large or multitemporal hyperspectral datasets
has been specifically addressed in the remote sensing literature only by a few
dedicated strategies. Among them, some attempts have been made within a
distributed estimation framework, in particular relying on the alternating
direction method of multipliers (ADMM). In this paper, we propose to study the
interest of a partially asynchronous distributed unmixing procedure based on a
recently proposed asynchronous algorithm. Under standard assumptions, the
proposed algorithm inherits its convergence properties from recent
contributions in non-convex optimization, while allowing the problem of
interest to be efficiently addressed. Comparisons with a distributed
synchronous counterpart of the proposed unmixing procedure allow its interest
to be assessed on synthetic and real data. Besides, thanks to its genericity
and flexibility, the procedure investigated in this work can be implemented to
address various matrix factorization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02633</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02633</id><created>2017-10-07</created><authors><author><keyname>Ghayoula</keyname><forenames>Elies</forenames></author><author><keyname>Ghayoula</keyname><forenames>Ridha</forenames></author><author><keyname>Fattahi</keyname><forenames>Jaouhar</forenames></author><author><keyname>Pricop</keyname><forenames>Emil</forenames></author><author><keyname>Chouinard</keyname><forenames>Jean-Yves</forenames></author><author><keyname>Bouallegue</keyname><forenames>Ammar</forenames></author></authors><title>Radiation Pattern Synthesis Using Hybrid Fourier- Woodward-Lawson-Neural
  Networks for Reliable MIMO Antenna Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted at the IEEE SMC 2017</comments><doi>10.1109/SMC.2017.8123136</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we implement hybrid Woodward-Lawson-Neural Networks and
weighted Fourier method to synthesize antenna arrays. The neural networks (NN)
is applied here to simplify the modeling of MIMO antenna arrays by assessing
phases. The main problem is obviously to find optimal weights of the linear
antenna array elements giving radiation pattern with minimum sidelobe level
(SLL) and hence ameliorating the antenna array performance. To attain this
purpose, an antenna array for reliable Multiple-Input Multiple-Output (MIMO)
applications with frequency at 2.45 GHz is implemented. To validate the
suggested method, many examples of uniformly excited array patterns with the
main beam are put in the direction of the useful signal. The
Woodward-Lawson-Neural Networks synthesis method permits to find out
interesting analytical equations for the synthesis of an antenna array and
highlights the flexibility between the system parameters in input and those in
output. The performance of this hybrid optimization underlines how well the
system is suitable for a wireless communication and how it participates in
reducing interference, as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02656</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02656</id><created>2017-10-07</created><authors><author><keyname>Nguyen</keyname><forenames>Mai P. T.</forenames></author><author><keyname>Song</keyname><forenames>I.</forenames></author></authors><title>Robust Radar Detection of a Mismatched Steering Vector Embedded in
  Compound Gaussian Clutter</title><categories>eess.SP</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of radar detection in compound Gaussian clutter when a radar
signature is not completely known has not been considered yet and is addressed
in this paper. We proposed a robust technique to detect, based on the
generalized likelihood ratio test, a point-like target embedded in compound
Gaussian clutter. Employing an array of antennas, we assume that the actual
steering vector departs from the nominal one, but lies in a known interval. The
detection is then secured by employing a semi-definite programming. It is
confirmed via simulation that the proposed detector experiences a negligible
detection loss compared to an adaptive normalized matched filter in a perfectly
matched case, but outperforms in cases of mismatched signal. Remarkably, the
proposed detector possesses constant false alarm rate with respect to the
clutter covariance matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02732</identifier>
 <datestamp>2018-03-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02732</id><created>2017-10-07</created><updated>2018-03-13</updated><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Shehata</keyname><forenames>Mohamed</forenames></author><author><keyname>McGuire</keyname><forenames>Peter</forenames></author><author><keyname>Smith</keyname><forenames>Andrew</forenames></author></authors><title>A Semi-Automated Technique for Internal Jugular Vein Segmentation in
  Ultrasound Images Using Active Contours</title><categories>eess.IV</categories><comments>4 pages, 6 figures</comments><journal-ref>BHI2016</journal-ref><doi>10.1109/BHI.2016.7455865</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The assessment of the blood volume is crucial for the management of many
acute and chronic diseases. Recent studies have shown that circulating blood
volume correlates with the cross-sectional area (CSA) of the internal jugular
vein (IJV) estimated from ultrasound imagery. In this paper, a semi-automatic
segmentation algorithm is proposed using a combination of region growing and
active contour techniques to provide a fast and accurate segmentation of IJV
ultrasound videos. The algorithm is applied to track and segment the IJV across
a range of image qualities, shapes, and temporal variation. The experimental
results show that the algorithm performs well compared to expert manual
segmentation and outperforms several published algorithms incorporating speckle
tracking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02751</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02751</id><created>2017-10-07</created><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Mehrmohammadi</keyname><forenames>Mohammad</forenames></author><author><keyname>Makkiabadi</keyname><forenames>Bahador</forenames></author></authors><title>Image Improvement in Linear-Array Photoacoustic Imaging using High
  Resolution Coherence Factor Weighting Technique</title><categories>eess.SP physics.med-ph</categories><comments>arXiv admin note: text overlap with arXiv:1709.07965</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Photoacoustic imaging (PAI), the most prevalent beamforming algorithm is
delay-and-sum (DAS) due to its simple implementation. However, it results in a
low quality image affected by the high level of sidelobes. Coherence factor
(CF) can be used to address the sidelobes in the reconstructed images by DAS,
but the resolution improvement is not good enough compared to the high
resolution beamformers such as minimum variance (MV). As a weighting algorithm
in linear-array PAI, it was proposed to use high-resolution-CF (HRCF) weighting
technique in which MV is used instead of the existing DAS in the formula of the
conventional CF. The higher performance of HRCF was proved numerically and
experimentally. The quantitative results obtained with the simulations show
that at the depth of 40 mm, in comparison with DAS+CF and MV+CF, HRCF improves
the full-width-half-maximum of about 91 % and 15 % and the signal-to-noise
ratio about 40 % and 14 %, respectively. Moreover, the contrast ratio at the
depth of 20 mm has been improved about 62 % and 21 % by HRCF, compared to
DAS+CF and MV+CF, respectively
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02907</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02907</id><created>2017-10-08</created><updated>2017-10-09</updated><authors><author><keyname>Ayinde</keyname><forenames>Babajide O.</forenames></author></authors><title>A Fast and Efficient Near-Lossless Image Compression using Zipper
  Transformation</title><categories>eess.IV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Near-lossless image compression-decompression scheme is proposed in this
paper using Zipper Transformation (ZT) and inverse zipper transformation (iZT).
The proposed ZT exploits the conjugate symmetry property of Discrete Fourier
Transformation (DFT). The proposed transformation is implemented using two
different configurations: the interlacing and concatenating ZT. In order to
quantify the efficacy of the proposed transformation, we benchmark with
Discrete Cosine Transformation (DCT) and Fast Walsh Hadamard Transformation
(FWHT) in terms of lossless compression capability and computational cost.
Numerical simulations show that ZT-based compression algorithm is
near-lossless, compresses better, and offers faster implementation than both
DCT and FWHT. Also, interlacing and concatenating ZT are shown to yield similar
results in most of the test cases considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02928</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02928</id><created>2017-10-08</created><authors><author><keyname>Nguyen</keyname><forenames>Mai. P. T.</forenames></author><author><keyname>Song</keyname><forenames>I.</forenames></author><author><keyname>Lee</keyname><forenames>S.</forenames></author><author><keyname>Yoon</keyname><forenames>S.</forenames></author></authors><title>Range-Spread Targets Detection in Unknown Doppler Shift via
  Semi-Definite Programming</title><categories>eess.SP</categories><comments>First author is Mai P. T. Nguyen</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the technique of generalized likelihood ratio test, we address
detection schemes for Doppler-shifted range-spread targets in Gaussian noise.
First, a detection scheme is derived by solving the maximization associated
with the estimation of unknown Doppler frequency with semi-definite
programming. To lower the computational complexity of the detector, we then
consider a simplification of the detector by adopting maximization over a
relaxed space. Both of the proposed detectors are shown to have constant false
alarm rate via numerical or theoretical analysis. The detection performance of
the proposed detector based on the semi-definite programming is shown to be
almost the same as that of the conventional detector designed for known Doppler
frequency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02997</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02997</id><created>2017-10-09</created><authors><author><keyname>Adavanne</keyname><forenames>Sharath</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>A report on sound event detection with different binaural features</title><categories>cs.SD eess.AS</categories><comments>Technical report for the top performing method in Task 3: Real life
  sound event detection challenge, at Detection and classification of acoustic
  scene and events (DCASE) 2017</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we compare the performance of using binaural audio features in
place of single-channel features for sound event detection. Three different
binaural features are studied and evaluated on the publicly available TUT Sound
Events 2017 dataset of length 70 minutes. Sound event detection is performed
separately with single-channel and binaural features using stacked
convolutional and recurrent neural network and the evaluation is reported using
standard metrics of error rate and F-score. The studied binaural features are
seen to consistently perform equal to or better than the single-channel
features with respect to error rate metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02998</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.02998</id><created>2017-10-09</created><authors><author><keyname>Adavanne</keyname><forenames>Sharath</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Sound event detection using weakly labeled dataset with stacked
  convolutional and recurrent neural network</title><categories>cs.SD eess.AS</categories><comments>Accepted in Detection and Classification of Acoustic Scenes and
  Events (DCASE 2017)</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper proposes a neural network architecture and training scheme to
learn the start and end time of sound events (strong labels) in an audio
recording given just the list of sound events existing in the audio without
time information (weak labels). We achieve this by using a stacked
convolutional and recurrent neural network with two prediction layers in
sequence one for the strong followed by the weak label. The network is trained
using frame-wise log mel-band energy as the input audio feature, and weak
labels provided in the dataset as labels for the weak label prediction layer.
Strong labels are generated by replicating the weak labels as many number of
times as the frames in the input audio feature, and used for strong label layer
during training. We propose to control what the network learns from the weak
and strong labels by different weighting for the loss computed in the two
prediction layers. The proposed method is evaluated on a publicly available
dataset of 155 hours with 17 sound event classes. The method achieves the best
error rate of 0.84 for strong labels and F-score of 43.3% for weak labels on
the unseen test split.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.03073</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.03073</id><created>2017-10-04</created><authors><author><keyname>Barcia</keyname><forenames>P.</forenames></author><author><keyname>Ferreira</keyname><forenames>P. Castelo</forenames></author><author><keyname>Freitas</keyname><forenames>P.</forenames></author></authors><title>Modelling Power Network: State Estimation and Correction</title><categories>eess.SP</categories><comments>29 pp; report 86th ESGI - version from September 2013; The same
  methods may also be employed in security systems fault detection. Hope it may
  be useful</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is presented a simple algorithm for power network state estimation and
correction (fault detection) employing standard methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.03147</identifier>
 <datestamp>2017-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.03147</id><created>2017-10-06</created><authors><author><keyname>Fujieda</keyname><forenames>M.</forenames></author><author><keyname>Yang</keyname><forenames>S-H.</forenames></author><author><keyname>Gotoh</keyname><forenames>T.</forenames></author><author><keyname>Hwang</keyname><forenames>S-W.</forenames></author><author><keyname>Hachisu</keyname><forenames>H.</forenames></author><author><keyname>Kim</keyname><forenames>H.</forenames></author><author><keyname>Lee</keyname><forenames>Y. K.</forenames></author><author><keyname>Tabuchi</keyname><forenames>R.</forenames></author><author><keyname>Ido</keyname><forenames>T.</forenames></author><author><keyname>Lee</keyname><forenames>W-K.</forenames></author><author><keyname>Heo</keyname><forenames>M-S.</forenames></author><author><keyname>Park</keyname><forenames>C. Y.</forenames></author><author><keyname>Yu</keyname><forenames>D-H.</forenames></author><author><keyname>Petit</keyname><forenames>G.</forenames></author></authors><title>Advanced Satellite-based Frequency Transfer at the 10^{-16} Level</title><categories>eess.SP physics.atom-ph</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advanced satellite-based frequency transfers by TWCP and IPPP have been
performed between NICT and KRISS. We confirm that the disagreement between them
is less than 1x10^{-16} at an averaging time of several days. Additionally, an
intercontinental frequency ratio measurement of Sr and Yb optical lattice
clocks was directly performed by TWCP. We achieved an uncertainty at the
mid-10^{-16} level after a total measurement time of 12 hours. The frequency
ratio was consistent with the recently reported values within the uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.03197</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.03197</id><created>2017-10-09</created><authors><author><keyname>Lin</keyname><forenames>Jyh-Miin</forenames></author></authors><title>Python Non-Uniform Fast Fourier Transform (PyNUFFT): multi-dimensional
  non-Cartesian image reconstruction package for heterogeneous platforms and
  applications to MRI</title><categories>physics.med-ph cs.DC eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports the development of a Python Non-Uniform Fast Fourier
Transform (PyNUFFT) package, which accelerates non-Cartesian image
reconstruction on heterogeneous platforms. Scientific computing with Python
encompasses a mature and integrated environment. The NUFFT algorithm has been
extensively used for non-Cartesian image reconstruction but previously there
was no native Python NUFFT library. The current PyNUFFT software enables
multi-dimensional NUFFT on heterogeneous platforms. The PyNUFFT also provides
several solvers, including the conjugate gradient method, $\ell$1
total-variation regularized ordinary least square (L1TV-OLS) and $\ell$1
total-variation regularized least absolute deviation (L1TV-LAD).
Metaprogramming libraries were employed to accelerate PyNUFFT. The PyNUFFT
package has been tested on multi-core CPU and GPU, with acceleration factors of
6.3 - 9.5$\times$ on a 32 thread CPU platform and 5.4 - 13$\times$ on the GPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.03218</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.03218</id><created>2017-10-09</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Saarnisaari</keyname><forenames>Harri</forenames></author></authors><title>Windowed Overlapped frequency-domain Block Filtering Approach for Direct
  Sequence Signal Acquisition</title><categories>eess.SP</categories><comments>Accepted in Digital Communications and Networks, 2017</comments><doi>10.1016/j.dcan.2017.04.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper applies a windowed frequency-domain overlapped block filtering
approach for the acquisition of direct sequence signals. The windows, as a
novel viewpoint, not only allow pulse shaping without a front end pulse shaping
filter, but also improve the performance of the spectrum sensing unit which can
efficiently be implemented into this frequency-domain receiver and may further
be used for spectrum sensing in cognitive radios or narrowband interference
cancellation in military radios. The proposed receiver is applicable for
initial time synchronization of different signals containing a preamble. These
signals include single carrier, constant-envelope single-carrier, multi-carrier
and even generalized-multi-carrier signals, which makes the proposed receiver
structure a universal unit. Furthermore, the receiver can be used to perform
filtering with long codes and compute the sliding correlation of an unknown
periodic preamble. It can further be modified to handle large Doppler shifts.
We will also demonstrate the computational complexity and analysis of the
acquisition performance in Rayleigh and Rician fading channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.03538</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.03538</id><created>2017-10-10</created><authors><author><keyname>Ravanelli</keyname><forenames>Mirco</forenames></author><author><keyname>Omologo</keyname><forenames>Maurizio</forenames></author></authors><title>Contaminated speech training methods for robust DNN-HMM distant speech
  recognition</title><categories>eess.AS cs.CL cs.SD</categories><journal-ref>INTERSPEECH 2015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the significant progress made in the last years, state-of-the-art
speech recognition technologies provide a satisfactory performance only in the
close-talking condition. Robustness of distant speech recognition in adverse
acoustic conditions, on the other hand, remains a crucial open issue for future
applications of human-machine interaction. To this end, several advances in
speech enhancement, acoustic scene analysis as well as acoustic modeling, have
recently contributed to improve the state-of-the-art in the field. One of the
most effective approaches to derive a robust acoustic modeling is based on
using contaminated speech, which proved helpful in reducing the acoustic
mismatch between training and testing conditions.
  In this paper, we revise this classical approach in the context of modern
DNN-HMM systems, and propose the adoption of three methods, namely, asymmetric
context windowing, close-talk based supervision, and close-talk based
pre-training. The experimental results, obtained using both real and simulated
data, show a significant advantage in using these three methods, overall
providing a 15% error rate reduction compared to the baseline systems. The same
trend in performance is confirmed either using a high-quality training set of
small size, and a large one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.03654</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.03654</id><created>2017-10-10</created><updated>2018-04-05</updated><authors><author><keyname>Fu</keyname><forenames>Haoyu</forenames></author><author><keyname>Chi</keyname><forenames>Yuejie</forenames></author></authors><title>Quantized Spectral Compressed Sensing: Cramer-Rao Bounds and Recovery
  Algorithms</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/TSP.2018.2827326</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient estimation of wideband spectrum is of great importance for
applications such as cognitive radio. Recently, sub-Nyquist sampling schemes
based on compressed sensing have been proposed to greatly reduce the sampling
rate. However, the important issue of quantization has not been fully
addressed, particularly for high-resolution spectrum and parameter estimation.
In this paper, we aim to recover spectrally-sparse signals and the
corresponding parameters, such as frequency and amplitudes, from heavy
quantizations of their noisy complex-valued random linear measurements, e.g.
only the quadrant information. We first characterize the Cramer-Rao bound under
Gaussian noise, which highlights the trade-off between sample complexity and
bit depth under different signal-to-noise ratios for a fixed budget of bits.
Next, we propose a new algorithm based on atomic norm soft thresholding for
signal recovery, which is equivalent to proximal mapping of properly designed
surrogate signals with respect to the atomic norm that motivates spectral
sparsity. The proposed algorithm can be applied to both the single measurement
vector case, as well as the multiple measurement vector case. It is shown that
under the Gaussian measurement model, the spectral signals can be reconstructed
accurately with high probability, as soon as the number of quantized
measurements exceeds the order of K log n, where K is the level of spectral
sparsity and $n$ is the signal dimension. Finally, numerical simulations are
provided to validate the proposed approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.03959</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.03959</id><created>2017-10-11</created><authors><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author><author><keyname>Tuia</keyname><forenames>Devis</forenames></author><author><keyname>Mou</keyname><forenames>Lichao</forenames></author><author><keyname>Xia</keyname><forenames>Gui-Song</forenames></author><author><keyname>Zhang</keyname><forenames>Liangpei</forenames></author><author><keyname>Xu</keyname><forenames>Feng</forenames></author><author><keyname>Fraundorfer</keyname><forenames>Friedrich</forenames></author></authors><title>Deep learning in remote sensing: a review</title><categories>cs.CV eess.IV</categories><comments>Accepted for publication IEEE Geoscience and Remote Sensing Magazine</comments><doi>10.1109/MGRS.2017.2762307</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Standing at the paradigm shift towards data-intensive science, machine
learning techniques are becoming increasingly important. In particular, as a
major breakthrough in the field, deep learning has proven as an extremely
powerful tool in many fields. Shall we embrace deep learning as the key to all?
Or, should we resist a 'black-box' solution? There are controversial opinions
in the remote sensing community. In this article, we analyze the challenges of
using deep learning for remote sensing data analysis, review the recent
advances, and provide resources to make deep learning in remote sensing
ridiculously simple to start with. More importantly, we advocate remote sensing
scientists to bring their expertise into deep learning, and use it as an
implicit general model to tackle unprecedented large-scale influential
challenges, such as climate change and urbanization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.03975</identifier>
 <datestamp>2017-10-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.03975</id><created>2017-10-11</created><authors><author><keyname>Sadasivan</keyname><forenames>Jishnu</forenames></author><author><keyname>Seelamantula</keyname><forenames>Chandra Sekhar</forenames></author><author><keyname>Muraka</keyname><forenames>Nagarjuna Reddy</forenames></author></authors><title>PROSE: Perceptual Risk Optimization for Speech Enhancement</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal in speech enhancement is to obtain an estimate of clean speech
starting from the noisy signal by minimizing a chosen distortion measure, which
results in an estimate that depends on the unknown clean signal or its
statistics. Since access to such prior knowledge is limited or not possible in
practice, one has to estimate the clean signal statistics. In this paper, we
develop a new risk minimization framework for speech enhancement, in which, one
optimizes an unbiased estimate of the distortion/risk instead of the actual
risk. The estimated risk is expressed solely as a function of the noisy
observations. We consider several perceptually relevant distortion measures and
develop corresponding unbiased estimates under realistic assumptions on the
noise distribution and a priori signal-to-noise ratio (SNR). Minimizing the
risk estimates gives rise to the corresponding denoisers, which are nonlinear
functions of the a posteriori SNR. Perceptual evaluation of speech quality
(PESQ), average segmental SNR (SSNR) computations, and listening tests show
that the proposed risk optimization approach employing Itakura-Saito and
weighted hyperbolic cosine distortions gives better performance than the other
distortion measures. For SNRs greater than 5 dB, the proposed approach gives
superior denoising performance over the benchmark techniques based on the
Wiener filter, log-MMSE minimization, and Bayesian nonnegative matrix
factorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04011</identifier>
 <datestamp>2018-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04011</id><created>2017-10-11</created><authors><author><keyname>McCann</keyname><forenames>Michael T.</forenames></author><author><keyname>Jin</keyname><forenames>Kyong Hwan</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>A Review of Convolutional Neural Networks for Inverse Problems in
  Imaging</title><categories>eess.IV cs.CV</categories><journal-ref>IEEE Signal Processing Magazine, vol. 34, no. 6, pp. 85-95, Nov.
  2017</journal-ref><doi>10.1109/MSP.2017.2739299</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this survey paper, we review recent uses of convolution neural networks
(CNNs) to solve inverse problems in imaging. It has recently become feasible to
train deep CNNs on large databases of images, and they have shown outstanding
performance on object classification and segmentation tasks. Motivated by these
successes, researchers have begun to apply CNNs to the resolution of inverse
problems such as denoising, deconvolution, super-resolution, and medical image
reconstruction, and they have started to report improvements over
state-of-the-art methods, including sparsity-based techniques such as
compressed sensing. Here, we review the recent experimental work in these
areas, with a focus on the critical design decisions: Where does the training
data come from? What is the architecture of the CNN? and How is the learning
problem formulated and solved? We also bring together a few key theoretical
papers that offer perspective on why CNNs are appropriate for inverse problems
and point to some next steps in the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04055</identifier>
 <datestamp>2019-07-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04055</id><created>2017-10-09</created><updated>2019-06-27</updated><authors><author><keyname>Pei</keyname><forenames>Yan</forenames></author><author><keyname>Biswas</keyname><forenames>Swarnendu</forenames></author><author><keyname>Fussell</keyname><forenames>Donald S.</forenames></author><author><keyname>Pingali</keyname><forenames>Keshav</forenames></author></authors><title>An Elementary Introduction to Kalman Filtering</title><categories>eess.SY cs.SY</categories><comments>Small tweaks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kalman filtering is a classic state estimation technique used in application
areas such as signal processing and autonomous control of vehicles. It is now
being used to solve problems in computer systems such as controlling the
voltage and frequency of processors.
  Although there are many presentations of Kalman filtering in the literature,
they usually deal with particular systems like autonomous robots or linear
systems with Gaussian noise, which makes it difficult to understand the general
principles behind Kalman filtering. In this paper, we first present the
abstract ideas behind Kalman filtering at a level accessible to anyone with a
basic knowledge of probability theory and calculus, and then show how these
concepts can be applied to the particular problem of state estimation in linear
systems. This separation of concepts from applications should make it easier to
understand Kalman filtering and to apply it to other problems in computer
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04122</identifier>
 <datestamp>2017-10-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04122</id><created>2017-09-22</created><authors><author><keyname>Suri</keyname><forenames>Manan</forenames></author></authors><title>Dispenser Concept for Unmanned Aerial Vehicles (UAV, Drone, UAS)</title><categories>cs.CY eess.SP</categories><comments>12 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  System, design and methodology to load and dispense different articles from
an autonomous aircraft are disclosed. In one embodiment, the design of a unique
detachable dispenser for delivery of articles is described along with an
intelligent methodology of loading and delivering the articles to and from the
dispenser. Design of the dispenser, interaction of the dispenser with the
flight control unit and ground control or base-station, and interaction of the
base station with the sender or recipient of the article, are also described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04196</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04196</id><created>2017-10-11</created><authors><author><keyname>Scheibler</keyname><forenames>Robin</forenames></author><author><keyname>Bezzam</keyname><forenames>Eric</forenames></author><author><keyname>Dokmani&#x107;</keyname><forenames>Ivan</forenames></author></authors><title>Pyroomacoustics: A Python package for audio room simulations and array
  processing algorithms</title><categories>cs.SD eess.AS</categories><comments>5 pages, 5 figures, describes a software package</comments><doi>10.1109/ICASSP.2018.8461310</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present pyroomacoustics, a software package aimed at the rapid development
and testing of audio array processing algorithms. The content of the package
can be divided into three main components: an intuitive Python object-oriented
interface to quickly construct different simulation scenarios involving
multiple sound sources and microphones in 2D and 3D rooms; a fast C
implementation of the image source model for general polyhedral rooms to
efficiently generate room impulse responses and simulate the propagation
between sources and receivers; and finally, reference implementations of
popular algorithms for beamforming, direction finding, and adaptive filtering.
Together, they form a package with the potential to speed up the time to market
of new algorithms by significantly reducing the implementation overhead in the
performance evaluation step.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04207</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04207</id><created>2017-10-11</created><authors><author><keyname>Celeghini</keyname><forenames>Enrico</forenames></author></authors><title>Algebraic Image Processing</title><categories>eess.IV cs.CV</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an approach to image processing related to algebraic operators
acting in the space of images. In view of the interest in the applications in
optics and computer science, mathematical aspects of the paper have been
simplified as much as possible. Underlying theory, related to rigged Hilbert
spaces and Lie algebras, is discussed elsewhere
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04275</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04275</id><created>2017-10-11</created><authors><author><keyname>Uyanik</keyname><forenames>Ismail</forenames></author></authors><title>Identification of Legged Locomotion via Model-Based and Data-Driven
  Approaches</title><categories>eess.SP</categories><comments>160 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the first part of this thesis, we present our efforts on experimental
validation of the predictive performance of mechanics-based mathematical models
on a physical one-legged hopping robot platform. We extend upon a recently
proposed approximate analytical solution developed for the lossy spring--mass
models for a real robotic system and perform a parametric system identification
to carefully identify the system parameters in the proposed model. We also
present our assessments on the predictive performance of the proposed
approximate analytical solution on our one-legged hopping robot data.
  The second part considers estimating state space models of legged locomotion
using input--output data. To accomplish this, we first propose a state space
identification method to estimate time periodic state and input matrices of a
hybrid LTP system under full state measurement assumption. We then release this
assumption and proceed with subspace identification methods to estimate LTP
state space realizations for unknown stable LTP systems. We utilize bilinear
(Tustin) transformation and frequency domain lifting methods to generalize our
solutions to different LTP system models. Our results provide a basis towards
identification of state space models for legged locomotion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04284</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04284</id><created>2017-10-11</created><authors><author><keyname>Niknam</keyname><forenames>Solmaz</forenames></author><author><keyname>Natarajan</keyname><forenames>Balasubramaniam</forenames></author><author><keyname>Barazideh</keyname><forenames>Reza</forenames></author></authors><title>A Spatial-Spectral Interference Model for Dense Finite-Area 5G mmWave
  Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the overcrowded sub-6 GHz bands, millimeter wave (mmWave) bands offer a
promising alternative for the next generation wireless standard, i.e., 5G.
However, the susceptibility of mmWave signals to severe pathloss and shadowing
requires the use of highly directional antennas to overcome such adverse
characteristics. Building a network with directional beams changes the
interference behavior, since, narrow beams are vulnerable to blockages. Such
sensitivity to blockages causes uncertainty in the active interfering node
locations. Configuration uncertainty may also manifest in the spectral domain
while applying dynamic channel and frequency assignment to support 5G
applications. In this paper, we first propose a blockage model considering
mmWave specifications. Subsequently, using the proposed blockage model, we
derive a spatial-spectral interference model for dense finite-area 5G mmWave
networks. The proposed interference model considers both spatial and spectral
randomness in node configuration. Finally, the error performance of the network
from an arbitrarily located user perspective is calculated in terms of bit
error rate (BER) and outage probability metrics. The analytical results are
validated via Monte-Carlo simulations. It is shown that considering mmWave
specifications and also randomness in both spectral and spatial node
configurations leads to a noticeably different interference profile.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04288</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04288</id><created>2017-10-11</created><authors><author><keyname>Ravanelli</keyname><forenames>Mirco</forenames></author><author><keyname>Elizalde</keyname><forenames>Benjamin</forenames></author><author><keyname>Ni</keyname><forenames>Karl</forenames></author><author><keyname>Friedland</keyname><forenames>Gerald</forenames></author></authors><title>Audio Concept Classification with Hierarchical Deep Neural Networks</title><categories>eess.AS cs.SD</categories><journal-ref>EUSIPCO 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audio-based multimedia retrieval tasks may identify semantic information in
audio streams, i.e., audio concepts (such as music, laughter, or a revving
engine). Conventional Gaussian-Mixture-Models have had some success in
classifying a reduced set of audio concepts. However, multi-class
classification can benefit from context window analysis and the discriminating
power of deeper architectures. Although deep learning has shown promise in
various applications such as speech and object recognition, it has not yet met
the expectations for other fields such as audio concept classification. This
paper explores, for the first time, the potential of deep learning in
classifying audio concepts on User-Generated Content videos. The proposed
system is comprised of two cascaded neural networks in a hierarchical
configuration to analyze the short- and long-term context information. Our
system outperforms a GMM approach by a relative 54%, a Neural Network by 33%,
and a Deep Neural Network by 12% on the TRECVID-MED database
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04291</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04291</id><created>2017-10-11</created><authors><author><keyname>Niknam</keyname><forenames>Solmaz</forenames></author><author><keyname>Natarajan</keyname><forenames>Balasubramaniam</forenames></author><author><keyname>Mehrpouyan</keyname><forenames>Hani</forenames></author></authors><title>A Spatial-Spectral Interference Model for Millimeter Wave 5G
  Applications</title><categories>eess.SP</categories><comments>This paper has been accepted in IEEE 86th Vehicular Technology
  Conference (VTC-Fall), 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The potential of the millimeter wave (mmWave) band in meeting the ever
growing demand for high data rate and capacity in emerging fifth generation
(5G) wireless networks is well-established. Since mmWave systems are expected
to use highly directional antennas with very focused beams to overcome severe
pathloss and shadowing in this band, the nature of signal propagation in mmWave
wireless networks may differ from current networks. One factor that is
influenced by such propagation characteristics is the interference behavior,
which is also impacted by simultaneous use of the unlicensed portion of the
spectrum by multiple users. Therefore, considering the propagation
characteristics in the mmWave band, we propose a spatial-spectral interference
model for 5G mmWave applications, in the presence of Poisson field of blockages
and interferers operating in licensed and unlicensed mmWave spectrum.
Consequently, the average bit error rate of the network is calculated.
Simulation is also carried out to verify the outcomes of the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04298</identifier>
 <datestamp>2017-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04298</id><created>2017-10-11</created><authors><author><keyname>Ryf</keyname><forenames>Roland</forenames></author><author><keyname>van Weerdenburg</keyname><forenames>John</forenames></author><author><keyname>Alvarez-Aguirre</keyname><forenames>Roberto A.</forenames></author><author><keyname>Fontaine</keyname><forenames>Nicolas K.</forenames></author><author><keyname>Essiambre</keyname><forenames>Rene-Jean</forenames></author><author><keyname>Chen</keyname><forenames>Haoshuo</forenames></author><author><keyname>Alvarado-Zacarias</keyname><forenames>Juan Carlos</forenames></author><author><keyname>Amezcua-Correa</keyname><forenames>Rodrigo</forenames></author><author><keyname>Koonen</keyname><forenames>Ton</forenames></author><author><keyname>Okonkwo</keyname><forenames>Chigo</forenames></author></authors><title>White Gaussian Noise Based Capacity Estimate and Characterization of
  Fiber-Optic Links</title><categories>eess.SP</categories><comments>submitted to The Optical Networking and Communication Conference
  (OFC) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use white Gaussian noise as a test signal for single-mode and multimode
transmission links and estimate the link capacity based on a calculation of
mutual information. We also extract the complex amplitude channel estimations
and mode-dependent loss with high accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04337</identifier>
 <datestamp>2018-04-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04337</id><created>2017-10-11</created><updated>2018-04-19</updated><authors><author><keyname>Rahimian</keyname><forenames>Samira</forenames></author><author><keyname>Zhang</keyname><forenames>Wuhua</forenames></author><author><keyname>Noori</keyname><forenames>Moslem</forenames></author><author><keyname>Jing</keyname><forenames>Yindi</forenames></author><author><keyname>Ardakani</keyname><forenames>Masoud</forenames></author></authors><title>Partial Zero-Forcing for Multi-Way Relay Networks</title><categories>eess.SP</categories><doi>10.1109/TCOMM.2018.2828107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ever increasing demands for mobile network access have resulted in a
significant increase in bandwidth usage. By improving the system spectral
efficiency, multi-way relay networks (MWRNs) provide promising approaches to
address this challenge. In this paper, we propose a novel linear beamforming
design, namely partial zero-forcing (PZF), for MWRNs with a
multiple-input-multiple-output (MIMO) relay. Compared to zero-forcing (ZF), PZF
relaxes the constraints on the relay beamforming matrix such that only partial
user-interference, instead of all, is canceled at the relay. The users
eliminate the remaining interferences through self-interference and successive
interference cancellation. A sum-rate maximization problem is formulated and
solved to exploit the extra degrees-of-freedom resulted from PZF. Simulation
results show that the proposed PZF relay beamforming design achieves
significantly higher network sum-rates than the existing linear beamforming
designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04507</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04507</id><created>2017-10-11</created><authors><author><keyname>Wenhuan</keyname><forenames>Bao</forenames></author><author><keyname>Naslcheraghi</keyname><forenames>Mansour</forenames></author><author><keyname>Shikh-Bahaei</keyname><forenames>Mohammad</forenames></author></authors><title>Performance Analysis of Energy Consumption in Cache-Enabled Multicast
  D2D Communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Device-to-Device (D2D) communication as a promising technology in 5G cellular
networks provides the communication of the users in the vicinity and thereby
decreases end-to-end delay and power consumption. In addition to the
aforementioned advantages, it also supports the high-speed data transmission
services such as content delivery. In this paper, we consider the D2D multicast
communications opportunity in the D2D-cellular hybrid network, in which that
one transmitter targets multiple receivers at the same time. We provide the
analysis for the proposed system by using tools from stochastic geometry, to
calculate the cache hitting probability of the receivers as well as the energy
consumption of the hybrid network aiming to seek the optimal number of caching
contents in the D2D multicast opportunities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04735</identifier>
 <datestamp>2017-10-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.04735</id><created>2017-10-12</created><authors><author><keyname>Choudhary</keyname><forenames>Dhruv</forenames></author><author><keyname>Kejariwal</keyname><forenames>Arun</forenames></author><author><keyname>Orsini</keyname><forenames>Francois</forenames></author></authors><title>On the Runtime-Efficacy Trade-off of Anomaly Detection Techniques for
  Real-Time Streaming Data</title><categories>stat.ML cs.IR cs.LG eess.SP</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ever growing volume and velocity of data coupled with decreasing attention
span of end users underscore the critical need for real-time analytics. In this
regard, anomaly detection plays a key role as an application as well as a means
to verify data fidelity. Although the subject of anomaly detection has been
researched for over 100 years in a multitude of disciplines such as, but not
limited to, astronomy, statistics, manufacturing, econometrics, marketing, most
of the existing techniques cannot be used as is on real-time data streams.
Further, the lack of characterization of performance -- both with respect to
real-timeliness and accuracy -- on production data sets makes model selection
very challenging. To this end, we present an in-depth analysis, geared towards
real-time streaming data, of anomaly detection techniques. Given the
requirements with respect to real-timeliness and accuracy, the analysis
presented in this paper should serve as a guide for selection of the &quot;best&quot;
anomaly detection technique. To the best of our knowledge, this is the first
characterization of anomaly detection techniques proposed in very diverse set
of fields, using production data sets corresponding to a wide set of
application domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.05003</identifier>
 <datestamp>2018-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.05003</id><created>2017-10-13</created><updated>2018-04-16</updated><authors><author><keyname>Torunbalci</keyname><forenames>Mert M.</forenames></author><author><keyname>Odelberg</keyname><forenames>Trevor J.</forenames></author><author><keyname>Sridaran</keyname><forenames>Suresh</forenames></author><author><keyname>Ruby</keyname><forenames>Richard C.</forenames></author><author><keyname>Bhave</keyname><forenames>Sunil A.</forenames></author></authors><title>An FBAR Circulator</title><categories>eess.SP</categories><doi>10.1109/LMWC.2018.2815271</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter presents the experimental demonstration of a film bulk acoustic
resonator (FBAR) circulator at 2.5 GHz. The circulator is based on
spatio-temporal modulation of the series resonant frequency of FBARs using
varactors and exhibits a large isolation of 76 dB at 2.5 GHz. The FBAR chip
(0.25 mm2) consists of three identical FBARs connected in wye configuration.
The FBAR0s quality factor (Q) of 1250 and piezoelectric coupling coefficient kt
2 of 3% relaxes the modulation requirements, achieving non-reciprocity with
small modulationto- RF frequency ratio bettter than 1:800 (3 MHz:2.5 GHz).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.05111</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.05111</id><created>2017-10-13</created><updated>2017-10-24</updated><authors><author><keyname>Almasi</keyname><forenames>Mojtaba Ahmadi</forenames></author><author><keyname>Mehrpouyan</keyname><forenames>Hani</forenames></author><author><keyname>Vakilian</keyname><forenames>Vida</forenames></author><author><keyname>Behdad</keyname><forenames>Nader</forenames></author><author><keyname>Jafarkhani</keyname><forenames>Hamid</forenames></author></authors><title>Reconfigurable Antennas in mmWave MIMO Systems</title><categories>eess.SP cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The key obstacle to achieving the full potential of the millimeter wave
(mmWave) band has been the poor propagation characteristics of wireless signals
in this band. One approach to overcome this issue is to use antennas that can
support higher gains while providing beam adaptability and diversity, i.e.,
reconfigurable antennas. In this article, we present a new architecture for
mmWave multiple-input multiple-output (MIMO) communications that uses a new
class of reconfigurable antennas. More specifically, the proposed lens-based
antennas can support multiple radiation patterns while using a single radio
frequency chain. Moreover, by using a beam selection network, each antenna beam
can be steered in the desired direction. Further, using the proposed
reconfigurable antenna in a MIMO architecture, we propose a new signal
processing algorithm that uses the additional degrees of freedom provided by
the antennas to overcome propagation issues at mmWave frequencies. Our
simulation results show that the proposed reconfigurable antenna MIMO
architecture significantly enhances the performance of mmWave communication
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.05282</identifier>
 <datestamp>2018-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.05282</id><created>2017-10-15</created><updated>2018-11-23</updated><authors><author><keyname>Sun</keyname><forenames>Chen</forenames></author><author><keyname>Gao</keyname><forenames>Xiqi</forenames></author><author><keyname>Wang</keyname><forenames>Jiaheng</forenames></author><author><keyname>Ding</keyname><forenames>Zhi</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author></authors><title>Beam Domain Massive MIMO for Optical Wireless Communications with
  Transmit Lens</title><categories>eess.SP</categories><comments>To be published in IEEE Trans. Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel massive multiple-input multiple-output (MIMO)
transmission in beam domain for optical wireless communications. The optical
base station equipped with massive optical transmitters communicates with a
number of user terminals (UTs) through a transmit lens. Focusing on LED
transmitters, we analyze light refraction of the lens and establish a channel
model for optical massive MIMO transmissions. For a large number of LEDs,
channel vectors of different UTs become asymptotically orthogonal. We
investigate the maximum ratio transmission and regularized zero-forcing
precoding in the optical massive MIMO system, and propose a linear precoding
design to maximize the sum rate. We further design the precoding when the
number of transmitters grows asymptotically large, and show that beam division
multiple access (BDMA) transmission achieves the asymptotically optimal
performance for sum rate maximization. Unlike optical MIMO without a transmit
lens, BDMA can increase the sum rate proportionally to $2K$ and $K$ under the
total and per transmitter power constraints, respectively, where $K$ is the
number of UTs. In the non-asymptotic case, we prove the orthogonality
conditions of the optimal power allocation in beam domain and propose efficient
beam allocation algorithms. Numerical results confirm the significantly
improved performance of our proposed beam domain optical massive MIMO
communication approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.05315</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.05315</id><created>2017-10-15</created><authors><author><keyname>Azizi</keyname><forenames>Arman</forenames></author><author><keyname>Mokari</keyname><forenames>Nader</forenames></author><author><keyname>Javan</keyname><forenames>Mohamad Reza</forenames></author></authors><title>Joint Radio Resource Allocation, 3D Placement and User Association of
  Aerial Base Stations in IoT Networks</title><categories>eess.SP</categories><comments>10 pages, 6 figures, 3 tables, submitted to journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel method for joint radio resource allocation (RRA),
three-dimensional placement (3DP), and user association of aerial base stations
(ABSs) as a main problem in the internet of things (IoT) networks is proposed.
In our proposed model, we consider two schemes: a) line of sight (LoS) b)
generalized. In the LoS scheme, all the ABSs should see the IoT users as LoS.
In the generalized scheme, ABSs can see some of the IoT users as LoS and some
of them as NLoS. The main goal of this paper is to minimize the overal transmit
power of the IoT users while satisfying some quality of service (QoS)
constraints in uplink scenario. To solve the optimization problems and to
convert the main problems with high complexity into the subproblems with lower
complexity, we decompose them into two subproblems namely 3DP subproblem and
joint RRA and user association (JRU) subproblem. The methods which we use to
solve our proposed optimization problems are Semi Definite Relaxation (SDR) and
Geometric Programming (GP). Finally, using simulations, we evaluate the
performance of the proposed schemes for different values of the network
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.05394</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.05394</id><created>2017-10-15</created><updated>2018-01-10</updated><authors><author><keyname>Ibrahim</keyname><forenames>Shahana</forenames></author><author><keyname>Kalathil</keyname><forenames>Dileep</forenames></author><author><keyname>Sanchez</keyname><forenames>Rene O.</forenames></author><author><keyname>Varaiya</keyname><forenames>Pravin</forenames></author></authors><title>Estimating Phase Duration for SPaT Messages</title><categories>stat.AP eess.SP</categories><comments>9 Pages, 13 Figures, Under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A SPaT (Signal Phase and Timing) message describes for each lane the current
phase at a signalized intersection together with an estimate of the residual
time of that phase. Accurate SPaT messages can be used to construct a speed
profile for a vehicle that reduces its fuel consumption as it approaches or
leaves an intersection. This paper presents SPaT estimation algorithms at an
intersection with a semi-actuated signal, using real-time signal phase
measurements. The algorithms are evaluated using high-resolution data from two
intersections in Montgomery County, MD. The algorithms can be readily
implemented at signal controllers. The study supports three findings. First,
real-time information dramatically improves the accuracy of the prediction of
the residual time compared with prediction based on historical data alone.
Second, as time increases the prediction of the residual time may increase or
decrease. Third, as drivers differently weight errors in predicting `end of
green' and `end of red', drivers on two different approaches may prefer
different estimates of the residual time of the same phase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.05631</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.05631</id><created>2017-10-16</created><authors><author><keyname>Goulianos</keyname><forenames>Angelos A.</forenames></author><author><keyname>Freire</keyname><forenames>Alberto L.</forenames></author><author><keyname>Barratt</keyname><forenames>Tom</forenames></author><author><keyname>Mellios</keyname><forenames>Evangelos</forenames></author><author><keyname>Cain</keyname><forenames>Peter</forenames></author><author><keyname>Rumney</keyname><forenames>Moray</forenames></author><author><keyname>Nix</keyname><forenames>Andrew</forenames></author><author><keyname>Beach</keyname><forenames>Mark</forenames></author></authors><title>Measurements and Characterisation of Surface Scattering at 60 GHz</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the analysis and characterization of the surface
scattering process for both specular and diffused components. The study is
focused on the investigation of various building materials each having a
different roughness, at a central frequency of 60GHz. Very large signal
strength variations in first order scattered components is observed as the user
moves over very short distances. This is due to the small-scale fading caused
by rough surface scatterers. Furthermore, it is shown that the diffused
scattering depends on the material roughness, the angle of incidence and the
distance from the surface. Finally, results indicate that reflections from
rough materials may suffer from high depolarization, a phenomenon that can
potentially be exploited in order to improve the performance of mm-Wave systems
using polarization diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.05702</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.05702</id><created>2017-09-30</created><authors><author><keyname>Najafi</keyname><forenames>Marzieh</forenames></author><author><keyname>Jamali</keyname><forenames>Vahid</forenames></author><author><keyname>Diamantoulakis</keyname><forenames>Panagiotis D.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Non-Orthogonal Multiple Access for FSO Backhauling</title><categories>eess.SP</categories><comments>This paper has been submitted to IEEE WCNC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a free space optical (FSO) backhauling system which consists of
two base stations (BSs) and one central unit (CU). We propose to employ
non-orthogonal multiple access (NOMA) for FSO backhauling where both BSs
transmit at the same time and in the same frequency band to the same
photodetector at the CU. We develop a dynamic NOMA scheme which determines the
optimal decoding order as a function of the channel state information at the CU
and the quality of service requirements of the BSs, such that the outage
probabilities of both BSs are jointly minimized. Moreover, we analyze the
performance of the proposed NOMA scheme in terms of the outage probability over
Gamma-Gamma FSO turbulence channels. We further derive closed-form expressions
for the outage probability for the high signal-to-noise ratio regime. Our
simulation results confirm the analytical derivations and reveal that the
proposed dynamic NOMA scheme significantly outperforms orthogonal transmission
and existing NOMA schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.05798</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.05798</id><created>2017-10-16</created><updated>2018-05-12</updated><authors><author><keyname>Narula</keyname><forenames>Lakshay</forenames></author><author><keyname>Humphreys</keyname><forenames>Todd</forenames></author></authors><title>Requirements for Secure Clock Synchronization</title><categories>cs.CR eess.SP</categories><comments>14 pages, 9 figures, accepted for publication in IEEE Journal of
  Selected Topics in Signal Processing</comments><doi>10.1109/JSTSP.2018.2835772</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper establishes a fundamental theory of secure clock synchronization.
Accurate clock synchronization is the backbone of systems managing power
distribution, financial transactions, telecommunication operations, database
services, etc. Some clock synchronization (time transfer) systems, such as the
Global Navigation Satellite Systems (GNSS), are based on one-way communication
from a master to a slave clock. Others, such as the Network Transport Protocol
(NTP), and the IEEE 1588 Precision Time Protocol (PTP), involve two-way
communication between the master and slave. This paper shows that all one-way
time transfer protocols are vulnerable to replay attacks that can potentially
compromise timing information. A set of conditions for secure two-way clock
synchronization is proposed and proved to be necessary and sufficient. It is
shown that IEEE 1588 PTP, although a two-way synchronization protocol, is not
compliant with these conditions, and is therefore insecure. Requirements for
secure IEEE 1588 PTP are proposed, and a second example protocol is offered to
illustrate the range of compliant systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.05817</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.05817</id><created>2017-10-10</created><authors><author><keyname>Rubin</keyname><forenames>Jonathan</forenames></author><author><keyname>Parvaneh</keyname><forenames>Saman</forenames></author><author><keyname>Rahman</keyname><forenames>Asif</forenames></author><author><keyname>Conroy</keyname><forenames>Bryan</forenames></author><author><keyname>Babaeizadeh</keyname><forenames>Saeed</forenames></author></authors><title>Densely Connected Convolutional Networks and Signal Quality Analysis to
  Detect Atrial Fibrillation Using Short Single-Lead ECG Recordings</title><categories>eess.SP cs.CV stat.ML</categories><comments>Computing in Cardiology 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of new technology such as wearables that record high-quality
single channel ECG, provides an opportunity for ECG screening in a larger
population, especially for atrial fibrillation screening. The main goal of this
study is to develop an automatic classification algorithm for normal sinus
rhythm (NSR), atrial fibrillation (AF), other rhythms (O), and noise from a
single channel short ECG segment (9-60 seconds). For this purpose, signal
quality index (SQI) along with dense convolutional neural networks was used.
Two convolutional neural network (CNN) models (main model that accepts 15
seconds ECG and secondary model that processes 9 seconds shorter ECG) were
trained using the training data set. If the recording is determined to be of
low quality by SQI, it is immediately classified as noisy. Otherwise, it is
transformed to a time-frequency representation and classified with the CNN as
NSR, AF, O, or noise. At the final step, a feature-based post-processing
algorithm classifies the rhythm as either NSR or O in case the CNN model's
discrimination between the two is indeterminate. The best result achieved at
the official phase of the PhysioNet/CinC challenge on the blind test set was
0.80 (F1 for NSR, AF, and O were 0.90, 0.80, and 0.70, respectively).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.05985</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.05985</id><created>2017-10-10</created><updated>2018-02-28</updated><authors><author><keyname>Yaroslavsky</keyname><forenames>Leonid P.</forenames></author></authors><title>Compressed Sensing, ASBSR-method of image sampling and reconstruction
  and the problem of digital image acquisition with the lowest possible
  sampling rate</title><categories>cs.CV eess.IV</categories><comments>28 pages, 19 figures</comments><journal-ref>Compressed Sensing: Methods, Theory and Applications, Chapt.1.,
  Ed. Jonathon M. Sheppard, Nova Publishers, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of minimization of the number of measurements needed for digital
image acquisition and reconstruction with a given accuracy is addressed. Basics
of the sampling theory are outlined to show that the lower bound of signal
sampling rate sufficient for signal reconstruction with a given accuracy is
equal to the spectrum sparsity of the signal sparse approximation that has this
accuracy. It is revealed that the compressed sensing approach, which was
advanced as a solution to the sampling rate minimization problem, is far from
reaching the sampling rate theoretical minimum. Potentials and limitations of
compressed sensing are demystified using a simple and intutive model, A method
of image Arbitrary Sampling and Bounded Spectrum Reconstruction (ASBSR-method)
is described that allows to draw near the image sampling rate theoretical
minimum. Presented and discussed are also results of experimental verification
of the ASBSR-method and its possible applicability extensions to solving
various underdetermined inverse problems such as color image demosaicing, image
in-painting, image reconstruction from their sparsely sampled or decimated
projections, image reconstruction from the modulus of its Fourier spectrum, and
image reconstruction from its sparse samples in Fourier domain
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06043</identifier>
 <datestamp>2017-10-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06043</id><created>2017-10-16</created><authors><author><keyname>Hu</keyname><forenames>Shuyan</forenames></author><author><keyname>Xu</keyname><forenames>Chongbin</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Huang</keyname><forenames>Yongwei</forenames></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author></authors><title>Distributed Coordinated Multicell Beamforming for Wireless Cellular
  Networks Powered by Renewables: A Stochastic ADMM Approach</title><categories>eess.SP</categories><comments>11 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The integration of renewable energy sources (RES) has facilitated efficient
and sustainable resource allocation for wireless communication systems. In this
paper, a novel framework is introduced to develop coordinated multicell
beamforming (CMBF) design for wireless cellular networks powered by a smart
microgrid, where the BSs are equipped with RES harvesting devices and can
perform two-way (i.e., buying/selling) energy trading with the main grid. To
this end, new models are put forth to account for the stochastic RES
harvesting, two-way energy trading, and conditional value-at-risk (CVaR) based
energy transaction cost. Capitalizing on these models, we propose a distributed
CMBF solution to minimize the grid-wide transaction cost subject to user
quality-of-service (QoS) constraints. Specifically, relying on state-of-the-art
optimization tools, we show that the relevant task can be formulated as a
convex problem that is well suited for development of a distributed solver. To
cope with stochastic availability of the RES, the stochastic alternating
direction method of multipliers (ADMM) is then leveraged to develop a novel
distributed CMBF scheme. It is established that the proposed scheme is
guaranteed to yield the optimal CMBF solution, with only local channel state
information available at each BS and limited information exchange among the
BSs. Numerical results are provided to corroborate the merits of the proposed
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06142</identifier>
 <datestamp>2018-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06142</id><created>2017-10-17</created><updated>2018-10-05</updated><authors><author><keyname>Jang</keyname><forenames>Jehyuk</forenames></author><author><keyname>Im</keyname><forenames>Sanghun</forenames></author><author><keyname>Lee</keyname><forenames>Heung-No</forenames></author></authors><title>Intentional Aliasing Method to Improve Sub-Nyquist Sampling System</title><categories>eess.SP</categories><comments>13 pages with 6 figures, published in IEEE Trans. signal Process</comments><journal-ref>Jehyuk Jang, Sanghun Im, and Heung-No Lee, &quot;Intentional aliasing
  method to improve sub-Nyquist sampling system,&quot; IEEE Transactions on Signal
  Processing, pp. 3311-3326, Vol. 66, No. 12, Jun. 2018</journal-ref><doi>10.1109/TSP.2018.2824257</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A modulated wideband converter (MWC) has been introduced as a sub-Nyquist
sampler that exploits a set of fast alternating pseudo random (PR) signals.
Through parallel sampling branches, an MWC compresses a multiband spectrum by
mixing it with PR signals in the time domain, and acquires its sub-Nyquist
samples. Previously, the ratio of compression was fully dependent on the
specifications of PR signals. That is, to further reduce the sampling rate
without information loss, faster and longer-period PR signals were needed.
However, the implementation of such PR signal generators results in high power
consumption and large fabrication area. In this paper, we propose a novel
aliased modulated wideband converter (AMWC), which can further reduce the
sampling rate of MWC with fixed PR signals. The main idea is to induce
intentional signal aliasing at the analog-to-digital converter (ADC). In
addition to the first spectral compression by the signal mixer, the intentional
aliasing compresses the mixed spectrum once again. We demonstrate that AMWC
reduces the number of sampling branches and the rate of ADC for lossless
sub-Nyquist sampling without needing to upgrade the speed or period of PR
signals. Conversely, for a given fixed number of sampling branches and sampling
rate, AMWC improves the performance of signal reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06304</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06304</id><created>2017-10-17</created><authors><author><keyname>Vedula</keyname><forenames>Sanketh</forenames></author><author><keyname>Senouf</keyname><forenames>Ortal</forenames></author><author><keyname>Bronstein</keyname><forenames>Alex M.</forenames></author><author><keyname>Michailovich</keyname><forenames>Oleg V.</forenames></author><author><keyname>Zibulevsky</keyname><forenames>Michael</forenames></author></authors><title>Towards CT-quality Ultrasound Imaging using Deep Learning</title><categories>cs.CV eess.IV physics.med-ph</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The cost-effectiveness and practical harmlessness of ultrasound imaging have
made it one of the most widespread tools for medical diagnosis. Unfortunately,
the beam-forming based image formation produces granular speckle noise,
blurring, shading and other artifacts. To overcome these effects, the ultimate
goal would be to reconstruct the tissue acoustic properties by solving a full
wave propagation inverse problem. In this work, we make a step towards this
goal, using Multi-Resolution Convolutional Neural Networks (CNN). As a result,
we are able to reconstruct CT-quality images from the reflected ultrasound
radio-frequency(RF) data obtained by simulation from real CT scans of a human
body. We also show that CNN is able to imitate existing computationally heavy
despeckling methods, thereby saving orders of magnitude in computations and
making them amenable to real-time applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06319</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06319</id><created>2017-10-17</created><updated>2017-10-24</updated><authors><author><keyname>Schwab</keyname><forenames>Patrick</forenames></author><author><keyname>Scebba</keyname><forenames>Gaetano</forenames></author><author><keyname>Zhang</keyname><forenames>Jia</forenames></author><author><keyname>Delai</keyname><forenames>Marco</forenames></author><author><keyname>Karlen</keyname><forenames>Walter</forenames></author></authors><title>Beat by Beat: Classifying Cardiac Arrhythmias with Recurrent Neural
  Networks</title><categories>cs.LG cs.CV eess.SP</categories><comments>Accepted at Computing in Cardiology (CinC) 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With tens of thousands of electrocardiogram (ECG) records processed by mobile
cardiac event recorders every day, heart rhythm classification algorithms are
an important tool for the continuous monitoring of patients at risk. We utilise
an annotated dataset of 12,186 single-lead ECG recordings to build a diverse
ensemble of recurrent neural networks (RNNs) that is able to distinguish
between normal sinus rhythms, atrial fibrillation, other types of arrhythmia
and signals that are too noisy to interpret. In order to ease learning over the
temporal dimension, we introduce a novel task formulation that harnesses the
natural segmentation of ECG signals into heartbeats to drastically reduce the
number of time steps per sequence. Additionally, we extend our RNNs with an
attention mechanism that enables us to reason about which heartbeats our RNNs
focus on to make their decisions. Through the use of attention, our model
maintains a high degree of interpretability, while also achieving
state-of-the-art classification performance with an average F1 score of 0.79 on
an unseen test set (n=3,658).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06420</identifier>
 <datestamp>2018-03-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06420</id><created>2017-10-15</created><updated>2018-03-02</updated><authors><author><keyname>Scheufele</keyname><forenames>Klaudius</forenames></author><author><keyname>Mang</keyname><forenames>Andreas</forenames></author><author><keyname>Gholami</keyname><forenames>Amir</forenames></author><author><keyname>Davatzikos</keyname><forenames>Christos</forenames></author><author><keyname>Biros</keyname><forenames>George</forenames></author><author><keyname>Mehl</keyname><forenames>Miriam</forenames></author></authors><title>Coupling Brain-Tumor Biophysical Models and Diffeomorphic Image
  Registration</title><categories>physics.med-ph eess.IV math.OC q-bio.TO</categories><comments>38 pages, 19 figures</comments><msc-class>49K20, 49M15, 35K57, 65K10, 68W10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the SIBIA (Scalable Integrated Biophysics-based Image Analysis)
framework for joint image registration and biophysical inversion and we apply
it to analyse MR images of glioblastomas (primary brain tumors). In particular,
we consider the following problem. Given the segmentation of a normal brain MRI
and the segmentation of a cancer patient MRI, we wish to determine tumor growth
parameters and a registration map so that if we &quot;grow a tumor&quot; (using our tumor
model) in the normal segmented image and then register it to the patient
segmented image, then the registration mismatch is as small as possible. We
call this &quot;the coupled problem&quot; because it two-way couples the biophysical
inversion and registration problems. In the image registration step we solve a
large-deformation diffeomorphic registration problem parameterized by an
Eulerian velocity field. In the biophysical inversion step we estimate
parameters in a reaction-diffusion tumor growth model that is formulated as a
partial differential equation.
  In this paper, our contributions are the introduction of a PDE-constrained
optimization formulation of the coupled problem, the derivation of the
optimality conditions, and the derivation of a Picard iterative scheme for the
solution of the coupled problem. In addition, we perform several tests to
experimentally assess the performance of our method on synthetic and clinical
datasets. We demonstrate the convergence of the SIBIA optimization solver in
different usage scenarios. We demonstrate that we can accurately solve the
coupled problem in three dimensions ($256^3$ resolution) in a few minutes using
11 dual-x86 nodes. Also, we demonstrate that, with our coupled approach, we can
successfully register normal MRI to tumor-bearing MRI while obtaining Dice
coefficients that match those achieved when registering of normal-to-normal
MRI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06531</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06531</id><created>2017-10-17</created><authors><author><keyname>Rosas</keyname><forenames>Fernando</forenames></author><author><keyname>Chen</keyname><forenames>Kwang-Cheng</forenames></author></authors><title>Social Learning Against Data Falsification in Sensor Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although surveillance and sensor networks play a key role in Internet of
Things, sensor nodes are usually vulnerable to tampering due to their
widespread locations. In this letter we consider data falsification attacks
where an smart attacker takes control of critical nodes within the network,
including nodes serving as fusion centers. In order to face this critical
security thread, we propose a data aggregation scheme based on social learning,
resembling the way in which agents make decisions in social networks. Our
results suggest that social learning enables network resilience, even when a
significant portion of the nodes have been compromised by the attacker.
Finally, we show the suitability of our scheme to sensor networks by developing
a low-complexity algorithm to facilitate the social learning data fusion rule
in devices with restricted computational power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06541</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06541</id><created>2017-10-17</created><authors><author><keyname>Chang</keyname><forenames>Gregory</forenames></author><author><keyname>Maity</keyname><forenames>Shovan</forenames></author><author><keyname>Chatterjee</keyname><forenames>Baibhab</forenames></author><author><keyname>Sen</keyname><forenames>Shreyas</forenames></author></authors><title>Design Considerations of a Sub-50 {\mu}W Receiver Front-end for
  Implantable Devices in MedRadio Band</title><categories>cs.NI eess.SP</categories><comments>Accepted to appear on International Conference on VLSI Design 2018
  (VLSID)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emerging health-monitor applications, such as information transmission
through multi-channel neural implants, image and video communication from
inside the body etc., calls for ultra-low active power (&lt;50${\mu}$W) high
data-rate, energy-scalable, highly energy-efficient (pJ/bit) radios. Previous
literature has strongly focused on low average power duty-cycled radios or low
power but low-date radios. In this paper, we investigate power performance
trade-off of each front-end component in a conventional radio including active
matching, down-conversion and RF/IF amplification and prioritize them based on
highest performance/energy metric. The analysis reveals 50${\Omega}$ active
matching and RF gain is prohibitive for 50${\mu}$W power-budget. A mixer-first
architecture with an N-path mixer and a self-biased inverter based baseband
LNA, designed in TSMC 65nm technology show that sub 50${\mu}$W performance can
be achieved up to 10Mbps (&lt; 5pJ/b) with OOK modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06619</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06619</id><created>2017-10-18</created><authors><author><keyname>Farah</keyname><forenames>Joumana</forenames></author><author><keyname>Kilzi</keyname><forenames>Antoine</forenames></author><author><keyname>Nour</keyname><forenames>Charbel Abdel</forenames></author><author><keyname>Douillard</keyname><forenames>Catherine</forenames></author></authors><title>Power Minimization Techniques in Distributed Base Station Antenna
  Systems using Non-Orthogonal Multiple Access</title><categories>eess.SP</categories><comments>Submitted paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces new approaches for combining non-orthogonal multiple
access (NOMA) with distributed base station (DBS) deployments. The purpose of
the study is to unlock the true potentials of DBS systems in the NOMA context,
since all previous works dealing with power minimization in NOMA are performed
in the CBS (centralized base station) context. This work targets a minimization
of the total transmit power in each cell, under user rate and power
multiplexing constraints. Different techniques are designed for the joint
allocation of subcarriers, antennas and power, with a particular care given to
insuring a moderate complexity. Results show an important gain in the total
transmit power obtained by the DBS-NOMA combination, with respect to both
DBS-OMA (orthogonal multiple access) and CBS-NOMA deployment scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06648</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06648</id><created>2017-10-18</created><updated>2018-06-18</updated><authors><author><keyname>Park</keyname><forenames>Jiyoung</forenames></author><author><keyname>Lee</keyname><forenames>Jongpil</forenames></author><author><keyname>Park</keyname><forenames>Jangyeon</forenames></author><author><keyname>Ha</keyname><forenames>Jung-Woo</forenames></author><author><keyname>Nam</keyname><forenames>Juhan</forenames></author></authors><title>Representation Learning of Music Using Artist Labels</title><categories>cs.SD eess.AS</categories><comments>19th International Society for Music Information Retrieval Conference
  (ISMIR), 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In music domain, feature learning has been conducted mainly in two ways:
unsupervised learning based on sparse representations or supervised learning by
semantic labels such as music genre. However, finding discriminative features
in an unsupervised way is challenging and supervised feature learning using
semantic labels may involve noisy or expensive annotation. In this paper, we
present a supervised feature learning approach using artist labels annotated in
every single track as objective meta data. We propose two deep convolutional
neural networks (DCNN) to learn the deep artist features. One is a plain DCNN
trained with the whole artist labels simultaneously, and the other is a Siamese
DCNN trained with a subset of the artist labels based on the artist identity.
We apply the trained models to music classification and retrieval tasks in
transfer learning settings. The results show that our approach is comparable to
previous state-of-the-art methods, indicating that the proposed approach
captures general music audio features as much as the models learned with
semantic labels. Also, we discuss the advantages and disadvantages of the two
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06655</identifier>
 <datestamp>2018-05-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06655</id><created>2017-10-18</created><updated>2018-05-11</updated><authors><author><keyname>Han</keyname><forenames>Bin</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>A Fast Blind Impulse Detector for Bernoulli-Gaussian Noise in
  Underspread Channel</title><categories>eess.SP</categories><comments>v2 to appear in IEEE ICC 2018, Kansas City, MO, USA, May 2018 Minor
  erratums added in v3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Bernoulli-Gaussian (BG) model is practical to characterize impulsive
noises that widely exist in various communication systems. To estimate the BG
model parameters from noise measurements, a precise impulse detection is
essential. In this paper, we propose a novel blind impulse detector, which is
proven to be fast and accurate for BG noise in underspread communication
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06895</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06895</id><created>2017-10-02</created><authors><author><keyname>Mahoor</keyname><forenames>Mohsen</forenames></author><author><keyname>Hosseini</keyname><forenames>Zohreh S.</forenames></author><author><keyname>Khodaei</keyname><forenames>Amin</forenames></author><author><keyname>Kushner</keyname><forenames>D.</forenames></author></authors><title>Electric Vehicle Battery Swapping Station</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing adequate charging infrastructure plays a momentous role in rapid
proliferation of Electric Vehicles (EVs). Easy access to such infrastructure
would remove various obstacles regarding limited EV mobility range. A Battery
Swapping Station (BSS) is an effective approach in supplying power to the EVs,
while mitigating long waiting times in a Battery Charging Station (BCS). In
contrast with the BCS, the BSS charges the batteries in advance and prepares
them to be swapped in a considerably short time. Considering that these
stations can serve as an intermediate entity between the EV owners and the
power system, they can potentially provide unique benefits to the power system.
This paper investigates the advantages of building the BSS from various
perspectives. Accordingly, a model for the scheduling of battery charging from
the station owner perspective is proposed. An illustrative example is provided
to show how the proposed model would help BSS owners in managing their assets
through scheduling battery charging time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.06925</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.06925</id><created>2017-10-18</created><authors><author><keyname>Sodergren</keyname><forenames>Tim</forenames></author><author><keyname>Hair</keyname><forenames>Jessica</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Wang</keyname><forenames>Bei</forenames></author></authors><title>Visualizing Sensor Network Coverage with Location Uncertainty</title><categories>cs.HC eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an interactive visualization system for exploring the coverage in
sensor networks with uncertain sensor locations. We consider a simple case of
uncertainty where the location of each sensor is confined to a discrete number
of points sampled uniformly at random from a region with a fixed radius.
Employing techniques from topological data analysis, we model and visualize
network coverage by quantifying the uncertainty defined on its simplicial
complex representations. We demonstrate the capabilities and effectiveness of
our tool via the exploration of randomly distributed sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.07052</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.07052</id><created>2017-10-19</created><authors><author><keyname>De Angelis</keyname><forenames>Alessio</forenames></author><author><keyname>Moschitta</keyname><forenames>Antonio</forenames></author><author><keyname>Comuniello</keyname><forenames>Antonella</forenames></author></authors><title>TDoA Based Positioning using Ultrasound Signals and Wireless Nodes</title><categories>eess.SP</categories><comments>Preprint</comments><journal-ref>2017 IEEE International Instrumentation and Measurement Technology
  Conference (I2MTC)</journal-ref><doi>10.1109/I2MTC.2017.7969873</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a positioning technique based on Time Difference of Arrival
(TDoA) measurements is analyzed. The proposed approach is designed to consent
range and position estimation, using ultrasound transmissions of a stream of
chirp pulses, received by a set of wireless nodes. A potential source of
inaccuracy introduced by lack of synchronization between transmitting node and
receiving nodes is identified and characterized. An algorithm to identify and
correct such inaccuracies is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.07054</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.07054</id><created>2017-10-19</created><authors><author><keyname>Moschitta</keyname><forenames>Antonio</forenames></author><author><keyname>De Angelis</keyname><forenames>Alessio</forenames></author><author><keyname>Santoni</keyname><forenames>Francesco</forenames></author><author><keyname>Dionigi</keyname><forenames>Marco</forenames></author><author><keyname>Carbone</keyname><forenames>Paolo</forenames></author><author><keyname>De Angelis</keyname><forenames>Guido</forenames></author></authors><title>Accurate Estimation of a Coil Magnetic Dipole Moment</title><categories>eess.SP</categories><comments>Preprint</comments><journal-ref>2017 IEEE International Workshop on Measurement and Networking
  (M&amp;N), Naples, 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a technique for accurate estimation of the moment of magnetic
dipole is proposed. The achievable accuracy is investigated, as a function of
measurement noise affecting estimation of magnetic field cartesian components.
The proposed technique is validated both via simulations and experimentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.07056</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.07056</id><created>2017-10-19</created><authors><author><keyname>De Angelis</keyname><forenames>Alessio</forenames></author><author><keyname>Carbone</keyname><forenames>Paolo</forenames></author><author><keyname>Dionigi</keyname><forenames>Marco</forenames></author><author><keyname>Di Giacomo</keyname><forenames>Emilio</forenames></author><author><keyname>Stoppini</keyname><forenames>Aurelio</forenames></author><author><keyname>Radicioni</keyname><forenames>Fabio</forenames></author><author><keyname>Tombesi</keyname><forenames>Enrico</forenames></author></authors><title>An Interactive System for Exhibitions in a Science and Technology Center</title><categories>eess.SP</categories><comments>Preprint</comments><journal-ref>IEEE International Symposium on Systems Engineering (ISSE),
  Vienna, Austria, October 11-13, 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the development of a system for realizing interactive
exhibitions in the context of a science and technology center. The core
functionality of the system is provided by a positioning subsystem comprised of
a fixed infrastructure of transmitters and a sensor worn by a user. The
operating principle of the positioning system is based on inductive coupling of
resonators. Information about the position of the user is transferred to an
information system for processing and displaying. Possible use cases include
interactive games, information retrieval interfaces and educational scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.07067</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.07067</id><created>2017-10-19</created><authors><author><keyname>De Angelis</keyname><forenames>A.</forenames></author><author><keyname>Schoukens</keyname><forenames>J.</forenames></author><author><keyname>Godfrey</keyname><forenames>K. R.</forenames></author><author><keyname>Carbone</keyname><forenames>P.</forenames></author></authors><title>Best Linear Approximation of Wiener Systems Using Multilevel Signals:
  Theory and Experiments</title><categories>eess.SP cs.NA cs.SY</categories><comments>Accepted for Publication in IEEE Transactions on Instrumentation and
  Measurement</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of measuring the best linear approximation of a nonlinear system
by means of multilevel excitation sequences is analyzed. A comparison between
different types of sequences applied at the input of Wiener systems is provided
by numerical simulations and by experiments on a practical circuit including an
analog filter and a clipping nonlinearity. The performance of the sequences is
compared with a white Gaussian noise signal for reference purposes. The
theoretical characterization of the best linear approximation when using
randomized constrained sequences is derived analytically for the cubic
nonlinearity case. Numerical and experimental results show that the randomized
constrained approach for designing ternary sequences has a low sensitivity to
both even and odd order nonlinearities, resulting in a response close to the
actual response of the underlying linear system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.07654</identifier>
 <datestamp>2018-02-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.07654</id><created>2017-10-20</created><updated>2018-02-22</updated><authors><author><keyname>Ping</keyname><forenames>Wei</forenames></author><author><keyname>Peng</keyname><forenames>Kainan</forenames></author><author><keyname>Gibiansky</keyname><forenames>Andrew</forenames></author><author><keyname>Arik</keyname><forenames>Sercan O.</forenames></author><author><keyname>Kannan</keyname><forenames>Ajay</forenames></author><author><keyname>Narang</keyname><forenames>Sharan</forenames></author><author><keyname>Raiman</keyname><forenames>Jonathan</forenames></author><author><keyname>Miller</keyname><forenames>John</forenames></author></authors><title>Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence
  Learning</title><categories>cs.SD cs.AI cs.CL cs.LG eess.AS</categories><comments>Published as a conference paper at ICLR 2018. (v3 changed paper
  title)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Deep Voice 3, a fully-convolutional attention-based neural
text-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural
speech synthesis systems in naturalness while training ten times faster. We
scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more
than eight hundred hours of audio from over two thousand speakers. In addition,
we identify common error modes of attention-based speech synthesis networks,
demonstrate how to mitigate them, and compare several different waveform
synthesis methods. We also describe how to scale inference to ten million
queries per day on one single-GPU server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.07837</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.07837</id><created>2017-10-21</created><authors><author><keyname>Levine</keyname><forenames>Evan</forenames></author><author><keyname>Hargreaves</keyname><forenames>Brian</forenames></author></authors><title>On-the-fly Adaptive $k$-Space Sampling for Linear MRI Reconstruction
  Using Moment-Based Spectral Analysis</title><categories>eess.IV</categories><comments>12 pages, 8 figures, Submitted to IEEE Transactions on Medical
  Imaging</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In high-dimensional magnetic resonance imaging applications, time-consuming,
sequential acquisition of data samples in the spatial frequency domain
($k$-space) can often be accelerated by accounting for dependencies along
imaging dimensions other than space in linear reconstruction, at the cost of
noise amplification that depends on the sampling pattern. Examples are
support-constrained, parallel, and dynamic MRI, and $k$-space sampling
strategies are primarily driven by image-domain metrics that are expensive to
compute for arbitrary sampling patterns. It remains challenging to provide
systematic and computationally efficient automatic designs of arbitrary
multidimensional Cartesian sampling patterns that mitigate noise amplification,
given the subspace to which the object is confined. To address this problem,
this work introduces a theoretical framework that describes local geometric
properties of the sampling pattern and relates these properties to a measure of
the spread in the eigenvalues of the information matrix described by its first
two spectral moments. This new criterion is then used for very efficient
optimization of complex multidimensional sampling patterns that does not
require reconstructing images or explicitly mapping noise amplification.
Experiments with in vivo data show strong agreement between this criterion and
traditional, comprehensive image-domain- and $k$-space-based metrics,
indicating the potential of the approach for computationally efficient
(on-the-fly), automatic, and adaptive design of sampling patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.07849</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.07849</id><created>2017-10-21</created><authors><author><keyname>Chung</keyname><forenames>Moo K.</forenames></author><author><keyname>Wang</keyname><forenames>Yanli</forenames></author><author><keyname>Wu</keyname><forenames>Gurong</forenames></author></authors><title>Heat Kernel Smoothing in Irregular Image Domains</title><categories>stat.ME cs.CV eess.IV stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the discrete version of heat kernel smoothing on graph data
structure. The method is used to smooth data in an irregularly shaped domains
in 3D images.
  New statistical properties are derived. As an application, we show how to
filter out data in the lung blood vessel trees obtained from computed
tomography. The method can be further used in representing the complex vessel
trees parametrically and extracting the skeleton representation of the trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.07868</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.07868</id><created>2017-10-21</created><updated>2017-10-24</updated><authors><author><keyname>Yadav</keyname><forenames>Mohit</forenames></author><author><keyname>Tyagi</keyname><forenames>Vivek</forenames></author></authors><title>Deep Triphone Embedding Improves Phoneme Recognition</title><categories>cs.SD cs.CL cs.LG eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel Deep Triphone Embedding (DTE)
representation derived from Deep Neural Network (DNN) to encapsulate the
discriminative information present in the adjoining speech frames. DTEs are
generated using a four hidden layer DNN with 3000 nodes in each hidden layer at
the first-stage. This DNN is trained with the tied-triphone classification
accuracy as an optimization criterion. Thereafter, we retain the activation
vectors (3000) of the last hidden layer, for each speech MFCC frame, and
perform dimension reduction to further obtain a 300 dimensional representation,
which we termed as DTE. DTEs along with MFCC features are fed into a
second-stage four hidden layer DNN, which is subsequently trained for the task
of tied-triphone classification. Both DNNs are trained using tri-phone labels
generated from a tied-state triphone HMM-GMM system, by performing a
forced-alignment between the transcriptions and MFCC feature frames. We conduct
the experiments on publicly available TED-LIUM speech corpus. The results show
that the proposed DTE method provides an improvement of absolute 2.11% in
phoneme recognition, when compared with a competitive hybrid tied-state
triphone HMM-DNN system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.07985</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.07985</id><created>2017-10-22</created><authors><author><keyname>Nangir</keyname><forenames>Mahdi</forenames></author><author><keyname>Ahmadian-Attari</keyname><forenames>Mahmoud</forenames></author><author><keyname>Asvadi</keyname><forenames>Reza</forenames></author></authors><title>A Binary Wyner-Ziv Code Design Based on Compound LDGM-LDPC Structures</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a practical coding scheme is designed for the binary Wyner-Ziv
(WZ) problem by using nested low-density generator-matrix (LDGM) and
low-density parity-check (LDPC) codes. This scheme contains two steps in the
encoding procedure. The first step involves applying the binary quantization by
employing LDGM codes and the second one is using the syndrome-coding technique
by utilizing LDPC codes. The decoding algorithm of the proposed scheme is based
on the Sum-Product (SP) algorithm with the help of a side information available
at the decoder side. It is theoretically shown that the compound structure has
the capability of achieving the WZ bound. The proposed method approaches this
bound by utilizing the iterative message-passing algorithms in both encoding
and decoding, although theoretical results show that it is asymptotically
achievable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08037</identifier>
 <datestamp>2018-06-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08037</id><created>2017-10-22</created><updated>2018-06-28</updated><authors><author><keyname>Bru&#xf1;a</keyname><forenames>Ricardo</forenames></author><author><keyname>Maest&#xfa;</keyname><forenames>Fernando</forenames></author><author><keyname>Pereda</keyname><forenames>Ernesto</forenames></author></authors><title>Phase Locking Value revisited: teaching new tricks to an old dog</title><categories>eess.SP nlin.CD physics.data-an q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the increase in calculation power in the last decades, the estimation
of brain connectivity is still a tedious task. The high computational cost of
the algorithms escalates with the square of the number of signals evaluated,
usually in the range of thousands. In this work we propose a re-formulation of
a widely used algorithm that allows the estimation of whole brain connectivity
in much smaller times. We start from the original implementation of Phase
Locking Value (PLV) and re-formulated it in a highly computational efficient
way. Besides, this formulation stresses its strong similarity with coherence,
which we used to introduce two new metrics insensitive to zero lag
synchronization, the imaginary part of PLV (iPLV) and its corrected counterpart
(ciPLV). The new implementation of PLV avoids some highly CPU-expensive
operations, and achieved a 100-fold speedup over the original algorithm. The
new derived metrics were highly robust in the presence of volume conduction.
ciPLV, in particular, proved capable of ignoring zero-lag connectivity, while
correctly estimating nonzero-lag connectivity. Our implementation of PLV makes
it possible to calculate whole-brain connectivity in much shorter times. The
results of the simulations using ciPLV suggest that this metric is ideal to
measure synchronization in the presence of volume conduction or source leakage
effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08062</identifier>
 <datestamp>2018-10-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08062</id><created>2017-10-22</created><updated>2018-10-01</updated><authors><author><keyname>Zhao</keyname><forenames>Bo</forenames></author><author><keyname>Haldar</keyname><forenames>Justin P.</forenames></author><author><keyname>Liao</keyname><forenames>Congyu</forenames></author><author><keyname>Ma</keyname><forenames>Dan</forenames></author><author><keyname>Jiang</keyname><forenames>Yun</forenames></author><author><keyname>Griswold</keyname><forenames>Mark A.</forenames></author><author><keyname>Setsompop</keyname><forenames>Kawin</forenames></author><author><keyname>Wald</keyname><forenames>Lawrence L.</forenames></author></authors><title>Optimal Experiment Design for Magnetic Resonance Fingerprinting:
  Cram\'er-Rao Bound Meets Spin Dynamics</title><categories>eess.SP</categories><comments>Manuscript accepted by the IEEE Transactions on Medical Imaging (18
  pages, 17 figures)</comments><doi>10.1109/TMI.2018.2873704</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance (MR) fingerprinting is a new quantitative imaging
paradigm, which simultaneously acquires multiple MR tissue parameter maps in a
single experiment. In this paper, we present an estimation-theoretic framework
to perform experiment design for MR fingerprinting. Specifically, we describe a
discrete-time dynamic system to model spin dynamics, and derive an
estimation-theoretic bound, i.e., the Cramer-Rao bound (CRB), to characterize
the signal-to-noise ratio (SNR) efficiency of an MR fingerprinting experiment.
We then formulate an optimal experiment design problem, which determines a
sequence of acquisition parameters to encode MR tissue parameters with the
maximal SNR efficiency, while respecting the physical constraints and other
constraints from the image decoding/reconstruction process. We evaluate the
performance of the proposed approach with numerical simulations, phantom
experiments, and in vivo experiments. We demonstrate that the optimized
experiments substantially reduce data acquisition time and/or improve parameter
estimation. For example, the optimized experiments achieve about a factor of
two improvement in the accuracy of $T_2$ maps, while keeping similar or
slightly better accuracy of $T_1$ maps. Finally, as a remarkable observation,
we find that the sequence of optimized acquisition parameters appears to be
highly structured rather than randomly/pseudo-randomly varying as is prescribed
in the conventional MR fingerprinting experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08286</identifier>
 <datestamp>2018-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08286</id><created>2017-10-23</created><updated>2017-10-24</updated><authors><author><keyname>Ibanez-Soria</keyname><forenames>D</forenames></author><author><keyname>Garcia-Ojalvo</keyname><forenames>J</forenames></author><author><keyname>Soria-Frisch</keyname><forenames>A</forenames></author><author><keyname>Ruffini</keyname><forenames>G</forenames></author></authors><title>Detection of Generalized Synchronization using Echo State Networks</title><categories>nlin.CD cs.ET eess.SP</categories><doi>10.1063/1.5010285</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalized synchronization between coupled dynamical systems is a phenomenon
of relevance in applications that range from secure communications to
physiological modelling. Here we test the capabilities of reservoir computing
and, in particular, echo state networks for the detection of generalized
synchronization. A nonlinear dynamical system consisting of two coupled
R\&quot;ossler chaotic attractors is used to generate temporal series consisting of
time-locked generalized synchronized sequences interleaved by unsynchronized
ones. Correctly tuned, echo state networks are able to efficiently discriminate
between unsynchronized and synchronized sequences. Compared to other
state-of-the-art techniques of synchronization detection, the online
capabilities of the proposed ESN based methodology make it a promising choice
for real-time applications aiming to monitor dynamical synchronization changes
in continuous signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08336</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08336</id><created>2017-10-19</created><authors><author><keyname>Rashidi</keyname><forenames>Bahram</forenames></author></authors><title>A Survey on Hardware Implementations of Elliptic Curve Cryptosystems</title><categories>eess.SP cs.AR</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In the past two decades, Elliptic Curve Cryptography (ECC) have become
increasingly advanced. ECC, with much smaller key sizes, offers equivalent
security when compared to other asymmetric cryptosystems. In this survey, an
comprehensive overview of hardware implementations of ECC is provided. We first
discuss different elliptic curves, point multiplication algorithms and
underling finite field operations over binary fields F2m and prime fields Fp
which are used in the literature for hardware implementation. Then methods,
steps and considerations of ECC implementation are presented. The
implementations of the ECC are categorized in two main groups based on
implementation technologies consist of field programmable gate array (FPGA)
based implementations and application specific integrated circuit (ASIC)
implementations. Therefore, in these categories to have a better presentation
and comparison, the implementations are presented and distinguished based on
type of finite fields. The best and newest structures in the literature are
described in more details for overall presentation of architectures and
approaches in each group of implementations. High-speed implementation is an
important factor in the ECC applications such as network servers. Also in smart
cards, Wireless Sensor Networks (WSN) and Radio Frequency Identification (RFID)
tags require to low-cost and lightweight implementations. Therefore,
implementation methods related to these applications are explored. In addition,
a classification of the previous works in terms of scalability, flexibility,
performance and cost effectiveness is provided. Finally, some words and
techniques about future works that should be considered are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08354</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08354</id><created>2017-10-23</created><authors><author><keyname>Lucena</keyname><forenames>Oeslle</forenames></author><author><keyname>Souza</keyname><forenames>Roberto</forenames></author><author><keyname>Rittner</keyname><forenames>Let&#xed;cia</forenames></author><author><keyname>Frayne</keyname><forenames>Richard</forenames></author><author><keyname>Lotufo</keyname><forenames>Roberto</forenames></author></authors><title>Silver Standard Masks for Data Augmentation Applied to
  Deep-Learning-Based Skull-Stripping</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bottleneck of convolutional neural networks (CNN) for medical imaging is
the number of annotated data required for training. Manual segmentation is
considered to be the &quot;gold-standard&quot;. However, medical imaging datasets with
expert manual segmentation are scarce as this step is time-consuming and
expensive. We propose in this work the use of what we refer to as silver
standard masks for data augmentation in deep-learning-based skull-stripping
also known as brain extraction. We generated the silver standard masks using
the consensus algorithm Simultaneous Truth and Performance Level Estimation
(STAPLE). We evaluated CNN models generated by the silver and gold standard
masks. Then, we validated the silver standard masks for CNNs training in one
dataset, and showed its generalization to two other datasets. Our results
indicated that models generated with silver standard masks are comparable to
models generated with gold standard masks and have better generalizability.
Moreover, our results also indicate that silver standard masks could be used to
augment the input dataset at training stage, reducing the need for manual
segmentation at this step.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08369</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08369</id><created>2017-10-17</created><authors><author><keyname>Unakafov</keyname><forenames>Anton M.</forenames></author></authors><title>Pulse rate estimation using imaging photoplethysmography: generic
  framework and comparison of methods on a publicly available dataset</title><categories>eess.IV physics.data-an physics.med-ph</categories><doi>10.1088/2057-1976/aabd09</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: to establish an algorithmic framework and a benchmark dataset for
comparing methods of pulse rate estimation using imaging photoplethysmography
(iPPG). Approach: first we reveal essential steps of pulse rate estimation from
facial video and review methods applied at each of the steps. Then we
investigate performance of these methods for DEAP dataset
www.eecs.qmul.ac.uk/mmv/datasets/deap/ containing facial videos and reference
contact photoplethysmograms. Main results: best assessment precision is
achieved when pulse rate is estimated using continuous wavelet transform from
iPPG extracted by the POS method (overall mean absolute error below 2 heart
beats per minute). Significance: we provide a generic framework for theoretical
comparison of methods for pulse rate estimation from iPPG and report results
for the most popular methods on a publicly available dataset that can be used
as a benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08377</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08377</id><created>2017-10-23</created><authors><author><keyname>McMahan</keyname><forenames>Brian</forenames></author><author><keyname>Rao</keyname><forenames>Delip</forenames></author></authors><title>Listening to the World Improves Speech Command Recognition</title><categories>cs.SD cs.AI eess.AS</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study transfer learning in convolutional network architectures applied to
the task of recognizing audio, such as environmental sound events and speech
commands. Our key finding is that not only is it possible to transfer
representations from an unrelated task like environmental sound classification
to a voice-focused task like speech command recognition, but also that doing so
improves accuracies significantly. We also investigate the effect of increased
model capacity for transfer learning audio, by first validating known results
from the field of Computer Vision of achieving better accuracies with
increasingly deeper networks on two audio datasets: UrbanSound8k and the newly
released Google Speech Commands dataset. Then we propose a simple multiscale
input representation using dilated convolutions and show that it is able to
aggregate larger contexts and increase classification performance. Further, the
models trained using a combination of transfer learning and multiscale input
representations need only 40% of the training data to achieve similar
accuracies as a freshly trained model with 100% of the training data. Finally,
we demonstrate a positive interaction effect for the multiscale input and
transfer learning, making a case for the joint application of the two
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08476</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08476</id><created>2017-10-23</created><authors><author><keyname>Alipour-Fanid</keyname><forenames>Amir</forenames></author><author><keyname>Dabaghchian</keyname><forenames>Monireh</forenames></author><author><keyname>Zeng</keyname><forenames>Kai</forenames></author></authors><title>Platoon Stability and Safety Analysis of Cooperative Adaptive Cruise
  Control under Wireless Rician Fading Channels and Jamming Attacks</title><categories>eess.SP cs.CR cs.SY</categories><comments>Due to the character limitation &quot;The abstract field cannot be longer
  than 1,920 characters&quot;, the abstract appearing above is slightly shorter than
  the one in the main PDF file</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative Adaptive Cruise Control (CACC) is considered as a key enabling
technology to automatically regulate the inter-vehicle distances in a vehicle
platoon to improve traffic efficiency while maintaining safety. Although the
wireless communication and physical processes in the existing CACC systems are
integrated in one control framework, the coupling between wireless
communication reliability and system states is not well modeled. Furthermore,
the research on the impact of jamming attacks on the system stability and
safety is largely open. In this paper, we conduct a comprehensive analysis on
the stability and safety of the platoon under the wireless Rician fading
channel model and jamming attacks. The effect of Rician fading and jamming on
the communication reliability is incorporated in the modeling of string
dynamics such that it captures its state dependency. Time-domain definition of
string stability is utilized to delineate the impact of Rician fading and
jamming on the CACC system's functionality and string stability. Attacker's
possible locations at which it can destabilize the string is further studied
based on the proposed model. From the safety perspective, reachable states
(i.e., inter-vehicle distances) of the CACC system under unreliable wireless
fading channels and jamming attacks is studied. Safety verification is
investigated by examining the inter-vehicle distance trajectories. We propose a
methodology to compute the upper and lower bounds of the trajectories of
inter-vehicle distances between the lead vehicle and its follower. We conduct
extensive simulations to evaluate the system stability and safety under jamming
attacks in different scenarios. We identify that channel fading can degrade the
performance of the CACC system, and the platoon's safety is highly sensitive to
jamming attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08592</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08592</id><created>2017-10-23</created><authors><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Xu</keyname><forenames>Yinliang</forenames></author><author><keyname>Li</keyname><forenames>Sisi</forenames></author><author><keyname>Zhou</keyname><forenames>MengChu</forenames></author><author><keyname>Liu</keyname><forenames>Wenxin</forenames></author><author><keyname>Xu</keyname><forenames>Ying</forenames></author></authors><title>A Distributed Dynamic Programming-based Solution for Load Management in
  Smart Grids</title><categories>eess.SP</categories><comments>12 pages, 18 figures, five tables, accepted by IEEE System Journal,
  Preprint</comments><doi>10.1109/JSYST.2016.2536141</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Load management is being recognized as an important option for active user
participation in the energy market. Traditional load management methods usually
require a centralized powerful control center and a two-way communication
network between the system operators and energy end-users. The increasing user
participation in smart grids may limit their applications. In this paper, a
distributed solution for load management in emerging smart grids is proposed.
The load management problem is formulated as a constrained optimization problem
aiming at maximizing the overall utility of users while meeting the requirement
for load reduction requested by the system operator, and is solved by using a
distributed dynamic programming algorithm. The algorithm is implemented via a
distributed framework and thus can deliver a highly desired distributed
solution. It avoids the required use of a centralized coordinator or control
center, and can achieve satisfactory outcomes for load management. Simulation
results with various test systems demonstrate its effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08623</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08623</id><created>2017-10-24</created><authors><author><keyname>AlSharif</keyname><forenames>Mohammed H.</forenames></author><author><keyname>Saad</keyname><forenames>Mohamed</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author></authors><title>Hand Gesture Recognition Using Ultrasonic Waves</title><categories>eess.SP</categories><comments>2 pages, Msc thesis paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new method for detecting and classifying a predefined
set of hand gestures using a single transmitter and a single receiver utilizing
a linearly frequency modulated ultrasonic signal. Gestures are identified based
on estimated range and received signal strength (RSS) of reflected signal from
the hand. Support Vector Machine (SVM) was used for gesture detection and
classification. The system was tested using experimental setup and achieved an
average accuracy of 88%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08633</identifier>
 <datestamp>2018-03-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08633</id><created>2017-10-24</created><updated>2018-03-05</updated><authors><author><keyname>Reddy</keyname><forenames>C Sandeep</forenames></author><author><keyname>Hegde</keyname><forenames>Rajesh M</forenames></author></authors><title>On the Conditioning of the Spherical Harmonic Matrix for Spatial Audio
  Applications</title><categories>eess.AS</categories><comments>12 pages; This paper is a preprint of a paper submitted to IET Signal
  Processing Journal. If accepted, the copy of record will be available at the
  IET Digital Library</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we attempt to study the conditioning of the Spherical Harmonic
Matrix (SHM), which is widely used in the discrete, limited order orthogonal
representation of sound fields. SHM's has been widely used in the audio
applications like spatial sound reproduction using loudspeakers, orthogonal
representation of Head Related Transfer Functions (HRTFs) etc. The conditioning
behaviour of the SHM depends on the sampling positions chosen in the 3D space.
Identification of the optimal sampling points in the continuous 3D space that
results in a well-conditioned SHM for any number of sampling points is a highly
challenging task. In this work, an attempt has been made to solve a discrete
version of the above problem using optimization based techniques. The discrete
problem is, to identify the optimal sampling points from a discrete set of
densely sampled positions of the 3D space, that minimizes the condition number
of SHM. This method has been subsequently utilized for identifying the geometry
of loudspeakers in the spatial sound reproduction, and in the selection of
spatial sampling configurations for HRTF measurement. The application specific
requirements have been formulated as additional constraints of the optimization
problem. Recently developed mixed-integer optimization solvers have been used
in solving the formulated problem. The performance of the obtained sampling
position in each application is compared with the existing configurations.
Objective measures like condition number, D-measure, and spectral distortion
are used to study the performance of the sampling configurations resulting from
the proposed and the existing methods. It is observed that the proposed
solution is able to find the sampling points that results in a better
conditioned SHM and also maintains all the application specific requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08684</identifier>
 <datestamp>2018-04-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08684</id><created>2017-10-24</created><authors><author><keyname>Shah</keyname><forenames>Muhammad A.</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author><author><keyname>Harras</keyname><forenames>Khaled A.</forenames></author></authors><title>Inferring Room Semantics Using Acoustic Monitoring</title><categories>cs.SD eess.AS</categories><comments>2017 IEEE International Workshop on Machine Learning for Signal
  Processing, Sept.\ 25--28, 2017, Tokyo, Japan</comments><journal-ref>IEEE International Workshop on Machine Learning for Signal
  Processing (MLSP) 27 (2017) 1-6</journal-ref><doi>10.1109/MLSP.2017.8168153</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Having knowledge of the environmental context of the user i.e. the knowledge
of the users' indoor location and the semantics of their environment, can
facilitate the development of many of location-aware applications. In this
paper, we propose an acoustic monitoring technique that infers semantic
knowledge about an indoor space \emph{over time,} using audio recordings from
it. Our technique uses the impulse response of these spaces as well as the
ambient sounds produced in them in order to determine a semantic label for
them. As we process more recordings, we update our \emph{confidence} in the
assigned label. We evaluate our technique on a dataset of single-speaker human
speech recordings obtained in different types of rooms at three university
buildings. In our evaluation, the confidence\emph{ }for the true label
generally outstripped the confidence for all other labels and in some cases
converged to 100\% with less than 30 samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08744</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08744</id><created>2017-10-24</created><authors><author><keyname>Ergen</keyname><forenames>Tolga</forenames></author><author><keyname>Kozat</keyname><forenames>Suleyman Serdar</forenames></author></authors><title>Online Training of LSTM Networks in Distributed Systems for Variable
  Length Data Sequences</title><categories>eess.SP</categories><doi>10.1109/TNNLS.2017.2770179</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this brief paper, we investigate online training of Long Short Term Memory
(LSTM) architectures in a distributed network of nodes, where each node employs
an LSTM based structure for online regression. In particular, each node
sequentially receives a variable length data sequence with its label and can
only exchange information with its neighbors to train the LSTM architecture. We
first provide a generic LSTM based regression structure for each node. In order
to train this structure, we put the LSTM equations in a nonlinear state space
form for each node and then introduce a highly effective and efficient
Distributed Particle Filtering (DPF) based training algorithm. We also
introduce a Distributed Extended Kalman Filtering (DEKF) based training
algorithm for comparison. Here, our DPF based training algorithm guarantees
convergence to the performance of the optimal LSTM coefficients in the mean
square error (MSE) sense under certain conditions. We achieve this performance
with communication and computational complexity in the order of the first order
gradient based methods. Through both simulated and real life examples, we
illustrate significant performance improvements with respect to the state of
the art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.08969</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.08969</id><created>2017-10-24</created><authors><author><keyname>Tachibana</keyname><forenames>Hideyuki</forenames></author><author><keyname>Uenoyama</keyname><forenames>Katsuya</forenames></author><author><keyname>Aihara</keyname><forenames>Shunsuke</forenames></author></authors><title>Efficiently Trainable Text-to-Speech System Based on Deep Convolutional
  Networks with Guided Attention</title><categories>cs.SD cs.AI cs.LG eess.AS</categories><comments>submitted to ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a novel text-to-speech (TTS) technique based on deep
convolutional neural networks (CNN), without any recurrent units. Recurrent
neural network (RNN) has been a standard technique to model sequential data
recently, and this technique has been used in some cutting-edge neural TTS
techniques. However, training RNN component often requires a very powerful
computer, or very long time typically several days or weeks. Recent other
studies, on the other hand, have shown that CNN-based sequence synthesis can be
much faster than RNN-based techniques, because of high parallelizability. The
objective of this paper is to show an alternative neural TTS system, based only
on CNN, that can alleviate these economic costs of training. In our experiment,
the proposed Deep Convolutional TTS can be sufficiently trained only in a night
(15 hours), using an ordinary gaming PC equipped with two GPUs, while the
quality of the synthesized speech was almost acceptable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09026</identifier>
 <datestamp>2018-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09026</id><created>2017-10-24</created><updated>2018-02-06</updated><authors><author><keyname>Kliegl</keyname><forenames>Markus</forenames></author><author><keyname>Goyal</keyname><forenames>Siddharth</forenames></author><author><keyname>Zhao</keyname><forenames>Kexin</forenames></author><author><keyname>Srinet</keyname><forenames>Kavya</forenames></author><author><keyname>Shoeybi</keyname><forenames>Mohammad</forenames></author></authors><title>Trace norm regularization and faster inference for embedded speech
  recognition RNNs</title><categories>cs.LG cs.CL eess.AS stat.ML</categories><comments>Our optimized inference kernels are available at:
  https://github.com/PaddlePaddle/farm (Note: This paper was submitted to, but
  rejected from, ICLR 2018. We believe it may still be of value to others.
  Please see the discussion here: https://openreview.net/forum?id=B1tC-LT6W)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and evaluate new techniques for compressing and speeding up dense
matrix multiplications as found in the fully connected and recurrent layers of
neural networks for embedded large vocabulary continuous speech recognition
(LVCSR). For compression, we introduce and study a trace norm regularization
technique for training low rank factored versions of matrix multiplications.
Compared to standard low rank training, we show that our method leads to good
accuracy versus number of parameter trade-offs and can be used to speed up
training of large models. For speedup, we enable faster inference on ARM
processors through new open sourced kernels optimized for small batch sizes,
resulting in 3x to 7x speed ups over the widely used gemmlowp library. Beyond
LVCSR, we expect our techniques and kernels to be more generally applicable to
embedded neural networks with large fully connected or recurrent layers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09064</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09064</id><created>2017-10-24</created><updated>2019-12-09</updated><authors><author><keyname>Kankanahalli</keyname><forenames>Srihari</forenames></author></authors><title>End-to-End Optimized Speech Coding with Deep Neural Networks</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted and presented at ICASSP 2018. Samples available here:
  http://srik.tk/speech-coding/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern compression algorithms are often the result of laborious
domain-specific research; industry standards such as MP3, JPEG, and AMR-WB took
years to develop and were largely hand-designed. We present a deep neural
network model which optimizes all the steps of a wideband speech coding
pipeline (compression, quantization, entropy coding, and decompression)
end-to-end directly from raw speech data -- no manual feature engineering
necessary, and it trains in hours. In testing, our DNN-based coder performs on
par with the AMR-WB standard at a variety of bitrates (~9kbps up to ~24kbps).
It also runs in realtime on a 3.8GhZ Intel CPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09091</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09091</id><created>2017-10-25</created><authors><author><keyname>Wang</keyname><forenames>Ziteng</forenames></author><author><keyname>Vincent</keyname><forenames>Emmanuel</forenames></author><author><keyname>Yan</keyname><forenames>Yonghong</forenames></author></authors><title>Relative Transfer Function Inverse Regression from Low Dimensional
  Manifold</title><categories>cs.SD eess.AS</categories><comments>5 pages, in preparation for Signal Processing Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In room acoustic environments, the Relative Transfer Functions (RTFs) are
controlled by few underlying modes of variability. Accordingly, they are
confined to a low-dimensional manifold. In this letter, we investigate a RTF
inverse regression problem, the task of which is to generate the
high-dimensional responses from their low-dimensional representations. The
problem is addressed from a pure data-driven perspective and a supervised Deep
Neural Network (DNN) model is applied to learn a mapping from the
source-receiver poses (positions and orientations) to the frequency domain RTF
vectors. The experiments show promising results: the model achieves lower
prediction error of the RTF than the free field assumption. However, it fails
to compete with the linear interpolation technique in small sampling distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09171</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09171</id><created>2017-10-25</created><updated>2019-01-08</updated><authors><author><keyname>Han</keyname><forenames>Bin</forenames></author><author><keyname>Lu</keyname><forenames>Yang</forenames></author><author><keyname>Wan</keyname><forenames>Kai</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Merging the Bernoulli-Gaussian and Symmetric Alpha-Stable Models for
  Impulsive Noises in Narrowband Power Line Channels</title><categories>eess.SP</categories><comments>Accepted by Physical Communication on 08. Jan. 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To model impulsive noise in power line channels, both the Bernoulli-Gaussian
model and the symmetric alpha-stable model are usually applied. Towards a merge
of existing noise measurement databases and a simplification of communication
system design, the compatibility between the two models is of interest. In this
paper, we show that they can be approximately converted to each other under
certain constrains, although never generally unified. Based on this, we propose
a fast model conversion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09175</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09175</id><created>2017-10-25</created><authors><author><keyname>Gishkori</keyname><forenames>Shahzad</forenames></author><author><keyname>Mulgrew</keyname><forenames>Bernard</forenames></author></authors><title>Pseudo-Zernike Moments Based Sparse Representations for SAR Image
  Classification</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose radar image classification via pseudo-Zernike moments based sparse
representations. We exploit invariance properties of pseudo-Zernike moments to
augment redundancy in the sparsity representative dictionary by introducing
auxiliary atoms. We employ complex radar signatures. We prove the validity of
our proposed methods on the publicly available MSTAR dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09207</identifier>
 <datestamp>2020-02-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09207</id><created>2017-10-25</created><authors><author><keyname>Ergen</keyname><forenames>Tolga</forenames></author><author><keyname>Mirza</keyname><forenames>Ali Hassan</forenames></author><author><keyname>Kozat</keyname><forenames>Suleyman Serdar</forenames></author></authors><title>Unsupervised and Semi-supervised Anomaly Detection with LSTM Neural
  Networks</title><categories>eess.SP cs.LG stat.ML</categories><doi>10.1109/TNNLS.2019.2935975</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate anomaly detection in an unsupervised framework and introduce
Long Short Term Memory (LSTM) neural network based algorithms. In particular,
given variable length data sequences, we first pass these sequences through our
LSTM based structure and obtain fixed length sequences. We then find a decision
function for our anomaly detectors based on the One Class Support Vector
Machines (OC-SVM) and Support Vector Data Description (SVDD) algorithms. As the
first time in the literature, we jointly train and optimize the parameters of
the LSTM architecture and the OC-SVM (or SVDD) algorithm using highly effective
gradient and quadratic programming based training methods. To apply the
gradient based training method, we modify the original objective criteria of
the OC-SVM and SVDD algorithms, where we prove the convergence of the modified
objective criteria to the original criteria. We also provide extensions of our
unsupervised formulation to the semi-supervised and fully supervised
frameworks. Thus, we obtain anomaly detection algorithms that can process
variable length data sequences while providing high performance, especially for
time series data. Our approach is generic so that we also apply this approach
to the Gated Recurrent Unit (GRU) architecture by directly replacing our LSTM
based structure with the GRU based structure. In our experiments, we illustrate
significant performance gains achieved by our algorithms with respect to the
conventional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09259</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09259</id><created>2017-10-16</created><authors><author><keyname>Das</keyname><forenames>B. K.</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>S.</forenames></author><author><keyname>Chakraborty</keyname><forenames>M.</forenames></author></authors><title>Convergence Analysis of l0-RLS Adaptive Filter</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents first and second order convergence analysis of the
sparsity aware l0-RLS adaptive filter. The theorems 1 and 2 state the steady
state value of mean and mean square deviation of the adaptive filter weight
vector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09281</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09281</id><created>2017-10-23</created><authors><author><keyname>Savitzky</keyname><forenames>Benjamin H.</forenames></author><author><keyname>Baggari</keyname><forenames>Ismail El</forenames></author><author><keyname>Clement</keyname><forenames>Colin</forenames></author><author><keyname>Waite</keyname><forenames>Emily</forenames></author><author><keyname>Sheckelton</keyname><forenames>John P.</forenames></author><author><keyname>Pasco</keyname><forenames>Christopher</forenames></author><author><keyname>Admasu</keyname><forenames>Alemayehu S.</forenames></author><author><keyname>Kim</keyname><forenames>Jaewook</forenames></author><author><keyname>Cheong</keyname><forenames>Sang-Wook</forenames></author><author><keyname>McQueen</keyname><forenames>Tyrel M.</forenames></author><author><keyname>Hovden</keyname><forenames>Robert</forenames></author><author><keyname>Kourkoutis</keyname><forenames>Lena F.</forenames></author></authors><title>Image registration of low signal-to-noise cryo-STEM data</title><categories>eess.SP physics.data-an</categories><comments>25 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining multiple fast image acquisitions to mitigate scan noise and drift
artifacts has proven essential for picometer precision, quantitative analysis
of atomic resolution scanning transmission electron microscopy (STEM) data. For
very low signal-to-noise ratio (SNR) image stacks - frequently required for
undistorted imaging at liquid nitrogen temperatures - image registration is
particularly delicate, and standard approaches may either fail, or produce
subtly specious reconstructed lattice images. We present an approach which
effectively registers and averages image stacks which are challenging due to
their low-SNR and propensity for unit cell misalignments. Registering all
possible image pairs in a multi-image stack leads to significant information
surplus. In combination with a simple physical picture of stage drift, this
enables identification of incorrect image registrations, and determination of
the optimal image shifts from the complete set of relative shifts. We
demonstrate the effectiveness of our approach on experimental, cryogenic STEM
datasets, highlighting subtle artifacts endemic to low-SNR lattice images and
how they can be avoided. High-SNR average images with information transfer out
to 0.72 A are achieved at 300 kV and with the sample cooled to near liquid
nitrogen temperature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09495</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09495</id><created>2017-10-25</created><authors><author><keyname>Al-Juboori</keyname><forenames>Ghaith R.</forenames></author><author><keyname>Halls</keyname><forenames>David</forenames></author><author><keyname>Doufexi</keyname><forenames>Angela</forenames></author><author><keyname>Nix</keyname><forenames>Andrew R.</forenames></author></authors><title>A Link Quality Model for Generalised Frequency Division Multiplexing</title><categories>eess.SP</categories><comments>5 pages, 8 figures, accepted in VTC- spring 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  5G systems aim to achieve extremely high data rates, low end-to-end latency
and ultra-low power consumption. Recently, there has been considerable interest
in the design of 5G physical layer waveforms. One important candidate is
Generalised Frequency Division Multiplexing (GFDM). In order to evaluate its
performance and features, system-level studies should be undertaken in a range
of scenarios. These studies, however, require highly complex computations if
they are performed using bit-level simulators. In this paper, the Mutual
Information (MI) based link quality model (PHY abstraction), which has been
regularly used to implement system-level studies for Orthogonal Frequency
Division Multiplexing (OFDM), is applied to GFDM. The performance of the GFDM
waveform using this model and the bit-level simulation performance is measured
using different channel types. Moreover, a system-level study for a GFDM based
LTE-A system in a realistic scenario, using both a bit-level simulator and this
abstraction model, has been studied and compared. The results reveal the
accuracy of this model using realistic channel data. Based on these results,
the PHY abstraction technique can be applied to evaluate the performance of
GFDM based systems in an effective manner with low complexity. The maximum
difference in the Packet Error Rate (PER) and throughput results in the
abstraction case compared to bit-level simulation does not exceed 4% whilst
offering a simulation time saving reduction of around 62,000 times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09540</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09540</id><created>2017-10-26</created><authors><author><keyname>Ahmadi</keyname><forenames>Hamid R.</forenames></author><author><keyname>Maleki</keyname><forenames>Nahal</forenames></author><author><keyname>Vosoughi</keyname><forenames>Azadeh</forenames></author></authors><title>On Power Allocation for Distributed Detection with Correlated
  Observations and Linear Fusion</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a binary hypothesis testing problem in an inhomogeneous wireless
sensor network, where a fusion center (FC) makes a global decision on the
underlying hypothesis. We assume sensors observations are correlated Gaussian
and sensors are unaware of this correlation when making decisions. Sensors send
their modulated decisions over fading channels, subject to individual and/or
total transmit power constraints. For parallel-access channel (PAC) and
multiple-access channel (MAC) models, we derive modified deflection coefficient
(MDC) of the test statistic at the FC with coherent reception.We propose a
transmit power allocation scheme, which maximizes MDC of the test statistic,
under three different sets of transmit power constraints: total power
constraint, individual and total power constraints, individual power
constraints only. When analytical solutions to our constrained optimization
problems are elusive, we discuss how these problems can be converted to convex
ones. We study how correlation among sensors observations, reliability of local
decisions, communication channel model and channel qualities and transmit power
constraints affect the reliability of the global decision and power allocation
of inhomogeneous sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09572</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09572</id><created>2017-10-26</created><authors><author><keyname>Gopala</keyname><forenames>Kalyana</forenames></author><author><keyname>Slock</keyname><forenames>Dirk</forenames></author></authors><title>A Refined Analysis of the Gap between Expected Rate for Partial CSIT and
  the Massive MIMO Rate Limit</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal BeamFormers (BFs) that maximize the Weighted Sum Rate (WSR) for a
Multiple-Input Multiple-Output (MIMO) interference broadcast channel (IBC)
remains an important research area. Under practical scenarios, the problem is
compounded by the fact that only partial channel state information at the
transmitter (CSIT) is available. Hence, a typical choice of the optimization
metric is the Expected Weighted Sum Rate (EWSR). However, the presence of the
expectation operator makes the optimization a daunting task. On the other hand,
for the particular, but significant, special case of massive MIMO (MaMIMO), the
EWSR converges to Expected Signal covariance Expected Interference covariance
based WSR (ESEI-WSR) and this metric is more amenable to optimization.
Recently, [1] considered a multi-user Multiple-Input Single-Output (MISO)
scenario and proposed approximating the EWSR by ESEI-WSR. They then derived a
constant bound for this approximation. This paper performs a refined analysis
of the gap between EWSR and ESEI-WSR criteria for finite antenna dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09676</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09676</id><created>2017-10-26</created><authors><author><keyname>Coutino</keyname><forenames>Mario</forenames></author><author><keyname>Chepuri</keyname><forenames>Sundeep Prabhakar</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Near-Optimal Sparse Sensing for Gaussian Detection with Correlated
  Observations</title><categories>eess.SP</categories><comments>13 pages, 9 figures</comments><doi>10.1109/TSP.2018.2846220</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection of a signal under noise is a classical signal processing problem.
When monitoring spatial phenomena under a fixed budget, i.e., either physical,
economical or computational constraints, the selection of a subset of available
sensors, referred to as sparse sensing, that meets both the budget and
performance requirements is highly desirable. Unfortunately, the subset
selection problem for detection under dependent observations is combinatorial
in nature and suboptimal subset selection algorithms must be employed. In this
work, different from the widely used convex relaxation of the problem, we
leverage submodularity, the diminishing returns property, to provide practical
near optimal algorithms suitable for large-scale subset selection. This is
achieved by means of low-complexity greedy algorithms, which incur a reduced
computational complexity compared to their convex counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09786</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09786</id><created>2017-10-26</created><authors><author><keyname>Medra</keyname><forenames>Mostafa</forenames></author><author><keyname>Huang</keyname><forenames>Yongwei</forenames></author><author><keyname>Davidson</keyname><forenames>Timothy N.</forenames></author></authors><title>Offset-Based Beamforming: A New Approach to Robust Downlink Transmission</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of a set of beamformers for the multiuser multiple-input
single-output (MISO) downlink that provides the receivers with prespecified
levels of quality-of-service (QoS) can be quite challenging when the channel
state information is not perfectly known at the base station. The constraint of
having the SINR meet or exceed a given threshold with high probability is
intractable in general, which results in problems that are fundamentally hard
to solve. In this paper, we will develop a high quality approximation of the
SINR outage constraint that, along with a semidefinite relaxation, enables us
to formulate the beamformer design problem as a convex optimization problem
that can be efficiently solved. For systems in which the uncertainty size is
small, a further approximation yields algorithms based on iterative evaluations
of closed-form expressions that have substantially lower computational cost.
Since finding the beamforming directions incurs most of the computational load
of these algorithms, analogous power loading algorithms for predefined
beamforming directions are developed and their performance is shown to be close
to optimal. When the system contains a large number of antennas, the proposed
power loading can be obtained at a computational cost that grows only linearly
in the number of antennas. The proposed power loading algorithm provides an
explicit relationship between the outage probability required and the power
consumed, which allows us to precisely control the power consumption, and
automatically identifies users who are consuming most of the power resources.
The flexibility of the proposed approach is illustrated by developing a power
loading technique that minimizes an average notion of outage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09798</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09798</id><created>2017-10-26</created><authors><author><keyname>Akbari</keyname><forenames>Hassan</forenames></author><author><keyname>Arora</keyname><forenames>Himani</forenames></author><author><keyname>Cao</keyname><forenames>Liangliang</forenames></author><author><keyname>Mesgarani</keyname><forenames>Nima</forenames></author></authors><title>Lip2AudSpec: Speech reconstruction from silent lip movements video</title><categories>cs.CV eess.AS eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this study, we propose a deep neural network for reconstructing
intelligible speech from silent lip movement videos. We use auditory
spectrogram as spectral representation of speech and its corresponding sound
generation method resulting in a more natural sounding reconstructed speech.
Our proposed network consists of an autoencoder to extract bottleneck features
from the auditory spectrogram which is then used as target to our main lip
reading network comprising of CNN, LSTM and fully connected layers. Our
experiments show that the autoencoder is able to reconstruct the original
auditory spectrogram with a 98% correlation and also improves the quality of
reconstructed speech from the main lip reading network. Our model, trained
jointly on different speakers is able to extract individual speaker
characteristics and gives promising results of reconstructing intelligible
speech with superior word recognition accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09836</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09836</id><created>2017-10-26</created><authors><author><keyname>Hossain</keyname><forenames>S Md Sakir</forenames></author><author><keyname>Islam</keyname><forenames>Md Atiqul</forenames></author></authors><title>Estimation of Rain Attenuation at EHF bands for Earth-to-Satellite Links
  in Bangladesh</title><categories>eess.SP</categories><comments>Int'l Conf. on Electrical, Computer and Communication Engineering
  (IEEE sponsored), Cox's Bazar, Bangladesh, February 2017, pp. 589-593</comments><doi>10.1109/ECACE.2017.7912973</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to heavy congestion in lower frequency bands, engineers are looking for
new frequency bands to support new services that require higher data rates,
which in turn needs broader bandwidths. To meet this requirement, extremely
high frequency (EHF), particularly Q (36 to 46 GHz) and V (46 to 56 GHz) bands,
is the best viable solution because of its complete availability. The most
serious challenge the EHF band poses is the attenuation caused by rain. This
paper investigates the effect of the rain on Q and V bands' performances in
Bangladeshi climatic conditions. The rain attenuations of the two bands are
predicted for the four main regions of Bangladesh using ITU rain attenuation
model. The measured rain statistics is used for this prediction. It is observed
that the attenuation due to rain in the Q/V band reaches up to 150 dB which is
much higher than that of the currently used Ka band. The variability of the
rain attenuation is also investigated over different sessions of Bangladesh.
The attenuation varies from 40 dB to 170 dB depending on the months. Finally,
the amount of rain fade required to compensate the high rain attenuation is
also predicted for different elevation angles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09915</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09915</id><created>2017-10-26</created><updated>2017-12-01</updated><authors><author><keyname>Sheng</keyname><forenames>Hao</forenames></author><author><keyname>Wang</keyname><forenames>Xiaozhe</forenames></author></authors><title>Probabilistic Available Delivery Capability Assessment of General
  Distribution Network with Renewables</title><categories>eess.SP</categories><comments>6 pages, 3 figures, Conference paper, Published in the IEEE Canada
  Electrical Power and Energy Conference 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rapid increase of renewable energy sources and electric vehicles in utility
distribution feeders introduces more and more uncertainties. To investigate how
such uncertainties may affect the available delivery capability (ADC) of the
distribution network, it is imperative to employ a probabilistic analysis
framework. In this paper, a formulation for probabilistic ADC incorporating
renewable generators and load variations is proposed; a computationally
efficient method to solve the probabilistic ADC is presented, which combines
the up-to-date sparse polynomial chaos expansion (PCE) and the continuation
method. A numerical example in the IEEE 13 node test feeder is given to
demonstrate the accuracy and efficiency of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09962</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09962</id><created>2017-10-26</created><authors><author><keyname>Lu</keyname><forenames>Jingyang</forenames></author><author><keyname>Niu</keyname><forenames>Ruixin</forenames></author></authors><title>A Study Of Optimal False Information Injection Attack On Dynamic State
  Estimation in Multi-Sensor Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the impact of false information injection is investigated for
linear dynamic systems with multiple sensors. It is assumed that the system is
unsuspecting the existence of false information and the adversary is trying to
maximize the negative effect of the false information on Kalman filter's
estimation performance. The false information attack under different conditions
is mathematically characterized. For the adversary, many closed-form results
for the optimal attack strategies that maximize Kalman filter's estimation
error are theoretically derived. It is shown that by choosing the optimal
correlation coefficients among the bias noises and allocating power optimally
among sensors, the adversary could significantly increase Kalman filter's
estimation errors. To be concrete, a target tracking system is used as an
example in the paper. From the adversary's point of view, the best attack
strategies are obtained under different scenarios, including a single-sensor
system with both position and velocity measurements, and a multi-sensor system
with position and velocity measurements. Under a constraint on the total power
of the injected bias noises, the optimal solutions are solved from two
perspectives: trace and determinant. Numerical results are also provided in
order to illustrate the effectiveness of the proposed attack strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.09985</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.09985</id><created>2017-10-27</created><updated>2018-03-21</updated><authors><author><keyname>He</keyname><forenames>Di</forenames></author><author><keyname>Lim</keyname><forenames>Boon Pang</forenames></author><author><keyname>Yang</keyname><forenames>Xuesong</forenames></author><author><keyname>Hasegawa-Johnson</keyname><forenames>Mark</forenames></author><author><keyname>Chen</keyname><forenames>Deming</forenames></author></authors><title>Acoustic Landmarks Contain More Information About the Phone String than
  Other Frames for Automatic Speech Recognition with Deep Neural Network
  Acoustic Model</title><categories>eess.AS cs.SD</categories><comments>The article has been submitted to Journal of the Acoustical Society
  of America</comments><doi>10.1121/1.5039837</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most mainstream Automatic Speech Recognition (ASR) systems consider all
feature frames equally important. However, acoustic landmark theory is based on
a contradictory idea, that some frames are more important than others. Acoustic
landmark theory exploits quantal non-linearities in the articulatory-acoustic
and acoustic-perceptual relations to define landmark times at which the speech
spectrum abruptly changes or reaches an extremum; frames overlapping landmarks
have been demonstrated to be sufficient for speech perception. In this work, we
conduct experiments on the TIMIT corpus, with both GMM and DNN based ASR
systems and find that frames containing landmarks are more informative for ASR
than others. We find that altering the level of emphasis on landmarks by
re-weighting acoustic likelihood tends to reduce the phone error rate (PER).
Furthermore, by leveraging the landmark as a heuristic, one of our hybrid DNN
frame dropping strategies maintained a PER within 0.44% of optimal when scoring
less than half (45.8% to be precise) of the frames. This hybrid strategy
out-performs other non-heuristic-based methods and demonstrate the potential of
landmarks for reducing computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10005</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10005</id><created>2017-10-27</created><authors><author><keyname>Nikunen</keyname><forenames>Joonas</forenames></author><author><keyname>Diment</keyname><forenames>Aleksandr</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Separation of Moving Sound Sources Using Multichannel NMF and Acoustic
  Tracking</title><categories>cs.SD eess.AS</categories><comments>Preprint of manuscript submitted to IEEE/ACM Transactions on Audio
  Speech and Language processing (R1)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a method for separation of moving sound sources. The
method is based on first tracking the sources and then estimation of source
spectrograms using multichannel non-negative matrix factorization (NMF) and
extracting the sources from the mixture by single-channel Wiener filtering. We
propose a novel multichannel NMF model with time-varying mixing of the sources
denoted by spatial covariance matrices (SCM) and provide update equations for
optimizing model parameters minimizing squared Frobenius norm. The SCMs of the
model are obtained based on estimated directions of arrival of tracked sources
at each time frame. The evaluation is based on established objective separation
criteria and using real recordings of two and three simultaneous moving sound
sources. The compared methods include conventional beamforming and ideal ratio
mask separation. The proposed method is shown to exceed the separation quality
of other evaluated blind approaches according to all measured quantities.
Additionally, we evaluate the method's susceptibility towards tracking errors
by comparing the separation quality achieved using annotated ground truth
source trajectories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10059</identifier>
 <datestamp>2018-08-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10059</id><created>2017-10-27</created><updated>2018-08-05</updated><authors><author><keyname>Adavanne</keyname><forenames>Sharath</forenames></author><author><keyname>Politis</keyname><forenames>Archontis</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Direction of arrival estimation for multiple sound sources using
  convolutional recurrent neural network</title><categories>cs.SD cs.LG eess.AS</categories><comments>EUSIPCO 2018</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper proposes a deep neural network for estimating the directions of
arrival (DOA) of multiple sound sources. The proposed stacked convolutional and
recurrent neural network (DOAnet) generates a spatial pseudo-spectrum (SPS)
along with the DOA estimates in both azimuth and elevation. We avoid any
explicit feature extraction step by using the magnitudes and phases of the
spectrograms of all the channels as input to the network. The proposed DOAnet
is evaluated by estimating the DOAs of multiple concurrently present sources in
anechoic, matched and unmatched reverberant conditions. The results show that
the proposed DOAnet is capable of estimating the number of sources and their
respective DOAs with good precision and generate SPS with high signal-to-noise
ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10197</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10197</id><created>2017-10-27</created><authors><author><keyname>Tao</keyname><forenames>Fei</forenames></author><author><keyname>Liu</keyname><forenames>Gang</forenames></author></authors><title>Advanced LSTM: A Study about Better Time Dependency Modeling in Emotion
  Recognition</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Long short-term memory (LSTM) is normally used in recurrent neural network
(RNN) as basic recurrent unit. However,conventional LSTM assumes that the state
at current time step depends on previous time step. This assumption constraints
the time dependency modeling capability. In this study, we propose a new
variation of LSTM, advanced LSTM (A-LSTM), for better temporal context
modeling. We employ A-LSTM in weighted pooling RNN for emotion recognition. The
A-LSTM outperforms the conventional LSTM by 5.5% relatively. The A-LSTM based
weighted pooling RNN can also complement the state-of-the-art emotion
classification framework. This shows the advantage of A-LSTM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10200</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10200</id><created>2017-10-27</created><authors><author><keyname>Candan</keyname><forenames>Cagatay</forenames></author></authors><title>An Automated Window Selection Procedure For DFT Based Detection Schemes
  To Reduce Windowing SNR Loss</title><categories>eess.SP</categories><comments>Keywords: Spectral Analysis, Window Function, Pulse-Doppler Radar,
  Target Detection. A Matlab implementation is available at
  http://users.metu.edu.tr/ccandan/pub.htm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical spectrum analysis methods utilize window functions to reduce
the masking effect of a strong spectral component over weaker components. The
main cost of side-lobe reduction is the reduction of signal-to-noise ratio
(SNR) level of the output spectrum. We present a single snapshot method which
optimizes the selection of most suitable window function among a finite set of
candidate windows, say rectangle, Hamming, Blackman windows, for each spectral
bin. The main goal is to utilize different window functions at each spectral
output depending on the interference level encountered at that spectral bin so
as to reduce the SNR loss associated with the windowing operation. Stated
differently, the windows with strong interference suppression capabilities are
utilized only when a sufficiently powerful interferer is corrupting the
spectral bin of interest is present, i.e. only when this window is needed. The
achieved reduction in the windowing SNR loss can be important for the detection
of low SNR targets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10224</identifier>
 <datestamp>2018-02-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10224</id><created>2017-10-27</created><updated>2018-02-21</updated><authors><author><keyname>Kim</keyname><forenames>Jaeyoung</forenames></author><author><keyname>El-Khamy</keyname><forenames>Mostafa</forenames></author><author><keyname>Lee</keyname><forenames>Jungwon</forenames></author></authors><title>BridgeNets: Student-Teacher Transfer Learning Based on Recursive Neural
  Networks and its Application to Distant Speech Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>Accepted to 2018 IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the remarkable progress achieved on automatic speech recognition,
recognizing far-field speeches mixed with various noise sources is still a
challenging task. In this paper, we introduce novel student-teacher transfer
learning, BridgeNet which can provide a solution to improve distant speech
recognition. There are two key features in BridgeNet. First, BridgeNet extends
traditional student-teacher frameworks by providing multiple hints from a
teacher network. Hints are not limited to the soft labels from a teacher
network. Teacher's intermediate feature representations can better guide a
student network to learn how to denoise or dereverberate noisy input. Second,
the proposed recursive architecture in the BridgeNet can iteratively improve
denoising and recognition performance. The experimental results of BridgeNet
showed significant improvements in tackling the distant speech recognition
problem, where it achieved up to 13.24% relative WER reductions on AMI corpus
compared to a baseline neural network without teacher's hints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10227</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10227</id><created>2017-10-27</created><authors><author><keyname>Samant</keyname><forenames>Salil</forenames></author><author><keyname>Joshi</keyname><forenames>Shiv Dutt</forenames></author></authors><title>Unified Functorial Signal Representation III: Foundations, Redundancy,
  $L^0$ and $L^2$ functors</title><categories>eess.SP cs.IT math.CT math.IT</categories><comments>First draft version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose and lay the foundations of a functorial framework
for representing signals. By incorporating additional category-theoretic
relative and generative perspective alongside the classic set-theoretic measure
theory the fundamental concepts of redundancy, compression are formulated in a
novel authentic arrow-theoretic way. The existing classic framework
representing a signal as a vector of appropriate linear space is shown as a
special case of the proposed framework.
  Next in the context of signal-spaces as a categories we study the various
covariant and contravariant forms of $L^0$ and $L^2$ functors using categories
of measurable or measure spaces and their opposites involving Boolean and
measure algebras along with partial extension. Finally we contribute a novel
definition of intra-signal redundancy using general concept of isomorphism
arrow in a category covering the translation case and others as special cases.
Through category-theory we provide a simple yet precise explanation for the
well-known heuristic of lossless differential encoding standards yielding
better compressions in image types such as line drawings, iconic image, text
etc; as compared to classic representation techniques such as JPEG which choose
bases or frames in a global Hilbert space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10242</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10242</id><created>2017-10-27</created><authors><author><keyname>Li</keyname><forenames>Haochen</forenames></author><author><keyname>Shek</keyname><forenames>Jonathan</forenames></author></authors><title>Reconfigurable Power Electronics Topologies</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents two novel topologies for automatically transforming power
converter topology from three-phase 3-level cascaded H-bridge to three-phase
2-level converter design. These techniques are implemented by flicking specific
switches to rearrange circuit connections. The switches can be controlled by
signals in order to realize automation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10378</identifier>
 <datestamp>2019-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10378</id><created>2017-10-27</created><updated>2019-01-08</updated><authors><author><keyname>Liu</keyname><forenames>Qinghua</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Xie</keyname><forenames>Yao</forenames></author></authors><title>Distributed Change Detection via Average Consensus over Networks</title><categories>eess.SP cs.IT cs.SY math.IT</categories><comments>15 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed change-point detection has been a fundamental problem when
performing real-time monitoring using sensor-networks. We propose a distributed
detection algorithm, where each sensor only exchanges CUSUM statistic with
their neighbors based on the average consensus scheme, and an alarm is raised
when local consensus statistic exceeds a pre-specified global threshold. We
provide theoretical performance bounds showing that the performance of the
fully distributed scheme can match the centralized algorithms under some mild
conditions. Numerical experiments demonstrate the good performance of the
algorithm especially in detecting asynchronous changes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10384</identifier>
 <datestamp>2018-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10384</id><created>2017-10-27</created><authors><author><keyname>Hoang</keyname><forenames>Thang</forenames></author><author><keyname>Sowailem</keyname><forenames>Mohammed</forenames></author><author><keyname>Zhuge</keyname><forenames>Qunbi</forenames></author><author><keyname>Xing</keyname><forenames>Zhenping</forenames></author><author><keyname>Morsy-Osman</keyname><forenames>Mohamed</forenames></author><author><keyname>El-Fiky</keyname><forenames>Eslam</forenames></author><author><keyname>Fan</keyname><forenames>Sujie</forenames></author><author><keyname>Xiang</keyname><forenames>Meng</forenames></author><author><keyname>Plant</keyname><forenames>David V.</forenames></author></authors><title>Single wavelength 480 Gb/s direct detection over 80km SSMF enabled by
  Stokes Vector Kramers Kronig transceiver</title><categories>eess.SP</categories><doi>10.1364/OE.25.033534</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose 4D modulation with directed detection employing a novel
Stokes-Vector Kramers-Kronig transceiver. It shows that employing Stokes vector
receiver, transmitted digital carrier and Kramers-Kronig detection offers an
effective way to de-rotate polarization multiplexed complex double side band
signal without using a local oscillator at receiver. The impact of system
parameters and configurations including carrier-to-signal-power ratio, guard
band of the digital carrier, oversampling ratio and real MIMO is experimentally
investigated. Finally, a record 480 Gb/s data rate over 80 km SSMF is achieved
in a 60 Gbaud PDM-16QAM single carrier experiment with a BER below the
threshold of 2.0x10-2
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10432</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10432</id><created>2017-10-28</created><updated>2018-04-16</updated><authors><author><keyname>Lin</keyname><forenames>Shoufeng</forenames></author></authors><title>Jointly Tracking and Separating Speech Sources Using Multiple Features
  and the generalized labeled multi-Bernoulli Framework</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel joint multi-speaker tracking-and-separation
method based on the generalized labeled multi-Bernoulli (GLMB) multi-target
tracking filter, using sound mixtures recorded by microphones. Standard
multi-speaker tracking algorithms usually only track speaker locations, and
ambiguity occurs when speakers are spatially close. The proposed multi-feature
GLMB tracking filter treats the set of vectors of associated speaker features
(location, pitch and sound) as the multi-target multi-feature observation,
characterizes transitioning features with corresponding transition models and
overall likelihood function, thus jointly tracks and separates each
multi-feature speaker, and addresses the spatial ambiguity problem. Numerical
evaluation verifies that the proposed method can correctly track locations of
multiple speakers and meanwhile separate speech signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10436</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10436</id><created>2017-10-28</created><updated>2018-09-02</updated><authors><author><keyname>Liu</keyname><forenames>Yi</forenames></author><author><keyname>He</keyname><forenames>Liang</forenames></author><author><keyname>Zhang</keyname><forenames>Weiqiang</forenames></author><author><keyname>Liu</keyname><forenames>Jia</forenames></author><author><keyname>Johnson</keyname><forenames>Michael T.</forenames></author></authors><title>Investigation of Frame Alignments for GMM-based Digit-prompted Speaker
  Verification</title><categories>cs.SD eess.AS</categories><comments>accepted by APSIPA ASC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frame alignments can be computed by different methods in GMM-based speaker
verification. By incorporating a phonetic Gaussian mixture model (PGMM), we are
able to compare the performance using alignments extracted from the deep neural
networks (DNN) and the conventional hidden Markov model (HMM) in digit-prompted
speaker verification. Based on the different characteristics of these two
alignments, we present a novel content verification method to improve the
system security without much computational overhead. Our experiments on the
RSR2015 Part-3 digit-prompted task show that, the DNN based alignment performs
on par with the HMM alignment. The results also demonstrate the effectiveness
of the proposed Kullback-Leibler (KL) divergence based scoring to reject speech
with incorrect pass-phrases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10450</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10450</id><created>2017-10-28</created><updated>2018-06-10</updated><authors><author><keyname>Chen</keyname><forenames>Liyan</forenames></author><author><keyname>Cheng</keyname><forenames>Samuel</forenames></author><author><keyname>Stankovic</keyname><forenames>Vlandimir</forenames></author><author><keyname>Stankovic</keyname><forenames>Lina</forenames></author></authors><title>Shift-enabled graphs: Graphs where shift-invariant filters are
  representable as polynomials of shift operations</title><categories>eess.SP</categories><comments>4 pages, 3 figures</comments><doi>10.1109/LSP.2018.2849685</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In digital signal processing, shift-invariant filters can be represented as a
polynomial expansion of a shift operation,that is, the Z-transform
representation. When extended to graph signal processing (GSP), this would mean
that a shift-invariant graph filter can be represented as a polynomial of the
adjacency (shift) matrix of the graph. However, the characteristic and minimum
polynomials of the adjacency matrix must be identical for the property to hold.
While it has been suggested that this condition might be ignored as it is
always possible to find a polynomial transform to represent the original
adjacency matrix by another adjacency matrix that satisfies the condition, this
letter shows that a filter that is shift invariant in terms of the original
graph may not be shift invariant anymore under the modified graph and vice
versa. We introduce the notion of &quot;shift-enabled graph&quot; for graphs that satisfy
the aforementioned condition, and present a concrete example of a graph that is
not &quot;shift-enabled&quot; and a shift-invariant filter that is not a polynomial of
the shift operation matrix. The result provides a deeper understanding of
shift-invariant filters when applied in GSP and shows that further
investigation of shift-enabled graphs is needed to make it applicable to
practical scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10451</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10451</id><created>2017-10-28</created><updated>2018-02-13</updated><authors><author><keyname>Kim</keyname><forenames>Taejun</forenames></author><author><keyname>Lee</keyname><forenames>Jongpil</forenames></author><author><keyname>Nam</keyname><forenames>Juhan</forenames></author></authors><title>Sample-level CNN Architectures for Music Auto-tagging Using Raw
  Waveforms</title><categories>cs.SD cs.LG cs.MM cs.NE eess.AS</categories><comments>Accepted for publication at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has shown that the end-to-end approach using convolutional neural
network (CNN) is effective in various types of machine learning tasks. For
audio signals, the approach takes raw waveforms as input using an 1-D
convolution layer. In this paper, we improve the 1-D CNN architecture for music
auto-tagging by adopting building blocks from state-of-the-art image
classification models, ResNets and SENets, and adding multi-level feature
aggregation to it. We compare different combinations of the modules in building
CNN architectures. The results show that they achieve significant improvements
over previous state-of-the-art models on the MagnaTagATune dataset and
comparable results on Million Song Dataset. Furthermore, we analyze and
visualize our model to show how the 1-D CNN operates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10456</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10456</id><created>2017-10-28</created><authors><author><keyname>Al-Juboori</keyname><forenames>Ghaith</forenames></author><author><keyname>Doufexi</keyname><forenames>Angela</forenames></author><author><keyname>Nix</keyname><forenames>Andrew R.</forenames></author></authors><title>Feasibility Study of OFDM-MFSK Modulation Scheme for Smart Metering
  Technology</title><categories>eess.SP</categories><comments>6 pages, 11 figures, ISGT Europe 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Orthogonal Frequency Division Multiplexing based M-ary Frequency Shift
Keying (OFDM-MFSK) is a noncoherent modulation scheme which merges MFSK with
the OFDM waveform. It is designed to improve the receiver sensitivity in the
hard environments where channel estimation is very difficult to perform. In
this paper, the OFDM-MFSK is suggested for the smart metering technology and
its performance is measured and compared with the ordinary OFDM-BPSK. Our
results show that, depending on the MFSK size value (M), the Packet Error Rate
(PER) has dramatically improved for OFDM-MFSK. Additionally, the adaptive
OFDM-MFSK, which selects the best M value that gives the minimum PER and higher
throughput for each Smart Meter (SM), has better coverage than OFDM-BPSK.
Although its throughput and capacity are lower than OFDMBPSK, the connected SMs
per sector are higher. Based on the smart metering technology requirements
which imply the need for high coverage and low amount of data exchanged between
the network and the SMs, The OFDM-MFSK can be efficiently used in this
technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10467</identifier>
 <datestamp>2019-01-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10467</id><created>2017-10-28</created><updated>2019-01-24</updated><authors><author><keyname>Wan</keyname><forenames>Li</forenames></author><author><keyname>Wang</keyname><forenames>Quan</forenames></author><author><keyname>Papir</keyname><forenames>Alan</forenames></author><author><keyname>Moreno</keyname><forenames>Ignacio Lopez</forenames></author></authors><title>Generalized End-to-End Loss for Speaker Verification</title><categories>eess.AS cs.CL cs.LG stat.ML</categories><comments>Published at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new loss function called generalized end-to-end
(GE2E) loss, which makes the training of speaker verification models more
efficient than our previous tuple-based end-to-end (TE2E) loss function. Unlike
TE2E, the GE2E loss function updates the network in a way that emphasizes
examples that are difficult to verify at each step of the training process.
Additionally, the GE2E loss does not require an initial stage of example
selection. With these properties, our model with the new loss function
decreases speaker verification EER by more than 10%, while reducing the
training time by 60% at the same time. We also introduce the MultiReader
technique, which allows us to do domain adaptation - training a more accurate
model that supports multiple keywords (i.e. &quot;OK Google&quot; and &quot;Hey Google&quot;) as
well as multiple dialects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10468</identifier>
 <datestamp>2018-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10468</id><created>2017-10-28</created><updated>2018-12-14</updated><authors><author><keyname>Wang</keyname><forenames>Quan</forenames></author><author><keyname>Downey</keyname><forenames>Carlton</forenames></author><author><keyname>Wan</keyname><forenames>Li</forenames></author><author><keyname>Mansfield</keyname><forenames>Philip Andrew</forenames></author><author><keyname>Moreno</keyname><forenames>Ignacio Lopez</forenames></author></authors><title>Speaker Diarization with LSTM</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Published at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For many years, i-vector based audio embedding techniques were the dominant
approach for speaker verification and speaker diarization applications.
However, mirroring the rise of deep learning in various domains, neural network
based audio embeddings, also known as d-vectors, have consistently demonstrated
superior speaker verification performance. In this paper, we build on the
success of d-vector based speaker verification systems to develop a new
d-vector based approach to speaker diarization. Specifically, we combine
LSTM-based d-vector audio embeddings with recent work in non-parametric
clustering to obtain a state-of-the-art speaker diarization system. Our system
is evaluated on three standard public datasets, suggesting that d-vector based
diarization systems offer significant advantages over traditional i-vector
based systems. We achieved a 12.0% diarization error rate on NIST SRE 2000
CALLHOME, while our model is trained with out-of-domain data from voice search
logs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10470</identifier>
 <datestamp>2018-02-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10470</id><created>2017-10-28</created><updated>2018-01-31</updated><authors><author><keyname>Chowdhury</keyname><forenames>F A Rezaur Rahman</forenames></author><author><keyname>Wang</keyname><forenames>Quan</forenames></author><author><keyname>Moreno</keyname><forenames>Ignacio Lopez</forenames></author><author><keyname>Wan</keyname><forenames>Li</forenames></author></authors><title>Attention-Based Models for Text-Dependent Speaker Verification</title><categories>eess.AS cs.LG cs.SD stat.ML</categories><comments>Submitted to ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attention-based models have recently shown great performance on a range of
tasks, such as speech recognition, machine translation, and image captioning
due to their ability to summarize relevant information that expands through the
entire length of an input sequence. In this paper, we analyze the usage of
attention mechanisms to the problem of sequence summarization in our end-to-end
text-dependent speaker recognition system. We explore different topologies and
their variants of the attention layer, and compare different pooling methods on
the attention weights. Ultimately, we show that attention-based models can
improves the Equal Error Rate (EER) of our speaker verification system by
relatively 14% compared to our non-attention LSTM baseline model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10774</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10774</id><created>2017-10-30</created><updated>2018-02-28</updated><authors><author><keyname>Tjandra</keyname><forenames>Andros</forenames></author><author><keyname>Sakti</keyname><forenames>Sakriani</forenames></author><author><keyname>Nakamura</keyname><forenames>Satoshi</forenames></author></authors><title>Sequence-to-Sequence ASR Optimization via Reinforcement Learning</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Accepted at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the success of sequence-to-sequence approaches in automatic speech
recognition (ASR) systems, the models still suffer from several problems,
mainly due to the mismatch between the training and inference conditions. In
the sequence-to-sequence architecture, the model is trained to predict the
grapheme of the current time-step given the input of speech signal and the
ground-truth grapheme history of the previous time-steps. However, it remains
unclear how well the model approximates real-world speech during inference.
Thus, generating the whole transcription from scratch based on previous
predictions is complicated and errors can propagate over time. Furthermore, the
model is optimized to maximize the likelihood of training data instead of error
rate evaluation metrics that actually quantify recognition quality. This paper
presents an alternative strategy for training sequence-to-sequence ASR models
by adopting the idea of reinforcement learning (RL). Unlike the standard
training scheme with maximum likelihood estimation, our proposed approach
utilizes the policy gradient algorithm. We can (1) sample the whole
transcription based on the model's prediction in the training process and (2)
directly optimize the model with negative Levenshtein distance as the reward.
Experimental results demonstrate that we significantly improved the performance
compared to a model trained only with maximum likelihood estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10775</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10775</id><created>2017-10-30</created><authors><author><keyname>Rouhani</keyname><forenames>Mohammadhadi</forenames></author><author><keyname>Mohammadi</keyname><forenames>Mohammad</forenames></author></authors><title>Probabilistic Distribution Power Flow Based on Finite Smoothing of Data
  Samples Considering Plug-in Hybrid Electric Vehicles</title><categories>eess.SP</categories><comments>30 pages, 10 figures, 5 tables, journal paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ever increasing penetration of plug-in hybrid electric vehicles in
distribution systems has triggered the need for a more accurate and at the same
time fast solution to probabilistic distribution power flow problem. In this
paper a novel algorithm is introduced based on finite sample points to
determine probabilistic density function of probabilistic distribution power
flow results. A modified probabilistic charging behavior of plug-in hybrid
electric vehicles at charging stations and their overlap with residential peak
load is evaluated in probabilistic distribution power flow problem. The
proposed algorithm is faster than Monte Carlo Simulation and at the same time
keeps adequate accuracy. It is applied to solve probabilistic distribution
power flow for two dimensionally different test systems and is compared with
recent probabilistic solutions. Simulation results show the accuracy and
efficiency of the proposed algorithm to calculate probability density function
of uncertain outputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10829</identifier>
 <datestamp>2019-11-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10829</id><created>2017-10-30</created><authors><author><keyname>Todescato</keyname><forenames>Marco</forenames></author><author><keyname>Bof</keyname><forenames>Nicoletta</forenames></author><author><keyname>Cavraro</keyname><forenames>Guido</forenames></author><author><keyname>Carli</keyname><forenames>Ruggero</forenames></author><author><keyname>Schenato</keyname><forenames>Luca</forenames></author></authors><title>Generalized gradient optimization over lossy networks for
  partition-based estimation</title><categories>math.OC cs.SY eess.SY</categories><comments>20 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of distributed convex unconstrained optimization over
networks characterized by asynchronous and possibly lossy communications. We
analyze the case where the global cost function is the sum of locally coupled
local strictly convex cost functions. As discussed in detail in a motivating
example, this class of optimization objectives is, for example, typical in
localization problems and in partition-based state estimation. Inspired by a
generalized gradient descent strategy, namely the block Jacobi iteration, we
propose a novel solution which is amenable for a distributed implementation and
which, under a suitable condition on the step size, is provably locally
resilient to communication failures. The theoretical analysis relies on the
separation of time scales and Lyapunov theory. In addition, to show the
flexibility of the proposed algorithm, we derive a resilient gradient descent
iteration and a resilient generalized gradient for quadratic programming as two
natural particularizations of our strategy. In this second case, global
robustness is provided. Finally, the proposed algorithm is numerically tested
on the IEEE 123 nodes distribution feeder in the context of partition-based
smart grid robust state estimation in the presence of measurements outliers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10830</identifier>
 <datestamp>2018-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10830</id><created>2017-10-30</created><authors><author><keyname>Jiang</keyname><forenames>Xiwen</forenames></author><author><keyname>Decurninge</keyname><forenames>Alexis</forenames></author><author><keyname>Gopala</keyname><forenames>Kalyana</forenames></author><author><keyname>Kaltenberger</keyname><forenames>Florian</forenames></author><author><keyname>Guillaud</keyname><forenames>Maxime</forenames></author><author><keyname>Slock</keyname><forenames>Dirk</forenames></author><author><keyname>Deneire</keyname><forenames>Luc</forenames></author></authors><title>A Framework for Over-the-air Reciprocity Calibration for TDD Massive
  MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the biggest challenges in operating massive multiple-input
multiple-output systems is the acquisition of accurate channel state
information at the transmitter. To take up this challenge, time division duplex
is more favorable thanks to its channel reciprocity between downlink and
uplink. However, while the propagation channel over the air is reciprocal, the
radio-frequency front-ends in the transceivers are not. Therefore, calibration
is required to compensate the RF hardware asymmetry.
  Although various over-the-air calibration methods exist to address the above
problem, this paper offers a unified representation of these algorithms,
providing a higher level view on the calibration problem, and introduces
innovations on calibration methods. We present a novel family of calibration
methods, based on antenna grouping, which improve accuracy and speed up the
calibration process compared to existing methods. We then provide the
Cram\'er-Rao bound as the performance evaluation benchmark and compare maximum
likelihood and least squares estimators. We also differentiate between coherent
and non-coherent accumulation of calibration measurements, and point out that
enabling non-coherent accumulation allows the training to be spread in time,
minimizing impact to the data service. Overall, these results have special
value in allowing to design reciprocity calibration techniques that are both
accurate and resource-effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10857</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10857</id><created>2017-10-30</created><authors><author><keyname>Hojeij</keyname><forenames>Marie-Rita</forenames></author><author><keyname>Nour</keyname><forenames>Charbel Abdel</forenames></author><author><keyname>Farah</keyname><forenames>Joumana</forenames></author><author><keyname>Douillard</keyname><forenames>Catherine</forenames></author></authors><title>Weighted Proportional Fair Scheduling for Downlink Non-Orthogonal
  Multiple Access</title><categories>eess.SP</categories><comments>11 pages, 8 figures, 2 tables. Submitted paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a weighted proportional fair (PF) scheduling method is
proposed in the context of non-orthogonal multiple access (NOMA) with
successive interference cancellation (SIC) at the receiver side. The new scheme
introduces weights that adapt the classical PF metric to the NOMA scenario,
improving performance indicators and enabling new services. The distinguishing
value of the proposal resides in its ability to improve long term fairness and
total system throughput while achieving a high level of fairness in every
scheduling slot. Finally, it is shown that the additional complexity caused by
the weight calculation has only a limited impact on the overall scheduler
complexity while simulation results confirm the claimed improvements making the
proposal an appealing alternative for resource allocation in a cellular
downlink system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10948</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10948</id><created>2017-10-26</created><authors><author><keyname>Ferguson</keyname><forenames>Eric L.</forenames></author><author><keyname>Williams</keyname><forenames>Stefan B.</forenames></author><author><keyname>Jin</keyname><forenames>Craig T.</forenames></author></authors><title>Sound Source Localization in a Multipath Environment Using Convolutional
  Neural Networks</title><categories>cs.SD cs.CV eess.AS</categories><comments>5 pages, 5 figures, Final draft of paper submitted to 2018 IEEE
  International Conference on Acoustics, Speech and Signal Processing (ICASSP)
  15-20 April 2018 in Calgary, Alberta, Canada. arXiv admin note: text overlap
  with arXiv:1612.03505</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The propagation of sound in a shallow water environment is characterized by
boundary reflections from the sea surface and sea floor. These reflections
result in multiple (indirect) sound propagation paths, which can degrade the
performance of passive sound source localization methods. This paper proposes
the use of convolutional neural networks (CNNs) for the localization of sources
of broadband acoustic radiated noise (such as motor vessels) in shallow water
multipath environments. It is shown that CNNs operating on cepstrogram and
generalized cross-correlogram inputs are able to more reliably estimate the
instantaneous range and bearing of transiting motor vessels when the source
localization performance of conventional passive ranging methods is degraded.
The ensuing improvement in source localization performance is demonstrated
using real data collected during an at-sea experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10974</identifier>
 <datestamp>2018-02-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10974</id><created>2017-10-30</created><updated>2018-02-15</updated><authors><author><keyname>Manocha</keyname><forenames>Pranay</forenames></author><author><keyname>Badlani</keyname><forenames>Rohan</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author><author><keyname>Shah</keyname><forenames>Ankit</forenames></author><author><keyname>Elizalde</keyname><forenames>Benjamin</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author></authors><title>Content-based Representations of audio using Siamese neural networks</title><categories>cs.SD cs.IR eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on the problem of content-based retrieval for audio,
which aims to retrieve all semantically similar audio recordings for a given
audio clip query. This problem is similar to the problem of query by example of
audio, which aims to retrieve media samples from a database, which are similar
to the user-provided example. We propose a novel approach which encodes the
audio into a vector representation using Siamese Neural Networks. The goal is
to obtain an encoding similar for files belonging to the same audio class, thus
allowing retrieval of semantically similar audio. Using simple similarity
measures such as those based on simple euclidean distance and cosine similarity
we show that these representations can be very effectively used for retrieving
recordings similar in audio content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10976</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10976</id><created>2017-10-30</created><authors><author><keyname>Lou</keyname><forenames>Shun</forenames></author><author><keyname>Gong</keyname><forenames>Chen</forenames></author><author><keyname>Gao</keyname><forenames>Qian</forenames></author><author><keyname>Xu</keyname><forenames>Zhengyuan</forenames></author></authors><title>SCMA with Low Complexity Symmetric Codebook Design for Visible Light
  Communication</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse code multiple access (SCMA) is attracting significant research
interests currently, which is considered as a promising multiple access
technique for 5G systems. It serves as a good candidate for the future
communication network with massive nodes due to its capability of handling user
overloading. Introducing SCMA to visible light communication (VLC) can provide
another opportunity on design of transmission protocols for the communication
network with massive nodes due to the limited communication range of VLC, which
reduces the interference intensity. However, when applying SCMA in VLC systems,
we need to modify the SCMA codebook to accommodate the real and positive signal
requirement for VLC.We apply multidimensional constellation design methods to
SCMA codebook. To reduce the design complexity, we also propose a symmetric
codebook design. For all the proposed design approaches, the minimum Euclidean
distance aims to be maximized. Our symmetric codebook design can reduce design
and detection complexity simultaneously. Simulation results show that our
design implies fast convergence with respect to the number of iterations, and
outperforms the design that simply modifies the existing approaches to VLC
signal requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.10985</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.10985</id><created>2017-10-27</created><authors><author><keyname>Overgaard</keyname><forenames>Niels Chr.</forenames></author></authors><title>On the Taut String Interpretation of the One-dimensional
  Rudin-Osher-Fatemi Model: A New Proof, a Fundamental Estimate and Some
  Applications</title><categories>eess.IV cs.CV</categories><comments>19 pages, 2 figures, 1 appendix</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new proof of the equivalence of the Taut String Algorithm and the
one-dimensional Rudin-Osher-Fatemi model is presented. Based on duality and the
projection theorem in Hilbert space, the proof is strictly elementary.
Existence and uniqueness of solutions to both denoising models follow as
by-products. The standard convergence properties of the denoised signal, as the
regularizing parameter tends to zero, are recalled and efficient proofs
provided. Moreover, a new and fundamental bound on the denoised signal is
derived. This bound implies, among other things, the strong convergence (in the
space of functions of bounded variation) of the denoised signal to the insignal
as the regularization parameter vanishes. The methods developed in the paper
can be modified to cover other interesting applications such as isotonic
regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11026</identifier>
 <datestamp>2019-06-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11026</id><created>2017-10-30</created><updated>2018-05-02</updated><authors><author><keyname>Renevey</keyname><forenames>Philippe</forenames></author><author><keyname>Delgado-Gonzalo</keyname><forenames>Ricard</forenames></author><author><keyname>Lemkaddem</keyname><forenames>Alia</forenames></author><author><keyname>Verjus</keyname><forenames>Christophe</forenames></author><author><keyname>Combertaldi</keyname><forenames>Selina</forenames></author><author><keyname>Rasch</keyname><forenames>Bj&#xf6;rn</forenames></author><author><keyname>Leeners</keyname><forenames>Brigitte</forenames></author><author><keyname>Dammeier</keyname><forenames>Franziska</forenames></author><author><keyname>K&#xfc;bler</keyname><forenames>Florian</forenames></author></authors><title>Respiratory and cardiac monitoring at night using a wrist wearable
  optical system</title><categories>eess.SP</categories><comments>Submitted to the 40th International Conference of the IEEE
  Engineering in Medicine and Biology Society (EMBC)</comments><doi>10.1109/EMBC.2018.8512881</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sleep monitoring provides valuable insights into the general health of an
individual and helps in the diagnostic of sleep-derived illnesses.
Polysomnography, is considered the gold standard for such task. However, it is
very unwieldy and therefore not suitable for long-term analysis. Here, we
present a non-intrusive wearable system that, by using photoplethysmography, it
can estimate beat-to-beat intervals, pulse rate, and breathing rate reliably
during the night. The performance of the proposed approach was evaluated
empirically in the Department of Psychology at the University of Fribourg. Each
participant was wearing two smart-bracelets from Ava as well as a complete
polysomnographic setup as reference. The resulting mean absolute errors are
17.4 ms (MAPE 1.8%) for the beat-to-beat intervals, 0.13 beats-per-minute (MAPE
0.20%) for the pulse rate, and 0.9 breaths-per-minute (MAPE 6.7%) for the
breath rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11062</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11062</id><created>2017-10-27</created><updated>2017-11-02</updated><authors><author><keyname>Mohammadi</keyname><forenames>Mohammadali</forenames></author><author><keyname>Shi</keyname><forenames>Xiaoyan</forenames></author><author><keyname>Chalise</keyname><forenames>Batu K.</forenames></author><author><keyname>Suraweera</keyname><forenames>Himal A.</forenames></author><author><keyname>Zhong</keyname><forenames>Caijun</forenames></author><author><keyname>Thompson</keyname><forenames>John S.</forenames></author></authors><title>Full-Duplex Non-Orthogonal Multiple Access for Modern Wireless Networks</title><categories>eess.SP</categories><comments>Revised, IEEE Wireless Communication Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-orthogonal multiple access (NOMA) is an interesting concept to provide
higher capacity for future wireless communications. In this article, we
consider the feasibility and benefits of combining full-duplex operation with
NOMA for modern communication systems. Specifically, we provide a comprehensive
overview on application of full-duplex NOMA in cellular networks, cooperative
and cognitive radio networks, and characterize gains possible due to
full-duplex operation. Accordingly, we discuss challenges, particularly the
self-interference and inter-user interference and provide potential solutions
to interference mitigation and quality-of-service provision based on
beamforming, power control, and link scheduling. We further discuss future
research challenges and interesting directions to pursue to bring full-duplex
NOMA into maturity and use in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11120</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11120</id><created>2017-10-28</created><authors><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Djouadi</keyname><forenames>Seddik M.</forenames></author><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Kuruganti</keyname><forenames>Teja</forenames></author></authors><title>Estimation and Control over Cognitive Radio Channels with Distributed
  and Dynamic Spectral Activity</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since its first inception by Joseph Mitola III in 1998 cognitive radio (CR)
systems have seen an explosion of papers in the communication community.
However, the interaction of CR and control has remained vastly unexplored. In
fact, when combined with control theory CR may pave the way for new and
exciting control and communication applications. In this paper, the control and
estimation problem via the well known two switch model which represents a CR
link is considered. In particular, The optimal linear estimator subject to a CR
link between the sensor and the estimator is derived. Furthermore, it is shown
that in the Linear Quadratic Gaussian (LQG) Control law for a closed-loop
system over double CR links is not linear in the state estimate. Consequently,
the separation principle is shown to be violated. Several conditions of
stochastic stability are also discussed. Illustrative numerical examples are
provided to show the effectiveness of the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11124</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11124</id><created>2017-10-30</created><authors><author><keyname>Huang</keyname><forenames>Jianwen</forenames></author><author><keyname>Wang</keyname><forenames>Jianjun</forenames></author><author><keyname>Zhang</keyname><forenames>Feng</forenames></author><author><keyname>Wang</keyname><forenames>Wendong</forenames></author></authors><title>New sufficient conditions of signal recovery with tight frames via
  $l_1$-analysis</title><categories>eess.SP</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper discusses the recovery of signals in the case that signals are
nearly sparse with respect to a tight frame $D$ by means of the $l_1$-analysis
approach. We establish several new sufficient conditions regarding the
$D$-restricted isometry property to ensure stable reconstruction of signals
that are approximately sparse with respect to $D$. It is shown that if the
measurement matrix $\Phi$ fulfils the condition $\delta_{ts}&lt;t/(4-t)$ for
$0&lt;t&lt;4/3$, then signals which are approximately sparse with respect to $D$ can
be stably recovered by the $l_1$-analysis method. In the case of $D=I$, the
bound is sharp, see Cai and Zhang's work \cite{Cai and Zhang 2014}. When $t=1$,
the present bound improves the condition $\delta_s&lt;0.307$ from Lin et al.'s
reuslt to $\delta_s&lt;1/3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11125</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11125</id><created>2017-10-30</created><authors><author><keyname>Huang</keyname><forenames>Jianwen</forenames></author><author><keyname>Wang</keyname><forenames>Jianjun</forenames></author><author><keyname>Wang</keyname><forenames>Wendong</forenames></author><author><keyname>Zhang</keyname><forenames>Feng</forenames></author></authors><title>A sharp sufficient condition of block signal recovery via
  $l_2/l_1$-minimization</title><categories>eess.SP</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work gains a sharp sufficient condition on the block restricted isometry
property for the recovery of sparse signal. Under the certain assumption, the
signal with block structure can be stably recovered in the present of noisy
case and the block sparse signal can be exactly reconstructed in the noise-free
case. Besides, an example is proposed to exhibit the condition is sharp. As
byproduct, when $t=1$, the result improves the bound of block restricted
isometry constant $\delta_{s|\mathcal{I}}$ in Lin and Li (Acta Math. Sin. Engl.
Ser. 29(7): 1401-1412, 2013).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11151</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11151</id><created>2017-10-30</created><updated>2018-02-15</updated><authors><author><keyname>Choi</keyname><forenames>Hyomin</forenames></author><author><keyname>Bajic</keyname><forenames>Ivan V.</forenames></author></authors><title>High efficiency compression for object detection</title><categories>eess.IV cs.CV</categories><comments>The paper is published in IEEE ICASSP 18'</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image and video compression has traditionally been tailored to human vision.
However, modern applications such as visual analytics and surveillance rely on
computers seeing and analyzing the images before (or instead of) humans. For
these applications, it is important to adjust compression to computer vision.
In this paper we present a bit allocation and rate control strategy that is
tailored to object detection. Using the initial convolutional layers of a
state-of-the-art object detector, we create an importance map that can guide
bit allocation to areas that are important for object detection. The proposed
method enables bit rate savings of 7% or more compared to default HEVC, at the
equivalent object detection rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11153</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11153</id><created>2017-10-30</created><updated>2018-06-05</updated><authors><author><keyname>Hawthorne</keyname><forenames>Curtis</forenames></author><author><keyname>Elsen</keyname><forenames>Erich</forenames></author><author><keyname>Song</keyname><forenames>Jialin</forenames></author><author><keyname>Roberts</keyname><forenames>Adam</forenames></author><author><keyname>Simon</keyname><forenames>Ian</forenames></author><author><keyname>Raffel</keyname><forenames>Colin</forenames></author><author><keyname>Engel</keyname><forenames>Jesse</forenames></author><author><keyname>Oore</keyname><forenames>Sageev</forenames></author><author><keyname>Eck</keyname><forenames>Douglas</forenames></author></authors><title>Onsets and Frames: Dual-Objective Piano Transcription</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>Examples available at https://goo.gl/magenta/onsets-frames-examples</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We advance the state of the art in polyphonic piano music transcription by
using a deep convolutional and recurrent neural network which is trained to
jointly predict onsets and frames. Our model predicts pitch onset events and
then uses those predictions to condition framewise pitch predictions. During
inference, we restrict the predictions from the framewise detector by not
allowing a new note to start unless the onset detector also agrees that an
onset for that pitch is present in the frame. We focus on improving onsets and
offsets together instead of either in isolation as we believe this correlates
better with human musical perception. Our approach results in over a 100%
relative improvement in note F1 score (with offsets) on the MAPS dataset.
Furthermore, we extend the model to predict relative velocities of normalized
audio which results in more natural-sounding transcriptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11251</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11251</id><created>2017-10-30</created><updated>2018-03-12</updated><authors><author><keyname>Demesmaeker</keyname><forenames>Robin</forenames></author><author><keyname>Preti</keyname><forenames>Maria Giulia</forenames></author><author><keyname>Van De Ville</keyname><forenames>Dimitri</forenames></author></authors><title>Augmented Slepians: Bandlimited Functions that Counterbalance Energy in
  Selected Intervals</title><categories>eess.SP</categories><doi>10.1109/TSP.2018.2844193</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Slepian functions provide a solution to the optimization problem of joint
time-frequency localization. Here, this concept is extended by using a
generalized optimization criterion that favors energy concentration in one
interval while penalizing energy in another interval, leading to the
&quot;augmented&quot; Slepian functions. Mathematical foundations together with examples
are presented in order to illustrate the most interesting properties that these
generalized Slepian functions show. Also the relevance of this novel
energy-concentration criterion is discussed along with some of its
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11270</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11270</id><created>2017-10-30</created><authors><author><keyname>Saxena</keyname><forenames>Vidit</forenames></author><author><keyname>Jald&#xe9;n</keyname><forenames>Joakim</forenames></author><author><keyname>Bengtsson</keyname><forenames>Mats</forenames></author><author><keyname>Tullberg</keyname><forenames>Hugo</forenames></author></authors><title>Deep Learning for Frame Error Probability Prediction in BICM-OFDM
  Systems</title><categories>eess.SP</categories><comments>Submitted to 2018 IEEE International Conference on Acoustics, Speech
  and Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of wireless communications, we propose a deep learning
approach to learn the mapping from the instantaneous state of a frequency
selective fading channel to the corresponding frame error probability (FEP) for
an arbitrary set of transmission parameters. We propose an abstract model of a
bit interleaved coded modulation (BICM) orthogonal frequency division
multiplexing (OFDM) link chain and show that the maximum likelihood (ML)
estimator of the model parameters estimates the true FEP distribution. Further,
we exploit deep neural networks as a general purpose tool to implement our
model and propose a training scheme for which, even while training with the
binary frame error events (i.e., ACKs / NACKs), the network outputs converge to
the FEP conditioned on the input channel state. We provide simulation results
that demonstrate gains in the FEP prediction accuracy with our approach as
compared to the traditional effective exponential SIR metric (EESM) approach
for a range of channel code rates, and show that these gains can be exploited
to increase the link throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11317</identifier>
 <datestamp>2018-06-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11317</id><created>2017-10-31</created><updated>2018-06-06</updated><authors><author><keyname>Hua</keyname><forenames>Kanru</forenames></author></authors><title>Nebula: F0 Estimation and Voicing Detection by Modeling the Statistical
  Properties of Feature Extractors</title><categories>eess.AS cs.SD</categories><comments>To be presented at Interspeech 2018</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  A F0 and voicing status estimation algorithm for high quality speech
analysis/synthesis is proposed. This problem is approached from a different
perspective that models the behavior of feature extractors under noise, instead
of directly modeling speech signals. Under time-frequency locality assumptions,
the joint distribution of extracted features and target F0 can be characterized
by training a bank of Gaussian mixture models (GMM) on artificial data
generated from Monte-Carlo simulations. The trained GMMs can then be used to
generate a set of conditional distributions on the predicted F0, which are then
combined and post-processed by Viterbi algorithm to give a final F0 trajectory.
Evaluation on CSTR and CMU Arctic speech databases shows that the proposed
method, trained on fully synthetic data, achieves lower gross error rates than
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11385</identifier>
 <datestamp>2019-04-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11385</id><created>2017-10-31</created><updated>2018-11-07</updated><authors><author><keyname>Grinstein</keyname><forenames>Eric</forenames></author><author><keyname>Duong</keyname><forenames>Ngoc</forenames></author><author><keyname>Ozerov</keyname><forenames>Alexey</forenames></author><author><keyname>P&#xe9;rez</keyname><forenames>Patrick</forenames></author></authors><title>Audio style transfer</title><categories>cs.SD eess.AS physics.class-ph</categories><comments>ICASSP 2018 - 2018 IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP), Apr 2018, Calgary, France. IEEE</comments><proxy>ccsd</proxy><doi>10.1109/ICASSP.2018.8461711</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  'Style transfer' among images has recently emerged as a very active research
topic, fuelled by the power of convolution neural networks (CNNs), and has
become fast a very popular technology in social media. This paper investigates
the analogous problem in the audio domain: How to transfer the style of a
reference audio signal to a target audio content? We propose a flexible
framework for the task, which uses a sound texture model to extract statistics
characterizing the reference audio style, followed by an optimization-based
audio texture synthesis to modify the target content. In contrast to mainstream
optimization-based visual transfer method, the proposed process is initialized
by the target content instead of random noise and the optimized loss is only
about texture, not structure. These differences proved key for audio style
transfer in our experiments. In order to extract features of interest, we
investigate different architectures, whether pre-trained on other tasks, as
done in image style transfer, or engineered based on the human auditory system.
Experimental results on different types of audio signal confirm the potential
of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11418</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11418</id><created>2017-10-31</created><updated>2018-07-02</updated><authors><author><keyname>Lee</keyname><forenames>Sang-gil</forenames></author><author><keyname>Hwang</keyname><forenames>Uiwon</forenames></author><author><keyname>Min</keyname><forenames>Seonwoo</forenames></author><author><keyname>Yoon</keyname><forenames>Sungroh</forenames></author></authors><title>Polyphonic Music Generation with Sequence Generative Adversarial
  Networks</title><categories>cs.SD eess.AS</categories><comments>8 pages, 3 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an application of sequence generative adversarial networks
(SeqGAN), which are generative adversarial networks for discrete sequence
generation, for creating polyphonic musical sequences. Instead of a monophonic
melody generation suggested in the original work, we present an efficient
representation of a polyphony MIDI file that simultaneously captures chords and
melodies with dynamic timings. The proposed method condenses duration, octaves,
and keys of both melodies and chords into a single word vector representation,
and recurrent neural networks learn to predict distributions of sequences from
the embedded musical word space. We experiment with the original method and the
least squares method to the discriminator, which is known to stabilize the
training of GANs. The network can create sequences that are musically coherent
and shows an improved quantitative and qualitative measures. We also report
that careful optimization of reinforcement learning signals of the model is
crucial for general application of the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11428</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11428</id><created>2017-10-31</created><updated>2017-11-13</updated><authors><author><keyname>Fan</keyname><forenames>Zhe-Cheng</forenames></author><author><keyname>Lai</keyname><forenames>Yen-Lin</forenames></author><author><keyname>Jang</keyname><forenames>Jyh-Shing Roger</forenames></author></authors><title>SVSGAN: Singing Voice Separation via Generative Adversarial Network</title><categories>cs.SD cs.LG eess.AS</categories><comments>5 pages, 4 figures, 1 table. Demo website:
  http://mirlab.org/demo/svsgan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Separating two sources from an audio mixture is an important task with many
applications. It is a challenging problem since only one signal channel is
available for analysis. In this paper, we propose a novel framework for singing
voice separation using the generative adversarial network (GAN) with a
time-frequency masking function. The mixture spectra is considered to be a
distribution and is mapped to the clean spectra which is also considered a
distribtution. The approximation of distributions between mixture spectra and
clean spectra is performed during the adversarial training process. In contrast
with current deep learning approaches for source separation, the parameters of
the proposed framework are first initialized in a supervised setting and then
optimized by the training procedure of GAN in an unsupervised setting.
Experimental results on three datasets (MIR-1K, iKala and DSD100) show that
performance can be improved by the proposed framework consisting of
conventional networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11439</identifier>
 <datestamp>2019-03-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11439</id><created>2017-10-31</created><updated>2018-03-19</updated><authors><author><keyname>Bando</keyname><forenames>Yoshiaki</forenames></author><author><keyname>Mimura</keyname><forenames>Masato</forenames></author><author><keyname>Itoyama</keyname><forenames>Katsutoshi</forenames></author><author><keyname>Yoshii</keyname><forenames>Kazuyoshi</forenames></author><author><keyname>Kawahara</keyname><forenames>Tatsuya</forenames></author></authors><title>Statistical Speech Enhancement Based on Probabilistic Integration of
  Variational Autoencoder and Non-Negative Matrix Factorization</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>5 pages, 3 figures, version that Eqs. (9), (19), and (20) in v2
  (submitted to ICASSP 2018) are corrected. Samples available here:
  http://sap.ist.i.kyoto-u.ac.jp/members/yoshiaki/demo/vae-nmf/</comments><doi>10.1109/ICASSP.2018.8461530</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a statistical method of single-channel speech enhancement
that uses a variational autoencoder (VAE) as a prior distribution on clean
speech. A standard approach to speech enhancement is to train a deep neural
network (DNN) to take noisy speech as input and output clean speech. Although
this supervised approach requires a very large amount of pair data for
training, it is not robust against unknown environments. Another approach is to
use non-negative matrix factorization (NMF) based on basis spectra trained on
clean speech in advance and those adapted to noise on the fly. This
semi-supervised approach, however, causes considerable signal distortion in
enhanced speech due to the unrealistic assumption that speech spectrograms are
linear combinations of the basis spectra. Replacing the poor linear generative
model of clean speech in NMF with a VAE---a powerful nonlinear deep generative
model---trained on clean speech, we formulate a unified probabilistic
generative model of noisy speech. Given noisy speech as observed data, we can
sample clean speech from its posterior distribution. The proposed method
outperformed the conventional DNN-based method in unseen noisy environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11473</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11473</id><created>2017-10-28</created><authors><author><keyname>Grais</keyname><forenames>Emad M.</forenames></author><author><keyname>Wierstorf</keyname><forenames>Hagen</forenames></author><author><keyname>Ward</keyname><forenames>Dominic</forenames></author><author><keyname>Plumbley</keyname><forenames>Mark D.</forenames></author></authors><title>Multi-Resolution Fully Convolutional Neural Networks for Monaural Audio
  Source Separation</title><categories>cs.SD cs.CV cs.LG eess.AS</categories><comments>arXiv admin note: text overlap with arXiv:1703.08019</comments><msc-class>68T01</msc-class><acm-class>H.5.5; I.5; I.2.6; I.4.3; I.4; I.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In deep neural networks with convolutional layers, each layer typically has
fixed-size/single-resolution receptive field (RF). Convolutional layers with a
large RF capture global information from the input features, while layers with
small RF size capture local details with high resolution from the input
features. In this work, we introduce novel deep multi-resolution fully
convolutional neural networks (MR-FCNN), where each layer has different RF
sizes to extract multi-resolution features that capture the global and local
details information from its input features. The proposed MR-FCNN is applied to
separate a target audio source from a mixture of many audio sources.
Experimental results show that using MR-FCNN improves the performance compared
to feedforward deep neural networks (DNNs) and single resolution deep fully
convolutional neural networks (FCNNs) on the audio source separation problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11549</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11549</id><created>2017-10-31</created><authors><author><keyname>Shin</keyname><forenames>Andrew</forenames></author><author><keyname>Crestel</keyname><forenames>Leopold</forenames></author><author><keyname>Kato</keyname><forenames>Hiroharu</forenames></author><author><keyname>Saito</keyname><forenames>Kuniaki</forenames></author><author><keyname>Ohnishi</keyname><forenames>Katsunori</forenames></author><author><keyname>Yamaguchi</keyname><forenames>Masataka</forenames></author><author><keyname>Nakawaki</keyname><forenames>Masahiro</forenames></author><author><keyname>Ushiku</keyname><forenames>Yoshitaka</forenames></author><author><keyname>Harada</keyname><forenames>Tatsuya</forenames></author></authors><title>Melody Generation for Pop Music via Word Representation of Musical
  Properties</title><categories>cs.SD cs.MM eess.AS</categories><comments>submitted to ICLR 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic melody generation for pop music has been a long-time aspiration for
both AI researchers and musicians. However, learning to generate euphonious
melody has turned out to be highly challenging due to a number of factors.
Representation of multivariate property of notes has been one of the primary
challenges. It is also difficult to remain in the permissible spectrum of
musical variety, outside of which would be perceived as a plain random play
without auditory pleasantness. Observing the conventional structure of pop
music poses further challenges. In this paper, we propose to represent each
note and its properties as a unique `word,' thus lessening the prospect of
misalignments between the properties, as well as reducing the complexity of
learning. We also enforce regularization policies on the range of notes, thus
encouraging the generated melody to stay close to what humans would find easy
to follow. Furthermore, we generate melody conditioned on song part
information, thus replicating the overall structure of a full song.
Experimental results demonstrate that our model can generate auditorily
pleasant songs that are more indistinguishable from human-written ones than
previous models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.11594</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1710.11594</id><created>2017-10-31</created><authors><author><keyname>Krikheli</keyname><forenames>Michael</forenames></author><author><keyname>Leshem</keyname><forenames>Amir</forenames></author></authors><title>Finite sample performance of linear least squares estimators under
  sub-Gaussian martingale difference noise</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear Least Squares is a very well known technique for parameter estimation,
which is used even when sub-optimal, because of its very low computational
requirements and the fact that exact knowledge of the noise statistics is not
required. Surprisingly, bounding the probability of large errors with finitely
many samples has been left open, especially when dealing with correlated noise
with unknown covariance. In this paper we analyze the finite sample performance
of the linear least squares estimator under sub-Gaussian martingale difference
noise. In order to analyze this important question we used concentration of
measure bounds. When applying these bounds we obtained tight bounds on the tail
of the estimator's distribution. We show the fast exponential convergence of
the number of samples required to ensure a given accuracy with high
probability. We provide probability tail bounds on the estimation error's norm.
Our analysis method is simple and uses simple $L_{\infty}$ type bounds on the
estimation error. The tightness of the bounds is tested through simulation. The
proposed bounds make it possible to predict the number of samples required for
least squares estimation even when least squares is sub-optimal and used for
computational simplicity. The finite sample analysis of least squares models
with this general noise model is novel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00069</identifier>
 <datestamp>2019-03-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00069</id><created>2017-10-31</created><updated>2019-03-20</updated><authors><author><keyname>Wang</keyname><forenames>Shulei</forenames></author><author><keyname>Arena</keyname><forenames>Ellen T.</forenames></author><author><keyname>Becker</keyname><forenames>Jordan T.</forenames></author><author><keyname>Bement</keyname><forenames>William M.</forenames></author><author><keyname>Sherer</keyname><forenames>Nathan M.</forenames></author><author><keyname>Eliceiri</keyname><forenames>Kevin W.</forenames></author><author><keyname>Yuan</keyname><forenames>Ming</forenames></author></authors><title>Spatially Adaptive Colocalization Analysis in Dual-Color Fluorescence
  Microscopy</title><categories>stat.ME eess.IV q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colocalization analysis aims to study complex spatial associations between
bio-molecules via optical imaging techniques. However, existing colocalization
analysis workflows only assess an average degree of colocalization within a
certain region of interest and ignore the unique and valuable spatial
information offered by microscopy. In the current work, we introduce a new
framework for colocalization analysis that allows us to quantify colocalization
levels at each individual location and automatically identify pixels or regions
where colocalization occurs. The framework, referred to as spatially adaptive
colocalization analysis (SACA), integrates a pixel-wise local kernel model for
colocalization quantification and a multi-scale adaptive propagation-separation
strategy for utilizing spatial information to detect colocalization in a
spatially adaptive fashion. Applications to simulated and real biological
datasets demonstrate the practical merits of SACA in what we hope to be an
easily applicable and robust colocalization analysis method. In addition,
theoretical properties of SACA are investigated to provide rigorous statistical
justification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00124</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00124</id><created>2017-10-31</created><authors><author><keyname>Pires</keyname><forenames>Ivan Miguel</forenames></author><author><keyname>Garcia</keyname><forenames>Nuno M.</forenames></author><author><keyname>Pombo</keyname><forenames>Nuno</forenames></author><author><keyname>Fl&#xf3;rez-Revuelta</keyname><forenames>Francisco</forenames></author></authors><title>User Environment Detection with Acoustic Sensors Embedded on Mobile
  Devices for the Recognition of Activities of Daily Living</title><categories>cs.SD eess.AS physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The detection of the environment where user is located, is of extreme use for
the identification of Activities of Daily Living (ADL). ADL can be identified
by use of the sensors available in many off-the-shelf mobile devices, including
magnetic and motion, and the environment can be also identified using acoustic
sensors. The study presented in this paper is divided in two parts: firstly, we
discuss the recognition of the environment using acoustic sensors (i.e.,
microphone), and secondly, we fuse this information with motion and magnetic
sensors (i.e., motion and magnetic sensors) for the recognition of standing
activities of daily living. The recognition of the environments and the ADL are
performed using pattern recognition techniques, in order to develop a system
that includes data acquisition, data processing, data fusion, and artificial
intelligence methods. The artificial intelligence methods explored in this
study are composed by different types of Artificial Neural Networks (ANN),
comparing the different types of ANN and selecting the best methods to
implement in the different stages of the system developed. Conclusions point to
the use of Deep Neural Networks (DNN) with normalized data for the
identification of ADL with 85.89% of accuracy, the use of Feedforward neural
networks with non-normalized data for the identification of the environments
with 86.50% of accuracy, and the use of DNN with normalized data for the
identification of standing activities with 100% of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00213</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00213</id><created>2017-11-01</created><authors><author><keyname>Lu</keyname><forenames>Keng-Shih</forenames></author><author><keyname>Ortega</keyname><forenames>Antonio</forenames></author></authors><title>Closed Form Solutions of Combinatorial Graph Laplacian Estimation under
  Acyclic Topology Constraints</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How to obtain a graph from data samples is an important problem in graph
signal processing. One way to formulate this graph learning problem is based on
Gaussian maximum likelihood estimation, possibly under particular topology
constraints. To solve this problem, we typically require iterative convex
optimization solvers. In this paper, we show that when the target graph
topology does not contain any cycle, then the solution has a closed form in
terms of the empirical covariance matrix. This enables us to efficiently
construct a tree graph from data, even if there is only a single data sample
available. We also provide an error bound of the objective function when we use
the same solution to approximate a cyclic graph. As an example, we consider an
image denoising problem, in which for each input image we construct a graph
based on the theoretical result. We then apply low-pass graph filters based on
this graph. Experimental results show that the weights given by the graph
learning solution lead to better denoising results than the bilateral weights
under some conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00229</identifier>
 <datestamp>2018-10-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00229</id><created>2017-11-01</created><updated>2018-10-30</updated><authors><author><keyname>Wu</keyname><forenames>Yuzhong</forenames></author><author><keyname>Lee</keyname><forenames>Tan</forenames></author></authors><title>Reducing Model Complexity for DNN Based Large-Scale Audio Classification</title><categories>cs.SD eess.AS</categories><comments>Accepted by ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Audio classification is the task of identifying the sound categories that are
associated with a given audio signal. This paper presents an investigation on
large-scale audio classification based on the recently released AudioSet
database. AudioSet comprises 2 millions of audio samples from YouTube, which
are human-annotated with 527 sound category labels. Audio classification
experiments with the balanced training set and the evaluation set of AudioSet
are carried out by applying different types of neural network models. The
classification performance and the model complexity of these models are
compared and analyzed. While the CNN models show better performance than MLP
and RNN, its model complexity is relatively high and undesirable for practical
use. We propose two different strategies that aim at constructing
low-dimensional embedding feature extractors and hence reducing the number of
model parameters. It is shown that the simplified CNN model has only 1/22 model
parameters of the original model, with only a slight degradation of
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00261</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00261</id><created>2017-11-01</created><authors><author><keyname>Mannari</keyname><forenames>Toko</forenames></author><author><keyname>Hikihara</keyname><forenames>Takashi</forenames></author></authors><title>Transient Behavior of Redox Flow Battery Connected to Circuit Based on
  Global Phase Structure</title><categories>eess.SP math.DS</categories><comments>10 pages, 7 figures, IEICE, Nonlinear Theory and Its Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Redox Flow Battery (RFB) is one of the promising energy storage systems in
power grid. An RFB has many advantages such as a quick response, a large
capacity, and a scalability. Due to these advantages, an RFB can operate in
mixed time scale. Actually, it has been demonstrated that an RFB can be used
for load leveling, compensating sag, and smoothing the output of the renewable
sources. An analysis on transient behaviors of an RFB is a key issue for these
applications. An RFB is governed by electrical, chemical, and fluid dynamics.
The hybrid structure makes the analysis difficult. To analyze transient
behaviors of an RFB, the exact model is necessary. In this paper, we focus on a
change in a concentration of ions in the electrolyte, and simulate the change
with a model which is mainly based on chemical kinetics. The simulation results
introduces transient behaviors of an RFB in a response to a load variation.
There are found three kinds of typical transient behaviors including
oscillations. As results, it is clarified that the complex transient behaviors,
due to slow and fast dynamics in the system, arise by the quick response to
load.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00328</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00328</id><created>2017-11-01</created><updated>2020-01-17</updated><authors><author><keyname>Sreter</keyname><forenames>Hillel</forenames></author><author><keyname>Giryes</keyname><forenames>Raja</forenames></author></authors><title>Learned Convolutional Sparse Coding</title><categories>eess.SP</categories><journal-ref>ICASSP 2018</journal-ref><doi>10.1109/ICASSP.2018.8462313</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a convolutional recurrent sparse auto-encoder model. The model
consists of a sparse encoder, which is a convolutional extension of the learned
ISTA (LISTA) method, and a linear convolutional decoder. Our strategy offers a
simple method for learning a task-driven sparse convolutional dictionary (CD),
and producing an approximate convolutional sparse code (CSC) over the learned
dictionary. We trained the model to minimize reconstruction loss via gradient
decent with back-propagation and have achieved competitive results to KSVD
image denoising and to leading CSC methods in image inpainting requiring only a
small fraction of their run-time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00351</identifier>
 <datestamp>2018-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00351</id><created>2017-11-01</created><updated>2018-02-16</updated><authors><author><keyname>Yela</keyname><forenames>Delia Fano</forenames></author><author><keyname>Ewert</keyname><forenames>Sebastian</forenames></author><author><keyname>O'Hanlon</keyname><forenames>Ken</forenames></author><author><keyname>Sandler</keyname><forenames>Mark B.</forenames></author></authors><title>Shift-Invariant Kernel Additive Modelling for Audio Source Separation</title><categories>cs.SD eess.AS</categories><comments>Feedback is welcome</comments><acm-class>H.5.5; I.5.1; I.5.4</acm-class><journal-ref>IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), Calgary, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major goal in blind source separation to identify and separate sources is
to model their inherent characteristics. While most state-of-the-art approaches
are supervised methods trained on large datasets, interest in non-data-driven
approaches such as Kernel Additive Modelling (KAM) remains high due to their
interpretability and adaptability. KAM performs the separation of a given
source applying robust statistics on the time-frequency bins selected by a
source-specific kernel function, commonly the K-NN function. This choice
assumes that the source of interest repeats in both time and frequency. In
practice, this assumption does not always hold. Therefore, we introduce a
shift-invariant kernel function capable of identifying similar spectral content
even under frequency shifts. This way, we can considerably increase the amount
of suitable sound material available to the robust statistics. While this leads
to an increase in separation performance, a basic formulation, however, is
computationally expensive. Therefore, we additionally present acceleration
techniques that lower the overall computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00366</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00366</id><created>2017-10-31</created><updated>2018-02-27</updated><authors><author><keyname>Li</keyname><forenames>Lantian</forenames></author><author><keyname>Tang</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Wang</keyname><forenames>Dong</forenames></author><author><keyname>Zheng</keyname><forenames>Thomas Fang</forenames></author></authors><title>Full-info Training for Deep Speaker Feature Learning</title><categories>cs.SD cs.LG eess.AS</categories><comments>Accepted by ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent studies, it has shown that speaker patterns can be learned from
very short speech segments (e.g., 0.3 seconds) by a carefully designed
convolutional &amp; time-delay deep neural network (CT-DNN) model. By enforcing the
model to discriminate the speakers in the training data, frame-level speaker
features can be derived from the last hidden layer. In spite of its good
performance, a potential problem of the present model is that it involves a
parametric classifier, i.e., the last affine layer, which may consume some
discriminative knowledge, thus leading to `information leak' for the feature
learning. This paper presents a full-info training approach that discards the
parametric classifier and enforces all the discriminative knowledge learned by
the feature net. Our experiments on the Fisher database demonstrate that this
new training scheme can produce more coherent features, leading to consistent
and notable performance improvement on the speaker verification task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00379</identifier>
 <datestamp>2018-10-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00379</id><created>2017-11-01</created><updated>2018-10-05</updated><authors><author><keyname>Balatsoukas-Stimming</keyname><forenames>Alexios</forenames></author></authors><title>Non-Linear Digital Self-Interference Cancellation for In-Band
  Full-Duplex Radios Using Neural Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>Presented at the IEEE International Workshop on Signal Processing
  Advances in Wireless Communications (SPAWC) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Full-duplex systems require very strong self-interference cancellation in
order to operate correctly and a significant part of the self-interference
signal is due to non-linear effects created by various transceiver impairments.
As such, linear cancellation alone is usually not sufficient and sophisticated
non-linear cancellation algorithms have been proposed in the literature. In
this work, we investigate the use of a neural network as an alternative to the
traditional non-linear cancellation method that is based on polynomial basis
functions. Measurement results from a full-duplex testbed demonstrate that a
small and simple feed-forward neural network canceler works exceptionally well,
as it can match the performance of the polynomial non-linear canceler with
significantly lower computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00442</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00442</id><created>2017-11-01</created><authors><author><keyname>Yao</keyname><forenames>Miao</forenames></author><author><keyname>Sohul</keyname><forenames>Munawwar</forenames></author><author><keyname>Ma</keyname><forenames>Xiaofu</forenames></author><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey H.</forenames></author></authors><title>Sustainable Green Networking: Exploiting Degrees of Freedom towards
  Energy-Efficient 5G Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The carbon footprint concern in the development and deployment of 5G new
radio systems has drawn the attention to several stakeholders. In this article,
we analyze the critical power consuming component of all candidate 5G system
architectures-the power amplifier (PA)-and propose PA-centric resource
management solutions for green 5G communications. We discuss the impact of
ongoing trends in cellular communications on sustainable green networking and
analyze two communications architectures that allow exploiting the extra
degrees-of-freedom (DoF) from multi-antenna and massive antenna deployments:
small cells/distributed antenna network and massive MIMO. For small cell
systems with a moderate number of antennas, we propose a peak to average power
ratio-aware resource allocation scheme for joint orthogonal frequency and space
division multiple access. For massive MIMO systems, we develop a highly
parallel recurrent neural network for energy-efficient precoding. Simulation
results for representative 5G deployment scenarios demonstrate an energy
efficiency improvement of one order of magnitude or higher with respect to
current state-of-the-art solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00487</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00487</id><created>2017-11-01</created><authors><author><keyname>Kisil</keyname><forenames>Ilia</forenames></author><author><keyname>Calvi</keyname><forenames>Giuseppe G.</forenames></author><author><keyname>Mandic</keyname><forenames>Danilo P.</forenames></author></authors><title>Tensor Valued Common and Individual Feature Extraction:
  Multi-dimensional Perspective</title><categories>eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel method for common and individual feature analysis from exceedingly
large-scale data is proposed, in order to ensure the tractability of both the
computation and storage and thus mitigate the curse of dimensionality, a major
bottleneck in modern data science. This is achieved by making use of the
inherent redundancy in so-called multi-block data structures, which represent
multiple observations of the same phenomenon taken at different times, angles
or recording conditions. Upon providing an intrinsic link between the
properties of the outer vector product and extracted features in tensor
decompositions (TDs), the proposed common and individual information extraction
from multi-block data is performed through imposing physical meaning to
otherwise unconstrained factorisation approaches. This is shown to dramatically
reduce the dimensionality of search spaces for subsequent classification
procedures and to yield greatly enhanced accuracy. Simulations on a multi-class
classification task of large-scale extraction of individual features from a
collection of partially related real-world images demonstrate the advantages of
the &quot;blessing of dimensionality&quot; associated with TDs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00493</identifier>
 <datestamp>2020-02-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00493</id><created>2017-11-01</created><updated>2020-02-18</updated><authors><author><keyname>Alanwar</keyname><forenames>Amr</forenames></author><author><keyname>Said</keyname><forenames>Hazem</forenames></author><author><keyname>Mehta</keyname><forenames>Ankur</forenames></author><author><keyname>Althoff</keyname><forenames>Matthias</forenames></author></authors><title>Event-Triggered Diffusion Kalman Filters</title><categories>cs.SY cs.RO eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed state estimation strongly depends on collaborative signal
processing, which often requires excessive communication and computation to be
executed on resource-constrained sensor nodes. To address this problem, we
propose an event-triggered diffusion Kalman filter, which collects measurements
and exchanges messages between nodes based on a local signal indicating the
estimation error. On this basis, we develop an energy-aware state estimation
algorithm that regulates the resource consumption in wireless networks and
ensures the effectiveness of every consumed resource. The proposed algorithm
does not require the nodes to share its local covariance matrices, and thereby
allows considerably reducing the number of transmission messages. To confirm
its efficiency, we apply the proposed algorithm to the distributed simultaneous
localization and time synchronization problem and evaluate it on a physical
testbed of a mobile quadrotor node and stationary custom ultra-wideband
wireless devices. The obtained experimental results indicate that the proposed
algorithm allows saving 86% of the communication overhead associated with the
original diffusion Kalman filter while causing deterioration of performance by
16% only. We make the Matlab code and the real testing data available online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00541</identifier>
 <datestamp>2018-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00541</id><created>2017-11-01</created><updated>2018-04-17</updated><authors><author><keyname>Luo</keyname><forenames>Yi</forenames></author><author><keyname>Mesgarani</keyname><forenames>Nima</forenames></author></authors><title>TasNet: time-domain audio separation network for real-time,
  single-channel speech separation</title><categories>cs.SD cs.LG cs.MM cs.NE eess.AS</categories><comments>Camera ready version for ICASSP 2018, Calgary, Canada</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Robust speech processing in multi-talker environments requires effective
speech separation. Recent deep learning systems have made significant progress
toward solving this problem, yet it remains challenging particularly in
real-time, short latency applications. Most methods attempt to construct a mask
for each source in time-frequency representation of the mixture signal which is
not necessarily an optimal representation for speech separation. In addition,
time-frequency decomposition results in inherent problems such as
phase/magnitude decoupling and long time window which is required to achieve
sufficient frequency resolution. We propose Time-domain Audio Separation
Network (TasNet) to overcome these limitations. We directly model the signal in
the time-domain using an encoder-decoder framework and perform the source
separation on nonnegative encoder outputs. This method removes the frequency
decomposition step and reduces the separation problem to estimation of source
masks on encoder outputs which is then synthesized by the decoder. Our system
outperforms the current state-of-the-art causal and noncausal speech separation
algorithms, reduces the computational cost of speech separation, and
significantly reduces the minimum required latency of the output. This makes
TasNet suitable for applications where low-power, real-time implementation is
desirable such as in hearable and telecommunication devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00593</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00593</id><created>2017-11-01</created><authors><author><keyname>Shi</keyname><forenames>Minwei</forenames></author><author><keyname>Yang</keyname><forenames>Kai</forenames></author><author><keyname>Xing</keyname><forenames>Chengwen</forenames></author><author><keyname>Fan</keyname><forenames>Rongfei</forenames></author></authors><title>Decoupled Heterogeneous Networks with Millimeter Wave Small Cells</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deploying sub-6GHz network together with millimeter wave (mmWave) is a
promising solution to simultaneously achieve sufficient coverage and high data
rate. In the heterogeneous networks (HetNets), the traditional coupled access,
i.e., the users are constrained to be associated with the same base station in
both downlink and uplink, is no longer optimal, and the concept of downlink and
uplink decoupling has recently been proposed. In this paper, we propose an
analytical framework to investigate the traditional sub-6GHz HetNets
integrating with mmWave small cells (SCells) with decoupled access, where both
the uplink power control and mmWave interference are taken into account. Using
the tools from stochastic geometry, the performance metrics of
signal-to-interference-plus-noise ratio coverage probability, user-perceived
rate coverage probability, and area sum rate are derived. The impact of the
densification of different SCells on the network performance is also analyzed
to give insights on the network design. Simulation results validate the
accuracy of our analysis, and reveal that mmWave interference can not be
neglected when the mmWave SCells are extremely dense and that different kinds
of SCells have various effects on the network performance and thus need to be
organized properly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00701</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00701</id><created>2017-11-02</created><authors><author><keyname>Calvi</keyname><forenames>Giuseppe G.</forenames></author><author><keyname>Kisil</keyname><forenames>Ilia</forenames></author><author><keyname>Mandic</keyname><forenames>Danilo P.</forenames></author></authors><title>The sum of tensor networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tensor networks (TNs) have been gaining interest as multiway data analysis
tools owing to their ability to tackle the curse of dimensionality and to
represent tensors as smaller-scale interconnections of their intrinsic
features. However, despite the obvious advantages, the current treatment of TNs
as stand-alone entities does not take full benefit of their underlying
structure and the associated feature localization. To this end, embarking upon
the analogy with a feature fusion, we propose a rigorous framework for the
combination of TNs, focusing on their summation as the natural way for their
combination. This allows for feature combination for any number of tensors, as
long as their TN representation topologies are isomorphic. The benefits of the
proposed framework are demonstrated on the classification of several groups of
partially related images, where it outperforms standard machine learning
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00727</identifier>
 <datestamp>2018-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00727</id><created>2017-11-01</created><updated>2018-01-31</updated><authors><author><keyname>Lyu</keyname><forenames>Wei</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author><author><keyname>Jiao</keyname><forenames>Chunxu</forenames></author><author><keyname>Qin</keyname><forenames>Kangjian</forenames></author><author><keyname>Zhang</keyname><forenames>Huazi</forenames></author></authors><title>Performance Evaluation of Channel Decoding With Deep Neural Networks</title><categories>eess.SP cs.LG cs.NE</categories><comments>6 pages, 11 figures, Latex; typos corrected; IEEE ICC 2018 to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the demand of high data rate and low latency in fifth generation (5G),
deep neural network decoder (NND) has become a promising candidate due to its
capability of one-shot decoding and parallel computing. In this paper, three
types of NND, i.e., multi-layer perceptron (MLP), convolution neural network
(CNN) and recurrent neural network (RNN), are proposed with the same parameter
magnitude. The performance of these deep neural networks are evaluated through
extensive simulation. Numerical results show that RNN has the best decoding
performance, yet at the price of the highest computational overhead. Moreover,
we find there exists a saturation length for each type of neural network, which
is caused by their restricted learning abilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00804</identifier>
 <datestamp>2018-04-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00804</id><created>2017-11-02</created><updated>2018-04-04</updated><authors><author><keyname>Badlani</keyname><forenames>Rohan</forenames></author><author><keyname>Shah</keyname><forenames>Ankit</forenames></author><author><keyname>Elizalde</keyname><forenames>Benjamin</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author></authors><title>Framework for evaluation of sound event detection in web videos</title><categories>cs.SD cs.AI cs.IR eess.AS</categories><comments>Camera Ready Version of Paper accepted at International Conference on
  Acoustics, Speech, and Signal Processing (ICASSP) 2018. First two Authors -
  Rohan Badlani and Ankit Shah contributed equally</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  The largest source of sound events is web videos. Most videos lack sound
event labels at segment level, however, a significant number of them do respond
to text queries, from a match found using metadata by search engines. In this
paper we explore the extent to which a search query can be used as the true
label for detection of sound events in videos. We present a framework for
large-scale sound event recognition on web videos. The framework crawls videos
using search queries corresponding to 78 sound event labels drawn from three
datasets. The datasets are used to train three classifiers, and we obtain a
prediction on 3.7 million web video segments. We evaluated performance using
the search query as true label and compare it with human labeling. Both types
of ground truth exhibited close performance, to within 10%, and similar
performance trend with increasing number of evaluated segments. Hence, our
experiments show potential for using search query as a preliminary true label
for sound event recognition in web videos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00913</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00913</id><created>2017-11-02</created><authors><author><keyname>Dubey</keyname><forenames>Mohit</forenames></author><author><keyname>Kenyon</keyname><forenames>Garrett</forenames></author><author><keyname>Carlson</keyname><forenames>Nils</forenames></author><author><keyname>Thresher</keyname><forenames>Austin</forenames></author></authors><title>Does Phase Matter For Monaural Source Separation?</title><categories>cs.SD cs.NE eess.AS</categories><comments>4 pages, 2 figures, NIPS format</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The &quot;cocktail party&quot; problem of fully separating multiple sources from a
single channel audio waveform remains unsolved. Current biological
understanding of neural encoding suggests that phase information is preserved
and utilized at every stage of the auditory pathway. However, current
computational approaches primarily discard phase information in order to mask
amplitude spectrograms of sound. In this paper, we seek to address whether
preserving phase information in spectral representations of sound provides
better results in monaural separation of vocals from a musical track by using a
neurally plausible sparse generative model. Our results demonstrate that
preserving phase information reduces artifacts in the separated tracks, as
quantified by the signal to artifact ratio (GSAR). Furthermore, our proposed
method achieves state-of-the-art performance for source separation, as
quantified by a mean signal to interference ratio (GSIR) of 19.46.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00927</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00927</id><created>2017-11-02</created><updated>2018-02-07</updated><authors><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Wang</keyname><forenames>Wenwu</forenames></author><author><keyname>Plumbley</keyname><forenames>Mark D.</forenames></author></authors><title>Audio Set classification with attention model: A probabilistic
  perspective</title><categories>cs.SD eess.AS</categories><comments>Accepted by ICASSP 2018</comments><journal-ref>IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), 2018, pp. 316-320</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the classification of the Audio Set dataset. Audio
Set is a large scale weakly labelled dataset of sound clips. Previous work used
multiple instance learning (MIL) to classify weakly labelled data. In MIL, a
bag consists of several instances, and a bag is labelled positive if at least
one instances in the audio clip is positive. A bag is labelled negative if all
the instances in the bag are negative. We propose an attention model to tackle
the MIL problem and explain this attention model from a novel probabilistic
perspective. We define a probability space on each bag, where each instance in
the bag has a trainable probability measure for each class. Then the
classification of a bag is the expectation of the classification output of the
instances in the bag with respect to the learned probability measure.
Experimental results show that our proposed attention model modeled by fully
connected deep neural network obtains mAP of 0.327 on Audio Set dataset,
outperforming the Google's baseline of 0.314 and recurrent neural network of
0.325.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.00962</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.00962</id><created>2017-11-02</created><authors><author><keyname>Zappone</keyname><forenames>Alessio</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Energy-Delay Efficient Power Control in Wireless Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>13 pages, 6 figures, to appear on IEEE Transactions on Communications</comments><doi>10.1109/TCOMM.2017.2755644</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work aims at developing a power control framework to jointly optimize
energy efficiency (measured in bit/Joule) and delay in wireless networks. A
multi-objective approach is taken to deal with both performance metrics, while
ensuring a minimum quality-of-service to each user in the network. Each user in
the network is modeled as a rational agent that engages in a generalized
non-cooperative game. Feasibility conditions are derived for the existence of
each player's best response, and used to show that if these conditions are met,
the game best response dynamics will converge to a unique Nash equilibrium.
Based on these results, a convergent power control algorithm is derived, which
can be implemented in a fully decentralized fashion. Next, a centralized power
control algorithm is proposed, which also serves as a benchmark for the
proposed decentralized solution. Due to the non-convexity of the centralized
problem, the tool of maximum block improvement is used, to trade-off complexity
with optimality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01033</identifier>
 <datestamp>2019-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01033</id><created>2017-11-03</created><updated>2019-12-02</updated><authors><author><keyname>Ashari</keyname><forenames>Zhila Esna</forenames></author><author><keyname>Kavehvash</keyname><forenames>Zahra</forenames></author><author><keyname>Mehrany</keyname><forenames>Khashayar</forenames></author></authors><title>Diffraction Influence on the Field of View and Resolution of
  Three-Dimensional Integral Imaging</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The influence of the diffraction limit on the field of view of
three-dimensional integral imaging (InI) systems is estimated by calculating
the resolution of the InI system along arbitrarily tilted directions. The
deteriorating effects of diffraction on the resolution are quantified in this
manner. Two different three-dimensional scenes are recorded by real/virtual and
focused imaging modes. The recorded scenes are reconstructed at different
tilted planes and the obtained results for the resolution and field of view of
the system are verified. It is shown that the diffraction effects severely
affect the resolution of InI in the real/virtual mode when the tilted angle of
viewing is increased. It is also shown that the resolution of InI in the
focused mode is more robust to the unwanted effects of diffraction even though
it is much lower than the resolution of InI in the real/virtual mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01176</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01176</id><created>2017-11-02</created><updated>2019-01-29</updated><authors><author><keyname>Mehrabkhani</keyname><forenames>Soheil</forenames></author><author><keyname>Kuester</keyname><forenames>Melvin</forenames></author></authors><title>Optimization of phase retrieval in the Fresnel domain by the modified
  Gerchberg-Saxton algorithm</title><categories>eess.IV physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modified Gerchberg-Saxton algorithm (MGSA) is one of the standard methods
for phase retrieval. In this work we apply the MGSA in the paraxial domain. For
three given physical parameters - i.e. wavelength, propagation distance and
pixel size the computational width in the Fresnel-Transform is fixed. This
width can be larger than the real dimension of the input or output images.
Consequently, it can induce a padding around the real input and output without
given amplitude (intensity) values. To solve this problem, we propose a very
simple and efficient solution and compare it to other approaches. We
demonstrate that the new modified GSA provides almost perfect results without
losing the time efficiency of the simplest method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01191</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01191</id><created>2017-11-03</created><updated>2018-03-13</updated><authors><author><keyname>Bohannon</keyname><forenames>Addison</forenames></author><author><keyname>Sadler</keyname><forenames>Brian</forenames></author><author><keyname>Balan</keyname><forenames>Radu</forenames></author></authors><title>Learning flexible representations of stochastic processes on graphs</title><categories>eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph convolutional networks adapt the architecture of convolutional neural
networks to learn rich representations of data supported on arbitrary graphs by
replacing the convolution operations of convolutional neural networks with
graph-dependent linear operations. However, these graph-dependent linear
operations are developed for scalar functions supported on undirected graphs.
We propose a class of linear operations for stochastic (time-varying) processes
on directed (or undirected) graphs to be used in graph convolutional networks.
We propose a parameterization of such linear operations using functional
calculus to achieve arbitrarily low learning complexity. The proposed approach
is shown to model richer behaviors and display greater flexibility in learning
representations than product graph methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01201</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01201</id><created>2017-11-03</created><authors><author><keyname>Graham</keyname><forenames>Dillon</forenames></author><author><keyname>Langroudi</keyname><forenames>Seyed Hamed Fatemi</forenames></author><author><keyname>Kanan</keyname><forenames>Christopher</forenames></author><author><keyname>Kudithipudi</keyname><forenames>Dhireesha</forenames></author></authors><title>Convolutional Drift Networks for Video Classification</title><categories>cs.CV cs.NE eess.IV</categories><comments>Published in IEEE Rebooting Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analyzing spatio-temporal data like video is a challenging task that requires
processing visual and temporal information effectively. Convolutional Neural
Networks have shown promise as baseline fixed feature extractors through
transfer learning, a technique that helps minimize the training cost on visual
information. Temporal information is often handled using hand-crafted features
or Recurrent Neural Networks, but this can be overly specific or prohibitively
complex. Building a fully trainable system that can efficiently analyze
spatio-temporal data without hand-crafted features or complex training is an
open challenge. We present a new neural network architecture to address this
challenge, the Convolutional Drift Network (CDN). Our CDN architecture combines
the visual feature extraction power of deep Convolutional Neural Networks with
the intrinsically efficient temporal processing provided by Reservoir
Computing. In this introductory paper on the CDN, we provide a very simple
baseline implementation tested on two egocentric (first-person) video activity
datasets.We achieve video-level activity classification results on-par with
state-of-the art methods. Notably, performance on this complex spatio-temporal
task was produced by only training a single feed-forward layer in the CDN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01218</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01218</id><created>2017-11-03</created><authors><author><keyname>Rezaei</keyname><forenames>Behnaz</forenames></author><author><keyname>Ostadabbas</keyname><forenames>Sarah</forenames></author></authors><title>Background Subtraction via Fast Robust Matrix Completion</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background subtraction is the primary task of the majority of video
inspection systems. The most important part of the background subtraction which
is common among different algorithms is background modeling. In this regard,
our paper addresses the problem of background modeling in a computationally
efficient way, which is important for current eruption of &quot;big data&quot; processing
coming from high resolution multi-channel videos. Our model is based on the
assumption that background in natural images lies on a low-dimensional
subspace. We formulated and solved this problem in a low-rank matrix completion
framework. In modeling the background, we benefited from the in-face extended
Frank-Wolfe algorithm for solving a defined convex optimization problem. We
evaluated our fast robust matrix completion (fRMC) method on both background
models challenge (BMC) and Stuttgart artificial background subtraction (SABS)
datasets. The results were compared with the robust principle component
analysis (RPCA) and low-rank robust matrix completion (RMC) methods, both
solved by inexact augmented Lagrangian multiplier (IALM). The results showed
faster computation, at least twice as when IALM solver is used, while having a
comparable accuracy even better in some challenges, in subtracting the
backgrounds in order to detect moving objects in the scene.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01264</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01264</id><created>2017-11-03</created><authors><author><keyname>Reznik</keyname><forenames>Aleksander</forenames></author><author><keyname>Soloview</keyname><forenames>Aleksander</forenames></author><author><keyname>Torgov</keyname><forenames>Andrey</forenames></author></authors><title>Optimal-speed algorithms for localization of random pulsed point sources
  generating super short pulses</title><categories>eess.SP</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The time-optimal technique of spatial localization of the random pulsed-point
source that has the uniform distribution density on search interval and
indicating itself by generation of the instant impulses (delta functions) at
random time points is developed. Localization is carried out by means of the
receiver having view window freely reconstructed in time. The created
algorithms are generalized to the search carried out by system consisting of
several receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01320</identifier>
 <datestamp>2018-03-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01320</id><created>2017-11-03</created><updated>2018-03-08</updated><authors><author><keyname>Tran</keyname><forenames>Ha-Vu</forenames></author><author><keyname>Kaddoum</keyname><forenames>Georges</forenames></author></authors><title>RF Wireless Power Transfer: Regreening Future Networks</title><categories>cs.IT eess.SP math.IT</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Green radio communication is an emerging topic since the overall footprint of
information and communication technology (ICT) services is predicted to triple
between 2007 and 2020. Given this research line, energy harvesting (EH) and
wireless power transfer (WPT) networks can be evaluated as promising
approaches. In this paper, an overview of recent trends for future green
networks on the platforms of EH and WPT is provided. By rethinking the
application of radio frequency (RF)-WPT, a new concept, namely green RF-WTP, is
introduced. Accordingly, opening challenges and promising combinations among
current technologies, such as small-cell, millimeter (mm)-wave, and Internet of
Things (IoT) networks, are discussed in details to seek solutions for the
question with how to re-green the future networks?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01329</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01329</id><created>2017-11-03</created><authors><author><keyname>Yang</keyname><forenames>Yaoqing</forenames></author><author><keyname>Chen</keyname><forenames>Siheng</forenames></author><author><keyname>Maddah-Ali</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Grover</keyname><forenames>Pulkit</forenames></author><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Kova&#x10d;evi&#x107;</keyname><forenames>Jelena</forenames></author></authors><title>Fast Path Localization on Graphs via Multiscale Viterbi Decoding</title><categories>eess.SP</categories><comments>submitted</comments><doi>10.1109/TSP.2018.2869119</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a problem of localizing a path-signal that evolves over time on a
graph. A path-signal can be viewed as the trajectory of a moving agent on a
graph in several consecutive time points. Combining dynamic programming and
graph partitioning, we propose a path-localization algorithm with significantly
reduced computational complexity. We analyze the localization error for the
proposed approach both in the Hamming distance and the destination's distance
between the path estimate and the true path using numerical bounds. Unlike
usual theoretical bounds that only apply to restricted graph models, the
obtained numerical bounds apply to all graphs and all non-overlapping
graph-partitioning schemes. In random geometric graphs, we are able to derive a
closed-form expression for the localization error bound, and a tradeoff between
localization error and the computational complexity. Finally, we compare the
proposed technique with the maximum likelihood estimate under the path
constraint in terms of computational complexity and localization error, and
show significant speedup (100 times) with comparable localization error (4
times) on a graph from real data. Variants of the proposed technique can be
applied to tracking, road congestion monitoring, and brain signal processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01369</identifier>
 <datestamp>2018-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01369</id><created>2017-11-03</created><updated>2018-09-07</updated><authors><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author><author><keyname>Khadkevich</keyname><forenames>Maksim</forenames></author><author><keyname>Fugen</keyname><forenames>Christian</forenames></author></authors><title>Knowledge Transfer from Weakly Labeled Audio using Convolutional Neural
  Network for Sound Events and Scenes</title><categories>cs.SD cs.MM eess.AS</categories><comments>ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose approaches to effectively transfer knowledge from
weakly labeled web audio data. We first describe a convolutional neural network
(CNN) based framework for sound event detection and classification using weakly
labeled audio data. Our model trains efficiently from audios of variable
lengths; hence, it is well suited for transfer learning. We then propose
methods to learn representations using this model which can be effectively used
for solving the target task. We study both transductive and inductive transfer
learning tasks, showing the effectiveness of our methods for both domain and
task adaptation. We show that the learned representations using the proposed
CNN model generalizes well enough to reach human level accuracy on ESC-50 sound
events dataset and set state of art results on this dataset. We further use
them for acoustic scene classification task and once again show that our
proposed approaches suit well for this task as well. We also show that our
methods are helpful in capturing semantic meanings and relations as well.
Moreover, in this process we also set state-of-art results on Audioset dataset,
relying on balanced training set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01437</identifier>
 <datestamp>2018-02-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01437</id><created>2017-11-04</created><updated>2018-02-13</updated><authors><author><keyname>Mimilakis</keyname><forenames>Stylianos Ioannis</forenames></author><author><keyname>Drossos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Santos</keyname><forenames>Jo&#xe3;o F.</forenames></author><author><keyname>Schuller</keyname><forenames>Gerald</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Monaural Singing Voice Separation with Skip-Filtering Connections and
  Recurrent Inference of Time-Frequency Mask</title><categories>cs.SD eess.AS</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Singing voice separation based on deep learning relies on the usage of
time-frequency masking. In many cases the masking process is not a learnable
function or is not encapsulated into the deep learning optimization.
Consequently, most of the existing methods rely on a post processing step using
the generalized Wiener filtering. This work proposes a method that learns and
optimizes (during training) a source-dependent mask and does not need the
aforementioned post processing step. We introduce a recurrent inference
algorithm, a sparse transformation step to improve the mask generation process,
and a learned denoising filter. Obtained results show an increase of 0.49 dB
for the signal to distortion ratio and 0.30 dB for the signal to interference
ratio, compared to previous state-of-the-art approaches for monaural singing
voice separation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01538</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01538</id><created>2017-11-05</created><authors><author><keyname>Chaumette</keyname><forenames>Eric</forenames></author><author><keyname>Vincent</keyname><forenames>Francois</forenames></author></authors><title>Linearly Constrained Kalman Filter For Linear Discrete State-Space
  Models</title><categories>eess.SP</categories><comments>Submitted to Automatica (13/05/2017). Publication decision
  (04/11/2017): Reject - may be resubmitted as Technical Communique (T.
  S\&quot;oderstr\&quot;om, Editor System Identification and Filtering)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For linear discrete state-space (LDSS) models, under certain conditions, the
linear least mean squares filter estimate has a convenient recursive
predictor/corrector format, aka the Kalman filter (KF). The aim of the paper is
to introduce the general form of the linearly constrained KF (LCKF) for LDSS
models, which encompasses the linearly constrained minimum variance estimator
(LCMVE). Thus the LCKF opens access to the abundant litterature on LCMVE in the
deterministic framework which can be transposed to the stochastic framework.
Therefore, among other things, the LCKF may provide alternative solutions to
$H_{\infty }$ filter and unbiased finite impulse response filter to robustify
the KF, which performance are sensible to misspecified noise or uncertainties
in the system matrices
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01559</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01559</id><created>2017-11-05</created><updated>2017-11-07</updated><authors><author><keyname>Youssef</keyname><forenames>K.</forenames></author><author><keyname>Bouchard</keyname><forenames>Louis-S.</forenames></author><author><keyname>Haigh</keyname><forenames>K. Z.</forenames></author><author><keyname>Krovi</keyname><forenames>H.</forenames></author><author><keyname>Silovsky</keyname><forenames>J.</forenames></author><author><keyname>Valk</keyname><forenames>C. P. Vander</forenames></author></authors><title>Machine Learning Approach to RF Transmitter Identification</title><categories>eess.SP cs.LG cs.NE stat.ML</categories><comments>14 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the development and widespread use of wireless devices in recent years
(mobile phones, Internet of Things, Wi-Fi), the electromagnetic spectrum has
become extremely crowded. In order to counter security threats posed by rogue
or unknown transmitters, it is important to identify RF transmitters not by the
data content of the transmissions but based on the intrinsic physical
characteristics of the transmitters. RF waveforms represent a particular
challenge because of the extremely high data rates involved and the potentially
large number of transmitters present in a given location. These factors outline
the need for rapid fingerprinting and identification methods that go beyond the
traditional hand-engineered approaches. In this study, we investigate the use
of machine learning (ML) strategies to the classification and identification
problems, and the use of wavelets to reduce the amount of data required. Four
different ML strategies are evaluated: deep neural nets (DNN), convolutional
neural nets (CNN), support vector machines (SVM), and multi-stage training
(MST) using accelerated Levenberg-Marquardt (A-LM) updates. The A-LM MST method
preconditioned by wavelets was by far the most accurate, achieving 100%
classification accuracy of transmitters, as tested using data originating from
12 different transmitters. We discuss strategies for extension of MST to a much
larger number of transmitters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01583</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01583</id><created>2017-11-05</created><authors><author><keyname>Lolaee</keyname><forenames>Hossein</forenames></author><author><keyname>Akhaee</keyname><forenames>Mohammad Ali</forenames></author></authors><title>Robust Expectation-Maximization Algorithm for DOA Estimation of Acoustic
  Sources in the Spherical Harmonic Domain</title><categories>eess.AS stat.AP</categories><comments>10 pages, 9 figures, IEEE journal manuscript</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The direction of arrival (DOA) estimation of sound sources has been a popular
signal processing research topic due to its widespread applications. Using
spherical microphone arrays (SMA), DOA estimation can be applied in the
spherical harmonic (SH) domain without any spatial ambiguity. However, the
environment reverberation and noise can degrade the estimation performance. In
this paper, we propose a new expectation maximization (EM) algorithm for
deterministic maximum likelihood (ML) DOA estimation of L sound sources in the
presence of spatially nonuniform noise in the SH domain. Furthermore a new
closed-form Cramer-Rao bound (CRB) for the deterministic ML DOA estimation is
derived for the signal model in the SH domain. The main idea of the proposed
algorithm is considering the general model of the received signal in the SH
domain, we reduce the complexity of the ML estimation by breaking it down into
two steps: expectation and maximization steps. The proposed algorithm reduces
the complexity from 2L-dimensional space to L 2-dimensional space. Simulation
results indicate that the proposed algorithm shows at least an improvement of
6dB in robustness in terms of root mean square error (RMSE). Moreover, the RMSE
of the proposed algorithm is very close to the CRB compared to the recent
methods in reverberant and noisy environments in the large range of signal to
noise ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01629</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01629</id><created>2017-11-05</created><updated>2018-03-15</updated><authors><author><keyname>Malladi</keyname><forenames>Rakesh</forenames></author><author><keyname>Johnson</keyname><forenames>Don H</forenames></author><author><keyname>Kalamangalam</keyname><forenames>Giridhar P</forenames></author><author><keyname>Tandon</keyname><forenames>Nitin</forenames></author><author><keyname>Aazhang</keyname><forenames>Behnaam</forenames></author></authors><title>Mutual Information in Frequency and its Application to Measure
  Cross-Frequency Coupling in Epilepsy</title><categories>q-bio.NC cs.IT eess.SP math.IT</categories><comments>This paper is accepted for publication in IEEE Transactions on Signal
  Processing and contains 15 pages, 9 figures and 1 table</comments><doi>10.1109/TSP.2018.2821627</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a metric, mutual information in frequency (MI-in-frequency), to
detect and quantify the statistical dependence between different frequency
components in the data, referred to as cross-frequency coupling and apply it to
electrophysiological recordings from the brain to infer cross-frequency
coupling. The current metrics used to quantify the cross-frequency coupling in
neuroscience cannot detect if two frequency components in non-Gaussian brain
recordings are statistically independent or not. Our MI-in-frequency metric,
based on Shannon's mutual information between the Cramer's representation of
stochastic processes, overcomes this shortcoming and can detect statistical
dependence in frequency between non-Gaussian signals. We then describe two
data-driven estimators of MI-in-frequency: one based on kernel density
estimation and the other based on the nearest neighbor algorithm and validate
their performance on simulated data. We then use MI-in-frequency to estimate
mutual information between two data streams that are dependent across time,
without making any parametric model assumptions. Finally, we use the MI-in-
frequency metric to investigate the cross-frequency coupling in seizure onset
zone from electrocorticographic recordings during seizures. The inferred
cross-frequency coupling characteristics are essential to optimize the spatial
and spectral parameters of electrical stimulation based treatments of epilepsy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01694</identifier>
 <datestamp>2018-02-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01694</id><created>2017-11-05</created><updated>2018-02-15</updated><authors><author><keyname>Toshniwal</keyname><forenames>Shubham</forenames></author><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Weiss</keyname><forenames>Ron J.</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Moreno</keyname><forenames>Pedro</forenames></author><author><keyname>Weinstein</keyname><forenames>Eugene</forenames></author><author><keyname>Rao</keyname><forenames>Kanishka</forenames></author></authors><title>Multilingual Speech Recognition With A Single End-To-End Model</title><categories>eess.AS cs.AI cs.CL</categories><comments>Accepted in ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Training a conventional automatic speech recognition (ASR) system to support
multiple languages is challenging because the sub-word unit, lexicon and word
inventories are typically language specific. In contrast, sequence-to-sequence
models are well suited for multilingual ASR because they encapsulate an
acoustic, pronunciation and language model jointly in a single network. In this
work we present a single sequence-to-sequence ASR model trained on 9 different
Indian languages, which have very little overlap in their scripts.
Specifically, we take a union of language-specific grapheme sets and train a
grapheme-based sequence-to-sequence model jointly on data from all languages.
We find that this model, which is not explicitly given any information about
language identity, improves recognition performance by 21% relative compared to
analogous sequence-to-sequence models trained on each language individually. By
modifying the model to accept a language identifier as an additional input
feature, we further improve performance by an additional 7% relative and
eliminate confusion between different languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01790</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01790</id><created>2017-11-06</created><authors><author><keyname>Xiao</keyname><forenames>Hang</forenames></author><author><keyname>Xing</keyname><forenames>Zhengli</forenames></author><author><keyname>Yang</keyname><forenames>Linxiao</forenames></author><author><keyname>Fang</keyname><forenames>Jun</forenames></author><author><keyname>Wu</keyname><forenames>Yanlun</forenames></author></authors><title>Simultaneous Block-Sparse Signal Recovery Using Pattern-Coupled Sparse
  Bayesian Learning</title><categories>cs.LG cs.IT eess.SP math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the block-sparse signals recovery problem in the
context of multiple measurement vectors (MMV) with common row sparsity
patterns. We develop a new method for recovery of common row sparsity MMV
signals, where a pattern-coupled hierarchical Gaussian prior model is
introduced to characterize both the block-sparsity of the coefficients and the
statistical dependency between neighboring coefficients of the common row
sparsity MMV signals. Unlike many other methods, the proposed method is able to
automatically capture the block sparse structure of the unknown signal. Our
method is developed using an expectation-maximization (EM) framework.
Simulation results show that our proposed method offers competitive performance
in recovering block-sparse common row sparsity pattern MMV signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01813</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01813</id><created>2017-11-06</created><authors><author><keyname>Cheng</keyname><forenames>Hei Victor</forenames></author><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Performance Analysis of NOMA in Training Based Multiuser MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>13 pages, accepted in IEEE Transaction on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the use of NOMA in multiuser MIMO systems in practical
scenarios where CSI is acquired through pilot signaling. A new NOMA scheme that
uses shared pilots is proposed. Achievable rate analysis is carried out for
different pilot signaling schemes including both uplink and downlink pilots.
The achievable rate performance of the proposed NOMA scheme with shared pilot
within each group is compared with the traditional orthogonal access scheme
with orthogonal pilots. Our proposed scheme is a generalization of the
orthogonal scheme, and can be reduced to the orthogonal scheme when appropriate
power allocation parameters are chosen. Numerical results show that when
downlink CSI is available at the users, our proposed NOMA scheme outperforms
orthogonal schemes. However with more groups of users present in the cell, it
is preferable to use multi-user beamforming in stead of NOMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01872</identifier>
 <datestamp>2018-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01872</id><created>2017-11-06</created><updated>2018-04-03</updated><authors><author><keyname>C</keyname><forenames>Sandeep Reddy</forenames></author><author><keyname>Hegde</keyname><forenames>Rajesh M</forenames></author></authors><title>Minimum-Phase HRTF Modeling of Pinna Spectral Notches using Group Delay
  Decomposition</title><categories>eess.AS cs.SD</categories><comments>11 pages; This paper is a preprint of a paper submitted to IET Signal
  Processing Journal. If accepted, the copy of record will be available at the
  IET Digital Library</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate reconstruction of HRTFs is important in the development of high
quality binaural sound synthesis systems. Conventionally, minimum phase HRTF
model development for reconstruction of HRTFs has been limited to minimum
phase-pure delay models which ignore the all pass component of the HRTF. In
this paper, a novel method for minimum phase HRTF modelling of Pinna Spectral
Notches (PSNs) using group delay decomposition is proposed. The proposed model
captures the PSNs contributed by both the minimum phase and all pass component
of HRTF thus facilitating an accurate reconstruction of HRTFs. The purely
minimum phase HRTF components and their corresponding spatial angles are first
identified using Fourier Bessel Series method that ensures a continuous
evolution of the PSNs. The minimum phase-pure delay model is used to
reconstruct HRTF for these spatial angles. Subsequently, the spatial angles
which require both the minimum phase and all pass components are modelled using
an all-pass filter cascaded with minimum-phase pure-delay model. Performance of
the proposed model is evaluated by conducting experiments on PSN extraction,
cross coherence analysis, and binaural synthesis. Both objective and subjective
evaluation results are used to indicate the significance of the proposed model
in binaural sound synthesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01946</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01946</id><created>2017-11-06</created><authors><author><keyname>Huang</keyname><forenames>Hao</forenames></author><author><keyname>Hu</keyname><forenames>Ying</forenames></author><author><keyname>Xu</keyname><forenames>Haihua</forenames></author></authors><title>Mandarin tone modeling using recurrent neural networks</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an Encoder-Classifier framework to model the Mandarin tones using
recurrent neural networks (RNN). In this framework, extracted frames of
features for tone classification are fed in to the RNN and casted into a fixed
dimensional vector (tone embedding) and then classified into tone types using a
softmax layer along with other auxiliary inputs. We investigate various
configurations that help to improve the model, including pooling, feature
splicing and utilization of syllable-level tone embeddings. Besides, tone
embeddings and durations of the contextual syllables are exploited to
facilitate tone classification. Experimental results on Mandarin tone
classification show the proposed network setups improve tone classification
accuracy. The results indicate that the RNN encoder-classifier based tone model
flexibly accommodates heterogeneous inputs (sequential and segmental) and hence
has the advantages from both the sequential classification tone models and
segmental classification tone models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01963</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01963</id><created>2017-11-06</created><authors><author><keyname>Bazrafkan</keyname><forenames>Shabab</forenames></author><author><keyname>Corcoran</keyname><forenames>Peter</forenames></author></authors><title>Semi-Parallel Deep Neural Networks (SPDNN), Convergence and
  Generalization</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Semi-Parallel Deep Neural Network (SPDNN) idea is explained in this
article and it has been shown that the convergence of the mixed network is very
close to the best network in the set and the generalization of SPDNN is better
than all the parent networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.01982</identifier>
 <datestamp>2018-11-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.01982</id><created>2017-11-06</created><updated>2018-07-19</updated><authors><author><keyname>Trinh-Hoang</keyname><forenames>Minh</forenames></author><author><keyname>Viberg</keyname><forenames>Mats</forenames></author><author><keyname>Pesavento</keyname><forenames>Marius</forenames></author></authors><title>Partial Relaxation Approach: An Eigenvalue-Based DOA Estimator Framework</title><categories>eess.SP</categories><comments>This work has been submitted to IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><doi>10.1109/TSP.2018.2875853</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the partial relaxation approach is introduced and applied to
DOA estimation using spectral search. Unlike existing methods like Capon or
MUSIC which can be considered as single source approximations of multi-source
estimation criteria, the proposed approach accounts for the existence of
multiple sources. At each considered direction, the manifold structure of the
remaining interfering signals impinging on the sensor array is relaxed, which
results in closed form estimates for the interference parameters. The
conventional multidimensional optimization problem reduces, thanks to this
relaxation, to a simple spectral search. Following this principle, we propose
estimators based on the Deterministic Maximum Likelihood, Weighted Subspace
Fitting and covariance fitting methods. To calculate the pseudo-spectra
efficiently, an iterative rooting scheme based on the rational function
approximation is applied to the partial relaxation methods. Simulation results
show that the performance of the proposed estimators is superior to the
conventional methods especially in the case of low Signal-to-Noise-Ratio and
low number of snapshots, irrespectively of any specific structure of the sensor
array while maintaining a comparable computational cost as MUSIC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02043</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02043</id><created>2017-11-02</created><updated>2018-02-28</updated><authors><author><keyname>Erk&#x131;l&#x131;n&#xe7;</keyname><forenames>M. Sezer</forenames></author><author><keyname>Lavery</keyname><forenames>Domani&#xe7;</forenames></author><author><keyname>Shi</keyname><forenames>Kai</forenames></author><author><keyname>Thomsen</keyname><forenames>Benn C.</forenames></author><author><keyname>Killey</keyname><forenames>Robert I.</forenames></author><author><keyname>Savory</keyname><forenames>Seb J.</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>Comparison of Low Complexity Coherent Receivers for UDWDM-PONs
  ($\lambda$-to-the-user)</title><categories>eess.SP</categories><comments>12 pages, 10 figures, 2 tables and 46 referecens</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is predicted that demand in optical access networks will reach multi-Gb/s
per user. However, the limited performance of the direct detection receiver
technology currently used in the optical network units at the customers'
premises restricts data rates/user. Therefore, the concept of coherent-enabled
access networks has attracted attention in recent years, as this technology
offers high receiver sensitivity, inherent frequency selectivity, and linear
field detection enabling the full compensation of linear channel impairments.
However, the complexity of conventional (dual-polarisation digital) coherent
receivers has so far prevented their introduction into access networks. Thus,
to exploit the benefits of coherent technology in the ONUs, low complexity
coherent receivers, suitable for implementation in ONUs, are needed. In this
paper, the recently proposed low complexity coherent (i.e.,
polarisation-independent Alamouti-coding heterodyne) receiver is, for the first
time, compared in terms of its minimum receiver sensitivity with five
previously reported receiver designs, including a detailed discussion on their
advantages and limitations. It is shown that the Alamouti-coding based receiver
approach allows the lowest number of photons per bit (PPB) transmitted (with a
lower bound of 15.5 PPB in an ideal system simulations) whilst requiring the
lowest optical receiver hardware complexity. It also exhibits comparable
complexity to the currently deployed direct-detection receivers, which
typically require &gt;1000 PPB. Finally, a comparison of experimentally achieved
receiver sensitivities and transmission distances using these receivers is
presented. The highest spectral efficiency and longest transmission distance at
the highest bit rate reported using the Alamouti-coding receiver, which is also
the only one, to date, to have been demonstrated in a full system bidirectional
transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02044</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02044</id><created>2017-11-03</created><updated>2017-11-14</updated><authors><author><keyname>Li</keyname><forenames>Kai</forenames></author><author><keyname>Ni</keyname><forenames>Wei</forenames></author><author><keyname>Duan</keyname><forenames>Lingjie</forenames></author><author><keyname>Abolhasan</keyname><forenames>Mehran</forenames></author><author><keyname>Niu</keyname><forenames>Jianwei</forenames></author></authors><title>Wireless Power Transfer and Data Collection in Wireless Sensor Networks</title><categories>eess.SP</categories><comments>30 pages, 8 figures, accepted to IEEE Transactions on Vehicular
  Technology</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In a rechargeable wireless sensor network, the data packets are generated by
sensor nodes at a specific data rate, and transmitted to a base station.
Moreover, the base station transfers power to the nodes by using Wireless Power
Transfer (WPT) to extend their battery life. However, inadequately scheduling
WPT and data collection causes some of the nodes to drain their battery and
have their data buffer overflow, while the other nodes waste their harvested
energy, which is more than they need to transmit their packets. In this paper,
we investigate a novel optimal scheduling strategy, called EHMDP, aiming to
minimize data packet loss from a network of sensor nodes in terms of the nodes'
energy consumption and data queue state information. The scheduling problem is
first formulated by a centralized MDP model, assuming that the complete states
of each node are well known by the base station. This presents the upper bound
of the data that can be collected in a rechargeable wireless sensor network.
Next, we relax the assumption of the availability of full state information so
that the data transmission and WPT can be semi-decentralized. The simulation
results show that, in terms of network throughput and packet loss rate, the
proposed algorithm significantly improves the network performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02046</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02046</id><created>2017-11-03</created><authors><author><keyname>Tremblay</keyname><forenames>Nicolas</forenames></author><author><keyname>Gon&#xe7;alves</keyname><forenames>Paulo</forenames></author><author><keyname>Borgnat</keyname><forenames>Pierre</forenames></author></authors><title>Design of graph filters and filterbanks</title><categories>eess.SP cs.IT cs.SI math.IT</categories><comments>chapter in collective book</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Basic operations in graph signal processing consist in processing signals
indexed on graphs either by filtering them, to extract specific part out of
them, or by changing their domain of representation, using some transformation
or dictionary more adapted to represent the information contained in them. The
aim of this chapter is to review general concepts for the introduction of
filters and representations of graph signals. We first begin by recalling the
general framework to achieve that, which put the emphasis on introducing some
spectral domain that is relevant for graph signals to define a Graph Fourier
Transform. We show how to introduce a notion of frequency analysis for graph
signals by looking at their variations. Then, we move to the introduction of
graph filters, that are defined like the classical equivalent for 1D signals or
2D images, as linear systems which operate on each frequency of a signal. Some
examples of filters and of their implementations are given. Finally, as
alternate representations of graph signals, we focus on multiscale transforms
that are defined from filters. Continuous multiscale transforms such as
spectral wavelets on graphs are reviewed, as well as the versatile approaches
of filterbanks on graphs. Several variants of graph filterbanks are discussed,
for structured as well as arbitrary graphs, with a focus on the central point
of the choice of the decimation or aggregation operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02209</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02209</id><created>2017-11-06</created><authors><author><keyname>Jansen</keyname><forenames>Aren</forenames></author><author><keyname>Plakal</keyname><forenames>Manoj</forenames></author><author><keyname>Pandya</keyname><forenames>Ratheet</forenames></author><author><keyname>Ellis</keyname><forenames>Daniel P. W.</forenames></author><author><keyname>Hershey</keyname><forenames>Shawn</forenames></author><author><keyname>Liu</keyname><forenames>Jiayang</forenames></author><author><keyname>Moore</keyname><forenames>R. Channing</forenames></author><author><keyname>Saurous</keyname><forenames>Rif A.</forenames></author></authors><title>Unsupervised Learning of Semantic Audio Representations</title><categories>cs.SD eess.AS stat.ML</categories><comments>Submitted to ICASSP 2018</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Even in the absence of any explicit semantic annotation, vast collections of
audio recordings provide valuable information for learning the categorical
structure of sounds. We consider several class-agnostic semantic constraints
that apply to unlabeled nonspeech audio: (i) noise and translations in time do
not change the underlying sound category, (ii) a mixture of two sound events
inherits the categories of the constituents, and (iii) the categories of events
in close temporal proximity are likely to be the same or related. Without
labels to ground them, these constraints are incompatible with classification
loss functions. However, they may still be leveraged to identify geometric
inequalities needed for triplet loss-based training of convolutional neural
networks. The result is low-dimensional embeddings of the input spectrograms
that recover 41% and 84% of the performance of their fully-supervised
counterparts when applied to downstream query-by-example sound retrieval and
sound event classification tasks, respectively. Moreover, in
limited-supervision settings, our unsupervised embeddings double the
state-of-the-art classification performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02248</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02248</id><created>2017-11-06</created><updated>2018-06-18</updated><authors><author><keyname>Aminjavaheri</keyname><forenames>Amir</forenames></author><author><keyname>RezazadehReyhani</keyname><forenames>Ahmad</forenames></author><author><keyname>Khalona</keyname><forenames>Ramon</forenames></author><author><keyname>Moradi</keyname><forenames>Hussein</forenames></author><author><keyname>Farhang-Boroujeny</keyname><forenames>Behrouz</forenames></author></authors><title>Underlay Control Signaling for Ultra-Reliable Low-Latency IoT
  Communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future mobile networks not only envision enhancing the traditional link
quality and data rates of mobile broad band (MBB) links, but also development
of new control channels to meet the requirements of delay sensitive use cases.
In particular, the need for ultra-reliable low-latency communications (URLLC)
for many internet of things (IoT) users is greatly emphasized. In this paper,
we present a novel spread spectrum waveform design that we propose for
transmission of control signals to establish URLLC communications. These
control signals are transmitted over the spectral resources that belong to the
MBB communications in the network, but at a level that minimally affects these
data channels. The proposed waveform, although a direct sequence spread
spectrum (DSSS) technique, is designed to take advantage of symbol
synchronization available to the OFDM broad band communications in the network.
This, clearly, allows simple synchronization with the rest of the network. The
proposed DSSS method can transmit single and multiple bits within each OFDM
time frame and can serve many user equipment (UE) nodes simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02318</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02318</id><created>2017-11-07</created><authors><author><keyname>Viraraghavan</keyname><forenames>Venkata Subramanian</forenames></author><author><keyname>Pal</keyname><forenames>Arpan</forenames></author><author><keyname>Aravind</keyname><forenames>R</forenames></author><author><keyname>Murthy</keyname><forenames>Hema</forenames></author></authors><title>Non-uniform time-scaling of Carnatic music transients</title><categories>cs.SD eess.AS</categories><comments>The non-uniform time-scaling of CP-notes and transients in Carnatic
  concert renditions is new; it has not been reported earlier in the
  literature, but a reviewer pointed out that the proposed algorithm is
  previously known</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gamakas are an integral aspect of Carnatic Music, a form of classical music
prevalent in South India. They are used in ragas, which may be seen as melodic
scales and/or a set of characteristic melodic phrases. Gamakas exhibit
continuous pitch variation often spanning several semitones. In this paper, we
study how gamakas scale with tempo and propose a novel approach to change the
tempo of Carnatic music pieces. The music signal is viewed as consisting of
constant-pitch segments and transients. The transients show continuous pitch
variation and we consider their analyses from a theoretical stand-point. We
next observe the non-uniform ratios of time-scaling of constant-pitch segments,
transients and silence in excerpts from nine concert renditions of varnams in
six ragas. The results indicate that the changing tempo of Carnatic music does
not change the duration of transients significantly. We report listening tests
on our algorithm to slow down Carnatic music that is consistent with this
observation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02387</identifier>
 <datestamp>2018-05-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02387</id><created>2017-11-07</created><authors><author><keyname>Delgado-Gonzalo</keyname><forenames>Ricard</forenames></author><author><keyname>Renevey</keyname><forenames>Philippe</forenames></author><author><keyname>Tarniceriu</keyname><forenames>Adrian</forenames></author><author><keyname>Parak</keyname><forenames>Jakub</forenames></author><author><keyname>Bertschi</keyname><forenames>Mattia</forenames></author></authors><title>Learning a Physical Activity Classifier for a Low-power Embedded
  Wrist-located Device</title><categories>eess.SP</categories><comments>Submitted to the 2018 IEEE International Conference on Biomedical and
  Health Informatics</comments><doi>10.1109/BHI.2018.8333368</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents and evaluates a novel algorithm for learning a physical
activity classifier for a low-power embedded wrist-located device. The overall
system is designed for real-time execution and it is implemented in the
commercial low-power System-on-Chips nRF51 and nRF52. Results were obtained
using a database composed of 140 users containing more than 340 hours of
labeled raw acceleration data. The final precision achieved for the most
important classes, (Rest, Walk, and Run), was of 96%, 94%, and 99% and it
generalizes to compound activities such as XC skiing or Housework. We conclude
with a benchmarking of the system in terms of memory footprint and power
consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02427</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02427</id><created>2017-11-07</created><authors><author><keyname>Cancino-Chac&#xf3;n</keyname><forenames>Carlos</forenames></author><author><keyname>Bonev</keyname><forenames>Martin</forenames></author><author><keyname>Durand</keyname><forenames>Amaury</forenames></author><author><keyname>Grachten</keyname><forenames>Maarten</forenames></author><author><keyname>Arzt</keyname><forenames>Andreas</forenames></author><author><keyname>Bishop</keyname><forenames>Laura</forenames></author><author><keyname>Goebl</keyname><forenames>Werner</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>The ACCompanion v0.1: An Expressive Accompaniment System</title><categories>cs.SD cs.HC eess.AS</categories><comments>Presented at the Late-Breaking Demo Session of the 18th International
  Society for Music Information Retrieval Conference (ISMIR 2017), Suzhou,
  China, 2017</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper we present a preliminary version of the ACCompanion, an
expressive accompaniment system for MIDI input. The system uses a probabilistic
monophonic score follower to track the position of the soloist in the score,
and a linear Gaussian model to compute tempo updates. The expressiveness of the
system is powered by the Basis-Mixer, a state-of-the-art computational model of
expressive music performance. The system allows for expressive dynamics, timing
and articulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02441</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02441</id><created>2017-11-07</created><authors><author><keyname>El-Shafie</keyname><forenames>Al-Hussein A.</forenames></author><author><keyname>Habib</keyname><forenames>S. E. D.</forenames></author></authors><title>A Survey on Hardware Implementations of Visual Object Trackers</title><categories>eess.IV cs.CV</categories><comments>17 pages, 14 Figures, 6 tables, 84 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual object tracking is an active topic in the computer vision domain with
applications extending over numerous fields. The main sub-tasks required to
build an object tracker (e.g. object detection, feature extraction and object
tracking) are computation-intensive. In addition, real-time operation of the
tracker is indispensable for almost all of its applications. Therefore,
complete hardware or hardware/software co-design approaches are pursued for
better tracker implementations. This paper presents a literature survey of the
hardware implementations of object trackers over the last two decades. Although
several tracking surveys exist in literature, a survey addressing the hardware
implementations of the different trackers is missing. We believe this survey
would fill the gap and complete the picture with the existing surveys of how to
design an efficient tracker and point out the future directions researchers can
follow in this field. We highlight the lack of hardware implementations for
state-of-the-art tracking algorithms as well as for enhanced classical
algorithms. We also stress the need for measuring the tracking performance of
the hardware-based trackers. Additionally, enough details of the hardware-based
trackers need to be provided to allow reasonable comparison between the
different implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02500</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02500</id><created>2017-10-31</created><authors><author><keyname>Nejadriahi</keyname><forenames>Hani</forenames></author><author><keyname>HillerKuss</keyname><forenames>David</forenames></author><author><keyname>George</keyname><forenames>Jonathan K.</forenames></author><author><keyname>Sorger</keyname><forenames>Volker J.</forenames></author></authors><title>Integrated All-Optical Fast Fourier Transform: Design and Sensitivity
  Analysis</title><categories>eess.SP physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fast Fourier transform, FFT, is a useful and prevalent algorithm in
signal processing. It characterizes the spectral components of a signal, or is
used in combination with other operations to perform more complex computations
such as filtering, convolution, and correlation. Digital FFTs are limited in
speed by the necessity of moving charge within logic gates. An analog temporal
FFT in fiber optics has been demonstrated with highest data bandwidth. However,
the implementation with discrete fiber optic FFT components is bulky. Here, we
present and analyze a design of an optical FFT in Silicon photonics and
evaluate its performance with respect to variations in phase and amplitude. We
discuss the impact of the deployed devices on the FFTs transfer function
quality as defined by the transmission output power as a function of frequency,
detuning phase, optical delay, and loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02520</identifier>
 <datestamp>2018-06-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02520</id><created>2017-11-07</created><updated>2018-06-15</updated><authors><author><keyname>Pons</keyname><forenames>Jordi</forenames></author><author><keyname>Nieto</keyname><forenames>Oriol</forenames></author><author><keyname>Prockup</keyname><forenames>Matthew</forenames></author><author><keyname>Schmidt</keyname><forenames>Erik</forenames></author><author><keyname>Ehmann</keyname><forenames>Andreas</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>End-to-end learning for music audio tagging at scale</title><categories>cs.SD eess.AS</categories><comments>Presented at the Workshop on Machine Learning for Audio Signal
  Processing (ML4Audio) at NIPS 2017, and in proceedings of the 19th
  International Society for Music Information Retrieval Conference (ISMIR2018).
  Code: https://github.com/jordipons/music-audio-tagging-at-scale-models. Demo:
  http://www.jordipons.me/apps/music-audio-tagging-at-scale-demo/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lack of data tends to limit the outcomes of deep learning research,
particularly when dealing with end-to-end learning stacks processing raw data
such as waveforms. In this study, 1.2M tracks annotated with musical labels are
available to train our end-to-end models. This large amount of data allows us
to unrestrictedly explore two different design paradigms for music
auto-tagging: assumption-free models - using waveforms as input with very small
convolutional filters; and models that rely on domain knowledge - log-mel
spectrograms with a convolutional neural network designed to learn timbral and
temporal features. Our work focuses on studying how these two types of deep
architectures perform when datasets of variable size are available for
training: the MagnaTagATune (25k songs), the Million Song Dataset (240k songs),
and a private dataset of 1.2M songs. Our experiments suggest that music domain
assumptions are relevant when not enough training data are available, thus
showing how waveform-based models outperform spectrogram-based ones in
large-scale data scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02521</identifier>
 <datestamp>2018-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02521</id><created>2017-11-04</created><authors><author><keyname>Banaszek</keyname><forenames>Konrad</forenames></author><author><keyname>Jachura</keyname><forenames>Micha&#x142;</forenames></author></authors><title>Structured Optical Receivers for Efficient Deep-Space Communication</title><categories>eess.SP quant-ph</categories><comments>4 pages, 2 figures. To be presented at the IEEE International
  Conference on Space Optical Systems and Applications, 14-16 November 2017,
  Naha, Okinawa, Japan</comments><journal-ref>Proceedings of the 2017 IEEE International Conference on Space
  Optical Systems and Applications (ICSOS), Naha, Okinawa, Japan, pp. 34-37</journal-ref><doi>10.1109/ICSOS.2017.8357208</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss conceptual designs for structured optical receivers that can
alleviate the requirement for high peak-to-average power ratio in
photon-starved optical communication. The basic idea is to transmit sequences
of suitably modulated coherent light pulses whose energy can be concentrated in
a single temporal bin on the receiver side through optical interference. Two
examples of scalable architectures for structured receivers are presented. The
first one, based on active polarization switching, maps Hadamard codewords
composed from the binary phase shift keying (BPSK) constellation onto the
standard pulse position modulation (PPM) format. The second receiver, using
solely passive optical elements, converts phase-polarization patterns of
coherent light pulses into a single pulse preserving a synchronized time of
arrival. Such a conversion enables implementation of a communication protocol
equivalent to the PPM scheme but with distributed optical power provided that
the intersymbol guard-time exceeds the pattern length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02544</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02544</id><created>2017-11-06</created><authors><author><keyname>Chen</keyname><forenames>Jiaoxuan</forenames></author><author><keyname>Zhang</keyname><forenames>Maomao</forenames></author><author><keyname>Li</keyname><forenames>Yi</forenames></author></authors><title>A reconstruction algorithm for electrical capacitance tomography via
  total variation and l0-norm regularizations using experimental data</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electrical capacitance tomography (ECT) has been investigated in many fields
due to its advantages of being non-invasive and low cost. Sparse algorithms
with l1-norm regularization are used to reduce the smoothing effect and obtain
sharp images, such as total variation (TV)regularization. This paper proposed
for the first time to solve the ECT inverse problem using an l0-norm
regularization algorithm, namely the doubly extrapolated proximal iterative
hard thresholding (DEPIHT) algorithm. The accelerated alternating direction
method of multipliers (AADMM) algorithm, based on the TV regularization, has
been selected to acquire the first point for the DEPIHT algorithm. Experimental
tests were carried out to validate the feasibility of the AADMM-DEPIHT
algorithm,which is compared with the Landweber iteration (LI) and AADMM
algorithms. The results show the AADMM-DEPIHT algorithm has an improvement on
the quality of images and also indicates that the DEPIHT algorithm can be a
suitable candidate for ECT in post-process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02550</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02550</id><created>2017-11-06</created><authors><author><keyname>Antonelli</keyname><forenames>Cristian</forenames></author><author><keyname>Mecozzi</keyname><forenames>Antonio</forenames></author><author><keyname>Shtaif</keyname><forenames>Mark</forenames></author></authors><title>Kramers Kronig PAM transceiver and two-sided polarization-multiplexed
  Kramers Kronig transceiver</title><categories>eess.SP</categories><doi>10.1109/JLT.2018.2796306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose two transceiver schemes based on Kramers Kronig (KK) detection.
One targets low-cost high-throughput applications and uses PAM transmission in
combination with direct detection and digital reconstruction of the optical
phase. This scheme allows digital compensation of chromatic dispersion and
provides a significant improvement in terms of spectral efficiency, compared to
conventional PAM transmission. The second scheme targets high-channel-count
coherent systems with the aim of simplifying the receiver complexity by
reducing the optical components count.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02666</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02666</id><created>2017-11-07</created><authors><author><keyname>Zhu</keyname><forenames>Chenxiao</forenames></author><author><keyname>Xu</keyname><forenames>Lingqing</forenames></author><author><keyname>Liu</keyname><forenames>Xiao-Yang</forenames></author><author><keyname>Qian</keyname><forenames>Feng</forenames></author></authors><title>Tensor-Generative Adversarial Network with Two-dimensional Sparse
  Coding: Application to Real-time Indoor Localization</title><categories>cs.LG cs.NI eess.SP</categories><comments>6 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Localization technology is important for the development of indoor
location-based services (LBS). Global Positioning System (GPS) becomes invalid
in indoor environments due to the non-line-of-sight issue, so it is urgent to
develop a real-time high-accuracy localization approach for smartphones.
However, accurate localization is challenging due to issues such as real-time
response requirements, limited fingerprint samples and mobile device storage.
To address these problems, we propose a novel deep learning architecture:
Tensor-Generative Adversarial Network (TGAN).
  We first introduce a transform-based 3D tensor to model fingerprint samples.
Instead of those passive methods that construct a fingerprint database as a
prior, our model applies artificial neural network with deep learning to train
network classifiers and then gives out estimations. Then we propose a novel
tensor-based super-resolution scheme using the generative adversarial network
(GAN) that adopts sparse coding as the generator network and a residual
learning network as the discriminator. Further, we analyze the performance of
tensor-GAN and implement a trace-based localization experiment, which achieves
better performance. Compared to existing methods for smartphones indoor
positioning, that are energy-consuming and high demands on devices, TGAN can
give out an improved solution in localization accuracy, response time and
implementation complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02743</identifier>
 <datestamp>2018-06-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02743</id><created>2017-11-07</created><updated>2018-06-14</updated><authors><author><keyname>Durgin</keyname><forenames>Natalie</forenames></author><author><keyname>Grotheer</keyname><forenames>Rachel</forenames></author><author><keyname>Huang</keyname><forenames>Chenxi</forenames></author><author><keyname>Li</keyname><forenames>Shuang</forenames></author><author><keyname>Ma</keyname><forenames>Anna</forenames></author><author><keyname>Needell</keyname><forenames>Deanna</forenames></author><author><keyname>Qin</keyname><forenames>Jing</forenames></author></authors><title>Sparse Randomized Kaczmarz for Support Recovery of Jointly Sparse
  Corrupted Multiple Measurement Vectors</title><categories>eess.SP cs.DS math.NA</categories><comments>13 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While single measurement vector (SMV) models have been widely studied in
signal processing, there is a surging interest in addressing the multiple
measurement vectors (MMV) problem. In the MMV setting, more than one
measurement vector is available and the multiple signals to be recovered share
some commonalities such as a common support. Applications in which MMV is a
naturally occurring phenomenon include online streaming, medical imaging, and
video recovery. This work presents a stochastic iterative algorithm for the
support recovery of jointly sparse corrupted MMV. We present a variant of the
Sparse Randomized Kaczmarz algorithm for corrupted MMV and compare our proposed
method with an existing Kaczmarz type algorithm for MMV problems. We also
showcase the usefulness of our approach in the online (streaming) setting and
provide empirical evidence that suggests the robustness of the proposed method
to the distribution of the corruption and the number of corruptions occurring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02821</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02821</id><created>2017-11-07</created><authors><author><keyname>Yang</keyname><forenames>Yuzhe</forenames></author><author><keyname>Zheng</keyname><forenames>Zijie</forenames></author><author><keyname>Bian</keyname><forenames>Kaigui</forenames></author><author><keyname>Song</keyname><forenames>Lingyang</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>Realtime Profiling of Fine-Grained Air Quality Index Distribution using
  UAV Sensing</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given significant air pollution problems, air quality index (AQI) monitoring
has recently received increasing attention. In this paper, we design a mobile
AQI monitoring system boarded on unmanned-aerial-vehicles (UAVs), called ARMS,
to efficiently build fine-grained AQI maps in realtime. Specifically, we first
propose the Gaussian plume model on basis of the neural network (GPM-NN), to
physically characterize the particle dispersion in the air. Based on GPM-NN, we
propose a battery efficient and adaptive monitoring algorithm to monitor AQI at
the selected locations and construct an accurate AQI map with the sensed data.
The proposed adaptive monitoring algorithm is evaluated in two typical
scenarios, a two-dimensional open space like a roadside park, and a
three-dimensional space like a courtyard inside a building. Experimental
results demonstrate that our system can provide higher prediction accuracy of
AQI with GPM-NN than other existing models, while greatly reducing the power
consumption with the adaptive monitoring algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02832</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02832</id><created>2017-11-08</created><authors><author><keyname>Okuda</keyname><forenames>Takafumi</forenames></author><author><keyname>Hikihara</keyname><forenames>Takashi</forenames></author></authors><title>High-Speed Gate Driver Using GaN HEMTs for 20-MHz Hard Switching of SiC
  MOSFETs</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigated a gate driver using a GaN HEMT push-pull
configuration for the high-frequency hard switching of a SiC power MOSFET. Low
on-resistance and low input capacitance of GaN HEMTs are suitable for a
high-frequency gate driver from the logic level, and robustness of SiC MOSFET
with high avalanche capability is suitable for a valve transistor in power
converters. Our proposed gate driver consists of digital isolators,
complementary Si MOSFETs, and GaN HEMTs. The GaN HEMT push-pull stage has a
high driving capability owing to its superior switching characteristics, and
complementary Si MOSFETs can enhance the control signal from the digital
isolator. We investigated limiting factors of the switching frequency of the
proposed gate driver by focusing on each circuit component and proposed an
improved driving configuration for the gate driver. As a result, 20-MHz hard
switching of a SiC MOSFET was achieved using the improved gate driver with GaN
HEMTs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.02868</identifier>
 <datestamp>2018-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.02868</id><created>2017-11-08</created><authors><author><keyname>Tarniceriu</keyname><forenames>Adrian</forenames></author><author><keyname>Harju</keyname><forenames>Jarkko</forenames></author><author><keyname>Vehkaoja</keyname><forenames>Antti</forenames></author><author><keyname>Parak</keyname><forenames>Jakub</forenames></author><author><keyname>Delgado-Gonzalo</keyname><forenames>Ricard</forenames></author><author><keyname>Renevey</keyname><forenames>Philippe</forenames></author><author><keyname>Yli-Hankala</keyname><forenames>Arvi</forenames></author><author><keyname>Korhonen</keyname><forenames>Ilkka</forenames></author></authors><title>Detection of Beat-to-Beat Intervals from Wrist Photoplethysmography in
  Patients with Sinus Rhythm and Atrial Fibrillation after Surgery</title><categories>eess.SP</categories><comments>Submitted to the 2018 IEEE International Conference on Biomedical and
  Health Informatics</comments><doi>10.1109/BHI.2018.8333387</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wrist photoplethysmography (PPG) allows unobtrusive monitoring of the heart
rate (HR). PPG is affected by the capillary blood perfusion and the pumping
function of the heart, which generally deteriorate with age and due to presence
of cardiac arrhythmia. The performance of wrist PPG in monitoring beat-to-beat
HR in older patients with arrhythmia has not been reported earlier. We
monitored PPG from wrist in 18 patients recovering from surgery in the post
anesthesia care unit, and evaluated the inter-beat interval (IBI) detection
accuracy against ECG based R-to-R intervals (RRI). Nine subjects had sinus
rhythm (SR, 68.0y$\pm$10.2y, 6 males) and nine subjects had atrial fibrillation
(AF, 71.3y$\pm$7.8y, 4 males) during the recording. For the SR group, 99.44% of
the beats were correctly identified, 2.39% extra beats were detected, and the
mean absolute error (MAE) was 7.34 ms. For the AF group, 97.49% of the
heartbeats were correctly identified, 2.26% extra beats were detected, and the
MAE was 14.31 ms. IBI from the PPG were hence in close agreement with the ECG
reference in both groups. The results suggest that wrist PPG provides a
comfortable alternative to ECG and can be used for long-term monitoring and
screening of AF episodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03031</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03031</id><created>2017-11-08</created><authors><author><keyname>Maschietti</keyname><forenames>Flavio</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author><author><keyname>de Kerret</keyname><forenames>Paul</forenames></author></authors><title>Location-Aided Coordinated Analog Precoding for Uplink Multi-User
  Millimeter Wave Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>17 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) communication is expected to play an important role
in next generation cellular networks, aiming to cope with the bandwidth
shortage affecting conventional wireless carriers. Using side-information has
been proposed as a potential approach to accelerate beam selection in mmWave
massive MIMO (m-MIMO) communications. However, in practice, such information is
not error-free, leading to performance degradation. In the multi-user case, a
wrong beam choice might result in irreducible inter-user interference at the
base station (BS) side. In this paper, we consider location-aided precoder
design in a mmWave uplink scenario with multiple users (UEs). Assuming the
existence of direct device-to-device (D2D) links, we propose a decentralized
coordination mechanism for robust fast beam selection. The algorithm allows for
improved treatment of interference at the BS side and in turn leads to greater
spectral efficiencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03037</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03037</id><created>2017-11-08</created><updated>2018-02-07</updated><authors><author><keyname>Kong</keyname><forenames>Qiuqiang</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Wang</keyname><forenames>Wenwu</forenames></author><author><keyname>Plumbley</keyname><forenames>Mark D.</forenames></author></authors><title>A joint separation-classification model for sound event detection of
  weakly labelled data</title><categories>cs.SD eess.AS</categories><comments>Accepted by ICASSP 2018</comments><journal-ref>IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), 2018, pp. 321-325</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Source separation (SS) aims to separate individual sources from an audio
recording. Sound event detection (SED) aims to detect sound events from an
audio recording. We propose a joint separation-classification (JSC) model
trained only on weakly labelled audio data, that is, only the tags of an audio
recording are known but the time of the events are unknown. First, we propose a
separation mapping from the time-frequency (T-F) representation of an audio to
the T-F segmentation masks of the audio events. Second, a classification
mapping is built from each T-F segmentation mask to the presence probability of
each audio event. In the source separation stage, sources of audio events and
time of sound events can be obtained from the T-F segmentation masks. The
proposed method achieves an equal error rate (EER) of 0.14 in SED,
outperforming deep neural network baseline of 0.29. Source separation SDR of
8.08 dB is obtained by using global weighted rank pooling (GWRP) as probability
mapping, outperforming the global max pooling (GMP) based probability mapping
giving SDR at 0.03 dB. Source code of our work is published.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03197</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03197</id><created>2017-11-08</created><authors><author><keyname>Zou</keyname><forenames>Xun</forenames></author><author><keyname>Jafarkhani</keyname><forenames>Hamid</forenames></author></authors><title>Asynchronous Channel Training in Multi-Cell Massive MIMO</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pilot contamination has been regarded as the main bottleneck in time division
duplexing (TDD) multi-cell massive multiple-input multiple-output (MIMO)
systems. The pilot contamination problem cannot be addressed with large-scale
antenna arrays. We provide a novel asynchronous channel training scheme to
obtain precise channel matrices without the cooperation of base stations. The
scheme takes advantage of sampling diversity by inducing intentional timing
mismatch. Then, the linear minimum mean square error (LMMSE) estimator and the
zero-forcing (ZF) estimator are designed. Moreover, we derive the minimum
square error (MSE) upper bound of the ZF estimator. In addition, we propose the
equally-divided delay scheme which under certain conditions is the optimal
solution to minimize the MSE of the ZF estimator employing the identity matrix
as pilot matrix. We calculate the uplink achievable rate using maximum ratio
combining (MRC) to compare asynchronous and synchronous channel training
schemes. Finally, simulation results demonstrate that the asynchronous channel
estimation scheme can greatly reduce the harmful effect of pilot contamination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03240</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03240</id><created>2017-11-08</created><authors><author><keyname>Lv</keyname><forenames>Bojie</forenames></author><author><keyname>Huang</keyname><forenames>Lexiang</forenames></author><author><keyname>Wang</keyname><forenames>Rui</forenames></author></authors><title>Cellular Offloading via Downlink Cache Placement</title><categories>eess.SP cs.IT math.IT</categories><comments>Submitted for IEEE ICC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the downlink file transmission within a finite lifetime is
optimized with the assistance of wireless cache nodes. Specifically, the number
of requests within the lifetime of one file is modeled as a Poisson point
process. The base station multicasts files to downlink users and the selected
the cache nodes, so that the cache nodes can help to forward the files in the
next file request. Thus we formulate the downlink transmission as a Markov
decision process with random number of stages, where transmission power and
time on each transmission are the control policy. Due to random number of file
transmissions, we first proposed a revised Bellman's equation, where the
optimal control policy can be derived. In order to address the prohibitively
huge state space, we also introduce a low-complexity sub-optimal solution based
on an linear approximation of the value function. The approximated value
function can be calculated analytically, so that conventional numerical value
iteration can be eliminated. Moreover, the gap between the approximated value
function and the real value function is bounded analytically. It is shown by
simulation that, with the approximated MDP approach, the proposed algorithm can
significantly reduce the resource consumption at the base station.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03280</identifier>
 <datestamp>2019-01-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03280</id><created>2017-11-09</created><updated>2019-01-11</updated><authors><author><keyname>Gong</keyname><forenames>Yuan</forenames></author><author><keyname>Poellabauer</keyname><forenames>Christian</forenames></author></authors><title>Crafting Adversarial Examples For Speech Paralinguistics Applications</title><categories>cs.LG cs.CR cs.SD eess.AS stat.ML</categories><comments>Published in DYnamic and Novel Advances in Machine Learning and
  Intelligent Cyber Security (DYNAMICS) Workshop in conjunction with ACSAC'18,
  San Juan, Puerto Rico, December 2018</comments><doi>10.1145/3306195.3306196</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational paralinguistic analysis is increasingly being used in a wide
range of cyber applications, including security-sensitive applications such as
speaker verification, deceptive speech detection, and medical diagnostics.
While state-of-the-art machine learning techniques, such as deep neural
networks, can provide robust and accurate speech analysis, they are susceptible
to adversarial attacks. In this work, we propose an end-to-end scheme to
generate adversarial examples for computational paralinguistic applications by
perturbing directly the raw waveform of an audio recording rather than specific
acoustic features. Our experiments show that the proposed adversarial
perturbation can lead to a significant performance drop of state-of-the-art
deep neural networks, while only minimally impairing the audio quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03536</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03536</id><created>2017-11-08</created><authors><author><keyname>Elgammal</keyname><forenames>Ahmed</forenames></author><author><keyname>Kang</keyname><forenames>Yan</forenames></author><author><keyname>Leeuw</keyname><forenames>Milko Den</forenames></author></authors><title>Picasso, Matisse, or a Fake? Automated Analysis of Drawings at the
  Stroke Level for Attribution and Authentication</title><categories>eess.IV cs.AI cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a computational approach for analysis of strokes in line
drawings by artists. We aim at developing an AI methodology that facilitates
attribution of drawings of unknown authors in a way that is not easy to be
deceived by forged art. The methodology used is based on quantifying the
characteristics of individual strokes in drawings. We propose a novel algorithm
for segmenting individual strokes. We designed and compared different
hand-crafted and learned features for the task of quantifying stroke
characteristics. We also propose and compare different classification methods
at the drawing level. We experimented with a dataset of 300 digitized drawings
with over 80 thousands strokes. The collection mainly consisted of drawings of
Pablo Picasso, Henry Matisse, and Egon Schiele, besides a small number of
representative works of other artists. The experiments shows that the proposed
methodology can classify individual strokes with accuracy 70%-90%, and
aggregate over drawings with accuracy above 80%, while being robust to be
deceived by fakes (with accuracy 100% for detecting fakes in most settings).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03538</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03538</id><created>2017-11-08</created><authors><author><keyname>Eggimann</keyname><forenames>Manuel</forenames></author><author><keyname>Gloor</keyname><forenames>Christelle</forenames></author><author><keyname>Scheidegger</keyname><forenames>Florian</forenames></author><author><keyname>Cavigelli</keyname><forenames>Lukas</forenames></author><author><keyname>Schaffner</keyname><forenames>Michael</forenames></author><author><keyname>Smolic</keyname><forenames>Aljosa</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>Hydra: An Accelerator for Real-Time Edge-Aware Permeability Filtering in
  65nm CMOS</title><categories>eess.IV cs.AR cs.GR eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many modern video processing pipelines rely on edge-aware (EA) filtering
methods. However, recent high-quality methods are challenging to run in
real-time on embedded hardware due to their computational load. To this end, we
propose an area-efficient and real-time capable hardware implementation of a
high quality EA method. In particular, we focus on the recently proposed
permeability filter (PF) that delivers promising quality and performance in the
domains of HDR tone mapping, disparity and optical flow estimation. We present
an efficient hardware accelerator that implements a tiled variant of the PF
with low on-chip memory requirements and a significantly reduced external
memory bandwidth (6.4x w.r.t. the non-tiled PF). The design has been taped out
in 65 nm CMOS technology, is able to filter 720p grayscale video at 24.8 Hz and
achieves a high compute density of 6.7 GFLOPS/mm2 (12x higher than embedded
GPUs when scaled to the same technology node). The low area and bandwidth
requirements make the accelerator highly suitable for integration into SoCs
where silicon area budget is constrained and external memory is typically a
heavily contended resource.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03576</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03576</id><created>2017-11-06</created><authors><author><keyname>Bouteggui</keyname><forenames>Mokhtar</forenames></author><author><keyname>Merazka</keyname><forenames>Fatiha</forenames></author></authors><title>Performance of Source transmit Antenna selection for MIMO cooperative
  communication System Based DF protocol: Symbol Error Rate and Diversity order</title><categories>eess.SP cs.IT math.IT</categories><comments>8 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the performance of a single relay Multiple Input
Multiple Output (MIMO) cooperative communication system based on Decode and
Forward (DF) relaying protocol for two strategies using transmit antenna
selection at the source. The first strategy uses one antenna between the relay
and the destination, and the second strategy uses Space Time Block Coding
(STBC). All channels follow the Rayleigh fading distribution. We derive the
expression and Upper Bound for Symbol Error Rate (SER) for M-ary Phase Shift
Keying (M-PSK), and the diversity order for both strategies. The analytical
results show that the second strategy performs better than the first one for
the same diversity order and the same Rate R.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03601</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03601</id><created>2017-11-08</created><authors><author><keyname>Meng</keyname><forenames>Yao</forenames></author><author><keyname>Yu</keyname><forenames>Zhe</forenames></author><author><keyname>Shi</keyname><forenames>Di</forenames></author><author><keyname>Bian</keyname><forenames>Desong</forenames></author><author><keyname>Wang</keyname><forenames>Zhiwei</forenames></author></authors><title>Forced Oscillation Source Location via Multivariate Time Series
  Classification</title><categories>eess.SP</categories><comments>5 pages, 3 figures. Accepted by 2018 IEEE/PES Transmission and
  Distribution Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precisely locating low-frequency oscillation sources is the prerequisite of
suppressing sustained oscillation, which is an essential guarantee for the
secure and stable operation of power grids. Using synchrophasor measurements, a
machine learning method is proposed to locate the source of forced oscillation
in power systems. Rotor angle and active power of each power plant are utilized
to construct multivariate time series (MTS). Applying Mahalanobis distance
metric and dynamic time warping, the distance between MTS with different phases
or lengths can be appropriately measured. The obtained distance metric,
representing characteristics during the transient phase of forced oscillation
under different disturbance sources, is used for offline classifier training
and online matching to locate the disturbance source. Simulation results using
the four-machine two-area system and IEEE 39-bus system indicate that the
proposed location method can identify the power system forced oscillation
source online with high accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03633</identifier>
 <datestamp>2019-04-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03633</id><created>2017-11-09</created><authors><author><keyname>Karaku&#x15f;</keyname><forenames>Oktay</forenames></author><author><keyname>Kuruo&#x11f;lu</keyname><forenames>Ercan E.</forenames></author><author><keyname>Alt&#x131;nkaya</keyname><forenames>Mustafa A.</forenames></author></authors><title>Beyond Trans-dimensional RJMCMC: Application to Impulsive Data Modeling</title><categories>eess.SP</categories><comments>22 pages, 9 figures</comments><report-no>SIGPRO-D-17-01574</report-no><journal-ref>Signal Processing 153 (2018) 396-410</journal-ref><doi>10.1016/j.sigpro.2018.07.028</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible jump Markov chain Monte Carlo (RJMCMC) is a Bayesian model
estimation method which has been used for trans-dimensional sampling. In this
study, we propose utilization of RJMCMC beyond trans-dimensional sampling. This
new interpretation, which we call trans-space RJMCMC, reveals the undiscovered
potential of RJMCMC by exploiting the original formulation to explore spaces of
different classes or structures. This provides flexibility in using different
types of candidate classes in the combined model space such as spaces of linear
and nonlinear models or of various distribution families. As an application for
the proposed method, we have performed a special case of trans-space sampling,
namely trans-distributional RJMCMC in impulsive data modeling. In many areas
such as seismology, radar, image, using Gaussian models is a common practice
due to analytical ease. However, many noise processes do not follow a Gaussian
character and generally exhibit events too impulsive to be successfully
described by the Gaussian model. We test the proposed method to choose between
various impulsive distribution families to model both synthetically generated
noise processes and real-life measurements on power line communications (PLC)
impulsive noises and 2-D discrete wavelet transform (2-D DWT) coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03651</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03651</id><created>2017-11-09</created><authors><author><keyname>He</keyname><forenames>Liang</forenames></author><author><keyname>Shin</keyname><forenames>Kang G.</forenames></author></authors><title>How Long Will My Phone Battery Last?</title><categories>eess.SP cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile devices are only as useful as their battery lasts. Unfortunately, the
operation and life of a mobile device's battery degrade over time and usage.
The state-of-health (SoH) of batteries quantifies their degradation, but mobile
devices are unable to support its accurate estimation -- despite its importance
-- due mainly to their limited hardware and dynamic usage patterns, causing
various problems such as unexpected device shutoffs or even fire/explosion. To
remedy this lack of support, we design, implement and evaluate V-Health, a
low-cost user-level SoH estimation service for mobile devices based only on
their battery voltage, which is commonly available on all commodity mobile
devices. V-Health also enables four novel use-cases that improve mobile users'
experience from different perspectives. The design of V-Health is inspired by
our empirical finding that the relaxing voltages of a device battery
fingerprint its SoH, and is steered by extensive measurements with 15 batteries
used for various commodity mobile devices, such as Nexus 6P, Galaxy S3, iPhone
6 Plus, etc. These measurements consist of 13,377 battery
discharging/charging/resting cycles and have been conducted over 72 months
cumulatively. V-Health has been evaluated via both laboratory experiments and
field tests over 4-6 months, showing &lt;5% error in SoH estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03683</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03683</id><created>2017-11-09</created><authors><author><keyname>Nasim</keyname><forenames>Imtiaz</forenames></author><author><keyname>Kim</keyname><forenames>Seungmo</forenames></author></authors><title>Human Exposure to RF Fields in 5G Downlink</title><categories>eess.SP</categories><comments>Submitted to IEEE International Communications Conference (ICC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While cellular communications in millimeter wave (mmW) bands have been
attracting significant research interest, their potential harmful impacts on
human health are not as significantly studied. Prior research on human exposure
to radio frequency (RF) fields in a cellular communications system has been
focused on uplink only due to the closer physical contact of a transmitter to a
human body. However, this paper claims the necessity of thorough investigation
on human exposure to downlink RF fields, as cellular systems deployed in mmW
bands will entail (i) deployment of more transmitters due to smaller cell size
and (ii) higher concentration of RF energy using a highly directional antenna.
In this paper, we present human RF exposure levels in downlink of a Fifth
Generation Wireless Systems (5G). Our results show that 5G downlink RF fields
generate significantly higher power density (PD) and specific absorption rate
(SAR) than a current cellular system. This paper also shows that SAR should
also be taken into account for determining human RF exposure in the mmW
downlink.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03799</identifier>
 <datestamp>2019-10-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03799</id><created>2017-11-10</created><updated>2019-10-26</updated><authors><author><keyname>Scheel</keyname><forenames>Alexander</forenames></author><author><keyname>Dietmayer</keyname><forenames>Klaus</forenames></author></authors><title>Tracking Multiple Vehicles Using a Variational Radar Model</title><categories>eess.SP cs.RO stat.CO</categories><comments>This is a preprint (i.e. the accepted version) of: A. Scheel and K.
  Dietmayer, &quot;Tracking Multiple Vehicles Using a Variational Radar Model,&quot; in
  IEEE Transactions on Intelligent Transportation Systems, vol. 20, no. 10, pp.
  3721-3736, 2019. Digital Object Identifier 10.1109/TITS.2018.2879041</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-resolution radar sensors are able to resolve multiple detections per
object and therefore provide valuable information for vehicle environment
perception. For instance, multiple detections allow to infer the size of an
object or to more precisely measure the object's motion. Yet, the increased
amount of data raises the demands on tracking modules: measurement models that
are able to process multiple detections for an object are necessary and
measurement-to-object associations become more complex. This paper presents a
new variational radar model for tracking vehicles using radar detections and
demonstrates how this model can be incorporated into a Random-Finite-Set-based
multi-object filter. The measurement model is learned from actual data using
variational Gaussian mixtures and avoids excessive manual engineering. In
combination with the multiobject tracker, the entire process chain from the raw
measurements to the resulting tracks is formulated probabilistically. The
presented approach is evaluated on experimental data and it is demonstrated
that the data-driven measurement model outperforms a manually designed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03847</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03847</id><created>2017-11-08</created><authors><author><keyname>Gerstoft</keyname><forenames>Peter</forenames></author><author><keyname>Nannuru</keyname><forenames>Santosh</forenames></author><author><keyname>Mecklenbr&#xe4;uker</keyname><forenames>Christoph F.</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Sparse Bayesian Learning for DOA Estimation in Heteroscedastic Noise</title><categories>eess.SP physics.data-an</categories><comments>Submitted to IEEE TSP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper considers direction of arrival (DOA) estimation from long-term
observations in a noisy environment. In such an environment the noise source
might evolve, causing the stationary models to fail. Therefore a
heteroscedastic Gaussian noise model is introduced where the variance can vary
across observations and sensors. The source amplitudes are assumed independent
zero-mean complex Gaussian distributed with unknown variances (i.e. the source
powers), inspiring stochastic maximum likelihood DOA estimation. The DOAs of
plane waves are estimated from multi-snapshot sensor array data using sparse
Bayesian learning (SBL) where the noise is estimated across both sensors and
snapshots. This SBL approach is more flexible and performs better than
high-resolution methods since they cannot estimate the heteroscedastic noise
process. An alternative to SBL is simple data normalization, whereby only the
phase across the array is utilized. Simulations demonstrate that taking the
heteroscedastic noise into account improves DOA estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03890</identifier>
 <datestamp>2019-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03890</id><created>2017-11-10</created><updated>2019-05-29</updated><authors><author><keyname>Elvander</keyname><forenames>Filip</forenames></author><author><keyname>Jakobsson</keyname><forenames>Andreas</forenames></author><author><keyname>Karlsson</keyname><forenames>Johan</forenames></author></authors><title>Interpolation and Extrapolation of Toeplitz Matrices via Optimal Mass
  Transport</title><categories>eess.SP math.ST stat.ME stat.TH</categories><journal-ref>IEEE Transactions on Signal Processing, vol. 66, no. 20, (2018),
  pp. 5285 - 5298</journal-ref><doi>10.1109/TSP.2018.2866432</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a novel method for quantifying distances between
Toeplitz structured covariance matrices. By exploiting the spectral
representation of Toeplitz matrices, the proposed distance measure is defined
based on an optimal mass transport problem in the spectral domain. This may
then be interpreted in the covariance domain, suggesting a natural way of
interpolating and extrapolating Toeplitz matrices, such that the positive
semi-definiteness and the Toeplitz structure of these matrices are preserved.
The proposed distance measure is also shown to be contractive with respect to
both additive and multiplicative noise, and thereby allows for a quantification
of the decreased distance between signals when these are corrupted by noise.
Finally, we illustrate how this approach can be used for several applications
in signal processing. In particular, we consider interpolation and
extrapolation of Toeplitz matrices, as well as clustering problems and tracking
of slowly varying stochastic processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.03996</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.03996</id><created>2017-11-10</created><authors><author><keyname>Barzegar</keyname><forenames>Mahdi</forenames></author><author><keyname>Caire</keyname><forenames>Guiseppe</forenames></author><author><keyname>Flinth</keyname><forenames>Axel</forenames></author><author><keyname>Haghighatshoar</keyname><forenames>Saeid</forenames></author><author><keyname>Kutyniok</keyname><forenames>Gitta</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author></authors><title>Estimation of Angles of Arrival Through Superresolution -- A Soft
  Recovery Approach for General Antenna Geometries</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The estimation of direction of arrivals with help of $TV$-minimization is
studied. Contrary to prior work in this direction, which has only considered
certain antenna placement designs, we consider general antenna geometries.
Applying the soft-recovery framework, we are able to derive a theoretic
guarantee for a certain direction of arrival to be approximately recovered. We
discuss the impact of the recovery guarantee for a few concrete antenna
designs. Additionally, numerical simulations supporting the findings of the
theoretical part are performed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04022</identifier>
 <datestamp>2018-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04022</id><created>2017-11-10</created><updated>2018-11-30</updated><authors><author><keyname>Eghbal-zadeh</keyname><forenames>Hamid</forenames></author><author><keyname>Dorfer</keyname><forenames>Matthias</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Deep Within-Class Covariance Analysis for Robust Audio Representation
  Learning</title><categories>cs.LG cs.AI cs.SD eess.AS</categories><comments>11 pages, 3 tables, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Networks (CNNs) can learn effective features, though
have been shown to suffer from a performance drop when the distribution of the
data changes from training to test data. In this paper we analyze the internal
representations of CNNs and observe that the representations of unseen data in
each class, spread more (with higher variance) in the embedding space of the
CNN compared to representations of the training data. More importantly, this
difference is more extreme if the unseen data comes from a shifted
distribution. Based on this observation, we objectively evaluate the degree of
representation's variance in each class via eigenvalue decomposition on the
within-class covariance of the internal representations of CNNs and observe the
same behaviour. This can be problematic as larger variances might lead to
mis-classification if the sample crosses the decision boundary of its class. We
apply nearest neighbor classification on the representations and empirically
show that the embeddings with the high variance actually have significantly
worse KNN classification performances, although this could not be foreseen from
their end-to-end classification results. To tackle this problem, we propose
Deep Within-Class Covariance Analysis (DWCCA), a deep neural network layer that
significantly reduces the within-class covariance of a DNN's representation,
improving performance on unseen test data from a shifted distribution. We
empirically evaluate DWCCA on two datasets for Acoustic Scene Classification
(DCASE2016 and DCASE2017). We demonstrate that not only does DWCCA
significantly improve the network's internal representation, it also increases
the end-to-end classification accuracy, especially when the test set exhibits a
distribution shift. By adding DWCCA to a VGG network, we achieve around 6
percentage points improvement in the case of a distribution mismatch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04121</identifier>
 <datestamp>2018-05-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04121</id><created>2017-11-11</created><updated>2018-05-17</updated><authors><author><keyname>Zhang</keyname><forenames>Ning</forenames></author><author><keyname>Yan</keyname><forenames>Junchi</forenames></author><author><keyname>Zhou</keyname><forenames>Yuchen</forenames></author></authors><title>Weakly Supervised Audio Source Separation via Spectrum Energy Preserved
  Wasserstein Learning</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Separating audio mixtures into individual instrument tracks has been a long
standing challenging task. We introduce a novel weakly supervised audio source
separation approach based on deep adversarial learning. Specifically, our loss
function adopts the Wasserstein distance which directly measures the
distribution distance between the separated sources and the real sources for
each individual source. Moreover, a global regularization term is added to
fulfill the spectrum energy preservation property regardless separation. Unlike
state-of-the-art weakly supervised models which often involve deliberately
devised constraints or careful model selection, our approach need little prior
model specification on the data, and can be straightforwardly learned in an
end-to-end fashion. We show that the proposed method performs competitively on
public benchmark against state-of-the-art weakly supervised methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04174</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04174</id><created>2017-11-11</created><authors><author><keyname>Navon</keyname><forenames>Ariel</forenames></author><author><keyname>Keller</keyname><forenames>Yosi</forenames></author></authors><title>Financial Time Series Prediction Using Deep Learning</title><categories>eess.SP q-fin.ST</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present a data-driven end-to-end Deep Learning approach for
time series prediction, applied to financial time series. A Deep Learning
scheme is derived to predict the temporal trends of stocks and ETFs in NYSE or
NASDAQ. Our approach is based on a neural network (NN) that is applied to raw
financial data inputs, and is trained to predict the temporal trends of stocks
and ETFs. In order to handle commission-based trading, we derive an investment
strategy that utilizes the probabilistic outputs of the NN, and optimizes the
average return. The proposed scheme is shown to provide statistically
significant accurate predictions of financial market trends, and the investment
strategy is shown to be profitable under this challenging setup. The
performance compares favorably with contemporary benchmarks along two-years of
back-testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04256</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04256</id><created>2017-11-12</created><authors><author><keyname>Wang</keyname><forenames>Songyan</forenames></author><author><keyname>Yu</keyname><forenames>Jilai</forenames></author><author><keyname>Zhang</keyname><forenames>Wei</forenames></author></authors><title>Power System Transient Stability Assessment Using Couple Machines Method</title><categories>eess.SP</categories><comments>16 pages, 24 figures, preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analyzing the stability of the power system by using a few machines is
promising for transient stability assessment. A hybrid direct-time-domain
method that is fully based on the thinking of partial energy function is
proposed in this paper. During post-fault period, a pair of machines with high
rotor speed difference is defined as couple machines, and the stability
analysis of the system is transformed into that of several pairs of couple
machines. Based on the prediction of power-angle curve of couple machines
within a sampling window after fault clearing, the proposed method avoids the
definition of Center of Inertia (COI) and it can also evaluate the stability
margin of the system by using the predicted power-angle curve. Simulation
results demonstrate its effectiveness in transient stability assessment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04308</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04308</id><created>2017-11-12</created><updated>2017-11-23</updated><authors><author><keyname>Zhang</keyname><forenames>Pengfei</forenames></author><author><keyname>Nevat</keyname><forenames>Ido</forenames></author><author><keyname>Peters</keyname><forenames>Gareth W.</forenames></author><author><keyname>Fruehwirt</keyname><forenames>Wolfgang</forenames></author><author><keyname>Huang</keyname><forenames>Yongchao</forenames></author><author><keyname>Anders</keyname><forenames>Ivonne</forenames></author><author><keyname>Osborne</keyname><forenames>Michael</forenames></author></authors><title>Sensor Selection and Random Field Reconstruction for Robust and
  Cost-effective Heterogeneous Weather Sensor Networks for the Developing World</title><categories>stat.ML eess.SP</categories><comments>Presented at NIPS 2017 Workshop on Machine Learning for the
  Developing World</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the two fundamental problems of spatial field reconstruction and
sensor selection in heterogeneous sensor networks: (i) how to efficiently
perform spatial field reconstruction based on measurements obtained
simultaneously from networks with both high and low quality sensors; and (ii)
how to perform query based sensor set selection with predictive MSE performance
guarantee. For the first problem, we developed a low complexity algorithm based
on the spatial best linear unbiased estimator (S-BLUE). Next, building on the
S-BLUE, we address the second problem, and develop an efficient algorithm for
query based sensor set selection with performance guarantee. Our algorithm is
based on the Cross Entropy method which solves the combinatorial optimization
problem in an efficient manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04347</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04347</id><created>2017-11-12</created><authors><author><keyname>Fanioudakis</keyname><forenames>Lefteris</forenames></author><author><keyname>Potamitis</keyname><forenames>Ilyas</forenames></author></authors><title>Deep Networks tag the location of bird vocalisations on audio
  spectrograms</title><categories>eess.AS cs.SD</categories><comments>arXiv admin note: substantial text overlap with arXiv:1609.08408</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work focuses on reliable detection and segmentation of bird
vocalizations as recorded in the open field. Acoustic detection of avian sounds
can be used for the automatized monitoring of multiple bird taxa and querying
in long-term recordings for species of interest. These tasks are tackled in
this work, by suggesting two approaches: A) First, DenseNets are applied to
weekly labeled data to infer the attention map of the dataset (i.e. Salience
and CAM). We push further this idea by directing attention maps to the YOLO v2
Deepnet-based, detection framework to localize bird vocalizations. B) A deep
autoencoder, namely the U-net, maps the audio spectrogram of bird vocalizations
to its corresponding binary mask that encircles the spectral blobs of
vocalizations while suppressing other audio sources. We focus solely on
procedures requiring minimum human attendance, suitable to scan massive volumes
of data, in order to analyze them, evaluate insights and hypotheses and
identify patterns of bird activity. Hopefully, this approach will be valuable
to researchers, conservation practitioners, and decision makers that need to
design policies on biodiversity issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04351</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04351</id><created>2017-11-12</created><authors><author><keyname>Raboshchuk</keyname><forenames>Ganna</forenames></author><author><keyname>Quintana</keyname><forenames>Sergi G&#xf3;mez</forenames></author><author><keyname>Lilja</keyname><forenames>Alex Peir&#xf3;</forenames></author><author><keyname>Nadeu</keyname><forenames>Climent</forenames></author></authors><title>Automatic detection of alarm sounds in a noisy hospital environment
  using model and non-model based approaches</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the noisy acoustic environment of a Neonatal Intensive Care Unit (NICU)
there is a variety of alarms, which are frequently triggered by the biomedical
equipment. In this paper different approaches for automatic detection of those
sound alarms are presented and compared: 1) a non-model-based approach that
employs signal processing techniques; 2) a model-based approach based on neural
networks; and 3) an approach that combines both non-model and model-based
approaches. The performance of the developed detection systems that follow each
of those approaches is assessed, analysed and compared both at the frame level
and at the event level by using an audio database recorded in a real-world
hospital environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04365</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04365</id><created>2017-11-12</created><authors><author><keyname>Lu</keyname><forenames>Jingyang</forenames></author><author><keyname>Li</keyname><forenames>Lun</forenames></author><author><keyname>Shen</keyname><forenames>Dan</forenames></author><author><keyname>Chen</keyname><forenames>Genshe</forenames></author><author><keyname>Jia</keyname><forenames>Bin</forenames></author><author><keyname>Blasch</keyname><forenames>Erik</forenames></author><author><keyname>Pham</keyname><forenames>Khanh</forenames></author></authors><title>Dynamic Multi-Arm Bandit Game Based Multi-Agents Spectrum Sharing
  Strategy Design</title><categories>eess.SP</categories><doi>10.1109/DASC.2017.8102137</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a wireless avionics communication system, a Multi-arm bandit game is
mathematically formulated, which includes channel states, strategies, and
rewards. The simple case includes only two agents sharing the spectrum which is
fully studied in terms of maximizing the cumulative reward over a finite time
horizon. An Upper Confidence Bound (UCB) algorithm is used to achieve the
optimal solutions for the stochastic Multi-Arm Bandit (MAB) problem. Also, the
MAB problem can also be solved from the Markov game framework perspective.
Meanwhile, Thompson Sampling (TS) is also used as benchmark to evaluate the
proposed approach performance. Numerical results are also provided regarding
minimizing the expectation of the regret and choosing the best parameter for
the upper confidence bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04388</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04388</id><created>2017-11-12</created><authors><author><keyname>Xu</keyname><forenames>Juncai</forenames></author><author><keyname>Ren</keyname><forenames>Qingwen</forenames></author></authors><title>A Novel Method of Bolt Detection Based on Variational Modal
  Decomposition</title><categories>eess.SP</categories><comments>9 pages, 11 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The pull test is a destructive detection method, and it can t measure the
actual length of the bolt. As such, ultrasonic echo is one of the most
important non-destructive testing methods for bolt quality detection. In this
paper, the variance modal decomposition method is introduced into the bolt
detection signal analysis. Based on the morphological filtering and the VMD
method, the VMD combined morphological filtering principle is established into
the bolt detection signal analysis method. MF-VMD was used in order to analyze
the simulation vibration signal and the actual bolt detection signal. The
results showed that the MF-VMD is able to effectively separate the intrinsic
mode function, even when under the background of strong interference. Compared
with the conventional VMD method, the proposed method is able to remove the
noise interference. The intrinsic mode function of the field detection signal
can be effectively identified by the reflection of the signal at the bottom of
the bolt.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04459</identifier>
 <datestamp>2018-04-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04459</id><created>2017-11-13</created><updated>2018-04-22</updated><authors><author><keyname>He</keyname><forenames>Xin</forenames></author><author><keyname>Sun</keyname><forenames>Meng</forenames></author><author><keyname>Tay</keyname><forenames>Wee Peng</forenames></author><author><keyname>Gong</keyname><forenames>Yi</forenames></author></authors><title>Multilayer Nonlinear Processing for Information Privacy in Sensor
  Networks</title><categories>cs.CR eess.SP</categories><comments>The proof in Theorem 1 relies on the proof from other papers, but the
  extension from the discrete space can not be directly extended to the
  continuous space. Therefore, the proof in Theorem 1 is not reliable. The
  third author is responsible for the correctness in Section II.B, while the
  first author is responsible for other sections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sensor network wishes to transmit information to a fusion center to allow
it to detect a public hypothesis, but at the same time prevent it from
inferring a private hypothesis. We propose a multilayer nonlinear processing
procedure at each sensor to distort the sensor's data before it is sent to the
fusion center. In our proposed framework, sensors are grouped into clusters,
and each sensor first applies a nonlinear fusion function on the information it
receives from sensors in the same cluster and in a previous layer. A linear
weighting matrix is then used to distort the information it sends to sensors in
the next layer. We adopt a nonparametric approach and develop a modified mirror
descent algorithm to optimize the weighting matrices so as to ensure that the
regularized empirical risk of detecting the private hypothesis is above a given
privacy threshold, while minimizing the regularized empirical risk of detecting
the public hypothesis. Experiments on empirical datasets demonstrate that our
approach is able to achieve a good trade-off between the error rates of the
public and private hypothesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04460</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04460</id><created>2017-11-13</created><updated>2018-02-12</updated><authors><author><keyname>Keriven</keyname><forenames>Nicolas</forenames><affiliation>DMA</affiliation></author><author><keyname>Deleforge</keyname><forenames>Antoine</forenames><affiliation>PANAMA</affiliation></author><author><keyname>Liutkus</keyname><forenames>Antoine</forenames><affiliation>ZENITH</affiliation></author></authors><title>Blind Source Separation Using Mixtures of Alpha-Stable Distributions</title><categories>stat.ML cs.SD eess.AS</categories><comments>International Conference on Acoustics, Speech and Signal Processing
  (ICASSP), Apr 2018, Calgary, Canada</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new blind source separation algorithm based on mixtures of
alpha-stable distributions. Complex symmetric alpha-stable distributions have
been recently showed to better model audio signals in the time-frequency domain
than classical Gaussian distributions thanks to their larger dynamic range.
However, inference of these models is notoriously hard to perform because their
probability density functions do not have a closed-form expression in general.
Here, we introduce a novel method for estimating mixture of alpha-stable
distributions based on characteristic function matching. We apply this to the
blind estimation of binary masks in individual frequency bands from
multichannel convolutive audio mixes. We show that the proposed method yields
better separation performance than Gaussian-based binary-masking methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04480</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04480</id><created>2017-11-13</created><authors><author><keyname>Kwon</keyname><forenames>Taegyun</forenames></author><author><keyname>Jeong</keyname><forenames>Dasaem</forenames></author><author><keyname>Nam</keyname><forenames>Juhan</forenames></author></authors><title>Audio-to-score alignment of piano music using RNN-based automatic music
  transcription</title><categories>cs.SD eess.AS</categories><comments>6 pages, 5 figures, The paper was published in SMC 2017 proceedings,
  Proceedings of 14th Sound and Music Computing Conference (SMC). 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a framework for audio-to-score alignment on piano performance that
employs automatic music transcription (AMT) using neural networks. Even though
the AMT result may contain some errors, the note prediction output can be
regarded as a learned feature representation that is directly comparable to
MIDI note or chroma representation. To this end, we employ two recurrent neural
networks that work as the AMT-based feature extractors to the alignment
algorithm. One predicts the presence of 88 notes or 12 chroma in frame-level
and the other detects note onsets in 12 chroma. We combine the two types of
learned features for the audio-to-score alignment. For comparability, we apply
dynamic time warping as an alignment algorithm without any additional
post-processing. We evaluate the proposed framework on the MAPS dataset and
compare it to previous work. The result shows that the alignment framework with
the learned features significantly improves the accuracy, achieving less than
10 ms in mean onset error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04564</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04564</id><created>2017-11-13</created><authors><author><keyname>M&#xfc;ller</keyname><forenames>Markus</forenames></author><author><keyname>St&#xfc;ker</keyname><forenames>Sebastian</forenames></author><author><keyname>Waibel</keyname><forenames>Alex</forenames></author></authors><title>Phonemic and Graphemic Multilingual CTC Based Speech Recognition</title><categories>eess.AS cs.AI cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Training automatic speech recognition (ASR) systems requires large amounts of
data in the target language in order to achieve good performance. Whereas large
training corpora are readily available for languages like English, there exists
a long tail of languages which do suffer from a lack of resources. One method
to handle data sparsity is to use data from additional source languages and
build a multilingual system. Recently, ASR systems based on recurrent neural
networks (RNNs) trained with connectionist temporal classification (CTC) have
gained substantial research interest. In this work, we extended our previous
approach towards training CTC-based systems multilingually. Our systems feature
a global phone set, based on the joint phone sets of each source language. We
evaluated the use of different language combinations as well as the addition of
Language Feature Vectors (LFVs). As contrastive experiment, we built systems
based on graphemes as well. Systems having a multilingual phone set are known
to suffer in performance compared to their monolingual counterparts. With our
proposed approach, we could reduce the gap between these mono- and multilingual
setups, using either graphemes or phonemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04569</identifier>
 <datestamp>2018-02-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04569</id><created>2017-11-13</created><updated>2018-02-27</updated><authors><author><keyname>M&#xfc;ller</keyname><forenames>Markus</forenames></author><author><keyname>St&#xfc;ker</keyname><forenames>Sebastian</forenames></author><author><keyname>Waibel</keyname><forenames>Alex</forenames></author></authors><title>Multilingual Adaptation of RNN Based ASR Systems</title><categories>eess.AS cs.AI cs.CL</categories><comments>5 pages, 1 figure, to appear in 2018 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we focus on multilingual systems based on recurrent neural
networks (RNNs), trained using the Connectionist Temporal Classification (CTC)
loss function. Using a multilingual set of acoustic units poses difficulties.
To address this issue, we proposed Language Feature Vectors (LFVs) to train
language adaptive multilingual systems. Language adaptation, in contrast to
speaker adaptation, needs to be applied not only on the feature level, but also
to deeper layers of the network. In this work, we therefore extended our
previous approach by introducing a novel technique which we call &quot;modulation&quot;.
Based on this method, we modulated the hidden layers of RNNs using LFVs. We
evaluated this approach in both full and low resource conditions, as well as
for grapheme and phone based systems. Lower error rates throughout the
different conditions could be achieved by the use of the modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04644</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04644</id><created>2017-11-08</created><authors><author><keyname>Yu</keyname><forenames>Zhe</forenames></author><author><keyname>Shi</keyname><forenames>Di</forenames></author><author><keyname>Li</keyname><forenames>Haifeng</forenames></author><author><keyname>Wang</keyname><forenames>Yishen</forenames></author><author><keyname>Yi</keyname><forenames>Zhehan</forenames></author><author><keyname>Wang</keyname><forenames>Zhiwei</forenames></author></authors><title>An Extended Kalman Filter Enhanced Hilbert-Huang Transform in
  Oscillation Detection</title><categories>eess.SP math.NA</categories><comments>5 pages, 2 figures. Submitted to 2018 IEEE PES General Meeting. arXiv
  admin note: text overlap with arXiv:1706.05355</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hilbert-Huang transform (HHT) has drawn great attention in power system
analysis due to its capability to deal with dynamic signal and provide
instantaneous characteristics such as frequency, damping, and amplitudes.
However, its shortcomings, including mode mixing and end effects, are as
significant as its advantages. A preliminary result of an extended Kalman
filter (EKF) method to enhance HHT and hopefully to overcome these
disadvantages is presented in this paper. The proposal first removes dynamic DC
components in signals using empirical mode decomposition. Then an EKF model is
applied to extract instant coefficients. Numerical results using simulated and
real-world low-frequency oscillation data suggest the proposal can help to
overcome the mode mixing and end effects with a properly chosen number of
modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04646</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04646</id><created>2017-11-09</created><authors><author><keyname>Zhang</keyname><forenames>Junwei</forenames></author><author><keyname>Zhu</keyname><forenames>Guoxuan</forenames></author><author><keyname>Jie</keyname><forenames>Liu</forenames></author><author><keyname>Wu</keyname><forenames>Xiong</forenames></author><author><keyname>Zhu</keyname><forenames>Jianbo</forenames></author><author><keyname>Du</keyname><forenames>Cheng</forenames></author><author><keyname>Luo</keyname><forenames>Wenyong</forenames></author><author><keyname>Yu</keyname><forenames>Siyuan</forenames></author></authors><title>Orbital-angular-momentum mode-group multiplexed transmission over a
  graded-index ring-core fiber based on receive diversity and maximal ratio
  combining</title><categories>eess.SP physics.optics</categories><comments>13 pages, 6 figures</comments><doi>10.1364/OE.26.004243</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An orbital-angular-momentum (OAM) mode-group multiplexing (MGM) scheme based
on a graded-index ring-core fiber (GIRCF) is proposed, in which a single-input
two-output (or receive diversity) architecture is designed for each MG channel
and simple digital signal processing (DSP) is utilized to adaptively resist the
mode partition noise resulting from random intra-group mode crosstalk. There is
no need of complex multiple-input multiple-output (MIMO) equalization in this
scheme. Furthermore, the signal-to-noise ratio (SNR) of the received signals
can be improved if a simple maximal ratio combining (MRC) technique is employed
on the receiver side to efficiently take advantage of the diversity gain of
receiver. Intensity-modulated direct-detection (IM-DD) systems transmitting
three OAM mode groups with total 100-Gb/s discrete multi-tone (DMT) signals
over a 1-km GIRCF and two OAM mode groups with total 40-Gb/s DMT signals over
an 18-km GIRCF are experimentally demonstrated, respectively, to confirm the
feasibility of our proposed OAM-MGM scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04689</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04689</id><created>2017-11-13</created><authors><author><keyname>Singha</keyname><forenames>Thingom Bishal</forenames></author><author><keyname>Nath</keyname><forenames>Rajsekhar Kumar</forenames></author><author><keyname>Narsimhadhan</keyname><forenames>A. V.</forenames></author></authors><title>Person Recognition using Smartphones' Accelerometer Data</title><categories>eess.SP cs.CR cs.LG</categories><comments>Currently under review at IEEE National Conference on Communications
  2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smartphones have become quite pervasive in various aspects of our daily
lives. They have become important links to a host of important data and
applications, which if compromised, can lead to disastrous results. Due to
this, today's smartphones are equipped with multiple layers of authentication
modules. However, there still lies the need for a viable and unobtrusive layer
of security which can perform the task of user authentication using resources
which are cost-efficient and widely available on smartphones. In this work, we
propose a method to recognize users using data from a phone's embedded
accelerometer sensors. Features encapsulating information from both time and
frequency domains are extracted from walking data samples, and are used to
build a Random Forest ensemble classification model. Based on the experimental
results, the resultant model delivers an accuracy of 0.9679 and Area under
Curve (AUC) of 0.9822.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.04845</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.04845</id><created>2017-11-13</created><authors><author><keyname>Thickstun</keyname><forenames>John</forenames></author><author><keyname>Harchaoui</keyname><forenames>Zaid</forenames></author><author><keyname>Foster</keyname><forenames>Dean</forenames></author><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author></authors><title>Invariances and Data Augmentation for Supervised Music Transcription</title><categories>stat.ML cs.LG cs.SD eess.AS</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores a variety of models for frame-based music transcription,
with an emphasis on the methods needed to reach state-of-the-art on human
recordings. The translation-invariant network discussed in this paper, which
combines a traditional filterbank with a convolutional neural network, was the
top-performing model in the 2017 MIREX Multiple Fundamental Frequency
Estimation evaluation. This class of models shares parameters in the
log-frequency domain, which exploits the frequency invariance of music to
reduce the number of model parameters and avoid overfitting to the training
data. All models in this paper were trained with supervision by labeled data
from the MusicNet dataset, augmented by random label-preserving pitch-shift
transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05078</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05078</id><created>2017-11-14</created><updated>2019-07-08</updated><authors><author><keyname>Bharadwaj</keyname><forenames>Diddigi Raghuram</forenames></author><author><keyname>Danda</keyname><forenames>Sai Koti Reddy</forenames></author><author><keyname>Narayanam</keyname><forenames>Krishnasuri</forenames></author><author><keyname>Bhatnagar</keyname><forenames>Shalabh</forenames></author></authors><title>A unified decision making framework for supply and demand management in
  microgrid networks</title><categories>eess.SY cs.AI cs.SY</categories><doi>10.1109/SmartGridComm.2018.8587514</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers two important problems -- on the supply-side and
demand-side respectively and studies both in a unified framework. On the supply
side, we study the problem of energy sharing among microgrids with the goal of
maximizing profit obtained from selling power while at the same time not
deviating much from the customer demand. On the other hand, under shortage of
power, this problem becomes one of deciding the amount of power to be bought
with dynamically varying prices. On the demand side, we consider the problem of
optimally scheduling the time-adjustable demand - i.e., of loads with flexible
time windows in which they can be scheduled. While previous works have treated
these two problems in isolation, we combine these problems together and provide
a unified Markov decision process (MDP) framework for these problems. We then
apply the Q-learning algorithm, a popular model-free reinforcement learning
technique, to obtain the optimal policy. Through simulations, we show that the
policy obtained by solving our MDP model provides more profit to the
microgrids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05088</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05088</id><created>2017-11-14</created><authors><author><keyname>Weinand</keyname><forenames>Andreas</forenames></author><author><keyname>Karrenbauer</keyname><forenames>Michael</forenames></author><author><keyname>Sattiraju</keyname><forenames>Raja</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Application of Machine Learning for Channel based Message Authentication
  in Mission Critical Machine Type Communication</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of robust wireless communication systems for industrial
applications such as closed loop control processes has been considered manifold
recently. Additionally, the ongoing advances in the area of connected mobility
have similar or even higher requirements regarding system reliability and
availability. Beside unfulfilled reliability requirements, the availability of
a system can further be reduced, if it is under attack in the sense of
violation of information security goals such as data authenticity or integrity.
In order to guarantee the safe operation of an application, a system has at
least to be able to detect these attacks. Though there are numerous techniques
in the sense of conventional cryptography in order to achieve that goal, these
are not always suited for the requirements of the applications mentioned due to
resource inefficiency. In the present work, we show how the goal of message
authenticity based on physical layer security (PHYSEC) can be achieved. The
main idea for such techniques is to exploit user specific characteristics of
the wireless channel, especially in spatial domain. Additionally, we show the
performance of our machine learning based approach and compare it with other
existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05154</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05154</id><created>2017-11-14</created><authors><author><keyname>Roth</keyname><forenames>K.</forenames></author><author><keyname>Nossek</keyname><forenames>J. A.</forenames></author></authors><title>Robust massive MIMO Equilization for mmWave systems with low resolution
  ADCs</title><categories>eess.SP</categories><comments>submitted to WCNC 2018 Workshops</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Leveraging the available millimeter wave spectrum will be important for 5G.
In this work, we investigate the performance of digital beamforming with low
resolution ADCs based on link level simulations including channel estimation,
MIMO equalization and channel decoding. We consider the recently agreed 3GPP NR
type 1 OFDM reference signals. The comparison shows sequential DCD outperforms
MMSE-based MIMO equalization both in terms of detection performance and
complexity. We also show that the DCD based algorithm is more robust to channel
estimation errors. In contrast to the common believe we also show that the
complexity of MMSE equalization for a massive MIMO system is not dominated by
the matrix inversion but by the computation of the Gram matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05260</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05260</id><created>2017-11-14</created><authors><author><keyname>Bannerman</keyname><forenames>Aricca</forenames></author><author><keyname>Emington</keyname><forenames>James</forenames></author><author><keyname>Venkatesh</keyname><forenames>Anil</forenames></author></authors><title>Optimal Tuning of Two-Dimensional Keyboards</title><categories>cs.SD eess.AS</categories><comments>14 page, 3 figures</comments><msc-class>00A65</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new analysis of a tuning problem in music theory, pertaining
specifically to the approximation of harmonics on a two-dimensional keyboard.
We formulate the question as a linear programming problem on families of
constraints and provide exact solutions for many new keyboard dimensions. We
also show that an optimal tuning for harmonic approximation can be obtained for
any keyboard of given width, provided sufficiently many rows of octaves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05324</identifier>
 <datestamp>2019-12-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05324</id><created>2017-11-14</created><updated>2019-03-09</updated><authors><author><keyname>Furieri</keyname><forenames>Luca</forenames></author><author><keyname>Kamgarpour</keyname><forenames>Maryam</forenames></author></authors><title>Unified Approach to Convex Robust Distributed Control given Arbitrary
  Information Structures</title><categories>cs.SY eess.SY math.OC</categories><doi>10.1109/TAC.2019.2911655</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing optimal linear control policies for
linear systems in finite-horizon. The states and the inputs are required to
remain inside pre-specified safety sets at all times despite unknown
disturbances. In this technical note, we focus on the requirement that the
control policy is distributed, in the sense that it can only be based on
partial information about the history of the outputs. It is well-known that
when a condition denoted as Quadratic Invariance (QI) holds, the optimal
distributed control policy can be computed in a tractable way. Our goal is to
unify and generalize the class of information structures over which quadratic
invariance is equivalent to a test over finitely many binary matrices. The test
we propose certifies convexity of the output-feedback distributed control
problem in finite-horizon given any arbitrarily defined information structure,
including the case of time varying communication networks and forgetting
mechanisms. Furthermore, the framework we consider allows for including
polytopic constraints on the states and the inputs in a natural way, without
affecting convexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05355</identifier>
 <datestamp>2018-02-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05355</id><created>2017-11-14</created><updated>2018-02-14</updated><authors><author><keyname>Letcher</keyname><forenames>Alistair</forenames></author><author><keyname>Tri&#x161;ovi&#x107;</keyname><forenames>Jelena</forenames></author><author><keyname>Cademartori</keyname><forenames>Collin</forenames></author><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Xu</keyname><forenames>Jason</forenames></author></authors><title>Automatic Conflict Detection in Police Body-Worn Audio</title><categories>eess.AS cs.SD stat.ML</categories><comments>5 pages, 2 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic conflict detection has grown in relevance with the advent of
body-worn technology, but existing metrics such as turn-taking and overlap are
poor indicators of conflict in police-public interactions. Moreover, standard
techniques to compute them fall short when applied to such diversified and
noisy contexts. We develop a pipeline catered to this task combining adaptive
noise removal, non-speech filtering and new measures of conflict based on the
repetition and intensity of phrases in speech. We demonstrate the effectiveness
of our approach on body-worn audio data collected by the Los Angeles Police
Department.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05400</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05400</id><created>2017-11-14</created><authors><author><keyname>Tang</keyname><forenames>Zhanghan</forenames></author><author><keyname>Kuijper</keyname><forenames>Margreta</forenames></author><author><keyname>Chong</keyname><forenames>Michelle</forenames></author><author><keyname>Mareels</keyname><forenames>Iven</forenames></author><author><keyname>Leckie</keyname><forenames>Chris</forenames></author></authors><title>Linear system security -- detection and correction of adversarial
  attacks in the noise-free case</title><categories>eess.SP cs.SY</categories><comments>10 pages, 4 figures; this paper also submitted to Automatica in Nov
  2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of attack detection and attack correction for
multi-output discrete-time linear time-invariant systems under sensor attack.
More specifically, we focus on the situation where adversarial attack signals
are added to some of the system's output signals. A 'security index' is defined
to characterize the vulnerability of a system against such sensor attacks.
Methods to compute the security index are presented as are algorithms to detect
and correct for sensor attacks. The results are illustrated by examples
involving multiple sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05443</identifier>
 <datestamp>2018-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05443</id><created>2017-11-15</created><updated>2018-02-05</updated><authors><author><keyname>Zhang</keyname><forenames>Miao</forenames></author><author><keyname>Kang</keyname><forenames>Xiaofei</forenames></author><author><keyname>Wang</keyname><forenames>Yanqing</forenames></author><author><keyname>Li</keyname><forenames>Lantian</forenames></author><author><keyname>Tang</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Dai</keyname><forenames>Haisheng</forenames></author><author><keyname>Wang</keyname><forenames>Dong</forenames></author></authors><title>Human and Machine Speaker Recognition Based on Short Trivial Events</title><categories>cs.SD cs.CL cs.NE eess.AS</categories><comments>ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trivial events are ubiquitous in human to human conversations, e.g., cough,
laugh and sniff. Compared to regular speech, these trivial events are usually
short and unclear, thus generally regarded as not speaker discriminative and so
are largely ignored by present speaker recognition research. However, these
trivial events are highly valuable in some particular circumstances such as
forensic examination, as they are less subjected to intentional change, so can
be used to discover the genuine speaker from disguised speech. In this paper,
we collect a trivial event speech database that involves 75 speakers and 6
types of events, and report preliminary speaker recognition results on this
database, by both human listeners and machines. Particularly, the deep feature
learning technique recently proposed by our group is utilized to analyze and
recognize the trivial events, which leads to acceptable equal error rates
(EERs) despite the extremely short durations (0.2-0.5 seconds) of these events.
Comparing different types of events, 'hmm' seems more speaker discriminative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05447</identifier>
 <datestamp>2018-11-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05447</id><created>2017-11-15</created><updated>2017-11-27</updated><authors><author><keyname>Lee</keyname><forenames>Younggun</forenames></author><author><keyname>Rabiee</keyname><forenames>Azam</forenames></author><author><keyname>Lee</keyname><forenames>Soo-Young</forenames></author></authors><title>Emotional End-to-End Neural Speech Synthesizer</title><categories>cs.SD cs.CL eess.AS</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce an emotional speech synthesizer based on the
recent end-to-end neural model, named Tacotron. Despite its benefits, we found
that the original Tacotron suffers from the exposure bias problem and
irregularity of the attention alignment. Later, we address the problem by
utilization of context vector and residual connection at recurrent neural
networks (RNNs). Our experiments showed that the model could successfully train
and generate speech for given emotion labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05456</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05456</id><created>2017-11-15</created><authors><author><keyname>Soleimani</keyname><forenames>Hossein</forenames></author><author><keyname>Parada</keyname><forenames>Ra&#xf9;l</forenames></author><author><keyname>Tomasin</keyname><forenames>Stefano</forenames></author><author><keyname>Zorzi</keyname><forenames>Michele</forenames></author></authors><title>Statistical Approaches for Initial Access in mmWave 5G Systems</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  mmWave communication systems overcome high attenuation by using multiple
antennas at both the transmitter and the receiver to perform beamforming. Upon
entrance of a user equipment (UE) into a cell a scanning procedure must be
performed by the base station in order to find the UE, in what is known as
initial access (IA) procedure. In this paper we start from the observation that
UEs are more likely to enter from some directions than from others, as they
typically move along streets, while other movements are impossible due to the
presence of obstacles. Moreover, users are entering with a given time
statistics, for example described by inter-arrival times. In this context we
propose scanning strategies for IA that take into account the entrance
statistics. In particular, we propose two approaches: a memory-less random
illumination (MLRI) algorithm and a statistic and memory-based illumination
(SMBI) algorithm. The MLRI algorithm scans a random sector in each slot, based
on the statistics of sector entrance, without memory. The SMBI algorithm
instead scans sectors in a deterministic sequence selected according to the
statistics of sector entrance and time of entrance, and taking into account the
fact that the user has not yet been discovered (thus including memory). We
assess the performance of the proposed methods in terms of average discovery
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05551</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05551</id><created>2017-11-15</created><authors><author><keyname>Lafay</keyname><forenames>Gr&#xe9;goire</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Benetos</keyname><forenames>Emmanouil</forenames><affiliation>QMUL</affiliation></author><author><keyname>Lagrange</keyname><forenames>Mathieu</forenames><affiliation>LS2N</affiliation></author></authors><title>Sound Event Detection in Synthetic Audio: Analysis of the DCASE 2016
  Task Results</title><categories>eess.AS cs.SD stat.ML</categories><proxy>ccsd</proxy><journal-ref>IEEE Workshop on Applications of Signal Processing to Audio and
  Acoustics (WASPAA 2017), Sep 2017, Mohonk, United States</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As part of the 2016 public evaluation challenge on Detection and
Classification of Acoustic Scenes and Events (DCASE 2016), the second task
focused on evaluating sound event detection systems using synthetic mixtures of
office sounds. This task, which follows the `Event Detection - Office
Synthetic' task of DCASE 2013, studies the behaviour of tested algorithms when
facing controlled levels of audio complexity with respect to background noise
and polyphony/density, with the added benefit of a very accurate ground truth.
This paper presents the task formulation, evaluation metrics, submitted
systems, and provides a statistical analysis of the results achieved, with
respect to various aspects of the evaluation dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05596</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05596</id><created>2017-11-15</created><authors><author><keyname>Bader</keyname><forenames>Rolf</forenames></author></authors><title>Pitch and timbre discrimination at wave-to-spike transition in the
  cochlea</title><categories>q-bio.NC eess.AS</categories><comments>12 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new definition of musical pitch is proposed. A Finite-Difference Time
Domain (FDTM) model of the cochlea is used to calculate spike trains caused by
tone complexes and by a recorded classical guitar tone. All harmonic tone
complexes, musical notes, show a narrow-band Interspike Interval (ISI) pattern
at the respective fundamental frequency of the tone complex. Still this
fundamental frequency is not only present at the bark band holding the
respective best frequency of this fundamental frequency, but rather at all bark
bands driven by the tone complex partials. This is caused by drop-outs in the
basically regular, periodic spike train in the respective bands. These
drop-outs are caused by the energy distribution in the wave form, where time
spans of low energy are not able to drive spikes. The presence of the
fundamental periodicity in all bark bands can be interpreted as pitch. Contrary
to pitch, timbre is represented as a wide distribution of different ISIs over
bark bands. The definition of pitch is shown to also works with residue
pitches. The spike drop-outs in times of low energy of the wave form also cause
undertones, integer multiple subdivisions in periodicity, but in no case
overtones can appear. This might explain the musical minor scale, which was
proposed to be caused by undertones already in 1880 by Hugo Riemann, still
until now without knowledge about any physical realization of such undertones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05655</identifier>
 <datestamp>2018-07-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05655</id><created>2017-11-15</created><updated>2018-07-10</updated><authors><author><keyname>Mahjoub</keyname><forenames>Hossein Nourkhiz</forenames></author><author><keyname>Toghi</keyname><forenames>Behrad</forenames></author><author><keyname>Fallah</keyname><forenames>Yaser P.</forenames></author></authors><title>A Stochastic Hybrid Framework for Driver Behavior Modeling Based on
  Hierarchical Dirichlet Process</title><categories>eess.SP</categories><comments>This is the accepted version of the paper in 2018 IEEE 88th Vehicular
  Technology Conference (VTC2018-Fall) (references added, title and abstract
  modified)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scalability is one of the major issues for real-world Vehicle-to-Vehicle
network realization. To tackle this challenge, a stochastic hybrid modeling
framework based on a non-parametric Bayesian inference method, i.e.,
hierarchical Dirichlet process (HDP), is investigated in this paper. This
framework is able to jointly model driver/vehicle behavior through forecasting
the vehicle dynamical time-series. This modeling framework could be merged with
the notion of model-based information networking, which is recently proposed in
the vehicular literature, to overcome the scalability challenges in dense
vehicular networks via broadcasting the behavioral models instead of raw
information dissemination. This modeling approach has been applied on several
scenarios from the realistic Safety Pilot Model Deployment (SPMD) driving data
set and the results show a higher performance of this model in comparison with
the zero-hold method as the baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05747</identifier>
 <datestamp>2018-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05747</id><created>2017-11-15</created><updated>2018-10-30</updated><authors><author><keyname>Donahue</keyname><forenames>Chris</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Prabhavalkar</keyname><forenames>Rohit</forenames></author></authors><title>Exploring Speech Enhancement with Generative Adversarial Networks for
  Robust Speech Recognition</title><categories>cs.SD cs.LG cs.NE eess.AS</categories><comments>Published as a conference paper at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the effectiveness of generative adversarial networks (GANs)
for speech enhancement, in the context of improving noise robustness of
automatic speech recognition (ASR) systems. Prior work demonstrates that GANs
can effectively suppress additive noise in raw waveform speech signals,
improving perceptual quality metrics; however this technique was not justified
in the context of ASR. In this work, we conduct a detailed study to measure the
effectiveness of GANs in enhancing speech contaminated by both additive and
reverberant noise. Motivated by recent advances in image processing, we propose
operating GANs on log-Mel filterbank spectra instead of waveforms, which
requires less computation and is more robust to reverberant noise. While GAN
enhancement improves the performance of a clean-trained ASR system on noisy
speech, it falls short of the performance achieved by conventional multi-style
training (MTR). By appending the GAN-enhanced features to the noisy inputs and
retraining, we achieve a 7% WER improvement relative to the MTR system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05837</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05837</id><created>2017-11-15</created><authors><author><keyname>Depatla</keyname><forenames>Saandeep</forenames></author><author><keyname>Mostofi</keyname><forenames>Yasamin</forenames></author></authors><title>Crowd Counting Through Walls Using WiFi</title><categories>eess.SP cs.NI</categories><comments>10 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Counting the number of people inside a building, from outside and without
entering the building, is crucial for many applications. In this paper, we are
interested in counting the total number of people walking inside a building (or
in general behind walls), using readily-deployable WiFi transceivers that are
installed outside the building, and only based on WiFi RSSI measurements. The
key observation of the paper is that the inter-event times, corresponding to
the dip events of the received signal, are fairly robust to the attenuation
through walls (for instance as compared to the exact dip values). We then
propose a methodology that can extract the total number of people from the
inter-event times. More specifically, we first show how to characterize the
wireless received power measurements as a superposition of renewal-type
processes. By borrowing theories from the renewal-process literature, we then
show how the probability mass function of the inter-event times carries vital
information on the number of people. We validate our framework with 44
experiments in five different areas on our campus (3 classrooms, a conference
room, and a hallway), using only one WiFi transmitter and receiver installed
outside of the building, and for up to and including 20 people. Our experiments
further include areas with different wall materials, such as concrete, plaster,
and wood, to validate the robustness of the proposed approach. Overall, our
results show that our approach can estimate the total number of people behind
the walls with a high accuracy while minimizing the need for prior
calibrations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05855</identifier>
 <datestamp>2018-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05855</id><created>2017-11-15</created><updated>2018-01-31</updated><authors><author><keyname>Depatla</keyname><forenames>Saandeep</forenames></author><author><keyname>Mostofi</keyname><forenames>Yasamin</forenames></author></authors><title>Passive Crowd Speed Estimation in Adjacent Regions With Minimal WiFi
  Sensing</title><categories>eess.SP cs.NI</categories><comments>14 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a methodology for estimating the crowd speed using
WiFi devices without relying on people to carry any device. Our approach not
only enables speed estimation in the region where WiFi links are, but also in
the adjacent possibly WiFi-free regions. More specifically, we use a pair of
WiFi links in one region, whose RSSI measurements are then used to estimate the
crowd speed, not only in this region, but also in adjacent WiFi-free regions.
We first prove how the cross-correlation and the probability of crossing the
two links implicitly carry key information about the pedestrian speeds and
develop a mathematical model to relate them to pedestrian speeds. We then
validate our approach with 108 experiments, in both indoor and outdoor, where
up to 10 people walk in two adjacent areas, with variety of speeds per region,
showing that our framework can accurately estimate these speeds with only a
pair of WiFi links in one region. For instance, the NMSE over all experiments
is 0.18. We also evaluate our framework in a museum-type setting and estimate
the popularity of different exhibits. We finally run experiments in an aisle in
Costco, estimating key attributes of buyers' behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.05923</identifier>
 <datestamp>2018-04-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.05923</id><created>2017-11-15</created><updated>2018-04-19</updated><authors><author><keyname>Gupta</keyname><forenames>Payal</forenames></author><author><keyname>Agrawal</keyname><forenames>Monika</forenames></author></authors><title>Enhanced Array Aperture using Higher Order Statistics for DoA Estimation</title><categories>eess.SP stat.AP</categories><comments>I want to withdraw the paper because of I have noticed many drawbacks
  of the paper. I got the review about this &quot;it is not correct technically&quot;</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Recently, the higher order statistics (HOS) and sparsity based array are most
talked about techniques to estimate the Direction of Arrival (DoA). They not
only provide enhanced Degree of Freedom (DoF) to handle underdetermined cases
but also improve the estimation accuracy of the system. To achieve high
accuracy and more number of DoF with limited number of sensors, here we have
proposed a method based on the fourth order statistics. The aperture of virtual
array becomes O(16N^4) using N physical sensors. Proposed method can be
extended to the HOS which increases the DoF by many folds. Numeric simulation
validates these claims that the proposed method increases the resolution
capacity as well as maximize the DoF among all the earlier proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06101</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06101</id><created>2017-11-14</created><authors><author><keyname>Weinand</keyname><forenames>Andreas</forenames></author><author><keyname>Karrenbauer</keyname><forenames>Michael</forenames></author><author><keyname>Lianghai</keyname><forenames>Ji</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>Physical Layer Authentication for Mission Critical Machine Type
  Communication using Gaussian Mixture Model based Clustering</title><categories>cs.NI eess.SP</categories><comments>arXiv admin note: text overlap with arXiv:1711.03806 and substantial
  text overlap with arXiv:1711.05088</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The application of Mission Critical Machine Type Communication (MC-MTC) in
wireless systems is currently a hot research topic. Wireless systems are
considered to provide numerous advantages over wired systems in e.g. industrial
applications such as closed loop control. However, due to the broadcast nature
of the wireless channel, such systems are prone to a wide range of cyber
attacks. These range from passive eavesdropping attacks to active attacks like
data manipulation or masquerade attacks. Therefore it is necessary to provide
reliable and efficient security mechanisms. Some of the most important security
issues in such a system are to ensure integrity as well as authenticity of
exchanged messages over the air between communicating devices. In the present
work, an approach on how to achieve this goal in MC-MTC systems based on
Physical Layer Security (PHYSEC) is presented. A new method that clusters
channel estimates of different transmitters based on a Gaussian Mixture Model
is applied for that purpose. Further, an experimental proof-of-concept
evaluation is given and we compare the performance of our approach with a mean
square error based detection method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06297</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06297</id><created>2017-11-16</created><authors><author><keyname>Thrampoulidis</keyname><forenames>Christos</forenames></author><author><keyname>Shulkind</keyname><forenames>Gal</forenames></author><author><keyname>Xu</keyname><forenames>Feihu</forenames></author><author><keyname>Freeman</keyname><forenames>William T.</forenames></author><author><keyname>Shapiro</keyname><forenames>Jeffrey H.</forenames></author><author><keyname>Torralba</keyname><forenames>Antonio</forenames></author><author><keyname>Wong</keyname><forenames>Franco N. C.</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory W.</forenames></author></authors><title>Exploiting Occlusion in Non-Line-of-Sight Active Imaging</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active non-line-of-sight imaging systems are of growing interest for diverse
applications. The most commonly proposed approaches to date rely on exploiting
time-resolved measurements, i.e., measuring the time it takes for short light
pulses to transit the scene. This typically requires expensive, specialized,
ultrafast lasers and detectors that must be carefully calibrated. We develop an
alternative approach that exploits the valuable role that natural occluders in
a scene play in enabling accurate and practical image formation in such
settings without such hardware complexity. In particular, we demonstrate that
the presence of occluders in the hidden scene can obviate the need for
collecting time-resolved measurements, and develop an accompanying analysis for
such systems and their generalizations. Ultimately, the results suggest the
potential to develop increasingly sophisticated future systems that are able to
identify and exploit diverse structural features of the environment to
reconstruct scenes hidden from view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06309</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06309</id><created>2017-11-16</created><authors><author><keyname>Santos</keyname><forenames>Joao Felipe</forenames></author><author><keyname>Falk</keyname><forenames>Tiago H.</forenames></author></authors><title>Speech Dereverberation with Context-aware Recurrent Neural Networks</title><categories>cs.SD eess.AS</categories><comments>Submitted to IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a model to perform speech dereverberation by
estimating its spectral magnitude from the reverberant counterpart. Our models
are capable of extracting features that take into account both short and
long-term dependencies in the signal through a convolutional encoder (which
extracts features from a short, bounded context of frames) and a recurrent
neural network for extracting long-term information. Our model outperforms a
recently proposed model that uses different context information depending on
the reverberation time, without requiring any sort of additional input,
yielding improvements of up to 0.4 on PESQ, 0.3 on STOI, and 1.0 on POLQA
relative to reverberant speech. We also show our model is able to generalize to
real room impulse responses even when only trained with simulated room impulse
responses, different speakers, and high reverberation times. Lastly, listening
tests show the proposed method outperforming benchmark models in reduction of
perceived reverberation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06386</identifier>
 <datestamp>2019-11-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06386</id><created>2017-11-16</created><updated>2019-11-06</updated><authors><author><keyname>Zeng</keyname><forenames>Tingting</forenames></author><author><keyname>Brooks</keyname><forenames>Jonathan</forenames></author><author><keyname>Barooah</keyname><forenames>Prabir</forenames></author></authors><title>Simultaneous identification of linear building dynamic model and
  disturbance using sparsity-promoting optimization</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method that simultaneously identifies a linear time-invariant
model of a building's temperature dynamics and a transformed version of the
unmeasured disturbance affecting the building. Our method uses
l1-regularization to encourage the identified disturbance to be approximately
sparse, which is motivated by the slowly-varying nature of occupancy that
determines the disturbance. The proposed method involves solving a convex
optimization problem that guarantees the identified black-box model possess
known properties of the plant, especially input-output stability and positive
DC gains. These features enable one to use the method as part of a
self-learning control system in which the model of the building is updated
periodically without requiring human intervention. Results from the application
of the method on data from a simulated and real building are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06434</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06434</id><created>2017-11-17</created><authors><author><keyname>Shi</keyname><forenames>Ziqiang</forenames></author><author><keyname>Wang</keyname><forenames>Mengjiao</forenames></author><author><keyname>Liu</keyname><forenames>Liu</forenames></author><author><keyname>Lin</keyname><forenames>Huibin</forenames></author><author><keyname>Liu</keyname><forenames>Rujie</forenames></author></authors><title>A Double Joint Bayesian Approach for J-Vector Based Text-dependent
  Speaker Verification</title><categories>cs.SD cs.MM eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  J-vector has been proved to be very effective in text-dependent speaker
verification with short-duration speech. However, the current state-of-the-art
back-end classifiers, e.g. joint Bayesian model, cannot make full use of such
deep features. In this paper, we generalize the standard joint Bayesian
approach to model the multi-faceted information in the j-vector explicitly and
jointly. In our generalization, the j-vector was modeled as a result derived by
a generative Double Joint Bayesian (DoJoBa) model, which contains several kinds
of latent variables. With DoJoBa, we are able to explicitly build a model that
can combine multiple heterogeneous information from the j-vectors. In
verification step, we calculated the likelihood to describe whether the two
j-vectors having consistent labels or not. On the public RSR2015 data corpus,
the experimental results showed that our approach can achieve 0.02\% EER and
0.02\% EER for impostor wrong and impostor correct cases respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06546</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06546</id><created>2017-11-02</created><authors><author><keyname>Xu</keyname><forenames>Tianhua</forenames></author><author><keyname>Shevchenko</keyname><forenames>Nikita A.</forenames></author><author><keyname>Karanov</keyname><forenames>Boris</forenames></author><author><keyname>Liga</keyname><forenames>Gabriele</forenames></author><author><keyname>Lavery</keyname><forenames>Domani&#xe7;</forenames></author><author><keyname>Killey</keyname><forenames>Robert I.</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>Digital Nonlinearity Compensation in High-Capacity Optical Fibre
  Communication Systems: Performance and Optimisation</title><categories>eess.SP</categories><comments>Invited paper</comments><msc-class>94A12</msc-class><acm-class>C.2.5</acm-class><journal-ref>[IEEE] Advances in Wireless and Optical Communications (RTUWO),
  2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Meeting the ever-growing information rate demands has become of utmost
importance for optical communication systems. However, it has proven to be a
challenging task due to the presence of Kerr effects, which have largely been
regarded as a major bottleneck for enhancing the achievable information rates
in modern optical communications. In this work, the optimisation and
performance of digital nonlinearity compensation are discussed for maximising
the achievable information rates in spectrally-efficient optical fibre
communication systems. It is found that, for any given target information rate,
there exists a trade-off between modulation format and compensated bandwidth to
reduce the computational complexity requirement of digital nonlinearity
compensation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06548</identifier>
 <datestamp>2018-02-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06548</id><created>2017-11-12</created><updated>2018-02-24</updated><authors><author><keyname>Dai</keyname><forenames>Jisheng</forenames></author><author><keyname>Liu</keyname><forenames>An</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>FDD Massive MIMO Channel Estimation with Arbitrary 2D-Array Geometry</title><categories>eess.SP</categories><comments>15 pages, 9 figures, IEEE Transactions on Signal Processing, 2018</comments><doi>10.1109/TSP.2018.2807390</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of downlink channel estimation in
frequency-division duplexing (FDD) massive multiple-input multiple-output
(MIMO) systems. The existing methods usually exploit hidden sparsity under a
discrete Fourier transform (DFT) basis to estimate the cdownlink channel.
However, there are at least two shortcomings of these DFT-based methods: 1)
they are applicable to uniform linear arrays (ULAs) only, since the DFT basis
requires a special structure of ULAs, and 2) they always suffer from a
performance loss due to the leakage of energy over some DFT bins. To deal with
the above shortcomings, we introduce an off-grid model for downlink channel
sparse representation with arbitrary 2D-array antenna geometry, and propose an
efficient sparse Bayesian learning (SBL) approach for the sparse channel
recovery and off-grid refinement. The main idea of the proposed off-grid method
is to consider the sampled grid points as adjustable parameters. Utilizing an
in-exact block majorization-minimization (MM) algorithm, the grid points are
refined iteratively to minimize the off-grid gap. Finally, we further extend
the solution to uplink-aided channel estimation by exploiting the angular
reciprocity between downlink and uplink channels, which brings enhanced
recovery performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06549</identifier>
 <datestamp>2018-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06549</id><created>2017-11-15</created><authors><author><keyname>Cox</keyname><forenames>Mitchell A.</forenames></author><author><keyname>Rosales-Guzm&#xe1;n</keyname><forenames>Carmelo</forenames></author><author><keyname>Cheng</keyname><forenames>Ling</forenames></author><author><keyname>Forbes</keyname><forenames>Andrew</forenames></author></authors><title>Spatial Mode Diversity for Robust Free-Space Optical Communications</title><categories>eess.SP physics.optics</categories><journal-ref>Phys. Rev. Applied 10, 024020 (2018)</journal-ref><doi>10.1103/PhysRevApplied.10.024020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Free-space communication links are severely affected by atmospheric
turbulence, which causes degradation in the transmitted signal. One of the most
common solutions to overcome this is to exploit diversity. In this approach,
information is sent in parallel using two or more transmitters that are
spatially separated, with each beam therefore experiencing different
atmospheric turbulence, lowering the probability of a receive error. In this
work we propose and experimentally demonstrate a generalization of diversity
based on spatial modes of light, which we have termed $\textit{modal
diversity}$. We remove the need for a physical separation of the transmitters
by exploiting the fact that spatial modes of light experience different
perturbations, even when travelling along the same path. For this
proof-of-principle we selected modes from the Hermite-Gaussian and
Laguerre-Gaussian basis sets and demonstrate an improvement in Bit Error Rate
by up to 54\%. We outline that modal diversity enables physically compact and
longer distance free space optical links without increasing the total transmit
power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06550</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06550</id><created>2017-11-14</created><authors><author><keyname>Ghaemmaghami</keyname><forenames>Pouya</forenames></author></authors><title>Reconstruction of the External Stimuli from Brain Signals</title><categories>eess.SP cs.AI</categories><comments>9 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the rapid advances in Brain-computer Interfacing (BCI) and continuous
effort to improve the accuracy of brain decoding systems, the urge for the
systems to reconstruct the experiences of the users has been widely
acknowledged. This urge has been investigated by some researchers during the
past years in terms of reconstruction of the naturalistic images, abstract
images, video and audio. In this study, we try to tackle this issue by
regressing the stimuli spectrogram using the spectrogram analysis of the brain
signals. The results of our regression-based method suggest the feasibility of
such reconstructions using the neuroimaging techniques that are appropriate for
out-of-lab scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06560</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06560</id><created>2017-11-15</created><authors><author><keyname>Cohen</keyname><forenames>David</forenames></author><author><keyname>Cohen</keyname><forenames>Deborah</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>High Resolution FDMA MIMO Radar</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1608.07799</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional multiple input multiple output radars, which transmit orthogonal
coded waveforms, suffer from range-azimuth resolution trade-off. In this work,
we adopt a frequency division multiple access (FDMA) approach that breaks this
conflict. We combine narrow individual bandwidth for high azimuth resolution
and large overall total bandwidth for high range resolution. We process all
channels jointly to overcome the FDMA range resolution limitation to a single
bandwidth, and address range-azimuth coupling using a random array
configuration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06706</identifier>
 <datestamp>2018-04-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06706</id><created>2017-11-17</created><authors><author><keyname>Ahmed</keyname><forenames>I. Zakir</forenames></author><author><keyname>Sadjadpour</keyname><forenames>Hamid</forenames></author><author><keyname>Yousefi</keyname><forenames>Shahram</forenames></author></authors><title>A Joint Combiner and Bit Allocation Design for Massive MIMO Using
  Genetic Algorithm</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted for publication in Asilomar Conference on Signals, Systems,
  and Computers 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we derive a closed-form expression for the combiner of a
multiple-input-multiple-output (MIMO) receiver equipped with a
minimum-mean-square-error (MMSE) estimator. We propose using
variable-bit-resolution analog-to- digital converters (ADC) across radio
frequency (RF) paths. The combiner designed is a function of the quantization
errors across each RF path. Using very low bit resolution ADCs (1-2bits) is a
popular approach with massive MIMO receiver architectures to mitigate large
power demands. We show that for certain channel conditions, adopting unequal
bit resolution ADCs (e.g., between 1 and 4 bits) on different RF chains, along
with the proposed combiner, improves the performance of the MIMO receiver in
the Mean Squared Error (MSE) sense. The variable-bit-resolution ADCs is still
within the power constraint of using equal bit resolution ADCs on all paths
(e.g., 2-bits). We propose a genetic algorithm in conjunction with the derived
combiner to arrive at an optimal ADC bit allocation framework with significant
reduction in computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06805</identifier>
 <datestamp>2019-05-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06805</id><created>2017-11-17</created><authors><author><keyname>Scheibler</keyname><forenames>Robin</forenames></author><author><keyname>Di Carlo</keyname><forenames>Diego</forenames></author><author><keyname>Deleforge</keyname><forenames>Antoine</forenames></author><author><keyname>Dokmani&#x107;</keyname><forenames>Ivan</forenames></author></authors><title>Separake: Source Separation with a Little Help From Echoes</title><categories>cs.SD eess.AS</categories><doi>10.1109/ICASSP.2018.8461345</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is commonly believed that multipath hurts various audio processing
algorithms. At odds with this belief, we show that multipath in fact helps
sound source separation, even with very simple propagation models. Unlike most
existing methods, we neither ignore the room impulse responses, nor we attempt
to estimate them fully. We rather assume that we know the positions of a few
virtual microphones generated by echoes and we show how this gives us enough
spatial diversity to get a performance boost over the anechoic case. We show
improvements for two standard algorithms---one that uses only magnitudes of the
transfer functions, and one that also uses the phases. Concretely, we show that
multichannel non-negative matrix factorization aided with a small number of
echoes beats the vanilla variant of the same algorithm, and that with magnitude
information only, echoes enable separation where it was previously impossible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06815</identifier>
 <datestamp>2018-10-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06815</id><created>2017-11-18</created><updated>2018-10-10</updated><authors><author><keyname>Shahtalebi</keyname><forenames>Soroosh</forenames></author><author><keyname>Atashzar</keyname><forenames>Seyed Farokh</forenames></author><author><keyname>Patel</keyname><forenames>Rajni V.</forenames></author><author><keyname>Mohammadi</keyname><forenames>Arash</forenames></author></authors><title>WAKE: Wavelet Decomposition Coupled with Adaptive Kalman Filtering for
  Pathological Tremor Extraction</title><categories>eess.SP cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pathological Hand Tremor (PHT) is among common symptoms of several
neurological movement disorders, which can significantly degrade quality of
life of affected individuals. Beside pharmaceutical and surgical therapies,
mechatronic technologies have been utilized to control PHTs. Most of these
technologies function based on estimation, extraction, and characterization of
tremor movement signals. Real-time extraction of tremor signal is of paramount
importance because of its application in assistive and rehabilitative devices.
In this paper, we propose a novel on-line adaptive method which can adjust the
hyper-parameters of the filter to the variable characteristics of the tremor.
The proposed &quot;WAKE: Wavelet decomposition coupled with Adaptive Kalman
filtering technique for pathological tremor Extraction, referred to as the WAKE
framework&quot; is composed of a new adaptive Kalman filter and a wavelet transform
core to provide indirect prediction of the tremor, one sample ahead of time, to
be used for its suppression. In this paper, the design, implementation and
evaluation of WAKE are given. The performance is evaluated based on three
different datasets, the first one is a synthetic dataset, developed in this
work, that simulates hand tremor under ten different conditions. The second and
third ones are real datasets recorded from patients with PHTs. The results
obtained from the proposed WAKE framework demonstrate significant improvements
in the estimation accuracy in comparison with two well regarded techniques in
the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06816</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06816</id><created>2017-11-18</created><authors><author><keyname>Shi</keyname><forenames>Haowei</forenames></author><author><keyname>Xie</keyname><forenames>Mutong</forenames></author><author><keyname>Gao</keyname><forenames>Xinlu</forenames></author><author><keyname>Huang</keyname><forenames>Shanguo</forenames></author></authors><title>A Figurative Identification for Superposed OAM Modes in FSO Systems</title><categories>eess.SP physics.optics</categories><comments>3 pages, 3 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate that a complete projection in Hilbert Space figuratively
describes a superposed state, introducing a new scale to qualify an FSO system.
Measurement simulation of superposed OAM beam through this projection scheme is
given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06830</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06830</id><created>2017-11-18</created><updated>2018-06-19</updated><authors><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>D'Amico</keyname><forenames>Antonio A.</forenames></author><author><keyname>Morelli</keyname><forenames>Michele</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Random Access in Massive MIMO by Exploiting Timing Offsets and Excess
  Antennas</title><categories>eess.SP cs.IT math.IT</categories><comments>30 pages, 6 figures, 1 table, submitted to Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive MIMO systems, where base stations are equipped with hundreds of
antennas, are an attractive way to handle the rapid growth of data traffic. As
the number of user equipments (UEs) increases, the initial access and handover
in contemporary networks will be flooded by user collisions. In this paper, a
random access protocol is proposed that resolves collisions and performs timing
estimation by simply utilizing the large number of antennas envisioned in
Massive MIMO networks. UEs entering the network perform spreading in both time
and frequency domains, and their timing offsets are estimated at the base
station in closed-form using a subspace decomposition approach. This
information is used to compute channel estimates that are subsequently employed
by the base station to communicate with the detected UEs. The favorable
propagation conditions of Massive MIMO suppress interference among UEs whereas
the inherent timing misalignments improve the detection capabilities of the
protocol. Numerical results are used to validate the performance of the
proposed procedure in cellular networks under uncorrelated and correlated
fading channels. With $2.5\times10^3$ UEs that may simultaneously become active
with probability 1\% and a total of $16$ frequency-time codes (in a given
random access block), it turns out that, with $100$ antennas, the proposed
procedure successfully detects a given UE with probability 75\% while providing
reliable timing estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06954</identifier>
 <datestamp>2019-09-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06954</id><created>2017-11-18</created><updated>2019-09-07</updated><authors><author><keyname>Hasanzadeh</keyname><forenames>Arman</forenames></author><author><keyname>Liu</keyname><forenames>Xi</forenames></author><author><keyname>Duffield</keyname><forenames>Nick</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>Piecewise Stationary Modeling of Random Processes Over Graphs With an
  Application to Traffic Prediction</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stationarity is a key assumption in many statistical models for random
processes. With recent developments in the field of graph signal processing,
the conventional notion of wide-sense stationarity has been extended to random
processes defined on the vertices of graphs. It has been shown that well-known
spectral graph kernel methods assume that the underlying random process over a
graph is stationary. While many approaches have been proposed, both in machine
learning and signal processing literature, to model stationary random processes
over graphs, they are too restrictive to characterize real-world datasets as
most of them are non-stationary processes. In this paper, to well-characterize
a non-stationary process over graph, we propose a novel model and a
computationally efficient algorithm that partitions a large graph into disjoint
clusters such that the process is stationary on each of the clusters but
independent across clusters. We evaluate our model for traffic prediction on a
large-scale dataset of fine-grained highway travel times in the Dallas--Fort
Worth area. The accuracy of our method is very close to the state-of-the-art
graph based deep learning methods while the computational complexity of our
model is substantially smaller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.06974</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.06974</id><created>2017-11-19</created><authors><author><keyname>Waks</keyname><forenames>Zeev</forenames></author><author><keyname>Mazeh</keyname><forenames>Itzik</forenames></author><author><keyname>Admati</keyname><forenames>Chen</forenames></author><author><keyname>Afek</keyname><forenames>Michal</forenames></author><author><keyname>Dolan</keyname><forenames>Yonatan</forenames></author><author><keyname>Wagner</keyname><forenames>Avishai</forenames></author></authors><title>Wrist Sensor Fusion Enables Robust Gait Quantification Across Walking
  Scenarios</title><categories>eess.SP</categories><comments>NIPS 2017 Machine Learning for Health Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantifying step abundance via single wrist-worn accelerometers is a common
approach for encouraging active lifestyle and tracking disease status.
Nonetheless, step counting accuracy can be hampered by fluctuations in walking
pace or demeanor. Here, we assess whether the use of various sensor fusion
techniques, each combining bilateral wrist accelerometer data, may increase
step count robustness. By collecting data from 27 healthy subjects, we find
that high-level step fusion leads to substantially improved accuracy across
diverse walking scenarios. Gait cycle analysis illustrates that wrist devices
can recurrently detect steps proximal to toe-off events. Collectively, our
study suggests that dual-wrist sensor fusion may enable robust gait
quantification in free-living environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07128</identifier>
 <datestamp>2018-02-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07128</id><created>2017-11-19</created><updated>2018-02-14</updated><authors><author><keyname>Zhang</keyname><forenames>Yundong</forenames></author><author><keyname>Suda</keyname><forenames>Naveen</forenames></author><author><keyname>Lai</keyname><forenames>Liangzhen</forenames></author><author><keyname>Chandra</keyname><forenames>Vikas</forenames></author></authors><title>Hello Edge: Keyword Spotting on Microcontrollers</title><categories>cs.SD cs.CL cs.LG cs.NE eess.AS</categories><comments>Code available in github at
  https://github.com/ARM-software/ML-KWS-for-MCU</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Keyword spotting (KWS) is a critical component for enabling speech based user
interactions on smart devices. It requires real-time response and high accuracy
for good user experience. Recently, neural networks have become an attractive
choice for KWS architecture because of their superior accuracy compared to
traditional speech processing algorithms. Due to its always-on nature, KWS
application has highly constrained power budget and typically runs on tiny
microcontrollers with limited memory and compute capability. The design of
neural network architecture for KWS must consider these constraints. In this
work, we perform neural network architecture evaluation and exploration for
running KWS on resource-constrained microcontrollers. We train various neural
network architectures for keyword spotting published in literature to compare
their accuracy and memory/compute requirements. We show that it is possible to
optimize these neural network architectures to fit within the memory and
compute constraints of microcontrollers without sacrificing accuracy. We
further explore the depthwise separable convolutional neural network (DS-CNN)
and compare it against other neural network architectures. DS-CNN achieves an
accuracy of 95.4%, which is ~10% higher than the DNN model with similar number
of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07217</identifier>
 <datestamp>2018-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07217</id><created>2017-11-20</created><updated>2018-01-30</updated><authors><author><keyname>Emara</keyname><forenames>Mustafa</forenames></author><author><keyname>Filippou</keyname><forenames>Miltiades C.</forenames></author><author><keyname>Sabella</keyname><forenames>Dario</forenames></author></authors><title>MEC-aware Cell Association for 5G Heterogeneous Networks</title><categories>eess.SP</categories><comments>2018 IEEE Wireless Communications and Networking Conference Workshops
  (WCNCW): The First Workshop on Control and management of Vertical slicing
  including the Edge and Fog Systems (COMPASS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need for efficient use of network resources is continuously increasing
with the grow of traffic demand, however, current mobile systems have been
planned and deployed so far with the mere aim of enhancing radio coverage and
capacity. Unfortunately, this approach is not sustainable anymore, as 5G
communication systems will have to cope with huge amounts of traffic,
heterogeneous in terms of latency among other Qualityof- Service (QoS)
requirements. Moreover, the advent of Multiaccess Edge Computing (MEC) brings
up the need to more efficiently plan and dimension network deployment by means
of jointly exploiting the available radio and processing resources. From this
standpoint, advanced cell association of users can play a key role for 5G
systems. Focusing on a Heterogeneous Network (HetNet), this paper proposes a
comparison between state-of-the-art (i.e., radio-only) and MEC-aware cell
association rules, taking the scenario of task offloading in the Uplink (UL) as
an example. Numerical evaluations show that the proposed cell association rule
provides nearly 60% latency reduction, as compared to its standard,
radio-exclusive counterpart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07223</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07223</id><created>2017-11-20</created><authors><author><keyname>Emara</keyname><forenames>Mustafa</forenames></author><author><keyname>Rosson</keyname><forenames>Patrick</forenames></author><author><keyname>Roth</keyname><forenames>Kilian</forenames></author><author><keyname>Dassonville</keyname><forenames>David</forenames></author></authors><title>A Full Duplex Transceiver with Reduced Hardware Complexity</title><categories>eess.SP</categories><comments>Accepted at the 2017 IEEE Global Communications Conference: Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For future wireless communication systems, full duplex is seen as a possible
solution to the ever present spectrum shortage. The key aspect to enable
In-Band Full Duplex (IBFD) is sufficient cancellation of the unavoidable
Self-Interference (SI). In this work we evaluate the performance of a low
complexity IBFD transceiver, including the required analog and digital
interference cancellation techniques. The Radio Frequency Self- Interference
Canceler (RFSIC) is based on the isolation of a circulator in combination with
a vector modulator regenerating the interference signal, to destructively
combine it with the received signal. On the digital side, a Digital
Self-Interference Cancellation (DSIC) algorithm based on non-linear adaptive
filtering is used. With the simplified analog front-end of a Software Defined
Radio (SDR) platform, SI cancellation of 90 dB is achieved with the presence of
a received signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07274</identifier>
 <datestamp>2018-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07274</id><created>2017-11-20</created><updated>2018-06-20</updated><authors><author><keyname>Chiu</keyname><forenames>Chung-Cheng</forenames></author><author><keyname>Tripathi</keyname><forenames>Anshuman</forenames></author><author><keyname>Chou</keyname><forenames>Katherine</forenames></author><author><keyname>Co</keyname><forenames>Chris</forenames></author><author><keyname>Jaitly</keyname><forenames>Navdeep</forenames></author><author><keyname>Jaunzeikare</keyname><forenames>Diana</forenames></author><author><keyname>Kannan</keyname><forenames>Anjuli</forenames></author><author><keyname>Nguyen</keyname><forenames>Patrick</forenames></author><author><keyname>Sak</keyname><forenames>Hasim</forenames></author><author><keyname>Sankar</keyname><forenames>Ananth</forenames></author><author><keyname>Tansuwan</keyname><forenames>Justin</forenames></author><author><keyname>Wan</keyname><forenames>Nathan</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Zhang</keyname><forenames>Xuedong</forenames></author></authors><title>Speech recognition for medical conversations</title><categories>cs.CL cs.SD eess.AS stat.ML</categories><comments>Interspeech 2018 camera ready</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we explored building automatic speech recognition models for
transcribing doctor patient conversation. We collected a large scale dataset of
clinical conversations ($14,000$ hr), designed the task to represent the real
word scenario, and explored several alignment approaches to iteratively improve
data quality. We explored both CTC and LAS systems for building speech
recognition models. The LAS was more resilient to noisy data and CTC required
more data clean up. A detailed analysis is provided for understanding the
performance for clinical tasks. Our analysis showed the speech recognition
models performed well on important medical utterances, while errors occurred in
causal conversations. Overall we believe the resulting models can provide
reasonable quality in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07345</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07345</id><created>2017-11-20</created><authors><author><keyname>Xie</keyname><forenames>Xuan</forenames></author><author><keyname>Feng</keyname><forenames>Hui</forenames></author><author><keyname>Jia</keyname><forenames>Junlian</forenames></author><author><keyname>Hu</keyname><forenames>Bo</forenames></author></authors><title>Design of Sampling Set for Bandlimited Graph Signal Estimation</title><categories>eess.SP</categories><comments>GlobalSIP 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is of particular interest to reconstruct or estimate bandlimited graph
signals, which are smoothly varying signals defined over graphs, from partial
noisy measurements. However, choosing an optimal subset of nodes to sample is
NP-hard. We formularize the problem as the experimental design of a linear
regression model if we allow multiple measurements on a single node. By
relaxing it to a convex optimization problem, we get the proportion of sample
for each node given the budget of total sample size. Then, we use a
probabilistic quantization to get the number of each node to be sampled.
Moreover, we analyze how the sample size influences whether our object function
is well-defined by perturbation analysis. Finally, we demonstrate the
performance of the proposed approach through various numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07421</identifier>
 <datestamp>2019-03-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07421</id><created>2017-11-20</created><updated>2018-03-12</updated><authors><author><keyname>Raman</keyname><forenames>Akhila</forenames></author></authors><title>On the Signal Processing Operations in LIGO signals</title><categories>eess.SP astro-ph.IM</categories><comments>Corrected typographical errors, updated names, references and
  acknowledgement section. Added a subsection on an improved whitening
  procedure</comments><journal-ref>2018 IEEE Global Conference on Signal and Information Processing
  (GlobalSIP). https://ieeexplore.ieee.org/document/8646464</journal-ref><doi>10.1109/GlobalSIP.2018.8646464</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article analyzes the data for the five gravitational wave (GW) events
detected in Hanford(H1), Livingston(L1) and Virgo(V1) detectors by the LIGO
collaboration. It is shown that GW170814, GW170817, GW151226 and GW170104 are
very weak signals whose amplitude does not rise significantly during the GW
event, and they are indistinguishable from non-stationary detector noise. LIGO
software implements cross-correlation funcion(CCF) of H1/L1 signals with the
template reference signal, in frequency domain, in a matched filter, using 32
second windows. It is shown that this matched filter misfires with high SNR/CCF
peaks, even for very low-amplitude, short bursts of sine wave signals and
additive white gaussian noise(AWGN), all the time. It is shown that this
erratic behaviour of the matched filter, is due to the error in signal
processing operations, such as lack of cyclic prefix necessary to account for
circular convolution. It is also shown that normalized CCF method implemented
in time domain using short windows, does not have false CCF peaks for sine wave
and noise bursts. It is shown that the normalized CCF for GW151226 and
GW170104, when correlating H1/L1 and template, is indistinguishable from
correlating detector noise and the template. It is also shown that the
normalized CCF for GW151226 and GW170104, when correlating H1/L1 and template,
is indistinguishable from correlating H1/L1 and bogus chirp templates which are
frequency modulated(FM) waveforms which differ significantly from ideal
templates. Similar results are shown with LIGO matched filter, which misfires
with high Signal to Noise Ratio(SNR) for bogus chirp templates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07551</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07551</id><created>2017-11-02</created><authors><author><keyname>Gong</keyname><forenames>Rong</forenames></author><author><keyname>Serra</keyname><forenames>Xavier</forenames></author></authors><title>Identification of potential Music Information Retrieval technologies for
  computer-aided jingju singing training</title><categories>cs.IR cs.SD eess.AS</categories><comments>Chinese traditional music technology session - China conference on
  sound and music technology 2017, Suzhou, China</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Music Information Retrieval (MIR) technologies have been proven useful in
assisting western classical singing training. Jingju (also known as Beijing or
Peking opera) singing is different from western singing in terms of most of the
perceptual dimensions, and the trainees are taught by using mouth/heart method.
In this paper, we first present the training method used in the professional
jingju training classroom scenario and show the potential benefits of
introducing the MIR technologies into the training process. The main part of
this paper dedicates to identify the potential MIR technologies for jingju
singing training. To this intent, we answer the question: how the jingju
singing tutors and trainees value the importance of each jingju musical
dimension-intonation, rhythm, loudness, tone quality and pronunciation? This is
done by (i) classifying the classroom singing practices, tutor's verbal
feedbacks into these 5 dimensions, (ii) surveying the trainees. Then, with the
help of the music signal analysis, a finer inspection on the classroom practice
recording examples reveals the detailed elements in the training process.
Finally, based on the above analysis, several potential MIR technologies are
identified and would be useful for the jingju singing training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07557</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07557</id><created>2017-11-20</created><updated>2017-11-23</updated><authors><author><keyname>Badawy</keyname><forenames>Reham</forenames></author><author><keyname>Raykov</keyname><forenames>Yordan P.</forenames></author><author><keyname>Little</keyname><forenames>Max A.</forenames></author></authors><title>A unified algorithm framework for quality control of sensor data for
  behavioural clinimetric testing</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of smartphone and wearable sensing technology for objective,
non-invasive and remote clinimetric testing of symptoms has considerable
potential. However, the clinimetric accuracy achievable with such technology is
highly reliant on separating the useful from irrelevant or confounded sensor
data. Monitoring patient symptoms using digital sensors outside of controlled,
clinical lab settings creates a variety of practical challenges, such as
unavoidable and unexpected user behaviours. These behaviours often violate the
assumptions of clinimetric testing protocols, where these protocols are
designed to probe for specific symptoms. Such violations are frequent outside
the lab, and can affect the accuracy of the subsequent data analysis and
scientific conclusions. At the same time, curating sensor data by hand after
the collection process is inherently subjective, laborious and error-prone. To
address these problems, we report on a unified algorithmic framework for
automated sensor data quality control, which can identify those parts of the
sensor data which are sufficiently reliable for further analysis. Algorithms
which are special cases of this framework for different sensor data types (e.g.
accelerometer, digital audio) detect the extent to which the sensor data
adheres to the assumptions of the test protocol for a variety of clinimetric
tests. The approach is general enough to be applied to a large set of
clinimetric tests and we demonstrate its performance on walking, balance and
voice smartphone-based tests, designed to monitor the symptoms of Parkinson's
disease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07594</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07594</id><created>2017-11-20</created><authors><author><keyname>Guedes</keyname><forenames>Priscila F. S.</forenames></author><author><keyname>Peixoto</keyname><forenames>M. L. C.</forenames></author><author><keyname>Barbosa</keyname><forenames>A. M.</forenames></author><author><keyname>Martins</keyname><forenames>S. A. M.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>E. G.</forenames></author></authors><title>The Lower Bound Error for polynomial NARMAX using an Arbitrary Number of
  Natural Interval Extensions</title><categories>eess.SP</categories><comments>DINCON 2017 - Conferencia Brasileira de Dinamica, Controle e
  Aplicacoes. Sao Jose do Rio Preto. Brazil. 7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The polynomial NARMAX (Nonlinear AutoRegressive Moving Average model with
eXogenous input) is a model that represents the dynamics of physical systems.
This polynomial contains information from the past of the inputs and outputs of
the process, that is, it is a recursive model. In digital computers this
generates the propagation of the rounding error. Our procedure is based on the
estimation of the maximum value of the lower bound error considering an
arbitrary number of pseudo-orbits produced from different natural interval
extensions, and a posterior Lyapunov exponent calculation. We applied
successfully our technique for two identified models of the systems: sine map
and Duffing-Ueda oscillator
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07668</identifier>
 <datestamp>2019-07-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07668</id><created>2017-11-21</created><updated>2019-07-27</updated><authors><author><keyname>Chandhar</keyname><forenames>Prabhu</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Massive MIMO for Drone Communications: Case Studies and Future
  Directions</title><categories>cs.IT eess.SP math.IT</categories><comments>To appear in IEEE Access</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAVs), also known as drones, are proliferating.
Applications, such as surveillance, disaster management, and drone racing,
place high requirements on the communication with the drones in terms of
throughput, reliability, and latency. The existing wireless technologies,
notably Wi-Fi, that are currently used for drone connectivity are limited to
short ranges and low-mobility situations. New, scalable technology is needed to
meet future demands on long connectivity ranges, support for fast-moving
drones, and the possibility to simultaneously communicate with entire swarms of
drones. Massive multiple-input and multiple-output (MIMO), the main technology
component of emerging 5G standards, has the potential to meet these
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07682</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07682</id><created>2017-11-21</created><authors><author><keyname>Brunner</keyname><forenames>Gino</forenames></author><author><keyname>Wang</keyname><forenames>Yuyi</forenames></author><author><keyname>Wattenhofer</keyname><forenames>Roger</forenames></author><author><keyname>Wiesendanger</keyname><forenames>Jonas</forenames></author></authors><title>JamBot: Music Theory Aware Chord Based Generation of Polyphonic Music
  with LSTMs</title><categories>cs.SD cs.AI cs.IT cs.LG eess.AS math.IT stat.ML</categories><comments>Paper presented at the 29th International Conference on Tools with
  Artificial Intelligence, ICTAI 2017, Boston, MA, USA</comments><acm-class>I.2.1; I.2.4; I.2.6; H.5.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel approach for the generation of polyphonic music based on
LSTMs. We generate music in two steps. First, a chord LSTM predicts a chord
progression based on a chord embedding. A second LSTM then generates polyphonic
music from the predicted chord progression. The generated music sounds pleasing
and harmonic, with only few dissonant notes. It has clear long-term structure
that is similar to what a musician would play during a jam session. We show
that our approach is sensible from a music theory perspective by evaluating the
learned chord embeddings. Surprisingly, our simple model managed to extract the
circle of fifths, an important tool in music theory, from the dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07757</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07757</id><created>2017-11-21</created><authors><author><keyname>Silva</keyname><forenames>Igor C.</forenames></author><author><keyname>Silva</keyname><forenames>Gabriel H. A.</forenames></author><author><keyname>Martins</keyname><forenames>Samir A. M.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>Erivelton G.</forenames></author></authors><title>Incorporating Numerical Uncertainties for Validation of Nonlinear Models</title><categories>eess.SP</categories><comments>DINCON 2017 - Conferencia Brasileira de Dinamica, Controle e
  Aplicacoes - Sao Jose do Rio Preto - Brazil. 7 pages. In Portuguese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a model validation method that incorporates error due to
numerical procedures. Two identified models for Sine Map and Duffing-Ueda
Circuit systems have been investigated. The indexes RMSE and MAPE have been
applied. We have shown that after some few iterates, it is possible to notice
some significative difference between index provided in the literature. This
difference has been computed in around 34%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07791</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07791</id><created>2017-11-21</created><authors><author><keyname>An</keyname><forenames>Inkyu</forenames></author><author><keyname>Son</keyname><forenames>Myungbae</forenames></author><author><keyname>Manocha</keyname><forenames>Dinesh</forenames></author><author><keyname>Yoon</keyname><forenames>Sung-eui</forenames></author></authors><title>Reflection-Aware Sound Source Localization</title><categories>cs.SD cs.RO eess.AS</categories><comments>Submitted to ICRA 2018. The working video is available at
  (https://youtu.be/TkQ36lMEC-M)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel, reflection-aware method for 3D sound localization in
indoor environments. Unlike prior approaches, which are mainly based on
continuous sound signals from a stationary source, our formulation is designed
to localize the position instantaneously from signals within a single frame. We
consider direct sound and indirect sound signals that reach the microphones
after reflecting off surfaces such as ceilings or walls. We then generate and
trace direct and reflected acoustic paths using inverse acoustic ray tracing
and utilize these paths with Monte Carlo localization to estimate a 3D sound
source position. We have implemented our method on a robot with a cube-shaped
microphone array and tested it against different settings with continuous and
intermittent sound signals with a stationary or a mobile source. Across
different settings, our approach can localize the sound with an average
distance error of 0.8m tested in a room of 7m by 7m area with 3m height,
including a mobile and non-line-of-sight sound source. We also reveal that the
modeling of indirect rays increases the localization accuracy by 40% compared
to only using direct acoustic rays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07845</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07845</id><created>2017-11-20</created><authors><author><keyname>Holland</keyname><forenames>Naomi</forenames></author><author><keyname>Stuart</keyname><forenames>Dustin</forenames></author><author><keyname>Barter</keyname><forenames>Oliver</forenames></author><author><keyname>Kuhn</keyname><forenames>Axel</forenames></author></authors><title>Efficient and fast algorithms to generate holograms for optical tweezers</title><categories>eess.IV</categories><comments>9 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:1409.1841</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss and compare three algorithms for generating holograms: simple
rounding, Floyd-Steinberg error diffusion dithering, and mixed region amplitude
freedom (MRAF). The methods are optimised for producing large arrays of tightly
focused optical tweezers for trapping particles. The algorithms are compared in
terms of their speed, efficiency, and accuracy, for periodic arrangements of
traps; an arrangement of particular interest in the field of quantum computing.
We simulate the image formation using each of a binary amplitude modulating
digital mirror device (DMD) and a phase modulating spatial light modulator
(PSLM) as the display element. While a DMD allows for fast frame rates, the
slower PSLM is more efficient and provides higher accuracy with a
quasi-continuous variation of phase. We discuss the relative merits of each
algorithm for use with both a DMD and a PSLM, allowing one to choose the ideal
approach depending on the circumstances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07911</identifier>
 <datestamp>2019-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07911</id><created>2017-11-21</created><updated>2018-02-26</updated><authors><author><keyname>Li</keyname><forenames>Xiaofei</forenames></author><author><keyname>Girin</keyname><forenames>Laurent</forenames></author><author><keyname>Gannot</keyname><forenames>Sharon</forenames></author><author><keyname>Horaud</keyname><forenames>Radu</forenames></author></authors><title>Multichannel Speech Separation and Enhancement Using the Convolutive
  Transfer Function</title><categories>cs.SD eess.AS</categories><comments>Submitted to IEEE/ACM Transactions on Audio, Speech and Language
  Processing</comments><journal-ref>IEEE/ACM Transactions on Audio Speech and Language Processing
  27(3), 645-659, 2019</journal-ref><doi>10.1109/TASLP.2019.2892412</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of speech separation and enhancement from
multichannel convolutive and noisy mixtures, \emph{assuming known mixing
filters}. We propose to perform the speech separation and enhancement task in
the short-time Fourier transform domain, using the convolutive transfer
function (CTF) approximation. Compared to time-domain filters, CTF has much
less taps, consequently it has less near-common zeros among channels and less
computational complexity. The work proposes three speech-source recovery
methods, namely: i) the multichannel inverse filtering method, i.e. the
multiple input/output inverse theorem (MINT), is exploited in the CTF domain,
and for the multi-source case, ii) a beamforming-like multichannel inverse
filtering method applying single source MINT and using power minimization,
which is suitable whenever the source CTFs are not all known, and iii) a
constrained Lasso method, where the sources are recovered by minimizing the
$\ell_1$-norm to impose their spectral sparsity, with the constraint that the
$\ell_2$-norm fitting cost, between the microphone signals and the mixing model
involving the unknown source signals, is less than a tolerance. The noise can
be reduced by setting a tolerance onto the noise power. Experiments under
various acoustic conditions are carried out to evaluate the three proposed
methods. The comparison between them as well as with the baseline methods is
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.07925</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.07925</id><created>2017-11-21</created><authors><author><keyname>Huang</keyname><forenames>Kejun</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nicholas D.</forenames></author></authors><title>Kullback-Leibler Principal Component for Tensors is not NP-hard</title><categories>eess.SP cs.IT math.IT math.OC math.PR stat.ML</categories><comments>Asilomar 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of nonnegative rank-one approximation of a nonnegative
tensor, and show that the globally optimal solution that minimizes the
generalized Kullback-Leibler divergence can be efficiently obtained, i.e., it
is not NP-hard. This result works for arbitrary nonnegative tensors with an
arbitrary number of modes (including two, i.e., matrices). We derive a
closed-form expression for the KL principal component, which is easy to compute
and has an intuitive probabilistic interpretation. For generalized KL
approximation with higher ranks, the problem is for the first time shown to be
equivalent to multinomial latent variable modeling, and an iterative algorithm
is derived that resembles the expectation-maximization algorithm. On the Iris
dataset, we showcase how the derived results help us learn the model in an
\emph{unsupervised} manner, and obtain strikingly close performance to that
from supervised methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08010</identifier>
 <datestamp>2019-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08010</id><created>2017-11-21</created><updated>2019-04-30</updated><authors><author><keyname>Meng</keyname><forenames>Zhong</forenames></author><author><keyname>Chen</keyname><forenames>Zhuo</forenames></author><author><keyname>Mazalov</keyname><forenames>Vadim</forenames></author><author><keyname>Li</keyname><forenames>Jinyu</forenames></author><author><keyname>Gong</keyname><forenames>Yifan</forenames></author></authors><title>Unsupervised Adaptation with Domain Separation Networks for Robust
  Speech Recognition</title><categories>cs.CL cs.AI cs.SD eess.AS</categories><comments>8 pages, 1 figure, ASRU 2017</comments><journal-ref>2017 IEEE Automatic Speech Recognition and Understanding Workshop
  (ASRU), Okinawa, 2017, pp. 214-221</journal-ref><doi>10.1109/ASRU.2017.8268938</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unsupervised domain adaptation of speech signal aims at adapting a
well-trained source-domain acoustic model to the unlabeled data from target
domain. This can be achieved by adversarial training of deep neural network
(DNN) acoustic models to learn an intermediate deep representation that is both
senone-discriminative and domain-invariant. Specifically, the DNN is trained to
jointly optimize the primary task of senone classification and the secondary
task of domain classification with adversarial objective functions. In this
work, instead of only focusing on learning a domain-invariant feature (i.e. the
shared component between domains), we also characterize the difference between
the source and target domain distributions by explicitly modeling the private
component of each domain through a private component extractor DNN. The private
component is trained to be orthogonal with the shared component and thus
implicitly increases the degree of domain-invariance of the shared component. A
reconstructor DNN is used to reconstruct the original speech feature from the
private and shared components as a regularization. This domain separation
framework is applied to the unsupervised environment adaptation task and
achieved 11.08% relative WER reduction from the gradient reversal layer
training, a representative adversarial training method, for automatic speech
recognition on CHiME-3 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08016</identifier>
 <datestamp>2018-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08016</id><created>2017-11-21</created><authors><author><keyname>Meng</keyname><forenames>Zhong</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinji</forenames></author><author><keyname>Hershey</keyname><forenames>John R.</forenames></author><author><keyname>Erdogan</keyname><forenames>Hakan</forenames></author></authors><title>Deep Long Short-Term Memory Adaptive Beamforming Networks For
  Multichannel Robust Speech Recognition</title><categories>eess.AS cs.CL cs.SD</categories><comments>in 2017 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)</comments><journal-ref>2017 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), New Orleans, LA, 2017, pp. 271-275</journal-ref><doi>10.1109/ICASSP.2017.7952160</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Far-field speech recognition in noisy and reverberant conditions remains a
challenging problem despite recent deep learning breakthroughs. This problem is
commonly addressed by acquiring a speech signal from multiple microphones and
performing beamforming over them. In this paper, we propose to use a recurrent
neural network with long short-term memory (LSTM) architecture to adaptively
estimate real-time beamforming filter coefficients to cope with non-stationary
environmental noise and dynamic nature of source and microphones positions
which results in a set of timevarying room impulse responses. The LSTM adaptive
beamformer is jointly trained with a deep LSTM acoustic model to predict senone
labels. Further, we use hidden units in the deep LSTM acoustic model to assist
in predicting the beamforming filter coefficients. The proposed system achieves
7.97% absolute gain over baseline systems with no beamforming on CHiME-3 real
evaluation set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08058</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08058</id><created>2017-11-21</created><authors><author><keyname>AbdulKader</keyname><forenames>Ahmad</forenames></author><author><keyname>Nassar</keyname><forenames>Kareem</forenames></author><author><keyname>Mahmoud</keyname><forenames>Mohamed</forenames></author><author><keyname>Galvez</keyname><forenames>Daniel</forenames></author><author><keyname>Patil</keyname><forenames>Chetan</forenames></author></authors><title>Multiple-Instance, Cascaded Classification for Keyword Spotting in
  Narrow-Band Audio</title><categories>cs.LG cs.CL cs.SD eess.AS</categories><comments>To be published in the proceedings of NIPS 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose using cascaded classifiers for a keyword spotting (KWS) task on
narrow-band (NB), 8kHz audio acquired in non-IID environments --- a more
challenging task than most state-of-the-art KWS systems face. We present a
model that incorporates Deep Neural Networks (DNNs), cascading,
multiple-feature representations, and multiple-instance learning. The cascaded
classifiers handle the task's class imbalance and reduce power consumption on
computationally-constrained devices via early termination. The KWS system
achieves a false negative rate of 6% at an hourly false positive rate of 0.75
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08188</identifier>
 <datestamp>2018-12-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08188</id><created>2017-11-22</created><updated>2018-12-21</updated><authors><author><keyname>Santos</keyname><forenames>Irene</forenames></author><author><keyname>Murillo-Fuentes</keyname><forenames>Juan Jos&#xe9;</forenames></author><author><keyname>Arias-de-Reyna</keyname><forenames>Eva</forenames></author><author><keyname>Olmos</keyname><forenames>Pablo M.</forenames></author></authors><title>Turbo EP-based Equalization: a Filter-Type Implementation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript has been submitted to Transactions on Communications on
September 7, 2017; revised on January 10, 2018 and March 27, 2018; and accepted
on April 25, 2018
  We propose a novel filter-type equalizer to improve the solution of the
linear minimum-mean squared-error (LMMSE) turbo equalizer, with computational
complexity constrained to be quadratic in the filter length. When high-order
modulations and/or large memory channels are used the optimal BCJR equalizer is
unavailable, due to its computational complexity. In this scenario, the
filter-type LMMSE turbo equalization exhibits a good performance compared to
other approximations. In this paper, we show that this solution can be
significantly improved by using expectation propagation (EP) in the estimation
of the a posteriori probabilities. First, it yields a more accurate estimation
of the extrinsic distribution to be sent to the channel decoder. Second,
compared to other solutions based on EP the computational complexity of the
proposed solution is constrained to be quadratic in the length of the finite
impulse response (FIR). In addition, we review previous EP-based turbo
equalization implementations. Instead of considering default uniform priors we
exploit the outputs of the decoder. Some simulation results are included to
show that this new EP-based filter remarkably outperforms the turbo approach of
previous versions of the EP algorithm and also improves the LMMSE solution,
with and without turbo equalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08272</identifier>
 <datestamp>2019-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08272</id><created>2017-11-21</created><updated>2019-12-17</updated><authors><author><keyname>Singh</keyname><forenames>Kamal</forenames></author></authors><title>Optimal Power Control in Decentralized Gaussian Multiple Access Channels</title><categories>eess.SP cs.IT math.IT</categories><comments>4 pages, 4 figures, accepted for publication to IEEE Communication
  letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the decentralized power optimization problem for Gaussian
fast-fading multiple access channel (MAC) so that the average sum-throughput is
maximized. In our MAC setup, each transmitter has access to only its own fading
coefficient or channel state information (CSI) while the receiver has full CSI
available at all instants. Unlike centralized MAC (full CSIT MAC) where the
optimal powers are known explicitly, the analytical solution for optimal
decentralized powers does not seem feasible. In this letter, we specialize
alternating-maximization (AM) method for numerically computing the optimal
powers and ergodic capacity of the decentralized MAC for general fading
statistics and average power constraints. For illustration, we apply our AM
method to compute the capacity of MAC channels with fading distributions such
as Rayleigh, Rician etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08359</identifier>
 <datestamp>2017-11-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08359</id><created>2017-11-22</created><authors><author><keyname>Fruehwirt</keyname><forenames>Wolfgang</forenames></author><author><keyname>Gerstgrasser</keyname><forenames>Matthias</forenames></author><author><keyname>Zhang</keyname><forenames>Pengfei</forenames></author><author><keyname>Weydemann</keyname><forenames>Leonard</forenames></author><author><keyname>Waser</keyname><forenames>Markus</forenames></author><author><keyname>Schmidt</keyname><forenames>Reinhold</forenames></author><author><keyname>Benke</keyname><forenames>Thomas</forenames></author><author><keyname>Dal-Bianco</keyname><forenames>Peter</forenames></author><author><keyname>Ransmayr</keyname><forenames>Gerhard</forenames></author><author><keyname>Grossegger</keyname><forenames>Dieter</forenames></author><author><keyname>Garn</keyname><forenames>Heinrich</forenames></author><author><keyname>Peters</keyname><forenames>Gareth W.</forenames></author><author><keyname>Roberts</keyname><forenames>Stephen</forenames></author><author><keyname>Dorffner</keyname><forenames>Georg</forenames></author></authors><title>Riemannian tangent space mapping and elastic net regularization for
  cost-effective EEG markers of brain atrophy in Alzheimer's disease</title><categories>stat.ML eess.SP q-bio.NC</categories><comments>Presented at NIPS 2017 Workshop on Machine Learning for Health</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The diagnosis of Alzheimer's disease (AD) in routine clinical practice is
most commonly based on subjective clinical interpretations. Quantitative
electroencephalography (QEEG) measures have been shown to reflect
neurodegenerative processes in AD and might qualify as affordable and thereby
widely available markers to facilitate the objectivization of AD assessment.
Here, we present a novel framework combining Riemannian tangent space mapping
and elastic net regression for the development of brain atrophy markers. While
most AD QEEG studies are based on small sample sizes and psychological test
scores as outcome measures, here we train and test our models using data of one
of the largest prospective EEG AD trials ever conducted, including MRI
biomarkers of brain atrophy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08363</identifier>
 <datestamp>2018-05-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08363</id><created>2017-11-22</created><updated>2018-04-29</updated><authors><author><keyname>Yang</keyname><forenames>Guang</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author><author><keyname>Xiao</keyname><forenames>Ming</forenames></author></authors><title>Traffic Allocation for Low-Latency Multi-Hop Networks with Buffers</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For millimeter-wave (mm-wave) buffer-aided tandem networks consisting of
relay nodes and multiple channels per hop, we consider two traffic allocation
schemes, namely local allocation and global allocation, and investigate the
end-to-end latency of a file transfer. We formulate the problem for generic
multi-hop queuing systems and subsequently derive closed-form expressions of
the end-to-end latency. We quantify the advantages of the global allocation
scheme relative to its local allocation counterpart, and we conduct an
asymptotic analysis on the performance gain when the number of channels in each
hop increases to infinity. The traffic allocations and the analytical delay
performance are validated through simulations. Furthermore, taking a specific
two-hop mm-wave network as an example, we derive lower bounds on the average
end-to-end latency, where Nakagami-$m$ fading is considered. Numerical results
demonstrate that, compared to the local allocation scheme, the advantage of
global allocation grows as the number of relay nodes increases, at the expense
of higher complexity that linearly increases with the number of relay nodes. It
is also demonstrated that a proper deployment of relay nodes in a linear
mm-wave network plays an important role in reducing the average end-to-end
latency, and the average latency decays as the mm-wave channels become more
deterministic. These findings provide insights for designing multi-hop mm-wave
networks with low end-to-end latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08420</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08420</id><created>2017-11-22</created><authors><author><keyname>Liu</keyname><forenames>Yixian</forenames></author><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Data-Driven Nonparametric Existence and Association Problems</title><categories>eess.SP</categories><comments>12 pages, 10 figures</comments><doi>10.1109/TSP.2018.2875392</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate two closely related nonparametric hypothesis testing problems.
In the first problem (i.e., the existence problem), we test whether a testing
data stream is generated by one of a set of composite distributions. In the
second problem (i.e., the association problem), we test which one of the
multiple distributions generates a testing data stream. We assume that some
distributions in the set are unknown with only training sequences generated by
the corresponding distributions are available. For both problems, we construct
the generalized likelihood (GL) tests, and characterize the error exponents of
the maximum error probabilities. For the existence problem, we show that the
error exponent is mainly captured by the Chernoff information between the set
of composite distributions and alternative distributions. For the association
problem, we show that the error exponent is captured by the minimum Chernoff
information between each pair of distributions as well as the KL divergences
between the approximated distributions (via training sequences) and the true
distributions. We also show that the ratio between the lengths of training and
testing sequences plays an important role in determining the error decay rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08532</identifier>
 <datestamp>2019-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08532</id><created>2017-11-22</created><updated>2019-01-19</updated><authors><author><keyname>Lodhi</keyname><forenames>Muhammad Asad</forenames></author><author><keyname>Bajwa</keyname><forenames>Waheed U.</forenames></author></authors><title>Detection Theory for Union of Subspaces</title><categories>eess.SP</categories><comments>16 pages, 1 table, 15 figures</comments><journal-ref>Published in IEEE Trans. Signal Processing, vol. 66, no. 24, pp.
  6347-6362, Dec. 2018</journal-ref><doi>10.1109/TSP.2018.2875897</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focus of this paper is on detection theory for union of subspaces (UoS).
To this end, generalized likelihood ratio tests (GLRTs) are presented for
detection of signals conforming to the UoS model and detection of the
corresponding &quot;active&quot; subspace. One of the main contributions of this paper is
bounds on the performances of these GLRTs in terms of geometry of subspaces
under various assumptions on the observation noise. The insights obtained
through geometrical interpretation of the GLRTs are also validated through
extensive numerical experiments on both synthetic and real-world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08597</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08597</id><created>2017-11-23</created><authors><author><keyname>Wei</keyname><forenames>Fan</forenames></author><author><keyname>Chen</keyname><forenames>Wen</forenames></author><author><keyname>Wu</keyname><forenames>Yongpeng</forenames></author><author><keyname>Ma</keyname><forenames>Jun</forenames></author><author><keyname>Tsiftsis</keyname><forenames>Theodoros A.</forenames></author></authors><title>Message-Passing Receiver Design for Joint Channel Estimation and Data
  Decoding in Uplink Grant-Free SCMA Systems</title><categories>eess.SP</categories><comments>13 pages double colummn, 8 figures, submitted to TCOM</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The conventional grant-based network relies on the handshaking between base
station and active users to achieve dynamic multi-user scheduling, which may
cost large signaling overheads as well as system latency. To address those
problems, the grant-free receiver design is considered in this paper based on
sparse code multiple access (SCMA), one of the promising air interface
technologies for 5G wireless networks. With the presence of unknown multipath
fading, the proposed receiver blindly performs joint channel estimation and
data decoding without knowing the user activity in the network. Based on the
framework of belief propagation (BP), we formulate a messagepassing receiver
for uplink SCMA that performs joint estimation iteratively. However, the direct
application of BP for the multivariable detection problem is complex. Motivated
by the idea of approximate inference, we use expectation propagation to project
the intractable distributions into Gaussian families such that a linear
complexity decoder is obtained.Simulation results show that the proposed
receiver can detect active users in the network with a high accuracy and can
achieve an improved bit-error-rate performance compared with existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08600</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08600</id><created>2017-11-23</created><authors><author><keyname>Luo</keyname><forenames>Yin-Jyun</forenames></author><author><keyname>Chen</keyname><forenames>Ming-Tso</forenames></author><author><keyname>Chi</keyname><forenames>Tai-Shih</forenames></author><author><keyname>Su</keyname><forenames>Li</forenames></author></authors><title>Singing voice correction using canonical time warping</title><categories>eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Expressive singing voice correction is an appealing but challenging problem.
A robust time-warping algorithm which synchronizes two singing recordings can
provide a promising solution. We thereby propose to address the problem by
canonical time warping (CTW) which aligns amateur singing recordings to
professional ones. A new pitch contour is generated given the alignment
information, and a pitch-corrected singing is synthesized back through the
vocoder. The objective evaluation shows that CTW is robust against
pitch-shifting and time-stretching effects, and the subjective test
demonstrates that CTW prevails the other methods including DTW and the
commercial auto-tuning software. Finally, we demonstrate the applicability of
the proposed method in a practical, real-world scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08677</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08677</id><created>2017-11-23</created><authors><author><keyname>Ma</keyname><forenames>Wentao</forenames></author><author><keyname>Zheng</keyname><forenames>Dongqiao</forenames></author><author><keyname>Li</keyname><forenames>Yuanhao</forenames></author><author><keyname>Zhang</keyname><forenames>Zhiyu</forenames></author><author><keyname>Chen</keyname><forenames>Badong</forenames></author></authors><title>Bias-Compensated Normalized Maximum Correntropy Criterion Algorithm for
  System Identification with Noisy Input</title><categories>stat.ML eess.SP</categories><comments>14 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposed a bias-compensated normalized maximum correntropy
criterion (BCNMCC) algorithm charactered by its low steady-state misalignment
for system identification with noisy input in an impulsive output noise
environment. The normalized maximum correntropy criterion (NMCC) is derived
from a correntropy based cost function, which is rather robust with respect to
impulsive noises. To deal with the noisy input, we introduce a bias-compensated
vector (BCV) to the NMCC algorithm, and then an unbiasedness criterion and some
reasonable assumptions are used to compute the BCV. Taking advantage of the
BCV, the bias caused by the input noise can be effectively suppressed. System
identification simulation results demonstrate that the proposed BCNMCC
algorithm can outperform other related algorithms with noisy input especially
in an impulsive output noise environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08789</identifier>
 <datestamp>2018-06-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08789</id><created>2017-11-23</created><updated>2018-06-13</updated><authors><author><keyname>Gabbay</keyname><forenames>Aviv</forenames></author><author><keyname>Shamir</keyname><forenames>Asaph</forenames></author><author><keyname>Peleg</keyname><forenames>Shmuel</forenames></author></authors><title>Visual Speech Enhancement</title><categories>cs.CV cs.SD eess.AS</categories><comments>Accepted to Interspeech 2018. Supplementary video:
  https://www.youtube.com/watch?v=nyYarDGpcYA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When video is shot in noisy environment, the voice of a speaker seen in the
video can be enhanced using the visible mouth movements, reducing background
noise. While most existing methods use audio-only inputs, improved performance
is obtained with our visual speech enhancement, based on an audio-visual neural
network. We include in the training data videos to which we added the voice of
the target speaker as background noise. Since the audio input is not sufficient
to separate the voice of a speaker from his own voice, the trained model better
exploits the visual input and generalizes well to different noise types. The
proposed model outperforms prior audio visual methods on two public lipreading
datasets. It is also the first to be demonstrated on a dataset not designed for
lipreading, such as the weekly addresses of Barack Obama.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08812</identifier>
 <datestamp>2018-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08812</id><created>2017-11-23</created><authors><author><keyname>Kohonen</keyname><forenames>Jukka</forenames></author><author><keyname>Koivunen</keyname><forenames>Visa</forenames></author><author><keyname>Rajam&#xe4;ki</keyname><forenames>Robin</forenames></author></authors><title>Planar additive bases for rectangles</title><categories>math.NT eess.SP</categories><comments>20 pages</comments><msc-class>11B13</msc-class><journal-ref>Journal of Integer Sequences, Vol. 21 (2018), Article 18.9.8</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a generalization of additive bases into a planar setting. A planar
additive basis is a set of non-negative integer pairs whose vector sumset
covers a given rectangle. Such bases find applications in active sensor arrays
used in, for example, radar and medical imaging. The problem of minimizing the
basis cardinality has not been addressed before.
  We propose two algorithms for finding the minimal bases of small rectangles:
one in the setting where the basis elements can be anywhere in the rectangle,
and another in the restricted setting, where the elements are confined to the
lower left quadrant. We present numerical results from such searches, including
the minimal cardinalities for all rectangles up to $[0,11]\times[0,11]$, and up
to $[0,46]\times[0,46]$ in the restricted setting. We also prove asymptotic
upper and lower bounds on the minimal basis cardinality for large rectangles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08823</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08823</id><created>2017-11-23</created><authors><author><keyname>Czech</keyname><forenames>Daniel</forenames></author><author><keyname>Mishra</keyname><forenames>Amit</forenames></author><author><keyname>Inggs</keyname><forenames>Michael</forenames></author></authors><title>A Dictionary Approach to Identifying Transient RFI</title><categories>astro-ph.IM cs.CV eess.SP</categories><doi>10.1029/2018RS006538</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As radio telescopes become more sensitive, the damaging effects of radio
frequency interference (RFI) become more apparent. Near radio telescope arrays,
RFI sources are often easily removed or replaced; the challenge lies in
identifying them. Transient (impulsive) RFI is particularly difficult to
identify. We propose a novel dictionary-based approach to transient RFI
identification. RFI events are treated as sequences of sub-events, drawn from
particular labelled classes. We demonstrate an automated method of extracting
and labelling sub-events using a dataset of transient RFI. A dictionary of
labels may be used in conjunction with hidden Markov models to identify the
sources of RFI events reliably. We attain improved classification accuracy over
traditional approaches such as SVMs or a na\&quot;ive kNN classifier. Finally, we
investigate why transient RFI is difficult to classify. We show that cluster
separation in the principal components domain is influenced by the mains supply
phase for certain sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08842</identifier>
 <datestamp>2018-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08842</id><created>2017-11-23</created><updated>2018-04-18</updated><authors><author><keyname>Zafar</keyname><forenames>Adnan</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Xiao</keyname><forenames>Pei</forenames></author><author><keyname>Imran</keyname><forenames>Muhammad Ali</forenames></author></authors><title>Spectrum Efficient MIMO-FBMC System using Filter Output Truncation</title><categories>eess.SP</categories><doi>10.1109/TVT.2017.2771531</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the use of an appropriately designed pulse shaping prototype filter,
filter bank multicarrier (FBMC) system can achieve low out of band (OoB)
emissions and is also robust to the channel and synchronization errors.
However, it comes at a cost of long filter tails which may reduce the spectral
efficiency significantly when the block size is small. Filter output truncation
(FOT) can reduce the overhead by discarding the filter tails but may also
significantly destroy the orthogonality of FBMC system, by introducing inter
carrier interference (ICI) and inter symbol interference (ISI) terms in the
received signal. As a result, the signal to interference ratio (SIR) is
degraded. In addition, the presence of intrinsic interference terms in FBMC
also proves to be an obstacle in combining multiple input multiple output
(MIMO) with FBMC. In this paper, we present a theoretical analysis on the
effect of FOT in an MIMO-FBMC system. First, we derive the matrix model of
MIMO-FBMC system which is subsequently used to analyze the impact of finite
filter length and FOT on the system performance. The analysis reveals that FOT
can avoid the overhead in time domain but also introduces extra interference in
the received symbols. To combat the interference terms, we then propose a
compensation algorithm that considers odd and even overlapping factors as two
separate cases, where the signals are interfered by the truncation in different
ways. The general form of the compensation algorithm can compensate all the
symbols in a MIMO-FBMC block and can improve the SIR values of each symbol for
better detection at the receiver. It is also shown that the proposed algorithm
requires no overhead and can still achieve a comparable BER performance to the
case with no filter truncation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08850</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08850</id><created>2017-11-23</created><authors><author><keyname>Zafar</keyname><forenames>Adnan</forenames></author><author><keyname>Abdullahi</keyname><forenames>Mahmoud</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Taheri</keyname><forenames>Sohail</forenames></author><author><keyname>Xiao</keyname><forenames>Pei</forenames></author><author><keyname>Imran</keyname><forenames>Muhammad Ali</forenames></author></authors><title>Complex-Valued Symbol Transmissions in Filter Bank Multicarrier Systems
  using Filter Deconvolution</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmission of complex-valued symbols using filter bank multicarrier systems
has been an issue due to the self-interference between the transmitted symbols
both in the time and frequency domain (so-called intrinsic interference). In
this paper, we propose a novel low-complexity interference-free filter bank
multicarrier system with QAM modulation (FBMC/QAM) using filter deconvolution.
The proposed method is based on inversion of the prototype filters which
completely removes the intrinsic interference at the receiver and allows the
use of complex-valued signaling. The interference terms in FBMC/QAM with and
without the proposed system are analyzed and compared in terms of mean square
error (MSE). It is shown with theoretical and simulation results that the
proposed method cancels the intrinsic interference and improves the output
signal to interference plus noise ratio (SINR) at the expense of slight
enhancement of residual interferences caused by multipath channel. The
complexity of the proposed system is also analyzed along with performance
evaluation in an asynchronous multiservice scenario. It is shown that the
proposed FBMC/QAM system with filter deconvolution outperforms the conventional
OFDM system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08970</identifier>
 <datestamp>2019-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08970</id><created>2017-11-24</created><updated>2019-02-04</updated><authors><author><keyname>Bitar</keyname><forenames>Ahmad W.</forenames></author><author><keyname>Cheong</keyname><forenames>Loong-Fah</forenames></author><author><keyname>Ovarlez</keyname><forenames>Jean-Philippe</forenames></author></authors><title>Sparse and Low-Rank Matrix Decomposition for Automatic Target Detection
  in Hyperspectral Imagery</title><categories>eess.IV stat.AP</categories><comments>Accepted for publication in the IEEE Transactions on Geoscience and
  Remote Sensing. Submitted in 20 November 2017. Accepted for publication in 06
  January 2019</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a target prior information, our goal is to propose a method for
automatically separating targets of interests from the background in
hyperspectral imagery. More precisely, we regard the given hyperspectral image
(HSI) as being made up of the sum of low-rank background HSI and a sparse
target HSI that contains the targets based on a pre-learned target dictionary
constructed from some online spectral libraries. Based on the proposed method,
two strategies are briefly outlined and evaluated to realize the target
detection on both synthetic and real experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.08976</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.08976</id><created>2017-11-24</created><updated>2017-11-28</updated><authors><author><keyname>Yu</keyname><forenames>Yi</forenames></author><author><keyname>Tang</keyname><forenames>Suhua</forenames></author><author><keyname>Raposo</keyname><forenames>Francisco</forenames></author><author><keyname>Chen</keyname><forenames>Lei</forenames></author></authors><title>Deep Cross-Modal Correlation Learning for Audio and Lyrics in Music
  Retrieval</title><categories>cs.IR cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Little research focuses on cross-modal correlation learning where temporal
structures of different data modalities such as audio and lyrics are taken into
account. Stemming from the characteristic of temporal structures of music in
nature, we are motivated to learn the deep sequential correlation between audio
and lyrics. In this work, we propose a deep cross-modal correlation learning
architecture involving two-branch deep neural networks for audio modality and
text modality (lyrics). Different modality data are converted to the same
canonical space where inter modal canonical correlation analysis is utilized as
an objective function to calculate the similarity of temporal structures. This
is the first study on understanding the correlation between language and music
audio through deep architectures for learning the paired temporal correlation
of audio and lyrics. Pre-trained Doc2vec model followed by fully-connected
layers (fully-connected deep neural network) is used to represent lyrics. Two
significant contributions are made in the audio branch, as follows: i)
pre-trained CNN followed by fully-connected layers is investigated for
representing music audio. ii) We further suggest an end-to-end architecture
that simultaneously trains convolutional layers and fully-connected layers to
better learn temporal structures of music audio. Particularly, our end-to-end
deep architecture contains two properties: simultaneously implementing feature
learning and cross-modal correlation learning, and learning joint
representation by considering temporal structures. Experimental results, using
audio to retrieve lyrics or using lyrics to retrieve audio, verify the
effectiveness of the proposed deep correlation learning architectures in
cross-modal music retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09052</identifier>
 <datestamp>2019-07-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09052</id><created>2017-11-24</created><updated>2019-07-10</updated><authors><author><keyname>Lim</keyname><forenames>Yeon-Geun</forenames></author><author><keyname>Cho</keyname><forenames>Yae Jee</forenames></author><author><keyname>Sim</keyname><forenames>MinSoo</forenames></author><author><keyname>Kim</keyname><forenames>Younsun</forenames></author><author><keyname>Chae</keyname><forenames>Chan-Byoung</forenames></author><author><keyname>Valenzuela</keyname><forenames>Reinaldo A.</forenames></author></authors><title>Map-based Millimeter-Wave Channel Models: An Overview, Hybrid Modeling,
  Data, and Learning</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compared to the current wireless communication systems, millimeter wave
(mm-Wave) promises a wide range of spectrum. As viable alternatives to existing
mm-Wave channel models, various map-based channel models with different
modeling methods have been widely discussed. Map-based channel models are based
on a ray-tracing algorithm and include realistic channel parameters in a given
map. Such parameters enable researchers to accurately evaluate novel
technologies in the mm-Wave range. Diverse map-based modeling methods result in
different modeling objectives, including the characteristics of channel
parameters and different complexities of the modeling procedure. This article
outlines an overview of map-based mm-Wave channel models and proposes a concept
of how they can be utilized to integrate a hardware testbed/sounder with a
software testbed/sounder. In addition, we categorize map-based channel
parameters and provide guidelines for hybrid modeling. Next, we share the
measurement data and the map-based channel parameters with the public. Lastly,
we evaluate a machine learning-based beam selection algorithm through the
shared database. We expect that the offered guidelines and the shared database
will enable researchers to readily design a map-based channel model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09061</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09061</id><created>2017-11-21</created><updated>2017-12-20</updated><authors><author><keyname>Darabi</keyname><forenames>Mohammadreza</forenames></author></authors><title>The Expected Achievable Distortion of Two-User Decentralized
  Interference Channels</title><categories>eess.SP cs.IT math.IT</categories><comments>arXiv admin note: submission has been withdrawn by arXiv
  administrators due to inappropriate text reuse from external sources</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the transmission of two independent Gaussian sources over
a two-user decentralized interference channel, assuming that the transmitters
are unaware of the instantaneous CSIs. The availability of the channel state
information at receivers (CSIR) is considered in two scenarios of perfect and
imperfect CSIR. In the imperfect CSIR case, we consider a more practical
assumption of having an MMSE estimation of the channel gain at the receivers.
In this case, minimizing the expected achievable distortion associated with
each link is considered. Due to the absence of CSI at the transmitters, the
Gaussian sources are encoded in a successively refinable manner and the
resulting code words are transmitted over the channel using a multi-layer
coding technique. Accordingly, the optimal power assignment between code layers
leading to the least expected achievable distortion, under a mean-square error
criterion is derived for both, the perfect and imperfect CSIR scenarios.
Finally, some numerical examples are provided and it is demonstrated that the
proposed method results in better performance as compared with the conventional
single-layer approach, termed as outage approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09062</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09062</id><created>2017-10-27</created><authors><author><keyname>Krivochiza</keyname><forenames>Jevgenij</forenames></author><author><keyname>Kalantari</keyname><forenames>Ashkan</forenames></author><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author><author><keyname>Ottersten</keyname><forenames>Bjorn</forenames></author></authors><title>Low Complexity Symbol-Level Design for Linear Precoding Systems</title><categories>eess.SP</categories><journal-ref>PROCEEDINGS of the 2017 Symposium on Information Theory and Signal
  Processing in the Benelux, ISBN 978-94-6186-811-4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The practical utilization of the symbol-level precoding in MIMO systems is
challenging since the implementation of the sophisticated optimization
algorithms must be done with reasonable computational resources. In the real
implementation of MIMO precoding systems, the processing time for each set of
symbols is a crucial parameter, especially in the high-throughput mode. In this
work, a symbol-level optimization algorithm with reduced complexity is devised.
Performance of a symbol-level precoder is shown to improve in terms of the
processing times per set of symbols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09072</identifier>
 <datestamp>2018-04-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09072</id><created>2017-11-24</created><authors><author><keyname>Rubido</keyname><forenames>Nicol&#xe1;s</forenames></author><author><keyname>Grebogi</keyname><forenames>Celso</forenames></author><author><keyname>Baptista</keyname><forenames>Murilo S.</forenames></author></authors><title>Entropy-based Generating Markov Partitions for Complex Systems</title><categories>nlin.CD eess.SP physics.data-an</categories><comments>10 pages, 10 figures</comments><doi>10.1063/1.5002097</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Finding the correct encoding for a generic dynamical system's trajectory is a
complicated task: the symbolic sequence needs to preserve the invariant
properties from the system's trajectory. In theory, the solution to this
problem is found when a Generating Markov Partition (GMP) is obtained, which is
only defined once the unstable and stable manifolds are known with infinite
precision and for all times. However, these manifolds usually form highly
convoluted Euclidean sets, are \emph{a priori} unknown, and, as it happens in
any real-world experiment, measurements are made with finite resolution and
over a finite time-span. The task gets even more complicated if the system is a
network composed of interacting dynamical units, namely, a high-dimensional
complex system. Here, we tackle this task and solve it by defining a method to
approximately construct GMPs for any complex system's finite-resolution and
finite-time trajectory. We critically test our method on networks of coupled
maps, encoding their trajectories into symbolic sequences. We show that these
sequences are optimal because they minimise the information loss and also any
spurious information added. Consequently, our method allows us to approximately
calculate the invariant probability measures of complex systems from observed
data. Thus, we can efficiently define complexity measures that are applicable
to a wide range of complex phenomena, such as the characterisation of brain
activity from EEG signals measured at different brain regions or the
characterisation of climate variability from temperature anomalies measured at
different Earth regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09086</identifier>
 <datestamp>2018-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09086</id><created>2017-11-22</created><updated>2018-06-29</updated><authors><author><keyname>Liu</keyname><forenames>Jiani</forenames></author><author><keyname>Isufi</keyname><forenames>Elvin</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Filter Design for Autoregressive Moving Average Graph Filters</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the field of signal processing on graphs, graph filters play a crucial
role in processing the spectrum of graph signals. This paper proposes two
different strategies for designing autoregressive moving average (ARMA) graph
filters on both directed and undirected graphs. The first approach is inspired
by Prony's method, which considers a modified error between the modeled and the
desired frequency response. The second technique is based on an iterative
approach, which finds the filter coefficients by iteratively minimizing the
true error (instead of the modified error) between the modeled and the desired
frequency response. The performance of the proposed algorithms is evaluated and
compared with finite impulse response (FIR) graph filters, on both synthetic
and real data. The obtained results show that ARMA filters outperform FIR
filters in terms of approximation accuracy and they are suitable for graph
signal interpolation, compression and prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09093</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09093</id><created>2017-11-26</created><authors><author><keyname>Markhasin</keyname><forenames>Alexander</forenames></author></authors><title>An Extremely Flexible, Energy, and Spectral Effective Green PHY-MAC for
  Profitable Ubiquitous Rural and Remote 5G/B5G IoT/M2M Communications</title><categories>eess.SP</categories><comments>12 pages, 5 figures, presented at 16th International Conference
  NEW2AN 2016 (author proof final version, the following this paper extremely
  effective green 5G PHY-MAC technique for profitable ubiquitous rural
  e/m-Healthcare applications is developed in arXiv:1711.06469). arXiv admin
  note: substantial text overlap with arXiv:1711.06469</comments><doi>10.1007/978-3-319-46301-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the fundamental throughput limits and extremums of the
invariant criteria of energy, power and spectral efficiency of the physical
layer (PHY) and medium access control (MAC) sublayer are proved. The invariant
criteria are constructed relying on Shannon m-ary digital channel capacity
which a rich palette of the technically interpreted physical and control
parameters consider. Therefore, the invariant criteria as very suitable for
research and design of the fifth generation (5G) communications extremely
performance problems are found. The smart distributed control techniques which
able implements on-the-fly the limits close and invariant criterion
optimization or trade-off is proposed. Such smart control techniques represent
a key disruptive technology meet the 5G and Beyond 5G network challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09175</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09175</id><created>2017-11-24</created><authors><author><keyname>Abdulatif</keyname><forenames>Sherif</forenames></author><author><keyname>Aziz</keyname><forenames>Fady</forenames></author><author><keyname>Kleiner</keyname><forenames>Bernhard</forenames></author><author><keyname>Schneider</keyname><forenames>Urs</forenames></author></authors><title>Real-Time Capable Micro-Doppler Signature Decomposition of Walking Human
  Limbs</title><categories>cs.CV eess.SP</categories><comments>6 pages, IEEE RadarConf 17</comments><msc-class>68T10 (Primary), 68T40 (Secondary)</msc-class><journal-ref>IEEE Radar Conference 2017 1093 1098</journal-ref><doi>10.1109/RADAR.2017.7944367</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unique micro-Doppler signature ($\boldsymbol{\mu}$-D) of a human body motion
can be analyzed as the superposition of different body parts
$\boldsymbol{\mu}$-D signatures. Extraction of human limbs $\boldsymbol{\mu}$-D
signatures in real-time can be used to detect, classify and track human motion
especially for safety application. In this paper, two methods are combined to
simulate $\boldsymbol{\mu}$-D signatures of a walking human. Furthermore, a
novel limbs $\mu$-D signature time independent decomposition feasibility study
is presented based on features as $\mu$-D signatures and range profiles also
known as micro-Range ($\mu$-R). Walking human body parts can be divided into
four classes (base, arms, legs, feet) and a decision tree classifier is used.
Validation is done and the classifier is able to decompose $\mu$-D signatures
of limbs from a walking human signature on real-time basis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09177</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09177</id><created>2017-11-24</created><updated>2018-02-26</updated><authors><author><keyname>Abdulatif</keyname><forenames>Sherif</forenames></author><author><keyname>Wei</keyname><forenames>Qian</forenames></author><author><keyname>Aziz</keyname><forenames>Fady</forenames></author><author><keyname>Kleiner</keyname><forenames>Bernhard</forenames></author><author><keyname>Schneider</keyname><forenames>Urs</forenames></author></authors><title>Micro-Doppler Based Human-Robot Classification Using Ensemble and Deep
  Learning Approaches</title><categories>cs.CV eess.SP</categories><comments>6 pages, accepted in IEEE Radar Conference 2018</comments><msc-class>68T10 (Primary), 68T40 (Secondary)</msc-class><journal-ref>IEEE Radar Conference 2017 1043 1048</journal-ref><doi>10.1109/RADAR.2018.8378705</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radar sensors can be used for analyzing the induced frequency shifts due to
micro-motions in both range and velocity dimensions identified as micro-Doppler
($\boldsymbol{\mu}$-D) and micro-Range ($\boldsymbol{\mu}$-R), respectively.
Different moving targets will have unique $\boldsymbol{\mu}$-D and
$\boldsymbol{\mu}$-R signatures that can be used for target classification.
Such classification can be used in numerous fields, such as gait recognition,
safety and surveillance. In this paper, a 25 GHz FMCW Single-Input
Single-Output (SISO) radar is used in industrial safety for real-time
human-robot identification. Due to the real-time constraint, joint
Range-Doppler (R-D) maps are directly analyzed for our classification problem.
Furthermore, a comparison between the conventional classical learning
approaches with handcrafted extracted features, ensemble classifiers and deep
learning approaches is presented. For ensemble classifiers, restructured range
and velocity profiles are passed directly to ensemble trees, such as gradient
boosting and random forest without feature extraction. Finally, a Deep
Convolutional Neural Network (DCNN) is used and raw R-D images are directly fed
into the constructed network. DCNN shows a superior performance of 99\%
accuracy in identifying humans from robots on a single R-D map.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09198</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09198</id><created>2017-11-25</created><authors><author><keyname>Abdulatif</keyname><forenames>Sherif</forenames></author><author><keyname>Aziz</keyname><forenames>Fady</forenames></author><author><keyname>Altiner</keyname><forenames>Pelin</forenames></author><author><keyname>Kleiner</keyname><forenames>Bernhard</forenames></author><author><keyname>Schneider</keyname><forenames>Urs</forenames></author></authors><title>Power-Based Real-Time Respiration Monitoring Using FMCW Radar</title><categories>eess.SP</categories><comments>4 pages, submitted in IEEE Radar Conference 2018</comments><msc-class>68T45 (Primary), 68T05 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-contact vital sign detection is a required application nowadays in many
fields as patient monitoring and static human detection. Within the last
decade, radar has been introduced as a smart and convenient sensor for
non-contact respiration monitoring. Radar sensors are considered suitable for
such application for its capability to work through obstacles and in harsh
environmental conditions. FMCW radar has been introduced as a powerful tool in
this field for its capability of detecting both the breathing target position
and his chest micro-motions induced due to breathing. Most of the presented
techniques for using the radar for respiration detection is based on bandpass
filtering or wavelet transforms on the required harmonics in either the range
or Doppler dimension. However, both techniques affect the real-time capability
of the monitoring and work on limited distances and aspect angles. A
recognizable fluctuation effect is observed in the received range spectrum
overtime due to respiration chest movements. The proposed technique in this
paper is based on detecting and processing the power changes in real-time over
different aspect angles and distances. Two radar modules working on different
carrier frequency bands, bandwidths and output power levels were tested and
compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09206</identifier>
 <datestamp>2018-06-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09206</id><created>2017-11-25</created><authors><author><keyname>Abdulatif</keyname><forenames>Sherif</forenames><affiliation>Fraunhofer Institute for Manufacturing Engineering and Automation IPA</affiliation></author><author><keyname>Kleiner</keyname><forenames>Bernhard</forenames><affiliation>Fraunhofer Institute for Manufacturing Engineering and Automation IPA</affiliation></author><author><keyname>Aziz</keyname><forenames>Fady</forenames><affiliation>Fraunhofer Institute for Manufacturing Engineering and Automation IPA</affiliation></author><author><keyname>Riehs</keyname><forenames>Christopher</forenames><affiliation>Fraunhofer Institute for Manufacturing Engineering and Automation IPA</affiliation></author><author><keyname>Cooper</keyname><forenames>Rory</forenames><affiliation>Human Engineering Research Laboratories, University of Pittsburg</affiliation></author><author><keyname>Schneider</keyname><forenames>Urs</forenames><affiliation>Fraunhofer Institute for Manufacturing Engineering and Automation IPA</affiliation></author></authors><title>Stairs Detection for Enhancing Wheelchair Capabilities Based on Radar
  Sensors</title><categories>cs.HC cs.RO eess.SP</categories><comments>5 pages, Accepted and presented in 2017 IEEE 6th Global Conference on
  Consumer Electronics (GCCE 2017)</comments><msc-class>68T40 (Primary), 68T45 (Secondary)</msc-class><journal-ref>IEEE 6th Global Conference on Consumer Electronics (GCCE) 2017 1 5</journal-ref><doi>10.1109/GCCE.2017.8229270</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Powered wheelchair users encounter barriers to their mobility everyday.
Entering a building with non barrier-free areas can massively impact the user
mobility related activities. There are a few commercial devices and some
experimental that can climb stairs using for instance adaptive wheels with
joints or caterpillar drive. These systems rely on the use for sensing and
control. For safe automated obstacle crossing, a robust and environment
invariant detection of the surrounding is necessary. Radar may prove to be a
suitable sensor for its capability to handle harsh outdoor environmental
conditions. In this paper, we introduce a mirror based two dimensional
Frequency-Modulated Continuous-Wave (FMCW) radar scanner for stair detection. A
radar image based stair dimensioning approach is presented and tested under
laboratory and realistic conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09217</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09217</id><created>2017-11-25</created><authors><author><keyname>Sadeghigol</keyname><forenames>Zahra</forenames></author><author><keyname>Zayyani</keyname><forenames>Hadi</forenames></author><author><keyname>Abin</keyname><forenames>Hamidreza</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Multivariate Copula Spatial Dependency in One Bit Compressed Sensing</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, the problem of sparse signal reconstruction from one bit
compressed sensing measurements is investigated. To solve the problem, a
variational Bayes framework with a new statistical multivariate model is used.
The dependency of the wavelet decomposition coefficients is modeled with a
multivariate Gaussian copula. This model can separate marginal structure of
coefficients from their intra scale dependency. In particular, the drawable
Gaussian vine copula multivariate double Lomax model is suggested. The
reconstructed signal is derived by variational Bayes algorithm which can
calculate closed forms for posterior of all unknown parameters and sparse
signal. Numerical results illustrate the effectiveness of the proposed model
and algorithm compared with the competing approaches in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09234</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09234</id><created>2017-11-25</created><authors><author><keyname>Tarzan</keyname><forenames>Ali</forenames><affiliation>RWTH Aachen University</affiliation></author><author><keyname>Alunno</keyname><forenames>Marco</forenames><affiliation>Universidad EAFIT</affiliation></author><author><keyname>Bientinesi</keyname><forenames>Paolo</forenames><affiliation>RWTH Aachen University</affiliation></author></authors><title>Assessment of sound spatialisation algorithms for sonic rendering with
  headsets</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an input sound signal and a target virtual sound source, sound
spatialisation algorithms manipulate the signal so that a listener perceives it
as though it were emitted from the target source. There exist several
established spatialisation approaches that deliver satisfactory results when
loudspeakers are used to playback the manipulated signal. As headphones have a
number of desirable characteristics over loudspeakers, such as portability,
isolation from the surrounding environment, cost and ease of use, it is
interesting to explore how a sense of acoustic space can be conveyed through
them. This article first surveys traditional spatialisation approaches intended
for loudspeakers, and then reviews them with regard to their adaptability to
headphones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09298</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09298</id><created>2017-11-25</created><authors><author><keyname>Silva</keyname><forenames>Melanie R.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>Erivelton G.</forenames></author><author><keyname>Martins</keyname><forenames>Samir A. M.</forenames></author></authors><title>Chaos suppression of Lorenz Systems by means on the average of rounding
  modes</title><categories>eess.SP</categories><comments>DINCON 2017 - Conferencia Brasileira de Dinamica, Controle e
  Aplicacoes - Sao Jose do Rio Preto - Brazil. 8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work deals with chaos suppression based on average of the rounded modes
to negative and positive infinite. The present procedure acts to reduce the
rounding errors. It was observed that when the method proposed in this paper is
applied to the chaotic Lorenz's system, it exhibits a periodic behaviour,
characterized by a limit cycle and negative largest Lyapunov exponent. We
tested our approach using three discretization schemes based on Runge-Kutta
method
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09301</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09301</id><created>2017-11-25</created><authors><author><keyname>Kruzick</keyname><forenames>Stephen</forenames></author><author><keyname>Moura</keyname><forenames>Jos&#xe9; M. F.</forenames></author></authors><title>Consensus State Gram Matrix Estimation for Stochastic Switching Networks
  from Spectral Distribution Moments</title><categories>eess.SP</categories><comments>52nd Asilomar Conference on Signals, Systems, and Computers (Asilomar
  2017)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reaching distributed average consensus quickly and accurately over a network
through iterative dynamics represents an important task in numerous distributed
applications. Suitably designed filters applied to the state values can
significantly improve the convergence rate. For constant networks, these
filters can be viewed in terms of graph signal processing as polynomials in a
single matrix, the consensus iteration matrix, with filter response evaluated
at its eigenvalues. For random, time-varying networks, filter design becomes
more complicated, involving eigendecompositions of sums and products of random,
time-varying iteration matrices. This paper focuses on deriving an estimate for
the Gram matrix of error in the state vectors over a filtering window for
large-scale, stationary, switching random networks. The result depends on the
moments of the empirical spectral distribution, which can be estimated through
Monte-Carlo simulation. This work then defines a quadratic objective function
to minimize the expected consensus estimate error norm. Simulation results
provide support for the approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09306</identifier>
 <datestamp>2018-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09306</id><created>2017-11-25</created><authors><author><keyname>Ioannidis</keyname><forenames>Vassilis N.</forenames></author><author><keyname>Romero</keyname><forenames>Daniel</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Inference of Spatio-Temporal Functions over Graphs via Multi-Kernel
  Kriged Kalman Filtering</title><categories>cs.LG eess.SP stat.ML</categories><comments>Submitted to IEEE Transactions on Signal processing, Nov. 2017</comments><doi>10.1109/TSP.2018.2827328</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inference of space-time varying signals on graphs emerges naturally in a
plethora of network science related applications. A frequently encountered
challenge pertains to reconstructing such dynamic processes, given their values
over a subset of vertices and time instants. The present paper develops a
graph-aware kernel-based kriged Kalman filter that accounts for the
spatio-temporal variations, and offers efficient online reconstruction, even
for dynamically evolving network topologies. The kernel-based learning
framework bypasses the need for statistical information by capitalizing on the
smoothness that graph signals exhibit with respect to the underlying graph. To
address the challenge of selecting the appropriate kernel, the proposed filter
is combined with a multi-kernel selection module. Such a data-driven method
selects a kernel attuned to the signal dynamics on-the-fly within the linear
span of a pre-selected dictionary. The novel multi-kernel learning algorithm
exploits the eigenstructure of Laplacian kernel matrices to reduce
computational complexity. Numerical tests with synthetic and real data
demonstrate the superior reconstruction performance of the novel approach
relative to state-of-the-art alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09309</identifier>
 <datestamp>2018-04-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09309</id><created>2017-11-25</created><updated>2018-04-19</updated><authors><author><keyname>Azizzadeh</keyname><forenames>Azad</forenames></author><author><keyname>Mohammadkhani</keyname><forenames>Reza</forenames></author><author><keyname>Makki</keyname><forenames>Seyed Vahab Al-Din</forenames></author><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author></authors><title>BER Performance Analysis of Coarse Quantized Uplink Massive MIMO</title><categories>eess.SP</categories><comments>9 pages, 7 figures, submitted to the IEEE Journals</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Having lower quantization resolution, has been introduced in the literature,
as a solution to reduce the power consumption of massive MIMO and millimeter
wave MIMO systems. In this paper, we analyze bit error rate (BER) performance
of quantized uplink massive MIMO employing a few-bit resolution ADCs.
Considering Zero-Forcing (ZF) detection, we derive a closed-form quantized
signal-to-interference-plus-noise ratio (SINR) to achieve an analytical BER
approximation for coarse quantized M-QAM massive MIMO systems, by using a
linear quantization model. The proposed expression is a function of
quantization resolution in bits. We further numerically investigate the effects
of different quantization levels, from 1-bit to 4-bits, on the BER of three
modulation types of QPSK, 16-QAM, and 64-QAM. Uniform and non-uniform
quantizers are employed in our simulation.
  Monte Carlo simulation results reveal that our approximate formula gives a
tight upper bound for the BER performance of $b$-bit resolution quantized
systems using non-uniform quantizers, whereas the use of uniform quantizers
cause a lower performance for the same systems. We also found a small BER
performance degradation in coarse quantized systems, for example 2-3 bits QPSK
and 3-4 bits 16-QAM, compared to the full-precision (unquantized) case.
However, this performance degradation can be compensated by increasing the
number of antennas at the BS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09311</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09311</id><created>2017-11-25</created><authors><author><keyname>Xiong</keyname><forenames>Wenhao</forenames></author><author><keyname>Tian</keyname><forenames>Xin</forenames></author><author><keyname>Chen</keyname><forenames>Genshe</forenames></author><author><keyname>Pham</keyname><forenames>Khanh</forenames></author><author><keyname>Blasch</keyname><forenames>Erik</forenames></author></authors><title>An adaptive software defined radio design based on a standard space
  telecommunication radio system API</title><categories>eess.SP</categories><doi>10.1117/12.2266543</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software defined radio (SDR) has become a popular tool for the implementation
and testing for communications performance. The advantage of the SDR approach
includes: a re-configurable design, adaptive response to changing conditions,
efficient development, and highly versatile implementation. In order to
understand the benefits of SDR, the space telecommunication radio system (STRS)
was proposed by NASA Glenn research center (GRC) along with the standard
application program interface (API) structure. Each component of the system
uses a well-defined API to communicate with other components. The benefit of
standard API is to relax the platform limitation of each component for addition
options. For example, the waveform generating process can support a field
programmable gate array (FPGA), personal computer (PC), or an embedded system.
As long as the API defines the requirements, the generated waveform selection
will work with the complete system. In this paper, we demonstrate the design
and development of adaptive SDR following the STRS and standard API protocol.
We introduce step by step the SDR testbed system including the controlling
graphic user interface (GUI), database, GNU radio hardware control, and
universal software radio peripheral (USRP) tranceiving front end. In addition,
a performance evaluation in shown on the effectiveness of the SDR approach for
space telecommunication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09360</identifier>
 <datestamp>2018-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09360</id><created>2017-11-26</created><updated>2018-05-16</updated><authors><author><keyname>Stimming</keyname><forenames>Alexios Balatsoukas</forenames></author><author><keyname>Liavas</keyname><forenames>Athanasios P.</forenames></author></authors><title>Design of LDPC Codes for the Unequal Power Two-User Gaussian Multiple
  Access Channel</title><categories>cs.IT eess.SP math.IT</categories><doi>10.1109/LWC.2018.2833855</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we describe an LDPC code design framework for the unequal power
two-user Gaussian multiple access channel using EXIT charts. We show that the
sum-rate of the LDPC codes designed using our approach can get close to the
maximal sum-rate of the two-user Gaussian multiple access channel. Moreover, we
provide numerical simulation results that demonstrate the excellent
finite-length performance of the designed LDPC codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09375</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09375</id><created>2017-11-26</created><authors><author><keyname>Dinh</keyname><forenames>Khanh Quoc</forenames></author><author><keyname>Canh</keyname><forenames>Thuong Nguyen</forenames></author><author><keyname>Jeon</keyname><forenames>Byeungwoo</forenames></author></authors><title>Compressive Sensing of Color Images Using Nonlocal Higher Order
  Dictionary</title><categories>eess.IV cs.CV</categories><comments>13 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses an ill-posed problem of recovering a color image from
its compressively sensed measurement data. Differently from the typical 1D
vector-based approach of the state-of-the-art methods, we exploit the nonlocal
similarities inherently existing in images by treating each patch of a color
image as a 3D tensor consisting of not only horizontal and vertical but also
spectral dimensions. A group of nonlocal similar patches form a 4D tensor for
which a nonlocal higher order dictionary is learned via higher order singular
value decomposition. The multiple sub-dictionaries contained in the higher
order dictionary decorrelate the group in each corresponding dimension, thus
help the detail of color images to be reconstructed better. Furthermore, we
promote sparsity of the final solution using a sparsity regularization based on
a weight tensor. It can distinguish those coefficients of the sparse
representation generated by the higher order dictionary which are expected to
have large magnitude from the others in the optimization. Accordingly, in the
iterative solution, it acts like a weighting process which is designed by
approximating the minimum mean squared error filter for more faithful recovery.
Experimental results confirm improvement by the proposed method over the
state-of-the-art ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09386</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09386</id><created>2017-11-26</created><authors><author><keyname>Liu</keyname><forenames>Haitao</forenames></author></authors><title>Design and Implementation of a LTE-WiFi Aggregation System based on SDR</title><categories>eess.SP</categories><comments>in Chinese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With explosive growth of the mobile Internet access and the popularization of
wireless local area network (WLAN) access points (APs), wireless fidelity
(WiFi) offloading is considered as an important supplementary technique to
reduce the load of cellular infrastructure and enhance quality of network
service. In this paper, we design and implement the framework of LTEWiFi
aggregation (LWA) which is in line with the 3rd Generation Partnership Project
(3GPP) released standard recently. In the LWA system, the process of data
offloading is different from that of WiFi interworking on the cellular core
network. WLAN APs directly connect to eNodeBs (eNBs), and the offloading is
realized in Packet Data Convergence Protocol layer (PDCP). Thus, this
architecture makes full use of existed WLAN APs to improve the performance of
indoor cellular network. Besides, benefiting from the flow control between LTE
and WiFi, eNB schedule can be more flexible and efficient. Next, it is
implemented based on open source OpenAirInterface (OAI) software defined radio
(SDR) platform, where a simple and practical reordering method is proposed and
carried out. Experimental results demonstrate that our design works stably with
the WiFi-offloading and reordering functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09444</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09444</id><created>2017-11-26</created><authors><author><keyname>Yi&#x11f;itler</keyname><forenames>H&#xfc;seyin</forenames></author><author><keyname>Kaltiokallio</keyname><forenames>Ossi</forenames></author><author><keyname>Hostettler</keyname><forenames>Roland</forenames></author><author><keyname>J&#xe4;ntti</keyname><forenames>Riku</forenames></author><author><keyname>Patwari</keyname><forenames>Neal</forenames></author><author><keyname>S&#xe4;rkk&#xe4;</keyname><forenames>Simo</forenames></author></authors><title>RSS Models for Respiration Rate Monitoring</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Received signal strength based respiration rate monitoring is emerging as an
alternative non-contact technology. These systems make use of the radio
measurements of short-range commodity wireless devices, which vary due to the
inhalation and exhalation motion of a person. The success of respiration rate
estimation using such measurements depends on the signal-to-noise ratio, which
alters with properties of the person and with the measurement system. To date,
no model has been presented that allows evaluation of different deployments or
system configurations for successful breathing rate estimation. In this paper,
a received signal strength model for respiration rate monitoring is introduced.
It is shown that measurements in linear and logarithmic scale have the same
functional form, and the same estimation techniques can be used in both cases.
The implications of the model are validated under varying signal-to-noise ratio
conditions using the performances of three estimators: batch frequency
estimator, recursive Bayesian estimator, and model-based estimator. The results
are in coherence with the findings, and they imply that different estimators
are advantageous in different signal-to-noise ratio regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09470</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09470</id><created>2017-11-26</created><authors><author><keyname>Ravanelli</keyname><forenames>Mirco</forenames></author><author><keyname>Svaizer</keyname><forenames>Piergiorgio</forenames></author><author><keyname>Omologo</keyname><forenames>Maurizio</forenames></author></authors><title>Realistic multi-microphone data simulation for distant speech
  recognition</title><categories>eess.AS cs.SD</categories><comments>Proc. of Interspeech 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The availability of realistic simulated corpora is of key importance for the
future progress of distant speech recognition technology. The reliability,
flexibility and low computational cost of a data simulation process may
ultimately allow researchers to train, tune and test different techniques in a
variety of acoustic scenarios, avoiding the laborious effort of directly
recording real data from the targeted environment.
  In the last decade, several simulated corpora have been released to the
research community, including the data-sets distributed in the context of
projects and international challenges, such as CHiME and REVERB. These efforts
were extremely useful to derive baselines and common evaluation frameworks for
comparison purposes. At the same time, in many cases they highlighted the need
of a better coherence between real and simulated conditions.
  In this paper, we examine this issue and we describe our approach to the
generation of realistic corpora in a domestic context. Experimental validation,
conducted in a multi-microphone scenario, shows that a comparable performance
trend can be observed with both real and simulated data across different
recognition frameworks, acoustic models, as well as multi-microphone processing
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09520</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09520</id><created>2017-11-26</created><authors><author><keyname>Wei</keyname><forenames>Chao</forenames></author><author><keyname>Zhang</keyname><forenames>Zaichen</forenames></author></authors><title>Analysis of Dual-Hop AF Relay Systems in Mixed RF and FSO Links</title><categories>eess.SP</categories><comments>4 pages, submitted to IEEE Photonics Technology Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analysis the performances for the dual-hop fixed gain amplify-and-forward
(AF) relay systems operating over mixed radio-frequency (RF) and free-space
optical (FSO) links. The RF link is subject to Rician fading and the FSO link
experiences Gamma-Gamma turbulence fading. We derive the closed-form
expressions for the outage probability and the average symbol error rate in
terms of the Meijer's G function.All analytical results are corroborated by
simulation results and the effects of fading parameters on the system
performances are also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09598</identifier>
 <datestamp>2019-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09598</id><created>2017-11-27</created><updated>2019-02-25</updated><authors><author><keyname>Shnitzer</keyname><forenames>Tal</forenames></author><author><keyname>Talmon</keyname><forenames>Ronen</forenames></author><author><keyname>Slotine</keyname><forenames>Jean-Jacques</forenames></author></authors><title>Diffusion Maps Kalman Filter for a Class of Systems with Gradient Flows</title><categories>eess.SP cs.SY</categories><comments>15 pages, 12 figures, submitted to IEEE TSP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a non-parametric method for state estimation of
high-dimensional nonlinear stochastic dynamical systems, which evolve according
to gradient flows with isotropic diffusion. We combine diffusion maps, a
manifold learning technique, with a linear Kalman filter and with concepts from
Koopman operator theory. More concretely, using diffusion maps, we construct
data-driven virtual state coordinates, which linearize the system model. Based
on these coordinates, we devise a data-driven framework for state estimation
using the Kalman filter. We demonstrate the strengths of our method with
respect to both parametric and non-parametric algorithms in three tracking
problems. In particular, applying the approach to actual recordings of
hippocampal neural activity in rodents directly yields a representation of the
position of the animals. We show that the proposed method outperforms competing
non-parametric algorithms in the examined stochastic problem formulations.
Additionally, we obtain results comparable to classical parametric algorithms,
which, in contrast to our method, are equipped with model knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.09776</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.09776</id><created>2017-11-24</created><authors><author><keyname>Saiga</keyname><forenames>Rino</forenames></author><author><keyname>Takeuchi</keyname><forenames>Akihisa</forenames></author><author><keyname>Uesugi</keyname><forenames>Kentaro</forenames></author><author><keyname>Terada</keyname><forenames>Yasuko</forenames></author><author><keyname>Suzuki</keyname><forenames>Yoshio</forenames></author><author><keyname>Mizutani</keyname><forenames>Ryuta</forenames></author></authors><title>Method for estimating modulation transfer function from sample images</title><categories>eess.IV physics.data-an</categories><comments>16 pages, 4 figures</comments><journal-ref>Micron 105, 64-69 (2018)</journal-ref><doi>10.1016/j.micron.2017.11.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modulation transfer function (MTF) represents the frequency domain
response of imaging modalities. Here, we report a method for estimating the MTF
from sample images. Test images were generated from a number of images,
including those taken with an electron microscope and with an observation
satellite. These original images were convolved with point spread functions
(PSFs) including those of circular apertures. The resultant test images were
subjected to a Fourier transformation. The logarithm of the squared norm of the
Fourier transform was plotted against the squared distance from the origin.
Linear correlations were observed in the logarithmic plots, indicating that the
PSF of the test images can be approximated with a Gaussian. The MTF was then
calculated from the Gaussian-approximated PSF. The obtained MTF closely
coincided with the MTF predicted from the original PSF. The MTF of an x-ray
microtomographic section of a fly brain was also estimated with this method.
The obtained MTF showed good agreement with the MTF determined from an edge
profile of an aluminum test object. We suggest that this approach is an
alternative way of estimating the MTF, independently of the image type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10025</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10025</id><created>2017-11-27</created><updated>2018-01-23</updated><authors><author><keyname>Tong</keyname><forenames>Sibo</forenames></author><author><keyname>Garner</keyname><forenames>Philip N.</forenames></author><author><keyname>Bourlard</keyname><forenames>Herv&#xe9;</forenames></author></authors><title>Multilingual Training and Cross-lingual Adaptation on CTC-based Acoustic
  Model</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multilingual models for Automatic Speech Recognition (ASR) are attractive as
they have been shown to benefit from more training data, and better lend
themselves to adaptation to under-resourced languages. However, initialisation
from monolingual context-dependent models leads to an explosion of
context-dependent states. Connectionist Temporal Classification (CTC) is a
potential solution to this as it performs well with monophone labels.
  We investigate multilingual CTC in the context of adaptation and
regularisation techniques that have been shown to be beneficial in more
conventional contexts. The multilingual model is trained to model a universal
International Phonetic Alphabet (IPA)-based phone set using the CTC loss
function. Learning Hidden Unit Contribution (LHUC) is investigated to perform
language adaptive training. In addition, dropout during cross-lingual
adaptation is also studied and tested in order to mitigate the overfitting
problem.
  Experiments show that the performance of the universal phoneme-based CTC
system can be improved by applying LHUC and it is extensible to new phonemes
during cross-lingual adaptation. Updating all the parameters shows consistent
improvement on limited data. Applying dropout during adaptation can further
improve the system and achieve competitive performance with Deep Neural Network
/ Hidden Markov Model (DNN/HMM) systems on limited data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10067</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10067</id><created>2017-11-27</created><updated>2018-05-22</updated><authors><author><keyname>Jin</keyname><forenames>Xiaojie</forenames></author><author><keyname>Yang</keyname><forenames>Yingzhen</forenames></author><author><keyname>Xu</keyname><forenames>Ning</forenames></author><author><keyname>Yang</keyname><forenames>Jianchao</forenames></author><author><keyname>Jojic</keyname><forenames>Nebojsa</forenames></author><author><keyname>Feng</keyname><forenames>Jiashi</forenames></author><author><keyname>Yan</keyname><forenames>Shuicheng</forenames></author></authors><title>WSNet: Compact and Efficient Networks Through Weight Sampling</title><categories>cs.CV cs.NE cs.SD eess.AS</categories><comments>To appear at ICML 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new approach and a novel architecture, termed WSNet, for
learning compact and efficient deep neural networks. Existing approaches
conventionally learn full model parameters independently and then compress them
via ad hoc processing such as model pruning or filter factorization.
Alternatively, WSNet proposes learning model parameters by sampling from a
compact set of learnable parameters, which naturally enforces {parameter
sharing} throughout the learning process. We demonstrate that such a novel
weight sampling approach (and induced WSNet) promotes both weights and
computation sharing favorably. By employing this method, we can more
efficiently learn much smaller networks with competitive performance compared
to baseline networks with equal numbers of convolution filters. Specifically,
we consider learning compact and efficient 1D convolutional neural networks for
audio classification. Extensive experiments on multiple audio classification
datasets verify the effectiveness of WSNet. Combined with weight quantization,
the resulted models are up to 180 times smaller and theoretically up to 16
times faster than the well-established baselines, without noticeable
performance drop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10084</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10084</id><created>2017-11-27</created><authors><author><keyname>Nazare</keyname><forenames>Thalita E.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>Erivelton G.</forenames></author><author><keyname>Paiva</keyname><forenames>Bruno P. O.</forenames></author></authors><title>On the Constructing Bifurcation Diagram of the Quadratic Map With
  Floating-Point Arithmetic</title><categories>eess.SP</categories><comments>6th International Conference on Nonlinear Dynamics, Chaos, Control
  and Applications (ICONNE 2017). Curitiba - Brazil. 6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an analysis on the effects of floating-point arithmetic
on the constructing bifurcation diagram of the quadratic map. More precisely,
we are interested in showing the dependence of initial conditions to obtain
some specific features of the diagram. With this study, it was possible to
observe that when there is a restriction regarding the initial condition, the
results present aspects with significant differences of the ones found in the
literature regarding the behaviour of the map, consequently there is a
considerable modification in its bifurcation diagram. We show that these
difference are related to floating-point arithmetic
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10107</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10107</id><created>2017-11-27</created><authors><author><keyname>Lu</keyname><forenames>Jingyang</forenames></author><author><keyname>Li</keyname><forenames>Lun</forenames></author><author><keyname>Chen</keyname><forenames>Genshe</forenames></author><author><keyname>Shen</keyname><forenames>Dan</forenames></author><author><keyname>Pham</keyname><forenames>Khanh</forenames></author><author><keyname>Blasch</keyname><forenames>Erik</forenames></author></authors><title>Machine Learning based Intelligent Cognitive Network using Fog Computing</title><categories>eess.SP</categories><doi>10.1117/12.2266563</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a Cognitive Radio Network (CRN) based on artificial
intelligence is proposed to distribute the limited radio spectrum resources
more efficiently. The CRN framework can analyze the time-sensitive signal data
close to the signal source using fog computing with different types of machine
learning techniques. Depending on the computational capabilities of the fog
nodes, different features and machine learning techniques are chosen to
optimize spectrum allocation. Also, the computing nodes send the periodic
signal summary which is much smaller than the original signal to the cloud so
that the overall system spectrum source allocation strategies are dynamically
updated. Applying fog computing, the system is more adaptive to the local
environment and robust to spectrum changes. As most of the signal data is
processed at the fog level, it further strengthens the system security by
reducing the communication burden of the communications network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10153</identifier>
 <datestamp>2018-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10153</id><created>2017-11-28</created><updated>2018-09-11</updated><authors><author><keyname>Selvaratnam</keyname><forenames>Daniel D.</forenames></author><author><keyname>Shames</keyname><forenames>Iman</forenames></author><author><keyname>Manton</keyname><forenames>Jonathan H.</forenames></author><author><keyname>Ristic</keyname><forenames>Branko</forenames></author></authors><title>Source Localisation Using Binary Measurements</title><categories>eess.SP</categories><comments>17 pages, 4 Figures, Submitted to IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of localising a stationary signal source
using a team of mobile agents which only take binary measurements. Background
false detection rates and missed detection probabilities are incorporated into
the framework. A Bayesian estimation algorithm that discretises the search
environment is employed, and analytical convergence and consistency results for
this are derived. Fisher Information is then used as a metric for the design of
optimal agent geometries. Knowledge of the probability of detection as a
function of the source and agent locations is assumed in the analysis, with
special attention given to range-dependent functions. The behaviour of the
algorithm under inexact knowledge of the probability of detection is also
analysed. Finally, simulation results are presented to demonstrate the
effectiveness of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10271</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10271</id><created>2017-11-28</created><authors><author><keyname>Paraschiv</keyname><forenames>Marius</forenames></author><author><keyname>Borgholt</keyname><forenames>Lasse</forenames></author><author><keyname>Tax</keyname><forenames>Tycho Max Sylvester</forenames></author><author><keyname>Singh</keyname><forenames>Marco</forenames></author><author><keyname>Maal&#xf8;e</keyname><forenames>Lars</forenames></author></authors><title>Exploiting Nontrivial Connectivity for Automatic Speech Recognition</title><categories>cs.SD eess.AS stat.ML</categories><comments>Accepted at the ML4Audio workshop at the NIPS 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nontrivial connectivity has allowed the training of very deep networks by
addressing the problem of vanishing gradients and offering a more efficient
method of reusing parameters. In this paper we make a comparison between
residual networks, densely-connected networks and highway networks on an image
classification task. Next, we show that these methodologies can easily be
deployed into automatic speech recognition and provide significant improvements
to existing models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10282</identifier>
 <datestamp>2018-03-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10282</id><created>2017-11-28</created><updated>2018-02-28</updated><authors><author><keyname>Tokozume</keyname><forenames>Yuji</forenames></author><author><keyname>Ushiku</keyname><forenames>Yoshitaka</forenames></author><author><keyname>Harada</keyname><forenames>Tatsuya</forenames></author></authors><title>Learning from Between-class Examples for Deep Sound Recognition</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>13 pages, 6 figures, published as a conference paper at ICLR 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning methods have achieved high performance in sound recognition
tasks. Deciding how to feed the training data is important for further
performance improvement. We propose a novel learning method for deep sound
recognition: Between-Class learning (BC learning). Our strategy is to learn a
discriminative feature space by recognizing the between-class sounds as
between-class sounds. We generate between-class sounds by mixing two sounds
belonging to different classes with a random ratio. We then input the mixed
sound to the model and train the model to output the mixing ratio. The
advantages of BC learning are not limited only to the increase in variation of
the training data; BC learning leads to an enlargement of Fisher's criterion in
the feature space and a regularization of the positional relationship among the
feature distributions of the classes. The experimental results show that BC
learning improves the performance on various sound recognition networks,
datasets, and data augmentation schemes, in which BC learning proves to be
always beneficial. Furthermore, we construct a new deep sound recognition
network (EnvNet-v2) and train it with BC learning. As a result, we achieved a
performance surpasses the human level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10353</identifier>
 <datestamp>2018-09-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10353</id><created>2017-11-28</created><updated>2018-04-10</updated><authors><author><keyname>Ioannidis</keyname><forenames>Vassilis N.</forenames></author><author><keyname>Ma</keyname><forenames>Meng</forenames></author><author><keyname>Nikolakopoulos</keyname><forenames>Athanasios N.</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author><author><keyname>Romero</keyname><forenames>Daniel</forenames></author></authors><title>Kernel-based Inference of Functions over Graphs</title><categories>stat.ML cs.LG eess.SP</categories><comments>To be published as a chapter in `Adaptive Learning Methods for
  Nonlinear System Modeling', Elsevier Publishing, Eds. D. Comminiello and J.C.
  Principe (2018). This chapter surveys recent work on kernel-based inference
  of functions over graphs including arXiv:1612.03615 and arXiv:1605.07174 and
  arXiv:1711.09306</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of networks has witnessed an explosive growth over the past decades
with several ground-breaking methods introduced. A particularly interesting --
and prevalent in several fields of study -- problem is that of inferring a
function defined over the nodes of a network. This work presents a versatile
kernel-based framework for tackling this inference problem that naturally
subsumes and generalizes the reconstruction approaches put forth recently by
the signal processing on graphs community. Both the static and the dynamic
settings are considered along with effective modeling approaches for addressing
real-world problems. The herein analytical discussion is complemented by a set
of numerical examples, which showcase the effectiveness of the presented
techniques, as well as their merits related to state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10538</identifier>
 <datestamp>2019-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10538</id><created>2017-11-28</created><updated>2018-01-20</updated><authors><author><keyname>Khalili</keyname><forenames>Ata</forenames></author><author><keyname>Akhlaghi</keyname><forenames>Soroush</forenames></author></authors><title>Power Control and Scheduling In Low SNR Region In The Uplink of Two Cell
  Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted in Journal of Communication Engineering with manuscript ID:
  JCE-1709-1066 (R1)</comments><doi>10.22070/JCE.2018.2810.1066</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the sub-channel assignment and power control to
maximize the total sum rate in the uplink of two-cell network. It is assumed
that there are some sub-channels in each cell which should be allocated among
some users. Also, each user is subjected to a power constraint. The underlying
problem is a non-convex mixed integer non-linear optimization problem which
does not have a trivial solution. To solve the problem, having fixed the
consumed power of each user, and assuming low co-channel interference region,
the sub-channel allocation problem is reformulate into a more mathematically
tractable problem which is shown can be tackled through the so-called Hungarian
algorithm. Then, the consumed power of each user is reformulated as a quadratic
fractional problem which can be numerically derived. Numerical results
demonstrate the superiority of the proposed method in low SNR region as
compared to existing works addressed in the literature
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10556</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10556</id><created>2017-11-10</created><authors><author><keyname>Chen</keyname><forenames>Ziyang</forenames></author><author><keyname>Shikh-Bahaei</keyname><forenames>Tamanna</forenames></author><author><keyname>Shikh-Bahaei</keyname><forenames>Mohammad</forenames></author></authors><title>Edge Computing and Dynamic Vision Sensing for Low Delay Access to Visual
  Medical Information</title><categories>cs.DC eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new method is proposed to decrease the transmission delay of visual and
non-visual medical records by using edge computing and Dynamic Vision Sensing
(DVS) technologies. The simulation results show that the proposed scheme can
decrease the transmission delay by 89.15% to 93.23%. The maximum number of
patients who can be served by edge devices is analysed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10686</identifier>
 <datestamp>2018-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10686</id><created>2017-11-29</created><updated>2018-04-13</updated><authors><author><keyname>Wang</keyname><forenames>Mao</forenames></author></authors><title>Practical Synchronization Waveform for Massive
  Machine-Type-Communications</title><categories>eess.SP</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general synchronization waveform type that is insensitive to frequency
error for massive Internet-of-Things (mIoT) is derived in &quot;Robust
synchronization waveform design for massive low-power IoT&quot; (IEEE Trans. on
Wireless Commun., vol. 16, no. 11, pp. 7551-7559, Nov. 2017). Detailed issues
such as (1) how to obtain the frequency error information from the waveform;
(2) how to refine the timing estimation; and (3) how to adjust the waveform
parameter to meet various spectral requirements are not addressed in the paper,
and yet are of great importance for a practical application. These issues are
discussed in this comment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10710</identifier>
 <datestamp>2020-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10710</id><created>2017-11-29</created><authors><author><keyname>Chen</keyname><forenames>Zhijie</forenames></author><author><keyname>Mohammed</keyname><forenames>Hoshyar</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author></authors><title>Proactive Caching for Energy-Efficiency in Wireless Networks: A Markov
  Decision Process Approach</title><categories>eess.SP</categories><comments>6 pages, 6 figures, submitted to IEEE International Conference on
  Communications 2018</comments><doi>10.1109/ICC.2018.8422143</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Content caching in wireless networks provides a substantial opportunity to
trade off low cost memory storage with energy consumption, yet finding the
optimal causal policy with low computational complexity remains a challenge.
This paper models the Joint Pushing and Caching (JPC) problem as a Markov
Decision Process (MDP) and provides a solution to determine the optimal
randomized policy. A novel approach to decouple the influence from buffer
occupancy and user requests is proposed to turn the high-dimensional
optimization problem into three low-dimensional ones. Furthermore, a
non-iterative algorithm to solve one of the sub-problems is presented,
exploiting a structural property we found as \textit{generalized monotonicity},
and hence significantly reduces the computational complexity. The result
attains close performance in comparison with theoretical bounds from
non-practical policies, while benefiting from higher time efficiency than the
unadapted MDP solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10739</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10739</id><created>2017-11-29</created><authors><author><keyname>Wei</keyname><forenames>Chao</forenames></author><author><keyname>Zhang</keyname><forenames>Zaichen</forenames></author></authors><title>Performance Analysis of Massive MIMO with Low-Resolution ADCs</title><categories>eess.SP</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The uplink performance of massive multiple-input-multiple-output (MIMO)
systems where the base stations (BS) employ low-resolution analog-to-digital
converters (ADCs) is analyzed. A high performance MMSE receiver that takes both
additive white Gaussian noise (AWGN) and quantization noise into consideration
is designed, which works well for both cases of uniform resolution ADCs and
non-uniform resolution ADCs. With the proposed MMSE receiver, we then employ
the random matrix theory to derive the asymptotic equivalent of the uplink
spectral efficiency (SE) of the system. Numerical results show the tightness of
the asymptotic equivalent of the uplink SE, and massive MIMO with
low-resolution ADCs can still achieve the satisfying uplink SE by increasing
the number of antennas at BS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10746</identifier>
 <datestamp>2019-04-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10746</id><created>2017-11-29</created><authors><author><keyname>Martin</keyname><forenames>Charles P.</forenames></author><author><keyname>Torresen</keyname><forenames>Jim</forenames></author></authors><title>RoboJam: A Musical Mixture Density Network for Collaborative Touchscreen
  Interaction</title><categories>cs.HC cs.NE cs.SD eess.AS</categories><journal-ref>Computational Intelligence in Music, Sound, Art and Design.
  EvoMUSART 2018. Lecture Notes in Computer Science, vol 10783</journal-ref><doi>10.1007/978-3-319-77583-8_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  RoboJam is a machine-learning system for generating music that assists users
of a touchscreen music app by performing responses to their short
improvisations. This system uses a recurrent artificial neural network to
generate sequences of touchscreen interactions and absolute timings, rather
than high-level musical notes. To accomplish this, RoboJam's network uses a
mixture density layer to predict appropriate touch interaction locations in
space and time. In this paper, we describe the design and implementation of
RoboJam's network and how it has been integrated into a touchscreen music app.
A preliminary evaluation analyses the system in terms of training, musical
generation and user interaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10788</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10788</id><created>2017-11-29</created><authors><author><keyname>Zhang</keyname><forenames>Fan</forenames></author><author><keyname>Wu</keyname><forenames>Qiong</forenames></author><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Shi</keyname><forenames>Yuanming</forenames></author></authors><title>$L_2$-Box Optimization for Green Cloud-RAN via Network Adaptation</title><categories>eess.SP</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a reformulation for the Mixed Integer Programming
(MIP) problem into an exact and continuous model through using the $\ell_2$-box
technique to recast the binary constraints into a box with an $\ell_2$ sphere
constraint. The reformulated problem can be tackled by a dual ascent algorithm
combined with a Majorization-Minimization (MM) method for the subproblems to
solve the network power consumption problem of the Cloud Radio Access Network
(Cloud-RAN), and which leads to solving a sequence of Difference of Convex (DC)
subproblems handled by an inexact MM algorithm. After obtaining the final
solution, we use it as the initial result of the bi-section Group Sparse
Beamforming (GSBF) algorithm to promote the group-sparsity of beamformers,
rather than using the weighted $\ell_1 / \ell_2$-norm. Simulation results
indicate that the new method outperforms the bi-section GSBF algorithm by
achieving smaller network power consumption, especially in sparser cases, i.e.,
Cloud-RANs with a lot of Remote Radio Heads (RRHs) but fewer users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10858</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10858</id><created>2017-11-29</created><authors><author><keyname>Hameed</keyname><forenames>Nauman</forenames></author><author><keyname>Mehmood</keyname><forenames>Tayyab</forenames></author><author><keyname>Qasim</keyname><forenames>Anisa</forenames></author></authors><title>Parametric Investigation Of Different Modulation Techniques On Free
  Space Optical Systems</title><categories>eess.SP</categories><comments>5 Pages, 8 Figures, 2014 12th International Conference on Frontiers
  of Information Technology (FIT), Islamabad, Pakistan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Free Space Optics systems (FSO) is one of the evolving wireless technologies.
FSO is the only technology with highest data rates in wireless mode of
operation but it suffers from bad weather conditions. In this work, analysis is
carried out on FSO system having certain parameters constant using different
modulation formats (i.e. RZ, NRZ, MDRZ, MODB and CSRZ). Impact of data rate,
link range, input power and attenuation factor has been computed. Weather
conditions are supposed to be nearly clear and suitable for FSO communication
while taking attenuation factor up to 10dB/Km. Q-factor, received signal power
and BER is calculated in all scenarios for obtaining an estimate of system
performance. Results have shown that NRZ &amp; RZ formats are in the lead until now
with highest Q values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10864</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10864</id><created>2017-11-29</created><authors><author><keyname>Mehmood</keyname><forenames>Tayyab</forenames></author><author><keyname>Hameed</keyname><forenames>Nauman</forenames></author></authors><title>Modeling and Performance Analysis of 10 Gbps Inter-Satellite-Link (ISL)
  In Inter-Satellite Optical-Wireless Communication (IsOWC) System between LEO
  and GEO Satellites</title><categories>eess.SP</categories><comments>4 Pages, 6 Figures, 2014 IEEE 17th International Multi-Topic
  Conference (INMIC), Karachi, Pakistan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Free space optical communication has merged the aspects of fiber optics and
the wireless communication which are the most conquered and controlled
telecommunication technologies. Most of the features of free space optics (FSO)
are interrelated to fiber optics but the difference between them is
transmission medium, which is glass in case of fiber-optics and air/vacuum in
case of FSO. In the near future, communication between LEO &amp; GEO satellites
with each other which are orbiting the Earth will be done by using
inter-satellite optical wireless communication (IsOWC) systems. IsOWC systems
is the most significant application of the FSO and it will be installed in the
space in the near future because of its low input power, no licensing by ITU,
low cost, light weight, small size of the telescopes and very high data rates
as compared to the radio frequency (RF) satellite systems. In this research
article, IsOWC system is designed between LEO and GEO satellites by using
optisystem which is not stated in past examined research works. Inter-satellite
link is established between satellites which are separated by the distance of
40,000 Km at the bit rate of 10 Gbps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10869</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10869</id><created>2017-11-29</created><authors><author><keyname>Hameed</keyname><forenames>Nauman</forenames></author><author><keyname>Mehmood</keyname><forenames>Tayyab</forenames></author><author><keyname>Manzoor</keyname><forenames>Habib Ullah</forenames></author></authors><title>Effect of Weather Conditions on FSO link based in Islamabad</title><categories>eess.SP</categories><comments>4 Pages, 7 Figures, 2014 IEEE 17th International Multi-Topic
  Conference (INMIC), Karachi, Pakistan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Free space optics (FSO) is a field of curiosity and importance for the
scientists because of its numerous applications and advantages like low cost
FSO systems, easy deployment, high data rate, secure FSO links and license free
bands. Very high bandwidth FSO link can be effectively established between the
skyscrapers of the Islamabad Pakistan for the purpose high capacity
applications in these skyscrapers. FSO links are badly affected by the weather
conditions especially rain and fog because of high attenuation factors.
optisystem is used to study the effect of rain and fog on the performance of
FSO links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10882</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10882</id><created>2017-10-26</created><authors><author><keyname>Hossain</keyname><forenames>Md. Sakir</forenames></author><author><keyname>Samad</keyname><forenames>Md Abdus</forenames></author></authors><title>The Tropospheric Scintillation Prediction based on measured data for
  earth-to-satellite link for Bangladeshi climatic condition</title><categories>eess.SP physics.ao-ph</categories><comments>Serbian Journal of Electrical Engineering, Vol 12, Issue 03, 2015</comments><doi>10.2298/SJEE1503263H</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of earth-to-satellite link largely depends on various
environmental factors like rain, fog, cloud, and atmospheric effects like
ionospheric and tropospheric scintillation. In this paper, the tropospheric
scintillation of Bangladesh, a subtropical country, is predicted based on
measured climatic parameters, like relative humidity, temperature. In this
prediction, ITU scintillation model are used. Four major cities, named Dhaka,
Chittagong, Rajshahi and Sylhet, of Bangladesh are selected for prediction of
scintillation. From the simulation result, Rajshahi is found to be the most
badly affected region by the scintillation fade depth (SFD), which is followed
by Chittagong and the SFD is minimum in Dhaka and Sylhet. The difference in
SFDs among the considered cities does not vary heavily. It is also found that
the SFD varies from 3 dB to 13 dB depending on the frequency in used. Moreover,
higher scintillation is found in rainy season of Bangladesh. During this
period, the scintillation becomes double of the average figure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.10958</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.10958</id><created>2017-11-29</created><authors><author><keyname>Arcas</keyname><forenames>Blaise Ag&#xfc;era y</forenames></author><author><keyname>Gfeller</keyname><forenames>Beat</forenames></author><author><keyname>Guo</keyname><forenames>Ruiqi</forenames></author><author><keyname>Kilgour</keyname><forenames>Kevin</forenames></author><author><keyname>Kumar</keyname><forenames>Sanjiv</forenames></author><author><keyname>Lyon</keyname><forenames>James</forenames></author><author><keyname>Odell</keyname><forenames>Julian</forenames></author><author><keyname>Ritter</keyname><forenames>Marvin</forenames></author><author><keyname>Roblek</keyname><forenames>Dominik</forenames></author><author><keyname>Sharifi</keyname><forenames>Matthew</forenames></author><author><keyname>Velimirovi&#x107;</keyname><forenames>Mihajlo</forenames></author></authors><title>Now Playing: Continuous low-power music recognition</title><categories>cs.SD cs.AI eess.AS</categories><comments>Authors are listed in alphabetical order by last name</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing music recognition applications require a connection to a server that
performs the actual recognition. In this paper we present a low-power music
recognizer that runs entirely on a mobile device and automatically recognizes
music without user interaction. To reduce battery consumption, a small music
detector runs continuously on the mobile device's DSP chip and wakes up the
main application processor only when it is confident that music is present.
Once woken, the recognizer on the application processor is provided with a few
seconds of audio which is fingerprinted and compared to the stored fingerprints
in the on-device fingerprint database of tens of thousands of songs. Our
presented system, Now Playing, has a daily battery usage of less than 1% on
average, respects user privacy by running entirely on-device and can passively
recognize a wide range of music.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11017</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11017</id><created>2017-11-29</created><authors><author><keyname>Brodeur</keyname><forenames>Simon</forenames></author><author><keyname>Perez</keyname><forenames>Ethan</forenames></author><author><keyname>Anand</keyname><forenames>Ankesh</forenames></author><author><keyname>Golemo</keyname><forenames>Florian</forenames></author><author><keyname>Celotti</keyname><forenames>Luca</forenames></author><author><keyname>Strub</keyname><forenames>Florian</forenames></author><author><keyname>Rouat</keyname><forenames>Jean</forenames></author><author><keyname>Larochelle</keyname><forenames>Hugo</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author></authors><title>HoME: a Household Multimodal Environment</title><categories>cs.AI cs.CL cs.CV cs.RO cs.SD eess.AS</categories><comments>Presented at NIPS 2017's Visually-Grounded Interaction and Language
  Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce HoME: a Household Multimodal Environment for artificial agents
to learn from vision, audio, semantics, physics, and interaction with objects
and other agents, all within a realistic context. HoME integrates over 45,000
diverse 3D house layouts based on the SUNCG dataset, a scale which may
facilitate learning, generalization, and transfer. HoME is an open-source,
OpenAI Gym-compatible platform extensible to tasks in reinforcement learning,
language grounding, sound-based navigation, robotics, multi-agent learning, and
more. We hope HoME better enables artificial agents to learn as humans do: in
an interactive, multimodal, and richly contextualized setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11121</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11121</id><created>2017-11-29</created><authors><author><keyname>Evirgen</keyname><forenames>Noyan</forenames></author><author><keyname>Kose</keyname><forenames>Alper</forenames></author></authors><title>Meeting of Mobile Nodes Based on RSS Measurements in Wireless Ad Hoc
  Networks</title><categories>eess.SP</categories><comments>This paper has been submitted to IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we address a completely novel case which is the meeting problem
of mobile nodes (players) in a wireless ad hoc network. We assume that the only
information players have is the received signal strength (RSS) measurements of
other players and there is no centralized communication. Each node has a
different frequency band and they try to meet with each other in a
decentralized manner. We consider the case where players are allowed to move in
four orthogonal directions in a grid. Then, we use multi-armed bandit approach
to give rewards in the end of every move that players do using RSS
measurements. Taking into account that we have an adversarial setting, we
propose different algorithms to solve the meeting problem. We start with
considering two players and then extend the work to multiplayer by considering
multiplayer problem as multiple two player problems. Throughout the paper, we
construct mathematical bounds on meeting times and related concepts and
evaluate the simulation results in the end.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11137</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11137</id><created>2017-11-29</created><authors><author><keyname>Azad</keyname><forenames>Md Khurshidul</forenames></author><author><keyname>Taebi</keyname><forenames>Amirtaha</forenames></author><author><keyname>Mansy</keyname><forenames>Joseph H</forenames></author><author><keyname>Mansy</keyname><forenames>HA</forenames></author></authors><title>Pressure Loss and Sound Generated In a Miniature Pig Airway Tree Model</title><categories>eess.SP</categories><journal-ref>Journal of Applied Biotechnology &amp; Bioengineering 3 (2017) 00086</journal-ref><doi>10.15406/jabb.2017.03.00086</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: Pulmonary auscultation is a common tool for diagnosing various
respiratory diseases. Previous studies have documented many details of
pulmonary sounds in humans. However, information on sound generation and
pressure loss inside animal airways is scarce. Since the morphology of animal
airways can be significantly different from human, the characteristics of
pulmonary sounds and pressure loss inside animal airways can be different.
Objective: The objective of this study is to investigate the sound and static
pressure loss measured at the trachea of a miniature pig airway tree model
based on the geometric details extracted from physical measurements. Methods:
In the current study, static pressure loss and sound generation measured in the
trachea was documented at different flow rates of a miniature pig airway tree.
Results: Results showed that the static pressure and the amplitude of the
recorded sound at the trachea increased as the flow rate increased. The
dominant frequency was found to be around 1840-1870 Hz for flow rates of
0.2-0.55 lit/s. Conclusion: The results suggested that the dominant frequency
of the measured sounds remained similar for flow rates from 0.20 to 0.55 lit/s.
Further investigation is needed to study sound generation under different inlet
flow and pulsatile flow conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11138</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11138</id><created>2017-11-29</created><authors><author><keyname>Taebi</keyname><forenames>Amirtaha</forenames></author><author><keyname>Mansy</keyname><forenames>Hansen A</forenames></author></authors><title>Analysis of Seismocardiographic Signals Using Polynomial Chirplet
  Transform and Smoothed Pseudo Wigner-Ville Distribution</title><categories>eess.SP</categories><journal-ref>Signal Processing in Medicine and Biology (2017) 1-6</journal-ref><doi>10.1109/SPMB.2017.8257022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seismocardiographic (SCG) signals are chest surface vibrations induced by
cardiac activity. These signals may offer a method for diagnosing and
monitoring heart function. Successful classification of SCG signals in health
and disease depends on accurate signal characterization and feature extraction.
One approach of determining signal features is to estimate its time-frequency
characteristics. In this regard, four different time-frequency distribution
(TFD) approaches were used including short-time Fourier transform (STFT),
polynomial chirplet transform (PCT), Wigner-Ville distribution (WVD), and
smoothed pseudo Wigner-Ville distribution (SPWVD). Synthetic SCG signals with
known time-frequency properties were generated and used to evaluate the
accuracy of the different TFDs in extracting SCG spectral characteristics.
Using different TFDs, the instantaneous frequency (IF) of each synthetic signal
was determined and the error (NRMSE) in estimating IF was calculated. STFT had
lower NRMSE than WVD for synthetic signals considered. PCT and SPWVD were,
however, more accurate IF estimators especially for the signal with
time-varying frequencies. PCT and SPWVD also provided better discrimination
between signal frequency components. Therefore, the results of this study
suggest that PCT and SPWVD would be more reliable methods for estimating IF of
SCG signals. Analysis of actual SCG signals showed that these signals had
multiple spectral components with slightly time-varying frequencies. More
studies are needed to investigate SCG spectral properties for healthy subjects
as well as patients with different cardiac conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11140</identifier>
 <datestamp>2018-03-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11140</id><created>2017-11-29</created><authors><author><keyname>Taebi</keyname><forenames>Amirtaha</forenames></author><author><keyname>Mansy</keyname><forenames>Hansen A</forenames></author></authors><title>Grouping Similar Seismocardiographic Signals Using Respiratory
  Information</title><categories>eess.SP</categories><journal-ref>Signal Processing in Medicine and Biology (2017) 1-6</journal-ref><doi>10.1109/SPMB.2017.8257053</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seismocardiography (SCG) offers a potential non-invasive method for cardiac
monitoring. Quantification of the effects of different physiological conditions
on SCG can lead to enhanced understanding of SCG genesis, and may explain how
some cardiac pathologies may affect SCG morphology. In this study, the effect
of the respiration on the SCG signal morphology is investigated. SCG, ECG, and
respiratory flow rate signals were measured simultaneously in 7 healthy
subjects. Results showed that SCG events tended to have two slightly different
morphologies. The respiratory flow rate and lung volume information were used
to group the SCG events into inspiratory/expiratory groups or low/high
lung-volume groups, respectively. Although respiratory flow information could
separate similar SCG events into two different groups, the lung volume
information provided better grouping of similar SCGs. This suggests that
variations in SCG morphology may be due, at least in part, to changes in the
intrathoracic pressure or heart location since those parameters correlates more
with lung volume than respiratory flow. Categorizing SCG events into different
groups containing similar events allows more accurate estimation of SCG
features, and better signal characterization, and classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11141</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11141</id><created>2017-11-29</created><authors><author><keyname>Wang</keyname><forenames>Xiaofei</forenames></author><author><keyname>Yan</keyname><forenames>Yonghong</forenames></author><author><keyname>Hermansky</keyname><forenames>Hynek</forenames></author></authors><title>Stream Attention for far-field multi-microphone ASR</title><categories>cs.SD cs.HC eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A stream attention framework has been applied to the posterior probabilities
of the deep neural network (DNN) to improve the far-field automatic speech
recognition (ASR) performance in the multi-microphone configuration. The stream
attention scheme has been realized through an attention vector, which is
derived by predicting the ASR performance from the phoneme posterior
distribution of individual microphone stream, focusing the recognizer's
attention to more reliable microphones. Investigation on the various ASR
performance measures has been carried out using the real recorded dataset.
Experiments results show that the proposed framework has yielded substantial
improvements in word error rate (WER).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11154</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11154</id><created>2017-11-29</created><authors><author><keyname>Lin</keyname><forenames>Shuoxin</forenames></author><author><keyname>Wu</keyname><forenames>Jiahao</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Shuvra S.</forenames></author></authors><title>Memory-constrained Vectorization and Scheduling of Dataflow Graphs for
  Hybrid CPU-GPU Platforms</title><categories>eess.SP</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing use of heterogeneous embedded systems with multi-core CPUs and
Graphics Processing Units (GPUs) presents important challenges in effectively
exploiting pipeline, task and data-level parallelism to meet throughput
requirements of digital signal processing (DSP) applications. Moreover, in the
presence of system-level memory constraints, hand optimization of code to
satisfy these requirements is inefficient and error-prone, and can therefore,
greatly slow down development time or result in highly underutilized processing
resources. In this paper, we present vectorization and scheduling methods to
effectively exploit multiple forms of parallelism for throughput optimization
on hybrid CPU-GPU platforms, while conforming to system-level memory
constraints. The methods operate on synchronous dataflow representations, which
are widely used in the design of embedded systems for signal and information
processing. We show that our novel methods can significantly improve system
throughput compared to previous vectorization and scheduling approaches under
the same memory constraints. In addition, we present a practical case-study of
applying our methods to significantly improve the throughput of an orthogonal
frequency division multiplexing (OFDM) receiver system for wireless
communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11215</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11215</id><created>2017-11-29</created><authors><author><keyname>Thrampoulidis</keyname><forenames>Christos</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Symbol Error Rate Performance of Box-relaxation Decoders in Massive MIMO</title><categories>eess.SP cs.IT math.IT</categories><doi>10.1109/TSP.2018.2831622</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The maximum-likelihood (ML) decoder for symbol detection in large
multiple-input multiple-output wireless communication systems is typically
computationally prohibitive. In this paper, we study a popular and practical
alternative, namely the Box-relaxation optimization (BRO) decoder, which is a
natural convex relaxation of the ML. For iid real Gaussian channels with
additive Gaussian noise, we obtain exact asymptotic expressions for the symbol
error rate (SER) of the BRO. The formulas are particularly simple, they yield
useful insights, and they allow accurate comparisons to the matched-filter
bound (MFB) and to the zero-forcing decoder. For BPSK signals the SER
performance of the BRO is within 3dB of the MFB for square systems, and it
approaches the MFB as the number of receive antennas grows large compared to
the number of transmit antennas. Our analysis further characterizes the
empirical density function of the solution of the BRO, and shows that error
events for any fixed number of symbols are asymptotically independent. The
fundamental tool behind the analysis is the convex Gaussian min-max theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11224</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11224</id><created>2017-11-29</created><authors><author><keyname>Yizhi</keyname><forenames>Song</forenames></author><author><keyname>Cheng</keyname><forenames>Xu</forenames></author><author><keyname>Daoxin</keyname><forenames>Ding</forenames></author><author><keyname>Hang</keyname><forenames>Zhou</forenames></author><author><keyname>Tingwei</keyname><forenames>Quan</forenames></author><author><keyname>Shiwei</keyname><forenames>Li</forenames></author></authors><title>Properties on n-dimensional convolution for image deconvolution</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolution system is linear and time invariant, and can describe the optical
imaging process. Based on convolution system, many deconvolution techniques
have been developed for optical image analysis, such as boosting the space
resolution of optical images, image denoising, image enhancement and so on.
Here, we gave properties on N-dimensional convolution. By using these
properties, we proposed image deconvolution method. This method uses a series
of convolution operations to deconvolute image. We demonstrated that the method
has the similar deconvolution results to the state-of-art method. The core
calculation of the proposed method is image convolution, and thus our method
can easily be integrated into GPU mode for large-scale image deconvolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11259</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11259</id><created>2017-11-30</created><authors><author><keyname>Gaultier</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>PANAMA</affiliation></author><author><keyname>Bertin</keyname><forenames>Nancy</forenames><affiliation>PANAMA</affiliation></author><author><keyname>Kiti&#x107;</keyname><forenames>Sr&#x111;an</forenames><affiliation>PANAMA</affiliation></author><author><keyname>Gribonval</keyname><forenames>R&#xe9;mi</forenames><affiliation>PANAMA</affiliation></author></authors><title>A modeling and algorithmic framework for (non)social (co)sparse audio
  restoration</title><categories>cs.SD eess.AS</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a unified modeling and algorithmic framework for audio restoration
problem. It encompasses analysis sparse priors as well as more classical
synthesis sparse priors, and regular sparsity as well as various forms of
structured sparsity embodied by shrinkage operators (such as social shrinkage).
The versatility of the framework is illustrated on two restoration scenarios:
denoising, and declipping. Extensive experimental results on these scenarios
highlight both the speedups of 20% or even more offered by the analysis sparse
prior, and the substantial declipping quality that is achievable with both the
social and the plain flavor. While both flavors overall exhibit similar
performance, their detailed comparison displays distinct trends depending
whether declipping or denoising is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11293</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11293</id><created>2017-11-30</created><updated>2017-12-20</updated><authors><author><keyname>Kaneko</keyname><forenames>Takuhiro</forenames></author><author><keyname>Kameoka</keyname><forenames>Hirokazu</forenames></author></authors><title>Parallel-Data-Free Voice Conversion Using Cycle-Consistent Adversarial
  Networks</title><categories>stat.ML cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a parallel-data-free voice-conversion (VC) method that can learn a
mapping from source to target speech without relying on parallel data. The
proposed method is general purpose, high quality, and parallel-data free and
works without any extra data, modules, or alignment procedure. It also avoids
over-smoothing, which occurs in many conventional statistical model-based VC
methods. Our method, called CycleGAN-VC, uses a cycle-consistent adversarial
network (CycleGAN) with gated convolutional neural networks (CNNs) and an
identity-mapping loss. A CycleGAN learns forward and inverse mappings
simultaneously using adversarial and cycle-consistency losses. This makes it
possible to find an optimal pseudo pair from unpaired data. Furthermore, the
adversarial loss contributes to reducing over-smoothing of the converted
feature sequence. We configure a CycleGAN with gated CNNs and train it with an
identity-mapping loss. This allows the mapping function to capture sequential
and hierarchical structures while preserving linguistic information. We
evaluated our method on a parallel-data-free VC task. An objective evaluation
showed that the converted feature sequence was near natural in terms of global
variance and modulation spectra. A subjective evaluation showed that the
quality of the converted speech was comparable to that obtained with a Gaussian
mixture model-based method under advantageous conditions with parallel and
twice the amount of data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11357</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11357</id><created>2017-11-30</created><authors><author><keyname>G.</keyname><forenames>Ranjani H.</forenames></author><author><keyname>Sreenivas</keyname><forenames>T. V.</forenames></author></authors><title>Raga Identification using Repetitive Note Patterns from prescriptive
  notations of Carnatic Music</title><categories>eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Carnatic music, a form of Indian Art Music, has relied on an oral tradition
for transferring knowledge across several generations. Over the last two
hundred years, the use of prescriptive notations has been adopted for learning,
sight-playing and sight-singing. Prescriptive notations offer generic
guidelines for a raga rendition and do not include information about the
ornamentations or the gamakas, which are considered to be critical for
characterizing a raga. In this paper, we show that prescriptive notations
contain raga attributes and can reliably identify a raga of Carnatic music from
its octave-folded prescriptive notations. We restrict the notations to 7 notes
and suppress the finer note position information. A dictionary based approach
captures the statistics of repetitive note patterns within a raga notation. The
proposed stochastic models of repetitive note patterns (or SMRNP in short)
obtained from raga notations of known compositions, outperforms the state of
the art melody based raga identification technique on an equivalent melodic
data corresponding to the same compositions. This in turn shows that for
Carnatic music, the note transitions and movements have a greater role in
defining the raga structure than the exact note positions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11386</identifier>
 <datestamp>2018-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11386</id><created>2017-11-30</created><updated>2018-12-19</updated><authors><author><keyname>Tezcan</keyname><forenames>Kerem C.</forenames></author><author><keyname>Baumgartner</keyname><forenames>Christian F.</forenames></author><author><keyname>Luechinger</keyname><forenames>Roger</forenames></author><author><keyname>Pruessmann</keyname><forenames>Klaas P.</forenames></author><author><keyname>Konukoglu</keyname><forenames>Ender</forenames></author></authors><title>MR image reconstruction using deep density priors</title><categories>cs.CV eess.IV stat.ML</categories><comments>Published in IEEE TMI. Main text and supplementary material, 19 pages
  total</comments><journal-ref>IEEE Transactions on Medical Imaging, December 2018</journal-ref><doi>10.1109/TMI.2018.2887072</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms for Magnetic Resonance (MR) image reconstruction from undersampled
measurements exploit prior information to compensate for missing k-space data.
Deep learning (DL) provides a powerful framework for extracting such
information from existing image datasets, through learning, and then using it
for reconstruction. Leveraging this, recent methods employed DL to learn
mappings from undersampled to fully sampled images using paired datasets,
including undersampled and corresponding fully sampled images, integrating
prior knowledge implicitly. In this article, we propose an alternative approach
that learns the probability distribution of fully sampled MR images using
unsupervised DL, specifically Variational Autoencoders (VAE), and use this as
an explicit prior term in reconstruction, completely decoupling the encoding
operation from the prior. The resulting reconstruction algorithm enjoys a
powerful image prior to compensate for missing k-space data without requiring
paired datasets for training nor being prone to associated sensitivities, such
as deviations in undersampling patterns used in training and test time or coil
settings. We evaluated the proposed method with T1 weighted images from a
publicly available dataset, multi-coil complex images acquired from healthy
volunteers (N=8) and images with white matter lesions. The proposed algorithm,
using the VAE prior, produced visually high quality reconstructions and
achieved low RMSE values, outperforming most of the alternative methods on the
same dataset. On multi-coil complex data, the algorithm yielded accurate
magnitude and phase reconstruction results. In the experiments on images with
white matter lesions, the method faithfully reconstructed the lesions.
  Keywords: Reconstruction, MRI, prior probability, machine learning, deep
learning, unsupervised learning, density estimation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11405</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11405</id><created>2017-11-30</created><updated>2018-07-28</updated><authors><author><keyname>Boroujerdi</keyname><forenames>Mahdi Nouri</forenames></author><author><keyname>Haghighatshoar</keyname><forenames>Saeid</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Low-Complexity Statistically Robust Precoder/Detector Computation for
  Massive MIMO Systems</title><categories>cs.IT eess.SP math.IT</categories><comments>to appear in \textit{IEEE Transactions on Wireless Communications}</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive MIMO is a variant of multiuser MIMO in which the number of antennas
at the base station (BS) $M$ is very large and typically much larger than the
number of served users (data streams) $K$. Recent research has illustrated the
system-level advantages of such a system and in particular the beneficial
effect of increasing the number of antennas $M$. These benefits, however, come
at the cost of dramatic increase in hardware and computational complexity. This
is partly due to the fact that the BS needs to compute suitable beamforming
vectors in order to coherently transmit/receive data to/from each user, where
the resulting complexity grows proportionally to the number of antennas $M$ and
the number of served users $K$. Recently, different algorithms based on tools
from random matrix theory in the asymptotic regime of $M,K \to \infty$ with
$\frac{K}{M} \to \rho \in (0,1)$ have been proposed to reduce such complexity.
The underlying assumption in all these techniques, however, is that the exact
statistics (covariance matrix) of the channel vectors of the users is a priori
known. This is far from being realistic, especially that in the high-dim regime
of $M\to \infty$, estimation of the underlying covariance matrices is well
known to be a very challenging problem.
  In this paper, we propose a novel technique for designing beamforming vectors
in a massive MIMO system. Our method is based on the randomized Kaczmarz
algorithm and does not require knowledge of the statistics of the users channel
vectors. We analyze the performance of our proposed algorithm theoretically and
compare its performance with that of other competitive techniques via numerical
simulations. Our results indicate that our proposed technique has a comparable
performance while it does not require the knowledge of the statistics of the
users channel vectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11407</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11407</id><created>2017-11-01</created><authors><author><keyname>Wang</keyname><forenames>Shaogang</forenames></author><author><keyname>Patel</keyname><forenames>Vishal M.</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina</forenames></author></authors><title>FPS-SFT: A Multi-dimensional Sparse Fourier Transform Based on the
  Fourier Projection-slice Theorem</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a multi-dimensional (M-D) sparse Fourier transform inspired by the
idea of the Fourier projection-slice theorem, called FPS-SFT. FPS-SFT extracts
samples along lines (1-dimensional slices from an M-D data cube), which are
parameterized by random slopes and offsets. The discrete Fourier transform
(DFT) along those lines represents projections of M-D DFT of the M-D data onto
those lines. The M-D sinusoids that are contained in the signal can be
reconstructed from the DFT along lines with a low sample and computational
complexity provided that the signal is sparse in the frequency domain and the
lines are appropriately designed. The performance of FPS-SFT is demonstrated
both theoretically and numerically. A sparse image reconstruction application
is illustrated, which shows the capability of the FPS-SFT in solving practical
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11413</identifier>
 <datestamp>2019-08-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11413</id><created>2017-11-29</created><updated>2019-08-21</updated><authors><author><keyname>Yu</keyname><forenames>Yi</forenames></author><author><keyname>Zhao</keyname><forenames>Haiquan</forenames></author><author><keyname>Chen</keyname><forenames>Badong</forenames></author><author><keyname>Wang</keyname><forenames>Wenyuan</forenames></author><author><keyname>Lu</keyname><forenames>Lu</forenames></author></authors><title>Mean-Square Performance Analysis of Noise-Robust Normalized Subband
  Adaptive Filter Algorithm</title><categories>eess.SP</categories><comments>7 pages,8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the statistical models of the noise-robust normalized
subband adaptive filter (NR-NSAF) algorithm in the mean and mean square
deviation senses involving transient-state and steady-state behavior by
resorting to the method of the vectorization operation and the Kronecker
product. The analysis method does not require the Gaussian input signal.
Moreover, the proposed analysis removes the paraunitary assumption imposed on
the analysis filter banks as in the existing analyses of subband adaptive
algorithms. Simulation results in various conditions demonstrate the
effectiveness of our theoretical analysis. For a special form of the algorithm,
the proposed steady-state expression is also better accurate than the previous
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11441</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11441</id><created>2017-11-29</created><authors><author><keyname>Ming</keyname><forenames>Hao</forenames></author><author><keyname>Xie</keyname><forenames>Le</forenames></author><author><keyname>Campi</keyname><forenames>Marco</forenames></author><author><keyname>Garatti</keyname><forenames>Simone</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>Scenario-based Economic Dispatch with Uncertain Demand Response</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new computational framework to account for
uncertainties in day-ahead electricity market clearing process in the presence
of demand response providers. A central challenge when dealing with many demand
response providers is the uncertainty of its realization. In this paper, a new
economic dispatch framework that is based on the recent theoretical development
of the scenario approach is introduced. By removing samples from a finite
uncertainty set, this approach improves dispatch performance while guaranteeing
a quantifiable risk level with respect to the probability of violating the
constraints. The theoretical bound on the level of risk is shown to be a
function of the number of scenarios removed. This is appealing to the system
operator for the following reasons: (1) the improvement of performance comes at
the cost of a quantifiable level of violation probability in the constraints;
(2) the violation upper bound does not depend on the probability distribution
assumption of the uncertainty in demand response. Numerical simulations on (1)
3-bus and (2) IEEE 14-bus system (3) IEEE 118-bus system suggest that this
approach could be a promising alternative in future electricity markets with
multiple demand response providers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11442</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11442</id><created>2017-11-29</created><authors><author><keyname>Zhang</keyname><forenames>Linyuan</forenames></author><author><keyname>Ding</keyname><forenames>Guoru</forenames></author><author><keyname>Wu</keyname><forenames>Qihui</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>Spectrum Sensing under Spectrum Misuse Behaviors: A Multi-Hypothesis
  Test Perspective</title><categories>eess.SP</categories><journal-ref>IEEE Transactions on Information Forensics and Security, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum misuse behaviors, brought either by illegitimate access or by rogue
power emission, endanger the legitimate communication and deteriorate the
spectrum usage environment. In this paper, our aim is to detect whether the
spectrum band is occupied, and if it is occupied, recognize whether the misuse
behavior exists. One vital challenge is that the legitimate spectrum
exploitation and misuse behaviors coexist and the illegitimate user may act in
an intermittent and fast-changing manner, which brings about much uncertainty
for spectrum sensing. To tackle it, we firstly formulate the spectrum sensing
problems under illegitimate access and rogue power emission as a uniform
ternary hypothesis test. Then, we develop a novel test criterion, named the
generalized multi-hypothesis N-P criterion. Following the criterion, we derive
two test rules based on the generalized likelihood ratio test and the R-test,
respectively, whose asymptotic performances are analyzed and an upper bound is
also given. Furthermore, a cooperative spectrum sensing scheme is designed
based on the global N-P criterion to further improve the detection
performances. In addition, extensive simulations are provided to verify the
proposed schemes' performance under various parameter configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11454</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11454</id><created>2017-11-29</created><authors><author><keyname>Imbiriba</keyname><forenames>Tales</forenames></author><author><keyname>Bermudez</keyname><forenames>Jos&#xe9; Carlos M.</forenames></author><author><keyname>Tourneret</keyname><forenames>Jean-Yves</forenames></author><author><keyname>Bershad</keyname><forenames>Neil J.</forenames></author></authors><title>Technical Report: A New Decision-Theory-Based Framework for Echo
  Canceler Control</title><categories>eess.SP cs.SY</categories><doi>10.1109/TSP.2018.2849748</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A control logic has a central role in many echo cancellation systems for
optimizing the performance of adaptive filters while estimating the echo path.
For reliable control, accurate double-talk (DT) and channel change (CC)
detectors are usually incorporated to the echo canceler. This work expands the
usual detection strategy to define a classification problem characterizing four
possible states of the echo canceler operation. The new formulation allow the
use of decision theory to continuously control the transitions among the
different modes of operation. The classification rule reduces to a low cost
statistics for which it is possible to determine the probability of error under
all hypotheses, allowing the classification performance to be accessed
analytically. Monte Carlo simulations using synthetic and real data illustrate
the reliability of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1711.11565</identifier>
 <datestamp>2018-09-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1711.11565</id><created>2017-11-30</created><updated>2018-02-26</updated><authors><author><keyname>He</keyname><forenames>Weipeng</forenames></author><author><keyname>Motlicek</keyname><forenames>Petr</forenames></author><author><keyname>Odobez</keyname><forenames>Jean-Marc</forenames></author></authors><title>Deep Neural Networks for Multiple Speaker Detection and Localization</title><categories>cs.SD cs.AI cs.MM cs.RO eess.AS</categories><comments>Accepted for ICRA 2018</comments><journal-ref>2018 IEEE International Conference on Robotics and Automation
  (ICRA), Brisbane, Australia, 2018, pp. 74-79</journal-ref><doi>10.1109/ICRA.2018.8461267</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose to use neural networks for simultaneous detection and localization
of multiple sound sources in human-robot interaction. In contrast to
conventional signal processing techniques, neural network-based sound source
localization methods require fewer strong assumptions about the environment.
Previous neural network-based methods have been focusing on localizing a single
sound source, which do not extend to multiple sources in terms of detection and
localization. In this paper, we thus propose a likelihood-based encoding of the
network output, which naturally allows the detection of an arbitrary number of
sources. In addition, we investigate the use of sub-band cross-correlation
information as features for better localization in sound mixtures, as well as
three different network architectures based on different motivations.
Experiments on real data recorded from a robot show that our proposed methods
significantly outperform the popular spatial spectrum-based approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00115</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00115</id><created>2017-11-30</created><authors><author><keyname>Yazdani</keyname><forenames>Hassan</forenames></author><author><keyname>Vosoughi</keyname><forenames>Azadeh</forenames></author></authors><title>On the Combined Effect of Directional Antennas and Imperfect Spectrum
  Sensing upon Ergodic Capacity of Cognitive Radio Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a cognitive radio system, consisting of a primary transmitter
(PUtx), a primary receiver (PUrx), a secondary transmitter (SUtx), and a
secondary receiver (SUrx). The secondary users (SUs) are equipped with
steerable directional antennas. We assume the SUs and primary users (PUs)
coexist and the SUtx knows the geometry of network. We find the ergodic
capacity of the channel between SUtx and SUrx , and study how spectrum sensing
errors affect the capacity. In our system, the SUtx first senses the spectrum
and then transmits data at two power levels, according to the result of
sensing. The optimal SUtx transmit power levels and the optimal directions of
SUtx transmit antenna and SUrx receive antenna are obtained by maximizing the
ergodic capacity, subject to average transmit power and average interference
power constraints. To study the effect of fading channel, we considered three
scenarios: 1) when SUtx knows fading channels between SUtx and PUrx, PUtx and
SUrx, SUtx and SUrx, 2) when SUtx knows only the channel between SUtx and SUrx,
and statistics of the other two channels, and, 3) when SUtx only knows the
statistics of these three fading channels. For each scenario, we explore the
optimal SUtx transmit power levels and the optimal directions of SUtx and SUrx
antennas, such that the ergodic capacity is maximized, while the power
constraints are satisfied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00122</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00122</id><created>2017-11-30</created><authors><author><keyname>Shirazi</keyname><forenames>Mojtaba</forenames></author><author><keyname>Sani</keyname><forenames>Alireza</forenames></author><author><keyname>Vosoughi</keyname><forenames>Azadeh</forenames></author></authors><title>Sensor Selection and Power Allocation via Maximizing Bayesian Fisher
  Information for Distributed Vector Estimation</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the problem of distributed estimation of a Gaussian
vector with linear observation model in a wireless sensor network (WSN)
consisting of K sensors that transmit their modulated quantized observations
over orthogonal erroneous wireless channels (subject to fading and noise) to a
fusion center, which estimates the unknown vector. Due to limited network
transmit power, only a subset of sensors can be active at each task period.
Here, we formulate the problem of sensor selection and transmit power
allocation that maximizes the trace of Bayesian Fisher Information Matrix (FIM)
under network transmit power constraint, and propose three algorithms to solve
it. Simulation results demonstrate the superiority of these algorithms compared
to the algorithm that uniformly allocates power among all sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00157</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00157</id><created>2017-11-30</created><updated>2018-01-02</updated><authors><author><keyname>Chung</keyname><forenames>Hye Won</forenames></author><author><keyname>Lee</keyname><forenames>Ji Oon</forenames></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames></author></authors><title>Fundamental Limits on Data Acquisition: Trade-offs between Sample
  Complexity and Query Difficulty</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider query-based data acquisition and the corresponding information
recovery problem, where the goal is to recover $k$ binary variables
(information bits) from parity measurements of those variables. The queries and
the corresponding parity measurements are designed using the encoding rule of
Fountain codes. By using Fountain codes, we can design potentially limitless
number of queries, and corresponding parity measurements, and guarantee that
the original $k$ information bits can be recovered with high probability from
any sufficiently large set of measurements of size $n$. In the query design,
the average number of information bits that is associated with one parity
measurement is called query difficulty ($\bar{d}$) and the minimum number of
measurements required to recover the $k$ information bits for a fixed $\bar{d}$
is called sample complexity ($n$). We analyze the fundamental trade-offs
between the query difficulty and the sample complexity, and show that the
sample complexity of $n=c\max\{k,(k\log k)/\bar{d}\}$ for some constant $c&gt;0$
is necessary and sufficient to recover $k$ information bits with high
probability as $k\to\infty$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00166</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00166</id><created>2017-11-30</created><authors><author><keyname>Chang</keyname><forenames>Sungkyun</forenames></author><author><keyname>Lee</keyname><forenames>Juheon</forenames></author><author><keyname>Choe</keyname><forenames>Sang Keun</forenames></author><author><keyname>Lee</keyname><forenames>Kyogu</forenames></author></authors><title>Audio Cover Song Identification using Convolutional Neural Network</title><categories>cs.SD cs.LG eess.AS</categories><comments>Workshop on ML4Audio: Machine Learning for Audio Signal Processing at
  NIPS 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new approach to cover song identification using a
CNN (convolutional neural network). Most previous studies extract the feature
vectors that characterize the cover song relation from a pair of songs and used
it to compute the (dis)similarity between the two songs. Based on the
observation that there is a meaningful pattern between cover songs and that
this can be learned, we have reformulated the cover song identification problem
in a machine learning framework. To do this, we first build the CNN using as an
input a cross-similarity matrix generated from a pair of songs. We then
construct the data set composed of cover song pairs and non-cover song pairs,
which are used as positive and negative training samples, respectively. The
trained CNN outputs the probability of being in the cover song relation given a
cross-similarity matrix generated from any two pieces of music and identifies
the cover song by ranking on the probability. Experimental results show that
the proposed algorithm achieves performance better than or comparable to the
state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00171</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00171</id><created>2017-11-30</created><updated>2017-12-04</updated><authors><author><keyname>Zhao</keyname><forenames>Wenbo</forenames></author><author><keyname>Gao</keyname><forenames>Yang</forenames></author><author><keyname>Singh</keyname><forenames>Rita</forenames></author></authors><title>Speaker identification from the sound of the human breath</title><categories>cs.SD eess.AS stat.ML</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the speaker identification potential of breath sounds in
continuous speech. Speech is largely produced during exhalation. In order to
replenish air in the lungs, speakers must periodically inhale. When inhalation
occurs in the midst of continuous speech, it is generally through the mouth.
Intra-speech breathing behavior has been the subject of much study, including
the patterns, cadence, and variations in energy levels. However, an often
ignored characteristic is the {\em sound} produced during the inhalation phase
of this cycle. Intra-speech inhalation is rapid and energetic, performed with
open mouth and glottis, effectively exposing the entire vocal tract to enable
maximum intake of air. This results in vocal tract resonances evoked by
turbulence that are characteristic of the speaker's speech-producing apparatus.
Consequently, the sounds of inhalation are expected to carry information about
the speaker's identity. Moreover, unlike other spoken sounds which are subject
to active control, inhalation sounds are generally more natural and less
affected by voluntary influences. The goal of this paper is to demonstrate that
breath sounds are indeed bio-signatures that can be used to identify speakers.
We show that these sounds by themselves can yield remarkably accurate speaker
recognition with appropriate feature representations and classification
frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00174</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00174</id><created>2017-11-30</created><authors><author><keyname>Wu</keyname><forenames>Chris</forenames></author><author><keyname>Tandon</keyname><forenames>Tanay</forenames></author></authors><title>Rapid point-of-care Hemoglobin measurement through low-cost optics and
  Convolutional Neural Network based validation</title><categories>physics.med-ph eess.IV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A low-cost, robust, and simple mechanism to measure hemoglobin would play a
critical role in the modern health infrastructure. Consistent sample
acquisition has been a long-standing technical hurdle for photometer-based
portable hemoglobin detectors which rely on micro cuvettes and dry chemistry.
Any particulates (e.g. intact red blood cells (RBCs), microbubbles, etc.) in a
cuvette's sensing area drastically impact optical absorption profile, and
commercial hemoglobinometers lack the ability to automatically detect faulty
samples. We present the ground-up development of a portable, low-cost and open
platform with equivalent accuracy to medical-grade devices, with the addition
of CNN-based image processing for rapid sample viability prechecks. The
developed platform has demonstrated precision to the nearest $0.18[g/dL]$ of
hemoglobin, an R^2 = 0.945 correlation to hemoglobin absorption curves reported
in literature, and a 97% detection accuracy of poorly-prepared samples. We see
the developed hemoglobin device/ML platform having massive implications in
rural medicine, and consider it an excellent springboard for robust deep
learning optical spectroscopy: a currently untapped source of data for
detection of countless analytes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00205</identifier>
 <datestamp>2018-10-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00205</id><created>2017-12-01</created><updated>2018-07-27</updated><authors><author><keyname>Kargas</keyname><forenames>Nikos</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nicholas D.</forenames></author><author><keyname>Fu</keyname><forenames>Xiao</forenames></author></authors><title>Tensors, Learning, and 'Kolmogorov Extension' for Finite-alphabet Random
  Vectors</title><categories>eess.SP cs.IT math.IT math.PR stat.ML</categories><doi>10.1109/TSP.2018.2862383</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating the joint probability mass function (PMF) of a set of random
variables lies at the heart of statistical learning and signal processing.
Without structural assumptions, such as modeling the variables as a Markov
chain, tree, or other graphical model, joint PMF estimation is often considered
mission impossible - the number of unknowns grows exponentially with the number
of variables. But who gives us the structural model? Is there a generic,
`non-parametric' way to control joint PMF complexity without relying on a
priori structural assumptions regarding the underlying probability model? Is it
possible to discover the operational structure without biasing the analysis up
front? What if we only observe random subsets of the variables, can we still
reliably estimate the joint PMF of all? This paper shows, perhaps surprisingly,
that if the joint PMF of any three variables can be estimated, then the joint
PMF of all the variables can be provably recovered under relatively mild
conditions. The result is reminiscent of Kolmogorov's extension theorem -
consistent specification of lower-dimensional distributions induces a unique
probability measure for the entire process. The difference is that for
processes of limited complexity (rank of the high-dimensional PMF) it is
possible to obtain complete characterization from only three-dimensional
distributions. In fact not all three-dimensional PMFs are needed; and under
more stringent conditions even two-dimensional will do. Exploiting multilinear
algebra, this paper proves that such higher-dimensional PMF completion can be
guaranteed - several pertinent identifiability results are derived. It also
provides a practical and efficient algorithm to carry out the recovery task.
Judiciously designed simulations and real-data experiments on movie
recommendation and data classification are presented to showcase the
effectiveness of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00216</identifier>
 <datestamp>2018-10-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00216</id><created>2017-12-01</created><updated>2018-10-11</updated><authors><author><keyname>Sang</keyname><forenames>Yu</forenames></author><author><keyname>Shi</keyname><forenames>Laixi</forenames></author><author><keyname>Liu</keyname><forenames>Yimin</forenames></author></authors><title>Micro Hand Gesture Recognition System Using Ultrasonic Active Sensing</title><categories>eess.SP cs.HC</categories><journal-ref>IEEE.Access. 6(2018)49339-49347</journal-ref><doi>10.1109/ACCESS.2018.2868268</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a micro hand gesture recognition system and methods
using ultrasonic active sensing. This system uses micro dynamic hand gestures
for recognition to achieve human-computer interaction (HCI). The implemented
system, called hand-ultrasonic gesture (HUG), consists of ultrasonic active
sensing, pulsed radar signal processing, and time-sequence pattern recognition
by machine learning. We adopt lower frequency (300 kHz) ultrasonic active
sensing to obtain high resolution range-Doppler image features. Using high
quality sequential range-Doppler features, we propose a state-transition-based
hidden Markov model for gesture recognition. This method achieves a recognition
accuracy of nearly 90\% by using symbolized range-Doppler features and
significantly reduces the computational complexity and power consumption.
Furthermore, to achieve higher classification accuracy, we utilize an
end-to-end neural network model and obtain a recognition accuracy of 96.32\%.
In addition to offline analysis, a real-time prototype is released to verify
our method's potential for application in the real world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00254</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00254</id><created>2017-12-01</created><authors><author><keyname>Tax</keyname><forenames>Tycho Max Sylvester</forenames></author><author><keyname>Antich</keyname><forenames>Jose Luis Diez</forenames></author><author><keyname>Purwins</keyname><forenames>Hendrik</forenames></author><author><keyname>Maal&#xf8;e</keyname><forenames>Lars</forenames></author></authors><title>Utilizing Domain Knowledge in End-to-End Audio Processing</title><categories>cs.SD eess.AS stat.ML</categories><comments>Accepted at the ML4Audio workshop at the NIPS 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-to-end neural network based approaches to audio modelling are generally
outperformed by models trained on high-level data representations. In this
paper we present preliminary work that shows the feasibility of training the
first layers of a deep convolutional neural network (CNN) model to learn the
commonly-used log-scaled mel-spectrogram transformation. Secondly, we
demonstrate that upon initializing the first layers of an end-to-end CNN
classifier with the learned transformation, convergence and performance on the
ESC-50 environmental sound classification dataset are similar to a CNN-based
model trained on the highly pre-processed log-scaled mel-spectrogram features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00256</identifier>
 <datestamp>2018-06-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00256</id><created>2017-12-01</created><updated>2018-05-09</updated><authors><author><keyname>Giard</keyname><forenames>Pascal</forenames></author><author><keyname>Burg</keyname><forenames>Andreas</forenames></author></authors><title>Fast-SSC-Flip Decoding of Polar Codes</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 3 figures, appeared at IEEE Wireless Commun. and Netw. Conf.
  (WCNC) 2018</comments><doi>10.1109/WCNCW.2018.8369026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes are widely considered as one of the most exciting recent
discoveries in channel coding. For short to moderate block lengths, their
error-correction performance under list decoding can outperform that of other
modern error-correcting codes. However, high-speed list-based decoders with
moderate complexity are challenging to implement. Successive-cancellation
(SC)-flip decoding was shown to be capable of a competitive error-correction
performance compared to that of list decoding with a small list size, at a
fraction of the complexity, but suffers from a variable execution time and a
higher worst-case latency. In this work, we show how to modify the
state-of-the-art high-speed SC decoding algorithm to incorporate the SC-flip
ideas. The algorithmic improvements are presented as well as average
execution-time results tailored to a hardware implementation. The results show
that the proposed fast-SSC-flip algorithm has a decoding speed close to an
order of magnitude better than the previous works while retaining a comparable
error-correction performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00348</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00348</id><created>2017-11-29</created><authors><author><keyname>Zhang</keyname><forenames>Feng</forenames></author><author><keyname>Chen</keyname><forenames>Chen</forenames></author><author><keyname>Wang</keyname><forenames>Beibei</forenames></author><author><keyname>Liu</keyname><forenames>K. J. Ray</forenames></author></authors><title>WiSpeed: A Statistical Electromagnetic Approach for Device-Free Indoor
  Speed Estimation</title><categories>eess.SP</categories><journal-ref>IEEE Internet of Things Journal, 2018</journal-ref><doi>10.1109/JIOT.2018.2826227</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the severe multipath effect, no satisfactory device-free methods have
ever been found for indoor speed estimation problem, especially in
non-line-of-sight scenarios, where the direct path between the source and
observer is blocked. In this paper, we present WiSpeed, a universal
low-complexity indoor speed estimation system leveraging radio signals, such as
commercial WiFi, LTE, 5G, etc., which can work in both device-free and
device-based situations. By exploiting the statistical theory of
electromagnetic waves, we establish a link between the autocorrelation function
of the physical layer channel state information and the speed of a moving
object, which lays the foundation of WiSpeed. WiSpeed differs from the other
schemes requiring strong line-of-sight conditions between the source and
observer in that it embraces the rich-scattering environment typical for
indoors to facilitate highly accurate speed estimation. Moreover, as a
calibration-free system, WiSpeed saves the users' efforts from large-scale
training and fine-tuning of system parameters. In addition, WiSpeed could
extract the stride length as well as detect abnormal activities such as falling
down, a major threat to seniors that leads to a large number of fatalities
every year. Extensive experiments show that WiSpeed achieves a mean absolute
percentage error of 4.85% for device-free human walking speed estimation and
4.62% for device-based speed estimation, and a detection rate of 95% without
false alarms for fall detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00376</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00376</id><created>2017-12-01</created><authors><author><keyname>Balatsoukas-Stimming</keyname><forenames>Alexios</forenames></author><author><keyname>Podzorny</keyname><forenames>Tomasz</forenames></author><author><keyname>Uythoven</keyname><forenames>Jan</forenames></author></authors><title>Polar Coding for the Large Hadron Collider: Challenges in Code
  Concatenation</title><categories>cs.IT eess.SP math.IT</categories><comments>Presented at the 51st Asilomar Conference on Signals, Systems, and
  Computers, November 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present a concatenated repetition-polar coding scheme that
is aimed at applications requiring highly unbalanced unequal bit-error
protection, such as the Beam Interlock System of the Large Hadron Collider at
CERN. Even though this concatenation scheme is simple, it reveals significant
challenges that may be encountered when designing a concatenated scheme that
uses a polar code as an inner code, such as error correlation and unusual
decision log-likelihood ratio distributions. We explain and analyze these
challenges and we propose two ways to overcome them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00382</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00382</id><created>2017-11-30</created><authors><author><keyname>Saito</keyname><forenames>Hiroshi</forenames></author></authors><title>Estimating Target-Object Shape Using Location-Unknown Mobile
  Fixed-Direction Distance Sensors</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method of estimating a target-object shape, the
location of which is unknown, through the use of location-unknown mobile
distance sensors. The direction of the sensor is fixed from the moving
direction. Typically, mobile sensors are mounted on vehicles. Each sensor
continuously measures the distance from it to the target object. The estimation
method does not require any positioning function, anchor-location information,
or additional mechanisms to obtain side information such as angle of arrival of
signal. Under the assumption of a polygon target object, each edge length and
vertex angle and their combinations are estimated to completely estimate the
shape of the target object.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00404</identifier>
 <datestamp>2018-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00404</id><created>2017-12-01</created><updated>2018-10-19</updated><authors><author><keyname>Isufi</keyname><forenames>Elvin</forenames></author><author><keyname>Banelli</keyname><forenames>Paolo</forenames></author><author><keyname>Di Lorenzo</keyname><forenames>Paolo</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Observing and Tracking Bandlimited Graph Processes</title><categories>eess.SP</categories><comments>Submitted to Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most crucial challenges in graph signal processing is the sampling
of bandlimited graph signals, i.e., signals that are sparse in a well-defined
graph Fourier domain. So far, the prior art is mostly focused on (sub)sampling
single snapshots of graph signals ignoring their evolution over time. However,
time can bring forth new insights, since many real signals like sensor
measurements, biological, financial, and network signals in general, have
intrinsic correlations in both domains. In this work, {we fill this lacuna} by
jointly considering the graph-time nature of graph signals, named \emph{graph
processes} for two main tasks: \emph{i)} observability of graph processes; and
\emph{ii)} tracking of graph processes via Kalman filtering; both from a
(possibly time-varying) subset of nodes. A detailed mathematical analysis
ratifies the proposed methods and provides insights into the role played by the
different actors, such as the graph topology, the process bandwidth, and the
sampling strategy. Moreover, (sub)optimal sampling strategies that jointly
exploit the nature of the graph structure and graph process are proposed.
Several numerical tests on both synthetic and real data validate our
theoretical findings and illustrate the performance of the proposed methods in
coping with time-varying graph signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00468</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00468</id><created>2017-12-01</created><updated>2018-03-26</updated><authors><author><keyname>Ortega</keyname><forenames>Antonio</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author><author><keyname>Kova&#x10d;evi&#x107;</keyname><forenames>Jelena</forenames></author><author><keyname>Moura</keyname><forenames>Jos&#xe9; M. F.</forenames></author><author><keyname>Vandergheynst</keyname><forenames>Pierre</forenames></author></authors><title>Graph Signal Processing: Overview, Challenges and Applications</title><categories>eess.SP</categories><comments>To appear, Proceedings of the IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research in Graph Signal Processing (GSP) aims to develop tools for
processing data defined on irregular graph domains. In this paper we first
provide an overview of core ideas in GSP and their connection to conventional
digital signal processing. We then summarize recent developments in developing
basic GSP tools, including methods for sampling, filtering or graph learning.
Next, we review progress in several application areas using GSP, including
processing and analysis of sensor network data, biological data, and
applications to image processing and machine learning. We finish by providing a
brief historical perspective to highlight how concepts recently developed in
GSP build on top of prior research in other areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00489</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00489</id><created>2017-12-01</created><authors><author><keyname>Gupta</keyname><forenames>Abhinav</forenames></author><author><keyname>Miao</keyname><forenames>Yajie</forenames></author><author><keyname>Neves</keyname><forenames>Leonardo</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author></authors><title>Visual Features for Context-Aware Speech Recognition</title><categories>cs.CL cs.AI cs.CV cs.LG eess.AS</categories><comments>5 pages and 3 figures</comments><journal-ref>IEEE Xplore (ICASSP) (2017) 5020-5024</journal-ref><doi>10.1109/ICASSP.2017.7953112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic transcriptions of consumer-generated multi-media content such as
&quot;Youtube&quot; videos still exhibit high word error rates. Such data typically
occupies a very broad domain, has been recorded in challenging conditions, with
cheap hardware and a focus on the visual modality, and may have been
post-processed or edited. In this paper, we extend our earlier work on adapting
the acoustic model of a DNN-based speech recognition system to an RNN language
model and show how both can be adapted to the objects and scenes that can be
automatically detected in the video. We are working on a corpus of &quot;how-to&quot;
videos from the web, and the idea is that an object that can be seen (&quot;car&quot;),
or a scene that is being detected (&quot;kitchen&quot;) can be used to condition both
models on the &quot;context&quot; of the recording, thereby reducing perplexity and
improving transcription. We achieve good improvements in both cases and compare
and analyze the respective reductions in word error rate. We expect that our
results can be used for any type of speech processing in which &quot;context&quot;
information is available, for example in robotics, man-machine interaction, or
when indexing large audio-visual archives, and should ultimately help to bring
together the &quot;video-to-text&quot; and &quot;speech-to-text&quot; communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00530</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00530</id><created>2017-12-01</created><authors><author><keyname>Silva</keyname><forenames>Melanie R.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>Erivelton G.</forenames></author><author><keyname>Martins</keyname><forenames>Samir A. M.</forenames></author></authors><title>Note on improvement precision of recursive function simulation in
  floating point standard</title><categories>eess.SP</categories><comments>DINCON 2017 - Conferencia Brasileira de Dinamica, Controle e
  Aplicacoes - Sao Jose do Rio Preto - Brazil. 8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An improvement on precision of recursive function simulation in IEEE floating
point standard is presented. It is shown that the average of rounding towards
negative infinite and rounding towards positive infinite yields a better result
than the usual standard rounding to the nearest in the simulation of recursive
functions. In general, the method improves one digit of precision and it has
also been useful to avoid divergence from a correct stationary regime in the
logistic map. Numerical studies are presented to illustrate the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00590</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00590</id><created>2017-12-02</created><authors><author><keyname>&#xc7;ay&#x131;r</keyname><forenames>&#xd6;mer</forenames></author><author><keyname>Candan</keyname><forenames>&#xc7;a&#x11f;atay</forenames></author></authors><title>Performance Improvement of Time-Balance Radar Schedulers Through
  Decision Policies (Extended Version)</title><categories>eess.SP</categories><comments>The extended version of the paper accepted for publication in IEEE
  Transactions on Aerospace and Electronic Systems, 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The resource management of a phase array system capable of multiple target
tracking and surveillance is critical for the realization of its full
potential. Present work aims to improve the performance of an existing method,
time-balance scheduling, by establishing an analogy with a well-known
stochastic control problem, the machine replacement problem. With the suggested
policy, the scheduler can adapt to the operational scenario without a
significant sacrifice from the practicality of the time-balance schedulers.
More specifically, the numerical experiments indicate that the schedulers
directed with the suggested policy can successfully trade the unnecessary track
updates, say of non-maneuvering targets, with the updates of targets with
deteriorating tracks, say of rapidly maneuvering targets, yielding an overall
improvement in the tracking performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00631</identifier>
 <datestamp>2019-07-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00631</id><created>2017-12-02</created><updated>2019-07-22</updated><authors><author><keyname>Kwon</keyname><forenames>Minhae</forenames></author><author><keyname>Park</keyname><forenames>Hyunggon</forenames></author></authors><title>Distributed Topology Design for Network Coding Deployed Large-scale
  Sensor Networks</title><categories>cs.GT cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a solution to the distributed topology formation
problem for large-scale sensor networks with multi-source multicast flows. The
proposed solution is based on game-theoretic approaches in conjunction with
network coding. The proposed algorithm requires significantly low computational
complexity, while it is known as NP-hard to find an optimal topology for
network coding deployed multi-source multicast flows. In particular, we
formulate the problem of distributed network topology formation as a network
formation game by considering the nodes in the network as players that can take
actions for making outgoing links. The proposed solution decomposes the
original game that consists of multiple players and multicast flows into
independent link formation games played by only two players with a unicast
flow. We also show that the proposed algorithm is guaranteed to determine at
least one stable topology. Our simulation results confirm that the
computational complexity of the proposed solution is low enough for practical
deployment in large-scale networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00635</identifier>
 <datestamp>2019-07-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00635</id><created>2017-12-02</created><updated>2018-08-16</updated><authors><author><keyname>Kwon</keyname><forenames>Minhae</forenames></author><author><keyname>Park</keyname><forenames>Hyunggon</forenames></author></authors><title>Network Coding Based Evolutionary Network Formation for Dynamic Wireless
  Networks</title><categories>cs.NI cs.LG cs.MA eess.SP</categories><comments>IEEE Transactions on Mobile Computing (Early Access)</comments><journal-ref>IEEE Transactions on Mobile Computing (Volume: 18 , Issue: 6 ,
  June 1 2019)</journal-ref><doi>10.1109/TMC.2018.2861001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we aim to find a robust network formation strategy that can
adaptively evolve the network topology against network dynamics in a
distributed manner. We consider a network coding deployed wireless ad hoc
network where source nodes are connected to terminal nodes with the help of
intermediate nodes. We show that mixing operations in network coding can induce
packet anonymity that allows the inter-connections in a network to be
decoupled. This enables each intermediate node to consider complex network
inter-connections as a node-environment interaction such that the Markov
decision process (MDP) can be employed at each intermediate node. The optimal
policy that can be obtained by solving the MDP provides each node with optimal
amount of changes in transmission range given network dynamics (e.g., the
number of nodes in the range and channel condition). Hence, the network can be
adaptively and optimally evolved by responding to the network dynamics. The
proposed strategy is used to maximize long-term utility, which is achieved by
considering both current network conditions and future network dynamics. We
define the utility of an action to include network throughput gain and the cost
of transmission power. We show that the resulting network of the proposed
strategy eventually converges to stationary networks, which maintain the states
of the nodes. Moreover, we propose to determine initial transmission ranges and
initial network topology that can expedite the convergence of the proposed
algorithm. Our simulation results confirm that the proposed strategy builds a
network which adaptively changes its topology in the presence of network
dynamics. Moreover, the proposed strategy outperforms existing strategies in
terms of system goodput and successful connectivity ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00649</identifier>
 <datestamp>2018-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00649</id><created>2017-12-02</created><updated>2018-04-13</updated><authors><author><keyname>Mital</keyname><forenames>Nitish</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author></authors><title>Coded Caching in a Multi-Server System with Random Topology</title><categories>cs.IT eess.SP math.IT</categories><comments>Published in WCNC, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cache-aided content delivery is studied in a multi-server system with $P$
servers and $K$ users, each equipped with a local cache memory. In the delivery
phase, each user connects randomly to any $\rho$ out of $P$ servers. Thanks to
the availability of multiple servers, which model small base stations with
limited storage capacity, user demands can be satisfied with reduced storage
capacity at each server and reduced delivery rate per server; however, this
also leads to reduced multicasting opportunities compared to a single server
serving all the users simultaneously. A joint storage and proactive caching
scheme is proposed, which exploits coded storage across the servers, uncoded
cache placement at the users, and coded delivery. The delivery \textit{latency}
is studied for both \textit{successive} and \textit{simultaneous} transmission
from the servers. It is shown that, with successive transmission the achievable
average delivery latency is comparable to that achieved by a single server,
while the gap between the two depends on $\rho$, the available redundancy
across servers, and can be reduced by increasing the storage capacity at the
SBSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00712</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00712</id><created>2017-12-03</created><authors><author><keyname>Santos</keyname><forenames>Wellington Pinheiro dos</forenames></author><author><keyname>de Souza</keyname><forenames>Ricardo Emmanuel</forenames></author><author><keyname>Filho</keyname><forenames>Pl&#xed;nio B. dos Santos</forenames></author></authors><title>Evaluation of Alzheimer's Disease by Analysis of MR Images using
  Multilayer Perceptrons and Kohonen SOM Classifiers as an Alternative to the
  ADC Maps</title><categories>eess.IV cs.AI cs.CV cs.NE</categories><comments>29th Annual Conference of the IEEE Engineering in Medicine and
  Biology Society - EMBC 2007</comments><doi>10.1109/IEMBS.2007.4352740</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alzheimer's disease is the most common cause of dementia, yet hard to
diagnose precisely without invasive techniques, particularly at the onset of
the disease. This work approaches image analysis and classification of
synthetic multispectral images composed by diffusion-weighted magnetic
resonance (MR) cerebral images for the evaluation of cerebrospinal fluid area
and measuring the advance of Alzheimer's disease. A clinical 1.5 T MR imaging
system was used to acquire all images presented. The classification methods are
based on multilayer perceptrons and Kohonen Self-Organized Map classifiers. We
assume the classes of interest can be separated by hyperquadrics. Therefore, a
2-degree polynomial network is used to classify the original image, generating
the ground truth image. The classification results are used to improve the
usual analysis of the apparent diffusion coefficient map.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00789</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00789</id><created>2017-12-03</created><authors><author><keyname>Barbosa</keyname><forenames>Valter Augusto de Freitas</forenames></author><author><keyname>Ribeiro</keyname><forenames>Reiga Ramalho</forenames></author><author><keyname>Feitosa</keyname><forenames>Allan Rivalles Souza</forenames></author><author><keyname>da Silva</keyname><forenames>Victor Luiz Bezerra Ara&#xfa;jo</forenames></author><author><keyname>Rocha</keyname><forenames>Arthur Diego Dias</forenames></author><author><keyname>de Freitas</keyname><forenames>Rafaela Covello</forenames></author><author><keyname>de Souza</keyname><forenames>Ricardo Emmanuel</forenames></author><author><keyname>Santos</keyname><forenames>Wellington Pinheiro dos</forenames></author></authors><title>Reconstruction of Electrical Impedance Tomography Using Fish School
  Search, Non-Blind Search, and Genetic Algorithm</title><categories>physics.med-ph cs.NE eess.IV</categories><journal-ref>International Journal of Swarm Intelligence Research, Volume 8,
  Issue 2, 2017</journal-ref><doi>10.4018/IJSIR.2017040102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electrical Impedance Tomography (EIT) is a noninvasive imaging technique that
does not use ionizing radiation, with application both in environmental
sciences and in health. Image reconstruction is performed by solving an inverse
problem and ill-posed. Evolutionary Computation and Swarm Intelligence have
become a source of methods for solving inverse problems. Fish School Search
(FSS) is a promising search and optimization method, based on the dynamics of
schools of fish. In this article the authors present a method for
reconstruction of EIT images based on FSS and Non-Blind Search (NBS). The
method was evaluated using numerical phantoms consisting of electrical
conductivity images with subjects in the center, between the center and the
edge and on the edge of a circular section, with meshes of 415 finite elements.
The authors performed 20 simulations for each configuration. Results showed
that both FSS and FSS-NBS were able to converge faster than genetic algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00834</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00834</id><created>2017-12-03</created><authors><author><keyname>Rajabzadeh</keyname><forenames>Taha</forenames></author><author><keyname>Mousavi</keyname><forenames>Mohammad Hosein</forenames></author><author><keyname>Abdollahramezani</keyname><forenames>Sajjad</forenames></author><author><keyname>Jamali</keyname><forenames>Mohammad Vahid</forenames></author><author><keyname>Salehi</keyname><forenames>Jawad A.</forenames></author></authors><title>Femtosecond CDMA Using Dielectric Metasurfaces: Design Procedure and
  Challenges</title><categories>physics.app-ph eess.SP physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by the ever-increasing demand for higher data transmission rates and
the tremendous attention toward all-optical signal processing based on
miniaturized nanophotonics, in this paper, for the first time, we investigate
the integrable design of coherent ultrashort light pulse code-division
multiple-access (CDMA) technique, also known as femtosecond CDMA, using
all-dielectric metasurfaces (MSs). In this technique, the data bits are firstly
modulated using ultrashort femtosecond optical pulses generated by mode-locked
lasers, and then by employing a unique phase metamask for each data stream, in
order to provide the multiple access capability, the optical signals are
spectrally encoded. This procedure spreads the optical signal in the temporal
domain and generates low-intensity pseudo-noise bursts through random phase
coding leading to minimized multiple access interference. This paper
comprehensively presents the principles and design approach to realize
fundamental components of a typical femtosecond CDMA encoder, including the
grating, lens, and phase mask, by employing high-contrast CMOS-compatible MSs.
By controlling the interference between the provided Mie and Fabry-Perot
resonance modes, we tailor the spectral and spatial responses of the impinging
light locally and independently. Accordingly, we design a MS-based grating with
the highest possible refracted angle and, in the meantime, the maximized
efficiency which results in a reasonable diameter for the subsequent lens.
Moreover, to design our MS-based lens commensurate with the spot size and
distance requirements of the pursuant phase mask, we leverage a new
optimization method which splits the lens structure into central and peripheral
parts, and then design the peripheral part using a collection of gratings
converging the impinging at the subsequent phase mask.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00855</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00855</id><created>2017-12-03</created><authors><author><keyname>Saryazdi</keyname><forenames>Soroush</forenames></author><author><keyname>Saryazdi</keyname><forenames>Saman</forenames></author><author><keyname>Nezamabadi-pour</keyname><forenames>Hossein</forenames></author></authors><title>EDIZ: An Error Diffusion Image Zooming Scheme</title><categories>eess.IV</categories><comments>Submitted to IEEE Signal Processing Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interpolation based image zooming methods provide a high execution speed and
low computational complexity. However, the quality of the zoomed images is
unsatisfactory in many cases. The main challenge of super- resolution methods
is to create new details to the image. This paper proposes a new algorithm to
create new details using a zoom-out-zoom-in strategy. This strategy permits
reducing blurring effects by adding the estimated error to the final image.
Experimental results for natural images confirm the algorithm's ability to
create visually pleasing results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00866</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00866</id><created>2017-12-03</created><authors><author><keyname>Lee</keyname><forenames>Jongpil</forenames></author><author><keyname>Kim</keyname><forenames>Taejun</forenames></author><author><keyname>Park</keyname><forenames>Jiyoung</forenames></author><author><keyname>Nam</keyname><forenames>Juhan</forenames></author></authors><title>Raw Waveform-based Audio Classification Using Sample-level CNN
  Architectures</title><categories>cs.SD cs.LG cs.MM eess.AS</categories><comments>NIPS, Machine Learning for Audio Signal Processing Workshop
  (ML4Audio), 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music, speech, and acoustic scene sound are often handled separately in the
audio domain because of their different signal characteristics. However, as the
image domain grows rapidly by versatile image classification models, it is
necessary to study extensible classification models in the audio domain as
well. In this study, we approach this problem using two types of sample-level
deep convolutional neural networks that take raw waveforms as input and uses
filters with small granularity. One is a basic model that consists of
convolution and pooling layers. The other is an improved model that
additionally has residual connections, squeeze-and-excitation modules and
multi-level concatenation. We show that the sample-level models reach
state-of-the-art performance levels for the three different categories of
sound. Also, we visualize the filters along layers and compare the
characteristics of learned filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00879</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00879</id><created>2017-12-03</created><authors><author><keyname>Wang</keyname><forenames>Songyan</forenames></author><author><keyname>Non-member</keyname></author><author><keyname>Yu</keyname><forenames>Jilai</forenames></author><author><keyname>Zhang</keyname><forenames>Wei</forenames></author></authors><title>Transient Stability Assessment Using Individual Machine Equal Area
  Criterion Part I: Unity Principle</title><categories>eess.SP cs.SY</categories><comments>11 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analyzing system trajectory from the perspective of individual machines
provides a distinctive angle to analyze the transient stability of power
systems. This two-paper series propose a direct-time-domain method that is
based on the individual-machine equal area criterion. In the first paper, by
examining the mapping between the trajectory and power-vs-angle curve of an
individual machine, the stability property to characterize a critical machine
is clarified. The mapping between the system trajectory and individual-machine
equal area criterion is established. Furthermore, a unity principle between the
individual-machine stability and system stability is proposed. It is proved
that the instability of the system can be confirmed by finding any one unstable
critical machine, thence, the transient stability of a multimachine system can
be monitored in an individual-machine way in transient stability assessment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00881</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00881</id><created>2017-12-03</created><authors><author><keyname>Wang</keyname><forenames>Songyan</forenames></author><author><keyname>Yu</keyname><forenames>Jilai</forenames></author><author><keyname>Zhang</keyname><forenames>Wei</forenames></author></authors><title>Transient Stability Assessment Using Individual Machine Equal Area
  Criterion Part II: Stability Margin</title><categories>eess.SP</categories><comments>10 pages, 20 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the second part of this two-paper series, the stability margin of a
critical machine and that of the system are first proposed, and then the
concept of non-global stability margin is illustrated. Based on the crucial
statuses of the leading unstable critical machine and the most severely
disturbed critical machine, the critical stability of the system from the
perspective of an individual machine is analyzed. In the end of this paper,
comparisons between the proposed method and classic global methods are
demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00888</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00888</id><created>2017-12-03</created><authors><author><keyname>Nguyen</keyname><forenames>Tung Lam</forenames></author><author><keyname>Tran</keyname><forenames>Quoc Tuan</forenames></author><author><keyname>Caire</keyname><forenames>Raphael</forenames></author><author><keyname>Besanger</keyname><forenames>Yvon</forenames></author><author><keyname>Hoang</keyname><forenames>Tran The</forenames></author><author><keyname>Nguyen</keyname><forenames>Van Hoa</forenames></author></authors><title>FMI Compliant Approach to Investigate the Impact of Communication to
  Islanded Microgrid Secondary Control</title><categories>eess.SP</categories><comments>Proceedings of the IEEE PES ISGT Asia 2017 conference</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In multi-master islanded microgrids, the inverter controllers need to share
the signals and to coordinate, in either centralized or distributed way, in
order to operate properly and to assure a good functionality of the grid. The
central controller is used in centralized strategy. In distributed control,
Multi-agent system (MAS) is considered to be a suitable solution for
coordination of such system. However the latency and disturbance of the network
may disturb the communication from central controller to local controllers or
among agents or and negatively influence the grid operation. As a consequence,
communication aspects need to be properly addressed during the control design
and assessment. In this paper, we propose a holistic approach with
co-simulation using Functional Mockup Interface (FMI) standard to validate the
microgrid control system taking into account the communication network. A
use-case of islanded microgrid frequency secondary control with MAS under
consensus algorithm is implemented to demonstrate the impact of communication
and to illustrate the proposed holistic approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.00917</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.00917</id><created>2017-12-04</created><authors><author><keyname>Charan</keyname><forenames>Rishi</forenames></author><author><keyname>A</keyname><forenames>Manisha.</forenames></author><author><keyname>R</keyname><forenames>Karthik.</forenames></author><author><keyname>M</keyname><forenames>Rajesh Kumar</forenames></author></authors><title>A text-independent speaker verification model: A comparative analysis</title><categories>cs.SD eess.AS</categories><comments>presented and accepted by 2017 International Conference on
  Intelligent Computing and Control (I2C2)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most pressing challenge in the field of voice biometrics is selecting the
most efficient technique of speaker recognition. Every individual's voice is
peculiar, factors like physical differences in vocal organs, accent and
pronunciation contributes to the problem's complexity. In this paper, we
explore the various methods available in each block in the process of speaker
recognition with the objective to identify best of techniques that could be
used to get precise results. We study the results on text independent corpora.
We use MFCC (Melfrequency cepstral coefficient), LPCC (linear predictive
cepstral coefficient) and PLP (perceptual linear prediction) algorithms for
feature extraction, PCA (Principal Component Analysis) and tSNE for
dimensionality reduction and SVM (Support Vector Machine), feed forward,
nearest neighbor and decision tree algorithms for classification block in
speaker recognition system and comparatively analyze each block to determine
the best technique
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01011</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01011</id><created>2017-12-04</created><authors><author><keyname>Lim</keyname><forenames>Hyungui</forenames></author><author><keyname>Rhyu</keyname><forenames>Seungyeon</forenames></author><author><keyname>Lee</keyname><forenames>Kyogu</forenames></author></authors><title>Chord Generation from Symbolic Melody Using BLSTM Networks</title><categories>cs.SD cs.LG eess.AS</categories><comments>18th International Society for Music Information Retrieval Conference
  (ISMIR 2017)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generating a chord progression from a monophonic melody is a challenging
problem because a chord progression requires a series of layered notes played
simultaneously. This paper presents a novel method of generating chord
sequences from a symbolic melody using bidirectional long short-term memory
(BLSTM) networks trained on a lead sheet database. To this end, a group of
feature vectors composed of 12 semitones is extracted from the notes in each
bar of monophonic melodies. In order to ensure that the data shares uniform key
and duration characteristics, the key and the time signatures of the vectors
are normalized. The BLSTM networks then learn from the data to incorporate the
temporal dependencies to produce a chord progression. Both quantitative and
qualitative evaluations are conducted by comparing the proposed method with the
conventional HMM and DNN-HMM based approaches. Proposed model achieves 23.8%
and 11.4% performance increase from the other models, respectively. User
studies further confirm that the chord sequences generated by the proposed
method are preferred by listeners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01013</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01013</id><created>2017-12-04</created><authors><author><keyname>Oliveira</keyname><forenames>Marcella N. R.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>Erivelton G.</forenames></author></authors><title>A rigorous evaluation of the intermittence in the logistic map using
  lower bound error</title><categories>eess.SP</categories><comments>DINCON 2017 - Conferencia Brasileira de Dinamica, Controle e
  Aplicacoes - Sao Jose do Rio Preto - Brazil. 7 pages. In Portuguese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article investigates the maximum time of simulation in which the
phenomenon of the intermittence can be observed with numerical confidence in
discrete maps. Interval analysis and the lower error limit were used. As a
result, it was observed that the reliability of the intermittency is dependent
on the initial condition. Four numerical examples show the efficiency of the
proposal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01015</identifier>
 <datestamp>2018-06-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01015</id><created>2017-12-04</created><authors><author><keyname>Dey</keyname><forenames>Jayanta</forenames></author><author><keyname>Hasan</keyname><forenames>Md. Kamrul</forenames></author></authors><title>Ultrasonic Tissue Reflectivity Function Estimation Using Correlation
  Constrained Multichannel FLMS Algorithm with Missing RF Data</title><categories>eess.SP</categories><doi>10.1088/2057-1976/aaca00</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Poor resolution of ultrasound images due to convolution of the tissue
reflectivity function (TRF) with the system point spread function (PSF) is a
major issue in medical ultrasound imaging. In this paper, we propose a
correlation constrained missing-data estimation based blind multichannel
frequency- domain least-mean-squares (md-bMCFLMS) algorithm to undo the effect
of PSF on the ultrasound radio-frequency (RF) data. In the first step, a
block-based MCFLMS (bMCFLMS) algorithm is proposed to estimate the TRFs and the
PSF which are used in the second step to estimate the missing data. This
missing data is used in the md-bMCFLMS algorithm to construct a modified cost
function for further improvement of the image resolution. To account for the
nonstationarity of the PSF, unlike the blocking approach described in the
literature, we introduce a time-efficient blocking method in this paper. The
blocking approach described here uses a block position independent fixed size
matrix and can be implemented parallely. The bMCFLMS algorithm, however, shows
misconvergence due to both channel noise and propagation of TRF estimation
error from the previous blocks. This phe- nomenon is more intense in the case
of md-bMCFLMS algorithm because of increased estimation error. To address this
problem, a novel constraint based on the correlation between the measured RF
data and estimated TRF is proposed in this paper. The efficacy of our proposed
blind deconvolution algorithm is measured using simulation phantom,
experimental phantom and in-vivo data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01019</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01019</id><created>2017-12-04</created><authors><author><keyname>Silva</keyname><forenames>Gabriel H. A.</forenames></author><author><keyname>Silva</keyname><forenames>Igor C.</forenames></author><author><keyname>Junior</keyname><forenames>Wilson R. L.</forenames></author><author><keyname>Martins</keyname><forenames>Samir A. M.</forenames></author><author><keyname>Barroso</keyname><forenames>Marcio F. S.</forenames></author><author><keyname>Nepomuceno</keyname><forenames>Erivelton G.</forenames></author></authors><title>Synchronization on the accuracy of chaotic oscillators simulations</title><categories>eess.SP nlin.CD</categories><comments>DINCON 2017 - Conferencia Brasileira de Dinamica, Controle e
  Aplicacoes - Sao Jose do Rio Preto - Brazil. 8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerical problems are considered on general synchronization of chaotic
oscillators, through the evaluation of the Lower Bound Error index on two case
studies: a Lorenz system unidirectionally coupled to a Duffing system and a
Duffing system unidirectionally coupled to a Rossler system. It was possible to
observe, in each case, that the behavior of the slave's LBE curve tends to
follow the behavior of the master's as the value of the coupling constant is
increased up to a certain value, and thus, that synchronization can affect
numerical calculations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01108</identifier>
 <datestamp>2018-08-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01108</id><created>2017-11-29</created><updated>2017-12-05</updated><authors><author><keyname>Maddali</keyname><forenames>Siddharth</forenames></author><author><keyname>Calvo-Almazan</keyname><forenames>Irene</forenames></author><author><keyname>Almer</keyname><forenames>Jonathan</forenames></author><author><keyname>Kenesei</keyname><forenames>Peter</forenames></author><author><keyname>Park</keyname><forenames>Jun-Sang</forenames></author><author><keyname>Harder</keyname><forenames>Ross</forenames></author><author><keyname>Nashed</keyname><forenames>Youssef</forenames></author><author><keyname>Hruszkewycz</keyname><forenames>Stephan</forenames></author></authors><title>Sparse recovery of undersampled intensity patterns for coherent
  diffraction imaging at high X-ray energies</title><categories>eess.SP cond-mat.mtrl-sci physics.ins-det</categories><comments>11 pages, 7 figures (submitted)</comments><doi>10.1038/s41598-018-23040-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coherent X-ray photons with energies higher than 50 keV offer new
possibilities for imaging nanoscale lattice distortions in bulk crystalline
materials using Bragg peak phase retrieval methods. However, the compression of
reciprocal space at high energies typically results in poorly resolved fringes
on an area detector, rendering the diffraction data unsuitable for the
three-dimensional reconstruction of compact crystals. To address this problem,
we propose a method by which to recover fine fringe detail in the scattered
intensity. This recovery is achieved in two steps: multiple undersampled
measurements are made by in-plane sub-pixel motion of the area detector, then
this data set is passed to a sparsity-based numerical solver that recovers
fringe detail suitable for standard Bragg coherent diffraction imaging (BCDI)
reconstruction methods of compact single crystals. The key insight of this
paper is that sparsity in a BCDI data set can be enforced by recognising that
the signal in the detector, though poorly resolved, is band-limited. This
requires fewer in-plane detector translations for complete signal recovery,
while adhering to information theory limits. We use simulated BCDI data sets to
demonstrate the approach, outline our sparse recovery strategy, and comment on
future opportunities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01115</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01115</id><created>2017-11-30</created><authors><author><keyname>Ruan</keyname><forenames>H.</forenames></author><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author></authors><title>Study of Robust Distributed Beamforming Based on Cross-Correlation and
  Subspace Projection Techniques</title><categories>eess.SP cs.IT math.IT</categories><comments>3 figures, 7 pages. arXiv admin note: text overlap with
  arXiv:1707.00953&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present a novel robust distributed beamforming (RDB)
approach to mitigate the effects of channel errors on wireless networks
equipped with relays based on the exploitation of the cross-correlation between
the received data from the relays at the destination and the system output. The
proposed RDB method, denoted cross-correlation and subspace projection (CCSP)
RDB, considers a total relay transmit power constraint in the system and the
objective of maximizing the output signal-to-interference-plus-noise ratio
(SINR). The relay nodes are equipped with an amplify-and-forward (AF) protocol
and we assume that the channel state information (CSI) is imperfectly known at
the relays and there is no direct link between the sources and the destination.
The CCSP does not require any costly optimization procedure and simulations
show an excellent performance as compared to previously reported algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01120</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01120</id><created>2017-12-01</created><authors><author><keyname>Kleijn</keyname><forenames>W. Bastiaan</forenames></author><author><keyname>Lim</keyname><forenames>Felicia S. C.</forenames></author><author><keyname>Luebs</keyname><forenames>Alejandro</forenames></author><author><keyname>Skoglund</keyname><forenames>Jan</forenames></author><author><keyname>Stimberg</keyname><forenames>Florian</forenames></author><author><keyname>Wang</keyname><forenames>Quan</forenames></author><author><keyname>Walters</keyname><forenames>Thomas C.</forenames></author></authors><title>Wavenet based low rate speech coding</title><categories>eess.AS cs.SD eess.SP</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional parametric coding of speech facilitates low rate but provides
poor reconstruction quality because of the inadequacy of the model used. We
describe how a WaveNet generative speech model can be used to generate high
quality speech from the bit stream of a standard parametric coder operating at
2.4 kb/s. We compare this parametric coder with a waveform coder based on the
same generative model and show that approximating the signal waveform incurs a
large rate penalty. Our experiments confirm the high performance of the WaveNet
based coder and show that the speech produced by the system is able to
additionally perform implicit bandwidth extension and does not significantly
impair recognition of the original speaker for the human listener, even when
that speaker has not been used during the training of the generative model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01154</identifier>
 <datestamp>2018-12-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01154</id><created>2017-12-01</created><updated>2018-12-27</updated><authors><author><keyname>Abeywickrama</keyname><forenames>Samith</forenames></author><author><keyname>Jayasinghe</keyname><forenames>Lahiru</forenames></author><author><keyname>Fu</keyname><forenames>Hua</forenames></author><author><keyname>Nissanka</keyname><forenames>Subashini</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author></authors><title>RF-Based Direction Finding of UAVs Using DNN</title><categories>eess.SP cs.NI</categories><comments>In Proc. IEEE International Conference on Communication Systems
  (ICCS) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a sparse denoising autoencoder (SDAE)-based deep neural
network (DNN) for the direction finding (DF) of small unmanned aerial vehicles
(UAVs). It is motivated by the practical challenges associated with classical
DF algorithms such as MUSIC and ESPRIT. The proposed DF scheme is practical and
low-complex in the sense that a phase synchronization mechanism, an antenna
calibration mechanism, and the analytical model of the antenna radiation
pattern are not essential. Also, the proposed DF method can be implemented
using a single-channel RF receiver. The paper validates the proposed method
experimentally as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01317</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01317</id><created>2017-12-04</created><authors><author><keyname>Carquex</keyname><forenames>C.</forenames></author><author><keyname>Rosenberg</keyname><forenames>C.</forenames></author><author><keyname>Bhattacharya</keyname><forenames>K.</forenames></author></authors><title>State Estimation in Power Distribution Systems Based on Ensemble Kalman
  Filtering</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State estimation in power distribution systems is a key component for
increased reliability and optimal system performance. Well understood in
transmission systems, state estimation is now an area of active research in
distribution networks. While several snapshot-based approaches have been used
to solve this problem, few solutions have been proposed in a dynamic framework.
In this paper, a Past-Aware State Estimation (PASE) method is proposed for
distribution systems that takes previous estimates into account to improve the
accuracy of the current one, using an Ensemble Kalman Filter. Fewer phasor
measurements units (PMU) are needed to achieve the same estimation error target
than snapshot-based methods. Contrary to current methods, the proposed solution
does not embed power flow equations into the estimator. A theoretical
formulation is presented to compute a priori the advantages of the proposed
method vis-a-vis the state-of-the-art. The proposed approach is validated
considering the 33-bus distribution system and using power consumption traces
from real households.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01340</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01340</id><created>2017-12-04</created><authors><author><keyname>Ko</keyname><forenames>Jong Hwan</forenames></author><author><keyname>Fromm</keyname><forenames>Josh</forenames></author><author><keyname>Philipose</keyname><forenames>Matthai</forenames></author><author><keyname>Tashev</keyname><forenames>Ivan</forenames></author><author><keyname>Zarar</keyname><forenames>Shuayb</forenames></author></authors><title>Precision Scaling of Neural Networks for Efficient Audio Processing</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While deep neural networks have shown powerful performance in many audio
applications, their large computation and memory demand has been a challenge
for real-time processing. In this paper, we study the impact of scaling the
precision of neural networks on the performance of two common audio processing
tasks, namely, voice-activity detection and single-channel speech enhancement.
We determine the optimal pair of weight/neuron bit precision by exploring its
impact on both the performance and processing time. Through experiments
conducted with real user data, we demonstrate that deep neural networks that
use lower bit precision significantly reduce the processing time (up to 30x).
However, their performance impact is low (&lt; 3.14%) only in the case of
classification tasks such as those present in voice activity detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01456</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01456</id><created>2017-12-04</created><authors><author><keyname>Chen</keyname><forenames>Zhiqian</forenames></author><author><keyname>Wu</keyname><forenames>Chih-Wei</forenames></author><author><keyname>Lu</keyname><forenames>Yen-Cheng</forenames></author><author><keyname>Lerch</keyname><forenames>Alexander</forenames></author><author><keyname>Lu</keyname><forenames>Chang-Tien</forenames></author></authors><title>Learning to Fuse Music Genres with Generative Adversarial Dual Learning</title><categories>cs.LG cs.SD eess.AS</categories><comments>International Conference on Data Mining - New Orleans, 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  FusionGAN is a novel genre fusion framework for music generation that
integrates the strengths of generative adversarial networks and dual learning.
In particular, the proposed method offers a dual learning extension that can
effectively integrate the styles of the given domains. To efficiently quantify
the difference among diverse domains and avoid the vanishing gradient issue,
FusionGAN provides a Wasserstein based metric to approximate the distance
between the target domain and the existing domains. Adopting the Wasserstein
distance, a new domain is created by combining the patterns of the existing
domains using adversarial learning. Experimental results on public music
datasets demonstrated that our approach could effectively merge two genres.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01497</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01497</id><created>2017-12-05</created><authors><author><keyname>Wu</keyname><forenames>Xiaohuan</forenames></author><author><keyname>Zhu</keyname><forenames>Wei-Ping</forenames></author><author><keyname>Yan</keyname><forenames>Jun</forenames></author></authors><title>Gridless Two-dimensional DOA Estimation With L-shaped Array Based on the
  Cross-covariance Matrix</title><categories>cs.IT eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The atomic norm minimization (ANM) has been successfully incorporated into
the two-dimensional (2-D) direction-of-arrival (DOA) estimation problem for
super-resolution. However, its computational workload might be unaffordable
when the number of snapshots is large. In this paper, we propose two gridless
methods for 2-D DOA estimation with L-shaped array based on the atomic norm to
improve the computational efficiency. Firstly, by exploiting the
cross-covariance matrix an ANM-based model has been proposed. We then prove
that this model can be efficiently solved as a semi-definite programming (SDP).
Secondly, a modified model has been presented to improve the estimation
accuracy. It is shown that our proposed methods can be applied to both uniform
and sparse L-shaped arrays and do not require any knowledge of the number of
sources. Furthermore, since our methods greatly reduce the model size as
compared to the conventional ANM method, and thus are much more efficient.
Simulations results are provided to demonstrate the advantage of our methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01541</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01541</id><created>2017-12-05</created><authors><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Sim</keyname><forenames>Khe Chai</forenames></author><author><keyname>Bacchiani</keyname><forenames>Michiel</forenames></author><author><keyname>Weinstein</keyname><forenames>Eugene</forenames></author><author><keyname>Nguyen</keyname><forenames>Patrick</forenames></author><author><keyname>Chen</keyname><forenames>Zhifeng</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Rao</keyname><forenames>Kanishka</forenames></author></authors><title>Multi-Dialect Speech Recognition With A Single Sequence-To-Sequence
  Model</title><categories>eess.AS cs.SD</categories><comments>submitted to ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence-to-sequence models provide a simple and elegant solution for
building speech recognition systems by folding separate components of a typical
system, namely acoustic (AM), pronunciation (PM) and language (LM) models into
a single neural network. In this work, we look at one such sequence-to-sequence
model, namely listen, attend and spell (LAS), and explore the possibility of
training a single model to serve different English dialects, which simplifies
the process of training multi-dialect systems without the need for separate AM,
PM and LMs for each dialect. We show that simply pooling the data from all
dialects into one LAS model falls behind the performance of a model fine-tuned
on each dialect. We then look at incorporating dialect-specific information
into the model, both by modifying the training targets by inserting the dialect
symbol at the end of the original grapheme sequence and also feeding a 1-hot
representation of the dialect information into all layers of the model.
Experimental results on seven English dialects show that our proposed system is
effective in modeling dialect variations within a single LAS model,
outperforming a LAS model trained individually on each of the seven dialects by
3.1 ~ 16.5% relative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01694</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01694</id><created>2017-12-03</created><authors><author><keyname>Santos</keyname><forenames>Wellington Pinheiro dos</forenames></author><author><keyname>de Assis</keyname><forenames>Francisco Marcos</forenames></author><author><keyname>de Souza</keyname><forenames>Ricardo Emmanuel</forenames></author><author><keyname>Mendes</keyname><forenames>Priscilla B.</forenames></author><author><keyname>Monteiro</keyname><forenames>Henrique S. S.</forenames></author><author><keyname>Alves</keyname><forenames>Havana Diogo</forenames></author></authors><title>Fuzzy-Based Dialectical Non-Supervised Image Classification and
  Clustering</title><categories>cs.CV cs.AI cs.GR cs.NE eess.IV</categories><journal-ref>International Journal of Hybrid Intelligent Systems, v. 7, p.
  115-124, 2010</journal-ref><doi>10.3233/HIS-2010-0108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The materialist dialectical method is a philosophical investigative method to
analyze aspects of reality. These aspects are viewed as complex processes
composed by basic units named poles, which interact with each other. Dialectics
has experienced considerable progress in the 19th century, with Hegel's
dialectics and, in the 20th century, with the works of Marx, Engels, and
Gramsci, in Philosophy and Economics. The movement of poles through their
contradictions is viewed as a dynamic process with intertwined phases of
evolution and revolutionary crisis. In order to build a computational process
based on dialectics, the interaction between poles can be modeled using fuzzy
membership functions. Based on this assumption, we introduce the Objective
Dialectical Classifier (ODC), a non-supervised map for classification based on
materialist dialectics and designed as an extension of fuzzy c-means
classifier. As a case study, we used ODC to classify 181 magnetic resonance
synthetic multispectral images composed by proton density, $T_1$- and
$T_2$-weighted synthetic brain images. Comparing ODC to k-means, fuzzy c-means,
and Kohonen's self-organized maps, concerning with image fidelity indexes as
estimatives of quantization distortion, we proved that ODC can reach almost the
same quantization performance as optimal non-supervised classifiers like
Kohonen's self-organized maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01695</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01695</id><created>2017-12-03</created><authors><author><keyname>Lima</keyname><forenames>Higor Neto</forenames></author><author><keyname>Santos</keyname><forenames>Wellington Pinheiro dos</forenames></author><author><keyname>Valen&#xe7;a</keyname><forenames>M&#xea;user Jorge Silva</forenames></author></authors><title>Triagem virtual de imagens de imuno-histoqu\'imica usando redes neurais
  artificiais e espectro de padr\~oes</title><categories>cs.CV cs.NE eess.IV</categories><comments>in Portuguese</comments><journal-ref>Learning and Nonlinear Models, v. 8, p. 202-215, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of organizing medical images according to their nature,
application and relevance is increasing. Furhermore, a previous selection of
medical images can be useful to accelerate the task of analysis by
pathologists. Herein this work we propose an image classifier to integrate a
CBIR (Content-Based Image Retrieval) selection system. This classifier is based
on pattern spectra and neural networks. Feature selection is performed using
pattern spectra and principal component analysis, whilst image classification
is based on multilayer perceptrons and a composition of self-organizing maps
and learning vector quantization. These methods were applied for content
selection of immunohistochemical images of placenta and newdeads lungs. Results
demonstrated that this approach can reach reasonable classification
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01696</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01696</id><created>2017-12-03</created><authors><author><keyname>Santos</keyname><forenames>Wellington Pinheiro dos</forenames></author><author><keyname>de Assis</keyname><forenames>Francisco Marcos</forenames></author></authors><title>Avalia\c{c}\~ao do m\'etodo dial\'etico na quantiza\c{c}\~ao de imagens
  multiespectrais</title><categories>cs.CV eess.IV</categories><comments>in Portuguese</comments><journal-ref>Learning and Nonlinear Models, v. 8, p. 174-201, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The unsupervised classification has a very important role in the analysis of
multispectral images, given its ability to assist the extraction of a priori
knowledge of images. Algorithms like k-means and fuzzy c-means has long been
used in this task. Computational Intelligence has proven to be an important
field to assist in building classifiers optimized according to the quality of
the grouping of classes and the evaluation of the quality of vector
quantization. Several studies have shown that Philosophy, especially the
Dialectical Method, has served as an important inspiration for the construction
of new computational methods. This paper presents an evaluation of four methods
based on the Dialectics: the Objective Dialectical Classifier and the
Dialectical Optimization Method adapted to build a version of k-means with
optimal quality indices; each of them is presented in two versions: a canonical
version and another version obtained by applying the Principle of Maximum
Entropy. These methods were compared to k-means, fuzzy c-means and Kohonen's
self-organizing maps. The results showed that the methods based on Dialectics
are robust to noise, and quantization can achieve results as good as those
obtained with the Kohonen map, considered an optimal quantizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01697</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01697</id><created>2017-12-03</created><authors><author><keyname>Santos</keyname><forenames>Wellington Pinheiro dos</forenames></author><author><keyname>de Assis</keyname><forenames>Francisco Marcos</forenames></author><author><keyname>de Souza</keyname><forenames>Ricardo Emmanuel</forenames></author><author><keyname>Filho</keyname><forenames>Pl&#xed;nio Batista dos Santos</forenames></author><author><keyname>Neto</keyname><forenames>Fernando Buarque de Lima</forenames></author></authors><title>Dialectical Multispectral Classification of Diffusion-Weighted Magnetic
  Resonance Images as an Alternative to Apparent Diffusion Coefficients Maps to
  Perform Anatomical Analysis</title><categories>cs.CV cs.GR cs.NE eess.IV</categories><journal-ref>Computerized Medical Imaging and Graphics, v. 33, p. 442-460, 2009</journal-ref><doi>10.1016/j.compmedimag.2009.04.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multispectral image analysis is a relatively promising field of research with
applications in several areas, such as medical imaging and satellite
monitoring. A considerable number of current methods of analysis are based on
parametric statistics. Alternatively, some methods in Computational
Intelligence are inspired by biology and other sciences. Here we claim that
Philosophy can be also considered as a source of inspiration. This work
proposes the Objective Dialectical Method (ODM): a method for classification
based on the Philosophy of Praxis. ODM is instrumental in assembling evolvable
mathematical tools to analyze multispectral images. In the case study described
in this paper, multispectral images are composed of diffusion-weighted (DW)
magnetic resonance (MR) images. The results are compared to ground-truth images
produced by polynomial networks using a morphological similarity index. The
classification results are used to improve the usual analysis of the apparent
diffusion coefficient map. Such results proved that gray and white matter can
be distinguished in DW-MR multispectral analysis and, consequently, DW-MR
images can also be used to furnish anatomical information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01700</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01700</id><created>2017-12-03</created><authors><author><keyname>Santos</keyname><forenames>Wellington Pinheiro dos</forenames></author><author><keyname>de Souza</keyname><forenames>Ricardo Emmanuel</forenames></author><author><keyname>Silva</keyname><forenames>Ascendino Fl&#xe1;vio Dias e</forenames></author><author><keyname>Filho</keyname><forenames>Pl&#xed;nio Batista dos Santos</forenames></author></authors><title>Avalia\c{c}\~ao da doen\c{c}a de Alzheimer pela an\'alise multiespectral
  de imagens DW-MR por redes RBF como alternativa aos mapas ADC</title><categories>cs.CV eess.IV</categories><comments>in Portuguese</comments><journal-ref>Learning and Nonlinear Models, v. 4, p. 43-53, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alzheimer's disease is the most common cause of dementia, yet difficult to
accurately diagnose without the use of invasive techniques, particularly at the
beginning of the disease. This work addresses the classification and analysis
of multispectral synthetic images composed by diffusion-weighted magnetic
resonance brain volumes for evaluation of the area of cerebrospinal fluid and
its correlation with the progression of Alzheimer's disease. A 1.5 T MR imaging
system was used to acquire all the images presented. The classification methods
are based on multilayer perceptrons and classifiers of radial basis function
networks. It is assumed that the classes of interest can be separated by
hyperquadrics. A polynomial network of degree 2 is used to classify the
original volumes, generating a ground-truth volume. The classification results
are used to improve the usual analysis by the map of apparent diffusion
coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01722</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01722</id><created>2017-11-08</created><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Liu</keyname><forenames>Xiao-Yang</forenames></author></authors><title>A Tensor Completion Approach for Efficient and Robust Fingerprint-based
  Indoor Localization</title><categories>eess.SP</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The localization technology is important for the development of indoor
location-based services (LBS). The radio frequency (RF) fingerprint-based
localization is one of the most promising approaches. However, it is
challenging to apply this localization to real-world environments since it is
time-consuming and labor-intensive to construct a fingerprint database as a
prior for localization. Another challenge is that the presence of anomaly
readings in the fingerprints reduces the localization accuracy. To address
these two challenges, we propose an efficient and robust indoor localization
approach. First, we model the fingerprint database as a 3-D tensor, which
represents the relationships between fingerprints, locations and indices of
access points. Second, we introduce a tensor decomposition model for robust
fingerprint data recovery, which decomposes a partial observation tensor as the
superposition of a low-rank tensor and a spare anomaly tensor. Third, we
exploit the alternating direction method of multipliers (ADMM) to solve the
convex optimization problem of tensor-nuclear-norm completion for the anomaly
case. Finally, we verify the proposed approach on a ground truth data set
collected in an office building with size 80m times 20m. Experiment results
show that to achieve a same error rate 4%, the sampling rate of our approach is
only 10%, while it is 60% for the state-of-the-art approach. Moreover, the
proposed approach leads to a more accurate localization (nearly 20%, 0.6m
improvement) over the compared approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01742</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01742</id><created>2017-12-05</created><authors><author><keyname>Wang</keyname><forenames>Yiqian</forenames></author><author><keyname>Sun</keyname><forenames>Wensheng</forenames></author></authors><title>Multi-speaker Recognition in Cocktail Party Problem</title><categories>eess.AS cs.SD</categories><comments>the 6th International Conference on Communications, Signal Processing
  and Systems (CSPS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an original statistical decision theory to accomplish a
multi-speaker recognition task in cocktail party problem. This theory relies on
an assumption that the varied frequencies of speakers obey Gaussian
distribution and the relationship of their voiceprints can be represented by
Euclidean distance vectors. This paper uses Mel-Frequency Cepstral Coefficients
to extract the feature of a voice in judging whether a speaker is included in a
multi-speaker environment and distinguish who the speaker should be. Finally, a
thirteen-dimension constellation drawing is established by mapping from
Manhattan distances of speakers in order to take a thorough consideration about
gross influential factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01743</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01743</id><created>2017-11-21</created><authors><author><keyname>Rusci</keyname><forenames>Manuele</forenames></author><author><keyname>Cavigelli</keyname><forenames>Lukas</forenames></author><author><keyname>Benini</keyname><forenames>Luca</forenames></author></authors><title>Design Automation for Binarized Neural Networks: A Quantum Leap
  Opportunity?</title><categories>cs.OH cs.AR cs.CV cs.NE eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Design automation in general, and in particular logic synthesis, can play a
key role in enabling the design of application-specific Binarized Neural
Networks (BNN). This paper presents the hardware design and synthesis of a
purely combinational BNN for ultra-low power near-sensor processing. We
leverage the major opportunities raised by BNN models, which consist mostly of
logical bit-wise operations and integer counting and comparisons, for pushing
ultra-low power deep learning circuits close to the sensor and coupling it with
binarized mixed-signal image sensor data. We analyze area, power and energy
metrics of BNNs synthesized as combinational networks. Our synthesis results in
GlobalFoundries 22nm SOI technology shows a silicon area of 2.61mm2 for
implementing a combinational BNN with 32x32 binary input sensor receptive field
and weight parameters fixed at design time. This is 2.2x smaller than a
synthesized network with re-configurable parameters. With respect to other
comparable techniques for deep learning near-sensor processing, our approach
features a 10x higher energy efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01769</identifier>
 <datestamp>2018-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01769</id><created>2017-12-05</created><updated>2018-02-23</updated><authors><author><keyname>Chiu</keyname><forenames>Chung-Cheng</forenames></author><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Prabhavalkar</keyname><forenames>Rohit</forenames></author><author><keyname>Nguyen</keyname><forenames>Patrick</forenames></author><author><keyname>Chen</keyname><forenames>Zhifeng</forenames></author><author><keyname>Kannan</keyname><forenames>Anjuli</forenames></author><author><keyname>Weiss</keyname><forenames>Ron J.</forenames></author><author><keyname>Rao</keyname><forenames>Kanishka</forenames></author><author><keyname>Gonina</keyname><forenames>Ekaterina</forenames></author><author><keyname>Jaitly</keyname><forenames>Navdeep</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Chorowski</keyname><forenames>Jan</forenames></author><author><keyname>Bacchiani</keyname><forenames>Michiel</forenames></author></authors><title>State-of-the-art Speech Recognition With Sequence-to-Sequence Models</title><categories>cs.CL cs.SD eess.AS stat.ML</categories><comments>ICASSP camera-ready version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attention-based encoder-decoder architectures such as Listen, Attend, and
Spell (LAS), subsume the acoustic, pronunciation and language model components
of a traditional automatic speech recognition (ASR) system into a single neural
network. In previous work, we have shown that such architectures are comparable
to state-of-theart ASR systems on dictation tasks, but it was not clear if such
architectures would be practical for more challenging tasks such as voice
search. In this work, we explore a variety of structural and optimization
improvements to our LAS model which significantly improve performance. On the
structural side, we show that word piece models can be used instead of
graphemes. We also introduce a multi-head attention architecture, which offers
improvements over the commonly-used single-head attention. On the optimization
side, we explore synchronous training, scheduled sampling, label smoothing, and
minimum word error rate optimization, which are all shown to improve accuracy.
We present results with a unidirectional LSTM encoder for streaming
recognition. On a 12, 500 hour voice search task, we find that the proposed
changes improve the WER from 9.2% to 5.6%, while the best conventional system
achieves 6.7%; on a dictation task our model achieves a WER of 4.1% compared to
5% for the conventional system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01807</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01807</id><created>2017-12-05</created><authors><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Chiu</keyname><forenames>Chung-Cheng</forenames></author><author><keyname>Prabhavalkar</keyname><forenames>Rohit</forenames></author><author><keyname>Kannan</keyname><forenames>Anjuli</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Nguyen</keyname><forenames>Patrick</forenames></author><author><keyname>Chen</keyname><forenames>Zhifeng</forenames></author></authors><title>Improving the Performance of Online Neural Transducer Models</title><categories>cs.CL eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Having a sequence-to-sequence model which can operate in an online fashion is
important for streaming applications such as Voice Search. Neural transducer is
a streaming sequence-to-sequence model, but has shown a significant degradation
in performance compared to non-streaming models such as Listen, Attend and
Spell (LAS). In this paper, we present various improvements to NT.
Specifically, we look at increasing the window over which NT computes
attention, mainly by looking backwards in time so the model still remains
online. In addition, we explore initializing a NT model from a LAS-trained
model so that it is guided with a better alignment. Finally, we explore
including stronger language models such as using wordpiece models, and applying
an external LM during the beam search. On a Voice Search task, we find with
these improvements we can get NT to match the performance of LAS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01818</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01818</id><created>2017-12-05</created><authors><author><keyname>Prabhavalkar</keyname><forenames>Rohit</forenames></author><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Nguyen</keyname><forenames>Patrick</forenames></author><author><keyname>Chen</keyname><forenames>Zhifeng</forenames></author><author><keyname>Chiu</keyname><forenames>Chung-Cheng</forenames></author><author><keyname>Kannan</keyname><forenames>Anjuli</forenames></author></authors><title>Minimum Word Error Rate Training for Attention-based
  Sequence-to-Sequence Models</title><categories>cs.CL eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence-to-sequence models, such as attention-based models in automatic
speech recognition (ASR), are typically trained to optimize the cross-entropy
criterion which corresponds to improving the log-likelihood of the data.
However, system performance is usually measured in terms of word error rate
(WER), not log-likelihood. Traditional ASR systems benefit from discriminative
sequence training which optimizes criteria such as the state-level minimum
Bayes risk (sMBR) which are more closely related to WER. In the present work,
we explore techniques to train attention-based models to directly minimize
expected word error rate. We consider two loss functions which approximate the
expected number of word errors: either by sampling from the model, or by using
N-best lists of decoded hypotheses, which we find to be more effective than the
sampling-based method. In experimental evaluations, we find that the proposed
training procedure improves performance by up to 8.2% relative to the baseline
system. This allows us to train grapheme-based, uni-directional attention-based
models which match the performance of a traditional, state-of-the-art,
discriminative sequence-trained system on a mobile voice-search task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01864</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01864</id><created>2017-12-05</created><authors><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Prabhavalkar</keyname><forenames>Rohit</forenames></author><author><keyname>Kumar</keyname><forenames>Shankar</forenames></author><author><keyname>Lee</keyname><forenames>Seungji</forenames></author><author><keyname>Kannan</keyname><forenames>Anjuli</forenames></author><author><keyname>Rybach</keyname><forenames>David</forenames></author><author><keyname>Schogol</keyname><forenames>Vlad</forenames></author><author><keyname>Nguyen</keyname><forenames>Patrick</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Chen</keyname><forenames>Zhifeng</forenames></author><author><keyname>Chiu</keyname><forenames>Chung-Cheng</forenames></author></authors><title>No Need for a Lexicon? Evaluating the Value of the Pronunciation Lexica
  in End-to-End Models</title><categories>cs.CL cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For decades, context-dependent phonemes have been the dominant sub-word unit
for conventional acoustic modeling systems. This status quo has begun to be
challenged recently by end-to-end models which seek to combine acoustic,
pronunciation, and language model components into a single neural network. Such
systems, which typically predict graphemes or words, simplify the recognition
process since they remove the need for a separate expert-curated pronunciation
lexicon to map from phoneme-based units to words. However, there has been
little previous work comparing phoneme-based versus grapheme-based sub-word
units in the end-to-end modeling framework, to determine whether the gains from
such approaches are primarily due to the new probabilistic model, or from the
joint learning of the various components with grapheme-based units.
  In this work, we conduct detailed experiments which are aimed at quantifying
the value of phoneme-based pronunciation lexica in the context of end-to-end
models. We examine phoneme-based end-to-end models, which are contrasted
against grapheme-based ones on a large vocabulary English Voice-search task,
where we find that graphemes do indeed outperform phonemes. We also compare
grapheme and phoneme-based approaches on a multi-dialect English task, which
once again confirm the superiority of graphemes, greatly simplifying the system
for recognizing multiple dialects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01916</identifier>
 <datestamp>2018-08-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01916</id><created>2017-12-05</created><authors><author><keyname>Cameron</keyname><forenames>Karleigh J.</forenames></author><author><keyname>Bates</keyname><forenames>Daniel J.</forenames></author></authors><title>Geolocation with FDOA Measurements via Polynomial Systems and RANSAC</title><categories>eess.SP</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><doi>10.1109/RADAR.2018.8378640</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of geolocation of a transmitter via time difference of arrival
(TDOA) and frequency difference of arrival (FDOA) is given as a system of
polynomial equations. This allows for the use of homotopy continuation-based
methods from numerical algebraic geometry. A novel geolocation algorithm
employs numerical algebraic geometry techniques in conjunction with the random
sample consensus (RANSAC) method. This is all developed and demonstrated in the
setting of only FDOA measurements, without loss of generality. Additionally,
the problem formulation as polynomial systems immediately provides lower bounds
on the number of receivers or measurements required for the solution set to
consist of only isolated points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.01996</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.01996</id><created>2017-12-05</created><authors><author><keyname>Kannan</keyname><forenames>Anjuli</forenames></author><author><keyname>Wu</keyname><forenames>Yonghui</forenames></author><author><keyname>Nguyen</keyname><forenames>Patrick</forenames></author><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Chen</keyname><forenames>Zhifeng</forenames></author><author><keyname>Prabhavalkar</keyname><forenames>Rohit</forenames></author></authors><title>An analysis of incorporating an external language model into a
  sequence-to-sequence model</title><categories>eess.AS cs.AI cs.CL cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attention-based sequence-to-sequence models for automatic speech recognition
jointly train an acoustic model, language model, and alignment mechanism. Thus,
the language model component is only trained on transcribed audio-text pairs.
This leads to the use of shallow fusion with an external language model at
inference time. Shallow fusion refers to log-linear interpolation with a
separately trained language model at each step of the beam search. In this
work, we investigate the behavior of shallow fusion across a range of
conditions: different types of language models, different decoding units, and
different tasks. On Google Voice Search, we demonstrate that the use of shallow
fusion with a neural LM with wordpieces yields a 9.1% relative word error rate
reduction (WERR) over our competitive attention-based sequence-to-sequence
model, obviating the need for second-pass rescoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02116</identifier>
 <datestamp>2019-04-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02116</id><created>2017-12-06</created><updated>2019-04-06</updated><authors><author><keyname>Phan</keyname><forenames>Huy</forenames></author><author><keyname>Koch</keyname><forenames>Philipp</forenames></author><author><keyname>McLoughlin</keyname><forenames>Ian</forenames></author><author><keyname>Mertins</keyname><forenames>Alfred</forenames></author></authors><title>Enabling Early Audio Event Detection with Neural Networks</title><categories>cs.SD cs.LG eess.AS</categories><comments>Published version available at
  https://ieeexplore.ieee.org/document/8461859</comments><journal-ref>Published in Proceedings of 43rd IEEE International Conference on
  Acoustics, Speech, and Signal Processing (ICASSP), pp. 141-145, 2018</journal-ref><doi>10.1109/ICASSP.2018.8461859</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a methodology for early detection of audio events from
audio streams. Early detection is the ability to infer an ongoing event during
its initial stage. The proposed system consists of a novel inference step
coupled with dual parallel tailored-loss deep neural networks (DNNs). The DNNs
share a similar architecture except for their loss functions, i.e. weighted
loss and multitask loss, which are designed to efficiently cope with issues
common to audio event detection. The inference step is newly introduced to make
use of the network outputs for recognizing ongoing events. The monotonicity of
the detection function is required for reliable early detection, and will also
be proved. Experiments on the ITC-Irst database show that the proposed system
achieves state-of-the-art detection performance. Furthermore, even partial
events are sufficient to achieve good performance similar to that obtained when
an entire event is observed, enabling early event detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02146</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02146</id><created>2017-12-06</created><authors><author><keyname>Lunglmayr</keyname><forenames>Michael</forenames></author><author><keyname>Lang</keyname><forenames>Oliver</forenames></author><author><keyname>Huemer</keyname><forenames>Mario</forenames></author></authors><title>Knowledge-Aided Kaczmarz and LMS Algorithms</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The least mean squares (LMS) filter is often derived via the Wiener filter
solution. For a system identification scenario, such a derivation makes it hard
to incorporate prior information on the system's impulse response. We present
an alternative way based on the maximum a posteriori solution, which allows
developing a Knowledge-Aided Kaczmarz algorithm. Based on this Knowledge-Aided
Kaczmarz we formulate a Knowledge-Aided LMS filter. Both algorithms allow
incorporating the prior mean and covariance matrix on the parameter to be
estimated. The algorithms use this prior information in addition to the
measurement information in the gradient for the iterative update of their
estimates. We analyze the convergence of the algorithms and show simulation
results on their performance. As expected, reliable prior information allows
improving the performance of the algorithms for low signal-to-noise (SNR)
scenarios. The results show that the presented algorithms can nearly achieve
the optimal maximum a posteriori (MAP) performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02179</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02179</id><created>2017-12-06</created><updated>2017-12-07</updated><authors><author><keyname>Wang</keyname><forenames>Wentao</forenames></author><author><keyname>Han</keyname><forenames>Qi</forenames></author><author><keyname>Chen</keyname><forenames>Hui</forenames></author><author><keyname>Yuan</keyname><forenames>Yuan</forenames></author><author><keyname>Xu</keyname><forenames>Zhuo</forenames></author></authors><title>Ptychography intensity interferometry imaging</title><categories>eess.IV eess.SP physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intensity interferometry (II) exploits the second-order correlation to
acquire the spatial frequency information of an object, which has been used to
observe distant stars since 1950s. However, due to unreliability of employed
imaging reconstruction algorithms, II can only image simple and sparse objects
such as double stars. We here develop a method that overcomes this
unreliability problem and enables imaging complex objects by combing II and a
ptychography iterative algorithm. Different from previous ptychography
iterative-type algorithms that work only for diffractive objects using
coherence light sources, our method obtains the objects spatial spectrum from
the second-order correlation of intensity fluctuation by using an incoherent
source, which therefore largely simplifies the imaging process. Furthermore, by
introducing loose supports in the ptychography algorithm, a high-quality image
can be recovered without knowing the precise size and position of the scanning
illumination, which is a strong requirement for traditional ptychography
iterative algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02277</identifier>
 <datestamp>2019-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02277</id><created>2017-12-04</created><updated>2019-04-30</updated><authors><author><keyname>Shirvanimoghaddam</keyname><forenames>Mahyar</forenames></author><author><keyname>Shirvanimoghaddam</keyname><forenames>Kamyar</forenames></author><author><keyname>Abolhasani</keyname><forenames>Mohammad Mahdi</forenames></author><author><keyname>Farhangi</keyname><forenames>Majid</forenames></author><author><keyname>Barsari</keyname><forenames>Vaid Zahiri</forenames></author><author><keyname>Liu</keyname><forenames>Hangyue</forenames></author><author><keyname>Dohler</keyname><forenames>Mischa</forenames></author><author><keyname>Naebe</keyname><forenames>Minoo</forenames></author></authors><title>Towards a Green and Self-Powered Internet of Things Using Piezoelectric
  Energy Harvesting</title><categories>eess.SP</categories><comments>The paper has been submitted to IEEE Access</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet of things (IoT) is a revolutionizing technology which aims to create
an ecosystem of connected objects and embedded devices and provide ubiquitous
connectivity between trillions of not only smart devices but also simple
sensors and actuators. Although recent advancements in miniaturization of
devices with higher computational capabilities and ultra-low power
communication technologies have enabled the vast deployment of sensors and
actuators everywhere, such an evolution calls for fundamental changes in
hardware design, software, network architecture, data analytic, data storage
and power sources. A large portion of IoT devices cannot be powered by
batteries only anymore, as they will be installed in hard to reach areas and
regular battery replacement and maintenance are infeasible. A viable solution
is to scavenge and harvest energy from environment and then provide enough
energy to the devices to perform their operations. This will significantly
increase the device life time and eliminate the need for the battery as an
energy source. This survey aims at providing a comprehensive study on energy
harvesting techniques as alternative and promising solutions to power IoT
devices. We present the main design challenges of IoT devices in terms of
energy and power and provide design considerations for a successful
implementations of self-powered IoT devices. We then specifically focus on
piezoelectric energy harvesting and RF energy harvesting as most promising
solutions to power IoT devices and present the main challenges and research
directions. We also shed light on the security challenges of energy harvesting
enabled IoT systems and green big data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02453</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02453</id><created>2017-12-06</created><authors><author><keyname>Muns</keyname><forenames>Guillem Reus</forenames></author><author><keyname>Mishra</keyname><forenames>Kumar Vijay</forenames></author><author><keyname>Guerra</keyname><forenames>Carlos Bocanegra</forenames></author><author><keyname>Eldar</keyname><forenames>Yonnina C.</forenames></author><author><keyname>Chowdhury</keyname><forenames>Kaushik R.</forenames></author></authors><title>Beam Alignment and Tracking for Autonomous Vehicular Communication using
  IEEE 802.11ad-based Radar</title><categories>eess.SP</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobility scenarios involving short contact times pose a challenge for high
bandwidth data transfer between autonomous vehicles and roadside base stations
(BS). Millimeter wave bands are a viable solution as they offer enormous
bandwidth in the 60GHz band with several Gbps data transfer rates. However,
beamforming is used as a default mode in this band, which requires accurate and
continuous alignment under relative motion. We propose a method in which an
off-the-shelf IEEE 802.11ad WiFi router is configured to serve as the BS as
well as a radar exploiting special structure of 802.11ad preamble. We embed the
radar functionality within standards-compliant operations that do not modify
the core structure of the frames beyond what is defined by the 802.11ad
protocol. This not only reduces the beam training time, but also ensures
scalability with increasing vehicular traffic because radar allows accurate
ranging of up to 0.1m at distances up to 200m. We further analyze the ensuing
cost-benefit trade-off between the time allotted to the proposed in-band radar
and communication modes. Our results reveal 83% reduction on the overhead
incurred during the beam training achieved for a specific simulated vehicular
scenario over the classical 802.11ad operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02567</identifier>
 <datestamp>2018-11-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02567</id><created>2017-12-07</created><updated>2018-11-28</updated><authors><author><keyname>Silva</keyname><forenames>Nishal</forenames></author><author><keyname>Weeraddana</keyname><forenames>Chathuranga</forenames></author><author><keyname>Fischione</keyname><forenames>Carlo</forenames></author></authors><title>On Musical Onset Detection via the S-Transform</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Musical onset detection is a key component in any beat tracking system.
Existing onset detection methods are based on temporal/spectral analysis, or
methods that integrate temporal and spectral information together with
statistical estimation and machine learning models. In this paper, we propose a
method to localize onset components in music by using the S-transform, and
thus, the method is purely based on temporal/spectral data. Unlike the other
methods based on temporal/spectral data, which usually rely short time Fourier
transform (STFT), our method enables effective isolation of crucial frequency
subbands due to the frequency dependent resolution of S-transform. Moreover,
numerical results show, even with less computationally intensive steps, the
proposed method can closely resemble the performance of more resource intensive
statistical estimation based approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02675</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02675</id><created>2017-12-07</created><updated>2017-12-19</updated><authors><author><keyname>Svensson</keyname><forenames>Andreas</forenames></author><author><keyname>Zachariah</keyname><forenames>Dave</forenames></author><author><keyname>Sch&#xf6;n</keyname><forenames>Thomas B.</forenames></author></authors><title>How consistent is my model with the data? Information-Theoretic Model
  Check</title><categories>stat.ML cs.LG eess.SP stat.ME</categories><comments>The title has been updated, but no other significant changes have
  been made from the previous version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The choice of model class is fundamental in statistical learning and system
identification, no matter whether the class is derived from physical principles
or is a generic black-box. We develop a method to evaluate the specified model
class by assessing its capability of reproducing data that is similar to the
observed data record. This model check is based on the information-theoretic
properties of models viewed as data generators and is applicable to e.g.
sequential data and nonlinear dynamical models. The method can be understood as
a specific two-sided posterior predictive test. We apply the
information-theoretic model check to both synthetic and real data and compare
it with a classical whiteness test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02877</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02877</id><created>2017-12-07</created><authors><author><keyname>Bazrafkan</keyname><forenames>Shabab</forenames></author><author><keyname>Thavalengal</keyname><forenames>Shejin</forenames></author><author><keyname>Corcoran</keyname><forenames>Peter</forenames></author></authors><title>An End to End Deep Neural Network for Iris Segmentation in Unconstraint
  Scenarios</title><categories>eess.IV cs.CV</categories><doi>10.1016/j.neunet.2018.06.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing imaging and processing capabilities of today's mobile
devices, user authentication using iris biometrics has become feasible.
However, as the acquisition conditions become more unconstrained and as image
quality is typically lower than dedicated iris acquisition systems, the
accurate segmentation of iris regions is crucial for these devices. In this
work, an end to end Fully Convolutional Deep Neural Network (FCDNN) design is
proposed to perform the iris segmentation task for lower-quality iris images.
The network design process is explained in detail, and the resulting network is
trained and tuned using several large public iris datasets. A set of methods to
generate and augment suitable lower quality iris images from the high-quality
public databases are provided. The network is trained on Near InfraRed (NIR)
images initially and later tuned on additional datasets derived from visible
images. Comprehensive inter-database comparisons are provided together with
results from a selection of experiments detailing the effects of different
tunings of the network. Finally, the proposed model is compared with
SegNet-basic, and a near-optimal tuning of the network is compared to a
selection of other state-of-art iris segmentation algorithms. The results show
very promising performance from the optimized Deep Neural Networks design when
compared with state-of-art techniques applied to the same lower quality
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02898</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02898</id><created>2017-12-07</created><authors><author><keyname>Shuvaev</keyname><forenames>Sergey</forenames></author><author><keyname>Giaffar</keyname><forenames>Hamza</forenames></author><author><keyname>Koulakov</keyname><forenames>Alexei A.</forenames></author></authors><title>Representations of Sound in Deep Learning of Audio Features from Music</title><categories>cs.SD cs.CV eess.AS q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work of a single musician, group or composer can vary widely in terms of
musical style. Indeed, different stylistic elements, from performance medium
and rhythm to harmony and texture, are typically exploited and developed across
an artist's lifetime. Yet, there is often a discernable character to the work
of, for instance, individual composers at the perceptual level - an experienced
listener can often pick up on subtle clues in the music to identify the
composer or performer. Here we suggest that a convolutional network may learn
these subtle clues or features given an appropriate representation of the
music. In this paper, we apply a deep convolutional neural network to a large
audio dataset and empirically evaluate its performance on audio classification
tasks. Our trained network demonstrates accurate performance on such
classification tasks when presented with 5 s examples of music obtained by
simple transformations of the raw audio waveform. A particularly interesting
example is the spectral representation of music obtained by application of a
logarithmically spaced filter bank, mirroring the early stages of auditory
signal transduction in mammals. The most successful representation of music to
facilitate discrimination was obtained via a random matrix transform (RMT).
Networks based on logarithmic filter banks and RMT were able to correctly guess
the one composer out of 31 possibilities in 68 and 84 percent of cases
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02903</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02903</id><created>2017-12-07</created><updated>2018-07-20</updated><authors><author><keyname>Traganitis</keyname><forenames>Panagiotis A.</forenames></author><author><keyname>Pag&#xe8;s-Zamora</keyname><forenames>Alba</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Blind Multiclass Ensemble Classification</title><categories>stat.ML cs.LG eess.SP</categories><comments>To appear in IEEE Transactions in Signal Processing</comments><doi>10.1109/TSP.2018.2860562</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rising interest in pattern recognition and data analytics has spurred the
development of innovative machine learning algorithms and tools. However, as
each algorithm has its strengths and limitations, one is motivated to
judiciously fuse multiple algorithms in order to find the &quot;best&quot; performing
one, for a given dataset. Ensemble learning aims at such high-performance
meta-algorithm, by combining the outputs from multiple algorithms. The present
work introduces a blind scheme for learning from ensembles of classifiers,
using a moment matching method that leverages joint tensor and matrix
factorization. Blind refers to the combiner who has no knowledge of the
ground-truth labels that each classifier has been trained on. A rigorous
performance analysis is derived and the proposed scheme is evaluated on
synthetic and real datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02981</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02981</id><created>2017-12-08</created><authors><author><keyname>Xiong</keyname><forenames>Dan</forenames></author><author><keyname>Chai</keyname><forenames>Li</forenames></author><author><keyname>Zhang</keyname><forenames>Jingxin</forenames></author></authors><title>Uncertainty Principle and Sparse Reconstruction in Pairs of Orthonormal
  Rational Function Bases</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most rational systems can be described in terms of orthonormal basis
functions. This paper considers the reconstruction of a sparse coefficient
vector for a rational transfer function under a pair of orthonormal rational
function bases and from a limited number of linear frequency-domain
measurements. We prove the uncertainty principle concerning pairs of
compressible representation of orthonormal rational functions in the infinite
dimensional function space. The uniqueness of compressible representation using
such pairs is provided as a direct consequence of uncertainty principle. The
bound of the number of measurements which guarantees the replacement of 1_0
optimization searching for the unique sparse reconstruction by 1_1 optimization
using random sampling on the unit circle with high probability is provided as
well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.02997</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.02997</id><created>2017-12-08</created><authors><author><keyname>Piotrowski</keyname><forenames>Tomasz</forenames></author><author><keyname>Nikadon</keyname><forenames>Jan</forenames></author><author><keyname>Gutierrez</keyname><forenames>David</forenames></author></authors><title>Reconstruction of Brain Activity from EEG/MEG Using MV-PURE Framework</title><categories>eess.SP math.OC</categories><comments>Submitted to IEEE Transactions on Signal Processing on Jul 13, 2017</comments><msc-class>94A12, 60G35, 92C55, 15A29</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of reconstruction of brain activity from
electroencephalography (EEG) or magnetoencephalography (MEG) using spatial
filtering (beamforming). We propose spatial filters which are based on the
minimum-variance pseudo-unbiased reduced-rank estimation (MV-PURE) framework.
They come in two flavours, depending whether the EEG/MEG forward model
considers explicitly &quot;interfering activity&quot;, understood as brain's electrical
activity originating from brain areas other than regions of interest which is
recorded at EEG/MEG sensors as a signal correlated with activity of interest.
In both cases, the proposed filters are equipped with a rank-selection
criterion minimizing the mean-square-error (MSE) of the filter output.
Therefore, we consider them as novel nontrivial generalizations of well-known
linearly constrained minimum-variance (LCMV) and nulling filters. The proposed
filters have equally wide area of applications, which include in particular
evaluation of directed connectivity measures based on the reconstructed
activity of sources of interest, considered in this paper as a sample
application. Moreover, in order to facilitate reproducibility of our research,
we provide (jointly with this paper) comprehensive simulation framework that
allows for estimation of error of signal reconstruction for a number of spatial
filters applied to MEG or EEG signals. Based on this framework, chief
properties of proposed filters are verified in a set of detailed simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03183</identifier>
 <datestamp>2018-02-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03183</id><created>2017-12-06</created><authors><author><keyname>Ledesma-Alonso</keyname><forenames>Rene</forenames></author><author><keyname>Barbosa</keyname><forenames>Romeli</forenames></author><author><keyname>Ortegon</keyname><forenames>Jaime</forenames></author></authors><title>Effect of the image resolution on the statistical descriptors of
  heterogeneous media</title><categories>eess.IV cond-mat.mtrl-sci</categories><journal-ref>Phys. Rev. E 97, 023304 (2018)</journal-ref><doi>10.1103/PhysRevE.97.023304</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The characterization and reconstruction of heterogeneous materials, such as
porous media and electrode materials, involve the application of image
processing methods to data acquired by microscopy techniques. In this study, we
present a theoretical analysis of the effects of the image size reduction, due
to a gradual decimation of the original image. Three different decimation
procedures were implemented and their consequences on the discrete correlation
functions and the coarseness are reported and analyzed. A normalization for
each of the correlation functions has been performed. When the loss of
statistical information has not been significant for a decimated image, its
normalized correlation function is forecast by the trend of the original image.
In contrast, when the decimated image does not represent the statistical
evidence of the original one, the normalized correlation function diverts from
the reference function. Moreover, the equally weighted sum of the average of
the squared differences leads to a definition of an overall error. During the
first stages of the gradual decimation, the error remains relatively small and
independent of the decimation procedure. Above a threshold defined by the
correlation length of the reference function, the error becomes a function of
the number of decimation steps. At this stage, some statistical information is
lost and the error becomes dependent of the decimation procedure. These results
may help us to restrict the amount of information that one can afford to lose
during a decimation process, in order to reduce the computational and memory
cost, when one aims to diminish the time consumed by a characterization or
reconstruction technique, yet maintaining the statistical quality of the
digitized sample.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03228</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03228</id><created>2017-12-08</created><authors><author><keyname>Sarnatskyi</keyname><forenames>Vladyslav</forenames></author><author><keyname>Ovcharenko</keyname><forenames>Vadym</forenames></author><author><keyname>Tkachenko</keyname><forenames>Mariia</forenames></author><author><keyname>Stirenko</keyname><forenames>Sergii</forenames></author><author><keyname>Gordienko</keyname><forenames>Yuri</forenames></author><author><keyname>Rojbi</keyname><forenames>Anis</forenames></author></authors><title>Music Transcription by Deep Learning with Data and &quot;Artificial Semantic&quot;
  Augmentation</title><categories>cs.SD cs.LG eess.AS</categories><comments>4 pages, 3 figures</comments><journal-ref>International Journal of Systems Applications Engineering and
  Development, 11, 212-215 (2017)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this progress paper the previous results of the single note recognition by
deep learning are presented. The several ways for data augmentation and
&quot;artificial semantic&quot; augmentation are proposed to enhance efficiency of deep
learning approaches for monophonic and polyphonic note recognition by increase
of dimensions of training data, their lossless and lossy transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03267</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03267</id><created>2017-12-08</created><authors><author><keyname>Barazideh</keyname><forenames>Reza</forenames></author><author><keyname>Natarajan</keyname><forenames>Balasubramaniam</forenames></author><author><keyname>Nikitin</keyname><forenames>Alexei V.</forenames></author><author><keyname>Davidchack</keyname><forenames>Ruslan L.</forenames></author></authors><title>Performance of Analog Nonlinear Filtering for Impulsive Noise Mitigation
  in OFDM-based PLC Systems</title><categories>eess.SP</categories><comments>This paper has been accepted and presented in Latincom 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Asynchronous and cyclostationary impulsive noise can severely impact the
bit-error-rate (BER) of OFDM-based powerline communication systems. In this
paper, we analyze an adaptive nonlinear analog front end filter that mitigates
various types of impulsive noise without detrimental effects such as
self-interference and out-of-band power leakage caused by other nonlinear
approaches like clipping and blanking. Our proposed Adaptive Nonlinear
Differential Limiter (ANDL) is constructed from a linear analog filter by
applying a feedback-based nonlinearity, controlled by a single resolution
parameter. We present a simple practical method to find the value of this
resolution parameter that ensures the mitigation of impulsive without impacting
the desired OFDM signal. Unlike many prior approaches for impulsive noise
mitigation that assume a statistical noise model, ANDL is blind to the exact
nature of the noise distribution, and is designed to be fully compatible with
existing linear front end filters. We demonstrate the potency of ANDL by
simulating the OFDM-based narrowband PLC compliant with the IEEE standards. We
show that the proposed ANDL outperforms other approaches in reducing the BER in
impulsive noise environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03328</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03328</id><created>2017-12-08</created><authors><author><keyname>Floriach-Pigem</keyname><forenames>Marti</forenames></author><author><keyname>Xercavins-Torregrosa</keyname><forenames>Guillem</forenames></author><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author><author><keyname>Gelonch-Bosch</keyname><forenames>Antoni</forenames></author></authors><title>Open Orchestration Cloud Radio Access Network (OOCRAN) Testbed</title><categories>cs.NI eess.SP</categories><comments>International Workshop on Clouds and (eScience) Applications
  Management - CloudAM 2017, 10th IEEE/ACM Utility and Cloud Computing (UCC)</comments><msc-class>68M10</msc-class><doi>10.1145/3147234.3148113</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Cloud radio access network (C-RAN) offers a revolutionary approach to
cellular network deployment, management and evolution. Advances in
software-defined radio (SDR) and networking technology, moreover, enable
delivering software-defined everything through the Cloud. Resources will be
pooled and dynamically allocated leveraging abstraction, virtualization, and
consolidation techniques; processes will be automated using common application
programming interfaces; and network functions and services will be
programmatically provided through an orchestrator. OOCRAN, oocran.dynu.com, is
a software framework that is based on the NFV MANO architecture proposed by
ETSI. It provides an orchestration layer for the entire wireless
infrastructure, including hardware, software, spectrum, fronthaul and backhaul.
OOCRAN extends existing NFV management frameworks by incorporating the radio
communications layers and their management dependencies. The wireless
infrastructure provider can then dynamically provision virtualized wireless
networks to wireless service providers. The testbed's physical infrastructure
is built around a computing cluster that executes open-source SDR libraries and
connects to SDR-based remote radio heads. We demonstrate the operation of
OOCRAN and discuss the temporal implications of dynamic LTE small cell network
deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03381</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03381</id><created>2017-12-09</created><authors><author><keyname>Chen</keyname><forenames>Rui</forenames></author><author><keyname>Yang</keyname><forenames>Changshui</forenames></author><author><keyname>Jia</keyname><forenames>Huizhu</forenames></author><author><keyname>Xie</keyname><forenames>Xiaodong</forenames></author></authors><title>Noise Level Estimation for Overcomplete Dictionary Learning Based on
  Tight Asymptotic Bounds</title><categories>eess.SP cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we address the problem of estimating Gaussian noise level
from the trained dictionaries in update stage. We first provide rigorous
statistical analysis on the eigenvalue distributions of a sample covariance
matrix. Then we propose an interval-bounded estimator for noise variance in
high dimensional setting. To this end, an effective estimation method for noise
level is devised based on the boundness and asymptotic behavior of noise
eigenvalue spectrum. The estimation performance of our method has been
guaranteed both theoretically and empirically. The analysis and experiment
results have demonstrated that the proposed algorithm can reliably infer true
noise levels, and outperforms the relevant existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03401</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03401</id><created>2017-12-09</created><authors><author><keyname>Tan</keyname><forenames>Bo</forenames></author><author><keyname>Chen</keyname><forenames>Qingchao</forenames></author><author><keyname>Chetty</keyname><forenames>Kevin</forenames></author><author><keyname>Woodbridge</keyname><forenames>Karl</forenames></author><author><keyname>Li</keyname><forenames>Wenda</forenames></author><author><keyname>Piechocki</keyname><forenames>Robert</forenames></author></authors><title>Exploiting WiFi Channel State Information for Residential Healthcare
  Informatics</title><categories>eess.SP</categories><comments>5 figures, 1 table, 6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection and interpretation of human activities have emerged as a
challenging healthcare problem in areas such as assisted living and remote
monitoring. Besides traditional approaches that rely on wearable devices and
camera systems, WiFi based technologies are evolving as a promising solution
for indoor monitoring and activity recognition. This is, in part, due to the
pervasive nature of WiFi in residential settings such as homes and care
facilities, and unobtrusive nature of WiFi based sensing. Advanced signal
processing techniques can accurately extract WiFi channel status information
(CSI) using commercial off-the-shelf (COTS) devices or bespoke hardware. This
includes phase variations, frequency shifts and signal levels. In this paper,
we describe the healthcare application of Doppler shifts in the WiFi CSI,
caused by human activities which take place in the signal coverage area. The
technique is shown to recognize different types of human activities and
behaviour and be very suitable for applications in healthcare. Three
experimental case studies are presented to illustrate the capabilities of WiFi
CSI Doppler sensing in assisted living and residential care environments. We
also discuss the potential opportunities and practical challenges for
real-world scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03439</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03439</id><created>2017-12-09</created><updated>2018-12-31</updated><authors><author><keyname>Kim</keyname><forenames>Chanwoo</forenames></author><author><keyname>Variani</keyname><forenames>Ehsan</forenames></author><author><keyname>Narayanan</keyname><forenames>Arun</forenames></author><author><keyname>Bacchiani</keyname><forenames>Michiel</forenames></author></authors><title>Efficient Implementation of the Room Simulator for Training Deep Neural
  Network Acoustic Models</title><categories>cs.SD eess.AS eess.SP</categories><comments>Published at INTERSPEECH 2018.
  (https://www.isca-speech.org/archive/Interspeech_2018/abstracts/2566.html)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe how to efficiently implement an acoustic room
simulator to generate large-scale simulated data for training deep neural
networks. Even though Google Room Simulator in [1] was shown to be quite
effective in reducing the Word Error Rates (WERs) for far-field applications by
generating simulated far-field training sets, it requires a very large number
of Fast Fourier Transforms (FFTs) of large size. Room Simulator in [1] used
approximately 80 percent of Central Processing Unit (CPU) usage in our CPU +
Graphics Processing Unit (GPU) training architecture [2]. In this work, we
implement an efficient OverLap Addition (OLA) based filtering using the
open-source FFTW3 library. Further, we investigate the effects of the Room
Impulse Response (RIR) lengths. Experimentally, we conclude that we can cut the
tail portions of RIRs whose power is less than 20 dB below the maximum power
without sacrificing the speech recognition accuracy. However, we observe that
cutting RIR tail more than this threshold harms the speech recognition accuracy
for rerecorded test sets. Using these approaches, we were able to reduce CPU
usage for the room simulator portion down to 9.69 percent in CPU/GPU training
architecture. Profiling result shows that we obtain 22.4 times speed-up on a
single machine and 37.3 times speed up on Google's distributed training
infrastructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03531</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03531</id><created>2017-12-10</created><authors><author><keyname>Abeywickrama</keyname><forenames>Samith</forenames></author><author><keyname>Samarasinghe</keyname><forenames>Tharaka</forenames></author><author><keyname>Ho</keyname><forenames>Chin Keong</forenames></author></authors><title>Wireless Energy Beamforming Using Signal Strength Feedback</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 6 figures, in Proc. IEEE Global Communications Conference
  (GLOBECOM), 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple antenna techniques, that allow energy beamforming, have been looked
upon as a possible candidate for increasing the efficiency of the transfer
process between the energy transmitter (ET) and the energy receiver (ER) in
wireless energy transfer. This paper introduces a novel scheme that facilitates
energy beamforming by utilizing Received Signal Strength Indicator (RSSI)
values to estimate the channel. Firstly, in the training stage, the ET will
transmit sequentially using each beamforming vector in a codebook, which is
pre-defined using a Cramer-Rao lower bound analysis. The RSSI value
corresponding to each beamforming vector is fed back to the ET, and these
values are used to estimate the channel through a maximum likelihood analysis.
The results that are obtained are remarkably simple, requires minimal
processing, and can be easily implemented. Also, the results are general and
hold for all well known fading models. The paper also validates the analytical
results numerically, as well as experimentally, and it is shown that the
proposed method achieves impressive results in wireless energy transfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03569</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03569</id><created>2017-12-10</created><authors><author><keyname>Burskii</keyname><forenames>Vladimir P.</forenames></author></authors><title>The organization of a three-manual keyboard for 53-tone tempered and
  other tempered systems</title><categories>cs.SD eess.AS</categories><comments>16 pages, in Russian, 10 tables</comments><msc-class>94A99</msc-class><acm-class>H.5.5; H.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim is to explore new opportunities of the pitch organization of the
musical scale. Specifically, a numerical comparison of the different musical
temperaments among themselves in the degree of approximation of the Pythagorean
scale is provided, and thus it numerically substantiates the thesis that the
53-tone tempered system is the most advanced among possible others. We present
numerical data on the approximation of overtones from first twenty by steps of
the 53-tone temperament. Here were proposed some schemes of the three-manual
keyboard for the implementation of 53-tone temperament, which are also
implemented at the same time for 12 -, 17 -, 24 -, 29 - and 41-sounding system.
If there are technical means then these schemes can be used to play music in
any temperaments, based on said number of steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03579</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03579</id><created>2017-12-10</created><authors><author><keyname>Reza</keyname><forenames>Mohi</forenames></author><author><keyname>Rashid</keyname><forenames>Warida</forenames></author><author><keyname>Mostakim</keyname><forenames>Moin</forenames></author></authors><title>Prodorshok I: A Bengali Isolated Speech Dataset for Voice-Based
  Assistive Technologies - A comparative analysis of the effects of data
  augmentation on HMM-GMM and DNN classifiers</title><categories>cs.SD cs.HC eess.AS</categories><comments>4 pages, accepted for oral presentation at the 5th IEEE R10 HTC 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prodorshok I is a Bengali isolated word dataset tailored to help create
speaker-independent, voice-command driven automated speech recognition (ASR)
based assistive technologies to help improve human-computer interaction (HCI).
This paper presents the results of an objective analysis that was undertaken
using a subset of words from Prodorshok I to assess its reliability in ASR
systems that utilize Hidden Markov Models (HMM) with Gaussian emissions and
Deep Neural Networks (DNN). The results show that simple data augmentation
involving a small pitch shift can make surprisingly tangible improvements to
accuracy levels in speech recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03603</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03603</id><created>2017-12-10</created><authors><author><keyname>Gruenstein</keyname><forenames>Alexander</forenames></author><author><keyname>Alvarez</keyname><forenames>Raziel</forenames></author><author><keyname>Thornton</keyname><forenames>Chris</forenames></author><author><keyname>Ghodrat</keyname><forenames>Mohammadali</forenames></author></authors><title>A Cascade Architecture for Keyword Spotting on Mobile Devices</title><categories>cs.SD eess.AS</categories><comments>31st Conference on Neural Information Processing Systems (NIPS 2017),
  Long Beach, CA, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a cascade architecture for keyword spotting with speaker
verification on mobile devices. By pairing a small computational footprint with
specialized digital signal processing (DSP) chips, we are able to achieve low
power consumption while continuously listening for a keyword.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03627</identifier>
 <datestamp>2018-04-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03627</id><created>2017-12-10</created><updated>2018-04-07</updated><authors><author><keyname>Wang</keyname><forenames>Yahan</forenames></author><author><keyname>Bai</keyname><forenames>Huihui</forenames></author><author><keyname>Zhao</keyname><forenames>Lijun</forenames></author><author><keyname>Zhao</keyname><forenames>Yao</forenames></author></authors><title>Cascaded Reconstruction Network for Compressive image sensing</title><categories>eess.IV</categories><comments>17 pages,16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of compressed sensing (CS) has been successfully applied to image
compression in the past few years, whose traditional iterative reconstruction
algorithm is time-consuming. However, it has been reported deep learning-based
CS reconstruction algorithms could greatly reduce the computational complexity.
In this paper, we propose two efficient structures of cascaded reconstruction
networks corresponding to two different sampling methods in CS process. The
first reconstruction network is a compatibly sampling reconstruction network
(CSRNet), which recovers an image from its compressively sensed measurement
sampled by a traditional random matrix. In CSRNet, deep reconstruction network
module obtains an initial image with acceptable quality, which can be further
improved by residual network module based on convolutional neural network. The
second reconstruction network is adaptively sampling reconstruction network
(ASRNet), by matching automatically sampling module with corresponding residual
reconstruction module. The experimental results have shown that the proposed
two reconstruction networks outperform several state-of-the-art compressive
sensing reconstruction algorithms. Meanwhile, the proposed ASRNet can achieve
more than 1 dB gain, as compared with the CSRNet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03792</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03792</id><created>2017-12-11</created><authors><author><keyname>Li</keyname><forenames>Yaoguang</forenames></author><author><keyname>Cui</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Cong</forenames></author></authors><title>Identifying the Mislabeled Training Samples of ECG Signals using Machine
  Learning</title><categories>eess.SP cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The classification accuracy of electrocardiogram signal is often affected by
diverse factors in which mislabeled training samples issue is one of the most
influential problems. In order to mitigate this negative effect, the method of
cross validation is introduced to identify the mislabeled samples. The method
utilizes the cooperative advantages of different classifiers to act as a filter
for the training samples. The filter removes the mislabeled training samples
and retains the correctly labeled ones with the help of 10-fold cross
validation. Consequently, a new training set is provided to the final
classifiers to acquire higher classification accuracies. Finally, we
numerically show the effectiveness of the proposed method with the MIT-BIH
arrhythmia database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03945</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03945</id><created>2017-12-11</created><authors><author><keyname>Arafa</keyname><forenames>Ahmed</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Age Minimization in Energy Harvesting Communications: Energy-Controlled
  Delays</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>Appeared in Asilomar 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an energy harvesting source that is collecting measurements from
a physical phenomenon and sending updates to a destination within a
communication session time. Updates incur transmission delays that are function
of the energy used in their transmission. The more transmission energy used per
update, the faster it reaches the destination. The goal is to transmit updates
in a timely manner, namely, such that the total age of information is minimized
by the end of the communication session, subject to energy causality
constraints. We consider two variations of this problem. In the first setting,
the source controls the number of measurement updates, their transmission
times, and the amounts of energy used in their transmission (which govern their
delays, or service times, incurred). In the second setting, measurement updates
externally arrive over time, and therefore the number of updates becomes fixed,
at the expense of adding data causality constraints to the problem. We
characterize age-minimal policies in the two settings, and discuss the
relationship of the age of information metric to other metrics used in the
energy harvesting literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03993</identifier>
 <datestamp>2018-09-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.03993</id><created>2017-12-11</created><authors><author><keyname>Cherukuri</keyname><forenames>Venkateswararao</forenames></author><author><keyname>Ssenyonga</keyname><forenames>Peter</forenames></author><author><keyname>Warf</keyname><forenames>Benjamin C.</forenames></author><author><keyname>Kulkarni</keyname><forenames>Abhaya V.</forenames></author><author><keyname>Monga</keyname><forenames>Vishal</forenames></author><author><keyname>Schiff</keyname><forenames>Steven J.</forenames></author></authors><title>Learning Based Segmentation of CT Brain Images: Application to
  Post-Operative Hydrocephalic Scans</title><categories>eess.IV</categories><comments>IEEE Transactions on Biomedical Engineering, 2018</comments><journal-ref>IEEE Transactions on Biomedical Engineering 65.8 (2018): 1871-1884</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: Hydrocephalus is a medical condition in which there is an abnormal
accumulation of cerebrospinal fluid (CSF) in the brain. Segmentation of brain
imagery into brain tissue and CSF (before and after surgery, i.e. pre-op vs.
postop) plays a crucial role in evaluating surgical treatment. Segmentation of
pre-op images is often a relatively straightforward problem and has been well
researched. However, segmenting post-operative (post-op) computational
tomographic (CT)-scans becomes more challenging due to distorted anatomy and
subdural hematoma collections pressing on the brain. Most intensity and feature
based segmentation methods fail to separate subdurals from brain and CSF as
subdural geometry varies greatly across different patients and their intensity
varies with time. We combat this problem by a learning approach that treats
segmentation as supervised classification at the pixel level, i.e. a training
set of CT scans with labeled pixel identities is employed. Methods: Our
contributions include: 1.) a dictionary learning framework that learns class
(segment) specific dictionaries that can efficiently represent test samples
from the same class while poorly represent corresponding samples from other
classes, 2.) quantification of associated computation and memory footprint, and
3.) a customized training and test procedure for segmenting post-op
hydrocephalic CT images. Results: Experiments performed on infant CT brain
images acquired from the CURE Children's Hospital of Uganda reveal the success
of our method against the state-of-the-art alternatives. We also demonstrate
that the proposed algorithm is computationally less burdensome and exhibits a
graceful degradation against number of training samples, enhancing its
deployment potential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04276</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04276</id><created>2017-12-12</created><authors><author><keyname>Chakrabarty</keyname><forenames>Soumitro</forenames></author><author><keyname>Habets</keyname><forenames>Emanu&#xeb;l A. P.</forenames></author></authors><title>Multi-Speaker Localization Using Convolutional Neural Network Trained
  with Noise</title><categories>cs.SD eess.AS stat.ML</categories><comments>Presented at Machine Learning for Audio Processing (ML4Audio)
  Workshop at NIPS 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of multi-speaker localization is formulated as a multi-class
multi-label classification problem, which is solved using a convolutional
neural network (CNN) based source localization method. Utilizing the common
assumption of disjoint speaker activities, we propose a novel method to train
the CNN using synthesized noise signals. The proposed localization method is
evaluated for two speakers and compared to a well-known steered response power
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04320</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04320</id><created>2017-11-09</created><authors><author><keyname>Mathur</keyname><forenames>Monika</forenames></author><author><keyname>Agarawal</keyname><forenames>Ankit</forenames></author><author><keyname>Singh</keyname><forenames>Ghanshyam</forenames></author><author><keyname>Bhatnagar</keyname><forenames>S. K.</forenames></author></authors><title>A Novel RF Energy Harvesting Module Integrated on a Single Substrate</title><categories>eess.SP physics.app-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the RF energy harvesting module (RECTENNA). The working
range of this module includes multiple bands i.e. GSM, ISM, WLAN, and UWB band.
To enhance the capturing RF power capability an array arrangement of coplanar
monopole antenna has been proposed. Wilkinson power combiner has also been
implemented to combine the powers of this antenna array. The RF DC converter
circuit having seven stages has also been integrated with this structure. This
module produces the DC voltage of 1.8V with respect to +40dB RF input. It is
the unique module because it has no need of port connectors. The impedance
matching of antenna and converter has been fulfilled by incorporating the
passive component at the combiners branch. The value of this passive component
is kept equal to the existing value of impedance at input port of converter
circuit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04371</identifier>
 <datestamp>2018-11-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04371</id><created>2017-12-09</created><updated>2018-09-30</updated><authors><author><keyname>Briot</keyname><forenames>Jean-Pierre</forenames></author><author><keyname>Pachet</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Music Generation by Deep Learning - Challenges and Directions</title><categories>cs.SD cs.LG eess.AS</categories><comments>17 pages. arXiv admin note: substantial text overlap with
  arXiv:1709.01620. Accepted for publication in Special Issue on Deep learning
  for music and audio, Neural Computing &amp; Applications, Springer Nature, 2018</comments><doi>10.1007/s00521-018-3813-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In addition to traditional tasks such as prediction, classification and
translation, deep learning is receiving growing attention as an approach for
music generation, as witnessed by recent research groups such as Magenta at
Google and CTRL (Creator Technology Research Lab) at Spotify. The motivation is
in using the capacity of deep learning architectures and training techniques to
automatically learn musical styles from arbitrary musical corpora and then to
generate samples from the estimated distribution. However, a direct application
of deep learning to generate content rapidly reaches limits as the generated
content tends to mimic the training set without exhibiting true creativity.
Moreover, deep learning architectures do not offer direct ways for controlling
generation (e.g., imposing some tonality or other arbitrary constraints).
Furthermore, deep learning architectures alone are autistic automata which
generate music autonomously without human user interaction, far from the
objective of interactively assisting musicians to compose and refine music.
Issues such as: control, structure, creativity and interactivity are the focus
of our analysis. In this paper, we select some limitations of a direct
application of deep learning to music generation, analyze why the issues are
not fulfilled and how to address them by possible approaches. Various examples
of recent systems are cited as examples of promising directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04382</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04382</id><created>2017-12-12</created><updated>2017-12-22</updated><authors><author><keyname>Freitag</keyname><forenames>Michael</forenames></author><author><keyname>Amiriparian</keyname><forenames>Shahin</forenames></author><author><keyname>Pugachevskiy</keyname><forenames>Sergey</forenames></author><author><keyname>Cummins</keyname><forenames>Nicholas</forenames></author><author><keyname>Schuller</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>auDeep: Unsupervised Learning of Representations from Audio with Deep
  Recurrent Neural Networks</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  auDeep is a Python toolkit for deep unsupervised representation learning from
acoustic data. It is based on a recurrent sequence to sequence autoencoder
approach which can learn representations of time series data by taking into
account their temporal dynamics. We provide an extensive command line interface
in addition to a Python API for users and developers, both of which are
comprehensively documented and publicly available at
https://github.com/auDeep/auDeep. Experimental results indicate that auDeep
features are competitive with state-of-the art audio classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04501</identifier>
 <datestamp>2018-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04501</id><created>2017-12-12</created><updated>2018-05-14</updated><authors><author><keyname>Gross</keyname><forenames>Jason N.</forenames></author><author><keyname>Kilic</keyname><forenames>Cagri</forenames></author><author><keyname>Humphreys</keyname><forenames>Todd E.</forenames></author></authors><title>Maximum-Likelihood Power-Distortion Monitoring for GNSS Signal
  Authentication</title><categories>eess.SP cs.CR</categories><journal-ref>2018 IEEE Transactions on Aerospace and Electronic Systems</journal-ref><doi>10.1109/TAES.2018.2848318</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an extension to the so-called PD detector. The PD detector jointly
monitors received power and correlation profile distortion to detect the
presence of GNSS carry-off-type spoofing, jamming, or multipath. We show that
classification performance can be significantly improved by replacing the PD
detector's symmetric-difference-based distortion measurement with one based on
the post-fit residuals of the maximum-likelihood estimate of a single-signal
correlation function model. We call the improved technique the PD-ML detector.
In direct comparison with the PD detector, the PD-ML detector exhibits improved
classification accuracy when tested against an extensive library of recorded
field data. In particular, it is (1) significantly more accurate at
distinguishing a spoofing attack from a jamming attack, (2) better at
distinguishing multipath-afflicted data from interference-free data, and (3)
less likely to issue a false alarm by classifying multipath as spoofing. The
PD-ML detector achieves this improved performance at the expense of additional
computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04541</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04541</id><created>2017-12-12</created><authors><author><keyname>Yedidia</keyname><forenames>Adam</forenames></author><author><keyname>Thrampoulidis</keyname><forenames>Christos</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory</forenames></author></authors><title>Analysis and Optimization of Aperture Design in Computational Imaging</title><categories>eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is growing interest in the use of coded aperture imaging systems for a
variety of applications. Using an analysis framework based on mutual
information, we examine the fundamental limits of such systems---and the
associated optimum aperture coding---under simple but meaningful propagation
and sensor models. Among other results, we show that when thermal noise
dominates, spectrally-flat masks, which have 50% transmissivity, are optimal,
but that when shot noise dominates, randomly generated masks with lower
transmissivity offer greater performance. We also provide comparisons to
classical pinhole cameras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04555</identifier>
 <datestamp>2019-11-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04555</id><created>2017-12-12</created><updated>2018-02-15</updated><authors><author><keyname>St&#xf6;ter</keyname><forenames>Fabian-Robert</forenames></author><author><keyname>Chakrabarty</keyname><forenames>Soumitro</forenames></author><author><keyname>Edler</keyname><forenames>Bernd</forenames></author><author><keyname>Habets</keyname><forenames>Emanu&#xeb;l A. P.</forenames></author></authors><title>Classification vs. Regression in Supervised Learning for Single Channel
  Speaker Count Estimation</title><categories>eess.AS cs.SD</categories><comments>Accepted in ICASSP 2018</comments><doi>10.1109/ICASSP.2018.8462159</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of estimating the maximum number of concurrent speakers from single
channel mixtures is important for various audio-based applications, such as
blind source separation, speaker diarisation, audio surveillance or auditory
scene classification. Building upon powerful machine learning methodology, we
develop a Deep Neural Network (DNN) that estimates a speaker count. While DNNs
efficiently map input representations to output targets, it remains unclear how
to best handle the network output to infer integer source count estimates, as a
discrete count estimate can either be tackled as a regression or a
classification problem. In this paper, we investigate this important design
decision and also address complementary parameter choices such as the input
representation. We evaluate a state-of-the-art DNN audio model based on a
Bi-directional Long Short-Term Memory network architecture for speaker count
estimations. Through experimental evaluations aimed at identifying the best
overall strategy for the task and show results for five seconds speech segments
in mixtures of up to ten speakers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04573</identifier>
 <datestamp>2018-09-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04573</id><created>2017-12-12</created><updated>2018-09-12</updated><authors><author><keyname>Ohnishi</keyname><forenames>Motoya</forenames></author><author><keyname>Yukawa</keyname><forenames>Masahiro</forenames></author></authors><title>Online Nonlinear Estimation via Iterative L2-Space Projections:
  Reproducing Kernel of Subspace</title><categories>eess.SP</categories><comments>Published in IEEE Trans. Signal Processing This is not the published
  version, but is the accepted version. Please refer
  https://ieeexplore.ieee.org/document/8379456/?arnumber=8379456&amp;source=authoralert
  for the published version</comments><journal-ref>IEEE Trans. Signal Processing. Vol. 66, No. 15, August 1, 2018</journal-ref><doi>10.1109/TSP.2018.2846271</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel online learning paradigm for nonlinear-function estimation
tasks based on the iterative projections in the L2 space with probability
measure reflecting the stochastic property of input signals. The proposed
learning algorithm exploits the reproducing kernel of the so-called dictionary
subspace, based on the fact that any finite-dimensional space of functions has
a reproducing kernel characterized by the Gram matrix. The L2-space geometry
provides the best decorrelation property in principle. The proposed learning
paradigm is significantly different from the conventional kernel-based learning
paradigm in two senses: (i) the whole space is not a reproducing kernel Hilbert
space and (ii) the minimum mean squared error estimator gives the best
approximation of the desired nonlinear function in the dictionary subspace. It
preserves efficiency in computing the inner product as well as in updating the
Gram matrix when the dictionary grows. Monotone approximation, asymptotic
optimality, and convergence of the proposed algorithm are analyzed based on the
variable-metric version of adaptive projected subgradient method. Numerical
examples show the efficacy of the proposed algorithm for real data over a
variety of methods including the extended Kalman filter and many batch
machine-learning methods such as the multilayer perceptron.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04578</identifier>
 <datestamp>2018-03-14</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04578</id><created>2017-12-12</created><authors><author><keyname>O'Shea</keyname><forenames>Timothy J.</forenames></author><author><keyname>Roy</keyname><forenames>Tamoghna</forenames></author><author><keyname>Clancy</keyname><forenames>T. Charles</forenames></author></authors><title>Over the Air Deep Learning Based Radio Signal Classification</title><categories>cs.LG eess.SP</categories><comments>13 pages, 22 figures</comments><doi>10.1109/JSTSP.2018.2797022</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We conduct an in depth study on the performance of deep learning based radio
signal classification for radio communications signals. We consider a rigorous
baseline method using higher order moments and strong boosted gradient tree
classification and compare performance between the two approaches across a
range of configurations and channel impairments. We consider the effects of
carrier frequency offset, symbol rate, and multi-path fading in simulation and
conduct over-the-air measurement of radio classification performance in the lab
using software radios and compare performance and training strategies for both.
Finally we conclude with a discussion of remaining problems, and design
considerations for using such techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04639</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04639</id><created>2017-12-13</created><updated>2017-12-17</updated><authors><author><keyname>Wang</keyname><forenames>Pengfei</forenames></author><author><keyname>Di</keyname><forenames>Boya</forenames></author><author><keyname>Zhang</keyname><forenames>Hongliang</forenames></author><author><keyname>Bian</keyname><forenames>Kaigui</forenames></author><author><keyname>Song</keyname><forenames>Lingyang</forenames></author></authors><title>Cellular V2X in Unlicensed Spectrum: Harmonious Coexistence with VANET
  in 5G systems</title><categories>eess.SP</categories><comments>Cellular V2X, VANET, Semi-persistent scheduling, Resource allocation,
  Matching theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing demand for vehicular data transmission, limited dedicated
cellular spectrum becomes a bottleneck to satisfy the requirements of all
cellular vehicle-to-everything (V2X) users. To address this issue, unlicensed
spectrum is considered to serve as the complement to support cellular V2X
users. In this paper, we study the coexistence problem of cellular V2X users
and vehicular ad-hoc network~(VANET) users over the unlicensed spectrum. To
facilitate the coexistence, we design an energy sensing based spectrum sharing
scheme, where cellular V2X users are able to access the unlicensed channels
fairly while reducing the data transmission collisions between cellular V2X and
VANET users. In order to maximize the number of active cellular V2X users, we
formulate the scheduling and resource allocation problem as a two-sided
many-to-many matching with peer effects. We then propose a dynamic
vehicle-resource matching algorithm (DV-RMA) and present the analytical results
on the convergence time and computational complexity. Simulation results show
that the proposed algorithm outperforms existing approaches in terms of the
performance of cellular V2X system when the unlicensed spectrum is utilized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04753</identifier>
 <datestamp>2018-06-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04753</id><created>2017-12-12</created><updated>2018-06-13</updated><authors><author><keyname>Mangalam</keyname><forenames>Karttikeya</forenames></author><author><keyname>Guha</keyname><forenames>Tanaya</forenames></author></authors><title>Learning Spontaneity to Improve Emotion Recognition In Speech</title><categories>eess.AS cs.CL cs.HC cs.SD</categories><comments>Accepted at Interspeech 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the effect and usefulness of spontaneity (i.e. whether a given
speech is spontaneous or not) in speech in the context of emotion recognition.
We hypothesize that emotional content in speech is interrelated with its
spontaneity, and use spontaneity classification as an auxiliary task to the
problem of emotion recognition. We propose two supervised learning settings
that utilize spontaneity to improve speech emotion recognition: a hierarchical
model that performs spontaneity detection before performing emotion
recognition, and a multitask learning model that jointly learns to recognize
both spontaneity and emotion. Through various experiments on the well known
IEMOCAP database, we show that by using spontaneity detection as an additional
task, significant improvement can be achieved over emotion recognition systems
that are unaware of spontaneity. We achieve state-of-the-art emotion
recognition accuracy (4-class, 69.1%) on the IEMOCAP database outperforming
several relevant and competitive baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04829</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04829</id><created>2017-12-12</created><updated>2018-02-21</updated><authors><author><keyname>Jalan</keyname><forenames>Sarika</forenames></author><author><keyname>Pradhan</keyname><forenames>Priodyuti</forenames></author></authors><title>Localization of multilayer networks by the optimized single-layer
  rewiring</title><categories>eess.SP nlin.AO physics.soc-ph</categories><comments>10 pages, 8 figures</comments><journal-ref>Phys. Rev. E 97, 042314 (2018)</journal-ref><doi>10.1103/PhysRevE.97.042314</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study localization properties of principal eigenvector (PEV) of multilayer
networks. Starting with a multilayer network corresponding to a delocalized
PEV, we rewire the network edges using an optimization technique such that the
PEV of the rewired multilayer network becomes more localized. The framework
allows us to scrutinize structural and spectral properties of the networks at
various localization points during the rewiring process. We show that rewiring
only one-layer is enough to attain a multilayer network having a highly
localized PEV. Our investigation reveals that a single edge rewiring of the
optimized multilayer network can lead to the complete delocalization of a
highly localized PEV. This sensitivity in the localization behavior of PEV is
accompanied by a pair of almost degenerate eigenvalues. This observation opens
an avenue to gain a deeper insight into the origin of PEV localization of
networks. Furthermore, analysis of multilayer networks constructed using
real-world social and biological data show that the localization properties of
these real-world multilayer networks are in good agreement with the simulation
results for the model multilayer network. The study is relevant to applications
that require understanding propagation of perturbation in multilayer networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.04919</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.04919</id><created>2017-12-13</created><updated>2017-12-16</updated><authors><author><keyname>Deng</keyname><forenames>Tao</forenames></author><author><keyname>Liu</keyname><forenames>Xiao-Yang</forenames></author><author><keyname>Qian</keyname><forenames>Feng</forenames></author><author><keyname>Walid</keyname><forenames>Anwar</forenames></author></authors><title>Multidimensional Data Tensor Sensing for RF Tomographic Imaging</title><categories>cs.IT cs.CV eess.SP math.IT</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio-frequency (RF) tomographic imaging is a promising technique for
inferring multi-dimensional physical space by processing RF signals traversed
across a region of interest. However, conventional RF tomography schemes are
generally based on vector compressed sensing, which ignores the geometric
structures of the target spaces and leads to low recovery precision. The
recently proposed transform-based tensor model is more appropriate for sensory
data processing, as it helps exploit the geometric structures of the
three-dimensional target and improve the recovery precision. In this paper, we
propose a novel tensor sensing approach that achieves highly accurate
estimation for real-world three-dimensional spaces. First, we use the
transform-based tensor model to formulate a tensor sensing problem, and propose
a fast alternating minimization algorithm called Alt-Min. Secondly, we drive an
algorithm which is optimized to reduce memory and computation requirements.
Finally, we present evaluation of our Alt-Min approach using IKEA 3D data and
demonstrate significant improvement in recovery error and convergence speed
compared to prior tensor-based compressed sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05197</identifier>
 <datestamp>2017-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.05197</id><created>2017-12-14</created><updated>2017-12-15</updated><authors><author><keyname>Raposo</keyname><forenames>Francisco</forenames></author><author><keyname>de Matos</keyname><forenames>David Martins</forenames></author><author><keyname>Ribeiro</keyname><forenames>Ricardo</forenames></author><author><keyname>Tang</keyname><forenames>Suhua</forenames></author><author><keyname>Yu</keyname><forenames>Yi</forenames></author></authors><title>Towards Deep Modeling of Music Semantics using EEG Regularizers</title><categories>cs.IR cs.LG cs.SD eess.AS q-bio.NC</categories><comments>5 pages, 2 figures</comments><acm-class>H.5.5; H.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling of music audio semantics has been previously tackled through
learning of mappings from audio data to high-level tags or latent unsupervised
spaces. The resulting semantic spaces are theoretically limited, either because
the chosen high-level tags do not cover all of music semantics or because audio
data itself is not enough to determine music semantics. In this paper, we
propose a generic framework for semantics modeling that focuses on the
perception of the listener, through EEG data, in addition to audio data. We
implement this framework using a novel end-to-end 2-view Neural Network (NN)
architecture and a Deep Canonical Correlation Analysis (DCCA) loss function
that forces the semantic embedding spaces of both views to be maximally
correlated. We also detail how the EEG dataset was collected and use it to
train our proposed model. We evaluate the learned semantic space in a transfer
learning context, by using it as an audio feature extractor in an independent
dataset and proxy task: music audio-lyrics cross-modal retrieval. We show that
our embedding model outperforms Spotify features and performs comparably to a
state-of-the-art embedding model that was trained on 700 times more data. We
further discuss improvements to the model that are likely to improve its
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05266</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.05266</id><created>2017-11-29</created><authors><author><keyname>Adnan</keyname><forenames>Mahmood</forenames></author><author><keyname>Zen</keyname><forenames>Hushairi</forenames></author></authors><title>ICT Convergence in Internet of Things - The Birth of Smart Factories (A
  Technical Note)</title><categories>eess.SP</categories><journal-ref>International Journal of Computer Science and Information Security
  (IJCSIS), Vol. 14, No. 4, April 2016, pp. 93</journal-ref><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Over the past decade, most factories across developed parts of the world
employ a varying amount of the manufacturing technologies including autonomous
robots, RFID (radio frequency identification) technology, NCs (numerically
controlled machines), wireless sensor networks embedded with specialized
computerized softwares for sophisticated product designs, engineering analysis,
and remote control of machinery, etc. The ultimate aim of these all dramatic
developments in manufacturing sector is thus to achieve aspects such as shorter
innovation / product life cycles and raising overall productivity via
efficiently handling complex interactions among the various stages (functions,
departments) of a production line. The notion, Factory of the Future, is an
unpredictable heaven of efficaciousness, wherein, issues such as the flaws and
downtime would be issues of the long forgotten age. This technical note thus
provides an overview of this awesome revolution waiting to be soon realized in
the manufacturing sector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05289</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.05289</id><created>2017-12-13</created><updated>2018-01-17</updated><authors><author><keyname>Liu</keyname><forenames>Haichun</forenames></author><author><keyname>Zhang</keyname><forenames>TianHong</forenames></author><author><keyname>Ye</keyname><forenames>Yumeng</forenames></author><author><keyname>Pan</keyname><forenames>Changchun</forenames></author><author><keyname>Yang</keyname><forenames>Genke</forenames></author><author><keyname>Wang</keyname><forenames>JiJun</forenames></author><author><keyname>Qiu</keyname><forenames>Robert C.</forenames></author></authors><title>A Data Driven Approach for Resting-state EEG signal Classification of
  Schizophrenia with Control Participants using Random Matrix Theory</title><categories>eess.SP q-bio.QM</categories><comments>9 pages, 5 figures. arXiv admin note: text overlap with
  arXiv:1503.08445 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resting state electroencephalogram (EEG) abnormalities in clinically
high-risk individuals (CHR), clinically stable first-episode patients with
schizophrenia (FES), healthy controls (HC) suggest alterations in neural
oscillatory activity. However, few studies directly compare these anomalies
among each types. Therefore, this study investigated whether these
electrophysiological characteristics differentiate clinical populations from
one another, and from non-psychiatric controls. To address this question,
resting EEG power and coherence were assessed in 40 clinically high-risk
individuals (CHR), 40 first-episode patients with schizophrenia (FES), and 40
healthy controls (HC). These findings suggest that resting EEG can be a
sensitive measure for differentiating between clinical disorders.This paper
proposes a novel data-driven supervised learning method to obtain
identification of the patients mental status in schizophrenia research.
According to Marchenko-Pastur Law, the distribution of the eigenvalues of EEG
data is divided into signal subspace and noise subspace. A test statistic named
LES that embodies the characteristics of all eigenvalues is adopted. different
classifier and different feature(LES test function) are selected for
experiments, we have shown that using von Neumann Entropy as LES test function
combine with SVM classifier could obtain the best average classification
accuracy during three classification among HC, FES and CHR of Schizophrenia
group with EEG signal. It is worth noting that the result of LES feature
extraction with the highest classification accuracy is around 90% in two
classification(HC compare with FES) and around 70% in three classification.
Where the classification accuracy higher than 70% could be used to assist
clinical diagnosis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05457</identifier>
 <datestamp>2017-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.05457</id><created>2017-12-14</created><authors><author><keyname>Slezak</keyname><forenames>Christopher</forenames></author><author><keyname>Dhananjay</keyname><forenames>Aditya</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author></authors><title>60 GHz Blockage Study Using Phased Arrays</title><categories>eess.SP cs.NI</categories><comments>To appear in the Proceedings of the 51st Asilomar Conference on
  Signals, Systems, and Computers, 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The millimeter wave (mmWave) frequencies offer the potential for enormous
capacity wireless links. However, designing robust communication systems at
these frequencies requires that we understand the channel dynamics over both
time and space: mmWave signals are extremely vulnerable to blocking and the
channel can thus rapidly appear and disappear with small movement of obstacles
and reflectors. In rich scattering environments, different paths may experience
different blocking trajectories and understanding these multi-path blocking
dynamics is essential for developing and assessing beamforming and
beam-tracking algorithms. This paper presents the design and experimental
results of a novel measurement system which uses phased arrays to perform
mmWave dynamic channel measurements. Specifically, human blockage and its
effects across multiple paths are investigated with only several microseconds
between successive measurements. From these measurements we develop a modeling
technique which uses low-rank tensor factorization to separate the available
paths so that their joint statistics can be understood.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05587</identifier>
 <datestamp>2017-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.05587</id><created>2017-12-15</created><authors><author><keyname>Wan</keyname><forenames>Liangtian</forenames></author><author><keyname>Liu</keyname><forenames>Kaihui</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Zhu</keyname><forenames>Tong</forenames></author></authors><title>DOA and Polarization Estimation for Non-Circular Signals in 3-D
  Millimeter Wave Polarized Massive MIMO Systems</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an algorithm of multiple signal classification (MUSIC) is
proposed for two-dimensional (2-D) direction of- arrival (DOA) and polarization
estimation of non-circular signal in three-dimensional (3-D) millimeter wave
polarized largescale/ massive multiple-input-multiple-output (MIMO) systems.
The traditional MUSIC-based algorithms can estimate either the DOA and
polarization for circular signal or the DOA for non-circular signal by using
spectrum search. By contrast, in the proposed algorithm only the DOA estimation
needs spectrum search, and the polarization estimation has a closedform
expression. First, a novel dimension-reduced MUSIC (DRMUSIC) is proposed for
DOA and polarization estimation of circular signal with low computational
complexity. Next, based on the quaternion theory, a novel algorithm named
quaternion non-circular MUSIC (QNC-MUSIC) is proposed for parameter estimation
of non-circular signal with high estimation accuracy. Then based on the DOA
estimation result using QNC-MUSIC, the polarization estimation of non-circular
signal is acquired by using the closed-form expression of the polarization
estimation in DR-MUSIC. In addition, the computational complexity analysis
shows that compared with the conventional DOA and polarization estimation
algorithms, our proposed QNC-MUSIC and DRMUSIC have much lower computational
complexity, especially when the source number is large. The stochastic
Cramer-Rao Bound (CRB) for the estimation of the 2-D DOA and polarization
parameters of the non-circular signals is derived as well. Finally, numerical
examples are provided to demonstrate that the proposed algorithms can improve
the parameter estimation performance when the large-scale/massive MIMO systems
are employed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05608</identifier>
 <datestamp>2017-12-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.05608</id><created>2017-12-15</created><authors><author><keyname>Dumpala</keyname><forenames>Sri Harsha</forenames></author><author><keyname>Chakraborty</keyname><forenames>Rupayan</forenames></author><author><keyname>Kopparapu</keyname><forenames>Sunil Kumar</forenames></author></authors><title>A Novel Approach for Effective Learning in Low Resourced Scenarios</title><categories>cs.CL cs.SD eess.AS</categories><comments>Presented at NIPS 2017 Machine Learning for Audio Signal Processing
  (ML4Audio) Workshop, Dec. 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning based discriminative methods, being the state-of-the-art
machine learning techniques, are ill-suited for learning from lower amounts of
data. In this paper, we propose a novel framework, called simultaneous two
sample learning (s2sL), to effectively learn the class discriminative
characteristics, even from very low amount of data. In s2sL, more than one
sample (here, two samples) are simultaneously considered to both, train and
test the classifier. We demonstrate our approach for speech/music
discrimination and emotion classification through experiments. Further, we also
show the effectiveness of s2sL approach for classification in low-resource
scenario, and for imbalanced data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05865</identifier>
 <datestamp>2019-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.05865</id><created>2017-12-15</created><authors><author><keyname>Lalitha</keyname><forenames>Anusha</forenames></author><author><keyname>Ronquillo</keyname><forenames>Nancy</forenames></author><author><keyname>Javidi</keyname><forenames>Tara</forenames></author></authors><title>Improved Target Acquisition Rates with Feedback Codes</title><categories>cs.IT eess.SP math.IT stat.AP</categories><doi>10.1109/JSTSP.2018.2850751</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of acquiring an unknown target location
(among a finite number of locations) via a sequence of measurements, where each
measurement consists of simultaneously probing a group of locations. The
resulting observation consists of a sum of an indicator of the target's
presence in the probed region, and a zero mean Gaussian noise term whose
variance is a function of the measurement vector. An equivalence between the
target acquisition problem and channel coding over a binary input additive
white Gaussian noise (BAWGN) channel with state and feedback is established.
Utilizing this information theoretic perspective, a two-stage adaptive target
search strategy based on the sorted Posterior Matching channel coding strategy
is proposed. Furthermore, using information theoretic converses, the
fundamental limits on the target acquisition rate for adaptive and non-adaptive
strategies are characterized. As a corollary to the non-asymptotic upper bound
of the expected number of measurements under the proposed two-stage strategy,
and to non-asymptotic lower bound of the expected number of measurements for
optimal non-adaptive search strategy, a lower bound on the adaptivity gain is
obtained. The adaptivity gain is further investigated in different asymptotic
regimes of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05890</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.05890</id><created>2017-12-15</created><authors><author><keyname>Hung</keyname><forenames>Cheng-Yu</forenames></author><author><keyname>Kaveh</keyname><forenames>Mostafa</forenames></author></authors><title>Low Rank Matrix Recovery for Joint Array Self-Calibration and Sparse
  Model DoA Estimation</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, combined calibration and DoA estimation is approached as an
extension of the formulation for the Single Measurement Vector (SMV) model of
self-calibration to the Multiple Measurement Model (MMV) case. By taking
advantage of multiple snapshots, a modified nuclear norm minimization problem
is proposed to recover a low-rank larger dimension matrix. We also give the
definition of a linear operator for the MMV model, and give its corresponding
matrix representation to generate a variant of a convex optimization problem.
In order to mitigate the computational complexity of the approach, singular
value decomposition (SVD) is applied to reduce the problem size. The
performance of the proposed methods are demonstrated by numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.05970</identifier>
 <datestamp>2019-05-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.05970</id><created>2017-12-16</created><updated>2019-04-04</updated><authors><author><keyname>Song</keyname><forenames>Peiyang</forenames></author><author><keyname>Gong</keyname><forenames>Fengkui</forenames></author><author><keyname>Zhang</keyname><forenames>Hang</forenames></author><author><keyname>Li</keyname><forenames>Guo</forenames></author></authors><title>Blind Estimation Algorithms for I/Q Imbalance in Direct Down-conversion
  Receivers</title><categories>eess.SP</categories><comments>Accepted by IEEE VTC-2018 Fall</comments><doi>10.1109/VTCFall.2018.8690669</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As known, receivers with in-phase and quadrature phase (I/Q) down conversion,
especially direct-conversion architectures, always suffer from I/Q imbalance.
I/Q imbalance is caused by amplitude and phase mismatch between I/Q paths. The
performance degradation resulting from I/Q imbalance can not be mitigated with
simply higher signal to noise ratio (SNR). Thus, I/Q imbalance compensation in
the digital domain is critical. There are two main contributions in this paper.
Firstly, we proposed a blind estimation algorithm for I/Q imbalance parameters
based on joint first and second order statistics (FSS) which has lower
complexity than conventional Gaussian maximum likelihood estimation (GMLE).
This can be used for further processing such as equalization in the presence of
receiver IQ imbalance. In addition, we find out the reason of the error floor
in conventional I/Q imbalance compensation method based on the conjugate signal
model (CSM). The proposed joint first order statistics and conjugate signal
model (FSCSM) compensation algorithm can reach the ideal bit error rate (BER)
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06086</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.06086</id><created>2017-12-17</created><authors><author><keyname>Ravanelli</keyname><forenames>Mirco</forenames></author></authors><title>Deep Learning for Distant Speech Recognition</title><categories>cs.CL cs.SD eess.AS</categories><comments>PhD Thesis Unitn, 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning is an emerging technology that is considered one of the most
promising directions for reaching higher levels of artificial intelligence.
Among the other achievements, building computers that understand speech
represents a crucial leap towards intelligent machines. Despite the great
efforts of the past decades, however, a natural and robust human-machine speech
interaction still appears to be out of reach, especially when users interact
with a distant microphone in noisy and reverberant environments. The latter
disturbances severely hamper the intelligibility of a speech signal, making
Distant Speech Recognition (DSR) one of the major open challenges in the field.
  This thesis addresses the latter scenario and proposes some novel techniques,
architectures, and algorithms to improve the robustness of distant-talking
acoustic models. We first elaborate on methodologies for realistic data
contamination, with a particular emphasis on DNN training with simulated data.
We then investigate on approaches for better exploiting speech contexts,
proposing some original methodologies for both feed-forward and recurrent
neural networks. Lastly, inspired by the idea that cooperation across different
DNNs could be the key for counteracting the harmful effects of noise and
reverberation, we propose a novel deep learning paradigm called network of deep
neural networks. The analysis of the original concepts were based on extensive
experimental validations conducted on both real and simulated data, considering
different corpora, microphone configurations, environments, noisy conditions,
and ASR tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06087</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.06087</id><created>2017-12-17</created><authors><author><keyname>Shocher</keyname><forenames>Assaf</forenames></author><author><keyname>Cohen</keyname><forenames>Nadav</forenames></author><author><keyname>Irani</keyname><forenames>Michal</forenames></author></authors><title>&quot;Zero-Shot&quot; Super-Resolution using Deep Internal Learning</title><categories>cs.CV cs.LG cs.NE eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Learning has led to a dramatic leap in Super-Resolution (SR) performance
in the past few years. However, being supervised, these SR methods are
restricted to specific training data, where the acquisition of the
low-resolution (LR) images from their high-resolution (HR) counterparts is
predetermined (e.g., bicubic downscaling), without any distracting artifacts
(e.g., sensor noise, image compression, non-ideal PSF, etc). Real LR images,
however, rarely obey these restrictions, resulting in poor SR results by SotA
(State of the Art) methods. In this paper we introduce &quot;Zero-Shot&quot; SR, which
exploits the power of Deep Learning, but does not rely on prior training. We
exploit the internal recurrence of information inside a single image, and train
a small image-specific CNN at test time, on examples extracted solely from the
input image itself. As such, it can adapt itself to different settings per
image. This allows to perform SR of real old photos, noisy images, biological
data, and other images where the acquisition process is unknown or non-ideal.
On such images, our method outperforms SotA CNN-based SR methods, as well as
previous unsupervised SR methods. To the best of our knowledge, this is the
first unsupervised CNN-based SR method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06088</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.06088</id><created>2017-12-17</created><authors><author><keyname>Clerckx</keyname><forenames>Bruno</forenames></author><author><keyname>Costanzo</keyname><forenames>Alessandra</forenames></author><author><keyname>Georgiadis</keyname><forenames>Apostolos</forenames></author><author><keyname>Carvalho</keyname><forenames>Nuno Borges</forenames></author></authors><title>Towards the 1G of Mobile Power Network: RF, Signal and System Designs to
  Make Smart Objects Autonomous</title><categories>cs.IT eess.SP math.IT</categories><comments>submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article reviews some recent promising approaches to make mobile power
closer to reality. In contrast with articles commonly published by the
microwave community and the communication/signal processing community that
separately emphasize RF, circuit and antenna solutions for WPT on one hand and
communications, signal and system designs for WPT on the other hand, this
review article uniquely bridges RF, signal and system designs in order to bring
those communities closer to each other and get a better understanding of the
fundamental building blocks of an efficient WPT network architecture. We start
by reviewing the engineering requirements and design challenges of making
mobile power a reality. We then review the state-of-the-art in a wide range of
areas spanning sensors and devices, RF design for wireless power and wireless
communications. We identify their limitations and make critical observations
before providing some fresh new look and promising avenues on signal and system
designs for WPT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06181</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.06181</id><created>2017-12-17</created><updated>2019-02-12</updated><authors><author><keyname>Gulati</keyname><forenames>Nikhil</forenames></author><author><keyname>Bahl</keyname><forenames>Rohit</forenames></author><author><keyname>Dandekar</keyname><forenames>Kapil R.</forenames></author></authors><title>Learning Sequential Channel Selection for Interference Alignment using
  Reconfigurable Antennas</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, machine learning techniques have been explored to support,
enhance or augment wireless systems especially at the physical layer of the
protocol stack. Traditional ML based approach or optimization is often not
suitable due to algorithmic complexity, reliance on existing training data
and/or due to distributed setting. In this paper, we formulate a reconfigurable
antenna based channel selection problem for interference alignment in a
multi-user wireless network as a learning problem. More specifically, we
propose that by using sequential learning, an effective channel or combination
of channels can be selected in order to enhance interference alignment using
reconfigurable antennas. We first formulate the channel selection as a
multi-armed problem that aims to optimize the sum rate of the network. We show
that by using an adaptive sequential learning policy, each node in the network
can learn to select optimal channels without requiring full and instantaneous
CSI for all the available antenna states. We conduct performance analysis of
our technique for a MIMO interference channel using a conventional IA scheme
and quantify the benefits of pattern diversity and learning channel selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06288</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.06288</id><created>2017-12-18</created><authors><author><keyname>Kodera</keyname><forenames>Toshiro</forenames></author></authors><title>Adaptive antenna system by ESP32-PICO-D4 and its application to web
  radio system</title><categories>eess.SP</categories><comments>This article is submitted for HardwareX</comments><doi>10.1016/j.ohx.2018.03.001</doi><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Adaptive antenna technique has an important role in the IoT environment in
order to establish reliable and stable wireless communication in high
congestion situation. Even if knowing antenna characteristics in advance,
electromagnetic wave propagation in the non-line-of-sight environment is very
complex and unpredictable, therefore, the adjustment the antenna radiation for
the optimum signal reception is important for the better wireless link. This
article presents a simple but effective adaptive antenna system for Wi-Fi
utilizing the function of a highly integrated component, ESP32-PICO-D4. This
chip is a system-in-chip containing all components for Wi-Fi and Bluetooth
application except for antenna. Together with SP3T RF switch and dielectric
antennas and high-resolution audio DAC, completed web-radio system is made in
the size of 50 x 50 mm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06340</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.06340</id><created>2017-12-18</created><authors><author><keyname>Pascual</keyname><forenames>Santiago</forenames></author><author><keyname>Park</keyname><forenames>Maruchan</forenames></author><author><keyname>Serr&#xe0;</keyname><forenames>Joan</forenames></author><author><keyname>Bonafonte</keyname><forenames>Antonio</forenames></author><author><keyname>Ahn</keyname><forenames>Kang-Hun</forenames></author></authors><title>Language and Noise Transfer in Speech Enhancement Generative Adversarial
  Network</title><categories>cs.SD cs.LG eess.AS</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Speech enhancement deep learning systems usually require large amounts of
training data to operate in broad conditions or real applications. This makes
the adaptability of those systems into new, low resource environments an
important topic. In this work, we present the results of adapting a speech
enhancement generative adversarial network by finetuning the generator with
small amounts of data. We investigate the minimum requirements to obtain a
stable behavior in terms of several objective metrics in two very different
languages: Catalan and Korean. We also study the variability of test
performance to unseen noise as a function of the amount of different types of
noise available for training. Results show that adapting a pre-trained English
model with 10 min of data already achieves a comparable performance to having
two orders of magnitude more data. They also demonstrate the relative stability
in test performance with respect to the number of training noise types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06393</identifier>
 <datestamp>2019-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.06393</id><created>2017-12-18</created><updated>2019-07-30</updated><authors><author><keyname>Fracastoro</keyname><forenames>Giulia</forenames></author><author><keyname>Thanou</keyname><forenames>Dorina</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Graph Transform Optimization with Application to Image Compression</title><categories>cs.IT eess.IV math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new graph-based transform and illustrate its
potential application to signal compression. Our approach relies on the careful
design of a graph that optimizes the overall rate-distortion performance
through an effective graph-based transform. We introduce a novel graph
estimation algorithm, which uncovers the connectivities between the graph
signal values by taking into consideration the coding of both the signal and
the graph topology in rate-distortion terms. In particular, we introduce a
novel coding solution for the graph by treating the edge weights as another
graph signal that lies on the dual graph. Then, the cost of the graph
description is introduced in the optimization problem by minimizing the
sparsity of the coefficients of its graph Fourier transform (GFT) on the dual
graph. In this way, we obtain a convex optimization problem whose solution
defines an efficient transform coding strategy. The proposed technique is a
general framework that can be applied to different types of signals, and we
show two possible application fields, namely natural image coding and piecewise
smooth image coding. The experimental results show that the proposed
graph-based transform outperforms classical fixed transforms such as DCT for
both natural and piecewise smooth images. In the case of depth map coding, the
obtained results are even comparable to the state-of-the-art graph-based coding
method, that are specifically designed for depth map images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06482</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.06482</id><created>2017-12-18</created><authors><author><keyname>Babashah</keyname><forenames>Hossein</forenames></author><author><keyname>Kavehvash</keyname><forenames>Zahra</forenames></author><author><keyname>Khavasi</keyname><forenames>Amin</forenames></author><author><keyname>Koohi</keyname><forenames>Somayyeh</forenames></author></authors><title>Temporal Analog Optical Computing using an On-Chip Fully Reconfigurable
  Photonic Signal Processor</title><categories>physics.optics eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the concept of on-chip temporal optical computing,
based on dispersive Fourier transform and suitably designed modulation module,
to perform mathematical operations of interest, such as differentiation,
integration, or convolution in time domain. The desired mathematical operation
is performed as signal propagates through a fully reconfigurable on-chip
photonic signal processor. Although a few number of photonic temporal signal
processors have been introduced recently, they are usually bulky or they suffer
from limited reconfigurability which is of great importance to implement
large-scale general-purpose photonic signal processors. To address these
limitations, this paper demonstrates a fully reconfigurable photonic integrated
signal processing system. As the key point, the reconfigurability is achieved
by taking advantages of dispersive Fourier transformation, linearly chirp
modulation using four wave mixing, and applying the desired arbitrary transfer
function through a cascaded Mach-Zehnder modulator and phase modulator. Our
demonstration reveals an operation time of $200~ps$ with high resolution of
$300~fs$. To have an on-chip photonic signal processor, a broadband photonic
crystal waveguide with an extremely large group-velocity dispersion of $2.81
\times {10^{6}}~\frac{{{ps^2}}}{km}$ is utilized. Numerical simulations of the
proposed structure reveal a great potential for chip-scale fully reconfigurable
all-optical signal processing through a bandwidth of $400~GHz$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06562</identifier>
 <datestamp>2018-07-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.06562</id><created>2017-12-18</created><authors><author><keyname>Zhang</keyname><forenames>Feng</forenames></author><author><keyname>Chen</keyname><forenames>Chen</forenames></author><author><keyname>Wang</keyname><forenames>Beibei</forenames></author><author><keyname>Han</keyname><forenames>Yi</forenames></author><author><keyname>Liu</keyname><forenames>K. J. Ray</forenames></author></authors><title>WiBall: A Time-Reversal Focusing Ball Method for Indoor Tracking</title><categories>eess.SP</categories><doi>10.1109/JIOT.2018.2854825</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the development of the Internet of Things technology, indoor tracking
has become a popular application nowadays, but most existing solutions can only
work in line-of-sight scenarios, or require regular re-calibration. In this
paper, we propose WiBall, an accurate and calibration-free indoor tracking
system that can work well in non-line-of-sight based on radio signals. WiBall
leverages a stationary and location-independent property of the time-reversal
focusing effect of radio signals for highly accurate moving distance
estimation. Together with the direction estimation based on inertial
measurement unit and location correction using the constraints from the
floorplan, WiBall is shown to be able to track a moving object with
decimeter-level accuracy in different environments. Since WiBall can
accommodate a large number of users with only a single pair of devices, it is
low-cost and easily scalable, and can be a promising candidate for future
indoor tracking applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06651</identifier>
 <datestamp>2018-07-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.06651</id><created>2017-12-18</created><updated>2018-07-25</updated><authors><author><keyname>Arandjelovi&#x107;</keyname><forenames>Relja</forenames></author><author><keyname>Zisserman</keyname><forenames>Andrew</forenames></author></authors><title>Objects that Sound</title><categories>cs.CV cs.LG cs.MM cs.SD eess.AS</categories><comments>Appears in: European Conference on Computer Vision (ECCV) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper our objectives are, first, networks that can embed audio and
visual inputs into a common space that is suitable for cross-modal retrieval;
and second, a network that can localize the object that sounds in an image,
given the audio signal. We achieve both these objectives by training from
unlabelled video using only audio-visual correspondence (AVC) as the objective
function. This is a form of cross-modal self-supervision from video.
  To this end, we design new network architectures that can be trained for
cross-modal retrieval and localizing the sound source in an image, by using the
AVC task. We make the following contributions: (i) show that audio and visual
embeddings can be learnt that enable both within-mode (e.g. audio-to-audio) and
between-mode retrieval; (ii) explore various architectures for the AVC task,
including those for the visual stream that ingest a single image, or multiple
images, or a single image and multi-frame optical flow; (iii) show that the
semantic object that sounds within an image can be localized (using only the
sound, no motion or flow information); and (iv) give a cautionary tale on how
to avoid undesirable shortcuts in the data preparation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.06905</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.06905</id><created>2017-12-19</created><authors><author><keyname>Captain</keyname><forenames>Kamal</forenames></author><author><keyname>Joshi</keyname><forenames>Manjunath</forenames></author></authors><title>SNR Wall for Cooperative Spectrum Sensing Using Generalized Energy
  Detector</title><categories>eess.SP stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive radio (CR) is a promising scheme to improve the spectrum
utilization. Spectrum sensing (SS) is one of the main tasks of CR. Cooperative
spectrum sensing (CSS) is used in CR to improve detection capability. Due to
its simplicity and low complexity, sensing based on energy detection known as
conventional energy detection (CED) is widely adopted. CED can be generalized
by changing the squaring operation of the amplitude of received samples by an
arbitrary positive power p which is referred to as the generalized energy
detector (GED). The performance of GED degrades when there exists noise
uncertainty (NU). In this paper, we investigate the performance of CSS by
considering the noise NU when all the secondary users (SUs) employ GED. We
derive the signal to noise ratio (SNR) wall for CSS for both hard and soft
decision combining. All the derived expressions are validated using Monte Carlo
(MC) simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07003</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07003</id><created>2017-12-19</created><authors><author><keyname>Fablet</keyname><forenames>Ronan</forenames></author><author><keyname>Ouala</keyname><forenames>Said</forenames></author><author><keyname>Herzet</keyname><forenames>Cedric</forenames></author></authors><title>Bilinear residual Neural Network for the identification and forecasting
  of dynamical systems</title><categories>cs.LG eess.SP physics.data-an</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the increasing availability of large-scale observation and simulation
datasets, data-driven representations arise as efficient and relevant
computation representations of dynamical systems for a wide range of
applications, where model-driven models based on ordinary differential equation
remain the state-of-the-art approaches. In this work, we investigate neural
networks (NN) as physically-sound data-driven representations of such systems.
Reinterpreting Runge-Kutta methods as graphical models, we consider a residual
NN architecture and introduce bilinear layers to embed non-linearities which
are intrinsic features of dynamical systems. From numerical experiments for
classic dynamical systems, we demonstrate the relevance of the proposed
NN-based architecture both in terms of forecasting performance and model
identification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07065</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07065</id><created>2017-12-19</created><authors><author><keyname>Chakraborty</keyname><forenames>Rupayan</forenames></author><author><keyname>Nadeu</keyname><forenames>Climent</forenames></author></authors><title>Joint model-based recognition and localization of overlapped acoustic
  events using a set of distributed small microphone arrays</title><categories>cs.SD eess.AS</categories><comments>Computational acoustic scene analysis, microphone array signal
  processing, acoustic event detection</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In the analysis of acoustic scenes, often the occurring sounds have to be
detected in time, recognized, and localized in space. Usually, each of these
tasks is done separately. In this paper, a model-based approach to jointly
carry them out for the case of multiple simultaneous sources is presented and
tested. The recognized event classes and their respective room positions are
obtained with a single system that maximizes the combination of a large set of
scores, each one resulting from a different acoustic event model and a
different beamformer output signal, which comes from one of several
arbitrarily-located small microphone arrays. By using a two-step method, the
experimental work for a specific scenario consisting of meeting-room acoustic
events, either isolated or overlapped with speech, is reported. Tests carried
out with two datasets show the advantage of the proposed approach with respect
to some usual techniques, and that the inclusion of estimated priors brings a
further performance improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07101</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07101</id><created>2017-12-19</created><authors><author><keyname>Zhou</keyname><forenames>Yingbo</forenames></author><author><keyname>Xiong</keyname><forenames>Caiming</forenames></author><author><keyname>Socher</keyname><forenames>Richard</forenames></author></authors><title>Improving End-to-End Speech Recognition with Policy Learning</title><categories>cs.CL cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connectionist temporal classification (CTC) is widely used for maximum
likelihood learning in end-to-end speech recognition models. However, there is
usually a disparity between the negative maximum likelihood and the performance
metric used in speech recognition, e.g., word error rate (WER). This results in
a mismatch between the objective function and metric during training. We show
that the above problem can be mitigated by jointly training with maximum
likelihood and policy gradient. In particular, with policy learning we are able
to directly optimize on the (otherwise non-differentiable) performance metric.
We show that joint training improves relative performance by 4% to 13% for our
end-to-end model as compared to the same model learned through maximum
likelihood. The model achieves 5.53% WER on Wall Street Journal dataset, and
5.42% and 14.70% on Librispeech test-clean and test-other set, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07108</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07108</id><created>2017-12-19</created><authors><author><keyname>Zhou</keyname><forenames>Yingbo</forenames></author><author><keyname>Xiong</keyname><forenames>Caiming</forenames></author><author><keyname>Socher</keyname><forenames>Richard</forenames></author></authors><title>Improved Regularization Techniques for End-to-End Speech Recognition</title><categories>cs.CL cs.SD eess.AS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regularization is important for end-to-end speech models, since the models
are highly flexible and easy to overfit. Data augmentation and dropout has been
important for improving end-to-end models in other domains. However, they are
relatively under explored for end-to-end speech models. Therefore, we
investigate the effectiveness of both methods for end-to-end trainable, deep
speech recognition models. We augment audio data through random perturbations
of tempo, pitch, volume, temporal alignment, and adding random noise.We further
investigate the effect of dropout when applied to the inputs of all layers of
the network. We show that the combination of data augmentation and dropout give
a relative performance improvement on both Wall Street Journal (WSJ) and
LibriSpeech dataset of over 20%. Our model performance is also competitive with
other end-to-end speech models on both datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07116</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07116</id><created>2017-12-19</created><authors><author><keyname>de Lima</keyname><forenames>Sidney Marlon Lopes</forenames></author><author><keyname>Filho</keyname><forenames>Abel Guilhermino da Silva</forenames></author><author><keyname>Santos</keyname><forenames>Wellington Pinheiro dos</forenames></author></authors><title>Detection and classification of masses in mammographic images in a
  multi-kernel approach</title><categories>cs.CV cs.NE eess.IV</categories><journal-ref>Computer Methods and Programs in Biomedicine, 134 (2016), 11-29</journal-ref><doi>10.1016/j.cmpb.2016.04.029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to the World Health Organization, breast cancer is the main cause
of cancer death among adult women in the world. Although breast cancer occurs
indiscriminately in countries with several degrees of social and economic
development, among developing and underdevelopment countries mortality rates
are still high, due to low availability of early detection technologies. From
the clinical point of view, mammography is still the most effective diagnostic
technology, given the wide diffusion of the use and interpretation of these
images. Herein this work we propose a method to detect and classify
mammographic lesions using the regions of interest of images. Our proposal
consists in decomposing each image using multi-resolution wavelets. Zernike
moments are extracted from each wavelet component. Using this approach we can
combine both texture and shape features, which can be applied both to the
detection and classification of mammary lesions. We used 355 images of fatty
breast tissue of IRMA database, with 233 normal instances (no lesion), 72
benign, and 83 malignant cases. Classification was performed by using SVM and
ELM networks with modified kernels, in order to optimize accuracy rates,
reaching 94.11%. Considering both accuracy rates and training times, we defined
the ration between average percentage accuracy and average training time in a
reverse order. Our proposal was 50 times higher than the ratio obtained using
the best method of the state-of-the-art. As our proposed model can combine high
accuracy rate with low learning time, whenever a new data is received, our work
will be able to save a lot of time, hours, in learning process in relation to
the best method of the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07194</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07194</id><created>2017-12-19</created><authors><author><keyname>Chen</keyname><forenames>Li</forenames></author><author><keyname>Xie</keyname><forenames>Yanjun</forenames></author><author><keyname>Sun</keyname><forenames>Jie</forenames></author><author><keyname>Balu</keyname><forenames>Niranjan</forenames></author><author><keyname>Mossa-Basha</keyname><forenames>Mahmud</forenames></author><author><keyname>Pimentel</keyname><forenames>Kristi</forenames></author><author><keyname>Hatsukami</keyname><forenames>Thomas S.</forenames></author><author><keyname>Hwang</keyname><forenames>Jenq-Neng</forenames></author><author><keyname>Yuan</keyname><forenames>Chun</forenames></author></authors><title>Y-net: 3D intracranial artery segmentation using a convolutional
  autoencoder</title><categories>eess.IV cs.CV</categories><comments>5 pages, 4 figures, an improved version after accepted by IEEE
  International Conference on Bioinformatics and Biomedicine, Kansas City, MO,
  USA, November 13 - 16, 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated segmentation of intracranial arteries on magnetic resonance
angiography (MRA) allows for quantification of cerebrovascular features, which
provides tools for understanding aging and pathophysiological adaptations of
the cerebrovascular system. Using a convolutional autoencoder (CAE) for
segmentation is promising as it takes advantage of the autoencoder structure in
effective noise reduction and feature extraction by representing high
dimensional information with low dimensional latent variables. In this report,
an optimized CAE model (Y-net) was trained to learn a 3D segmentation model of
intracranial arteries from 49 cases of MRA data. The trained model was shown to
perform better than the three traditional segmentation methods in both binary
classification and visual evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07312</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07312</id><created>2017-12-19</created><authors><author><keyname>Cordeiro</keyname><forenames>Filipe Rolim</forenames></author><author><keyname>Santos</keyname><forenames>Wellington Pinheiro dos</forenames></author><author><keyname>Filho</keyname><forenames>Abel Guilhermino da Silva</forenames></author></authors><title>Analysis of supervised and semi-supervised GrowCut applied to
  segmentation of masses in mammography images</title><categories>cs.CV cs.AI cs.NE eess.IV</categories><journal-ref>Computer Methods in Biomechanics and Biomedical Engineering:
  Imaging &amp; Visualization, v. 5, p. 1-19, 2017</journal-ref><doi>10.1080/21681163.2015.1127775</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Breast cancer is already one of the most common form of cancer worldwide.
Mammography image analysis is still the most effective diagnostic method to
promote the early detection of breast cancer. Accurately segmenting tumors in
digital mammography images is important to improve diagnosis capabilities of
health specialists and avoid misdiagnosis. In this work, we evaluate the
feasibility of applying GrowCut to segment regions of tumor and we propose two
GrowCut semi-supervised versions. All the analysis was performed by evaluating
the application of segmentation techniques to a set of images obtained from the
Mini-MIAS mammography image database. GrowCut segmentation was compared to
Region Growing, Active Contours, Random Walks and Graph Cut techniques.
Experiments showed that GrowCut, when compared to the other techniques, was
able to acquire better results for the metrics analyzed. Moreover, the proposed
semi-supervised versions of GrowCut was proved to have a clinically
satisfactory quality of segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07369</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07369</id><created>2017-12-20</created><updated>2018-01-17</updated><authors><author><keyname>Ye</keyname><forenames>Yumeng</forenames></author><author><keyname>Liu</keyname><forenames>Haichun</forenames></author><author><keyname>Zhang</keyname><forenames>TianHong</forenames></author><author><keyname>Pan</keyname><forenames>Changchun</forenames></author><author><keyname>Yang</keyname><forenames>Genke</forenames></author><author><keyname>Wang</keyname><forenames>JiJun</forenames></author><author><keyname>Qiu</keyname><forenames>Robert C.</forenames></author></authors><title>Improvement of Resting-state EEG Analysis Process with Spectrum
  Weight-Voting based on LES</title><categories>eess.SP q-bio.NC</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EEG is a non-invasive technique for recording brain bioelectric activity,
which has potential applications in various fields such as human-computer
interaction and neuroscience. However, there are many difficulties in analyzing
EEG data, including its complex composition, low amplitude as well as low
signal-to-noise ratio. Some of the existing methods of analysis are based on
feature extraction and machine learning to differentiate the phase of
schizophrenia that samples belong to. However, medical research requires the
use of machine learning not only to give more accurate classification results,
but also to give the results that can be applied to pathological studies. The
main purpose of this study is to obtain the weight values as the representation
of influence of each frequency band on the classification of schizophrenia
phases on the basis of a more effective classification method using the LES
feature extraction, and then the weight values are processed and applied to
improve the accuracy of machine learning classification. We propose a method
called weight-voting to obtain the weights of sub-bands features by using
results of classification for voting to fit the actual categories of EEG data,
and using weights for reclassification. Through this method, we can first
obtain the influence of each band in distinguishing three schizophrenia phases,
and analyze the effect of band features on the risk of schizophrenia
contributing to the study of psychopathology. Our results show that there is a
high correlation between the change of weight of low gamma band and the
difference between HC, CHR and FES. If the features revised according to
weights are used for reclassification, the accuracy of result will be improved
compared with the original classifier, which confirms the role of the band
weight distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07435</identifier>
 <datestamp>2018-08-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07435</id><created>2017-12-20</created><authors><author><keyname>Akdeniz</keyname><forenames>Bayram Cevdet</forenames></author><author><keyname>Turgut</keyname><forenames>Nafi Ahmet</forenames></author><author><keyname>Yilmaz</keyname><forenames>H. Birkan</forenames></author><author><keyname>Chae</keyname><forenames>Chan-Byoung</forenames></author><author><keyname>Tugcu</keyname><forenames>Tuna</forenames></author><author><keyname>Pusane</keyname><forenames>Ali Emre</forenames></author></authors><title>Molecular Signal Modeling of a Partially Counting Absorbing Spherical
  Receiver</title><categories>cs.ET eess.SP</categories><comments>submitted to Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To communicate at the nanoscale, researchers have proposed molecular
communication as an energy-efficient solution. The drawback to this solution is
that the histogram of the molecules' hitting times, which constitute the
molecular signal at the receiver, has a heavy tail. Reducing the effects of
this heavy tail, inter-symbol interference (ISI), has been the focus of most
prior research. In this paper, a novel way of decreasing the ISI by defining a
counting region on the spherical receiver's surface facing towards the
transmitter node is proposed. The beneficial effect comes from the fact that
the molecules received from the back lobe of the receiver are more likely to be
coming through longer paths that contribute to ISI. In order to justify this
idea, the joint distribution of the arrival molecules with respect to angle and
time is derived. Using this distribution, the channel model function is
approximated for the proposed system, i.e., the partially counting absorbing
spherical receiver. After validating the channel model function, the
characteristics of the molecular signal are investigated and improved
performance is presented. Moreover, the optimal counting region in terms of bit
error rate is found analytically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07443</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07443</id><created>2017-12-20</created><authors><author><keyname>Kinney-Lang</keyname><forenames>Eli</forenames></author><author><keyname>Spyrou</keyname><forenames>Loukianos</forenames></author><author><keyname>Ebied</keyname><forenames>Ahmed</forenames></author><author><keyname>Chin</keyname><forenames>Richard FM</forenames></author><author><keyname>Escudero</keyname><forenames>Javier</forenames></author></authors><title>Tensor-driven extraction of developmental features from varying
  paediatric EEG datasets</title><categories>q-bio.NC eess.SP</categories><comments>16 pages, 6 figures, pre-print, under consideration for publication.
  Reduced figure resolution due to size limit-please contact corresponding
  author for full figure resolution</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective. Consistently changing physiological properties in developing
children's brains challenges new data heavy technologies, like brain-computer
interfaces (BCI). Advancing signal processing methods in such technologies to
be more sensitive to developmental changes could help improve their function
and usability in paediatric populations. Taking advantage of the
multi-dimensional structure of EEG data through tensor analysis offers a
framework to extract relevant developmental features present in paediatric
resting-state EEG datasets. Methods. Three paediatric datasets from varying
developmental states and populations were analyzed using a developed two-step
constrained Parallel Factor (PARAFAC) tensor decomposition. The datasets
included the Muir Maxwell Epilepsy Centre, Children's Hospital Boston-MIT and
the Child Mind Institute, outlining two impaired and one healthy population,
respectively. Within dataset cross-validation used support vector machines
(SVM) for classification of out-of-fold data predicting subject age as a proxy
measure of development. t-distributed Stochastic Neighbour Embedding (t-SNE)
maps complemented classification analysis through visualization of the
high-dimensional feature structures. Main Results. Development-sensitive
features were successfully identified for the developmental conditions of each
dataset. SVM classification accuracy and misclassification costs were improved
significantly for both healthy and impaired paediatric populations. t-SNE maps
revealed suitable tensor factorization was key in extracting developmental
features. Significance. The described methods are a promising tool for
incorporating the unique developmental features present throughout childhood
EEG into new technologies like BCI and its applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07630</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07630</id><created>2017-12-20</created><authors><author><keyname>Yang</keyname><forenames>Zhe</forenames></author><author><keyname>Cai</keyname><forenames>Lin</forenames></author><author><keyname>Gulliver</keyname><forenames>Aaron</forenames></author><author><keyname>He</keyname><forenames>Liang</forenames></author><author><keyname>Pan</keyname><forenames>Jianping</forenames></author></authors><title>Beyond Powers of Two: Hexagonal Modulation and Non-Binary Coding for
  Wireless Communication Systems</title><categories>eess.SP</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive modulation and coding (AMC) is widely employed in modern wireless
communication systems to improve the transmission efficiency by adjusting the
transmission rate according to the channel conditions. Thus, AMC can provide
very efficient use of channel resources especially over fading channels.
Quadrature Amplitude Modulation (QAM) is an ef- ficient and widely employed
digital modulation technique. It typically employs a rectangular signal
constellation. Therefore the decision regions of the constellation are square
partitions of the two-dimensional signal space. However, it is well known that
hexagons rather than squares provide the most compact regular tiling in two
dimensions. A compact tiling means a dense packing of the constellation points
and thus more energy efficient data transmission. Hexagonal modulation can be
difficult to implement because it does not fit well with the usual power-
of-two symbol sizes employed with binary data. To overcome this problem,
non-binary coding is combined with hexagonal modulation in this paper to
provide a system which is compatible with binary data. The feasibility and
efficiency are evaluated using a software-defined radio (SDR) based prototype.
Extensive simulation results are presented which show that this approach can
provide improved energy efficiency and spectrum utilization in wireless
communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07799</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07799</id><created>2017-12-21</created><authors><author><keyname>Dean</keyname><forenames>Roger T.</forenames></author><author><keyname>Forth</keyname><forenames>Jamie</forenames></author></authors><title>Towards a Deep Improviser: a prototype deep learning post-tonal free
  music generator</title><categories>cs.SD cs.LG eess.AS</categories><comments>13 pages, 1 Figure, 3 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two modest-sized symbolic corpora of post-tonal and post-metric keyboard
music have been constructed, one algorithmic, the other improvised. Deep
learning models of each have been trained and largely optimised. Our purpose is
to obtain a model with sufficient generalisation capacity that in response to a
small quantity of separate fresh input seed material, it can generate outputs
that are distinctive, rather than recreative of the learned corpora or the seed
material. This objective has been first assessed statistically, and as judged
by k-sample Anderson-Darling and Cramer tests, has been achieved. Music has
been generated using the approach, and informal judgements place it roughly on
a par with algorithmic and composed music in related forms. Future work will
aim to enhance the model such that it can be evaluated in relation to
expression, meaning and utility in real-time performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07814</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07814</id><created>2017-12-21</created><authors><author><keyname>Sun</keyname><forenames>Yingxiang</forenames></author><author><keyname>Chen</keyname><forenames>Jiajia</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Rahardja</keyname><forenames>Susanto</forenames></author></authors><title>Indoor Sound Source Localization with Probabilistic Neural Network</title><categories>cs.SD cs.LG eess.AS</categories><comments>10 pages, accepted by IEEE Transactions on Industrial Electronics</comments><journal-ref>IEEE Transactions on Industrial Electronics, vol. 65, no. 8, pp.
  6403-6413, Aug. 2018</journal-ref><doi>10.1109/TIE.2017.2786219</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that adverse environments such as high reverberation and low
signal-to-noise ratio (SNR) pose a great challenge to indoor sound source
localization. To address this challenge, in this paper, we propose a sound
source localization algorithm based on probabilistic neural network, namely
Generalized cross correlation Classification Algorithm (GCA). Experimental
results for adverse environments with high reverberation time T60 up to 600ms
and low SNR such as -10dB show that, the average azimuth angle error and
elevation angle error by GCA are only 4.6 degrees and 3.1 degrees respectively.
Compared with three recently published algorithms, GCA has increased the
success rate on direction of arrival estimation significantly with good
robustness to environmental changes. These results show that the proposed GCA
can localize accurately and robustly for diverse indoor applications where the
site acoustic features can be studied prior to the localization stage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07862</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07862</id><created>2017-12-21</created><authors><author><keyname>Uezato</keyname><forenames>Tatsumi</forenames></author><author><keyname>Fauvel</keyname><forenames>Mathieu</forenames></author><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author></authors><title>Hyperspectral image unmixing with LiDAR data-aided spatial
  regularization</title><categories>eess.IV physics.data-an</categories><doi>10.1109/TGRS.2018.2823419</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral unmixing methods incorporating spatial regularizations have
demonstrated increasing interest. Although spatial regularizers which promote
smoothness of the abundance maps have been widely used, they may overly smooth
these maps and, in particular, may not preserve edges present in the
hyperspectral image. Existing unmixing methods usually ignore these edge
structures or use edge information derived from the hyperspectral image itself.
However, this information may be affected by large amounts of noise or
variations in illumination, leading to erroneous spatial information
incorporated into the unmixing procedure. This paper proposes a simple, yet
powerful, spectral unmixing framework which incorporates external data (i.e.
LiDAR data). The LiDAR measurements can be easily exploited to adjust standard
spatial regularizations applied to the unmixing process. The proposed framework
is rigorously evaluated using two simulated datasets and a real hyperspectral
image. It is compared with competing methods that rely on spatial information
derived from a hyperspectral image. The results show that the proposed
framework can provide better abundance estimates and, more specifically, can
significantly improve the abundance estimates for pixels affected by shadows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07941</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07941</id><created>2017-12-21</created><authors><author><keyname>Zhang</keyname><forenames>Jie</forenames></author><author><keyname>Heusdens</keyname><forenames>Richard</forenames></author><author><keyname>Hendriks</keyname><forenames>Richard C.</forenames></author></authors><title>Rate-Distributed Spatial Filtering Based Noise Reduction in Wireless
  Acoustic Sensor Networks</title><categories>cs.SD eess.AS</categories><comments>submitted to IEEE Transactions on Audio, Speech and Language
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless acoustic sensor networks (WASNs), sensors typically have a
limited energy budget as they are often battery driven. Energy efficiency is
therefore essential to the design of algorithms in WASNs. One way to reduce
energy costs is to only select the sensors which are most informative, a
problem known as {\it sensor selection}. In this way, only sensors that
significantly contribute to the task at hand will be involved. In this work, we
consider a more general approach, which is based on rate-distributed spatial
filtering. Together with the distance over which transmission takes place, bit
rate directly influences the energy consumption. We try to minimize the battery
usage due to transmission, while constraining the noise reduction performance.
This results in an efficient rate allocation strategy, which depends on the
underlying signal statistics, as well as the distance from sensors to a fusion
center (FC). Under the utilization of a linearly constrained minimum variance
(LCMV) beamformer, the problem is derived as a semi-definite program.
Furthermore, we show that rate allocation is more general than sensor
selection, and sensor selection can be seen as a special case of the presented
rate-allocation solution, e.g., the best microphone subset can be determined by
thresholding the rates. Finally, numerical simulations for the application of
estimating several target sources in a WASN demonstrate that the proposed
method outperforms the microphone subset selection based approaches in the
sense of energy usage, and we find that the sensors close to the FC and close
to point sources are allocated with higher rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07951</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07951</id><created>2017-12-07</created><authors><author><keyname>Au</keyname><forenames>Minh</forenames></author><author><keyname>Kaddoum</keyname><forenames>Georges</forenames></author><author><keyname>Gagnon</keyname><forenames>Francois</forenames></author><author><keyname>Soujeri</keyname><forenames>Ebrahim</forenames></author></authors><title>A Joint Code-Frequency Index Modulation for Low-complexity, High
  Spectral and Energy Efficiency Communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A relatively simple low complexity multiuser communication system based on
simultaneous code and frequency index modulation (CFIM) is proposed in this
paper. The proposed architecture reduces the emitted energy at the transmitter
as well as the peak-to-average-power ratio (PAPR) of orthogonal
frequency-division multiplexing (OFDM)- based schemes functions without
relegating data rate. In the scheme we introduce here, we implement a joint
code- frequency- index modulation (CFIM) in order to enhance spectral and
energy efficiencies. After introducing and analysing the structure with respect
to latter metrics, we derive closed-form expressions of the bit error rate
(BER) performance over Rayleigh fading channels and we validate the outcome by
simulation results. Simulation are used verify the analyses and show that, in
terms of BER, the proposed CFIM outperforms the existing index modulation (IM)
based systems such as spatial modulation (SM), OFDM-IM and OFDM schemes
significantly. To better exhibit the particularities of the proposed scheme,
PAPR, complexity, spectral efficiency (SE) and energy efficiency (EE) are
thoroughly examined. Results indicate a high SE while ensuring an elevated
reliability compared to the aforementioned systems. In addition, the concept is
extended to synchronous multiuser communication networks, where full
functionality is obtained. With the characteristics demonstrated in this work,
the proposed system would constitute an exceptional nominee for Internet of
Things (IoT) applications where low-complexity, low-power consumption and high
data rate are paramount.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07958</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07958</id><created>2017-12-13</created><authors><author><keyname>Ahmed</keyname><forenames>Umair</forenames></author><author><keyname>Ali</keyname><forenames>Muhammad Faizyab</forenames></author><author><keyname>Javed</keyname><forenames>Kashif</forenames></author><author><keyname>Babri</keyname><forenames>Haroon Atique</forenames></author></authors><title>Predicting physiological developments from human gait using smartphone
  sensor data</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coronary artery disease, heart failure, angina pectoris and diabetes are
among the leading causes of morbidity and mortality over the globe.
Susceptibility to such disorders is compounded by changing lifestyles, poor
dietary routines, aging and obesity. Besides, conventional diagnostics are
limited in their capability to detect such pathologies at an early stage. This
generates demand for automatic recommender systems that could effectively
monitor and predict pathogenic behaviors in the body. To this end, we propose
human gait analysis for predicting two important physiological parameters
associated with different diseases, body mass index and age. Predicting age and
body mass index by actively profiling the gait samples, could be further used
for providing suitable healthcare recommendations. Existing strategies for
predicting age and body mass index, however, necessitate stringent experimental
settings for achieving appropriate performance. For instance, precisely
recorded speech signals were recently used for predicting body mass indices of
different subjects. Similarly, age groups were predicted by recording gait
samples from on-body and wearable sensors. Such specialized methods limit
active and convenient profiling of human age and body mass indices. We address
these issues, by introducing smartphone sensors as a means for recording gait
signals. Using on-board accelerometer and gyroscope helps in developing
easy-to-use and accessible systems for predicting body mass index and age. To
empirically show the effectiveness of our proposed methodology, we collected
gait samples from sixty-three different subjects that were classified in body
mass index and age groups using six well-known machine learning classifiers. We
evaluated our system using two different windowing operations for feature
extraction, namely Gaussian and Square.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07968</identifier>
 <datestamp>2018-08-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07968</id><created>2017-12-19</created><updated>2018-07-10</updated><authors><author><keyname>Wu</keyname><forenames>Hau-tieng</forenames></author><author><keyname>Liu</keyname><forenames>Yi-Wen</forenames></author></authors><title>Analyzing transient-evoked otoacoustic emissions by concentration of
  frequency and time</title><categories>eess.SP physics.data-an stat.AP</categories><doi>10.1121/1.5047749</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linear part of transient evoked (TE) otoacoustic emission (OAE) is
thought to be generated via coherent reflection near the characteristic place
of constituent wave components. Because of the tonotopic organization of the
cochlea, high frequency emissions return earlier than low frequencies; however,
due to the random nature of coherent reflection, the instantaneous frequency
(IF) and amplitude envelope of TEOAEs both fluctuate. Multiple reflection
components and synchronized spontaneous emissions can further make it difficult
to extract the IF by linear transforms. In this paper, we propose to model
TEOAEs as a sum of {\em intrinsic mode-type functions} and analyze it by a
{nonlinear-type time-frequency analysis} technique called concentration of
frequency and time (ConceFT). When tested with synthetic OAE signals {with
possibly multiple oscillatory components}, the present method is able to
produce clearly visualized traces of individual components on the
time-frequency plane. Further, when the signal is noisy, the proposed method is
compared with existing linear and bilinear methods in its accuracy for
estimating the fluctuating IF. Results suggest that ConceFT outperforms the
best of these methods in terms of optimal transport distance, reducing the
error by 10 to {21\%} when the signal to noise ratio is 10 dB or below.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.07970</identifier>
 <datestamp>2018-04-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.07970</id><created>2017-12-19</created><updated>2018-04-18</updated><authors><author><keyname>Zhu</keyname><forenames>Bin</forenames></author></authors><title>On a Parametric Spectral Estimation Problem</title><categories>eess.SP</categories><comments>6 pages, double columns, accepted for presentation at the IFAC
  conference SYSID 2018</comments><msc-class>30E05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an open question posed in \cite{Zhu-Baggio-17} on the uniqueness
of the solution to a parametric spectral estimation problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08034</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08034</id><created>2017-12-21</created><authors><author><keyname>Perrotin</keyname><forenames>Olivier</forenames></author><author><keyname>McLoughlin</keyname><forenames>Ian Vince</forenames></author></authors><title>On the Use of a Spectral Glottal Model for the Source-filter Separation
  of Speech</title><categories>eess.AS cs.SD</categories><comments>8 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The estimation of glottal flow from a speech waveform is a key method for
speech analysis and parameterization. Significant research effort has been made
to dissociate the first vocal tract resonance from the glottal formant (the
low-frequency resonance describing the open-phase of the vocal fold vibration).
However few methods cope with estimation of high-frequency spectral tilt to
describe the return-phase of the vocal fold vibration, which is crucial to the
perception of vocal effort. This paper proposes an improved version of the
well-known Iterative Adaptive Inverse Filtering (IAIF) called GFM-IAIF.
GFM-IAIF includes a full spectral model of the glottis that incorporates both
glottal formant and spectral tilt features. Comparisons with the standard IAIF
method show that while GFM-IAIF maintains good performance on vocal tract
removal, it significantly improves the perceptive timbral variations associated
to vocal effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08146</identifier>
 <datestamp>2019-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08146</id><created>2017-12-21</created><updated>2019-01-14</updated><authors><author><keyname>Fr&#xf6;hle</keyname><forenames>Markus</forenames></author><author><keyname>Lindberg</keyname><forenames>Christopher</forenames></author><author><keyname>Granstr&#xf6;m</keyname><forenames>Karl</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author></authors><title>Multisensor Poisson Multi-Bernoulli Filter for Joint Target-Sensor State
  Tracking</title><categories>cs.SY eess.SP</categories><comments>13 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a typical multitarget tracking (MTT) scenario, the sensor state is either
assumed known, or tracking is performed in the sensor's (relative) coordinate
frame. This assumption does not hold when the sensor, e.g., an automotive
radar, is mounted on a vehicle, and the target state should be represented in a
global (absolute) coordinate frame. Then it is important to consider the
uncertain location of the vehicle on which the sensor is mounted for MTT. In
this paper, we present a multisensor low complexity Poisson multi-Bernoulli MTT
filter, which jointly tracks the uncertain vehicle state and target states.
Measurements collected by different sensors mounted on multiple vehicles with
varying location uncertainty are incorporated sequentially based on the arrival
of new sensor measurements. In doing so, targets observed from a sensor mounted
on a well-localized vehicle reduce the state uncertainty of other poorly
localized vehicles, provided that a common non-empty subset of targets is
observed. A low complexity filter is obtained by approximations of the joint
sensor-feature state density minimizing the Kullback-Leibler divergence (KLD).
Results from synthetic as well as experimental measurement data, collected in a
vehicle driving scenario, demonstrate the performance benefits of joint
vehicle-target state tracking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08227</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08227</id><created>2017-12-21</created><authors><author><keyname>Li</keyname><forenames>Xuelu</forenames></author><author><keyname>Monga</keyname><forenames>Vishal</forenames></author><author><keyname>Rao</keyname><forenames>U. K. Arvind</forenames></author></authors><title>Analysis-synthesis model learning with shared features: a new framework
  for histopathological image classification</title><categories>eess.IV</categories><comments>2018 ISBI conference accepted paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated histopathological image analysis offers exciting opportunities for
the early diagnosis of several medical conditions including cancer. There are
however stiff practical challenges: 1.) discriminative features from such
images for separating diseased vs. healthy classes are not readily apparent,
and 2.) distinct classes, e.g. healthy vs. stages of disease continue to share
several geometric features. We propose a novel Analysis-synthesis model
Learning with Shared Features algorithm (ALSF) for classifying such images more
effectively. In ALSF, a joint analysis and synthesis learning model is
introduced to learn the classifier and the feature extractor at the same time.
In this way, the computation load in patch-level based image classification can
be much reduced. Crucially, we integrate into this framework the learning of a
low rank shared dictionary and a shared analysis operator, which more
accurately represents both similarities and differences in histopathological
images from distinct classes. ALSF is evaluated on two challenging databases:
(1) kidney tissue images provided by the Animal Diagnosis Lab (ADL) at the
Pennsylvania State University and (2) brain tumor images from The Cancer Genome
Atlas (TCGA) database. Experimental results confirm that ALSF can offer
benefits over state of the art alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08303</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08303</id><created>2017-12-21</created><authors><author><keyname>Mehmood</keyname><forenames>Tayyab</forenames></author></authors><title>COOJA Network Simulator: Exploring the Infinite Possible Ways to Compute
  the Performance Metrics of IOT Based Smart Devices to Understand the Working
  of IOT Based Compression &amp; Routing Protocols</title><categories>eess.SP cs.NI</categories><comments>7 Pages, 7 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates the scheme regarding Internet of Things (IOT) which
is well thought-out the next generation of Internet. IOT explicitly elaborates
the assimilation of human beings and physical systems, as they can cooperate
with each other so leading towards a sort of encroachment in networking by
interconnecting things together while making use of wireless embedded systems,
said to be the building blocks of IOT, that are capable to be given an IP
address and thus making them part of the global internet. Several essential
approaches that entail in IOT and supports this innovation are being argued in
this paper. 6LoWPAN (IPV6 Low Power Personal Area Networks) is a protocol used
to appropriately and efficiently use IPV6 addresses. Control messages of RPL
routing protocol for low power devices are discussed to understand the working
of RPL protocol. In the end Contiki OS based COOJA Network simulator is used to
demonstrate the working of how these routing and compression protocol works in
real time simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08335</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08335</id><created>2017-12-22</created><authors><author><keyname>Nguyen</keyname><forenames>Phu Xuan</forenames></author><author><keyname>Pham</keyname><forenames>Thinh Hung</forenames></author><author><keyname>Hoang</keyname><forenames>Trang</forenames></author><author><keyname>Shin</keyname><forenames>Oh-Soon</forenames></author></authors><title>An Efficient Spectral Leakage Filtering for IEEE 802.11af in TV White
  Space</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal frequency division multiplexing (OFDM) has been widely adopted for
modern wireless standards and become a key enabling technology for cognitive
radios. However, one of its main drawbacks is significant spectral leakage due
to the accumulation of multiple sinc-shaped subcarriers. In this paper, we
present a novel pulse shaping scheme for efficient spectral leakage suppression
in OFDM based physical layer of IEEE 802.11af standard. With conventional pulse
shaping filters such as a raised-cosine filter, vestigial symmetry can be used
to reduce spectral leakage very effectively. However, these pulse shaping
filters require long guard interval, i.e., cyclic prefix in an OFDM system, to
avoid inter-symbol interference (ISI), resulting in a loss of spectral
efficiency. The proposed pulse shaping method based on asymmetric pulse shaping
achieves better spectral leakage suppression and decreases ISI caused by
filtering as compared to conventional pulse shaping filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08336</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08336</id><created>2017-12-22</created><authors><author><keyname>Nag</keyname><forenames>Sayan</forenames></author><author><keyname>Sanyal</keyname><forenames>Shankha</forenames></author><author><keyname>Banerjee</keyname><forenames>Archi</forenames></author><author><keyname>Sengupta</keyname><forenames>Ranjan</forenames></author><author><keyname>Ghosh</keyname><forenames>Dipak</forenames></author></authors><title>Music of Brain and Music on Brain: A Novel EEG Sonification approach</title><categories>q-bio.NC cs.SD eess.AS physics.data-an</categories><comments>6 pages, 4 figures; Presented in the International Symposium on
  Frontiers of Research in speech and Music (FRSM)-2017, held at NIT, Rourkela
  in 15-16 December 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can we hear the sound of our brain? Is there any technique which can enable
us to hear the neuro-electrical impulses originating from the different lobes
of brain? The answer to all these questions is YES. In this paper we present a
novel method with which we can sonify the Electroencephalogram (EEG) data
recorded in rest state as well as under the influence of a simplest acoustical
stimuli - a tanpura drone. The tanpura drone has a very simple yet very complex
acoustic features, which is generally used for creation of an ambiance during a
musical performance. Hence, for this pilot project we chose to study the
correlation between a simple acoustic stimuli (tanpura drone) and sonified EEG
data. Till date, there have been no study which deals with the direct
correlation between a bio-signal and its acoustic counterpart and how that
correlation varies under the influence of different types of stimuli. This is
the first of its kind study which bridges this gap and looks for a direct
correlation between music signal and EEG data using a robust mathematical
microscope called Multifractal Detrended Cross Correlation Analysis (MFDXA).
For this, we took EEG data of 10 participants in 2 min 'rest state' (i.e. with
white noise) and in 2 min 'tanpura drone' (musical stimulus) listening
condition. Next, the EEG signals from different electrodes were sonified and
MFDXA technique was used to assess the degree of correlation (or the cross
correlation coefficient) between tanpura signal and EEG signals. The variation
of {\gamma}x for different lobes during the course of the experiment also
provides major interesting new information. Only music stimuli has the ability
to engage several areas of the brain significantly unlike other stimuli (which
engages specific domains only).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08340</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08340</id><created>2017-12-22</created><authors><author><keyname>Sapio</keyname><forenames>A.</forenames></author><author><keyname>Li</keyname><forenames>L.</forenames></author><author><keyname>Wu</keyname><forenames>J.</forenames></author><author><keyname>Wolf</keyname><forenames>M.</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>S. S.</forenames></author></authors><title>Reconfigurable Digital Channelizer Design Using Factored Markov Decision
  Processes</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a novel digital channelizer design is developed through the use
of a compact, system-level modeling approach. The model efficiently captures
key properties of a digital channelizer system and its time-varying operation.
The model applies powerful Markov Decision Process (MDP) techniques in new ways
for design optimization of reconfigurable channelization processing. The result
is a promising methodology for design and implementation of digital
channelizers that adapt dynamically to changing use cases and stochastic
environments while optimizing simultaneously for multiple conflicting
performance goals. The method is used to employ an MDP to generate a runtime
reconfiguration policy for a time-varying environment. Through extensive
simulations, the robustness of the adaptation is demonstrated in comparison
with the prior state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08363</identifier>
 <datestamp>2018-03-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08363</id><created>2017-12-22</created><updated>2018-03-08</updated><authors><author><keyname>Chorowski</keyname><forenames>Jan</forenames></author><author><keyname>Weiss</keyname><forenames>Ron J.</forenames></author><author><keyname>Saurous</keyname><forenames>Rif A.</forenames></author><author><keyname>Bengio</keyname><forenames>Samy</forenames></author></authors><title>On Using Backpropagation for Speech Texture Generation and Voice
  Conversion</title><categories>cs.SD eess.AS stat.ML</categories><comments>Accepted to ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by recent work on neural network image generation which rely on
backpropagation towards the network inputs, we present a proof-of-concept
system for speech texture synthesis and voice conversion based on two
mechanisms: approximate inversion of the representation learned by a speech
recognition neural network, and on matching statistics of neuron activations
between different source and target utterances. Similar to image texture
synthesis and neural style transfer, the system works by optimizing a cost
function with respect to the input waveform samples. To this end we use a
differentiable mel-filterbank feature extraction pipeline and train a
convolutional CTC speech recognition network. Our system is able to extract
speaker characteristics from very limited amounts of target speaker data, as
little as a few seconds, and can be used to generate realistic speech babble or
reconstruct an utterance in a different voice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08370</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08370</id><created>2017-12-22</created><authors><author><keyname>Feng</keyname><forenames>Lin</forenames></author><author><keyname>Liu</keyname><forenames>Shenlan</forenames></author><author><keyname>Yao</keyname><forenames>Jianing</forenames></author></authors><title>Music Genre Classification with Paralleling Recurrent Convolutional
  Neural Network</title><categories>cs.SD cs.IR eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has been demonstrated its effectiveness and efficiency in music
genre classification. However, the existing achievements still have several
shortcomings which impair the performance of this classification task. In this
paper, we propose a hybrid architecture which consists of the paralleling CNN
and Bi-RNN blocks. They focus on spatial features and temporal frame orders
extraction respectively. Then the two outputs are fused into one powerful
representation of musical signals and fed into softmax function for
classification. The paralleling network guarantees the extracting features
robust enough to represent music. Moreover, the experiments prove our proposed
architecture improve the music genre classification performance and the
additional Bi-RNN block is a supplement for CNNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08574</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08574</id><created>2017-12-20</created><authors><author><keyname>Bhatta</keyname><forenames>Abhishek</forenames></author><author><keyname>Mishra</keyname><forenames>Amit Kumar</forenames></author></authors><title>GSM-CommSense-based through-the-wall sensing</title><categories>eess.SP</categories><journal-ref>Taylor and Francis Remote Sensing Letters, Volume 9 Issue 3, 2018</journal-ref><doi>10.1080/2150704X.2017.1415476</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have recently proposed a scheme to use the channel equalization blocks of
telecommunication systems to sense changes in an environment. We call this
communication-sensing, CommSense for short. After some initial positive results
we tried to use our global system for mobile communication (GSM) based
CommSense system for a through-the-wall sensing application. As the system was
inherently highly under-determined we used statistical machine learning
techniques to help us sense environmental changes in the behind-the-wall
experiments. We observed that with limited amount of data per GSM frame of 577
{\mu}s a person can be detected across a wall to an accuracy of 77.458% and a
person carrying a weapon can be detected to an accuracy of 95.208%. We present
details of the experiments and the encouraging results that we have obtained in
this article.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08583</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08583</id><created>2017-12-22</created><authors><author><keyname>Yadav</keyname><forenames>Umang</forenames></author><author><keyname>Abbas</keyname><forenames>Sherif N</forenames></author><author><keyname>Hatzinakos</keyname><forenames>Dimitrios</forenames></author></authors><title>Evaluation of PPG Biometrics for Authentication in different states</title><categories>cs.CR cs.CV eess.SP</categories><comments>Accepted at 11th IAPR/IEEE International Conference on Biometrics,
  2018. 6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Amongst all medical biometric traits, Photoplethysmograph (PPG) is the
easiest to acquire. PPG records the blood volume change with just combination
of Light Emitting Diode and Photodiode from any part of the body. With IoT and
smart homes' penetration, PPG recording can easily be integrated with other
vital wearable devices. PPG represents peculiarity of hemodynamics and
cardiovascular system for each individual. This paper presents non-fiducial
method for PPG based biometric authentication. Being a physiological signal,
PPG signal alters with physical/mental stress and time. For robustness, these
variations cannot be ignored. While, most of the previous works focused only on
single session, this paper demonstrates extensive performance evaluation of PPG
biometrics against single session data, different emotions, physical exercise
and time-lapse using Continuous Wavelet Transform (CWT) and Direct Linear
Discriminant Analysis (DLDA). When evaluated on different states and datasets,
equal error rate (EER) of $0.5\%$-$6\%$ was achieved for $45$-$60$s average
training time. Our CWT/DLDA based technique outperformed all other
dimensionality reduction techniques and previous work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08655</identifier>
 <datestamp>2018-05-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08655</id><created>2017-12-15</created><updated>2018-05-16</updated><authors><author><keyname>Bianco</keyname><forenames>Michael</forenames></author><author><keyname>Gerstoft</keyname><forenames>Peter</forenames></author></authors><title>Travel time tomography with adaptive dictionaries</title><categories>physics.geo-ph eess.IV stat.ML</categories><comments>Submitted to IEEE Transactions on Computational Imaging (1st
  revision)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a 2D travel time tomography method which regularizes the inversion
by modeling groups of slowness pixels from discrete slowness maps, called
patches, as sparse linear combinations of atoms from a dictionary. We propose
to use dictionary learning during the inversion to adapt dictionaries to
specific slowness maps. This patch regularization, called the local model, is
integrated into the overall slowness map, called the global model. The local
model considers small-scale variations using a sparsity constraint and the
global model considers larger-scale features constrained using $\ell_2$
regularization. This strategy in a locally-sparse travel time tomography (LST)
approach enables simultaneous modeling of smooth and discontinuous slowness
features. This is in contrast to conventional tomography methods, which
constrain models to be exclusively smooth or discontinuous. We develop a
$\textit{maximum a posteriori}$ formulation for LST and exploit the sparsity of
slowness patches using dictionary learning. The LST approach compares favorably
with smoothness and total variation regularization methods on densely, but
irregularly sampled synthetic slowness maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08659</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08659</id><created>2017-12-22</created><authors><author><keyname>Chen</keyname><forenames>Leian</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Quickest Attack Detection in Smart Grid Based on Sequential Monte Carlo
  Filtering</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quick and accurate detection of cyber attack is key to the normal operation
of the smart grid system. In this paper, a joint state estimation and
sequential attack detection method for a given bus with grid frequency drift is
proposed that utilizes the commonly monitored output voltage. In particular,
based on a non-linear state-space model derived from the three-phase sinusoidal
voltage equations, we employ the sequential Monte Carlo (SMC) filtering to
estimate the system state. The output of the SMC filter is fed into a CUSUM
test to detect the attack in a fastest way. Moreover, an adaptive sampling
strategy is proposed to reduce the rate of taking measurements and
communicating with the controller. Extensive simulation results demonstrate
that the proposed method achieves high adaptivity and efficient detection of
various types of attacks in power systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08675</identifier>
 <datestamp>2018-04-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08675</id><created>2017-12-22</created><updated>2018-04-09</updated><authors><author><keyname>Du</keyname><forenames>Xianzhi</forenames></author><author><keyname>Wang</keyname><forenames>Xiaolong</forenames></author><author><keyname>Li</keyname><forenames>Dawei</forenames></author><author><keyname>Zhu</keyname><forenames>Jingwen</forenames></author><author><keyname>Tasci</keyname><forenames>Serafettin</forenames></author><author><keyname>Upright</keyname><forenames>Cameron</forenames></author><author><keyname>Walsh</keyname><forenames>Stephen</forenames></author><author><keyname>Davis</keyname><forenames>Larry</forenames></author></authors><title>Boundary-sensitive Network for Portrait Segmentation</title><categories>cs.CV eess.IV</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compared to the general semantic segmentation problem, portrait segmentation
has higher precision requirement on boundary area. However, this problem has
not been well studied in previous works. In this paper, we propose a
boundary-sensitive deep neural network (BSN) for portrait segmentation. BSN
introduces three novel techniques. First, an individual boundary-sensitive
kernel is proposed by dilating the contour line and assigning the boundary
pixels with multi-class labels. Second, a global boundary-sensitive kernel is
employed as a position sensitive prior to further constrain the overall shape
of the segmentation map. Third, we train a boundary-sensitive attribute
classifier jointly with the segmentation network to reinforce the network with
semantic boundary shape information. We have evaluated BSN on the current
largest public portrait segmentation dataset, i.e, the PFCN dataset, as well as
the portrait images collected from other three popular image segmentation
datasets: COCO, COCO-Stuff, and PASCAL VOC. Our method achieves the superior
quantitative and qualitative performance over state-of-the-arts on all the
datasets, especially on the boundary area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08708</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08708</id><created>2017-12-22</created><updated>2018-03-26</updated><authors><author><keyname>Latif</keyname><forenames>Siddique</forenames></author><author><keyname>Rana</keyname><forenames>Rajib</forenames></author><author><keyname>Qadir</keyname><forenames>Junaid</forenames></author><author><keyname>Epps</keyname><forenames>Julien</forenames></author></authors><title>Variational Autoencoders for Learning Latent Representations of Speech
  Emotion: A Preliminary Study</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning the latent representation of data in unsupervised fashion is a very
interesting process that provides relevant features for enhancing the
performance of a classifier. For speech emotion recognition tasks, generating
effective features is crucial. Currently, handcrafted features are mostly used
for speech emotion recognition, however, features learned automatically using
deep learning have shown strong success in many problems, especially in image
processing. In particular, deep generative models such as Variational
Autoencoders (VAEs) have gained enormous success for generating features for
natural images. Inspired by this, we propose VAEs for deriving the latent
representation of speech signals and use this representation to classify
emotions. To the best of our knowledge, we are the first to propose VAEs for
speech emotion classification. Evaluations on the IEMOCAP dataset demonstrate
that features learned by VAEs can produce state-of-the-art results for speech
emotion classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08776</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08776</id><created>2017-12-23</created><authors><author><keyname>Zhang</keyname><forenames>Jianwei</forenames></author><author><keyname>Chen</keyname><forenames>Xu</forenames></author><author><keyname>Xiao</keyname><forenames>Xuezhong</forenames></author></authors><title>Texture Object Segmentation Based on Affine Invariant Texture Detection</title><categories>eess.IV cs.CV</categories><comments>6pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To solve the issue of segmenting rich texture images, a novel detection
methods based on the affine invariable principle is proposed. Considering the
similarity between the texture areas, we first take the affine transform to get
numerous shapes, and utilize the KLT algorithm to verify the similarity. The
transforms include rotation, proportional transformation and perspective
deformation to cope with a variety of situations. Then we propose an improved
LBP method combining canny edge detection to handle the boundary in the
segmentation process. Moreover, human-computer interaction of this method which
helps splitting the matched texture area from the original images is
user-friendly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08849</identifier>
 <datestamp>2019-05-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08849</id><created>2017-12-23</created><updated>2018-05-04</updated><authors><author><keyname>Koutrouvelis</keyname><forenames>Andreas I.</forenames></author><author><keyname>Sherson</keyname><forenames>Thomas W.</forenames></author><author><keyname>Heusdens</keyname><forenames>Richard</forenames></author><author><keyname>Hendriks</keyname><forenames>Richard C.</forenames></author></authors><title>A Low-Cost Robust Distributed Linearly Constrained Beamformer for
  Wireless Acoustic Sensor Networks with Arbitrary Topology</title><categories>eess.SP cs.IT math.IT</categories><journal-ref>IEEE/ACM Transactions on Audio, Speech and Language Processing,
  26(8), 1434-1448, 2018</journal-ref><doi>10.1109/TASLP.2018.2829405</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new robust distributed linearly constrained beamformer which
utilizes a set of linear equality constraints to reduce the cross power
spectral density matrix to a block-diagonal form. The proposed beamformer has a
convenient objective function for use in arbitrary distributed network
topologies while having identical performance to a centralized implementation.
Moreover, the new optimization problem is robust to relative acoustic transfer
function (RATF) estimation errors and to target activity detection (TAD)
errors. Two variants of the proposed beamformer are presented and evaluated in
the context of multi-microphone speech enhancement in a wireless acoustic
sensor network, and are compared with other state-of-the-art distributed
beamformers in terms of communication costs and robustness to RATF estimation
errors and TAD errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.08992</identifier>
 <datestamp>2018-06-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.08992</id><created>2017-12-24</created><updated>2018-06-18</updated><authors><author><keyname>Siddhant</keyname><forenames>Aditya</forenames></author><author><keyname>Jyothi</keyname><forenames>Preethi</forenames></author><author><keyname>Ganapathy</keyname><forenames>Sriram</forenames></author></authors><title>Leveraging Native Language Speech for Accent Identification using Deep
  Siamese Networks</title><categories>cs.CL cs.LG cs.SD eess.AS</categories><comments>Published in ASRU 2017</comments><doi>10.1109/ASRU.2017.8268994</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of automatic accent identification is important for several
applications like speaker profiling and recognition as well as for improving
speech recognition systems. The accented nature of speech can be primarily
attributed to the influence of the speaker's native language on the given
speech recording. In this paper, we propose a novel accent identification
system whose training exploits speech in native languages along with the
accented speech. Specifically, we develop a deep Siamese network-based model
which learns the association between accented speech recordings and the native
language speech recordings. The Siamese networks are trained with i-vector
features extracted from the speech recordings using either an unsupervised
Gaussian mixture model (GMM) or a supervised deep neural network (DNN) model.
We perform several accent identification experiments using the CSLU Foreign
Accented English (FAE) corpus. In these experiments, our proposed approach
using deep Siamese networks yield significant relative performance improvements
of 15.4 percent on a 10-class accent identification task, over a baseline
DNN-based classification system that uses GMM i-vectors. Furthermore, we
present a detailed error analysis of the proposed accent identification system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09117</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.09117</id><created>2017-12-25</created><authors><author><keyname>Cosentino</keyname><forenames>Romain</forenames></author><author><keyname>Balestriero</keyname><forenames>Randall</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard</forenames></author><author><keyname>Patel</keyname><forenames>Ankit</forenames></author></authors><title>Overcomplete Frame Thresholding for Acoustic Scene Analysis</title><categories>eess.AS cs.SD stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we derive a generic overcomplete frame thresholding scheme
based on risk minimization. Overcomplete frames being favored for analysis
tasks such as classification, regression or anomaly detection, we provide a way
to leverage those optimal representations in real-world applications through
the use of thresholding. We validate the method on a large scale bird activity
detection task via the scattering network architecture performed by means of
continuous wavelets, known for being an adequate dictionary in audio
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09236</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.09236</id><created>2017-12-26</created><updated>2018-01-01</updated><authors><author><keyname>Akbari</keyname><forenames>Mojtaba</forenames></author><author><keyname>Mohrekesh</keyname><forenames>Majid</forenames></author><author><keyname>Karimi</keyname><forenames>Nader</forenames></author><author><keyname>Samavi</keyname><forenames>Shadrokh</forenames></author></authors><title>RIBBONS: Rapid Inpainting Based on Browsing of Neighborhood Statistics</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image inpainting refers to filling missing places in images using neighboring
pixels. It also has many applications in different tasks of image processing.
Most of these applications enhance the image quality by significant unwanted
changes or even elimination of some existing pixels. These changes require
considerable computational complexities which in turn results in remarkable
processing time. In this paper we propose a fast inpainting algorithm called
RIBBONS based on selection of patches around each missing pixel. This would
accelerate the execution speed and the capability of online frame inpainting in
video. The applied cost-function is a combination of statistical and spatial
features in all neighboring pixels. We evaluate some candidate patches using
the proposed cost function and minimize it to achieve the final patch.
Experimental results show the higher speed of 'Ribbons' in comparison with
previous methods while being comparable in terms of PSNR and SSIM for the
images in MISC dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09310</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.09310</id><created>2017-12-26</created><authors><author><keyname>Di Lorenzo</keyname><forenames>P.</forenames></author><author><keyname>Barbarossa</keyname><forenames>S.</forenames></author><author><keyname>Banelli</keyname><forenames>P.</forenames></author></authors><title>Sampling and Recovery of Graph Signals</title><categories>eess.SP</categories><comments>to appear in the book &quot;Cooperative and Graph Signal Pocessing:
  Principles and Applications&quot;, P. Djuric and C. Richard Eds., Academic Press,
  Elsevier, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this chapter is to give an overview of the recent advances related
to sampling and recovery of signals defined over graphs. First, we illustrate
the conditions for perfect recovery of bandlimited graph signals from samples
collected over a selected set of vertexes. Then, we describe some sampling
design criteria proposed in the literature to mitigate the effect of noise and
model mismatching when performing graph signal recovery. Finally, we illustrate
algorithms and optimal sampling strategies for adaptive recovery and tracking
of dynamic graph signals, where both sampling set and signal values are allowed
to vary with time. Numerical simulations carried out over both synthetic and
real data illustrate the potential advantages of graph signal processing
methods for sampling, interpolation, and tracking of signals observed over
irregular domains such as, e.g., technological or biological networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09350</identifier>
 <datestamp>2019-04-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.09350</id><created>2017-12-25</created><updated>2019-04-24</updated><authors><author><keyname>Tsitsvero</keyname><forenames>Mikhail</forenames></author><author><keyname>Borgnat</keyname><forenames>Pierre</forenames></author><author><keyname>Gon&#xe7;alves</keyname><forenames>Paulo</forenames></author></authors><title>Analytic signal in many dimensions</title><categories>eess.SP cs.IT math.CV math.IT math.SP</categories><comments>47 pages, under review in Applied and Computational Harmonic Analysis
  Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we extend analytic signal theory to the multidimensional case
when oscillations are observed in the $d$ orthogonal directions. First it is
shown how to obtain separate phase-shifted components and how to combine them
into instantaneous amplitude and phases. Second, the proper hypercomplex
analytic signal is defined as holomorphic hypercomplex function on the boundary
of certain upper half-space. Next it is shown that correct phase-shifted
components can be obtained by positive frequency restriction of hypercomplex
Fourier transform. Necessary and sufficient conditions for analytic extension
of the hypercomplex analytic signal into the upper hypercomplex half-space by
means of holomorphic Fourier transform are given by the corresponding
Paley-Wiener theorem. Moreover it is demonstrated that for $d&gt;2$ there is no
corresponding non-commutative hypercomplex Fourier transform (including
Clifford and Cayley-Dickson based) that allows to recover phase-shifted
components correctly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09382</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.09382</id><created>2017-12-19</created><authors><author><keyname>Shlizerman</keyname><forenames>Eli</forenames></author><author><keyname>Dery</keyname><forenames>Lucio M.</forenames></author><author><keyname>Schoen</keyname><forenames>Hayden</forenames></author><author><keyname>Kemelmacher-Shlizerman</keyname><forenames>Ira</forenames></author></authors><title>Audio to Body Dynamics</title><categories>eess.AS cs.CV cs.SD</categories><comments>Link with videos https://arviolin.github.io/AudioBodyDynamics/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method that gets as input an audio of violin or piano playing,
and outputs a video of skeleton predictions which are further used to animate
an avatar. The key idea is to create an animation of an avatar that moves their
hands similarly to how a pianist or violinist would do, just from audio. Aiming
for a fully detailed correct arms and fingers motion is a goal, however, it's
not clear if body movement can be predicted from music at all. In this paper,
we present the first result that shows that natural body dynamics can be
predicted at all. We built an LSTM network that is trained on violin and piano
recital videos uploaded to the Internet. The predicted points are applied onto
a rigged avatar to create the animation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09438</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.09438</id><created>2017-12-26</created><authors><author><keyname>Nguyen</keyname><forenames>Sinh Le Hong</forenames></author><author><keyname>Jarvelainen</keyname><forenames>Jan</forenames></author><author><keyname>Karttunen</keyname><forenames>Aki</forenames></author><author><keyname>Haneda</keyname><forenames>Katsuyuki</forenames></author><author><keyname>Putkonen</keyname><forenames>Jyri</forenames></author></authors><title>Comparing Radio Propagation Channels Between 28 and 140 GHz Bands in a
  Shopping Mall</title><categories>cs.IT eess.SP math.IT</categories><comments>This paper has been accepted to the 2018 12th European Conference on
  Antennas and Propagation (EuCAP), London, UK, April 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we compare the radio propagation channels characteristics
between 28 and 140 GHz bands based on the wideband (several GHz) and
directional channel sounding in a shopping mall environment. The measurements
and data processing are conducted in such a way to meet requirements for a fair
comparison of large- and small- scale channel parameters between the two bands.
Our results reveal that there is high spatial-temporal correlation between 28
and 140 GHz channels, similar numbers of strong multipath components, and only
small variations in the large-scale parameters between the two bands.
Furthermore, when including the weak paths there are higher total numbers of
clusters and paths in 28 GHz as compared to those in 140 GHz bands. With these
similarities, it would be very interesting to investigate the potentials of
using 140 GHz band in the future mobile radio communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09668</identifier>
 <datestamp>2018-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.09668</id><created>2017-12-27</created><updated>2018-02-19</updated><authors><author><keyname>Pham</keyname><forenames>Phuong</forenames></author><author><keyname>Li</keyname><forenames>Juncheng</forenames></author><author><keyname>Szurley</keyname><forenames>Joseph</forenames></author><author><keyname>Das</keyname><forenames>Samarjit</forenames></author></authors><title>Eventness: Object Detection on Spectrograms for Temporal Localization of
  Audio Events</title><categories>cs.SD eess.AS</categories><comments>5 pages, 3 figures, accepted to ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce the concept of Eventness for audio event
detection, which can, in part, be thought of as an analogue to Objectness from
computer vision. The key observation behind the eventness concept is that audio
events reveal themselves as 2-dimensional time-frequency patterns with specific
textures and geometric structures in spectrograms. These time-frequency
patterns can then be viewed analogously to objects occurring in natural images
(with the exception that scaling and rotation invariance properties do not
apply). With this key observation in mind, we pose the problem of detecting
monophonic or polyphonic audio events as an equivalent visual object(s)
detection problem under partial occlusion and clutter in spectrograms. We adapt
a state-of-the-art visual object detection model to evaluate the audio event
detection task on publicly available datasets. The proposed network has
comparable results with a state-of-the-art baseline and is more robust on
minority events. Provided large-scale datasets, we hope that our proposed
conceptual model of eventness will be beneficial to the audio signal processing
community towards improving performance of audio event detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09673</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.09673</id><created>2017-12-27</created><updated>2018-03-26</updated><authors><author><keyname>Tseng</keyname><forenames>Shao-Yen</forenames></author><author><keyname>Li</keyname><forenames>Juncheng</forenames></author><author><keyname>Wang</keyname><forenames>Yun</forenames></author><author><keyname>Szurley</keyname><forenames>Joseph</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author><author><keyname>Das</keyname><forenames>Samarjit</forenames></author></authors><title>Multiple Instance Deep Learning for Weakly Supervised Small-Footprint
  Audio Event Detection</title><categories>cs.SD eess.AS</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art audio event detection (AED) systems rely on supervised
learning using strongly labeled data. However, this dependence severely limits
scalability to large-scale datasets where fine resolution annotations are too
expensive to obtain. In this paper, we propose a small-footprint multiple
instance learning (MIL) framework for multi-class AED using weakly annotated
labels. The proposed MIL framework uses audio embeddings extracted from a
pre-trained convolutional neural network as input features. We show that by
using audio embeddings the MIL framework can be implemented using a simple DNN
with performance comparable to recurrent neural networks.
  We evaluate our approach by training an audio tagging system using a subset
of AudioSet, which is a large collection of weakly labeled YouTube video
excerpts. Combined with a late-fusion approach, we improve the F1 score of a
baseline audio tagging system by 17%. We show that audio embeddings extracted
by the convolutional neural networks significantly boost the performance of all
MIL models. This framework reduces the model complexity of the AED system and
is suitable for applications where computational resources are limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09680</identifier>
 <datestamp>2018-03-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.09680</id><created>2017-12-27</created><updated>2018-03-01</updated><authors><author><keyname>Li</keyname><forenames>Juncheng</forenames></author><author><keyname>Wang</keyname><forenames>Yun</forenames></author><author><keyname>Szurley</keyname><forenames>Joseph</forenames></author><author><keyname>Metze</keyname><forenames>Florian</forenames></author><author><keyname>Das</keyname><forenames>Samarjit</forenames></author></authors><title>A Light-Weight Multimodal Framework for Improved Environmental Audio
  Tagging</title><categories>cs.SD eess.AS</categories><comments>5 pages, 3 figures, Accepted and to appear at ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lack of strong labels has severely limited the state-of-the-art fully
supervised audio tagging systems to be scaled to larger dataset. Meanwhile,
audio-visual learning models based on unlabeled videos have been successfully
applied to audio tagging, but they are inevitably resource hungry and require a
long time to train. In this work, we propose a light-weight, multimodal
framework for environmental audio tagging. The audio branch of the framework is
a convolutional and recurrent neural network (CRNN) based on multiple instance
learning (MIL). It is trained with the audio tracks of a large collection of
weakly labeled YouTube video excerpts; the video branch uses pretrained
state-of-the-art image recognition networks and word embeddings to extract
information from the video track and to map visual objects to sound events.
Experiments on the audio tagging task of the DCASE 2017 challenge show that the
incorporation of video information improves a strong baseline audio tagging
system by 5.3\% absolute in terms of $F_1$ score. The entire system can be
trained within 6~hours on a single GPU, and can be easily carried over to other
audio tasks such as speech sentimental analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09771</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.09771</id><created>2017-12-28</created><authors><author><keyname>Golmohammadi</keyname><forenames>Meysam</forenames></author><author><keyname>Torbati</keyname><forenames>Amir Hossein Harati Nejad</forenames></author><author><keyname>de Diego</keyname><forenames>Silvia Lopez</forenames></author><author><keyname>Obeid</keyname><forenames>Iyad</forenames></author><author><keyname>Picone</keyname><forenames>Joseph</forenames></author></authors><title>Automatic Analysis of EEGs Using Big Data and Hybrid Deep Learning
  Architectures</title><categories>cs.LG eess.SP q-bio.NC stat.ML</categories><comments>Under review in Journal of Clinical Neurophysiology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: A clinical decision support tool that automatically interprets
EEGs can reduce time to diagnosis and enhance real-time applications such as
ICU monitoring. Clinicians have indicated that a sensitivity of 95% with a
specificity below 5% was the minimum requirement for clinical acceptance. We
propose a highperformance classification system based on principles of big data
and machine learning. Methods: A hybrid machine learning system that uses
hidden Markov models (HMM) for sequential decoding and deep learning networks
for postprocessing is proposed. These algorithms were trained and evaluated
using the TUH EEG Corpus, which is the world's largest publicly available
database of clinical EEG data. Results: Our approach delivers a sensitivity
above 90% while maintaining a specificity below 5%. This system detects three
events of clinical interest: (1) spike and/or sharp waves, (2) periodic
lateralized epileptiform discharges, (3) generalized periodic epileptiform
discharges. It also detects three events used to model background noise: (1)
artifacts, (2) eye movement (3) background. Conclusions: A hybrid HMM/deep
learning system can deliver a low false alarm rate on EEG event detection,
making automated analysis a viable option for clinicians. Significance: The TUH
EEG Corpus enables application of highly data consumptive machine learning
algorithms to EEG analysis. Performance is approaching clinical acceptance for
real-time applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.09776</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.09776</id><created>2017-12-28</created><authors><author><keyname>Golmohammadi</keyname><forenames>Meysam</forenames></author><author><keyname>Ziyabari</keyname><forenames>Saeedeh</forenames></author><author><keyname>Shah</keyname><forenames>Vinit</forenames></author><author><keyname>de Diego</keyname><forenames>Silvia Lopez</forenames></author><author><keyname>Obeid</keyname><forenames>Iyad</forenames></author><author><keyname>Picone</keyname><forenames>Joseph</forenames></author></authors><title>Deep Architectures for Automated Seizure Detection in Scalp EEGs</title><categories>cs.LG eess.SP q-bio.NC stat.ML</categories><comments>nder review in International Conference on Machine Learning,
  Stockholm, Sweden</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated seizure detection using clinical electroencephalograms is a
challenging machine learning problem because the multichannel signal often has
an extremely low signal to noise ratio. Events of interest such as seizures are
easily confused with signal artifacts (e.g, eye movements) or benign variants
(e.g., slowing). Commercially available systems suffer from unacceptably high
false alarm rates. Deep learning algorithms that employ high dimensional models
have not previously been effective due to the lack of big data resources. In
this paper, we use the TUH EEG Seizure Corpus to evaluate a variety of hybrid
deep structures including Convolutional Neural Networks and Long Short-Term
Memory Networks. We introduce a novel recurrent convolutional architecture that
delivers 30% sensitivity at 7 false alarms per 24 hours. We have also evaluated
our system on a held-out evaluation set based on the Duke University Seizure
Corpus and demonstrate that performance trends are similar to the TUH EEG
Seizure Corpus. This is a significant finding because the Duke corpus was
collected with different instrumentation and at different hospitals. Our work
shows that deep learning architectures that integrate spatial and temporal
contexts are critical to achieving state of the art performance and will enable
a new generation of clinically-acceptable technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10088</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.10088</id><created>2017-12-28</created><authors><author><keyname>Zhang</keyname><forenames>Xuejing</forenames></author><author><keyname>He</keyname><forenames>Zishu</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author><author><keyname>Liao</keyname><forenames>Bin</forenames></author><author><keyname>Zhang</keyname><forenames>Xuepan</forenames></author><author><keyname>Yang</keyname><forenames>Yue</forenames></author></authors><title>OPARC: Optimal and Precise Array Response Control Algorithm -- Part I:
  Fundamentals</title><categories>eess.SP</categories><comments>Submitted to TSP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of how to optimally and precisely control array
response levels is addressed. By using the concept of the optimal weight vector
from the adaptive array theory and adding virtual interferences one by one, the
change rule of the optimal weight vector is found and a new formulation of the
weight vector update is thus devised. Then, the issue of how to precisely
control the response level of one single direction is investigated. More
specifically, we assign a virtual interference to a direction such that the
response level can be precisely controlled. Moreover, the parameters, such as,
the interference-to-noise ratio (INR), can be figured out according to the
desired level. Additionally, the parameter optimization is carried out to
obtain the maximal array gain. The resulting scheme is called optimal and
precise array response control (OPARC) in this paper. To understand it better,
its properties are given, and its comparison with the existing accurate array
response control ($ {\textrm A}^2\textrm{RC} $) algorithm is provided. Finally,
simulation results are presented to verify the effectiveness and superiority of
the proposed OPARC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10090</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.10090</id><created>2017-12-28</created><authors><author><keyname>Zhang</keyname><forenames>Xuejing</forenames></author><author><keyname>He</keyname><forenames>Zishu</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author><author><keyname>Liao</keyname><forenames>Bin</forenames></author><author><keyname>Zhang</keyname><forenames>Xuepan</forenames></author><author><keyname>Yang</keyname><forenames>Yue</forenames></author></authors><title>OPARC: Optimal and Precise Array Response Control Algorithm -- Part II:
  Multi-points and Applications</title><categories>eess.SP</categories><comments>submitted to TSP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the optimal and precise array response control (OPARC)
algorithm proposed in Part I of this two paper series is extended from single
point to multi-points. Two computationally attractive parameter determination
approaches are provided to maximize the array gain under certain constraints.
In addition, the applications of the multi-point OPARC algorithm to array
signal processing are studied. It is applied to realize array pattern synthesis
(including the general array case and the large array case), multi-constraint
adaptive beamforming and quiescent pattern control, where an innovative concept
of normalized covariance matrix loading (NCL) is proposed. Finally, simulation
results are presented to validate the superiority and effectiveness of the
multi-point OPARC algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10092</identifier>
 <datestamp>2018-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.10092</id><created>2017-12-28</created><updated>2018-01-29</updated><authors><author><keyname>Zhang</keyname><forenames>Xuejing</forenames></author><author><keyname>He</keyname><forenames>Zishu</forenames></author><author><keyname>Liao</keyname><forenames>Bin</forenames></author><author><keyname>Zhang</keyname><forenames>Xuepan</forenames></author><author><keyname>Peng</keyname><forenames>Weilai</forenames></author></authors><title>A novel array response control algorithm via oblique projection</title><categories>eess.SP</categories><comments>This paper is not accepted by ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel array response control algorithm and its
application to array pattern synthesis. The proposed algorithm considers how to
flexibly and precisely adjust the array responses at multiple points, on the
basis of one given weight vector. With the principle of adaptive beamforming,
it is shown that the optimal weight vector for array response control can be
equivalently obtained with a different manner, in which a linear transformation
is conducted on the quiescent weight. This new strategy is utilized to realize
multi-point precise array response control from one given weight vector, and it
obtains a closed-form solution. A careful analysis shows that the response
levels at given points can be independently, flexibly and accurately adjusted
by simply varying the parameter vector, and that the uncontrolled region
remains almost unchanged. By applying the proposed algorithm, an effective
pattern synthesis approach is devised. Simulation results are provided to
demonstrate the performance of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10096</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.10096</id><created>2017-12-28</created><updated>2018-06-29</updated><authors><author><keyname>Gao</keyname><forenames>Jingkun</forenames></author><author><keyname>Deng</keyname><forenames>Bin</forenames></author><author><keyname>Qin</keyname><forenames>Yuliang</forenames></author><author><keyname>Wang</keyname><forenames>Hongqiang</forenames></author><author><keyname>Li</keyname><forenames>Xiang</forenames></author></authors><title>Enhanced Radar Imaging Using a Complex-valued Convolutional Neural
  Network</title><categories>eess.SP</categories><comments>5 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNN) have been successfully employed to tackle
several remote sensing tasks such as image classification and show better
performance than previous techniques. For the radar imaging community, a
natural question is: Can CNN be introduced to radar imaging and enhance its
performance? The presented letter gives an affirmative answer to this question.
We firstly propose a processing framework by which a complex-valued CNN
(CV-CNN) is used to enhance radar imaging. Then we introduce two modifications
to the CV-CNN to adapt it to radar imaging tasks. Subsequently, the method to
generate training data is shown and some implementation details are presented.
Finally, simulations and experiments are carried out, and both results show the
superiority of the proposed method on imaging quality and computational
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10107</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.10107</id><created>2017-12-28</created><updated>2019-12-02</updated><authors><author><keyname>Ziyabari</keyname><forenames>Saeedeh</forenames></author><author><keyname>Shah</keyname><forenames>Vinit</forenames></author><author><keyname>Golmohammadi</keyname><forenames>Meysam</forenames></author><author><keyname>Obeid</keyname><forenames>Iyad</forenames></author><author><keyname>Picone</keyname><forenames>Joseph</forenames></author></authors><title>Objective evaluation metrics for automatic classification of EEG events</title><categories>cs.LG eess.SP stat.ML</categories><comments>22 pages, 11 figures, 9 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evaluation of machine learning algorithms in biomedical fields for
applications involving sequential data lacks standardization. Common
quantitative scalar evaluation metrics such as sensitivity and specificity can
often be misleading depending on the requirements of the application.
Evaluation metrics must ultimately reflect the needs of users yet be
sufficiently sensitive to guide algorithm development. Feedback from critical
care clinicians who use automated event detection software in clinical
applications has been overwhelmingly emphatic that a low false alarm rate,
typically measured in units of the number of errors per 24 hours, is the single
most important criterion for user acceptance. Though using a single metric is
not often as insightful as examining performance over a range of operating
conditions, there is a need for a single scalar figure of merit. In this paper,
we discuss the deficiencies of existing metrics for a seizure detection task
and propose several new metrics that offer a more balanced view of performance.
We demonstrate these metrics on a seizure detection task based on the TUH EEG
Corpus. We show that two promising metrics are a measure based on a concept
borrowed from the spoken term detection literature, Actual Term-Weighted Value
(ATWV), and a new metric, Time-Aligned Event Scoring (TAES), that accounts for
the temporal alignment of the hypothesis to the reference annotation. We also
demonstrate that state of the art technology based on deep learning, though
impressive in its performance, still needs significant improvement before it
meets very strict user acceptance criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10164</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.10164</id><created>2017-12-29</created><authors><author><keyname>Khorsandi</keyname><forenames>Mohammad Amin</forenames></author><author><keyname>Karimi</keyname><forenames>Nader</forenames></author><author><keyname>Samavi</keyname><forenames>Shadrokh</forenames></author></authors><title>Polyp detection inside the capsule endoscopy: an approach for power
  consumption reduction</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Capsule endoscopy is a novel and non-invasive method for diagnosis, which
assists gastroenterologists to monitor the digestive track. Although this new
technology has many advantages over the conventional endoscopy, there are
weaknesses that limits the usage of this technology. Some weaknesses are due to
using small-size batteries. Radio transmitter consumes the largest portion of
energy; consequently, a simple way to reduce the power consumption is to reduce
the data to be transmitted. Many works are proposed to reduce the amount of
data to be transmitted consist of specific compression methods and reduction in
video resolution and frame rate. We proposed a system inside the capsule for
detecting informative frames and sending these frames instead of several
non-informative frames. In this work, we specifically focused on hardware
friendly algorithm (with capability of parallelism and pipeline) for
implementation of polyp detection. Two features of positive contrast and
customized edges of polyps are exploited to define whether the frame consists
of polyp or not. The proposed method is devoid of complex and iterative
structure to save power and reduce the response time. Experimental results
indicate acceptable rate of detection of our work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10252</identifier>
 <datestamp>2018-08-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.10252</id><created>2017-12-29</created><updated>2018-08-23</updated><authors><author><keyname>Meynard</keyname><forenames>Adrien</forenames><affiliation>I2M</affiliation></author><author><keyname>Torr&#xe9;sani</keyname><forenames>Bruno</forenames><affiliation>I2M</affiliation></author></authors><title>Spectral analysis for nonstationary audio</title><categories>eess.AS cs.SD math.ST stat.TH</categories><comments>IEEE/ACM Transactions on Audio, Speech and Language Processing,
  Institute of Electrical and Electronics Engineers, In press</comments><proxy>ccsd</proxy><doi>10.1109/TASLP.2018.2862353</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach for the analysis of nonstationary signals is proposed, with a
focus on audio applications. Following earlier contributions, nonstationarity
is modeled via stationarity-breaking operators acting on Gaussian stationary
random signals. The focus is on time warping and amplitude modulation, and an
approximate maximum-likelihood approach based on suitable approximations in the
wavelet transform domain is developed. This paper provides theoretical analysis
of the approximations, and introduces JEFAS, a corresponding estimation
algorithm. The latter is tested and validated on synthetic as well as real
audio signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.10291</identifier>
 <datestamp>2018-09-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1712.10291</id><created>2017-12-29</created><updated>2018-09-25</updated><authors><author><keyname>Mozaffari</keyname><forenames>Mohammad</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Communications and Control for Wireless Drone-Based Antenna Array</title><categories>eess.SP cs.IT math.IT</categories><comments>accepted in the IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the effective use of multiple quadrotor drones as an aerial
antenna array that provides wireless service to ground users is investigated.
In particular, under the goal of minimizing the airborne service time needed
for communicating with ground users, a novel framework for deploying and
operating a drone-based antenna array system whose elements are single-antenna
drones is proposed. In the considered model, the service time is minimized by
minimizing the wireless transmission time as well as the control time that is
needed for movement and stabilization of the drones. To minimize the
transmission time, first, the antenna array gain is maximized by optimizing the
drone spacing within the array. In this case, using perturbation techniques,
the drone spacing optimization problem is addressed by solving successive,
perturbed convex optimization problems. Then, the optimal locations of the
drones around the array's center are derived such that the transmission time
for the user is minimized. Given the determined optimal locations of drones,
the drones must spend a control time to adjust their positions dynamically so
as to serve multiple users. To minimize this control time of the quadrotor
drones, the speed of rotors is optimally adjusted based on both the
destinations of the drones and external forces (e.g., wind and gravity). In
particular, using bang-bang control theory, the optimal rotors' speeds as well
as the minimum control time are derived in closed-form. Simulation results show
that the proposed approach can significantly reduce the service time to ground
users compared to a fixed-array case in which the same number of drones form a
fixed uniform antenna array. The results also show that, in comparison with the
fixed-array case, the network's spectral efficiency can be improved by 32%
while leveraging the drone antenna array system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00075</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00075</id><created>2017-12-29</created><authors><author><keyname>Lin</keyname><forenames>Shoufeng</forenames></author></authors><title>Logarithmic Frequency Scaling and Consistent Frequency Coverage for the
  Selection of Auditory Filterbank Center Frequencies</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides new insights into the problem of selecting filter center
frequencies for the auditory filterbanks. We propose to use a constant
frequency distance and a consistent frequency coverage as the two metrics that
motivate the logarithmic frequency scaling and a regularized selection of
center frequencies. The frequency scaling and the consistent frequency coverage
have been derived based on a common harmonic speaker signal model. Furthermore,
we have found that the existing linear equivalent rectangular bandwidth (ERB)
function as well as any possible linear ERB approximation can also lead to a
consistent frequency coverage. The results are verified and demonstrated using
the gammatone filterbank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00098</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00098</id><created>2017-12-30</created><updated>2018-01-21</updated><authors><author><keyname>Nnolim</keyname><forenames>U. A.</forenames></author></authors><title>A PDE-based log-agnostic illumination correction algorithm</title><categories>cs.CV eess.IV</categories><comments>22 pages, 9 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report presents the results of a partial differential equation
(PDE)-based image enhancement algorithm, for dynamic range compression and
illumination correction in the absence of the logarithmic function. The
proposed algorithm combines forward and reverse flows in a PDE-based
formulation. The experimental results are compared with algorithms from the
literature and indicate comparable performance in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00148</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00148</id><created>2017-12-30</created><authors><author><keyname>Motmaen</keyname><forenames>Mehran</forenames></author><author><keyname>Mohrekesh</keyname><forenames>Majid</forenames></author><author><keyname>Akbari</keyname><forenames>Mojtaba</forenames></author><author><keyname>Karimi</keyname><forenames>Nader</forenames></author><author><keyname>Samavi</keyname><forenames>Shadrokh</forenames></author></authors><title>Image Inpainting by Hyperbolic Selection of Pixels for Two Dimensional
  Bicubic Interpolations</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image inpainting is a restoration process which has numerous applications.
Restoring of scanned old images with scratches, or removing objects in images
are some of inpainting applications. Different approaches have been used for
implementation of inpainting algorithms. Interpolation approaches only consider
one direction for this purpose. In this paper we present a new perspective to
image inpainting. We consider multiple directions and apply both
one-dimensional and two-dimensional bicubic interpolations. Neighboring pixels
are selected in a hyperbolic formation to better preserve corner pixels. We
compare our work with recent inpainting approaches to show our superior
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00159</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00159</id><created>2017-12-30</created><authors><author><keyname>Aref</keyname><forenames>Vahid</forenames></author><author><keyname>Le</keyname><forenames>Son T.</forenames></author><author><keyname>Buelow</keyname><forenames>Henning</forenames></author></authors><title>Does the Cross-Talk Between Nonlinear Modes Limit the Performance of
  NFDM Systems?</title><categories>eess.SP cs.IT math.IT</categories><comments>Invited paper, European Conference on Optical Communication (ECOC
  2017), Sept. 2017, p. Th.1.D.1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show a non-negligible cross-talk between nonlinear modes in Nonlinear
Frequency-Division Multiplexed system when data is modulated over the nonlinear
Fourier spectrum, both the continuous spectrum and the discrete spectrum, and
transmitted over a lumped amplified fiber link. We evaluate the performance
loss if the cross-talks are neglected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00418</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00418</id><created>2018-01-01</created><authors><author><keyname>Zhang</keyname><forenames>Bo</forenames></author><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Lan</keyname><forenames>Xiang</forenames></author></authors><title>Directional Modulation Design Based on Crossed-Dipole Arrays for Two
  Signals With Orthogonal Polarisations</title><categories>eess.SP cs.IT math.IT</categories><comments>5 pages, 9 figures. The paper has been accepted by EuCAP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Directional modulation (DM) is a physical layer security technique based on
antenna arrays and so far the polarisation information has not been considered
in its designs. To increase the channel capacity, we consider exploiting the
polarisation information and send two different signals simultaneously at the
same direction, same frequency, but with different polarisations. These two
signals can also be considered as one composite signal using the four
dimensional (4-D) modulation scheme across the two polarisation diversity
channels. In this paper, based on cross-dipole arrays, we formulate the design
to find a set of common weight coefficients to achieve directional modulation
for such a composite signal and examples are provided to verify the
effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00484</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00484</id><created>2018-01-01</created><authors><author><keyname>Nosrati</keyname><forenames>Mehrdad</forenames></author><author><keyname>Tavassolian</keyname><forenames>Negar</forenames></author></authors><title>Experimental Evaluation of the Effects of Antenna Radiation
  Characteristics on Heart Rate Monitoring Radar Systems</title><categories>eess.SP</categories><comments>13 pages. This is an extended version of our previously published
  paper (doi: 10.1109/TAP.2017.2694861)</comments><journal-ref>M. Nosrati and N. Tavassolian, &quot;Effects of Antenna Characteristics
  on the Performance of Heart Rate Monitoring Radar Systems,&quot; in IEEE
  Transactions on Antennas and Propagation, vol. 65, no. 6, pp. 3296-3301, June
  2017</journal-ref><doi>10.1109/TAP.2017.2694861</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an experimental study to evaluate the effects of antenna
radiation parameters on the detection capabilities of a 2.4 GHz Doppler radar
used in non-contact heart rate monitoring systems. Four different types of
patch antennas and array configurations were implemented on both the
transmitter and receiver sides. Extensive experiments using a linear actuator
were performed and several interesting and nontrivial results were reported. It
is shown that using a linearly polarized single patch antenna at the
transmitter and a circularly polarized antenna array at the receiver results in
the highest signal quality and system performance. Proof-of-concept experiments
on human subjects further validated the suggested results. It was also shown
that using the recommended antenna arrangement will boost the heart rate
detection accuracy of the radar by an average of 11%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00635</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00635</id><created>2018-01-02</created><authors><author><keyname>Shahdoosti</keyname><forenames>Hamid Reza</forenames></author></authors><title>Image denoising through bivariate shrinkage function in framelet domain</title><categories>eess.IV cs.CV</categories><comments>8 pages, 2 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Denoising of coefficients in a sparse domain (e.g. wavelet) has been
researched extensively because of its simplicity and effectiveness. Literature
mainly has focused on designing the best global threshold. However, this paper
proposes a new denoising method using bivariate shrinkage function in framelet
domain. In the proposed method, maximum aposteriori probability is used for
estimate of the denoised coefficient and non-Gaussian bivariate function is
applied to model the statistics of framelet coefficients. For every framelet
coefficient, there is a corresponding threshold depending on the local
statistics of framelet coefficients. Experimental results show that using
bivariate shrinkage function in framelet domain yields significantly superior
image quality and higher PSNR than some well-known denoising methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00668</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00668</id><created>2018-01-02</created><authors><author><keyname>Zhang</keyname><forenames>Jiashu</forenames></author><author><keyname>Zhang</keyname><forenames>Sheng</forenames></author><author><keyname>Li</keyname><forenames>Defang</forenames></author></authors><title>Random Euler Complex-Valued Nonlinear Filters</title><categories>stat.ML eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last decade, both the neural network and kernel adaptive filter have
successfully been used for nonlinear signal processing. However, they suffer
from high computational cost caused by their complex/growing network
structures. In this paper, we propose two random Euler filters for
complex-valued nonlinear filtering problem, i.e., linear random Euler
complex-valued filter (LRECF) and its widely-linear version (WLRECF), which
possess a simple and fixed network structure. The transient and steady-state
performances are studied in a non-stationary environment. The analytical
minimum mean square error (MSE) and optimum step-size are derived. Finally,
numerical simulations on complex-valued nonlinear system identification and
nonlinear channel equalization are presented to show the effectiveness of the
proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00688</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00688</id><created>2018-01-02</created><authors><author><keyname>Strisciuglio</keyname><forenames>Nicola</forenames></author></authors><title>Learning audio and image representations with bio-inspired trainable
  feature extractors</title><categories>cs.CV cs.AI cs.SD eess.AS eess.IV</categories><comments>Accepted for publication in the journal &quot;Eleectronic Letters on
  Computer Vision and Image Understanding&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advancements in pattern recognition and signal processing concern the
automatic learning of data representations from labeled training samples.
Typical approaches are based on deep learning and convolutional neural
networks, which require large amount of labeled training samples. In this work,
we propose novel feature extractors that can be used to learn the
representation of single prototype samples in an automatic configuration
process. We employ the proposed feature extractors in applications of audio and
image processing, and show their effectiveness on benchmark data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00841</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00841</id><created>2018-01-02</created><authors><author><keyname>Rao</keyname><forenames>Kanishka</forenames></author><author><keyname>Sak</keyname><forenames>Ha&#x15f;im</forenames></author><author><keyname>Prabhavalkar</keyname><forenames>Rohit</forenames></author></authors><title>Exploring Architectures, Data and Units For Streaming End-to-End Speech
  Recognition with RNN-Transducer</title><categories>cs.CL cs.SD eess.AS</categories><comments>In Proceedings of IEEE ASRU 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate training end-to-end speech recognition models with the
recurrent neural network transducer (RNN-T): a streaming, all-neural,
sequence-to-sequence architecture which jointly learns acoustic and language
model components from transcribed acoustic data. We explore various model
architectures and demonstrate how the model can be improved further if
additional text or pronunciation data are available. The model consists of an
`encoder', which is initialized from a connectionist temporal
classification-based (CTC) acoustic model, and a `decoder' which is partially
initialized from a recurrent neural network language model trained on text data
alone. The entire neural network is trained with the RNN-T loss and directly
outputs the recognized transcript as a sequence of graphemes, thus performing
end-to-end speech recognition. We find that performance can be improved further
through the use of sub-word units (`wordpieces') which capture longer context
and significantly reduce substitution errors. The best RNN-T system, a
twelve-layer LSTM encoder with a two-layer LSTM decoder trained with 30,000
wordpieces as output targets achieves a word error rate of 8.5\% on
voice-search and 5.2\% on voice-dictation tasks and is comparable to a
state-of-the-art baseline at 8.3\% on voice-search and 5.4\% voice-dictation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00887</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00887</id><created>2018-01-02</created><authors><author><keyname>Mao</keyname><forenames>Huanru Henry</forenames></author><author><keyname>Shin</keyname><forenames>Taylor</forenames></author><author><keyname>Cottrell</keyname><forenames>Garrison W.</forenames></author></authors><title>DeepJ: Style-Specific Music Generation</title><categories>cs.SD eess.AS</categories><doi>10.1109/ICSC.2018.00077</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in deep neural networks have enabled algorithms to compose
music that is comparable to music composed by humans. However, few algorithms
allow the user to generate music with tunable parameters. The ability to tune
properties of generated music will yield more practical benefits for aiding
artists, filmmakers, and composers in their creative tasks. In this paper, we
introduce DeepJ - an end-to-end generative model that is capable of composing
music conditioned on a specific mixture of composer styles. Our innovations
include methods to learn musical style and music dynamics. We use our model to
demonstrate a simple technique for controlling the style of generated music as
a proof of concept. Evaluation of our model using human raters shows that we
have improved over the Biaxial LSTM approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.00907</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.00907</id><created>2018-01-03</created><authors><author><keyname>Hasan</keyname><forenames>Abu Shahir Md. Khalid</forenames></author><author><keyname>Chowdhury</keyname><forenames>Dhiman</forenames></author><author><keyname>Khan</keyname><forenames>Mohammad Ziaur Rahman</forenames></author></authors><title>Performance Analysis of a Scalable DC Microgrid Offering Solar Power
  Based Energy Access and Efficient Control for Domestic Loads</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  DC microgrids conform to distributed control of renewable energy sources
which ratifies efficacious instantaneous power sharing and sustenance of energy
access among different domestic Power Management Units (PMUs) along with
maintaining stability of the grid voltage. In this paper design metrics and
performance evaluation of a scalable DC microgrid are documented where a
look-up table of generated power of a source converter complies with the
distribution of efficient power sharing phenomenon among a set of two home
PMUs. The source converter is connected with a Photovoltaic panel of 300 W and
uses Perturb and Observation (P&amp;O) method for executing Maximum Power Point
Tracking (MPPT). A boost average DCDC converter topology is used to enhance the
voltage level of the source converter before transmission. The load converter
consists of two parallely connected PMUs each of which is constructed with high
switching frequency based Full Bridge (FB) converter to charge an integrated
Energy Storage System (ESS). In this paper the overall system is modeled and
simulated on MATLAB/Simulink platform with ESSs in the form of Lead Acid
batteries connected to the load side of the FB converter circuits and these
batteries yield to support marginalized power utilities. The behaviour of the
system is tested in different solar insolation levels along with several
battery charging levels of 12 V and 36 V to assess the power efficiency. In
each testbed the efficiency is found to be more than 93% which affirm the
reliability of the framework and a look-up table is generated comprising the
grid and load quantities for effective control of power transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01111</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01111</id><created>2018-01-03</created><authors><author><keyname>Quadri</keyname><forenames>Adnan</forenames></author></authors><title>A Review of Noise Cancellation Techniques for Cognitive Radio</title><categories>eess.SP</categories><comments>10 pages, 2 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the fundamental challenges affecting the performance of communication
systems is the undesired impact of noise on a signal. Noise distorts the signal
and originates due to several sources including, system non-linearity and noise
interference from adjacent environment. Conventional communication systems use
filters to cancel noise in a received signal. In the case of cognitive radio
systems, denoising a signal is important during the spectrum sensing period,
and also during communication with other network nodes. Based on our findings,
few surveys are found that only review particular denoising techniques employed
for the spectrum sensing phase of cognitive radio communication. This paper
aims to provide a collective review of denoising techniques that can be applied
to a cognitive radio system during all the phases of cognitive communication
and discusses several works where the denoising techniques are employed. To
establish comprehensive overview, a performance comparison of the discussed
denoising techniques are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01121</identifier>
 <datestamp>2018-10-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01121</id><created>2018-01-03</created><updated>2018-10-19</updated><authors><author><keyname>Timmel</keyname><forenames>Abigail</forenames></author><author><keyname>Daly</keyname><forenames>John</forenames></author></authors><title>Multiplication with Fourier Optics Simulating 16-bit Modular
  Multiplication</title><categories>eess.IV eess.SP</categories><comments>Added IEEE copyright notice</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper will describe a simulator developed by the authors to explore the
design of Fourier transform based multiplication using optics. Then it will
demonstrate an application to the problem of constructing an all-optical
modular multiplication circuit. That circuit implements a novel approximate
version of the Montgomery multiplication algorithm that enables the calculation
to be performed entirely in the analog domain. The results will be used to
corroborate the feasibility of scaling the design up to 16-bits without the
need for analog to digital conversions at intermediate steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01150</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01150</id><created>2018-01-03</created><authors><author><keyname>Zhang</keyname><forenames>S.</forenames></author><author><keyname>Chang</keyname><forenames>D.</forenames></author><author><keyname>Dobre</keyname><forenames>O. A.</forenames></author><author><keyname>Omomukuyo</keyname><forenames>O.</forenames></author><author><keyname>Lin</keyname><forenames>X.</forenames></author><author><keyname>Venkatesan</keyname><forenames>R.</forenames></author></authors><title>Training Symbol-Based Equalization for Quadrature Duobinary PDM-FTN
  Systems</title><categories>eess.SP</categories><journal-ref>Photonics Technology Letters, vol.29 (5), 2017</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A training symbol-based equalization algorithm is proposed for polarization
de-multiplexing in quadrature duobinary (QDB) modulated polarization division
multiplexedfaster-than-Nyquist (FTN) coherent optical systems. The proposed
algorithm is based on the least mean square algorithm, and multiple location
candidates of a symbol are considered in order to make use of the training
symbols with QDB modulation.Results show that an excellent convergence
performance is obtained using the proposed algorithm under different
polarization alignment scenarios. The optical signal-to-noise ratio required to
attain a bit error rate of 2*10-2 is reduced by 1.7 and 1.8 dB using the
proposed algorithm, compared to systems using the constant modulus algorithm
with differential coding for 4-ary quadrature amplitude modulation(4-QAM) and
16-QAM systems with symbol-by-symbol detection, respectively.Furthermore,
comparisons with the Tomlinson-Harashima precoding-based FTN systems illustrate
that QDB is preferable when 4-QAM is utilized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01156</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01156</id><created>2018-01-03</created><authors><author><keyname>Mohammadkhani</keyname><forenames>S.</forenames></author><author><keyname>Jafari</keyname><forenames>A. H.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>G. K.</forenames></author></authors><title>Robust Tomlinson-Harashima Precoding for Two-Way Relaying</title><categories>eess.SP</categories><comments>15 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the non-linear transceivers, which are based on Tomlinson Harashima
(TH) precoding and have been proposed in the literature for two-way relay
networks, assume perfect channel state information (CSI). In this paper, we
propose a novel and robust TH precoding scheme for two-way relay networks with
multiple antennas at the transceiver and the relay nodes. We assume imperfect
CSI and that the channel uncertainty is bounded by a spherical region.
Furthermore, we consider the sum of the mean square error as the objective
function, under a limited power constraint for transceiver and relay nodes.
Simulations are provided to evaluate the performance and to validate the
efficiency of the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01212</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01212</id><created>2018-01-03</created><authors><author><keyname>Lin</keyname><forenames>Xiang</forenames></author><author><keyname>Eldemerdash</keyname><forenames>Yahia A.</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Zhang</keyname><forenames>Shu</forenames></author><author><keyname>Li</keyname><forenames>Cheng</forenames></author></authors><title>Modulation Classification Using Received Signal's Amplitude Distribution
  for Coherent Receivers</title><categories>eess.SP</categories><doi>10.1109/LPT.2017.2754501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we propose a modulation classification algorithm which is
based on the received signal's amplitude for coherent optical receivers. The
proposed algorithm classifies the modulation format from several possible
candidates by differentiating the cumulative distribution function (CDF) curves
of their normalized amplitudes. The candidate with the most similar CDF to the
received signal is selected. The measure of similarity is the minimum average
distance between these CDFs. Five commonly used quadrature amplitude modulation
formats in digital coherent optical systems are employed. Optical back-to-back
experiments and extended simulations are carried out to investigate the
performance of the proposed algorithm. Results show that the proposed algorithm
achieves accurate classification at optical signal-to-noise ratios of interest.
Furthermore, it does not require carrier recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01237</identifier>
 <datestamp>2019-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01237</id><created>2018-01-03</created><updated>2019-10-30</updated><authors><author><keyname>Lian</keyname><forenames>Zheng</forenames></author><author><keyname>Li</keyname><forenames>Ya</forenames></author><author><keyname>Tao</keyname><forenames>Jianhua</forenames></author><author><keyname>Huang</keyname><forenames>Jian</forenames></author></authors><title>A pairwise discriminative task for speech emotion recognition</title><categories>cs.HC cs.SD eess.AS</categories><comments>I have submitted a new version to arXiv:1910.11174. I forget to
  choose to replace the old version, but submitted a new one. It's my mistake</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I have submitted a new version to arXiv:1910.11174. I forget to choose to
replace the old version, but submitted a new one. It's my mistake.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01242</identifier>
 <datestamp>2018-07-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01242</id><created>2018-01-03</created><updated>2018-07-06</updated><authors><author><keyname>Dahlin</keyname><forenames>Johan</forenames></author><author><keyname>Wills</keyname><forenames>Adrian</forenames></author><author><keyname>Ninness</keyname><forenames>Brett</forenames></author></authors><title>Sparse Bayesian ARX models with flexible noise distributions</title><categories>stat.ME eess.SP stat.AP</categories><comments>17 pages, 4 figures. Accepted for publication in the Proceedings of
  the 18th IFAC Symposium on System Identification (SYSID). Typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of estimating linear dynamic system models
when the observations are corrupted by random disturbances with nonstandard
distributions. The paper is particularly motivated by applications where sensor
imperfections involve significant contribution of outliers or wrap-around
issues resulting in multi-modal distributions such as commonly encountered in
robotics applications. As will be illustrated, these nonstandard measurement
errors can dramatically compromise the effectiveness of standard estimation
methods, while a computational Bayesian approach developed here is demonstrated
to be equally effective as standard methods in standard measurement noise
scenarios, but dramatically more effective in nonstandard measurement noise
distribution scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01270</identifier>
 <datestamp>2018-08-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01270</id><created>2018-01-04</created><updated>2018-08-23</updated><authors><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author><author><keyname>Debbah</keyname><forenames>M&#xe9;rouane</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Ultra-Reliable and Low-Latency Wireless Communication: Tail, Risk and
  Scale</title><categories>cs.IT eess.SP math.IT</categories><comments>27 pages, Proceedings of the IEEE (in press), October 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensuring ultra-reliable and low-latency communication (URLLC) for 5G wireless
networks and beyond is of capital importance and is currently receiving
tremendous attention in academia and industry. At its core, URLLC mandates a
departure from expected utility-based network design approaches, in which
relying on average quantities (e.g., average throughput, average delay and
average response time) is no longer an option but a necessity. Instead, a
principled and scalable framework which takes into account delay, reliability,
packet size, network architecture, and topology (across access, edge, and core)
and decision-making under uncertainty is sorely lacking. The overarching goal
of this article is a first step to fill this void. Towards this vision, after
providing definitions of latency and reliability, we closely examine various
enablers of URLLC and their inherent tradeoffs. Subsequently, we focus our
attention on a plethora of techniques and methodologies pertaining to the
requirements of ultra-reliable and low-latency communication, as well as their
applications through selected use cases. These results provide crisp insights
for the design of low-latency and high-reliable wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01353</identifier>
 <datestamp>2019-12-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01353</id><created>2018-01-04</created><updated>2019-12-06</updated><authors><author><keyname>Xia</keyname><forenames>Yuxuan</forenames></author><author><keyname>Granstr&#xf6;m</keyname><forenames>Karl</forenames></author><author><keyname>Svensson</keyname><forenames>Lennart</forenames></author><author><keyname>Fatemi</keyname><forenames>Maryam</forenames></author></authors><title>Extended Target Poisson Multi-Bernoulli Filter</title><categories>eess.SP</categories><comments>17 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a Poisson multi-Bernoulli (PMB) filter for multiple
extended targets estimation. The extended target PMB filter is based on the
Poisson multi-Bernoulli mixture (PMBM) conjugate prior for multiple extended
target filtering and approximates the multi-Bernoulli (MB) mixture in the
posterior density as a single MB. Because both the prediction and the update
preserve the PMB form of the density, the proposed PMB filter is
computationally cheaper than the PMBM filter while maintaining good filtering
performance. Different methods for merging the MB mixture as a single MB are
presented, along with their Gamma Gaussian inverse Wishart implementations. The
performance of the extended target PMB filter is compared to the extended
target PMBM filter and the extended target labelled MB filter in a thorough
simulation study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01433</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01433</id><created>2018-01-04</created><authors><author><keyname>Chang</keyname><forenames>Deyuan</forenames></author><author><keyname>Omomukuyo</keyname><forenames>Oluyemi</forenames></author><author><keyname>Lin</keyname><forenames>Xiang</forenames></author><author><keyname>Zhang</keyname><forenames>Shu</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramachandran</forenames></author></authors><title>Robust Faster-than-Nyquist PDM-mQAM Systems with Tomlinson-Harashima
  Precoding</title><categories>eess.SP</categories><doi>10.1109/LPT.2016.2573740</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A training-based channel estimation algorithm is proposed for the
faster-than-Nyquist PDM-mQAM (m = 4, 16, 64) systems with Tomlinson-Harashima
precoding (THP). This is robust to the convergence failure phenomenon suffered
by the existing algorithm, yet remaining format-transparent. Simulation results
show that the proposed algorithm requires a reduced optical signal-to-noise
ratio (OSNR) to achieve a certain bit error rate (BER) in the presence of
first-order polarization mode dispersion and phase noise introduced by the
laser linewidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01443</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01443</id><created>2017-12-03</created><authors><author><keyname>Cordeiro</keyname><forenames>Filipe Rolim</forenames></author><author><keyname>Santos</keyname><forenames>Wellington Pinheiro dos</forenames></author><author><keyname>Filho</keyname><forenames>Abel Guilhermino da Silva</forenames></author></authors><title>A semi-supervised fuzzy GrowCut algorithm to segment and classify
  regions of interest of mammographic images</title><categories>cs.CV cs.AI cs.IR cs.NE eess.IV</categories><journal-ref>Expert Systems With Applications, 65 (2016), 116-126</journal-ref><doi>10.1016/j.eswa.2016.08.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to the World Health Organization, breast cancer is the most common
form of cancer in women. It is the second leading cause of death among women
round the world, becoming the most fatal form of cancer. Mammographic image
segmentation is a fundamental task to support image analysis and diagnosis,
taking into account shape analysis of mammary lesions and their borders.
However, mammogram segmentation is a very hard process, once it is highly
dependent on the types of mammary tissues. In this work we present a new
semi-supervised segmentation algorithm based on the modification of the GrowCut
algorithm to perform automatic mammographic image segmentation once a region of
interest is selected by a specialist. In our proposal, we used fuzzy Gaussian
membership functions to modify the evolution rule of the original GrowCut
algorithm, in order to estimate the uncertainty of a pixel being object or
background. The main impact of the proposed method is the significant reduction
of expert effort in the initialization of seed points of GrowCut to perform
accurate segmentation, once it removes the need of selection of background
seeds. We also constructed an automatic point selection process based on the
simulated annealing optimization method, avoiding the need of human
intervention. The proposed approach was qualitatively compared with other
state-of-the-art segmentation techniques, considering the shape of segmented
regions. In order to validate our proposal, we built an image classifier using
a classical multilayer perceptron. We used Zernike moments to extract segmented
image features. This analysis employed 685 mammograms from IRMA breast cancer
database, using fat and fibroid tissues. Results show that the proposed
technique could achieve a classification rate of 91.28\% for fat tissues,
evidencing the feasibility of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01535</identifier>
 <datestamp>2018-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01535</id><created>2018-01-04</created><updated>2018-02-22</updated><authors><author><keyname>Zhao</keyname><forenames>Zhongyang</forenames></author><author><keyname>Fu</keyname><forenames>Chang</forenames></author><author><keyname>Wang</keyname><forenames>Caisheng</forenames></author><author><keyname>Miller</keyname><forenames>Carol</forenames></author></authors><title>Improvement to the Prediction of Fuel Cost Distributions Using ARIMA
  Model</title><categories>stat.AP eess.SP</categories><comments>Accepted by IEEE PES 2018 General Meeting</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Availability of a validated, realistic fuel cost model is a prerequisite to
the development and validation of new optimization methods and control tools.
This paper uses an autoregressive integrated moving average (ARIMA) model with
historical fuel cost data in development of a three-step-ahead fuel cost
distribution prediction. First, the data features of Form EIA-923 are explored
and the natural gas fuel costs of Texas generating facilities are used to
develop and validate the forecasting algorithm for the Texas example.
Furthermore, the spot price associated with the natural gas hub in Texas is
utilized to enhance the fuel cost prediction. The forecasted data is fit to a
normal distribution and the Kullback-Leibler divergence is employed to evaluate
the difference between the real fuel cost distributions and the estimated
distributions. The comparative evaluation suggests the proposed forecasting
algorithm is effective in general and is worth pursuing further.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01548</identifier>
 <datestamp>2019-01-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01548</id><created>2018-01-04</created><updated>2018-01-07</updated><authors><author><keyname>Lu</keyname><forenames>Ruochen</forenames></author><author><keyname>Krol</keyname><forenames>John</forenames></author><author><keyname>Gao</keyname><forenames>Liuqing</forenames></author><author><keyname>Gong</keyname><forenames>Songbin</forenames></author></authors><title>Frequency Independent Framework for Synthesis of Programmable
  Non-reciprocal Networks</title><categories>eess.SP</categories><comments>10 pages, 6 figures</comments><journal-ref>Scientific Reports 8, 14655 (2018)</journal-ref><doi>10.1038/s41598-018-32898-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Passive and linear nonreciprocal networks at microwave frequencies hold great
promises in enabling new front-end architectures for wireless communication
systems. Their nonreciprocity has been achieved by disrupting the time-reversal
symmetry using various forms of biasing schemes, but only over a limited
frequency range. Here we demonstrate a framework for synthesizing theoretically
frequency-independent multi-port nonreciprocal networks. The framework is
highly expandable, and can have an arbitrary number of ports while
simultaneously sustaining balanced performance and providing unprecedented
programmability of non-reciprocity. A 4-port circulator based on such a
framework is implemented and tested to produce broadband nonreciprocal
performance from 10 MHz to 900 MHz with a temporal switching effort at 23.8
MHz. With the combination of broad bandwidth, low temporal effort, and high
programmability, the framework could inspire new ways of implementing multiple
input multiple output (MIMO) communication systems for 5G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01589</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01589</id><created>2018-01-04</created><authors><author><keyname>Verma</keyname><forenames>Prateek</forenames></author><author><keyname>Smith</keyname><forenames>Julius O.</forenames></author></authors><title>Neural Style Transfer for Audio Spectograms</title><categories>cs.SD cs.MM eess.AS</categories><comments>Appeared in 31st Conference on Neural Information Processing Systems
  (NIPS 2017), Long Beach, CA, USA at the workshop for Machine Learning for
  Creativity and Design</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been fascinating work on creating artistic transformations of
images by Gatys. This was revolutionary in how we can in some sense alter the
'style' of an image while generally preserving its 'content'. In our work, we
present a method for creating new sounds using a similar approach, treating it
as a style-transfer problem, starting from a random-noise input signal and
iteratively using back-propagation to optimize the sound to conform to
filter-outputs from a pre-trained neural architecture of interest.
  For demonstration, we investigate two different tasks, resulting in bandwidth
expansion/compression, and timbral transfer from singing voice to musical
instruments. A feature of our method is that a single architecture can generate
these different audio-style-transfer types using the same set of parameters
which otherwise require different complex hand-tuned diverse signal processing
pipelines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01598</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01598</id><created>2018-01-04</created><authors><author><keyname>Omomukuyo</keyname><forenames>Oluyemi</forenames></author><author><keyname>Zhang</keyname><forenames>Shu</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramachandran</forenames></author><author><keyname>Ngatched</keyname><forenames>Telex M. N.</forenames></author></authors><title>Discrete FRFT-Based Frame and Frequency Synchronization for Coherent
  Optical Systems</title><categories>eess.SP</categories><comments>4 pages, 5 figures, Journal</comments><journal-ref>IEEE Photonics Technology Letters, vol. 29, no. 23, pp. 2016-2019,
  Dec. 2017</journal-ref><doi>10.1109/LPT.2017.2759584</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A joint frame and carrier frequency synchronization algorithm for coherent
optical systems, based on the digital computation of the fractional Fourier
transform (FRFT), is proposed. The algorithm utilizes the characteristics of
energy centralization of chirp signals in the FRFT domain, together with the
time and phase shift properties of the FRFT. Chirp signals are used to
construct a training sequence (TS), and fractional cross-correlation is
employed to define a detection metric for the TS, from which a set of equations
can be obtained. Estimates of both the timing offset and carrier frequency
offset (CFO) are obtained by solving these equations. This TS is later employed
in a phase-dependent decision-directed least-mean square algorithm for adaptive
equalization. Simulation results of a 32-Gbaud coherent polarization division
multiplexed Nyquist system show that the proposed scheme has a wide CFO
estimation range and accurate synchronization performance even in poor optical
signal-to-noise ratio conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01599</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01599</id><created>2018-01-04</created><authors><author><keyname>Omomukuyo</keyname><forenames>Oluyemi</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramachandran</forenames></author><author><keyname>Ngatched</keyname><forenames>Telex M. N.</forenames></author></authors><title>Bandwidth-Efficient Synchronization for Fiber Optic Transmission: System
  Performance Measurements</title><categories>eess.SP</categories><comments>13 pages, 5 figures, Magazine article</comments><journal-ref>IEEE IMM Magazine, vol. 20, no. 5, pp. 39-45, Oct. 2017</journal-ref><doi>10.1109/MIM.2017.8036697</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we first provide a brief overview of optical transmission
systems and some of their performance specifications. We then present a simple,
robust, and bandwidth-efficient OFDM synchronization method, and carry out
measurements to validate the presented synchronization method with the aid of
an experimental setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01600</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01600</id><created>2018-01-04</created><authors><author><keyname>Omomukuyo</keyname><forenames>Oluyemi</forenames></author><author><keyname>Chang</keyname><forenames>Deyuan</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramachandran</forenames></author><author><keyname>Ngatched</keyname><forenames>Telex M. N.</forenames></author></authors><title>Robust Frame and Frequency Synchronization Based on Alamouti Coding for
  RGI-CO-OFDM</title><categories>eess.SP</categories><comments>4 pages, 3 figures, Journal</comments><journal-ref>IEEE Photonics Technology Letters, vol. 28, no. 24, pp. 2783-2786,
  Dec. 2016</journal-ref><doi>10.1109/LPT.2016.2623322</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an algorithm for carrying out joint frame and frequency
synchronization in reduced-guard-interval coherent optical orthogonal frequency
division multiplexing (RGI-CO-OFDM) systems. The synchronization is achieved by
using the same training symbols (TS) employed for training-aided channel
estimation (TA-CE), thereby avoiding additional training overhead. The proposed
algorithm is designed for polarization division multiplexing (PDM) RGI-CO-OFDM
systems that use the Alamouti-type polarization-time coding for TA-CE. Due to
their optimal TA-CE performance, Golay complementary sequences have been used
as the TS in the proposed algorithm. The frame synchronization is accomplished
by exploiting the cross-correlation between the received TS from the two
orthogonal polarizations. The arrangement of the TS is also used to estimate
the carrier frequency offset. Simulation results of a PDM RGI-CO-OFDM system
operating at 238.1 Gb/s data rate (197.6-Gb/s after coding), with a total
overhead of 9.2% (31.6% after coding), show that the proposed scheme has
accurate synchronization, and is robust to linear fiber impairments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01601</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01601</id><created>2018-01-04</created><authors><author><keyname>Omomukuyo</keyname><forenames>Oluyemi</forenames></author><author><keyname>Chang</keyname><forenames>Deyuan</forenames></author><author><keyname>Zhu</keyname><forenames>Jingwen</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramachandran</forenames></author><author><keyname>Ngatched</keyname><forenames>Telex</forenames></author><author><keyname>Rumbolt</keyname><forenames>Chuck</forenames></author></authors><title>Joint timing and frequency synchronization based on weighted CAZAC
  sequences for reduced-guard-interval CO-OFDM systems</title><categories>eess.SP</categories><comments>13 pages, 9 figures, Journal</comments><journal-ref>Opt. Express., vol. 23, no. 5, pp. 5777-5788, Mar. 2015</journal-ref><doi>10.1364/OE.23.005777</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel joint symbol timing and carrier frequency offset (CFO) estimation
algorithm is proposed for reduced-guard-interval coherent optical orthogonal
frequency-division multiplexing (RGI-CO-OFDM) systems. The proposed algorithm
is based on a constant amplitude zero autocorrelation (CAZAC) sequence weighted
by a pseudo-random noise (PN) sequence. The symbol timing is accomplished by
using only one training symbol of two identical halves, with the weighting
applied to the second half. The special structure of the training symbol is
also utilized in estimating the CFO. The performance of the proposed algorithm
is demonstrated by means of numerical simulations in a 115.8-Gb/s 16-QAM
RGI-CO-OFDM system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01603</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01603</id><created>2018-01-04</created><authors><author><keyname>Omomukuyo</keyname><forenames>Oluyemi</forenames></author><author><keyname>Chang</keyname><forenames>Deyuan</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramachandran</forenames></author><author><keyname>Ngatched</keyname><forenames>Telex M. N.</forenames></author></authors><title>Simple sampling clock synchronisation scheme for reduced-guard-interval
  coherent optical OFDM systems</title><categories>eess.SP</categories><comments>2 pages, 5 figures, Journal</comments><journal-ref>Electronics Letters, vol. 51, no. 24, pp. 2026-2028, Nov. 2015</journal-ref><doi>10.1049/el.2015.3064</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple data-aided scheme for sampling clock synchronisation in
reduced-guard-interval coherent optical orthogonal frequency division
multiplexing (RGI-CO-OFDM) systems is proposed. In the proposed scheme, the
sampling clock offset (SCO) is estimated by using the training symbols reserved
for channel estimation, thus avoiding extra training overhead. The SCO is then
compensated by resampling, using a time-domain interpolation filter. The
feasibility of the proposed scheme is demonstrated by means of numerical
simulations in a 32-Gbaud 16-QAM dual-polarisation RGI-CO-OFDM system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01625</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01625</id><created>2018-01-04</created><authors><author><keyname>Zhang</keyname><forenames>Yuhao</forenames></author><author><keyname>Cui</keyname><forenames>Qimei</forenames></author><author><keyname>Wang</keyname><forenames>Ning</forenames></author></authors><title>Optimal Pilot Symbols Ratio in terms of Spectrum and Energy Efficiency
  in Uplink CoMP Networks</title><categories>cs.IT eess.SP math.IT</categories><comments>5 pages, 3 figures, 2017 IEEE 85th Vehicular Technology Conference
  (VTC Spring)</comments><journal-ref>2017 IEEE 85th Vehicular Technology Conference (VTC Spring),
  Sydney, NSW, 2017, pp. 1-5</journal-ref><doi>10.1109/VTCSpring.2017.8108353</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless networks, Spectrum Efficiency (SE) and Energy Efficiency (EE) can
be affected by the channel estimation that needs to be well designed in
practice. In this paper, considering channel estimation error and non-ideal
backhaul links, we optimize the pilot symbols ratio in terms of SE and EE in
uplink Coordinated Multi-point (CoMP) networks. Modeling the channel estimation
error, we formulate the SE and EE maximization problems by analyzing the system
capacity with imperfect channel estimation. The maximal system capacity in SE
optimization and the minimal transmit power in EE optimization, which both have
the closed-form expressions, are derived by some reasonable approximations to
reduce the complexity of solving complicated equations. Simulations are carried
out to validate the superiority of our scheme, verify the accuracy of our
approximation, and show the effect of pilot symbols ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01656</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01656</id><created>2018-01-05</created><authors><author><keyname>Khawaja</keyname><forenames>Wahab</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Matolak</keyname><forenames>David</forenames></author><author><keyname>Fiebig</keyname><forenames>Uwe-Carsten</forenames></author><author><keyname>Schneckenberger</keyname><forenames>Nicolas</forenames></author></authors><title>A Survey of Air-to-Ground Propagation Channel Modeling for Unmanned
  Aerial Vehicles</title><categories>eess.SP</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In recent years, there has been a dramatic increase in the use of unmanned
aerial vehicles (UAVs), particularly for small UAVs, due to their affordable
prices, ease of availability, and ease of operability. Existing and future
applications of UAVs include remote surveillance and monitoring, relief
operations, package delivery, and communication backhaul infrastructure.
Additionally, UAVs are envisioned as an important component of 5G wireless
technology and beyond. The unique application scenarios for UAVs necessitate
accurate air-to-ground (AG) propagation channel models for designing and
evaluating UAV communication links for control/non-payload as well as payload
data transmissions. These AG propagation models have not been investigated in
detail when compared to terrestrial propagation models. In this paper, a
comprehensive survey is provided on available AG channel measurement campaigns,
large and small scale fading channel models, their limitations, and future
research directions for UAV communication scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01695</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01695</id><created>2018-01-05</created><authors><author><keyname>Popescu-Bodorin</keyname><forenames>Nicolaie</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author><author><keyname>Grigore</keyname><forenames>Lucian Stefanita</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author><author><keyname>Balas</keyname><forenames>Valentina Emilia</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author><author><keyname>Noaica</keyname><forenames>Cristina Madalina</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author><author><keyname>Axenie</keyname><forenames>Ionut</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author><author><keyname>Popa</keyname><forenames>Justinian</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author><author><keyname>Munteanu</keyname><forenames>Cristian</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author><author><keyname>Stroescu</keyname><forenames>Victor</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author><author><keyname>Manu</keyname><forenames>Ionut</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author><author><keyname>Herea</keyname><forenames>Alexandru</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author><author><keyname>Horasanli</keyname><forenames>Kartal</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author><author><keyname>Motoc</keyname><forenames>Iulia Maria</forenames><affiliation>ACSTL Cross-Sensor Comparison Competition Team 2013</affiliation></author></authors><title>Cross-Sensor Iris Recognition: LG4000-to-LG2200 Comparison</title><categories>eess.IV cs.CV</categories><comments>Pages: 18; Figures: 21; Iris Codes Comparisons: O(1E9); Results
  obtained by `ACSTL Cross-Sensor Comparison Competition Team 2013` during the
  Cross-Sensor Comparison Competition 2013 organized within the IEEE-BTAS-2013
  Conference</comments><report-no>Technical Report 460 / 24-07-2013, Rev. No. 4 / 30-09-2013,
  University of South-East Europe Lumina, Bucharest, ROMANIA</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cross-sensor comparison experimental results reported here show that the
procedure defined and simulated during the Cross-Sensor Comparison Competition
2013 by our team for migrating / upgrading LG2200 based to LG4000 based
biometric systems leads to better LG4000-to-LG2200 cross-sensor iris
recognition results than previously reported, both in terms of user comfort and
in terms of system safety. On the other hand, LG2200-to-LG400 migration/upgrade
procedure defined and implemented by us is applicable to solve interoperability
issues between LG2200 based and LG4000 based systems, but also to other pairs
of systems having the same shift in the quality of acquired images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01712</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01712</id><created>2018-01-05</created><authors><author><keyname>Deolekar</keyname><forenames>Subodh</forenames></author><author><keyname>Abraham</keyname><forenames>Siby</forenames></author></authors><title>Tree based classification of tabla strokes</title><categories>cs.SD cs.IR eess.AS</categories><comments>14 pages, 11 figures, current science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper attempts to validate the effectiveness of tree classifiers to
classify tabla strokes especially the ones which are overlapping in nature. It
uses decision tree, ID3 and random forest as classifiers. A custom made data
sets of 650 samples of 13 different tabla strokes were used for experimental
purpose. 31 different features with their mean and variances were extracted for
classification. Three data sets consisting of 21361, 18802 and 19543 instances
respectively were used for the purpose. Validation has been done using measures
like ROC curve and accuracy. The experimental results showed that all the
classifiers showing excellent results with random forest outperforming the
other two. The effectiveness of random forest in classifying strokes which are
overlapping in nature is done by comparing the known results of that with
multi-layer perceptron.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01717</identifier>
 <datestamp>2018-11-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01717</id><created>2018-01-05</created><updated>2018-10-29</updated><authors><author><keyname>Shi</keyname><forenames>Long</forenames></author><author><keyname>Zhao</keyname><forenames>Haiquan</forenames></author></authors><title>Diffusion Leaky Zero Attracting Least Mean Square Algorithm and Its
  Performance Analysis</title><categories>eess.SP</categories><journal-ref>IEEE Access. 6 (2018) 56911-56923</journal-ref><doi>10.1109/ACCESS.2018.2871555</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the leaky diffusion least-mean-square (DLMS) algorithm has obtained
much attention because of its good performance for high input eigenvalue spread
and low signal-to-noise ratio (SNR). However, the leaky DLMS algorithm may
suffer from performance deterioration in the sparse system. To overcome this
drawback, the leaky zero attracting DLMS (LZA-DLMS) algorithm is developed in
this paper, which adds an l1-norm penalty to the cost function to exploit the
property of sparse system. The leaky reweighted zero attracting DLMS
(LRZA-DLMS) algorithm is also put forward, which can improve the estimation
performance in the presence of time-varying sparsity. Instead of using the
l1-norm penalty, in the reweighted version, a log-sum function is employed as
the substitution. Based on the weight error variance relation and several
common assumptions, we analyze the transient behavior of our findings and
determine the stability bound of the step-size. Moreover, we implement the
steady state theoretical analysis for the proposed algorithms. Simulations in
the context of distributed network system identification illustrate that the
proposed schemes outperform various existing algorithms and validate the
accuracy of the theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01763</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01763</id><created>2018-01-03</created><authors><author><keyname>Belakaria</keyname><forenames>Syrine</forenames></author><author><keyname>Ammous</keyname><forenames>Mustafa</forenames></author><author><keyname>Sorour</keyname><forenames>Sameh</forenames></author><author><keyname>Abdel-Rahim</keyname><forenames>Ahmed</forenames></author></authors><title>Optimal Vehicle Dimensioning for Multi-Class Autonomous Electric
  Mobility On-Demand Systems</title><categories>cs.SY eess.SP</categories><comments>8 pages, 5 figure, Conference. arXiv admin note: text overlap with
  arXiv:1705.03070</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous electric mobility on demand (AEMoD) has recently emerged as a
cyber-physical system aiming to bring automation, electrification, and
on-demand services for the future private transportation market. The expected
massive demand for such services and its resulting insufficient charging
time/resources prohibit the use of centralized management and full vehicle
charging. A fog-based multi-class solution for these challenges was recently
suggested, by enabling per-zone management and partial charging for different
classes of AEMoD vehicles. This paper focuses on finding the optimal vehicle
dimensioning for each zone of these systems in order to guarantee a bounded
response time of its vehicles. Using a queuing model representing the
multi-class charging and dispatching processes, we first derive the stability
conditions and the number of system classes to guarantee the response time
bound. Decisions on the proportions of each class vehicles to partially/fully
charge, or directly serve customers are then optimized so as to minimize the
vehicles in-flow to any given zone. Excess waiting times of customers in rare
critical events, such as limited charging resources and/or limited vehicles
availabilities, are also investigated. Results show the merits of our proposed
model compared to other schemes and in usual and critical scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01876</identifier>
 <datestamp>2018-11-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01876</id><created>2018-01-06</created><updated>2018-11-22</updated><authors><author><keyname>Sun</keyname><forenames>Yi</forenames></author></authors><title>Root Mean Square Minimum Distance as a Quality Metric for Localization
  Nanoscopy Images</title><categories>q-bio.QM eess.IV</categories><comments>11 pages, 5 figures</comments><journal-ref>Y. Sun, &quot;Root mean square minimum distance as a quality metric for
  stochastic optical localization nanoscopy images,&quot; Scientific Reports, 8(1),
  Nov. 21, 2018</journal-ref><doi>10.1038/s41598-018-35053-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A localization algorithm in stochastic optical localization nanoscopy plays
an important role in obtaining a high-quality image. A universal and objective
metric is crucial and necessary to evaluate qualities of nanoscopy images and
performances of localization algorithms. In this paper, we propose root mean
square minimum distance (RMSMD) as a quality metric for localization nanoscopy
images. RMSMD measures an average, local, and mutual fitness between two sets
of points. Its properties common to a distance metric as well as unique to
itself are presented. The ambiguity, discontinuity, and inappropriateness of
the metrics of accuracy, precision, recall, and Jaccard index, which are
currently used in the literature, are analyzed. A numerical example
demonstrates the advantages of RMSMD over the four existing metrics that fail
to distinguish qualities of different nanoscopy images in certain conditions.
The unbiased Gaussian estimator that achieves the Fisher information and
Cramer-Rao lower bound (CRLB) of a single data frame is proposed to benchmark
the quality of localization nanoscopy images and the performance of
localization algorithms. The information-achieving estimator is simulated in an
example and the result demonstrates the superior sensitivity of RMSMD over the
other four metrics. As a universal and objective metric, RMSMD can be broadly
employed in various applications to measure the mutual fitness of two sets of
points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01959</identifier>
 <datestamp>2019-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01959</id><created>2018-01-05</created><authors><author><keyname>Hwang</keyname><forenames>Wen-Liang</forenames></author><author><keyname>Huang</keyname><forenames>Ping-Tzan</forenames></author><author><keyname>Jong</keyname><forenames>Tai-Lang</forenames></author></authors><title>Frame-based Sparse Analysis and Synthesis Signal Representations and
  Parseval K-SVD</title><categories>eess.SP cs.LG</categories><comments>32 pages, 31 figures</comments><doi>10.1109/TSP.2019.2916105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frames are the foundation of the linear operators used in the decomposition
and reconstruction of signals, such as the discrete Fourier transform, Gabor,
wavelets, and curvelet transforms. The emergence of sparse representation
models has shifted of the emphasis in frame theory toward sparse
l1-minimization problems. In this paper, we apply frame theory to the sparse
representation of signals in which a synthesis dictionary is used for a frame
and an analysis dictionary is used for a dual frame. We sought to formulate a
novel dual frame design in which the sparse vector obtained through the
decomposition of any signal is also the sparse solution representing signals
based on a reconstruction frame. Our findings demonstrate that this type of
dual frame cannot be constructed for over-complete frames, thereby precluding
the use of any linear analysis operator in driving the sparse synthesis
coefficient for signal representation. Nonetheless, the best approximation to
the sparse synthesis solution can be derived from the analysis coefficient
using the canonical dual frame. In this study, we developed a novel dictionary
learning algorithm (called Parseval K-SVD) to learn a tight-frame dictionary.
We then leveraged the analysis and synthesis perspectives of signal
representation with frames to derive optimization formulations for problems
pertaining to image recovery. Our preliminary, results demonstrate that the
images recovered using this approach are correlated to the frame bounds of
dictionaries, thereby demonstrating the importance of using different
dictionaries for different applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.01979</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.01979</id><created>2018-01-06</created><updated>2018-01-08</updated><authors><author><keyname>Gureyev</keyname><forenames>T. E.</forenames></author><author><keyname>Paganin</keyname><forenames>D. M.</forenames></author><author><keyname>Kozlov</keyname><forenames>A.</forenames></author><author><keyname>Nesterets</keyname><forenames>Ya. I.</forenames></author><author><keyname>Quiney</keyname><forenames>H. M.</forenames></author></authors><title>On the efficiency of computational imaging with structured illumination</title><categories>eess.IV physics.optics</categories><comments>Minor corrections and clarifications compared to the original version</comments><journal-ref>Phys. Rev. A 97, 053819 (2018)</journal-ref><doi>10.1103/PhysRevA.97.053819</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generic computational imaging setup is considered which assumes sequential
illumination of a semi-transparent object by an arbitrary set of structured
illumination patterns. For each incident illumination pattern, all transmitted
light is collected by a photon-counting bucket (single-pixel) detector. The
transmission coefficients measured in this way are then used to reconstruct the
spatial distribution of the object's projected transmission. It is demonstrated
that the squared spatial resolution of such a setup is usually equal to the
ratio of the image area to the number of linearly independent illumination
patterns. If the noise in the measured transmission coefficients is dominated
by photon shot noise, then the ratio of the spatially-averaged squared mean
signal to the spatially-averaged noise variance in the &quot;flat&quot; distribution
reconstructed in the absence of the object, is equal to the average number of
registered photons when the illumination patterns are orthogonal. The
signal-to-noise ratio in a reconstructed transmission distribution is always
lower in the case of non-orthogonal illumination patterns due to spatial
correlations in the measured data. Examples of imaging methods relevant to the
presented analysis include conventional imaging with a pixelated detector,
computational ghost imaging, compressive sensing, super-resolution imaging and
computed tomography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02016</identifier>
 <datestamp>2018-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02016</id><created>2018-01-06</created><updated>2018-02-09</updated><authors><author><keyname>Yu</keyname><forenames>Xiangxu</forenames></author><author><keyname>Bampis</keyname><forenames>Christos G.</forenames></author><author><keyname>Gupta</keyname><forenames>Praful</forenames></author><author><keyname>Bovik</keyname><forenames>Alan C.</forenames></author></authors><title>Predicting Encoded Picture Quality in Two Steps is a Better Way</title><categories>eess.IV</categories><comments>fix the link in the abstract</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Full-reference (FR) image quality assessment (IQA) models assume a high
quality &quot;pristine&quot; image as a reference against which to measure perceptual
image quality. In many applications, however, the assumption that the reference
image is of high quality may be untrue, leading to incorrect perceptual quality
predictions. To address this, we propose a new two-step image quality
prediction approach which integrates both no-reference (NR) and full-reference
perceptual quality measurements into the quality prediction process. The
no-reference module accounts for the possibly imperfect quality of the source
(reference) image, while the full-reference component measures the quality
differences between the source image and its possibly further distorted
version. A simple, yet very efficient, multiplication step fuses the two
sources of information into a reliable objective prediction score. We evaluated
our two-step approach on a recently designed subjective image database and
achieved standout performance compared to full-reference approaches, especially
when the reference images were of low quality. The proposed approach is made
publicly available at https://github.com/xiangxuyu/2stepQA
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02128</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02128</id><created>2018-01-06</created><authors><author><keyname>Luo</keyname><forenames>Chao</forenames></author><author><keyname>Huang</keyname><forenames>Yih-Fang</forenames></author><author><keyname>Gupta</keyname><forenames>Vijay</forenames></author></authors><title>Stochastic Dynamic Pricing for EV Charging Stations with Renewables
  Integration and Energy Storage</title><categories>eess.SP econ.EM math.OC</categories><comments>13 pages, IEEE Transactions on Smart Grid, 2017</comments><doi>10.1109/TSG.2017.2696493</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper studies the problem of stochastic dynamic pricing and energy
management policy for electric vehicle (EV) charging service providers. In the
presence of renewable energy integration and energy storage system, EV charging
service providers must deal with multiple uncertainties --- charging demand
volatility, inherent intermittency of renewable energy generation, and
wholesale electricity price fluctuation. The motivation behind our work is to
offer guidelines for charging service providers to determine proper charging
prices and manage electricity to balance the competing objectives of improving
profitability, enhancing customer satisfaction, and reducing impact on power
grid in spite of these uncertainties. We propose a new metric to assess the
impact on power grid without solving complete power flow equations. To protect
service providers from severe financial losses, a safeguard of profit is
incorporated in the model. Two algorithms --- stochastic dynamic programming
(SDP) algorithm and greedy algorithm (benchmark algorithm) --- are applied to
derive the pricing and electricity procurement policy. A Pareto front of the
multiobjective optimization is derived. Simulation results show that using SDP
algorithm can achieve up to 7% profit gain over using greedy algorithm.
Additionally, we observe that the charging service provider is able to reshape
spatial-temporal charging demands to reduce the impact on power grid via
pricing signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02129</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02129</id><created>2018-01-06</created><authors><author><keyname>Luo</keyname><forenames>Chao</forenames></author><author><keyname>Huang</keyname><forenames>Yih-Fang</forenames></author><author><keyname>Gupta</keyname><forenames>Vijay</forenames></author></authors><title>Placement of EV Charging Stations --- Balancing Benefits among Multiple
  Entities</title><categories>eess.SP cs.GT econ.EM math.OC</categories><comments>10 pages, 10 figures</comments><journal-ref>IEEE Transactions on Smart Grid, vol. 8, no. 2, pp. 759 - 768,
  2015</journal-ref><doi>10.1109/TSG.2015.2508740</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper studies the problem of multi-stage placement of electric vehicle
(EV) charging stations with incremental EV penetration rates. A nested logit
model is employed to analyze the charging preference of the individual consumer
(EV owner), and predict the aggregated charging demand at the charging
stations. The EV charging industry is modeled as an oligopoly where the entire
market is dominated by a few charging service providers (oligopolists). At the
beginning of each planning stage, an optimal placement policy for each service
provider is obtained through analyzing strategic interactions in a Bayesian
game. To derive the optimal placement policy, we consider both the
transportation network graph and the electric power network graph. A simulation
software --- The EV Virtual City 1.0 --- is developed using Java to investigate
the interactions among the consumers (EV owner), the transportation network
graph, the electric power network graph, and the charging stations. Through a
series of experiments using the geographic and demographic data from the city
of San Pedro District of Los Angeles, we show that the charging station
placement is highly consistent with the heatmap of the traffic flow. In
addition, we observe a spatial economic phenomenon that service providers
prefer clustering instead of separation in the EV charging market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02135</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02135</id><created>2018-01-07</created><authors><author><keyname>Luo</keyname><forenames>Chao</forenames></author><author><keyname>Huang</keyname><forenames>Yih-Fang</forenames></author><author><keyname>Gupta</keyname><forenames>Vijay</forenames></author></authors><title>A Consumer Behavior Based Approach to Multi-Stage EV Charging Station
  Placement</title><categories>eess.SP cs.GT econ.EM math.OC</categories><comments>7 pages, 5 figures, Vehicular Technology Conference (VTC Spring),
  2015 IEEE 81st. arXiv admin note: text overlap with arXiv:1801.02129</comments><doi>10.1109/VTCSpring.2015.7145593</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a multi-stage approach to the placement of charging
stations under the scenarios of different electric vehicle (EV) penetration
rates. The EV charging market is modeled as the oligopoly. A consumer behavior
based approach is applied to forecast the charging demand of the charging
stations using a nested logit model. The impacts of both the urban road network
and the power grid network on charging station planning are also considered. At
each planning stage, the optimal station placement strategy is derived through
solving a Bayesian game among the service providers. To investigate the
interplay of the travel pattern, the consumer behavior, urban road network,
power grid network, and the charging station placement, a simulation platform
(The EV Virtual City 1.0) is developed using Java on Repast.We conduct a case
study in the San Pedro District of Los Angeles by importing the geographic and
demographic data of that region into the platform. The simulation results
demonstrate a strong consistency between the charging station placement and the
traffic flow of EVs. The results also reveal an interesting phenomenon that
service providers prefer clustering instead of spatial separation in this
oligopoly market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02137</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02137</id><created>2018-01-07</created><authors><author><keyname>Luo</keyname><forenames>Chao</forenames></author><author><keyname>Wu</keyname><forenames>Xuanli</forenames></author><author><keyname>Cao</keyname><forenames>Yang</forenames></author></authors><title>Multipath interference analysis of IR-UWB systems in indoor office LOS
  environment</title><categories>eess.SP</categories><comments>5 pages, 2 figures, Communications and Networking in China
  (CHINACOM), 2011 6th International ICST Conference on</comments><doi>10.1109/ChinaCom.2011.6158272</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Bit error rate (BER) performance of impulse radio Ultra-Wideband (UWB)
systems in the presence of intrasymbol interference, inter-symbol interference,
multiuser interference and addictive white Gaussian noise (AWGN) is presented
in this paper. By analyzing the indoor office LOS channel model defined by IEEE
802.15.4a Task Group and deducing the variance for intra-symbol interference
(IASI), inter-symbol interference (ISI) and multiuser interference (MUI), the
system BER expression is obtained and verified by MATLAB simulations. Through
comparing the simulation results with and without intra-symbol interference,
the conclusion that intra-symbol interference cannot be neglected is
drawn-moreover, such interference will significantly decrease performance of
UWB based wireless sensor networks (WSN). Then, the BER performance of UWB
systems in multiuser environment is also analyzed and analysis results show
that multiuser interference will further worsen the transmission performance of
UWB systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02138</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02138</id><created>2018-01-07</created><authors><author><keyname>Cao</keyname><forenames>Yang</forenames></author><author><keyname>Luo</keyname><forenames>Chao</forenames></author><author><keyname>Wu</keyname><forenames>Xuanli</forenames></author></authors><title>Partial Template Based Receiver in Impulse Radio Ultra-Wideband
  Communication Systems</title><categories>eess.SP</categories><comments>4 pages, 5 figures, Communications and Networking in China
  (CHINACOM), 2011 6th International ICST Conference on</comments><doi>10.1109/ChinaCom.2011.6158273</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  For high speed ultra-wideband (UWB) communication systems, the multipath
interference exhibits a primary obstacle to improve transmission performance.
In order to enhance the signal to interference plus noise ratio (SINR) in the
receiver, a partial template receiver is proposed in this paper. Instead of
using the conventional template, the model in this paper adopts a partial
template to demodulate signals. To analyze the performance of the proposed
receiver, bit error rate (BER) formulation of IR-UWB systems in the presence of
multipath interference, multiuser interference and addictive white Gaussian
noise (AWGN) is derived in IEEE 802.15.4a channel models. Simulation results
show that, compared with the conventional correlation receiver, the proposed
receiver can achieve a better BER performance for high Eb/N0, which falls in
the conventional used Eb/N0 range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02140</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02140</id><created>2018-01-07</created><authors><author><keyname>Wu</keyname><forenames>Xuanli</forenames></author><author><keyname>Cao</keyname><forenames>Yang</forenames></author><author><keyname>Yang</keyname><forenames>Xiaozong</forenames></author><author><keyname>Luo</keyname><forenames>Chao</forenames></author></authors><title>Performance Analysis of UWB Based Wireless Sensor Networks in Indoor
  Office LOS Environment</title><categories>eess.SP</categories><comments>5 pages, 6 figures, Cross Strait Quad-Regional Radio Science and
  Wireless Technology Conference (CSQRWC), 2011</comments><doi>10.1109/CSQRWC.2011.6037125</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  With the fast development of wireless sensor networks (WSN), more attentions
are paid to high data rate transmission of WSN, and hence, in IEEE 802.15.4a
standard, ultra-wideband (UWB) is introduced as one of the physical layer
technique to support high transmission data rate and precisie locationing
applications. In order to analyze the bit error rate (BER) performance of UWB
based WSN, a system model considering intra-symbol interference (IASI),
inter-symbol interference (ISI), multiuser interference (MUI) and addictive
white Gaussian noise (AWGN) is proposed in this paper, and then verified using
simulation results. Moreover, the pulse waveforms complying with the spectrum
requirement of IEEE 802.15.4a standard are given, and based on such obtained
pulses, the effect of transmission data rate and user number is also shown.
Results show that with the increase of SNR, the intra-symbol interference will
decrease the system performance significantly, and system performance can be
improve by using pulse waveforms with little intra-symbol interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02155</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02155</id><created>2018-01-07</created><authors><author><keyname>Singh</keyname><forenames>Malvika</forenames></author></authors><title>Binning based algorithm for Pitch Detection in Hindustani Classical
  Music</title><categories>cs.SD eess.AS</categories><comments>5 pages, 11 figures, 1 Table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech coding forms a crucial element in speech communications. An important
area concerning it lies in feature extraction which can be used for analyzing
Hindustani Classical Music. An important feature in this respect is the
fundamental frequency often referred to as the pitch. In this work, the terms
pitch and its acoustical sensation, the frequency is used interchangeably.
There exists numerous pitch detection algorithms which detect the main/
fundamental frequency in a given musical piece, but we have come up with a
unique algorithm for pitch detection using the binning method as described in
the paper using appropriate bin size. Previous work on this subject throws
light on pitch identification for Hindustani Classical Music. Pitch Class
Distribution has been employed in this work. It can be used to identify pitches
in Hindustani Classical Music which is based on suitable intonations and
swaras. It follows a particular ratio pattern which is a tuning for diatonic
scale proposed by Ptolemy and confirmed by Zarlino is explored in this paper.
We have also given our estimated of these ratios and compared the error with
the above. The error produced by varying the bin size in our algorithm is
investigated and an estimate for an appropriate bin size is suggested and
tested. The binning algorithm thus helps to segregate the important pitches in
a given musical piece.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02197</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02197</id><created>2018-01-07</created><authors><author><keyname>Wittpahl</keyname><forenames>Christian</forenames></author><author><keyname>Zakour</keyname><forenames>Hatem Ben</forenames></author><author><keyname>Lehmann</keyname><forenames>Matthias</forenames></author><author><keyname>Braun</keyname><forenames>Alexander</forenames></author></authors><title>Realistic Image Degradation with Measured PSF</title><categories>eess.IV astro-ph.IM</categories><comments>5 pages, 12 figures, submitted and accepted for IS&amp;T Electronic
  Imaging, Autonomous Vehicles and Machines 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Training autonomous vehicles requires lots of driving sequences in all
situations\cite{zhao2016}. Typically a simulation environment
(software-in-the-loop, SiL) accompanies real-world test drives to
systematically vary environmental parameters. A missing piece in the optical
model of those SiL simulations is the sharpness, given in linear system theory
by the point-spread function (PSF) of the optical system. We present a novel
numerical model for the PSF of an optical system that can efficiently model
both experimental measurements and lens design simulations of the PSF. The
numerical basis for this model is a non-linear regression of the PSF with an
artificial neural network (ANN). The novelty lies in the portability and the
parameterization of this model, which allows to apply this model in basically
any conceivable optical simulation scenario, e.g. inserting a measured lens
into a computer game to train autonomous vehicles. We present a lens
measurement series, yielding a numerical function for the PSF that depends only
on the parameters defocus, field and azimuth. By convolving existing images and
videos with this PSF model we apply the measured lens as a transfer function,
therefore generating an image as if it were seen with the measured lens itself.
Applications of this method are in any optical scenario, but we focus on the
context of autonomous driving, where quality of the detection algorithms
depends directly on the optical quality of the used camera system. With the
parameterization of the optical model we present a method to validate the
functional and safety limits of camera-based ADAS based on the real, measured
lens actually used in the product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02200</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02200</id><created>2018-01-07</created><authors><author><keyname>Sur&#xed;s</keyname><forenames>Didac</forenames></author><author><keyname>Duarte</keyname><forenames>Amanda</forenames></author><author><keyname>Salvador</keyname><forenames>Amaia</forenames></author><author><keyname>Torres</keyname><forenames>Jordi</forenames></author><author><keyname>Gir&#xf3;-i-Nieto</keyname><forenames>Xavier</forenames></author></authors><title>Cross-modal Embeddings for Video and Audio Retrieval</title><categories>cs.IR cs.CV cs.SD eess.AS</categories><comments>6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing amount of online videos brings several opportunities for
training self-supervised neural networks. The creation of large scale datasets
of videos such as the YouTube-8M allows us to deal with this large amount of
data in manageable way. In this work, we find new ways of exploiting this
dataset by taking advantage of the multi-modal information it provides. By
means of a neural network, we are able to create links between audio and visual
documents, by projecting them into a common region of the feature space,
obtaining joint audio-visual embeddings. These links are used to retrieve audio
samples that fit well to a given silent video, and also to retrieve images that
match a given a query audio. The results in terms of Recall@K obtained over a
subset of YouTube-8M videos show the potential of this unsupervised approach
for cross-modal feature learning. We train embeddings for both scales and
assess their quality in a retrieval problem, formulated as using the feature
extracted from one modality to retrieve the most similar videos based on the
features computed in the other modality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02303</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02303</id><created>2018-01-07</created><authors><author><keyname>Liu</keyname><forenames>Rui</forenames></author><author><keyname>Nejati</keyname><forenames>Hossein</forenames></author><author><keyname>Cheung</keyname><forenames>Ngai-Man</forenames></author></authors><title>Joint Estimation of Low-Rank Components and Connectivity Graph in
  High-Dimensional Graph Signals: Application to Brain Imaging</title><categories>eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a graph signal processing algorithm to uncover the
intrinsic low-rank components and the underlying graph of a high-dimensional,
graph-smooth and grossly-corrupted dataset. In our problem formulation, we
assume that the perturbation on the low-rank components is sparse and the
signal is smooth on the graph. We propose an algorithm to estimate the low-rank
components with the help of the graph and refine the graph with better
estimated low-rank components. We propose to perform the low-rank estimation
and graph refinement jointly so that low-rank estimation can benefit from the
refined graph, and graph refinement can leverage the improved low-rank
estimation. We propose to address the problem with an alternating optimization.
Moreover, we perform a mathematical analysis to understand and quantify the
impact of the inexact graph on the low-rank estimation, justifying our scheme
with graph refinement as an integrated step in estimating low-rank components.
We perform extensive experiments on the proposed algorithm and compare with
state-of-the-art low-rank estimation and graph learning techniques. Our
experiments use synthetic data and real brain imaging (MEG) data that is
recorded when subjects are presented with different categories of visual
stimuli. We observe that our proposed algorithm is competitive in estimating
the low-rank components, adequately capturing the intrinsic task-related
information in the reduced dimensional representation, and leading to better
performance in a classification task. Furthermore, we notice that our estimated
graph indicates compatible brain active regions for visual activity as
neuroscientific findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02384</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02384</id><created>2018-01-08</created><authors><author><keyname>Cai</keyname><forenames>Wilson</forenames></author><author><keyname>Doshi</keyname><forenames>Anish</forenames></author><author><keyname>Valle</keyname><forenames>Rafael</forenames></author></authors><title>Attacking Speaker Recognition With Deep Generative Models</title><categories>cs.SD cs.LG eess.AS</categories><comments>5 pages, 3 Figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the ability of generative adversarial networks
(GANs) to synthesize spoofing attacks on modern speaker recognition systems. We
first show that samples generated with SampleRNN and WaveNet are unable to fool
a CNN-based speaker recognition system. We propose a modification of the
Wasserstein GAN objective function to make use of data that is real but not
from the class being learned. Our semi-supervised learning method is able to
perform both targeted and untargeted attacks, raising questions related to
security in speaker authentication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02460</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02460</id><created>2017-12-31</created><authors><author><keyname>Semrau</keyname><forenames>Daniel</forenames></author><author><keyname>Bayvel</keyname><forenames>Polina</forenames></author></authors><title>The Gaussian Noise Model in the Presence of Inter-channel Stimulated
  Raman Scattering</title><categories>eess.SP</categories><comments>10 pages, 7 figures</comments><doi>10.1109/JLT.2018.2830973</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A Gaussian noise (GN) model is presented that properly accounts for an
arbitrary frequency dependent signal power profile along the link. This enables
the evaluation of the impact of inter-channel stimulated Raman scattering
(ISRS) on the optical Kerr nonlinearity. Additionally, the frequency dependent
fiber attenuation can be taken into account and transmission systems that use
hybrid amplification schemes can be modeled, where distributed Raman
amplification is partly applied over the optical spectrum. To include the
latter two cases, a set of coupled ordinary differential equations must be
numerically solved in order to obtain the signal power profile yielding a
semi-analytical model. However for lumped amplification and negligible
variation in fiber attenuation, a less complex and fully analytical model is
presented which is referred to as the ISRS GN model. The derived model is exact
to first-order for Gaussian modulated signals and extensively validated by
numerical split-step simulations. A maximum deviation of $0.1$~dB in nonlinear
interference power between simulations and the ISRS GN model is found. The
model is applied to a transmission system that occupies an optical bandwidth of
$10$~THz, representing the entire C+L band. At optimum launch power, changes of
up to $2$~dB in nonlinear interference power due to ISRS are reported.
Furthermore, comparable models published in the literature are benchmarked
against the ISRS GN model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02470</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02470</id><created>2018-01-02</created><authors><author><keyname>von Weltin</keyname><forenames>Eva</forenames></author><author><keyname>Ahsan</keyname><forenames>Tameem</forenames></author><author><keyname>Shah</keyname><forenames>Vinit</forenames></author><author><keyname>Jamshed</keyname><forenames>Dawer</forenames></author><author><keyname>Golmohammadi</keyname><forenames>Meysam</forenames></author><author><keyname>Obeid</keyname><forenames>Iyad</forenames></author><author><keyname>Picone</keyname><forenames>Joseph</forenames></author></authors><title>Electroencephalographic Slowing: A Source of Error in Automatic Seizure
  Detection</title><categories>eess.SP</categories><comments>Dec 2017 publication In IEEE Signal Processing in Medicine and
  Biology Symposium. Philadelphia, Pennsylvania, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although a seizure event represents a major deviation from a baseline
electroencephalographic signal, there are features of seizure morphology that
can be seen in non-epileptic portions of the record. A transient decrease in
frequency, referred to as slowing, is a generally abnormal but not necessarily
epileptic EEG variant. Seizure termination is often associated with a period of
slowing between the period of peak amplitude and frequency of the seizure and
the return to baseline. In annotation of seizure events in the TUH EEG Seizure
Corpus, independent slowing events were identified as a major source of false
alarm error. Preliminary results demonstrated the difficulty in automatic
differentiation between seizure events and independent slowing events. The TUH
EEG Slowing database, a subset of the TUH EEG Corpus, was created, and is
introduced here, to aid in the development of a seizure detection tool that can
differentiate between slowing at the end of a seizure and an independent
non-seizure slowing event. The corpus contains 100 10-second samples each of
background, slowing, and seizure events. Preliminary experiments show that 77%
sensitivity can be achieved in seizure detection using models trained on all
three sample types compared to 43% sensitivity with only seizure and background
samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02471</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02471</id><created>2018-01-02</created><authors><author><keyname>Golmohammadi</keyname><forenames>Meysam</forenames></author><author><keyname>Ziyabari</keyname><forenames>Saeedeh</forenames></author><author><keyname>Shah</keyname><forenames>Vinit</forenames></author><author><keyname>Von Weltin</keyname><forenames>Eva</forenames></author><author><keyname>Campbell</keyname><forenames>Christopher</forenames></author><author><keyname>Obeid</keyname><forenames>Iyad</forenames></author><author><keyname>Picone</keyname><forenames>Joseph</forenames></author></authors><title>Gated Recurrent Networks for Seizure Detection</title><categories>eess.SP cs.AI stat.ML</categories><comments>Published in Dec 2017 publication In IEEE Signal Processing in
  Medicine and Biology Symposium. Philadelphia, Pennsylvania, USA. arXiv admin
  note: text overlap with arXiv:1712.09776</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent Neural Networks (RNNs) with sophisticated units that implement a
gating mechanism have emerged as powerful technique for modeling sequential
signals such as speech or electroencephalography (EEG). The latter is the focus
on this paper. A significant big data resource, known as the TUH EEG Corpus
(TUEEG), has recently become available for EEG research, creating a unique
opportunity to evaluate these recurrent units on the task of seizure detection.
In this study, we compare two types of recurrent units: long short-term memory
units (LSTM) and gated recurrent units (GRU). These are evaluated using a state
of the art hybrid architecture that integrates Convolutional Neural Networks
(CNNs) with RNNs. We also investigate a variety of initialization methods and
show that initialization is crucial since poorly initialized networks cannot be
trained. Furthermore, we explore regularization of these convolutional gated
recurrent networks to address the problem of overfitting. Our experiments
revealed that convolutional LSTM networks can achieve significantly better
performance than convolutional GRU networks. The convolutional LSTM
architecture with proper initialization and regularization delivers 30%
sensitivity at 6 false alarms per 24 hours.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02472</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02472</id><created>2018-01-02</created><authors><author><keyname>Shah</keyname><forenames>Vinit</forenames></author><author><keyname>Golmohammadi</keyname><forenames>Meysam</forenames></author><author><keyname>Ziyabari</keyname><forenames>Saeedeh</forenames></author><author><keyname>Von Weltin</keyname><forenames>Eva</forenames></author><author><keyname>Obeid</keyname><forenames>Iyad</forenames></author><author><keyname>Picone</keyname><forenames>Joseph</forenames></author></authors><title>Optimizing Channel Selection for Seizure Detection</title><categories>eess.SP cs.CV q-bio.NC stat.ML</categories><comments>Published in Dec 2017 publication IEEE Signal Processing in Medicine
  and Biology Symposium. Philadelphia, Pennsylvania, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interpretation of electroencephalogram (EEG) signals can be complicated by
obfuscating artifacts. Artifact detection plays an important role in the
observation and analysis of EEG signals. Spatial information contained in the
placement of the electrodes can be exploited to accurately detect artifacts.
However, when fewer electrodes are used, less spatial information is available,
making it harder to detect artifacts. In this study, we investigate the
performance of a deep learning algorithm, CNN-LSTM, on several channel
configurations. Each configuration was designed to minimize the amount of
spatial information lost compared to a standard 22-channel EEG. Systems using a
reduced number of channels ranging from 8 to 20 achieved sensitivities between
33% and 37% with false alarms in the range of [38, 50] per 24 hours. False
alarms increased dramatically (e.g., over 300 per 24 hours) when the number of
channels was further reduced. Baseline performance of a system that used all 22
channels was 39% sensitivity with 23 false alarms. Since the 22-channel system
was the only system that included referential channels, the rapid increase in
the false alarm rate as the number of channels was reduced underscores the
importance of retaining referential channels for artifact reduction. This
cautionary result is important because one of the biggest differences between
various types of EEGs administered is the type of referential channel used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02474</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02474</id><created>2018-01-02</created><authors><author><keyname>Lopez</keyname><forenames>Silvia</forenames></author><author><keyname>Gross</keyname><forenames>Aaron</forenames></author><author><keyname>Yang</keyname><forenames>Scott</forenames></author><author><keyname>Golmohammadi</keyname><forenames>Meysam</forenames></author><author><keyname>Obeid</keyname><forenames>Iyad</forenames></author><author><keyname>Picone</keyname><forenames>Joseph</forenames></author></authors><title>An Analysis of Two Common Reference Points for EEGs</title><categories>eess.SP cs.LG stat.ML</categories><comments>Published In IEEE Signal Processing in Medicine and Biology
  Symposium. Philadelphia, Pennsylvania, USA</comments><journal-ref>S. Lopez, A. Gross, S. Yang, M. Golmohammadi, I. Obeid and J.
  Picone, &quot;An analysis of two common reference points for EEGS,&quot; 2016 IEEE
  Signal Processing in Medicine and Biology Symposium (SPMB), Philadelphia, PA,
  2016, pp. 1-5</journal-ref><doi>10.1109/SPMB.2016.7846854</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clinical electroencephalographic (EEG) data varies significantly depending on
a number of operational conditions (e.g., the type and placement of electrodes,
the type of electrical grounding used). This investigation explores the
statistical differences present in two different referential montages: Linked
Ear (LE) and Averaged Reference (AR). Each of these accounts for approximately
45% of the data in the TUH EEG Corpus. In this study, we explore the impact
this variability has on machine learning performance. We compare the
statistical properties of features generated using these two montages, and
explore the impact of performance on our standard Hidden Markov Model (HMM)
based classification system. We show that a system trained on LE data
significantly outperforms one trained only on AR data (77.2% vs. 61.4%). We
also demonstrate that performance of a system trained on both data sets is
somewhat compromised (71.4% vs. 77.2%). A statistical analysis of the data
suggests that mean, variance and channel normalization should be considered.
However, cepstral mean subtraction failed to produce an improvement in
performance, suggesting that the impact of these statistical differences is
subtler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02476</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02476</id><created>2018-01-02</created><authors><author><keyname>Yang</keyname><forenames>Scott</forenames></author><author><keyname>Lopez</keyname><forenames>Silvia</forenames></author><author><keyname>Golmohammadi</keyname><forenames>Meysam</forenames></author><author><keyname>Obeid</keyname><forenames>Iyad</forenames></author><author><keyname>Picone</keyname><forenames>Joseph</forenames></author></authors><title>Semi-automated Annotation of Signal Events in Clinical EEG Data</title><categories>eess.SP cs.DB cs.LG stat.ML</categories><comments>Published in IEEE Signal Processing in Medicine and Biology
  Symposium. Philadelphia, Pennsylvania, USA</comments><journal-ref>S. Yang, S. Lopez, M. Golmohammadi, I. Obeid and J. Picone,
  &quot;Semi-automated annotation of signal events in clinical EEG data,&quot; 2016 IEEE
  Signal Processing in Medicine and Biology Symposium (SPMB), Philadelphia, PA,
  2016, pp. 1-5</journal-ref><doi>10.1109/SPMB.2016.7846855</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To be effective, state of the art machine learning technology needs large
amounts of annotated data. There are numerous compelling applications in
healthcare that can benefit from high performance automated decision support
systems provided by deep learning technology, but they lack the comprehensive
data resources required to apply sophisticated machine learning models.
Further, for economic reasons, it is very difficult to justify the creation of
large annotated corpora for these applications. Hence, automated annotation
techniques become increasingly important. In this study, we investigated the
effectiveness of using an active learning algorithm to automatically annotate a
large EEG corpus. The algorithm is designed to annotate six types of EEG
events. Two model training schemes, namely threshold-based and volume-based,
are evaluated. In the threshold-based scheme the threshold of confidence scores
is optimized in the initial training iteration, whereas for the volume-based
scheme only a certain amount of data is preserved after each iteration.
Recognition performance is improved 2% absolute and the system is capable of
automatically annotating previously unlabeled data. Given that the
interpretation of clinical EEG data is an exceedingly difficult task, this
study provides some evidence that the proposed method is a viable alternative
to expensive manual annotation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02477</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02477</id><created>2018-01-02</created><authors><author><keyname>Harati</keyname><forenames>Amir</forenames></author><author><keyname>Golmohammadi</keyname><forenames>Meysam</forenames></author><author><keyname>Lopez</keyname><forenames>Silvia</forenames></author><author><keyname>Obeid</keyname><forenames>Iyad</forenames></author><author><keyname>Picone</keyname><forenames>Joseph</forenames></author></authors><title>Improved EEG Event Classification Using Differential Energy</title><categories>eess.SP cs.CV stat.ML</categories><comments>Published in IEEE Signal Processing in Medicine and Biology
  Symposium. Philadelphia, Pennsylvania, USA</comments><journal-ref>A. Harati, M. Golmohammadi, S. Lopez, I. Obeid and J. Picone,
  &quot;Improved EEG event classification using differential energy,&quot; 2015 IEEE
  Signal Processing in Medicine and Biology Symposium (SPMB), Philadelphia, PA,
  2015, pp. 1-4</journal-ref><doi>10.1109/SPMB.2015.7405421</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature extraction for automatic classification of EEG signals typically
relies on time frequency representations of the signal. Techniques such as
cepstral-based filter banks or wavelets are popular analysis techniques in many
signal processing applications including EEG classification. In this paper, we
present a comparison of a variety of approaches to estimating and
postprocessing features. To further aid in discrimination of periodic signals
from aperiodic signals, we add a differential energy term. We evaluate our
approaches on the TUH EEG Corpus, which is the largest publicly available EEG
corpus and an exceedingly challenging task due to the clinical nature of the
data. We demonstrate that a variant of a standard filter bank-based approach,
coupled with first and second derivatives, provides a substantial reduction in
the overall error rate. The combination of differential energy and derivatives
produces a 24% absolute reduction in the error rate and improves our ability to
discriminate between signal events and background noise. This relatively simple
approach proves to be comparable to other popular feature extraction approaches
such as wavelets, but is much more computationally efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02478</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02478</id><created>2018-01-03</created><authors><author><keyname>Koohifar</keyname><forenames>Farshad</forenames></author><author><keyname>Guvenc</keyname><forenames>Ismail</forenames></author><author><keyname>Sichitiu</keyname><forenames>Mihail L.</forenames></author></authors><title>Autonomous Tracking of Intermittent RF Source Using a UAV Swarm</title><categories>eess.SP cs.MA cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Localization of a radio frequency (RF) transmitter with intermittent
transmissions is considered via a group of unmanned aerial vehicles (UAVs)
equipped with omnidirectional received signal strength (RSS) sensors. This
group embarks on an autonomous patrol to localize and track the target with a
specified accuracy, as quickly as possible. The challenge can be decomposed
into two stages: 1) estimation of the target position given previous
measurements (localization), and 2) planning the future trajectory of the
tracking UAVs to get lower expected localization error given current estimation
(path planning). For each stage we compare two algorithms in terms of
performance and computational load. For the localization stage, we compare a
detection based extended Kalman filter (EKF) and a recursive Bayesian
estimator. For the path planning stage, we compare steepest descent posterior
Cramer-Rao lower bound (CRLB) path planning and a bio-inspired heuristic path
planning. Our results show that the steepest descent path planning outperforms
the bio-inspired path planning by an order of magnitude, and recursive Bayesian
estimator narrowly outperforms detection based EKF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02485</identifier>
 <datestamp>2018-02-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02485</id><created>2018-01-04</created><authors><author><keyname>Zhao</keyname><forenames>Zhongyang</forenames></author><author><keyname>Wang</keyname><forenames>Caisheng</forenames></author><author><keyname>Nokleby</keyname><forenames>Matthew</forenames></author><author><keyname>Miller</keyname><forenames>Carol</forenames></author></authors><title>Improving Short-Term Electricity Price Forecasting Using Day-Ahead LMP
  with ARIMA Models</title><categories>eess.SP</categories><comments>IEEE PES 2017 General Meeting, Chicago, IL</comments><doi>10.1109/PESGM.2017.8274124</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short-term electricity price forecasting has become important for demand side
management and power generation scheduling. Especially as the electricity
market becomes more competitive, a more accurate price prediction than the
day-ahead locational marginal price (DALMP) published by the independent system
operator (ISO) will benefit participants in the market by increasing profit or
improving load demand scheduling. Hence, the main idea of this paper is to use
autoregressive integrated moving average (ARIMA) models to obtain a better LMP
prediction than the DALMP by utilizing the published DALMP, historical
real-time LMP (RTLMP) and other useful information. First, a set of seasonal
ARIMA (SARIMA) models utilizing the DALMP and historical RTLMP are developed
and compared with autoregressive moving average (ARMA) models that use the
differences between DALMP and RTLMP on their forecasting capability. A
generalized autoregressive conditional heteroskedasticity (GARCH) model is
implemented to further improve the forecasting by accounting for the price
volatility. The models are trained and evaluated using real market data in the
Midcontinent Independent System Operator (MISO) region. The evaluation results
indicate that the ARMAX-GARCH model, where an exogenous time series indicates
weekend days, improves the short-term electricity price prediction accuracy and
outperforms the other proposed ARIMA models
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02684</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02684</id><created>2018-01-08</created><authors><author><keyname>Karam</keyname><forenames>Lina</forenames></author><author><keyname>Borkar</keyname><forenames>Tejas</forenames></author><author><keyname>Cao</keyname><forenames>Yu</forenames></author><author><keyname>Chae</keyname><forenames>Junseok</forenames></author></authors><title>Generative Sensing: Transforming Unreliable Sensor Data for Reliable
  Recognition</title><categories>cs.CV eess.IV</categories><comments>5 pages, Submitted to IEEE MIPR 2018</comments><acm-class>I.2; I.2.10</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a deep learning enabled generative sensing framework
which integrates low-end sensors with computational intelligence to attain a
high recognition accuracy on par with that attained with high-end sensors. The
proposed generative sensing framework aims at transforming low-end, low-quality
sensor data into higher quality sensor data in terms of achieved classification
accuracy. The low-end data can be transformed into higher quality data of the
same modality or into data of another modality. Different from existing methods
for image generation, the proposed framework is based on discriminative models
and targets to maximize the recognition accuracy rather than a similarity
measure. This is achieved through the introduction of selective feature
regeneration in a deep neural network (DNN). The proposed generative sensing
will essentially transform low-quality sensor data into high-quality
information for robust perception. Results are presented to illustrate the
performance of the proposed framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02690</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02690</id><created>2018-01-08</created><authors><author><keyname>Jimenez</keyname><forenames>Abelino</forenames></author><author><keyname>Elizalde</keyname><forenames>Benjamin</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author></authors><title>DCASE 2017 Task 1: Acoustic Scene Classification Using Shift-Invariant
  Kernels and Random Features</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustic scene recordings are represented by different types of handcrafted
or Neural Network-derived features. These features, typically of thousands of
dimensions, are classified in state of the art approaches using kernel
machines, such as the Support Vector Machines (SVM). However, the complexity of
training these methods increases with the dimensionality of these input
features and the size of the dataset. A solution is to map the input features
to a randomized lower-dimensional feature space. The resulting random features
can approximate non-linear kernels with faster linear kernel computation. In
this work, we computed a set of 6,553 input features and used them to compute
random features to approximate three types of kernels, Gaussian, Laplacian and
Cauchy. We compared their performance using an SVM in the context of the DCASE
Task 1 - Acoustic Scene Classification. Experiments show that both, input and
random features outperformed the DCASE baseline by an absolute 4%. Moreover,
the random features reduced the dimensionality of the input by more than three
times with minimal loss of performance and by more than six times and still
outperformed the baseline. Hence, random features could be employed by state of
the art approaches to compute low-storage features and perform faster kernel
computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02728</identifier>
 <datestamp>2018-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02728</id><created>2018-01-08</created><authors><author><keyname>Chen</keyname><forenames>Yuhua</forenames></author><author><keyname>Xie</keyname><forenames>Yibin</forenames></author><author><keyname>Zhou</keyname><forenames>Zhengwei</forenames></author><author><keyname>Shi</keyname><forenames>Feng</forenames></author><author><keyname>Christodoulou</keyname><forenames>Anthony G.</forenames></author><author><keyname>Li</keyname><forenames>Debiao</forenames></author></authors><title>Brain MRI Super Resolution Using 3D Deep Densely Connected Neural
  Networks</title><categories>cs.CV eess.IV</categories><comments>Accepted by ISBI'18</comments><doi>10.1109/ISBI.2018.8363679</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance image (MRI) in high spatial resolution provides detailed
anatomical information and is often necessary for accurate quantitative
analysis. However, high spatial resolution typically comes at the expense of
longer scan time, less spatial coverage, and lower signal to noise ratio (SNR).
Single Image Super-Resolution (SISR), a technique aimed to restore
high-resolution (HR) details from one single low-resolution (LR) input image,
has been improved dramatically by recent breakthroughs in deep learning. In
this paper, we introduce a new neural network architecture, 3D Densely
Connected Super-Resolution Networks (DCSRN) to restore HR features of
structural brain MR images. Through experiments on a dataset with 1,113
subjects, we demonstrate that our network outperforms bicubic interpolation as
well as other deep learning methods in restoring 4x resolution-reduced images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.02783</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.02783</id><created>2018-01-08</created><authors><author><keyname>Luo</keyname><forenames>Chao</forenames></author><author><keyname>Huang</keyname><forenames>Yih-Fang</forenames></author><author><keyname>Gupta</keyname><forenames>Vijay</forenames></author></authors><title>Dynamic Pricing and Energy Management Strategy for EV Charging Stations
  under Uncertainties</title><categories>eess.SP econ.EM math.OC</categories><comments>11 pages, 9 figures, Proceedings of VEHITS 2016, ISBN:
  978-989-758-185-4</comments><journal-ref>In Proceedings of the International Conference on Vehicle
  Technology and Intelligent Transport Systems (VEHITS 2016)</journal-ref><doi>10.5220/0005797100490059</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents a dynamic pricing and energy management framework for
electric vehicle (EV) charging service providers. To set the charging prices,
the service providers faces three uncertainties: the volatility of wholesale
electricity price, intermittent renewable energy generation, and
spatial-temporal EV charging demand. The main objective of our work here is to
help charging service providers to improve their total profits while enhancing
customer satisfaction and maintaining power grid stability, taking into account
those uncertainties. We employ a linear regression model to estimate the EV
charging demand at each charging station, and introduce a quantitative measure
for customer satisfaction. Both the greedy algorithm and the dynamic
programming (DP) algorithm are employed to derive the optimal charging prices
and determine how much electricity to be purchased from the wholesale market in
each planning horizon. Simulation results show that DP algorithm achieves an
increased profit (up to 9%) compared to the greedy algorithm (the benchmark
algorithm) under certain scenarios. Additionally, we observe that the
integration of a low-cost energy storage into the system can not only improve
the profit, but also smooth out the charging price fluctuation, protecting the
end customers from the volatile wholesale market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03069</identifier>
 <datestamp>2018-05-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03069</id><created>2018-01-09</created><updated>2018-05-29</updated><authors><author><keyname>Chen</keyname><forenames>Tingjun</forenames></author><author><keyname>Dastjerdi</keyname><forenames>Mahmood Baraani</forenames></author><author><keyname>Farkash</keyname><forenames>Guy</forenames></author><author><keyname>Zhou</keyname><forenames>Jin</forenames></author><author><keyname>Krishnaswamy</keyname><forenames>Harish</forenames></author><author><keyname>Zussman</keyname><forenames>Gil</forenames></author></authors><title>Open-Access Full-Duplex Wireless in the ORBIT Testbed</title><categories>cs.NI eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to support experimentation with full-duplex (FD) wireless, we
recently integrated an open-access FD transceiver in the ORBIT testbed. In this
report, we present the design and implementation of the FD transceiver and
interfaces, and provide examples and guidelines for experimentation. In
particular, an ORBIT node with a National Instruments (NI)/Ettus Research
Universal Software Radio Peripheral (USRP) N210 software-defined radio (SDR)
was equipped with the Columbia FlexICoN Gen-1 customized RF self-interference
(SI) canceller box. The RF canceller box includes an RF SI canceller that is
implemented using discrete components on a printed circuit board (PCB) and
achieves 40dB RF SI cancellation across 5MHz bandwidth. We provide an FD
transceiver baseline program and present two example FD experiments where 90dB
and 85dB overall SI cancellation is achieved for a simple waveform and PSK
modulated signals across both the RF and digital domains. We also discuss
potential FD wireless experiments that can be conducted based on the
implemented open-access FD transceiver and baseline program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03266</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03266</id><created>2018-01-10</created><authors><author><keyname>Sidorenko</keyname><forenames>Juri</forenames></author><author><keyname>Doktorski</keyname><forenames>Leo</forenames></author><author><keyname>Schatz</keyname><forenames>Volker</forenames></author><author><keyname>Scherer-Negenborn</keyname><forenames>Norbert</forenames></author><author><keyname>Arens</keyname><forenames>Michael</forenames></author></authors><title>Improved Time of Arrival measurement model for non-convex optimization</title><categories>math.OC eess.SP</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quadratic system provided by the Time of Arrival technique can be solved
analytically or by optimization algorithms. In practice, a combination of both
methods is used. An important problem in quadratic optimization is the possible
convergence to a local minimum, instead of the global minimum. This article
presents an approach how this risk can be significantly reduced. The main idea
of our approach is to transform the local minimum to a saddle point, by
increasing the number of dimensions. In contrast to similar methods such as,
dimension lifting does our problem remains non-convex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03358</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03358</id><created>2018-01-10</created><authors><author><keyname>Sidorenko</keyname><forenames>Juri</forenames></author><author><keyname>Scherer-Negenborn</keyname><forenames>Norbert</forenames></author><author><keyname>Arens</keyname><forenames>Michael</forenames></author><author><keyname>Michaelsen</keyname><forenames>Eckart</forenames></author></authors><title>Improved linear direct solution for asynchronous radio network
  localization (RNL)</title><categories>eess.SP</categories><comments>Pacific PNT, ION 2017
  https://www.ion.org/publications/abstract.cfm?articleID=15036</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the field of localization the linear least square solution is frequently
used. This solution is compared to nonlinear solvers more effected by noise,
but able to provide a position estimation without the knowledge of any starting
condition. The linear least square solution is able to minimize Gaussian noise
by solving an overdetermined equation with the MoorePenrose pseudoinverse.
Unfortunately this solution fails if it comes to non Gaussian noise. This
publication presents a direct solution which is able to use prefiltered data
for the LPM (RNL) equation. The used input for the linear position estimation
will not be the raw data but over the time filtered data, for this reason this
solution will be called direct solution. It will be shown that the presented
symmetrical direct solution is superior to non symmetrical direct solution and
especially to the not prefiltered linear least square solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03412</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03412</id><created>2018-01-10</created><authors><author><keyname>Almazrouei</keyname><forenames>Ebtesam</forenames></author><author><keyname>Ali</keyname><forenames>Nazar</forenames></author><author><keyname>Al-Araji</keyname><forenames>Saleh</forenames></author></authors><title>Assessment of SFSDP Cooperative Localization Algorithm for WLAN
  Environment</title><categories>eess.SP cs.NI</categories><comments>4 pages, 5 figures, conference; Seventh International Conferences On
  Internet Technologies and Applications (ITA 17), 12-17 Sept 2017, North
  Wales, U.K</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative localization for indoor WiFi networks have received little
attention thus far. Many cooperative location algorithms exist for Wireless
Sensor Network Applications but their suitability for WiFi based networks has
not been studied. In this paper the performance of the Sparse Finite Semi
Definite Program (SFSDP) has been examined using real measurements data and
under different indoor conditions. Effects of other network parameters such as
varying number of anchors and blind nodes are also included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03525</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03525</id><created>2018-01-10</created><authors><author><keyname>Ma</keyname><forenames>Sen</forenames></author><author><keyname>Nguyen</keyname><forenames>Christopher T.</forenames></author><author><keyname>Christodoulou</keyname><forenames>Anthony G.</forenames></author><author><keyname>Luthringer</keyname><forenames>Daniel</forenames></author><author><keyname>Kobashigawa</keyname><forenames>Jon</forenames></author><author><keyname>Lee</keyname><forenames>Sang-Eun</forenames></author><author><keyname>Chang</keyname><forenames>Hyuk-Jae</forenames></author><author><keyname>Li</keyname><forenames>Debiao</forenames></author></authors><title>Accelerated Cardiac Diffusion Tensor Imaging Using Joint Low-Rank and
  Sparsity Constraints</title><categories>eess.SP</categories><comments>11 pages, 16 figures, published on IEEE Transactions on Biomedical
  Engineering</comments><journal-ref>S. Ma et al., &quot;Accelerated Cardiac Diffusion Tensor Imaging Using
  Joint Low-Rank and Sparsity Constraints,&quot; in IEEE Transactions on Biomedical
  Engineering, 2017, vol. PP, no. 99, pp. 1-1</journal-ref><doi>10.1109/TBME.2017.2787111</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective: The purpose of this manuscript is to accelerate cardiac diffusion
tensor imaging (CDTI) by integrating low-rankness and compressed sensing.
Methods: Diffusion-weighted images exhibit both transform sparsity and
low-rankness. These properties can jointly be exploited to accelerate CDTI,
especially when a phase map is applied to correct for the phase inconsistency
across diffusion directions, thereby enhancing low-rankness. The proposed
method is evaluated both ex vivo and in vivo, and is compared to methods using
either a low-rank or sparsity constraint alone. Results: Compared to using a
low-rank or sparsity constraint alone, the proposed method preserves more
accurate helix angle features, the transmural continuum across the myocardium
wall, and mean diffusivity at higher acceleration, while yielding significantly
lower bias and higher intraclass correlation coefficient. Conclusion:
Low-rankness and compressed sensing together facilitate acceleration for both
ex vivo and in vivo CDTI, improving reconstruction accuracy compared to
employing either constraint alone. Significance: Compared to previous methods
for accelerating CDTI, the proposed method has the potential to reach higher
acceleration while preserving myofiber architecture features which may allow
more spatial coverage, higher spatial resolution and shorter temporal footprint
in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03577</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03577</id><created>2018-01-10</created><authors><author><keyname>Shinoda</keyname><forenames>Kazuma</forenames></author><author><keyname>Hasegawa</keyname><forenames>Madoka</forenames></author><author><keyname>Yamaguchi</keyname><forenames>Masahiro</forenames></author><author><keyname>Ortega</keyname><forenames>Antonio</forenames></author></authors><title>Mosaicked multispectral image compression based on inter- and intra-band
  correlation</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multispectral imaging has been utilized in many fields, but the cost of
capturing and storing image data is still high. Single-sensor cameras with
multispectral filter arrays can reduce the cost of capturing images at the
expense of slightly lower image quality. When multispectral filter arrays are
used, conventional multispectral image compression methods can be applied after
interpolation, but the compressed image data after interpolation has some
redundancy because the interpolated data are computed from the captured raw
data. In this paper, we propose an efficient image compression method for
single-sensor multispectral cameras. The proposed method encodes the captured
multispectral data before interpolation. We also propose a new spectral
transform method for the compression of mosaicked multispectral images. This
transform is designed by considering the filter arrangement and the spectral
sensitivities of a multispectral filter array. The experimental results show
that the proposed method achieves a higher peak signal-to-noise ratio at higher
bit rates than a conventional compression method that encodes a multispectral
image after interpolation, e.g., 3-dB gain over conventional compression when
coding at rates of over 0.1 bit/pixel/bands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03607</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03607</id><created>2018-01-10</created><authors><author><keyname>Yang</keyname><forenames>Huizhang</forenames></author><author><keyname>Chen</keyname><forenames>Shengyao</forenames></author><author><keyname>Xi</keyname><forenames>Feng</forenames></author><author><keyname>Liu</keyname><forenames>Zhong</forenames></author></authors><title>Quadrature compressive sampling SAR imaging</title><categories>cs.IT eess.SP math.IT</categories><comments>4 pages, 2 figures, submitted to IGARSS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a quadrature compressive sampling (QuadCS) and associated
fast imaging scheme for synthetic aperture radar (SAR). Different from other
analog-to-information conversions (AIC), QuadCS AICs using independent
spreading signals sample the SAR echoes due to different transmitted pulses.
Then the resulting sensing matrix has lower correlation between any two columns
than that by a fixed spreading signal, and better SAR image can be
reconstructed. With proper setting of the spreading signals in QuadCS, the
sensing matrix has the structures suitable for fast computation of
matrix-vector multiplication operations, which leads to the fast image
reconstruction. The performance of the proposed scheme is assessed using real
SAR image. The reconstructed SAR images with only one-fourth of the Nyquist
data achieve the image quality similar to that of the classical SAR images with
Nyquist samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03652</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03652</id><created>2018-01-11</created><authors><author><keyname>Zhou</keyname><forenames>Anping</forenames></author><author><keyname>Yang</keyname><forenames>Ming</forenames></author><author><keyname>Wang</keyname><forenames>Zhaoyu</forenames></author></authors><title>A Linear Solution Method of Generalized Robust Chance Constrained
  Real-time Dispatch</title><categories>eess.SP</categories><comments>3 pages, 2 figures, IEEE Transactions on Power Systems Letter.
  submitted</comments><journal-ref>Anping Zhou, Ming Yang and Zhaoyu Wang. A Linear Solution Method
  of Generalized Robust Chance Constrained Real-time Dispatch[J]. IEEE
  Transactions on Power Systems, 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, a novel solution method of generalized robust chance
constrained real-time dispatch (GRCC-RTD) considering wind power uncertainty is
proposed. GRCC models are advantageous in dealing with distributional
uncertainty, however, they are difficult to solve because of the complex
ambiguity set. By constructing traceable counterparts of the robust chance
constraints and using the reformulation linearization technique, the model is
equivalently transformed into a deterministic linear programming problem, which
can be solved efficiently by off-the-shelf solvers. Numerical results verify
the effectiveness and efficiency of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03717</identifier>
 <datestamp>2018-05-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03717</id><created>2018-01-11</created><updated>2018-05-23</updated><authors><author><keyname>Silva</keyname><forenames>Jos&#xe9; Mairton B. da</forenames><suffix>Jr.</suffix></author><author><keyname>Ghauch</keyname><forenames>Hadi</forenames></author><author><keyname>Fodor</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Fischione</keyname><forenames>Carlo</forenames></author></authors><title>How to Split UL/DL Antennas in Full-Duplex Cellular Networks</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>7 pages, 4 figures. Accepted to IEEE ICC 2018 Workshop on Full-Duplex
  Communications for Future Wireless Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To further improve the potential of full-duplex communications, networks may
employ multiple antennas at the base station or user equipment. To this end,
networks that employ current radios usually deal with self-interference and
multi-user interference by beamforming techniques. Although previous works
investigated beamforming design to improve spectral efficiency, the fundamental
question of how to split the antennas at a base station between uplink and
downlink in full-duplex networks has not been investigated rigorously. This
paper addresses this question by posing antenna splitting as a binary nonlinear
optimization problem to minimize the sum mean squared error of the received
data symbols. It is shown that this is an NP-hard problem. This combinatorial
problem is dealt with by equivalent formulations, iterative convex
approximations, and a binary relaxation. The proposed algorithm is guaranteed
to converge to a stationary solution of the relaxed problem with much smaller
complexity than exhaustive search. Numerical results indicate that the proposed
solution is close to the optimal in both high and low self-interference capable
scenarios, while the usually assumed antenna splitting is far from optimal. For
large number of antennas, a simple antenna splitting is close to the proposed
solution. This reveals that the importance of antenna splitting is inversely
proportional with the number of antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03740</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03740</id><created>2018-01-11</created><updated>2018-08-28</updated><authors><author><keyname>Badawy</keyname><forenames>Dalia El</forenames></author><author><keyname>Dokmani&#x107;</keyname><forenames>Ivan</forenames></author></authors><title>Direction of Arrival with One Microphone, a few LEGOs, and Non-Negative
  Matrix Factorization</title><categories>eess.AS cs.SD</categories><comments>This article has been accepted for publication in IEEE/ACM
  Transactions on Audio, Speech, and Language processing (TASLP)</comments><doi>10.1109/TASLP.2018.2867081</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional approaches to sound source localization require at least two
microphones. It is known, however, that people with unilateral hearing loss can
also localize sounds. Monaural localization is possible thanks to the
scattering by the head, though it hinges on learning the spectra of the various
sources. We take inspiration from this human ability to propose algorithms for
accurate sound source localization using a single microphone embedded in an
arbitrary scattering structure. The structure modifies the frequency response
of the microphone in a direction-dependent way giving each direction a
signature. While knowing those signatures is sufficient to localize sources of
white noise, localizing speech is much more challenging: it is an ill-posed
inverse problem which we regularize by prior knowledge in the form of learned
non-negative dictionaries. We demonstrate a monaural speech localization
algorithm based on non-negative matrix factorization that does not depend on
sophisticated, designed scatterers. In fact, we show experimental results with
ad hoc scatterers made of LEGO bricks. Even with these rudimentary structures
we can accurately localize arbitrary speakers; that is, we do not need to learn
the dictionary for the particular speaker to be localized. Finally, we discuss
multi-source localization and the related limitations of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03773</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03773</id><created>2018-01-08</created><authors><author><keyname>Chan</keyname><forenames>Tak-Shing T.</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Polar $n$-Complex and $n$-Bicomplex Singular Value Decomposition and
  Principal Component Pursuit</title><categories>eess.SP cs.MM cs.SD eess.AS stat.ML</categories><comments>12 pages, 2 figures</comments><journal-ref>IEEE Trans. Signal Process., vol. 64, no. 24, pp. 6533-6544, Dec.
  2016</journal-ref><doi>10.1109/TSP.2016.2612171</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Informed by recent work on tensor singular value decomposition and circulant
algebra matrices, this paper presents a new theoretical bridge that unifies the
hypercomplex and tensor-based approaches to singular value decomposition and
robust principal component analysis. We begin our work by extending the
principal component pursuit to Olariu's polar $n$-complex numbers as well as
their bicomplex counterparts. In so doing, we have derived the polar
$n$-complex and $n$-bicomplex proximity operators for both the $\ell_1$- and
trace-norm regularizers, which can be used by proximal optimization methods
such as the alternating direction method of multipliers. Experimental results
on two sets of audio data show that our algebraically-informed formulation
outperforms tensor robust principal component analysis. We conclude with the
message that an informed definition of the trace norm can bridge the gap
between the hypercomplex and tensor-based approaches. Our approach can be seen
as a general methodology for generating other principal component pursuit
algorithms with proper algebraic structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03814</identifier>
 <datestamp>2019-09-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03814</id><created>2018-01-09</created><authors><author><keyname>Lu</keyname><forenames>Ruochen</forenames></author><author><keyname>Manzaneque</keyname><forenames>Tomas</forenames></author><author><keyname>Yang</keyname><forenames>Yansong</forenames></author><author><keyname>Gao</keyname><forenames>Anming</forenames></author><author><keyname>Gao</keyname><forenames>Liuqing</forenames></author><author><keyname>Gong</keyname><forenames>Songbin</forenames></author></authors><title>A Radio Frequency Non-reciprocal Network Based on Switched Low-loss
  Acoustic Delay Lines</title><categories>eess.SP</categories><comments>4 pages, 7 figures</comments><doi>10.1109/ULTSYM.2018.8579758</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work demonstrates the first non-reciprocal network based on switched
low-loss acoustic delay lines. A 21 dB non-reciprocal contrast between
insertion loss (IL=6.7 dB) and isolation (28.3 dB) has been achieved over a
fractional bandwidth of 8.8% at a center frequency 155MHz, using a record low
switching frequency of 877.22 kHz. The 4-port circulator is built upon a newly
reported framework by the authors, but using two in-house fabricated low-loss,
wide-band lithium niobate (LiNbO3) delay lines with single-phase unidirectional
transducers (SPUDT) and commercial available switches. Such a system can
potentially lead to future wide-band, low-loss chip-scale nonreciprocal RF
systems with unprecedented programmability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03815</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03815</id><created>2018-01-08</created><authors><author><keyname>Chan</keyname><forenames>Tak-Shing T.</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Informed Group-Sparse Representation for Singing Voice Separation</title><categories>eess.AS cs.IR cs.SD eess.SP stat.ML</categories><comments>5 pages, 1 figure</comments><journal-ref>IEEE Signal Process. Lett., vol. 24, no. 2, pp. 156-160, Feb. 2017</journal-ref><doi>10.1109/LSP.2017.2647810</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Singing voice separation attempts to separate the vocal and instrumental
parts of a music recording, which is a fundamental problem in music information
retrieval. Recent work on singing voice separation has shown that the low-rank
representation and informed separation approaches are both able to improve
separation quality. However, low-rank optimizations are computationally
inefficient due to the use of singular value decompositions. Therefore, in this
paper, we propose a new linear-time algorithm called informed group-sparse
representation, and use it to separate the vocals from music using pitch
annotations as side information. Experimental results on the iKala dataset
confirm the efficacy of our approach, suggesting that the music accompaniment
follows a group-sparse structure given a pre-trained instrumental dictionary.
We also show how our work can be easily extended to accommodate multiple
dictionaries using the DSD100 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03816</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03816</id><created>2018-01-08</created><authors><author><keyname>Chan</keyname><forenames>Tak-Shing T.</forenames></author><author><keyname>Yang</keyname><forenames>Yi-Hsuan</forenames></author></authors><title>Complex and Quaternionic Principal Component Pursuit and Its Application
  to Audio Separation</title><categories>eess.SP cs.MM cs.SD eess.AS stat.ML</categories><comments>5 pages, 1 figure</comments><journal-ref>IEEE Signal Process. Lett., vol. 23, no. 2, pp. 287-291, Feb. 2016</journal-ref><doi>10.1109/LSP.2016.2514845</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the principal component pursuit has received increasing attention
in signal processing research ranging from source separation to video
surveillance. So far, all existing formulations are real-valued and lack the
concept of phase, which is inherent in inputs such as complex spectrograms or
color images. Thus, in this letter, we extend principal component pursuit to
the complex and quaternionic cases to account for the missing phase
information. Specifically, we present both complex and quaternionic proximity
operators for the $\ell_1$- and trace-norm regularizers. These operators can be
used in conjunction with proximal minimization methods such as the inexact
augmented Lagrange multiplier algorithm. The new algorithms are then applied to
the singing voice separation problem, which aims to separate the singing voice
from the instrumental accompaniment. Results on the iKala and MSD100 datasets
confirmed the usefulness of phase information in principal component pursuit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03817</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03817</id><created>2018-01-08</created><authors><author><keyname>Sathya</keyname><forenames>Vanlin</forenames></author><author><keyname>Mehrnoush</keyname><forenames>Morteza</forenames></author><author><keyname>Ghosh</keyname><forenames>Monisha</forenames></author><author><keyname>Roy</keyname><forenames>Sumit</forenames></author></authors><title>Association fairness in Wi-Fi and LTE-U coexistence</title><categories>eess.SP</categories><comments>Accepted in IEEE WCNC 2018, Barcelona, Spain</comments><journal-ref>2018 IEEE Wireless Communications and Networking Conference (WCNC)
  - Emerging Technologies, Architectures and Services</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper we address the issue of association fairness when Wi-Fi and LTE
unlicensed (LTE-U) coexist on the same channel in the unlicensed 5 GHz band.
Since beacon transmission is the first step in starting the association process
in Wi-Fi, we define association fairness as how fair LTE-U is in allowing Wi-Fi
to start transmitting beacons on a channel that it occupies with a very large
duty cycle. According to the LTE-U specification, if a LTE-U base station
determines that a channel is vacant, it can transmit for up to 20 ms and turn
OFF for only 1 ms, resulting in a duty cycle of 95%. In an area with heavy
spectrum usage, there will be cases when a Wi-Fi access point wishes to share
the same channel, as it does today with Wi-Fi. We study, both theoretically and
experimentally, the effect that such a large LTE-U duty cycle can have on the
association process, specifically Wi-Fi beacon transmission and reception. We
demonstrate via an experimental set-up using National Instrument (NI) USRPs
that a significant percentage of Wi-Fi beacons will either not be transmitted
in a timely fashion or will not be received at the LTE-U BS thus making it
difficult for the LTE-U BS to adapt its duty cycle in response to the Wi-Fi
usage. Our experimental results corroborate our theoretical analysis. We
compare the results with Wi-Fi/Wi-Fi coexistence and demonstrate that
LTE-U/Wi-Fi coexistence is not fair when it comes to initial association since
there is a much larger percentage of beacon errors in the latter case. Hence,
the results in the paper indicate that in order to maintain association
fairness, a LTE-U BS should not transmit at such high duty cycles, even if it
deems the channel to be vacant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03818</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03818</id><created>2018-01-05</created><authors><author><keyname>Liang</keyname><forenames>Yunyi</forenames></author><author><keyname>Cui</keyname><forenames>Zhiyong</forenames></author><author><keyname>Tian</keyname><forenames>Yu</forenames></author><author><keyname>Chen</keyname><forenames>Huimiao</forenames></author><author><keyname>Wang</keyname><forenames>Yinhai</forenames></author></authors><title>A Deep Generative Adversarial Architecture for Network-Wide
  Spatial-Temporal Traffic State Estimation</title><categories>eess.SP math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study proposes a deep generative adversarial architecture (GAA) for
network-wide spatial-temporal traffic state estimation. The GAA is able to
combine traffic flow theory with neural networks and thus improve the accuracy
of traffic state estimation. It consists of two Long Short-Term Memory Neural
Networks (LSTM NNs) which capture correlation in time and space among traffic
flow and traffic density. One of the LSTM NNs, called a discriminative network,
aims to maximize the probability of assigning correct labels to both true
traffic state matrices (i.e., traffic flow and traffic density within a given
spatial-temporal area) and the traffic state matrices generated from the other
neural network. The other LSTM NN, called a generative network, aims to
generate traffic state matrices which maximize the probability that the
discriminative network assigns true labels to them. The two LSTM NNs are
trained simultaneously such that the trained generative network can generate
traffic matrices similar to those in the training data set. Given a traffic
state matrix with missing values, we use back-propagation on three defined loss
functions to map the corrupted matrix to a latent space. The mapping vector is
then passed through the pre-trained generative network to estimate the missing
values of the corrupted matrix. The proposed GAA is compared with the existing
Bayesian network approach on loop detector data collected from Seattle,
Washington and that collected from San Diego, California. Experimental results
indicate that the GAA can achieve higher accuracy in traffic state estimation
than the Bayesian network approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03819</identifier>
 <datestamp>2018-12-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03819</id><created>2018-01-04</created><updated>2018-12-06</updated><authors><author><keyname>M.</keyname><forenames>Akshatha Nayak</forenames></author><author><keyname>Roy</keyname><forenames>Arghyadip</forenames></author><author><keyname>Jha</keyname><forenames>Pranav</forenames></author><author><keyname>Karandikar</keyname><forenames>Abhay</forenames></author></authors><title>Control and Management of Multiple RATs in Wireless Networks: An SDN
  Approach</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Telecom operators are using a variety of Radio Access Technologies (RATs) for
providing services to mobile subscribers. This development has emphasized the
requirement for unified control and management of diverse RATs. Although
multiple RATs co-exist within today's cellular networks, each RAT is controlled
by a set of different entities. This may lead to suboptimal utilization of the
overall network resources. In this article, we review various architectures for
multi-RAT control proposed by both industry and academia. We also propose a
novel SDN based network architecture for end-to-end control and management of
diverse RATs. The architecture is scalable and provides a framework for
improved network performance over the present day architecture and proposals in
existing literature. Our architecture also provides a framework for deployment
of applications in a RAT agnostic fashion. It facilitates network slicing and
enables the provision of Quality of Service (QoS) guarantees to the end user.
We have also developed an evaluation platform based on ns-3 to evaluate the
performance offered by the architecture. Experimental results obtained using
the platform demonstrate the benefits provided by our architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03824</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03824</id><created>2018-01-02</created><authors><author><keyname>Nayak</keyname><forenames>Akshatha M.</forenames></author><author><keyname>Jha</keyname><forenames>Pranav</forenames></author><author><keyname>Karandikar</keyname><forenames>Abhay</forenames></author></authors><title>A Centralized SDN Architecture for the 5G Cellular Network</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to meet the increasing demands of high data rate and low latency
cellular broadband applications, plans are underway to roll out the Fifth
Generation (5G) cellular wireless system by the year 2020. This paper proposes
a novel method for adapting the Third Generation Partnership Project (3GPP)'s
5G architecture to the principles of Software Defined Networking (SDN). We
propose to have centralized network functions in the 5G network core to control
the network, end-to-end. This is achieved by relocating the control
functionality present in the 5G Radio Access Network (RAN) to the network core,
resulting in the conversion of the base station known as the gNB into a pure
data plane node. This brings about a significant reduction in signaling costs
between the RAN and the core network. It also results in improved system
performance. The merits of our proposal have been illustrated by evaluating the
Key Performance Indicators (KPIs) of the 5G network, such as network attach
(registration) time and handover time. We have also demonstrated improvements
in attach time and system throughput due to the use of centralized algorithms
for mobility management with the help of ns-3 simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03835</identifier>
 <datestamp>2018-10-10</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03835</id><created>2017-12-26</created><updated>2018-10-08</updated><authors><author><keyname>Zhang</keyname><forenames>Qingqing</forenames></author><author><keyname>Fang</keyname><forenames>Wen</forenames></author><author><keyname>Liu</keyname><forenames>Qingwen</forenames></author><author><keyname>Wu</keyname><forenames>Jun</forenames></author><author><keyname>Xia</keyname><forenames>Pengfei</forenames></author><author><keyname>Yang</keyname><forenames>Liuqing</forenames></author></authors><title>Distributed Laser Charging: A Wireless Power Transfer Approach</title><categories>eess.SP</categories><comments>add table IV</comments><doi>10.1109/JIOT.2018.2851070</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless power transfer (WPT) is a promising solution to provide convenient
and perpetual energy supplies to electronics. Traditional WPT technologies face
the challenge of providing Watt-level power over meter-level distance for
Internet of Things (IoT) and mobile devices, such as sensors, controllers,
smart-phones, laptops, etc.. Distributed laser charging (DLC), a new WPT
alternative, has the potential to solve these problems and enable WPT with the
similar experience as WiFi communications. In this paper, we present a
multi-module DLC system model, in order to illustrate its physical fundamentals
and mathematical formula. This analytical modeling enables the evaluation of
power conversion or transmission for each individual module, considering the
impacts of laser wavelength, transmission attenuation and photovoltaic-cell
(PV-cell) temperature. Based on the linear approximation of
electricity-to-laser and laser-to-electricity power conversion validated by
measurement and simulation, we derive the maximum power transmission efficiency
in closed-form. Thus, we demonstrate the variation of the maximum power
transmission efficiency depending on the supply power at the transmitter, laser
wavelength, transmission distance, and PV-cell temperature. Similar to the
maximization of information transmission capacity in wireless information
transfer (WIT), the maximization of the power transmission efficiency is
equally important in WPT. Therefore, this work not only provides the insight of
DLC in theory, but also offers the guideline of DLC system design in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.03862</identifier>
 <datestamp>2019-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.03862</id><created>2018-01-11</created><updated>2019-01-30</updated><authors><author><keyname>Shafipour</keyname><forenames>Rasoul</forenames></author><author><keyname>Segarra</keyname><forenames>Santiago</forenames></author><author><keyname>Marques</keyname><forenames>Antonio G.</forenames></author><author><keyname>Mateos</keyname><forenames>Gonzalo</forenames></author></authors><title>Identifying the Topology of Undirected Networks from Diffused
  Non-stationary Graph Signals</title><categories>eess.SP cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of inferring an undirected graph from nodal
observations, which are modeled as non-stationary graph signals generated by
local diffusion dynamics that depend on the structure of the unknown network.
Using the so-called graph-shift operator (GSO), which is a matrix
representation of the graph, we first identify the eigenvectors of the shift
matrix from realizations of the diffused signals, and then estimate the
eigenvalues by imposing desirable properties on the graph to be recovered.
Different from the stationary setting where the eigenvectors can be obtained
directly from the covariance matrix of the observations, here we need to
estimate first the unknown diffusion (graph) filter -- a polynomial in the GSO
that preserves the sought eigenbasis. To carry out this initial system
identification step, we exploit different sources of information on the
arbitrarily-correlated input signal driving the diffusion on the graph. We
first explore the simpler case where the observations, the input information,
and the unknown graph filter are linearly related. We then address the case
where the relation is given by a system of matrix quadratic equations, which
arises in pragmatic scenarios where only the second-order statistics of the
inputs are available. While such quadratic filter identification problem boils
down to a non-convex fourth-order polynomial minimization, we discuss
identifiability conditions, propose algorithms to approximate the solution and
analyze their performance. Numerical tests illustrate the effectiveness of the
proposed topology inference algorithms in recovering brain, social, financial
and urban transportation networks using synthetic and real-world signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04052</identifier>
 <datestamp>2018-02-20</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04052</id><created>2018-01-11</created><updated>2018-02-16</updated><authors><author><keyname>Lee</keyname><forenames>Wei-Jen</forenames></author><author><keyname>Wang</keyname><forenames>Syu-Siang</forenames></author><author><keyname>Chen</keyname><forenames>Fei</forenames></author><author><keyname>Lu</keyname><forenames>Xugang</forenames></author><author><keyname>Chien</keyname><forenames>Shao-Yi</forenames></author><author><keyname>Tsao</keyname><forenames>Yu</forenames></author></authors><title>Speech Dereverberation Based on Integrated Deep and Ensemble Learning
  Algorithm</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reverberation, which is generally caused by sound reflections from walls,
ceilings, and floors, can result in severe performance degradation of acoustic
applications. Due to a complicated combination of attenuation and time-delay
effects, the reverberation property is difficult to characterize, and it
remains a challenging task to effectively retrieve the anechoic speech signals
from reverberation ones. In the present study, we proposed a novel integrated
deep and ensemble learning algorithm (IDEA) for speech dereverberation. The
IDEA consists of offline and online phases. In the offline phase, we train
multiple dereverberation models, each aiming to precisely dereverb speech
signals in a particular acoustic environment; then a unified fusion function is
estimated that aims to integrate the information of multiple dereverberation
models. In the online phase, an input utterance is first processed by each of
the dereverberation models. The outputs of all models are integrated
accordingly to generate the final anechoic signal. We evaluated the IDEA on
designed acoustic environments, including both matched and mismatched
conditions of the training and testing data. Experimental results confirm that
the proposed IDEA outperforms single deep-neural-network-based dereverberation
model with the same model architecture and training data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04081</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04081</id><created>2018-01-12</created><authors><author><keyname>Park</keyname><forenames>Jeongsoo</forenames></author><author><keyname>Shin</keyname><forenames>Jaeyoung</forenames></author><author><keyname>Lee</keyname><forenames>Kyogu</forenames></author></authors><title>Separation of Instrument Sounds using Non-negative Matrix Factorization
  with Spectral Envelope Constraints</title><categories>cs.SD cs.MM eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral envelope is one of the most important features that characterize the
timbre of an instrument sound. However, it is difficult to use spectral
information in the framework of conventional spectrogram decomposition methods.
We overcome this problem by suggesting a simple way to provide a constraint on
the spectral envelope calculated by linear prediction. In the first part of
this study, we use a pre-trained spectral envelope of known instruments as the
constraint. Then we apply the same idea to a blind scenario in which the
instruments are unknown. The experimental results reveal that the proposed
method outperforms the conventional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04131</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04131</id><created>2018-01-12</created><authors><author><keyname>Karrenbauer</keyname><forenames>Michael</forenames></author><author><keyname>Weinand</keyname><forenames>Andreas</forenames></author><author><keyname>Schotten</keyname><forenames>Hans D.</forenames></author></authors><title>On Partly Overloaded Spreading Sequences with Variable Spreading Factor</title><categories>eess.SP cs.IT cs.NI math.IT</categories><comments>6 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future wireless communications systems are expected to support multi-service
operation, i.e. especially multi-rate as well as multi-level quality of service
(QoS) requirements. This evolution is mainly driven by the success of the
Internet of Things (IoT) and the growing presence of machine type communication
(MTC). Whereas in the last years information in wireless communication systems
was mainly generated or at least requested by humans and was also processed by
humans, we can now see a paradigm shift since so-called machine type
communication is gaining growing importance. Along with these changes we also
encounter changes regarding the quality of service requirements, data rate
requirements, latency constraints, different duty cycles et cetera. The
challenge for new communication systems will therefore be to enable different
user types and their different requirements efficiently. In this paper, we
present partly overloaded spreading sequences, i.e. sequences which are
globally orthogonal and sequences which interfere with a subset of sequences
while being orthogonal to the globally orthogonal sequences. Additionally, we
are able to vary the spreading factor of these sequences, which allows us to
flexibly assign appropriate sequences to different service types or user types
respectively. We propose the use of these sequences for a CDMA channel access
method which is able to flexibly support different traffic types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04270</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04270</id><created>2018-01-11</created><updated>2019-02-08</updated><authors><author><keyname>Bedeer</keyname><forenames>Ebrahim</forenames></author><author><keyname>Marey</keyname><forenames>Mohamed</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia</forenames></author><author><keyname>Baddour</keyname><forenames>Kareem</forenames></author></authors><title>On Partially Overlapping Coexistence for Dynamic Spectrum Access in
  Cognitive Radio</title><categories>eess.SP cs.IT math.IT</categories><comments>CAMAD 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study partially overlapping co-existence scenarios in
cognitive radio environment. We consider an Orthogonal Frequency Division
Multiplexing (OFDM) cognitive system coexisting with a narrow-band (NB) and an
OFDM primary system, respectively. We focus on finding the minimum frequency
separation between the coexisting systems to meet a certain target BER.
Windowing and nulling are used as simple techniques to reduce the OFDM
out-of-band radiations, and, hence decrease the separation. The effect of these
techniques on the OFDM spectral efficiency and PAPR is also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04307</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04307</id><created>2017-12-10</created><authors><author><keyname>Wang</keyname><forenames>Shaogang</forenames></author><author><keyname>Patel</keyname><forenames>Vishal M.</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina</forenames></author></authors><title>Robust Sparse Fourier Transform Based on The Fourier Projection-Slice
  Theorem</title><categories>eess.SP cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The state-of-the-art automotive radars employ multidimensional discrete
Fourier transforms (DFT) in order to estimate various target parameters. The
DFT is implemented using the fast Fourier transform (FFT), at sample and
computational complexity of $O(N)$ and $O(N \log N)$, respectively, where $N$
is the number of samples in the signal space. We have recently proposed a
sparse Fourier transform based on the Fourier projection-slice theorem
(FPS-SFT), which applies to multidimensional signals that are sparse in the
frequency domain. FPS-SFT achieves sample complexity of $O(K)$ and
computational complexity of $O(K \log K)$ for a multidimensional, $K$-sparse
signal. While FPS-SFT considers the ideal scenario, i.e., exactly sparse data
that contains on-grid frequencies, in this paper, by extending FPS-SFT into a
robust version (RFPS-SFT), we emphasize on addressing noisy signals that
contain off-grid frequencies; such signals arise from radar applications. This
is achieved by employing a windowing technique and a voting-based frequency
decoding procedure; the former reduces the frequency leakage of the off-grid
frequencies below the noise level to preserve the sparsity of the signal, while
the latter significantly lowers the frequency localization error stemming from
the noise. The performance of the proposed method is demonstrated both
theoretically and numerically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04541</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04541</id><created>2018-01-14</created><authors><author><keyname>de Vrieze</keyname><forenames>Colin</forenames></author><author><keyname>Barratt</keyname><forenames>Shane</forenames></author><author><keyname>Tsai</keyname><forenames>Daniel</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Cooperative Multi-Agent Reinforcement Learning for Low-Level Wireless
  Communication</title><categories>eess.SP cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Traditional radio systems are strictly co-designed on the lower levels of the
OSI stack for compatibility and efficiency. Although this has enabled the
success of radio communications, it has also introduced lengthy standardization
processes and imposed static allocation of the radio spectrum. Various
initiatives have been undertaken by the research community to tackle the
problem of artificial spectrum scarcity by both making frequency allocation
more dynamic and building flexible radios to replace the static ones. There is
reason to believe that just as computer vision and control have been overhauled
by the introduction of machine learning, wireless communication can also be
improved by utilizing similar techniques to increase the flexibility of
wireless networks. In this work, we pose the problem of discovering low-level
wireless communication schemes ex-nihilo between two agents in a fully
decentralized fashion as a reinforcement learning problem. Our proposed
approach uses policy gradients to learn an optimal bi-directional communication
scheme and shows surprisingly sophisticated and intelligent learning behavior.
We present the results of extensive experiments and an analysis of the fidelity
of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04627</identifier>
 <datestamp>2018-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04627</id><created>2018-01-14</created><updated>2018-02-12</updated><authors><author><keyname>Chen</keyname><forenames>Yifan</forenames></author><author><keyname>Zhou</keyname><forenames>Yu</forenames></author><author><keyname>Murch</keyname><forenames>Ross</forenames></author><author><keyname>Nakano</keyname><forenames>Tadashi</forenames></author></authors><title>Molecular Communications at the Macroscale: A Novel Framework for
  Modeling Epidemic Spreading and Mitigation</title><categories>physics.soc-ph eess.SP</categories><comments>16 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the notion of effective distance proposed by Brockmann and Helbing,
complex spatiotemporal processes of epidemic spreading can be reduced to
circular wave propagation patterns with well-defined wavefronts. This hidden
homogeneity of contagion phenomena enables the mapping of virtual mobility
networks to physical propagation channels. Subsequently, we propose a novel
communications-inspired model of epidemic spreading and mitigation by
establishing the one-to-one correspondence between the essential components
comprising information and disease transmissions. The epidemic processes can be
regarded as macroscale molecular communications, in which individuals are
macroscale information molecules carrying messages (epidemiological states). We
then present the notions of normalized ensemble-average prevalence (NEAP) and
prevalence delay profile (PDP) to characterize the relative impact and time
difference of all the spreading paths, which are analogous to the classical
description methods of path loss and power delay profile in communications.
Furthermore, we introduce the metric of root mean square (RMS) delay spread to
measure the distortion of early contagion dynamics caused by multiple infection
transmission routes. In addition, we show how social and medical interventions
can be understood from the perspectives of various communication modules. The
proposed framework provides an intuitive, coherent, and efficient approach for
characterization of the disease outbreaks by applying the deep-rooted
communications theories as the analytical lens.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04744</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04744</id><created>2018-01-15</created><authors><author><keyname>Shakya</keyname><forenames>Rajeev K.</forenames><affiliation>Department of Electrical and Electronics Engineering, Galgotia College of Engineering and Technology Greater noida</affiliation></author></authors><title>Modified SI Epidemic Model for Combating Virus Spread in Spatially
  Correlated Wireless Sensor Networks</title><categories>cs.NI eess.SP</categories><report-no>Report No.01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless sensor networks (WSNs), main task of each sensor node is to sense
the physical activity (i.e., targets or disaster conditions) and then to report
it to the control center for further process. For this, sensor nodes are
attached with many sensors having ability to measure the environmental
information. Spatial correlation between nodes exists in such wireless sensor
network based on common sensory coverage and then the redundant data
communication is observed. To study virus spreading dynamics in such scenario,
a modified SI epidemic model is derived mathematically by incorporating WSN
parameters such as spatial correlation, node density, sensing range,
transmission range, total sensor nodes etc. The solution for proposed SI model
is also determined to study the dynamics with time. Initially, a small number
of nodes are attacked by viruses and then virus infection propagates through
its neighboring nodes over normal data communication. Since redundant nodes
exists in correlated sensor field, virus spread process could be different with
different sensory coverage. The proposed SI model captures spatial and temporal
dynamics than existing ones which are global. The infection process leads to
network failure. By exploiting spatial correlation between nodes, spread
control scheme is developed to limit the further infection in the network.
Numerical result analysis is provided with comparison for validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04749</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04749</id><created>2018-01-15</created><updated>2018-01-16</updated><authors><author><keyname>Cheung</keyname><forenames>Gene</forenames></author><author><keyname>Magli</keyname><forenames>Enrico</forenames></author><author><keyname>Tanaka</keyname><forenames>Yuichi</forenames></author><author><keyname>Ng</keyname><forenames>Michael</forenames></author></authors><title>Graph Spectral Image Processing</title><categories>eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advent of graph signal processing (GSP) has spurred intensive studies
of signals that live naturally on irregular data kernels described by graphs
(e.g., social networks, wireless sensor networks). Though a digital image
contains pixels that reside on a regularly sampled 2D grid, if one can design
an appropriate underlying graph connecting pixels with weights that reflect the
image structure, then one can interpret the image (or image patch) as a signal
on a graph, and apply GSP tools for processing and analysis of the signal in
graph spectral domain. In this article, we overview recent graph spectral
techniques in GSP specifically for image / video processing. The topics covered
include image compression, image restoration, image filtering and image
segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04775</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04775</id><created>2018-01-15</created><authors><author><keyname>Shu</keyname><forenames>Feng</forenames></author><author><keyname>Wang</keyname><forenames>Zhengwang</forenames></author><author><keyname>Chen</keyname><forenames>Riqing</forenames></author><author><keyname>Wu</keyname><forenames>Yongpeng</forenames></author><author><keyname>Wang</keyname><forenames>Jiangzhou</forenames></author></authors><title>Two High-performance Schemes of Transmit Antenna Selection for Secure
  Spatial Modulation</title><categories>cs.IT cs.CR eess.SP math.IT</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, a secure spatial modulation (SM) system with artificial noise
(AN)-aided is investigated. To achieve higher secrecy rate (SR) in such a
system, two high-performance schemes of transmit antenna selection (TAS),
leakage-based and maximum secrecy rate (Max-SR), are proposed and a generalized
Euclidean distance-optimized antenna selection (EDAS) method is designed. From
simulation results and analysis, the four TAS schemes have an decreasing order:
Max-SR, leakage-based, generalized EDAS, and random (conventional), in terms of
SR performance. However, the proposed Max-SR method requires the exhaustive
search to achieve the optimal SR performance, thus its complexity is extremely
high as the number of antennas tends to medium and large scale. The proposed
leakage-based method approaches the Max-SR method with much lower complexity.
Thus, it achieves a good balance between complexity and SR performance. In
terms of bit error rate (BER), their performances are in an increasing order:
random, leakage-based, Max-SR, and generalized EDAS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04907</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04907</id><created>2018-01-15</created><authors><author><keyname>Baknina</keyname><forenames>Abdulrahman</forenames></author><author><keyname>Ozel</keyname><forenames>Omur</forenames></author><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Sending Information Through Status Updates</title><categories>cs.IT cs.NI eess.SP math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an energy harvesting transmitter sending status updates regarding
a physical phenomenon it observes to a receiver. Different from the existing
literature, we consider a scenario where the status updates carry information
about an independent message. The transmitter encodes this message into the
timings of the status updates. The receiver needs to extract this encoded
information, as well as update the status of the observed phenomenon. The
timings of the status updates, therefore, determine both the age of information
(AoI) and the message rate (rate). We study the tradeoff between the achievable
message rate and the achievable average AoI. We propose several achievable
schemes and compare their rate-AoI performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04981</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.04981</id><created>2017-12-16</created><authors><author><keyname>Ali</keyname><forenames>Md Shipon</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author><author><keyname>Al-Dweik</keyname><forenames>Arafat</forenames></author><author><keyname>Kim</keyname><forenames>Dong In</forenames></author></authors><title>Downlink Power Allocation for CoMP-NOMA in Multi-Cell Networks</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers the problem of dynamic power allocation in the downlink
of multi-cell networks, where each cell utilizes non-orthogonal multiple access
(NOMA)-based resource allocation. Also, coordinated multi-point (CoMP)
transmission is utilized among multiple cells to serve users experiencing
severe inter-cell interference (ICI). More specifically, we consider a two-tier
heterogeneous network (HetNet) consisting of a high-power macro cell underlaid
with multiple low-power small cells each of which uses the same resource block.
Under this {\em CoMP-NOMA framework}, CoMP transmission is applied to a user
experiencing high channel gain with multiple base stations (BSs)/cells, while
NOMA is utilized to schedule CoMP and non-CoMP users over the same transmission
resources, i.e., time, spectrum and space. Different CoMP-NOMA models are
discussed, but focus is primarily on the joint transmission CoMP-NOMA
(JT-CoMP-NOMA) model. For the JT-CoMP-NOMA model, an optimal joint power
allocation problem is formulated and the solution is derived for each CoMP-set
consisting of multiple cooperating BSs (i.e., CoMP BSs). To overcome the
substantial computational complexity of the joint power optimization approach,
we propose a distributed power optimization problem at each cooperating BS
whose optimal solution is independent of the solution of other coordinating
BSs. The validity of the distributed solution for the joint power optimization
problem is provided and numerical performance evaluation is carried out for the
proposed CoMP-NOMA models including JT-CoMP-NOMA and coordinated scheduling
CoMP-NOMA (CS-CoMP-NOMA). The obtained results reveal significant gains in
spectral and energy efficiency in comparison with conventional CoMP-orthogonal
multiple access (CoMP-OMA) systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05000</identifier>
 <datestamp>2018-08-29</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05000</id><created>2018-01-04</created><updated>2018-08-28</updated><authors><author><keyname>Zhang</keyname><forenames>Shuhang</forenames></author><author><keyname>Zhang</keyname><forenames>Hongliang</forenames></author><author><keyname>Di</keyname><forenames>Boya</forenames></author><author><keyname>Song</keyname><forenames>Lingyang</forenames></author></authors><title>Cellular UAV-to-X Communications: Design and Optimization for Multi-UAV
  Networks</title><categories>eess.SP</categories><comments>30 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a single-cell cellular network with a number of
cellular users (CUs) and unmanned aerial vehicles (UAVs), in which multiple
UAVs upload their collected data to the base station (BS). Two transmission
modes are considered to support the multi-UAV communications, i.e.,
UAV-to-infrastructure (U2I) and UAV-to-UAV (U2U) communications. Specifically,
the UAV with a high signal to noise ratio (SNR) for the U2I link uploads its
collected data directly to the BS through U2I communication, while the UAV with
a low SNR for the U2I link can transmit data to a nearby UAV through
underlaying U2U communication for the sake of quality of service. We first
propose a cooperative UAV sense-and-send protocol to enable the UAV-to-X
communications, and then formulate the subchannel allocation and UAV speed
optimization problem to maximize the uplink sum-rate. To solve this NP-hard
problem efficiently, we decouple it into three sub-problems: U2I and cellular
user (CU) subchannel allocation, U2U subchannel allocation, and UAV speed
optimization. An iterative subchannel allocation and speed optimization
algorithm (ISASOA) is proposed to solve these sub-problems jointly. Simulation
results show that the proposed ISASOA can upload 10\% more data than the greedy
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05082</identifier>
 <datestamp>2018-04-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05082</id><created>2018-01-15</created><updated>2018-04-16</updated><authors><author><keyname>Chen</keyname><forenames>Yingpin</forenames></author><author><keyname>Peng</keyname><forenames>Zhenming</forenames></author><author><keyname>Gholami</keyname><forenames>Ali</forenames></author><author><keyname>Yan</keyname><forenames>Jingwen</forenames></author><author><keyname>Li</keyname><forenames>Shu</forenames></author></authors><title>Seismic signal sparse time-frequency analysis by Lp-quasinorm constraint</title><categories>eess.SP math.NA</categories><comments>12 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time-frequency analysis has been applied successfully in many fields.
However, the traditional methods, like short time Fourier transform and Cohen
distribution, suffer from the low resolution or the interference of the cross
terms. To solve these issues, we put forward a new sparse time-frequency
analysis model by using the Lp-quasinorm constraint, which is capable of
fitting the sparsity prior knowledge in the frequency domain. In the proposed
model, we regard the short time truncated data as the observation of sparse
representation and design a dictionary matrix, which builds up the relationship
between the short time measurement and the sparse spectrum. Based on the
relationship and the Lp-quasinorm feasible domain, the proposed model is
established. The alternating direction method of multipliers (ADMM) is adopted
to solve the proposed model. Experiments are then conducted on several
theoretical signals and applied to the seismic signal spectrum decomposition,
indicating that the proposed method is able to obtain a higher time-frequency
distribution than state-of-the-art time-frequency methods. Thus, the proposed
method is of great importance to reservoir exploration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05210</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05210</id><created>2018-01-16</created><authors><author><keyname>Jiang</keyname><forenames>Xiaoda</forenames></author><author><keyname>Lu</keyname><forenames>Hancheng</forenames></author><author><keyname>Chen</keyname><forenames>Chang Wen</forenames></author></authors><title>Enabling Quality-Driven Scalable Video Transmission over Multi-User NOMA
  System</title><categories>cs.IT cs.MM cs.NI eess.SP math.IT</categories><comments>9 pages, 6 figures. This paper has already been accepted by IEEE
  INFOCOM 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, non-orthogonal multiple access (NOMA) has been proposed to achieve
higher spectral efficiency over conventional orthogonal multiple access.
Although it has the potential to meet increasing demands of video services, it
is still challenging to provide high performance video streaming. In this
research, we investigate, for the first time, a multi-user NOMA system design
for video transmission. Various NOMA systems have been proposed for data
transmission in terms of throughput or reliability. However, the perceived
quality, or the quality-of-experience of users, is more critical for video
transmission. Based on this observation, we design a quality-driven scalable
video transmission framework with cross-layer support for multi-user NOMA. To
enable low complexity multi-user NOMA operations, a novel user grouping
strategy is proposed. The key features in the proposed framework include the
integration of the quality model for encoded video with the physical layer
model for NOMA transmission, and the formulation of multi-user NOMA-based video
transmission as a quality-driven power allocation problem. As the problem is
non-concave, a global optimal algorithm based on the hidden monotonic property
and a suboptimal algorithm with polynomial time complexity are developed.
Simulation results show that the proposed multi-user NOMA system outperforms
existing schemes in various video delivery scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05351</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05351</id><created>2018-01-14</created><authors><author><keyname>Wang</keyname><forenames>Haichao</forenames></author><author><keyname>Ren</keyname><forenames>Guochun</forenames></author><author><keyname>Chen</keyname><forenames>Jin</forenames></author><author><keyname>Ding</keyname><forenames>Guoru</forenames></author><author><keyname>Yang</keyname><forenames>Yijun</forenames></author></authors><title>Unmanned Aerial Vehicle-Aided Communications: Joint Transmit Power and
  Trajectory Optimization</title><categories>eess.SP</categories><comments>IEEE Wireless Communications Letters, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter investigates the transmit power and trajectory optimization
problem for unmanned aerial vehicle (UAV)-aided networks. Different from
majority of the existing studies with fixed communication infrastructure, a
dynamic scenario is considered where a flying UAV provides wireless services
for multiple ground nodes simultaneously. To fully exploit the controllable
channel variations provided by the UAV's mobility, the UAV's transmit power and
trajectory are jointly optimized to maximize the minimum average throughput
within a given time length. For the formulated non-convex optimization with
power budget and trajectory constraints, this letter presents an efficient
joint transmit power and trajectory optimization algorithm. Simulation results
validate the effectiveness of the proposed algorithm and reveal that the
optimized transmit power shows a water-filling characteristic in spatial
domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05353</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05353</id><created>2018-01-12</created><updated>2019-02-08</updated><authors><author><keyname>Bedeer</keyname><forenames>Ebrahim</forenames></author><author><keyname>Amin</keyname><forenames>Osama</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Ahmed</keyname><forenames>Mohamed H.</forenames></author><author><keyname>Baddour</keyname><forenames>Kareem E.</forenames></author></authors><title>Energy-Efficient Power Loading for OFDM-based Cognitive Radio Systems
  with Channel Uncertainties</title><categories>eess.SP cs.IT math.IT</categories><comments>TVT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel algorithm to optimize the energy-efficiency
(EE) of orthogonal frequency division multiplexing-based cognitive radio
systems under channel uncertainties. We formulate an optimization problem that
guarantees a minimum required rate and a specified power budget for the
secondary user (SU), while restricting the interference to primary users (PUs)
in a statistical manner. The optimization problem is non-convex and it is
transformed to an equivalent problem using the concept of fractional
programming. Unlike all related works in the literature, we consider the effect
of imperfect channel-stateinformation (CSI) on the links between the SU
transmitter and receiver pairs and we additionally consider the effect of
limited sensing capabilities of the SU. Since the interference constraints are
met statistically, the SU transmitter does not require perfect CSI feedback
from the PUs receivers. Simulation results sho w that the EE deteriorates as
the channel estimation error increases. Comparisons with relevant works from
the literature show that the interference thresholds at the PUs receivers can
be severely exceeded and the EE is slightly deteriorated if the SU does no t
account for spectrum sensing errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05356</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05356</id><created>2018-01-16</created><authors><author><keyname>Zhang</keyname><forenames>Pengfei</forenames></author><author><keyname>Nevat</keyname><forenames>Ido</forenames></author><author><keyname>Peters</keyname><forenames>Gareth W.</forenames></author><author><keyname>Septier</keyname><forenames>Francois</forenames></author><author><keyname>Osborne</keyname><forenames>Michael A.</forenames></author></authors><title>Spatial Field Reconstruction and Sensor Selection in Heterogeneous
  Sensor Networks with Stochastic Energy Harvesting</title><categories>eess.SP</categories><doi>10.1109/TSP.2018.2802452</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the two fundamental problems of spatial field reconstruction and
sensor selection in het- erogeneous sensor networks. We consider the case where
two types of sensors are deployed: the first consists of expensive, high
quality sensors; and the second, of cheap low quality sensors, which are
activated only if the intensity of the spatial field exceeds a pre-defined
activation threshold (eg. wind sensors). In addition, these sensors are powered
by means of energy harvesting and their time varying energy status impacts on
the accuracy of the measurement that may be obtained. We account for this
phenomenon by encoding the energy harvesting process into the second moment
properties of the additive noise, resulting in a spatial heteroscedastic
process. We then address the following two important problems: (i) how to
efficiently perform spatial field reconstruction based on measurements obtained
simultaneously from both networks; and (ii) how to perform query based sensor
set selection with predictive MSE performance guarantee. We first show that the
resulting predictive posterior distribution, which is key in fusing such
disparate observations, involves solving intractable integrals. To overcome
this problem, we solve the first problem by developing a low complexity
algorithm based on the spatial best linear unbiased estimator (S-BLUE). Next,
building on the S-BLUE, we address the second problem, and develop an efficient
algorithm for query based sensor set selection with performance guarantee. Our
algorithm is based on the Cross Entropy method which solves the combinatorial
optimization problem in an efficient manner. We present a comprehensive study
of the performance gain that can be obtained by augmenting the high-quality
sensors with low-quality sensors using both synthetic and real insurance storm
surge database known as the Extreme Wind Storms Catalogue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05363</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05363</id><created>2018-01-11</created><authors><author><keyname>Garcia</keyname><forenames>P.</forenames></author><author><keyname>Dominguez</keyname><forenames>X.</forenames></author><author><keyname>Chiza</keyname><forenames>D.</forenames></author></authors><title>Non Intrusive Load Monitoring in Chaotic Switching Networks</title><categories>eess.SP nlin.CD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a non intrusive load disaggregation scheme is proposed. By
using a kernel based nonlinear regression strategy, the switching dynamic of an
electric network, simulated as a set of RLC circuits with chaotic switching, is
approximated using a time series of the total power consumption. The results
suggest that the employed methodology can be useful in the design of efficient
load disaggregation schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05388</identifier>
 <datestamp>2018-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05388</id><created>2017-12-17</created><updated>2018-01-27</updated><authors><author><keyname>Hu</keyname><forenames>Zhiwen</forenames></author><author><keyname>Zheng</keyname><forenames>Zijie</forenames></author><author><keyname>Song</keyname><forenames>Lingyang</forenames></author><author><keyname>Wang</keyname><forenames>Tao</forenames></author><author><keyname>Li</keyname><forenames>Xiaoming</forenames></author></authors><title>UAV Offloading: Spectrum Trading Contract Design for UAV Assisted 5G
  Networks</title><categories>eess.SP cs.NI cs.SI</categories><comments>30 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned Aerial Vehicle (UAV) has been recognized as a promising way to
assist future wireless communications due to its high flexibility of deployment
and scheduling. In this paper, we focus on temporarily deployed UAVs that
provide downlink data offloading in some regions under a macro base station
(MBS). Since the manager of the MBS and the operators of the UAVs could be of
different interest groups, we formulate the corresponding spectrum trading
problem by means of contract theory, where the manager of the MBS has to design
an optimal contract to maximize its own revenue. Such contract comprises a set
of bandwidth options and corresponding prices, and each UAV operator only
chooses the most profitable one from all the options in the whole contract. We
analytically derive the optimal pricing strategy based on fixed bandwidth
assignment, and then propose a dynamic programming algorithm to calculate the
optimal bandwidth assignment in polynomial time. By simulations, we compare the
outcome of the MBS optimal contract with that of a social optimal one, and find
that a selfish MBS manager sells less bandwidth to the UAV operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05405</identifier>
 <datestamp>2018-11-27</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05405</id><created>2018-01-16</created><updated>2018-11-21</updated><authors><author><keyname>Hattab</keyname><forenames>Ghaith</forenames></author><author><keyname>Visotsky</keyname><forenames>Eugene</forenames></author><author><keyname>Cudak</keyname><forenames>Mark</forenames></author><author><keyname>Ghosh</keyname><forenames>Amitava</forenames></author></authors><title>Uplink Interference Mitigation Techniques for Coexistence of 5G mmWave
  Users with Incumbents at 70 and 80 GHz</title><categories>eess.SP</categories><comments>This work is accepted for publication in the IEEE Transactions on
  Wireless Communications</comments><doi>10.1109/TWC.2018.2879509</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The millimeter wave spectra at 71-76GHz (70GHz) and 81-86GHz (80GHz) have the
potential to endow fifth-generation new radio (5G-NR) with mobile connectivity
at gigabit rates. However, a pressing issue is the presence of incumbent
systems in these bands, which are primarily point-to-point fixed stations
(FSs). In this paper, we first identify the key properties of incumbents by
parsing databases of existing stations in major cities to devise several
modeling guidelines and characterize their deployment geometry and antenna
specifications. Second, we develop a detailed uplink interference framework to
compute the aggregate interference from outdoor 5G-NR users into FSs. We then
present several case studies in dense populated areas, using actual incumbent
databases and building layouts. Our simulation results demonstrate promising 5G
coexistence at 70GHz and 80GHz as the majority of FSs experience interference
well below the noise floor thanks to the propagation losses in these bands and
the deployment geometry of the incumbent and 5G systems. For the few FSs that
may incur higher interference, we propose several passive interference
mitigation techniques such as angular-based exclusion zones and spatial power
control. Simulation results show that the techniques can effectively protect
FSs, without tangible degradation of the 5G coverage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05458</identifier>
 <datestamp>2018-02-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05458</id><created>2018-01-16</created><updated>2018-02-22</updated><authors><author><keyname>Vu</keyname><forenames>Tiep</forenames></author><author><keyname>Nguyen</keyname><forenames>Lam</forenames></author><author><keyname>Guo</keyname><forenames>Tiantong</forenames></author><author><keyname>Monga</keyname><forenames>Vishal</forenames></author></authors><title>Deep Network for Simultaneous Decomposition and Classification in
  UWB-SAR Imagery</title><categories>eess.IV cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classifying buried and obscured targets of interest from other natural and
manmade clutter objects in the scene is an important problem for the U.S. Army.
Targets of interest are often represented by signals captured using
low-frequency (UHF to L-band) ultra-wideband (UWB) synthetic aperture radar
(SAR) technology. This technology has been used in various applications,
including ground penetration and sensing-through-the-wall. However, the
technology still faces a significant issues regarding low-resolution SAR
imagery in this particular frequency band, low radar cross sections (RCS),
small objects compared to radar signal wavelengths, and heavy interference. The
classification problem has been firstly, and partially, addressed by sparse
representation-based classification (SRC) method which can extract noise from
signals and exploit the cross-channel information. Despite providing potential
results, SRC-related methods have drawbacks in representing nonlinear relations
and dealing with larger training sets. In this paper, we propose a Simultaneous
Decomposition and Classification Network (SDCN) to alleviate noise inferences
and enhance classification accuracy. The network contains two jointly trained
sub-networks: the decomposition sub-network handles denoising, while the
classification sub-network discriminates targets from confusers. Experimental
results show significant improvements over a network without decomposition and
SRC-related methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05504</identifier>
 <datestamp>2019-04-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05504</id><created>2018-01-16</created><updated>2019-04-28</updated><authors><author><keyname>Medhat</keyname><forenames>Fady</forenames></author><author><keyname>Chesmore</keyname><forenames>David</forenames></author><author><keyname>Robinson</keyname><forenames>John</forenames></author></authors><title>Automatic Classification of Music Genre using Masked Conditional Neural
  Networks</title><categories>cs.SD cs.LG eess.AS stat.ML</categories><comments>Restricted Boltzmann Machine; RBM; Conditional RBM; CRBM; Deep Belief
  Net; DBN; Conditional Neural Network; CLNN; Masked Conditional Neural
  Network; MCLNN; Music Information Retrieval; MIR. IEEE International
  Conference on Data Mining (ICDM), 2017</comments><journal-ref>IEEE International Conference on Data Mining (ICDM) Year: 2017
  Pages: 979 - 984</journal-ref><doi>10.1109/ICDM.2017.125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural network based architectures used for sound recognition are usually
adapted from other application domains such as image recognition, which may not
harness the time-frequency representation of a signal. The ConditionaL Neural
Networks (CLNN) and its extension the Masked ConditionaL Neural Networks
(MCLNN) are designed for multidimensional temporal signal recognition. The CLNN
is trained over a window of frames to preserve the inter-frame relation, and
the MCLNN enforces a systematic sparseness over the network's links that mimics
a filterbank-like behavior. The masking operation induces the network to learn
in frequency bands, which decreases the network susceptibility to
frequency-shifts in time-frequency representations. Additionally, the mask
allows an exploration of a range of feature combinations concurrently analogous
to the manual handcrafting of the optimum collection of features for a
recognition task. MCLNN have achieved competitive performance on the Ballroom
music dataset compared to several hand-crafted attempts and outperformed models
based on state-of-the-art Convolutional Neural Networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05525</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05525</id><created>2018-01-16</created><authors><author><keyname>Torres</keyname><forenames>Wuilan</forenames></author><author><keyname>Rueda-Toicen</keyname><forenames>Antonio</forenames></author></authors><title>Identification of Seed Cells in Multispectral Images for GrowCut
  Segmentation</title><categories>eess.IV cs.CV</categories><comments>10 pages, in Spanish, originally presented at CIMENICS 2016, accepted
  to the Journal of the Faculty of Engineering UCV</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The segmentation of satellite images is a necessary step to perform
object-oriented image classification, which has become relevant due to its
applicability on images with a high spatial resolution. To perform
object-oriented image classification, the studied image must first be segmented
in uniform regions. This segmentation requires manual work by an expert user,
who must exhaustively explore the image to establish thresholds that generate
useful and representative segments without oversegmenting and without
discarding representative segments. We propose a technique that automatically
segments the multispectral image while facing these issues. We identify in the
image homogenous zones according to their spectral signatures through the use
of morphological filters. These homogenous zones are representatives of
different types of land coverings in the image and are used as seeds for the
GrowCut multispectral segmentation algorithm. GrowCut is a cellular automaton
with competitive region growth, its cells are linked to every pixel in the
image through three parameters: the pixel's spectral signature, a label, and a
strength factor that represents the strength with which a cell defends its
label. The seed cells possess maximum strength and maintain their state
throughout the automaton's evolution. Starting from seed cells, each cell in
the image is iteratively attacked by its neighboring cells. When the automaton
stops updating its states, we obtain a segmented image where each pixel has
taken the label of one of its cells. In this paper the algorithm was applied in
an image acquired by Landsat8 on agricultural land of Calabozo, Guarico,
Venezuela where there are different types of land coverings: agriculture, urban
regions, water bodies, and savannas with different degrees of human
intervention. The segmentation obtained is presented as irregular polygons
enclosing geographical objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05544</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05544</id><created>2018-01-16</created><authors><author><keyname>Elizalde</keyname><forenames>Benjamin</forenames></author><author><keyname>Badlani</keyname><forenames>Rohan</forenames></author><author><keyname>Shah</keyname><forenames>Ankit</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author></authors><title>NELS - Never-Ending Learner of Sounds</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sounds are essential to how humans perceive and interact with the world and
are captured in recordings and shared on the Internet on a minute-by-minute
basis. These recordings, which are predominantly videos, constitute the largest
archive of sounds we know. However, most of these recordings have undescribed
content making necessary methods for automatic sound analysis, indexing and
retrieval. These methods have to address multiple challenges, such as the
relation between sounds and language, numerous and diverse sound classes, and
large-scale evaluation. We propose a system that continuously learns from the
web relations between sounds and language, improves sound recognition models
over time and evaluates its learning competency in the large-scale without
references. We introduce the Never-Ending Learner of Sounds (NELS), a project
for continuously learning of sounds and their associated knowledge, available
on line in nels.cs.cmu.edu
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05694</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05694</id><created>2018-01-17</created><authors><author><keyname>Ashfaq</keyname><forenames>Awais</forenames></author><author><keyname>Adler</keyname><forenames>Jonas</forenames></author></authors><title>A modified fuzzy C means algorithm for shading correction in
  craniofacial CBCT images</title><categories>cs.CV eess.IV physics.med-ph</categories><comments>15 pages, published in CMBEBIH 2017</comments><journal-ref>Proceedings of the International Conference on Medical and
  Biological Engineering 2017</journal-ref><doi>10.1007/978-981-10-4166-2_81</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CBCT images suffer from acute shading artifacts primarily due to scatter.
Numerous image-domain correction algorithms have been proposed in the
literature that use patient-specific planning CT images to estimate shading
contributions in CBCT images. However, in the context of radiosurgery
applications such as gamma knife, planning images are often acquired through
MRI which impedes the use of polynomial fitting approaches for shading
correction. We present a new shading correction approach that is independent of
planning CT images. Our algorithm is based on the assumption that true CBCT
images follow a uniform volumetric intensity distribution per material, and
scatter perturbs this uniform texture by contributing cupping and shading
artifacts in the image domain. The framework is a combination of fuzzy C-means
coupled with a neighborhood regularization term and Otsu's method. Experimental
results on artificially simulated craniofacial CBCT images are provided to
demonstrate the effectiveness of our algorithm. Spatial non-uniformity is
reduced from 16% to 7% in soft tissue and from 44% to 8% in bone regions. With
shading-correction, thresholding based segmentation accuracy for bone pixels is
improved from 85% to 91% when compared to thresholding without
shading-correction. The proposed algorithm is thus practical and qualifies as a
plug and play extension into any CBCT reconstruction software for shading
correction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05859</identifier>
 <datestamp>2018-08-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05859</id><created>2018-01-17</created><authors><author><keyname>de Oliveira</keyname><forenames>H. M.</forenames></author><author><keyname>Cintra</keyname><forenames>R. J.</forenames></author><author><keyname>de Oliveira</keyname><forenames>R. C.</forenames></author></authors><title>A Kotel'nikov Representation for Wavelets</title><categories>math.CA eess.AS eess.SP math.NA stat.ME</categories><comments>6 pages, 15 figures</comments><msc-class>42C40, 62G08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a wavelet representation using baseband signals, by
exploiting Kotel'nikov results. Details of how to obtain the processes of
envelope and phase at low frequency are shown. The archetypal interpretation of
wavelets as an analysis with a filter bank of constant quality factor is
revisited on these bases. It is shown that if the wavelet spectral support is
limited into the band $[f_m,f_M]$, then an orthogonal analysis is guaranteed
provided that $f_M \leq 3f_m$, a quite simple result, but that invokes some
parallel with the Nyquist rate. Nevertheless, in cases of orthogonal wavelets
whose spectrum does not verify this condition, it is shown how to construct an
&quot;equivalent&quot; filter bank with no spectral overlapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05908</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05908</id><created>2018-01-17</created><authors><author><keyname>Pham</keyname><forenames>Thinh H.</forenames></author><author><keyname>Vinod</keyname><forenames>A. P.</forenames></author><author><keyname>Madhukumar</keyname><forenames>A. S.</forenames></author></authors><title>An Efficient Data-aided Synchronization in L-DACS1 for Aeronautical
  Communications</title><categories>eess.SP</categories><comments>In the proceeding of International Conference on Data Mining,
  Communications and Information Technology (DMCIT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  L-band Digital Aeronautical Communication System type-1 (L-DACS1) is an
emerging standard that aims at enhancing air traffic management (ATM) by
transitioning the traditional analog aeronautical communication systems to the
superior and highly efficient digital domain. L-DACS1 employs modern and
efficient orthogonal frequency division multiplexing (OFDM) modulation
technique to achieve more efficient and higher data rate in comparison to the
existing aeronautical communication systems. However, the performance of OFDM
systems is very sensitive to synchronization errors. L-DACS1 transmission is in
the L-band aeronautical channels that suffer from large interference and large
Doppler shifts, which makes the synchronization for L-DACS more challenging.
This paper proposes a novel computationally efficient synchronization method
for L-DACS1 systems that offers robust performance. Through simulation, the
proposed method is shown to provide accurate symbol timing offset (STO)
estimation as well as fractional carrier frequency offset (CFO) estimation in a
range of aeronautical channels. In particular, it can yield excellent
synchronization performance in the face of a large carrier frequency offset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05925</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05925</id><created>2018-01-17</created><authors><author><keyname>Rim</keyname><forenames>Jusong</forenames></author><author><keyname>Ri</keyname><forenames>Cholyong</forenames></author><author><keyname>Jin</keyname><forenames>Hongchol</forenames></author><author><keyname>Ohr</keyname><forenames>Choljin</forenames></author><author><keyname>Rim</keyname><forenames>Choljun</forenames></author><author><keyname>Ri</keyname><forenames>Hyewon</forenames></author></authors><title>A New Peak Detection Method for Single or Three-Phase Unbalanced
  Sinusoidal Signals</title><categories>eess.SP</categories><comments>This paper consists of 5 pages, 10 figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In this paper, a fast amplitude detection method for the single or
three-phase unbalanced sinusoidal is reported. The proposed method is a method
of the amplitude detection for a single phase or three phase unbalanced
sinusoidal signal, based on detecting of the pulse width corresponding to the
peak amplitude. The detection period is the half period of the input signal.
This method is independent of the three-phase signal's unbalance and phase
sequence. The proposed method was verified through experiments for the single
or three-phase unbalanced signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.05984</identifier>
 <datestamp>2018-07-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.05984</id><created>2018-01-18</created><authors><author><keyname>Kara</keyname><forenames>Ferdi</forenames></author><author><keyname>Kaya</keyname><forenames>Hakan</forenames></author><author><keyname>Erkaymaz</keyname><forenames>Okan</forenames></author><author><keyname>Ozturk</keyname><forenames>Ertan</forenames></author></authors><title>Prediction of the Optimal Threshold Value in DF Relay Selection Schemes
  Based on Artificial Neural Networks</title><categories>eess.SP cs.LG cs.NE cs.NI</categories><comments>6 pages,IEEE INnovations in Intelligent SysTems and Applications
  (INISTA), 2016 International Symposium on</comments><doi>10.1109/INISTA.2016.7571823</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless communications, the cooperative communication (CC) technology
promises performance gains compared to traditional Single-Input Single Output
(SISO) techniques. Therefore, the CC technique is one of the nominees for 5G
networks. In the Decode-and-Forward (DF) relaying scheme which is one of the CC
techniques, determination of the threshold value at the relay has a key role
for the system performance and power usage. In this paper, we propose
prediction of the optimal threshold values for the best relay selection scheme
in cooperative communications, based on Artificial Neural Networks (ANNs) for
the first time in literature. The average link qualities and number of relays
have been used as inputs in the prediction of optimal threshold values using
Artificial Neural Networks (ANNs): Multi-Layer Perceptron (MLP) and Radial
Basis Function (RBF) networks. The MLP network has better performance from the
RBF network on the prediction of optimal threshold value when the same number
of neurons is used at the hidden layer for both networks. Besides, the optimal
threshold values obtained using ANNs are verified by the optimal threshold
values obtained numerically using the closed form expression derived for the
system. The results show that the optimal threshold values obtained by ANNs on
the best relay selection scheme provide a minimum Bit-Error-Rate (BER) because
of the reduction of the probability that error propagation may occur. Also, for
the same BER performance goal, prediction of optimal threshold values provides
2dB less power usage, which is great gain in terms of green communicationBER
performance goal, prediction of optimal threshold values provides 2dB less
power usage, which is great gain in terms of green communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06014</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06014</id><created>2018-01-18</created><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Mahloojifar</keyname><forenames>Ali</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author></authors><title>Image Enhancement and Noise Reduction Using Modified
  Delay-Multiply-and-Sum Beamformer: Application to Medical Photoacoustic
  Imaging</title><categories>eess.SP cs.IT math.IT</categories><comments>This paper was accepted and presented at Iranian Conference on
  Electrical Engineering (ICEE) 2017</comments><journal-ref>Iranian Conference on Electrical Engineering, 2-4 May 2017</journal-ref><doi>10.1109/IranianCEE.2017.7985131</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photoacoustic imaging (PAI) is an emerging biomedical imaging modality
capable of providing both high contrast and high resolution of optical and
UltraSound (US) imaging. When a short duration laser pulse illuminates the
tissue as a target of imaging, tissue induces US waves and detected waves can
be used to reconstruct optical absorption distribution. Since receiving part of
PA consists of US waves, a large number of beamforming algorithms in US imaging
can be applied on PA imaging. Delay-and-Sum (DAS) is the most common
beamforming algorithm in US imaging. However, make use of DAS beamformer leads
to low resolution images and large scale of off-axis signals contribution. To
address these problems a new paradigm namely Delay-Multiply-and-Sum (DMAS),
which was used as a reconstruction algorithm in confocal microwave imaging for
breast cancer detection, was introduced for US imaging. Consequently, DMAS was
used in PA imaging systems and it was shown this algorithm results in
resolution enhancement and sidelobe degrading. However, in presence of high
level of noise the reconstructed image still suffers from high contribution of
noise. In this paper, a modified version of DMAS beamforming algorithm is
proposed based on DAS inside DMAS formula expansion. The quantitative and
qualitative results show that proposed method results in more noise reduction
and resolution enhancement in expense of contrast degrading. For the
simulation, two-point target, along with lateral variation in two depths of
imaging are employed and it is evaluated under high level of noise in imaging
medium. Proposed algorithm in compare to DMAS, results in reduction of lateral
valley for about 19 dB followed by more distinguished two-point target.
Moreover, levels of sidelobe are reduced for about 25 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06023</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06023</id><created>2018-01-18</created><authors><author><keyname>Yao</keyname><forenames>Miao</forenames></author><author><keyname>Sohul</keyname><forenames>Munawwar</forenames></author><author><keyname>Nealy</keyname><forenames>Randall</forenames></author><author><keyname>Marojevic</keyname><forenames>Vuk</forenames></author><author><keyname>Reed</keyname><forenames>Jeffrey</forenames></author></authors><title>A Digital Predistortion Scheme Exploiting Degrees-of-Freedom for Massive
  MIMO Systems</title><categories>eess.SP</categories><comments>IEEE International Conference on Communications 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The primary source of nonlinear distortion in wireless transmitters is the
power amplifier (PA). Conventional digital predistortion (DPD) schemes use
high-order polynomials to accurately approximate and compensate for the
nonlinearity of the PA. This is not practical for scaling to tens or hundreds
of PAs in massive multiple-input multiple-output (MIMO) systems. There is more
than one candidate precoding matrix in a massive MIMO system because of the
excess degrees-of-freedom (DoFs), and each precoding matrix requires a
different DPD polynomial order to compensate for the PA nonlinearity. This
paper proposes a low-order DPD method achieved by exploiting massive DoFs of
next-generation front ends. We propose a novel indirect learning structure
which adapts the channel and PA distortion iteratively by cascading adaptive
zero forcing precoding and DPD. Our solution uses a 3rd order polynomial to
achieve the same performance as the conventional DPD using an 11th order
polynomial for a 100x10 massive MIMO configuration. Experimental results show a
70% reduction in computational complexity, enabling ultra-low latency
communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06061</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06061</id><created>2018-01-18</created><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Sadeghi</keyname><forenames>Masume</forenames></author><author><keyname>Mahloojifar</keyname><forenames>Ali</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author></authors><title>Double Stage Delay Multiply and Sum Beamforming Algorithm Applied to
  Ultrasound Medical Imaging</title><categories>eess.SP</categories><comments>This paper is accepted in &quot;Ultrasound in Medicine and Biology&quot;
  journal</comments><journal-ref>Ultrasound in Medicine and Biology, Available online 22 December
  2017</journal-ref><doi>10.1016/j.ultrasmedbio.2017.10.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Ultrasound (US) imaging, Delay and Sum (DAS) is the most common
beamformer, but it leads to low quality images. Delay Multiply and Sum (DMAS)
was introduced to address this problem. However, the reconstructed images using
DMAS still suffer from level of sidelobes and low noise suppression. In this
paper, a novel beamforming algorithm is introduced based on the expansion of
DMAS formula. It is shown that there is a DAS algebra inside the expansion, and
it is proposed to use DMAS instead of the DAS algebra. The introduced method,
namely Double Stage DMAS (DS-DMAS), is evaluated numerically and
experimentally. The quantitative results indicate that DS-DMAS results in about
25% lower level of sidelobes compared to DMAS. Moreover, the introduced method
leads to 23%, 22% and 43% improvement in Signal-to-Noise Ratio,
Full-Width-Half-Maximum and Contrast Ratio, respectively, in comparison with
DMAS beamformer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06128</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06128</id><created>2018-01-18</created><authors><author><keyname>Wang</keyname><forenames>Zhongxiang</forenames></author><author><keyname>Hamedi</keyname><forenames>Masoud</forenames></author><author><keyname>Young</keyname><forenames>Stanley</forenames></author></authors><title>A methodology for calculating the latency of GPS-probe data</title><categories>stat.AP eess.SP</categories><journal-ref>Transportation Research Record: Journal of the Transportation
  Research Board, (2645), pp.76-85</journal-ref><doi>10.3141/2645-09</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowdsourced GPS probe data has been gaining popularity in recent years as a
source for real-time traffic information. Efforts have been made to evaluate
the quality of such data from different perspectives. A quality indicator of
any traffic data source is latency that describes the punctuality of data,
which is critical for real-time operations, emergency response, and traveler
information systems. This paper offers a methodology for measuring the probe
data latency, with respect to a selected reference source. Although Bluetooth
re-identification data is used as the reference source, the methodology can be
applied to any other ground-truth data source of choice (i.e. Automatic License
Plate Readers, Electronic Toll Tag). The core of the methodology is a maximum
pattern matching algorithm that works with three different fitness objectives.
To test the methodology, sample field reference data were collected on multiple
freeways segments for a two-week period using portable Bluetooth sensors as
ground-truth. Equivalent GPS probe data was obtained from a private vendor, and
its latency was evaluated. Latency at different times of the day, the impact of
road segmentation scheme on latency, and sensitivity of the latency to both
speed slowdown, and recovery from slowdown episodes are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06277</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06277</id><created>2018-01-18</created><authors><author><keyname>Lee</keyname><forenames>Siyeong</forenames></author><author><keyname>An</keyname><forenames>Gwon Hwan</forenames></author><author><keyname>Kang</keyname><forenames>Suk-Ju</forenames></author></authors><title>Deep Chain HDRI: Reconstructing a High Dynamic Range Image from a Single
  Low Dynamic Range Image</title><categories>cs.CV eess.IV</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel deep neural network model that reconstructs
a high dynamic range (HDR) image from a single low dynamic range (LDR) image.
The proposed model is based on a convolutional neural network composed of
dilated convolutional layers, and infers LDR images with various exposures and
illumination from a single LDR image of the same scene. Then, the final HDR
image can be formed by merging these inference results. It is relatively easy
for the proposed method to find the mapping between the LDR and an HDR with a
different bit depth because of the chaining structure inferring the
relationship between the LDR images with brighter (or darker) exposures from a
given LDR image. The method not only extends the range, but also has the
advantage of restoring the light information of the actual physical world. For
the HDR images obtained by the proposed method, the HDR-VDP2 Q score, which is
the most popular evaluation metric for HDR images, was 56.36 for a display with
a 1920$\times$1200 resolution, which is an improvement of 6 compared with the
scores of conventional algorithms. In addition, when comparing the peak
signal-to-noise ratio values for tone mapped HDR images generated by the
proposed and conventional algorithms, the average value obtained by the
proposed algorithm is 30.86 dB, which is 10 dB higher than those obtained by
the conventional algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06421</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06421</id><created>2018-01-18</created><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Mahloojifar</keyname><forenames>Ali</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author></authors><title>Medical Photoacoustic Beamforming Using Minimum Variance-Based Delay
  Multiply and Sum</title><categories>eess.SP cs.IT math.IT</categories><comments>SPIE Digital Optical Technologies, 2017, Munich, Germany. arXiv admin
  note: substantial text overlap with arXiv:1709.07965</comments><journal-ref>Proceedings Volume 10335, Digital Optical Technologies 2017;
  1033522 (2017)</journal-ref><doi>10.1117/12.2269608</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delay-and-Sum (DAS) beamformer is the most common beamforming algorithm in
Photoacoustic imaging (PAI) due to its simple implementation and real time
imaging. However, it provides poor resolution and high levels of sidelobe. A
new algorithm named Delay-Multiply-and-Sum (DMAS) was introduced. Using DMAS
leads to lower levels of sidelobe compared to DAS, but resolution is not
satisfying yet. In this paper, a novel beamformer is introduced based on the
combination of Minimum Variance (MV) adaptive beamforming and DMAS, so-called
Minimum Variance-Based DMAS (MVB-DMAS). It is shown that expanding the DMAS
equation leads to some terms which contain a DAS equation. It is proposed to
use MV adaptive beamformer instead of existing DAS inside the DMAS algebra
expansion. MVB-DMAS is evaluated numerically compared to DAS, DMAS and MV and
Signal-to-noise ratio (SNR) metric is presented. It is shown that MVB-DMAS
leads to higher image quality and SNR for about 13 dB, 3 dB and 2 dB in
comparison with DAS, DMAS and MV, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06442</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06442</id><created>2018-01-19</created><authors><author><keyname>Meuel</keyname><forenames>Holger</forenames></author><author><keyname>Kluger</keyname><forenames>Florian</forenames></author><author><keyname>Ostermann</keyname><forenames>J&#xf6;rn</forenames></author></authors><title>Region of Interest (ROI) Coding for Aerial Surveillance Video using AVC
  &amp; HEVC</title><categories>eess.IV</categories><comments>5 pages, 7 figures, 1 table</comments><journal-ref>See also our extended OpenAccess article &quot;Mesh-based Piecewise
  Planar Motion Compensation and Optical Flow Clustering for ROI Coding&quot;,
  APSIPA Transact. on Sig.&amp;Inform. Proc., 2015</journal-ref><doi>10.1017/ATSIP.2015.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aerial surveillance from Unmanned Aerial Vehicles (UAVs), i.e. with moving
cameras, is of growing interest for police as well as disaster area monitoring.
For more detailed ground images the camera resolutions are steadily increasing.
Simultaneously the amount of video data to transmit is increasing
significantly, too. To reduce the amount of data, Region of Interest (ROI)
coding systems were introduced which mainly encode some regions in higher
quality at the cost of the remaining image regions. We employ an existing ROI
coding system relying on global motion compensation to retain full image
resolution over the entire image. Different ROI detectors are used to
automatically classify a video image on board of the UAV in ROI and non-ROI. We
propose to replace the modified Advanced Video Coding (AVC) video encoder by a
modified High Efficiency Video Coding (HEVC) encoder. Without any change of the
detection system itself, but by replacing the video coding back-end we are able
to improve the coding efficiency by 32% on average although regular HEVC
provides coding gains of 12-30% only for the same test sequences and similar
PSNR compared to regular AVC coding. Since the employed ROI coding mainly
relies on intra mode coding of new emerging image areas, gains of HEVC-ROI
coding over AVC-ROI coding compared to regular coding of the entire frames
including predictive modes (inter) depend on sequence characteristics. We
present a detailed analysis of bit distribution within the frames to explain
the gains. In total we can provide coding data rates of 0.7-1.0 Mbit/s for full
HDTV video sequences at 30 fps at reasonable quality of more than 37 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06485</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06485</id><created>2018-01-17</created><authors><author><keyname>Fernandez</keyname><forenames>Manuel P.</forenames></author><author><keyname>Rossini</keyname><forenames>Laureano A. Bulus</forenames></author><author><keyname>Pascual</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Caso</keyname><forenames>Pablo A. Costanzo</forenames></author></authors><title>DSP-Enhanced OTDR for Detection and Estimation of Events in PONs</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To plan a rapid response and minimize operational costs, passive optical
network operators require to automatically detect and identify faults that may
occur in the optical distribution network. In this work, we present
DSP-Enhanced OTDR, a novel methodology for remote fault analysis based on
conventional optical time-domain reflectometry complemented with reference
traces. Together with the mathematical formalism, we derive the detection tests
that result to be uniformly most powerful, which are optimal according to the
Neyman-Pearson criterion. To identify the type of fault and fully characterize
it, the detection stage is followed by the estimation of its characteristic
parameters, such as return loss and insertion loss. We experimentally
demonstrate that this approach allows to detect faults inside the event dead
zone, which overcomes the shortage of conventional event-marking algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06492</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06492</id><created>2018-01-19</created><authors><author><keyname>Rudresh</keyname><forenames>Sunil</forenames></author><author><keyname>Vasisht</keyname><forenames>Aditya</forenames></author><author><keyname>Vijayan</keyname><forenames>Karthika</forenames></author><author><keyname>Seelamantula</keyname><forenames>Chandra Sekhar</forenames></author></authors><title>Epoch-Synchronous Overlap-Add (ESOLA) for Time- and Pitch-Scale
  Modification of Speech Signals</title><categories>eess.AS cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time- and pitch-scale modifications of speech signals find important
applications in speech synthesis, playback systems, voice conversion,
learning/hearing aids, etc.. There is a requirement for computationally
efficient and real-time implementable algorithms. In this paper, we propose a
high quality and computationally efficient time- and pitch-scaling methodology
based on the glottal closure instants (GCIs) or epochs in speech signals. The
proposed algorithm, termed as epoch-synchronous overlap-add time/pitch-scaling
(ESOLA-TS/PS), segments speech signals into overlapping short-time frames and
then the adjacent frames are aligned with respect to the epochs and the frames
are overlap-added to synthesize time-scale modified speech. Pitch scaling is
achieved by resampling the time-scaled speech by a desired sampling factor. We
also propose a concept of epoch embedding into speech signals, which
facilitates the identification and time-stamping of samples corresponding to
epochs and using them for time/pitch-scaling to multiple scaling factors
whenever desired, thereby contributing to faster and efficient implementation.
The results of perceptual evaluation tests reported in this paper indicate the
superiority of ESOLA over state-of-the-art techniques. ESOLA significantly
outperforms the conventional pitch synchronous overlap-add (PSOLA) techniques
in terms of perceptual quality and intelligibility of the modified speech.
Unlike the waveform similarity overlap-add (WSOLA) or synchronous overlap-add
(SOLA) techniques, the ESOLA technique has the capability to do exact
time-scaling of speech with high quality to any desired modification factor
within a range of 0.5 to 2. Compared to synchronous overlap-add with fixed
synthesis (SOLAFS), the ESOLA is computationally advantageous and at least
three times faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06608</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06608</id><created>2018-01-19</created><updated>2018-12-03</updated><authors><author><keyname>Rasekh</keyname><forenames>Maryam Eslami</forenames></author><author><keyname>Madhow</keyname><forenames>Upamanyu</forenames></author></authors><title>Noncoherent compressive channel estimation for mm-wave massive MIMO</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter (mm) wave massive MIMO has the potential for delivering orders of
magnitude increases in mobile data rates, with compact antenna arrays providing
narrow steerable beams for unprecedented levels of spatial reuse. A fundamental
technical bottleneck, however, is rapid spatial channel estimation and beam
adaptation in the face of mobility and blockage. Recently proposed compressive
techniques which exploit the sparsity of mm wave channels are a promising
approach to this problem, with overhead scaling linearly with the number of
dominant paths and logarithmically with the number of array elements. Further,
they can be implemented with RF beamforming with low-precision phase control.
However, these methods make implicit assumptions on long-term phase coherence
that are not satisfied by existing hardware. In this paper, we propose and
evaluate a noncoherent compressive channel estimation technique which can
estimate a sparse spatial channel based on received signal strength (RSS)
alone, and is compatible with off-the-shelf hardware. The approach is based on
cascading phase retrieval (i.e., recovery of complex-valued measurements from
RSS measurements, up to a scalar multiple) with coherent compressive
estimation. While a conventional cascade scheme would multiply two measurement
matrices to obtain an overall matrix whose entries are in a continuum, a key
novelty in our scheme is that we constrain the overall measurement matrix to be
implementable using coarsely quantized pseudorandom phases, employing a virtual
decomposition of the matrix into a product of measurement matrices for phase
retrieval and compressive estimation. Theoretical and simulation results show
that our noncoherent method scales almost as well with array size as its
coherent counterpart, thus inheriting the scalability and low overhead of the
latter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06657</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06657</id><created>2018-01-20</created><authors><author><keyname>Shahin</keyname><forenames>Ismail</forenames></author></authors><title>Gender-dependent emotion recognition based on HMMs and SPHMMs</title><categories>cs.SD eess.AS</categories><comments>9 pages. arXiv admin note: text overlap with arXiv:1706.09760,
  arXiv:1707.00137</comments><journal-ref>International Journal of Speech Technology, Vol. 16, issue 2, June
  2013, pp. 133-141</journal-ref><doi>10.1007/s10772-012-9170-4.</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that emotion recognition performance is not ideal. The work
of this research is devoted to improving emotion recognition performance by
employing a two-stage recognizer that combines and integrates gender recognizer
and emotion recognizer into one system. Hidden Markov Models (HMMs) and
Suprasegmental Hidden Markov Models (SPHMMs) have been used as classifiers in
the two-stage recognizer. This recognizer has been tested on two distinct and
separate emotional speech databases. The first database is our collected
database and the second one is the Emotional Prosody Speech and Transcripts
database. Six basic emotions including the neutral state have been used in each
database. Our results show that emotion recognition performance based on the
two-stage approach (gender-dependent emotion recognizer) has been significantly
improved compared to that based on emotion recognizer without gender
information and emotion recognizer with correct gender information by an
average of 11% and 5%, respectively. This work shows that the highest emotion
identification performance takes place when the classifiers are completely
biased towards suprasegmental models and no impact of acoustic models. The
results achieved based on the two-stage framework fall within 2.28% of those
obtained in subjective assessment by human judges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06724</identifier>
 <datestamp>2019-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06724</id><created>2018-01-20</created><updated>2019-02-03</updated><authors><author><keyname>Schwartz</keyname><forenames>Eli</forenames></author><author><keyname>Giryes</keyname><forenames>Raja</forenames></author><author><keyname>Bronstein</keyname><forenames>Alex M.</forenames></author></authors><title>DeepISP: Towards Learning an End-to-End Image Processing Pipeline</title><categories>eess.IV cs.CV</categories><journal-ref>IEEE Transactions on Image Processing 28.2 (2019): 912-923</journal-ref><doi>10.1109/TIP.2018.2872858</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present DeepISP, a full end-to-end deep neural model of the camera image
signal processing (ISP) pipeline. Our model learns a mapping from the raw
low-light mosaiced image to the final visually compelling image and encompasses
low-level tasks such as demosaicing and denoising as well as higher-level tasks
such as color correction and image adjustment. The training and evaluation of
the pipeline were performed on a dedicated dataset containing pairs of
low-light and well-lit images captured by a Samsung S7 smartphone camera in
both raw and processed JPEG formats. The proposed solution achieves
state-of-the-art performance in objective evaluation of PSNR on the subtask of
joint denoising and demosaicing. For the full end-to-end pipeline, it achieves
better visual quality compared to the manufacturer ISP, in both a subjective
human assessment and when rated by a deep model trained for assessing image
quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06845</identifier>
 <datestamp>2018-04-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06845</id><created>2018-01-21</created><updated>2018-04-04</updated><authors><author><keyname>Bianchi</keyname><forenames>Filippo Maria</forenames></author><author><keyname>Livi</keyname><forenames>Lorenzo</forenames></author><author><keyname>Ferrante</keyname><forenames>Alberto</forenames></author><author><keyname>Milosevic</keyname><forenames>Jelena</forenames></author><author><keyname>Malek</keyname><forenames>Miroslaw</forenames></author></authors><title>Time series kernel similarities for predicting Paroxysmal Atrial
  Fibrillation from ECGs</title><categories>cs.LG eess.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the problem of classifying Electrocardiography (ECG) signals with
the aim of predicting the onset of Paroxysmal Atrial Fibrillation (PAF). Atrial
fibrillation is the most common type of arrhythmia, but in many cases PAF
episodes are asymptomatic. Therefore, in order to help diagnosing PAF, it is
important to design procedures for detecting and, more importantly, predicting
PAF episodes. We propose a method for predicting PAF events whose first step
consists of a feature extraction procedure that represents each ECG as a
multi-variate time series. Successively, we design a classification framework
based on kernel similarities for multi-variate time series, capable of handling
missing data. We consider different approaches to perform classification in the
original space of the multi-variate time series and in an embedding space,
defined by the kernel similarity measure. We achieve a classification accuracy
comparable with state of the art methods, with the additional advantage of
detecting the PAF onset up to 15 minutes in advance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06896</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.06896</id><created>2018-01-21</created><authors><author><keyname>Diamandis</keyname><forenames>Theo</forenames></author><author><keyname>Murin</keyname><forenames>Yonathan</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Ranking Causal Influence of Financial Markets via Directed Information
  Graphs</title><categories>q-fin.ST eess.SP</categories><comments>To be presented at Conference on Information Sciences and Systems
  (CISS) 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A non-parametric method for ranking stock indices according to their mutual
causal influences is presented. Under the assumption that indices reflect the
underlying economy of a country, such a ranking indicates which countries exert
the most economic influence in an examined subset of the global economy. The
proposed method represents the indices as nodes in a directed graph, where the
edges' weights are estimates of the pair-wise causal influences, quantified
using the directed information functional. This method facilitates using a
relatively small number of samples from each index. The indices are then ranked
according to their net-flow in the estimated graph (sum of the incoming weights
subtracted from the sum of outgoing weights). Daily and minute-by-minute data
from nine indices (three from Asia, three from Europe and three from the US)
were analyzed. The analysis of daily data indicates that the US indices are the
most influential, which is consistent with intuition that the indices
representing larger economies usually exert more influence. Yet, it is also
shown that an index representing a small economy can strongly influence an
index representing a large economy if the smaller economy is indicative of a
larger phenomenon. Finally, it is shown that while inter-region interactions
can be captured using daily data, intra-region interactions require more
frequent samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07023</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07023</id><created>2018-01-22</created><authors><author><keyname>Amirmazlaghani</keyname><forenames>Maryam</forenames></author></authors><title>A Novel Contourlet Domain Watermark Detector for Copyright Protection</title><categories>eess.IV eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital media can be distributed via Internet easily, so, media owners are
eagerly seeking methods to protect their rights. A typical solution is digital
watermarking for copyright protection. In this paper, we propose a novel
contourlet domain image watermarking scheme for copyright protection. In the
embedding phase, we insert the watermark into the image using an additive
contourlet domain spread spectrum approach. In the detection phase, we design a
detector using likelihood ratio test (LRT). Since the performance of the LRT
detector is completely dependent on the accuracy of the employed statistical
model, we first study the statistical properties of the contourlet
coefficients. This study demonstrates the heteroscedasticity and heavy-tailed
marginal distribution of these coefficients. Therefore, we propose using two
dimensional generalized autoregressive conditional heteroscedasticity
(2D-GARCH) model that is compatible with the contourlet coefficients. Motivated
by the modeling results, we design a new watermark detector based on 2D-GARCH
model. Also, we analyze its performance by computing the receiver operating
characteristics. Experimental results confirm the high efficiency of the
proposed detector. Since a watermark detector for copyright protection should
be robust against attacks, we examine the robustness of the proposed detector
under different kinds of attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07061</identifier>
 <datestamp>2018-05-22</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07061</id><created>2018-01-22</created><updated>2018-05-21</updated><authors><author><keyname>Peng</keyname><forenames>Tong</forenames></author><author><keyname>Wang</keyname><forenames>Yi</forenames></author><author><keyname>Burr</keyname><forenames>Alister G.</forenames></author><author><keyname>Shikh-Bahaei</keyname><forenames>Mohammad</forenames></author></authors><title>Wireless Network Coding in Network MIMO: A New Design for 5G and Beyond</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Physical layer network coding (PNC) has been studied to serve wireless
network MIMO systems with much lower backhaul load than approaches such as
Cloud Radio Access Network (Cloud-RAN) and coordinated multipoint (CoMP). In
this paper, we present a design guideline of engineering applicable PNC to
fulfil the request of high user densities in 5G wireless RAN infrastructure.
Unlike compute-and-forward and PNC design criteria for two-way relay channels,
the proposed guideline is designed for uplink of network MIMO (N-MIMO) systems.
We show that the proposed design criteria guarantee that 1) the whole system
operates over binary system; 2) the PNC functions utilised at each access point
overcome all singular fade states; 3) the destination can unambiguously recover
all source messages while the overall backhaul load remains at the lowest
level. We then develop a two-stage search algorithm to identify the optimum PNC
mapping functions which greatly reduces the real-time computational complexity.
The impact of estimated channel information and reduced number of singular fade
states in different QAM modulation schemes is studied in this paper. In
addition, a sub-optimal search method based on lookup table mechanism to
achieve further reduced computational complexity with limited performance loss
is presented. Numerical results show that the proposed schemes achieve low
outage probability with reduced backhaul load.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07067</identifier>
 <datestamp>2018-05-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07067</id><created>2018-01-22</created><updated>2018-05-30</updated><authors><author><keyname>Bahlke</keyname><forenames>Florian</forenames></author><author><keyname>Ramos-Cantor</keyname><forenames>Oscar D.</forenames></author><author><keyname>Henneberger</keyname><forenames>Steffen</forenames></author><author><keyname>Pesavento</keyname><forenames>Marius</forenames></author></authors><title>Optimized Cell Planning for Network Slicing in Heterogeneous Wireless
  Communication Networks</title><categories>eess.SP</categories><comments>This article has been accepted for publication in a future issue of
  the IEEE Communications Letters,
  https://ieeexplore.ieee.org/document/8368293, (c) 2018 IEEE</comments><doi>10.1109/LCOMM.2018.2841866</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a cell planning scheme to maximize the resource efficiency of a
wireless communication network while considering quality-of-service
requirements imposed by different mobile services. In dense and heterogeneous
cellular 5G networks, the available time-frequency resources are orthogonally
partitioned among different slices, which are serviced by the cells. The
proposed scheme achieves a joint optimization of the resource distribution
between network slices, the allocation of cells to operate on different slices,
and the allocation of users to cells. Since the original problem formulation is
computationally intractable, we propose a convex inner approximation.
Simulations show that the proposed approach optimizes the resource efficiency
and enables a service-centric network design paradigm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07087</identifier>
 <datestamp>2018-09-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07087</id><created>2018-01-22</created><updated>2018-07-25</updated><authors><author><keyname>Shin</keyname><forenames>Ban-Sok</forenames></author><author><keyname>Yukawa</keyname><forenames>Masahiro</forenames></author><author><keyname>Cavalcante</keyname><forenames>Renato Luis Garrido</forenames></author><author><keyname>Dekorsy</keyname><forenames>Armin</forenames></author></authors><title>Distributed Adaptive Learning with Multiple Kernels in Diffusion
  Networks</title><categories>eess.SP</categories><comments>Double-column 15 pages, 10 figures, submitted to IEEE Trans. Signal
  Processing</comments><doi>10.1109/TSP.2018.2868040</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an adaptive scheme for distributed learning of nonlinear functions
by a network of nodes. The proposed algorithm consists of a local adaptation
stage utilizing multiple kernels with projections onto hyperslabs and a
diffusion stage to achieve consensus on the estimates over the whole network.
Multiple kernels are incorporated to enhance the approximation of functions
with several high and low frequency components common in practical scenarios.
We provide a thorough convergence analysis of the proposed scheme based on the
metric of the Cartesian product of multiple reproducing kernel Hilbert spaces.
To this end, we introduce a modified consensus matrix considering this specific
metric and prove its equivalence to the ordinary consensus matrix. Besides, the
use of hyperslabs enables a significant reduction of the computational demand
with only a minor loss in the performance. Numerical evaluations with synthetic
and real data are conducted showing the efficacy of the proposed algorithm
compared to the state of the art schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07167</identifier>
 <datestamp>2018-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07167</id><created>2018-01-22</created><authors><author><keyname>Cho</keyname><forenames>Yae Jee</forenames></author><author><keyname>Suk</keyname><forenames>Gee-Yong</forenames></author><author><keyname>Kim</keyname><forenames>Byoungnam</forenames></author><author><keyname>Kim</keyname><forenames>Dong Ku</forenames></author><author><keyname>Chae</keyname><forenames>Chan-Byoung</forenames></author></authors><title>RF Lens-Embedded Antenna Array for mmWave MIMO: Design and Performance</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The requirement of high data-rate in the fifth generation wireless systems
(5G) calls for the ultimate utilization of the wide bandwidth in the mmWave
frequency band. Researchers seeking to compensate for mmWave's high path loss
and to achieve both gain and directivity have proposed that mmWave
multiple-input multiple-output (MIMO) systems make use of beamforming systems.
Hybrid beamforming in mmWave demonstrates promising performance in achieving
high gain and directivity by using phase shifters at the analog processing
block. What remains a problem, however, is the actual implementation of mmWave
beamforming systems; to fabricate such a system is costly and complex. With the
aim of reducing such cost and complexity, this article presents actual
prototypes of the lens antenna as an effective device to be used in the future
5G mmWave hybrid beamforming systems. Using a lens as a passive phase shifter
enables beamforming without the heavy network of active phase shifters, while
gain and directivity are achieved by the energy-focusing property of the lens.
Proposed in this article are two types of lens antennas, one for static and the
other for mobile usage. Their performance is evaluated using measurements and
simulation data along with link-level analysis via a software defined radio
(SDR) platform. Results show the promising potential of the lens antenna for
its high gain and directivity, and its improved beam-switching feasibility
compared to when a lens is not used. System-level evaluations reveal the
significant throughput enhancement in both real indoor and outdoor
environments. Moreover, the lens antenna's design issues are also discussed by
evaluating different lens sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07198</identifier>
 <datestamp>2019-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07198</id><created>2018-01-22</created><updated>2018-04-20</updated><authors><author><keyname>Fu</keyname><forenames>Chichen</forenames></author><author><keyname>Lee</keyname><forenames>Soonam</forenames></author><author><keyname>Ho</keyname><forenames>David Joon</forenames></author><author><keyname>Han</keyname><forenames>Shuo</forenames></author><author><keyname>Salama</keyname><forenames>Paul</forenames></author><author><keyname>Dunn</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Delp</keyname><forenames>Edward J.</forenames></author></authors><title>Three Dimensional Fluorescence Microscopy Image Synthesis and
  Segmentation</title><categories>cs.CV cs.LG eess.IV</categories><comments>Accepted by CVPR Workshop on Computer Vision for Microscopy Image
  Analysis (CVMI)</comments><doi>10.1109/CVPRW.2018.00298</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advances in fluorescence microscopy enable acquisition of 3D image volumes
with better image quality and deeper penetration into tissue. Segmentation is a
required step to characterize and analyze biological structures in the images
and recent 3D segmentation using deep learning has achieved promising results.
One issue is that deep learning techniques require a large set of groundtruth
data which is impractical to annotate manually for large 3D microscopy volumes.
This paper describes a 3D deep learning nuclei segmentation method using
synthetic 3D volumes for training. A set of synthetic volumes and the
corresponding groundtruth are generated using spatially constrained
cycle-consistent adversarial networks. Segmentation results demonstrate that
our proposed method is capable of segmenting nuclei successfully for various
data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07297</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07297</id><created>2018-01-11</created><authors><author><keyname>Mukherjee</keyname><forenames>Rahul</forenames></author><author><keyname>Basu</keyname><forenames>Joydeep</forenames></author><author><keyname>Mandal</keyname><forenames>Pradip</forenames></author><author><keyname>Guha</keyname><forenames>Prasanta Kumar</forenames></author></authors><title>A Review of Micromachined Thermal Accelerometers</title><categories>physics.app-ph eess.SP physics.class-ph</categories><journal-ref>Journal of Micromechanics and Microengineering 27 (12), 123002
  (18pp), November 2017</journal-ref><doi>10.1088/1361-6439/aa964d</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Thermal convection based micro-electromechanical accelerometer is a
relatively new kind of acceleration sensor that does not require a solid proof
mass, yielding unique benefits like high shock survival rating, low production
cost, and integrability with CMOS integrated circuit technology. This article
provides a comprehensive survey of the research, development, and current
trends in the field of thermal acceleration sensors, with detailed enumeration
on the theory, operation, modeling, and numerical simulation of such devices.
Different reported varieties and structures of thermal accelerometers have been
reviewed highlighting key design, implementation, and performance aspects.
Materials and technologies used for fabrication of such sensors have also been
discussed. Further, the advantages and challenges for thermal accelerometers
vis-\`a-vis other prominent accelerometer types have been presented, followed
by an overview of associated signal conditioning circuitry and potential
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07330</identifier>
 <datestamp>2018-10-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07330</id><created>2018-01-07</created><updated>2018-10-03</updated><authors><author><keyname>Zhang</keyname><forenames>Hao</forenames><affiliation>School of Optical and Electronic Informaiton, Huazhong University of Science and Technology, Wuhan, China</affiliation></author><author><keyname>Xie</keyname><forenames>Xinlin</forenames><affiliation>School of Optical and Electronic Informaiton, Huazhong University of Science and Technology, Wuhan, China</affiliation></author><author><keyname>Fang</keyname><forenames>Chunyu</forenames><affiliation>School of Optical and Electronic Informaiton, Huazhong University of Science and Technology, Wuhan, China</affiliation></author><author><keyname>Yang</keyname><forenames>Yicong</forenames><affiliation>School of Optical and Electronic Informaiton, Huazhong University of Science and Technology, Wuhan, China</affiliation></author><author><keyname>Jin</keyname><forenames>Di</forenames><affiliation>Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, U.S.A</affiliation></author><author><keyname>Fei</keyname><forenames>Peng</forenames><affiliation>School of Optical and Electronic Informaiton, Huazhong University of Science and Technology, Wuhan, China</affiliation><affiliation>Britton Chance Center for Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China</affiliation></author></authors><title>High-throughput, high-resolution registration-free generated adversarial
  network microscopy</title><categories>eess.IV cs.LG eess.SP physics.optics q-bio.QM q-bio.TO</categories><comments>21 pages, 9 figures and 1 table. Peng Fe and Di Jin conceived the
  ides, initiated the investigation. Hao Zhang, Di Jin and Peng Fei prepared
  the manuscript</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We combine generative adversarial network (GAN) with light microscopy to
achieve deep learning super-resolution under a large field of view (FOV). By
appropriately adopting prior microscopy data in an adversarial training, the
neural network can recover a high-resolution, accurate image of new specimen
from its single low-resolution measurement. Its capacity has been broadly
demonstrated via imaging various types of samples, such as USAF resolution
target, human pathological slides, fluorescence-labelled fibroblast cells, and
deep tissues in transgenic mouse brain, by both wide-field and light-sheet
microscopes. The gigapixel, multi-color reconstruction of these samples
verifies a successful GAN-based single image super-resolution procedure. We
also propose an image degrading model to generate low resolution images for
training, making our approach free from the complex image registration during
training dataset preparation. After a welltrained network being created, this
deep learning-based imaging approach is capable of recovering a large FOV (~95
mm2), high-resolution (~1.7 {\mu}m) image at high speed (within 1 second),
while not necessarily introducing any changes to the setup of existing
microscopes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07336</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07336</id><created>2018-01-22</created><authors><author><keyname>Jiang</keyname><forenames>Hao</forenames></author><author><keyname>Zhang</keyname><forenames>Zaichen</forenames></author><author><keyname>Wu</keyname><forenames>Liang</forenames></author><author><keyname>Dang</keyname><forenames>Jian</forenames></author><author><keyname>Gui</keyname><forenames>Guan</forenames></author></authors><title>A 3D Non-Stationary Wideband Geometry-Based Channel Model for MIMO
  Vehicle-to-Vehicle Communication System</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a three-dimensional (3D) non-wide-sense stationary
(non-WSS) wideband geometry-based channel model for vehicle-to-vehicle (V2V)
communication environments. We introduce a two-cylinder model to describe
moving vehicles as well as multiple confocal semi-ellipsoid models to depict
stationary roadside scenarios. The received signal is constructed as a sum of
the line-of-sight (LoS), single-, and double-bounced rays with different
energies. Accordingly, the proposed channel model is sufficient for depicting a
wide variety of V2V environments, such as macro-, micro-, and picocells. The
relative movement between the mobile transmitter (MT) and mobile receiver (MR)
results in time-variant geometric statistics that make our channel model
non-stationary. Using this channel model, the proposed channel statistics,
i.e., the time-variant space correlation functions (CFs), frequency CFs, and
corresponding Doppler power spectral density (PSD), were studied for different
relative moving time instants. The numerical results demonstrate that the
proposed 3D non-WSS wideband channel model is practical for characterizing real
V2V channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07356</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07356</id><created>2018-01-22</created><authors><author><keyname>Xu</keyname><forenames>Dongyang</forenames></author><author><keyname>Ren</keyname><forenames>Pinyi</forenames></author><author><keyname>Ritcey</keyname><forenames>James A.</forenames></author><author><keyname>Wang</keyname><forenames>Yichen</forenames></author></authors><title>Code-Frequency Block Group Coding for Anti-Spoofing Pilot Authentication
  in Multi-Antenna OFDM Systems</title><categories>cs.IT cs.CR eess.SP math.IT</categories><comments>accepted to IEEE Transactions on Information Forensics and Security,
  Jan. 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A pilot spoofer can paralyze the channel estimation in multi-user orthogonal
frequency-division multiplexing (OFD- M) systems by using the same
publicly-known pilot tones as legitimate nodes. This causes the problem of
pilot authentication (PA). To solve this, we propose, for a two-user
multi-antenna OFDM system, a code-frequency block group (CFBG) coding based PA
mechanism. Here multi-user pilot information, after being randomized
independently to avoid being spoofed, are converted into activation patterns of
subcarrier-block groups on code-frequency domain. Those patterns, though
overlapped and interfered mutually in the wireless transmission environment,
are qualified to be separated and identified as the original pilots with high
accuracy, by exploiting CFBG coding theory and channel characteristic.
Particularly, we develop the CFBG code through two steps, i.e., 1) devising an
ordered signal detection technique to recognize the number of signals
coexisting on each subcarrier block, and encoding each subcarrier block with
the detected number; 2) constructing a zero-false-drop (ZFD) code and block
detection based (BD) code via k-dimensional Latin hypercubes and integrating
those two codes into the CFBG code. This code can bring a desirable pilot
separation error probability (SEP), inversely proportional to the number of
occupied subcarriers and antennas with a power of k. To apply the code to PA, a
scheme of pilot conveying, separation and identification is proposed. Based on
this novel PA, a joint channel estimation and identification mechanism is
proposed to achieve high-precision channel recovery and simultaneously enhance
PA without occupying extra resources. Simulation results verify the
effectiveness of our proposed mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07359</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07359</id><created>2018-01-22</created><authors><author><keyname>Khuwaja</keyname><forenames>Aziz Altaf</forenames></author><author><keyname>Chen</keyname><forenames>Yunfei</forenames></author><author><keyname>Zhao</keyname><forenames>Nan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author><author><keyname>Dobbins</keyname><forenames>Paul</forenames></author></authors><title>A Survey of Channel Modeling for UAV Communications</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unmanned aerial vehicles (UAVs) have gained great interest for rapid
deployment in both civil and military applications. UAV communication has its
own distinctive channel characteristics compared with widely used cellular and
satellite systems. Thus, accurate channel characterization is crucial for the
performance optimization and design of efficient UAV communication systems.
However, several challenges exist in UAV channel modeling. For example,
propagation characteristics of UAV channels are still less explored for spatial
and temporal variations in non\textendash stationary channels. Also, airframe
shadowing has not yet been investigated for small size rotary UAVs. This paper
provides an extensive survey on the measurement campaigns launched for UAV
channel modeling using low altitude platforms and discusses various channel
characterization efforts. We also review the contemporary perspective of UAV
channel modeling approaches and outline some future research challenges in this
domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07446</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07446</id><created>2018-01-23</created><authors><author><keyname>Mozaffarzadeh</keyname><forenames>Moein</forenames></author><author><keyname>Mahloojifar</keyname><forenames>Ali</forenames></author><author><keyname>Orooji</keyname><forenames>Mahdi</forenames></author><author><keyname>Adabi</keyname><forenames>Saba</forenames></author><author><keyname>Nasiriavanaki</keyname><forenames>Mohammadreza</forenames></author></authors><title>Double-Stage Delay Multiply and Sum Beamforming Algorithm: Application
  to Linear-Array Photoacoustic Imaging</title><categories>eess.SP cs.IT math.IT</categories><comments>This paper is accepted in &quot;IEEE Transaction on Biomedical
  Engineering&quot;</comments><journal-ref>IEEE Transaction on Biomedical Engineering, Volume: 65, Issue 1,
  Jan. 2018</journal-ref><doi>10.1109/TBME.2017.2690959</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Photoacoustic imaging (PAI) is an emerging medical imaging modality capable
of providing high spatial resolution of Ultrasound (US) imaging and high
contrast of optical imaging. Delay-and-Sum (DAS) is the most common beamforming
algorithm in PAI. However, using DAS beamformer leads to low resolution images
and considerable contribution of off-axis signals. A new paradigm namely
Delay-Multiply-and-Sum (DMAS), which was originally used as a reconstruction
algorithm in confocal microwave imaging, was introduced to overcome the
challenges in DAS. DMAS was used in PAI systems and it was shown that this
algorithm results in resolution improvement and sidelobe degrading. However,
DMAS is still sensitive to high levels of noise, and resolution improvement is
not satisfying. Here, we propose a novel algorithm based on DAS algebra inside
DMAS formula expansion, Double Stage DMAS (DS-DMAS), which improves the image
resolution and levels of sidelobe, and is much less sensitive to high level of
noise compared to DMAS. The performance of DS-DMAS algorithm is evaluated
numerically and experimentally. The resulted images are evaluated qualitatively
and quantitatively using established quality metrics including signal-to-noise
ratio (SNR), full-width-half-maximum (FWHM) and contrast ratio (CR). It is
shown that DS-DMAS outperforms DAS and DMAS at the expense of higher
computational load. DS-DMAS reduces the lateral valley for about 15 dB and
improves the SNR and FWHM better than 13% and 30%, respectively. Moreover, the
levels of sidelobe are reduced for about 10 dB in comparison with those in
DMAS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07451</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07451</id><created>2018-01-23</created><authors><author><keyname>Sirinukunwattana</keyname><forenames>Korsuk</forenames></author><author><keyname>Snead</keyname><forenames>David</forenames></author><author><keyname>Epstein</keyname><forenames>David</forenames></author><author><keyname>Aftab</keyname><forenames>Zia</forenames></author><author><keyname>Mujeeb</keyname><forenames>Imaad</forenames></author><author><keyname>Tsang</keyname><forenames>Yee Wah</forenames></author><author><keyname>Cree</keyname><forenames>Ian</forenames></author><author><keyname>Rajpoot</keyname><forenames>Nasir</forenames></author></authors><title>Novel digital tissue phenotypic signatures of distant metastasis in
  colorectal cancer</title><categories>cs.CV eess.IV q-bio.TO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distant metastasis is the major cause of death in colorectal cancer (CRC).
Patients at high risk of developing distant metastasis could benefit from
appropriate adjuvant and follow-up treatments if stratified accurately at an
early stage of the disease. Studies have increasingly recognized the role of
diverse cellular components within the tumor microenvironment in the
development and progression of CRC tumors. In this paper, we show that a new
method of automated analysis of digitized images from colorectal cancer tissue
slides can provide important estimates of distant metastasis-free survival
(DMFS, the time before metastasis is first observed) on the basis of details of
the microenvironment. Specifically, we determine what cell types are found in
the vicinity of other cell types, and in what numbers, rather than
concentrating exclusively on the cancerous cells. We then extract novel tissue
phenotypic signatures using statistical measurements about tissue composition.
Such signatures can underpin clinical decisions about the advisability of
various types of adjuvant therapy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07499</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07499</id><created>2018-01-23</created><authors><author><keyname>Kang</keyname><forenames>Jian</forenames></author><author><keyname>Wang</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Schmitt</keyname><forenames>Michael</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author></authors><title>Object-based Multipass InSAR via Robust Low Rank Tensor Decomposition</title><categories>eess.IV</categories><doi>10.1109/TGRS.2018.2790480</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most unique advantage of multipass SAR interferometry (InSAR) is the
retrieval of long term geophysical parameters, e.g. linear deformation rates,
over large areas. Recently, an object-based multipass InSAR framework has been
proposed in [1], as an alternative to the typical single-pixel methods, e.g.
Persistent Scatterer Interferometry (PSI), or pixel-cluster-based methods, e.g.
SqueeSAR. This enables the exploitation of inherent properties of InSAR phase
stacks on an object level. As a followon, this paper investigates the inherent
low rank property of such phase tensors, and proposes a Robust Multipass InSAR
technique via Object-based low rank tensor decomposition (RoMIO). We
demonstrate that the filtered InSAR phase stacks can improve the accuracy of
geophysical parameters estimated via conventional multipass InSAR techniques,
e.g. PSI, by a factor of ten to thirty in typical settings. The proposed method
is particularly effective against outliers, such as pixels with unmodeled
phases. These merits in turn can effectively reduce the number of images
required for a reliable estimation. The promising performance of the proposed
method is demonstrated using high-resolution TerraSAR-X image stacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07532</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07532</id><created>2018-01-23</created><authors><author><keyname>Wang</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author></authors><title>The SARptical Dataset for Joint Analysis of SAR and Optical Image in
  Dense Urban Area</title><categories>eess.SP</categories><comments>This manuscript was submitted to IGARSS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The joint interpretation of very high resolution SAR and optical images in
dense urban area are not trivial due to the distinct imaging geometry of the
two types of images. Especially, the inevitable layover caused by the
side-looking SAR imaging geometry renders this task even more challenging. Only
until recently, the &quot;SARptical&quot; framework [1], [2] proposed a promising
solution to tackle this. SARptical can trace individual SAR scatterers in
corresponding high-resolution optical images, via rigorous 3-D reconstruction
and matching. This paper introduces the SARptical dataset, which is a dataset
of over 10,000 pairs of corresponding SAR, and optical image patches extracted
from TerraSAR-X high-resolution spotlight images and aerial UltraCAM optical
images. This dataset opens new opportunities of multisensory data analysis. One
can analyze the geometry, material, and other properties of the imaged object
in both SAR and optical image domain. More advanced applications such as SAR
and optical image matching via deep learning [3] is now also possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07536</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07536</id><created>2018-01-23</created><authors><author><keyname>Montazeri</keyname><forenames>Sina</forenames></author><author><keyname>Gisinger</keyname><forenames>Christoph</forenames></author><author><keyname>Eineder</keyname><forenames>Michael</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author></authors><title>Automatic Detection and Positioning of Ground Control Points Using
  TerraSAR-X Multi-Aspect Acquisitions</title><categories>eess.SP</categories><doi>10.1109/TGRS.2017.2769078</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geodetic stereo Synthetic Aperture Radar (SAR) is capable of absolute
three-dimensional localization of natural Persistent Scatterer (PS)s which
allows for Ground Control Point (GCP) generation using only SAR data. The
prerequisite for the method to achieve high precision results is the correct
detection of common scatterers in SAR images acquired from different viewing
geometries. In this contribution, we describe three strategies for automatic
detection of identical targets in SAR images of urban areas taken from
different orbit tracks. Moreover, a complete work-flow for automatic generation
of large number of GCPs using SAR data is presented and its applicability is
shown by exploiting TerraSAR-X (TS-X) high resolution spotlight images over the
city of Oulu, Finland and a test site in Berlin, Germany.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07562</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07562</id><created>2018-01-10</created><updated>2019-02-08</updated><authors><author><keyname>Bedeer</keyname><forenames>Ebrahim</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Ahmed</keyname><forenames>Mohamed H.</forenames></author><author><keyname>Baddour</keyname><forenames>Kareem E.</forenames></author></authors><title>Rate-Interference Tradeoff in OFDM-based Cognitive Radio Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>GC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cognitive radio (CR) networks, secondary users (SUs) are allowed to
opportunistically access the primary users (PUs) spectrum to improve the
spectrum utilization; however, this increases the interference levels at the
PUs. In this paper, we consider an orthogonal frequency division multiplexing
OFDM-based CR network and investigate the tradeoff between increasing the SU
transmission rate (hence improving the spectrum utilization) and reducing the
interference levels at the PUs. We formulate a new multiobjective optimization
(MOOP) problem that jointly maximizes the SU transmission rate and minimizes
its transmit power, while imposing interference thresholds to the PUs. Further,
we propose an algorithm to strike a balance between the SU transmission rate
and the interference levels to the PUs. The proposed algorithm considers the
practical scenario of knowing partial channel state information (CSI) of the
links between the SU transmitter and the PUs receivers. Simulation results
illustrate the performance of the proposed algorithm and its superiority when
compared to the work in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07566</identifier>
 <datestamp>2019-02-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07566</id><created>2018-01-11</created><updated>2019-02-08</updated><authors><author><keyname>Bedeer</keyname><forenames>Ebrahim</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Ahmed</keyname><forenames>Mohamed H.</forenames></author><author><keyname>Baddour</keyname><forenames>Kareem E.</forenames></author></authors><title>A Novel Algorithm for Rate/Power Allocation in OFDM-based Cognitive
  Radio Systems with Statistical Interference Constraints</title><categories>eess.SP</categories><comments>GC 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we adopt a multiobjective optimization approach to jointly
optimize the rate and power in OFDM-based cognitive radio (CR) systems. We
propose a novel algorithm that jointly maximizes the OFDM-based CR system
throughput and minimizes its transmit power, while guaranteeing a target bit
error rate per subcarrier and a total transmit power threshold for the
secondary user (SU), and restricting both co-channel and adjacent channel
interferences to existing primary users (PUs) in a statistical manner. Since
the interference constraints are met statistically, the SU transmitter does not
require perfect channel-state-information (CSI) feedback from the PUs
receivers. Closed-form expressions are derived for bit and power allocations
per subcarrier. Simulation results illustrate the performance of the proposed
algorithm and compare it to the case of perfect CSI. Further, the results show
that the performance of the proposed algorithm approaches that of an exhaustive
search for the discrete global optimal allocations with significantly reduced
computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07567</identifier>
 <datestamp>2019-02-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07567</id><created>2018-01-11</created><updated>2019-02-08</updated><authors><author><keyname>Bedeer</keyname><forenames>Ebrahim</forenames></author><author><keyname>Marey</keyname><forenames>Mohamed F.</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Ahmed</keyname><forenames>Mohamed H.</forenames></author><author><keyname>Baddour</keyname><forenames>Kareem E.</forenames></author></authors><title>A Novel Algorithm for Joint Bit and Power Loading for OFDM Systems with
  Unknown Interference</title><categories>eess.SP</categories><comments>ICC 2012. arXiv admin note: substantial text overlap with
  arXiv:1801.07569, arXiv:1801.07568, arXiv:1801.07571</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel low complexity bit and power loading algorithm is
formulated for orthogonal frequency division multiplexing (OFDM) systems
operating in fading environments and in the presence of unknown interference.
The proposed non-iterative algorithm jointly maximizes the throughput and
minimizes the transmitted power, while guaranteeing a target bit error rate
(BER) per subcarrier. Closed-form expressions are derived for the optimal bit
and power distributions per subcarrier. The performance of the proposed
algorithm is investigated through extensive simulations. A performance
comparison with the algorithm in [1] shows the superiority of the proposed
algorithm with reduced computational effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07568</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07568</id><created>2018-01-11</created><updated>2019-02-08</updated><authors><author><keyname>Bedeer</keyname><forenames>Ebrahim</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Ahmed</keyname><forenames>Mohamed H.</forenames></author><author><keyname>Baddour</keyname><forenames>Kareem E.</forenames></author></authors><title>Optimal Bit and Power Loading for OFDM Systems with Average BER and
  Total Power Constraints</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1801.07569,
  arXiv:1801.07567, arXiv:1801.07571</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel joint bit and power loading algorithm is proposed for
orthogonal frequency division multiplexing (OFDM) systems operating in fading
environments. The algorithm jointly maximizes the throughput and minimizes the
transmitted power, while guaranteeing a target average bit error rate (BER) and
meeting a constraint on the total transmit power. Simulation results are
described that illustrate the performance of the proposed scheme and
demonstrate its superiority when compared to the algorithm in [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07569</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07569</id><created>2018-01-11</created><updated>2019-02-08</updated><authors><author><keyname>Bedeer</keyname><forenames>Ebrahim</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Ahmed</keyname><forenames>Mohamed H.</forenames></author><author><keyname>Baddour</keyname><forenames>Kareem E.</forenames></author></authors><title>Constrained Joint Bit and Power Allocation for Multicarrier Systems</title><categories>eess.SP</categories><comments>GC 2012. arXiv admin note: substantial text overlap with
  arXiv:1801.07568, arXiv:1801.07567, arXiv:1801.07571</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel low complexity joint bit and power suboptimal
allocation algorithm for multicarrier systems operating in fading environments.
The algorithm jointly maximizes the throughput and minimizes the transmitted
power, while guaranteeing a target bit error rate (BER) per subcarrier and
meeting a constraint on the total transmit power. Simulation results are
described that illustrate the performance of the proposed scheme and
demonstrate its superiority when compared to the algorithm in [4] with similar
or reduced computational complexity. Furthermore, the results show that the
performance of the proposed suboptimal algorithm approaches that of an optimal
exhaustive search with significantly lower computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07571</identifier>
 <datestamp>2019-02-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07571</id><created>2018-01-12</created><updated>2019-02-08</updated><authors><author><keyname>Bedeer</keyname><forenames>Ebrahim</forenames></author><author><keyname>Dobre</keyname><forenames>Octavia A.</forenames></author><author><keyname>Ahmed</keyname><forenames>Mohamed H.</forenames></author><author><keyname>Baddour</keyname><forenames>Kareem E.</forenames></author></authors><title>Joint Optimization of Bit and Power Loading for Multicarrier Systems</title><categories>eess.SP</categories><comments>Accepted to WCL. arXiv admin note: substantial text overlap with
  arXiv:1801.07569, arXiv:1801.07568, arXiv:1801.07567</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, a novel low complexity bit and power loading algorithm is
formulated for multicarrier communication systems. The proposed algorithm
jointly maximizes the throughput and minimizes the transmit power through a
weighting coefficient $\alpha$, while meeting constraints on the target bit
error rate (BER) per subcarrier and on the total transmit power. The
optimization problem is solved by the Lagrangian multiplier method if the
initial $\alpha$ causes the transmit power not to violate the power constraint;
otherwise, a bisection search is used to find the appropriate $\alpha$.
Closed-form expressions are derived for the close-to-optimal bit and power
allocations per subcarrier, average throughput, and average transmit power.
Simulation results illustrate the performance of the proposed algorithm and
demonstrate its superiority with respect to existing allocation algorithms.
Furthermore, the results show that the performance of the proposed algorithm
approaches that of the exhaustive search for the discrete optimal allocations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07578</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07578</id><created>2018-01-18</created><authors><author><keyname>Pham</keyname><forenames>Thinh Hung</forenames></author><author><keyname>Prasad</keyname><forenames>Vinod A.</forenames></author><author><keyname>Madhukumar</keyname><forenames>A. S.</forenames></author></authors><title>A Hardware-Efficient Synchronization in L-DACS1 for Aeronautical
  Communications</title><categories>eess.SP</categories><comments>arXiv admin note: substantial text overlap with arXiv:1801.05908</comments><doi>10.1109/TVLSI.2018.2789467</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  L-band digital aeronautical communication system type-1 (L-DACS1) is an
emerging standard that aims at enhancing air traffic management by
transitioning the traditional analog aeronautical communication systems to the
superior and highly efficient digital domain. L-DACS1 employs modern and
efficient orthogonal frequency-division multiplexing (OFDM) modulation
technique to achieve more efficient and higher data rate in comparison to the
existing aeronautical communication systems. However, the performance of OFDM
systems is very sensitive to synchronization errors such as symbol timing
offset (STO) and carrier frequency offset (CFO). STO and CFO estimations are
extremely important for maintaining orthogonality among the subcarriers for the
retrieval of information. This paper proposes a novel efficient hardware
synchronizer for L-DACS1 systems that offers robust performance at low power
and low hardware resource usage. Monte Carlo simulations show that the proposed
synchronization algorithm provides accurate STO estimation as well as
fractional CFO estimation. Implementation of the proposed synchronizer on a
widely used field-programmable gate array (FPGA) (Xilinx xc7z020clg484-1)
results in a very low hardware usage which consumed 6.5%, 3.7%, and 6.4% of the
total number of lookup tables, flip-flops, and digital signal processing
blocks, respectively. The dynamic power of the proposed synchronizer is below 1
mW.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07851</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07851</id><created>2018-01-23</created><authors><author><keyname>Chen</keyname><forenames>Xuechen</forenames></author></authors><title>Zero-Delay Gaussian Joint Source-Channel Coding for the Interference
  Channel</title><categories>eess.SP</categories><comments>15 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies zero-delay joint source channel coding (JSCC) for
transmission of correlated Gaussian sources over a Gaussian interference
channel (GIC). We propose to adopt delay-free hybrid digital and analog (HDA)
scheme, which is, transmitting the superposition of scaled source and its
quantized version after applying scalar quantization to the source at each
transmitter. At the corresponding receiver, two kinds of estimators are
presented. It is shown that both the schemes, when optimized, beat the uncoded
transmission if the channel signal-to-noise ratio (CSNR) is higher than a
threshold value for different correlation coefficients and interference values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07871</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07871</id><created>2018-01-24</created><authors><author><keyname>Zhu</keyname><forenames>Shuaishuai</forenames></author><author><keyname>Jin</keyname><forenames>Peng</forenames></author><author><keyname>Liang</keyname><forenames>Rongguang</forenames></author><author><keyname>Gao</keyname><forenames>Liang</forenames></author></authors><title>Snapshot light-field laryngoscope</title><categories>eess.IV</categories><comments>15 pages, 6 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The convergence of recent advances in optical fabrication and digital
processing yields a new generation of imaging technology: light-field cameras,
which bridge the realms of applied mathematics, optics, and high-performance
computing. Herein for the first time, we introduce the paradigm of light-field
imaging into laryngoscopy. The resultant probe can image the three-dimensional
(3D) shape of vocal folds within a single camera exposure. Furthermore, to
improve the spatial resolution, we developed an image fusion algorithm,
providing a simple solution to a long-standing problem in light-field imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07910</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07910</id><created>2018-01-24</created><authors><author><keyname>Ling</keyname><forenames>Zhen-Hua</forenames></author><author><keyname>Ai</keyname><forenames>Yang</forenames></author><author><keyname>Gu</keyname><forenames>Yu</forenames></author><author><keyname>Dai</keyname><forenames>Li-Rong</forenames></author></authors><title>Waveform Modeling and Generation Using Hierarchical Recurrent Neural
  Networks for Speech Bandwidth Extension</title><categories>cs.SD eess.AS</categories><comments>Accepted by IEEE Transactions on Audio, Speech and Language
  Processing</comments><doi>10.1109/TASLP.2018.2798811</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a waveform modeling and generation method using
hierarchical recurrent neural networks (HRNN) for speech bandwidth extension
(BWE). Different from conventional BWE methods which predict spectral
parameters for reconstructing wideband speech waveforms, this BWE method models
and predicts waveform samples directly without using vocoders. Inspired by
SampleRNN which is an unconditional neural audio generator, the HRNN model
represents the distribution of each wideband or high-frequency waveform sample
conditioned on the input narrowband waveform samples using a neural network
composed of long short-term memory (LSTM) layers and feed-forward (FF) layers.
The LSTM layers form a hierarchical structure and each layer operates at a
specific temporal resolution to efficiently capture long-span dependencies
between temporal sequences. Furthermore, additional conditions, such as the
bottleneck (BN) features derived from narrowband speech using a deep neural
network (DNN)-based state classifier, are employed as auxiliary input to
further improve the quality of generated wideband speech. The experimental
results of comparing several waveform modeling methods show that the HRNN-based
method can achieve better speech quality and run-time efficiency than the
dilated convolutional neural network (DCNN)-based method and the plain
sample-level recurrent neural network (SRNN)-based method. Our proposed method
also outperforms the conventional vocoder-based BWE method using LSTM-RNNs in
terms of the subjective quality of the reconstructed wideband speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.07967</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.07967</id><created>2018-01-24</created><authors><author><keyname>Bertilsson</keyname><forenames>Erik</forenames></author><author><keyname>Gustafsson</keyname><forenames>Oscar</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>A Distributed Processing Architecture for Modular and Scalable Massive
  MIMO Base Stations</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a scalable and modular architecture for massive MIMO base
stations with distributed processing is proposed. New antennas can readily be
added by adding a new node as each node handles all the additional involved
processing. The architecture supports conjugate beamforming, zero-forcing, and
MMSE, where for the two latter cases a central matrix inversion is required.
The impact of the time required for this matrix inversion is carefully analyzed
along with a generic frame format. As part of the contribution, careful
computational, memory, and communication analyses are presented. It is shown
that all computations can be mapped to a single computational structure and
that a processing node consisting of a single such processing element can
handle a broad range of bandwidths and number of terminals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08085</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.08085</id><created>2018-01-02</created><authors><author><keyname>Shah</keyname><forenames>Vinit</forenames></author><author><keyname>von Weltin</keyname><forenames>Eva</forenames></author><author><keyname>Lopez</keyname><forenames>Silvia</forenames></author><author><keyname>McHugh</keyname><forenames>James Riley</forenames></author><author><keyname>Veloso</keyname><forenames>Lily</forenames></author><author><keyname>Golmohammadi</keyname><forenames>Meysam</forenames></author><author><keyname>Obeid</keyname><forenames>Iyad</forenames></author><author><keyname>Picone</keyname><forenames>Joseph</forenames></author></authors><title>The Temple University Hospital Seizure Detection Corpus</title><categories>q-bio.QM eess.SP q-bio.NC stat.ML</categories><comments>Under review in Frontiers in Neuroscience</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the TUH EEG Seizure Corpus (TUSZ), which is the largest open
source corpus of its type, and represents an accurate characterization of
clinical conditions. In this paper, we describe the techniques used to develop
TUSZ, evaluate their effectiveness, and present some descriptive statistics on
the resulting corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08268</identifier>
 <datestamp>2018-12-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.08268</id><created>2018-01-24</created><authors><author><keyname>Gewali</keyname><forenames>Utsav B.</forenames></author><author><keyname>Monteiro</keyname><forenames>Sildomar T.</forenames></author></authors><title>A Tutorial on Modeling and Inference in Undirected Graphical Models for
  Hyperspectral Image Analysis</title><categories>cs.CV eess.IV</categories><doi>10.1080/01431161.2018.1465614</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Undirected graphical models have been successfully used to jointly model the
spatial and the spectral dependencies in earth observing hyperspectral images.
They produce less noisy, smooth, and spatially coherent land cover maps and
give top accuracies on many datasets. Moreover, they can easily be combined
with other state-of-the-art approaches, such as deep learning. This has made
them an essential tool for remote sensing researchers and practitioners.
However, graphical models have not been easily accessible to the larger remote
sensing community as they are not discussed in standard remote sensing
textbooks and not included in the popular remote sensing software and
toolboxes. In this tutorial, we provide a theoretical introduction to Markov
random fields and conditional random fields based spatial-spectral
classification for land cover mapping along with a detailed step-by-step
practical guide on applying these methods using freely available software.
Furthermore, the discussed methods are benchmarked on four public hyperspectral
datasets for a fair comparison among themselves and easy comparison with the
vast number of methods in literature which use the same datasets. The source
code necessary to reproduce all the results in the paper is published on-line
to make it easier for the readers to apply these techniques to different remote
sensing problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08408</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.08408</id><created>2018-01-08</created><authors><author><keyname>Yang</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Ten</keyname><forenames>Chee-Wooi</forenames></author></authors><title>Cyber-Induced Risk Modeling for Microprocessor-Based Relays in
  Substations</title><categories>eess.SP</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Once critical substations are compromised, attack agents can coordinate among
their peers to plot for maximizing disruption using local control devices. For
defenders, it is critical to enumerate and identify all digital relays to
determine the systemic risks. Any combination of disruptive switching via the
compromised relays can result in misoperation or immediate effect to the
system. The resulting consequence of these attack's initial events would
possibly incur cascading failure to a grid. This paper quantifies the
criticality of substation protective relays with the combination of the outage
level and its corresponding severity risk index. The proposed hypothesized
outages are based on the type of protective relaying, bus configuration of a
substation, and commonly implemented relaying schemes, such as bus
differential, directional overcurrent, and distance relays, are studied. This
preliminary work also provides three approaches of determination in
probabilities for sensitivity analysis. The proposed risk indices are evaluated
using IEEE test systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08444</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.08444</id><created>2018-01-25</created><authors><author><keyname>Siljak</keyname><forenames>Harun</forenames></author><author><keyname>Subasi</keyname><forenames>Abdulhamit</forenames></author><author><keyname>Upadhyaya</keyname><forenames>Belle R.</forenames></author></authors><title>Hardware implementation of auto-mutual information function for
  condition monitoring</title><categories>cs.OH eess.SP</categories><doi>10.1016/j.compeleceng.2018.01.038</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study is aimed at showing applicability of mutual information, namely
auto-mutual information function for condition monitoring in electrical motors,
through age detection in accelerated motor aging. Vibration data collected in
artificial induction motor experiment is used for verification of both the
original auto-mutual information function algorithm and its hardware
implementation in Verilog, produced from an initial version made with Matlab
HDL (Hardware Description Language) Coder. A conceptual model for industry and
education based on a field programmable logic array development board is
developed and demonstrated on the auto-mutual information function example,
while suggesting other applications as well. It has also been shown that
attractor reconstruction for the vibration data cannot be straightforward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08445</identifier>
 <datestamp>2018-08-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.08445</id><created>2018-01-25</created><updated>2018-08-09</updated><authors><author><keyname>Fehenberger</keyname><forenames>Tobias</forenames></author><author><keyname>Millar</keyname><forenames>David S.</forenames></author><author><keyname>Koike-Akino</keyname><forenames>Toshiaki</forenames></author><author><keyname>Kojima</keyname><forenames>Keisuke</forenames></author><author><keyname>Parsons</keyname><forenames>Kieran</forenames></author></authors><title>Multiset-Partition Distribution Matching</title><categories>eess.SP</categories><comments>9 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distribution matching is a fixed-length invertible mapping from a uniformly
distributed bit sequence to shaped amplitudes and plays an important role in
the probabilistic amplitude shaping framework. With conventional
constantcomposition distribution matching (CCDM), all output sequences have
identical composition. In this paper, we propose multisetpartition distribution
matching (MPDM) where the composition is constant over all output sequences.
When considering the desired distribution as a multiset, MPDM corresponds to
partitioning this multiset into equal-size subsets. We show that MPDM allows to
address more output sequences and thus has lower rate loss than CCDM in all
nontrivial cases. By imposing some constraints on the partitioning, a
constructive MPDM algorithm is proposed which comprises two parts. A
variable-length prefix of the binary data word determines the composition to be
used, and the remainder of the input word is mapped with a conventional CCDM
algorithm, such as arithmetic coding, according to the chosen composition.
Simulations of 64-ary quadrature amplitude modulation over the additive white
Gaussian noise channel demonstrate that the block-length saving of MPDM over
CCDM for a fixed gap to capacity is approximately a factor of 2.5 to 5 at
medium to high signal-to-noise ratios (SNRs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08467</identifier>
 <datestamp>2018-05-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.08467</id><created>2018-01-25</created><authors><author><keyname>Hughes</keyname><forenames>Lloyd H.</forenames></author><author><keyname>Schmitt</keyname><forenames>Michael</forenames></author><author><keyname>Mou</keyname><forenames>Lichao</forenames></author><author><keyname>Wang</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author></authors><title>Identifying Corresponding Patches in SAR and Optical Images with a
  Pseudo-Siamese CNN</title><categories>eess.IV cs.CV</categories><doi>10.1109/LGRS.2018.2799232</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we propose a pseudo-siamese convolutional neural network
(CNN) architecture that enables to solve the task of identifying corresponding
patches in very-high-resolution (VHR) optical and synthetic aperture radar
(SAR) remote sensing imagery. Using eight convolutional layers each in two
parallel network streams, a fully connected layer for the fusion of the
features learned in each stream, and a loss function based on binary
cross-entropy, we achieve a one-hot indication if two patches correspond or
not. The network is trained and tested on an automatically generated dataset
that is based on a deterministic alignment of SAR and optical imagery via
previously reconstructed and subsequently co-registered 3D point clouds. The
satellite images, from which the patches comprising our dataset are extracted,
show a complex urban scene containing many elevated objects (i.e. buildings),
thus providing one of the most difficult experimental environments. The
achieved results show that the network is able to predict corresponding patches
with high accuracy, thus indicating great potential for further development
towards a generalized multi-sensor key-point matching procedure. Index
Terms-synthetic aperture radar (SAR), optical imagery, data fusion, deep
learning, convolutional neural networks (CNN), image matching, deep matching
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08479</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.08479</id><created>2018-01-25</created><updated>2018-03-27</updated><authors><author><keyname>Florea</keyname><forenames>Mihai I.</forenames></author><author><keyname>Basarab</keyname><forenames>Adrian</forenames></author><author><keyname>Kouam&#xe9;</keyname><forenames>Denis</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author></authors><title>An axially-variant kernel imaging model applied to ultrasound image
  reconstruction</title><categories>eess.SP</categories><msc-class>92C55</msc-class><doi>10.1109/LSP.2018.2824764</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing ultrasound deconvolution approaches unrealistically assume,
primarily for computational reasons, that the convolution model relies on a
spatially invariant kernel and circulant boundary conditions. We discard both
restrictions and introduce an image formation model applicable to ultrasound
imaging and deconvolution based on an axially varying kernel, that accounts for
arbitrary boundary conditions. Our model has the same computational complexity
as the one employing spatially invariant convolution and has negligible memory
requirements. To accommodate state-of-the-art deconvolution approaches when
applied to a variety of inverse problem formulations, we also provide an
equally efficient adjoint expression of our model. Simulation results confirm
the tractability of our model for the deconvolution of large images. Moreover,
the quality of reconstruction using our model is superior to that obtained
using spatially invariant convolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08535</identifier>
 <datestamp>2018-07-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.08535</id><created>2018-01-24</created><updated>2018-07-01</updated><authors><author><keyname>Yuan</keyname><forenames>Xuejing</forenames></author><author><keyname>Chen</keyname><forenames>Yuxuan</forenames></author><author><keyname>Zhao</keyname><forenames>Yue</forenames></author><author><keyname>Long</keyname><forenames>Yunhui</forenames></author><author><keyname>Liu</keyname><forenames>Xiaokang</forenames></author><author><keyname>Chen</keyname><forenames>Kai</forenames></author><author><keyname>Zhang</keyname><forenames>Shengzhi</forenames></author><author><keyname>Huang</keyname><forenames>Heqing</forenames></author><author><keyname>Wang</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Gunter</keyname><forenames>Carl A.</forenames></author></authors><title>CommanderSong: A Systematic Approach for Practical Adversarial Voice
  Recognition</title><categories>cs.CR cs.LG cs.SD eess.AS</categories><comments>Accepted by USENIX Security 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The popularity of ASR (automatic speech recognition) systems, like Google
Voice, Cortana, brings in security concerns, as demonstrated by recent attacks.
The impacts of such threats, however, are less clear, since they are either
less stealthy (producing noise-like voice commands) or requiring the physical
presence of an attack device (using ultrasound). In this paper, we demonstrate
that not only are more practical and surreptitious attacks feasible but they
can even be automatically constructed. Specifically, we find that the voice
commands can be stealthily embedded into songs, which, when played, can
effectively control the target system through ASR without being noticed. For
this purpose, we developed novel techniques that address a key technical
challenge: integrating the commands into a song in a way that can be
effectively recognized by ASR through the air, in the presence of background
noise, while not being detected by a human listener. Our research shows that
this can be done automatically against real world ASR applications. We also
demonstrate that such CommanderSongs can be spread through Internet (e.g.,
YouTube) and radio, potentially affecting millions of ASR users. We further
present a new mitigation technique that controls this threat.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08584</identifier>
 <datestamp>2019-04-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.08584</id><created>2018-01-25</created><authors><author><keyname>Torres-Ferrera</keyname><forenames>Pablo</forenames></author><author><keyname>Ferrero</keyname><forenames>Valter</forenames></author><author><keyname>Valvo</keyname><forenames>Maurizio</forenames></author><author><keyname>Gaudino</keyname><forenames>Roberto</forenames></author></authors><title>Impact of the Overall Electrical Filter Shaping in Next-Generation 25G
  and 50G PON</title><categories>eess.SP</categories><comments>12 pages, 11 figures</comments><doi>10.1364/JOCN.10.000493</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next-generation high-speed passive optical network (HS-PON) transceivers
supporting 25, 50 and 100 Gb/s are under the early stage of their
standardization process. One key aspect of this process is the choice of the
best modulation format. To this end, performance comparisons among several
modulation formats against different physical constraints have been presented
in literature and are still being carried out. In our contribution, we
performed an exhaustive analysis on the impact of transceivers electrical
frequency response shape on the performance of 2-levels pulse amplitude
modulation (PAM-2), 4-levels PAM (PAM-4), electrical and optical duobinary
modulation formats with adaptive equalizer at the receiver side. We show by
means of numerical simulations that the specification of the typically used
-3dB bandwidth is not sufficient, since also out-of-band electrical frequency
response specifications (such as the -20dB bandwidth) has a huge impact on the
performance of the analyzed modulation formats. The normalized graphs given at
the end of the paper in terms of -3dB and -20 dB bandwidths can thus be useful
for the design of the next generation of HS-PON transceivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.08639</identifier>
 <datestamp>2018-07-19</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.08639</id><created>2018-01-25</created><updated>2018-07-18</updated><authors><author><keyname>Huynh</keyname><forenames>Thang</forenames></author><author><keyname>Saab</keyname><forenames>Rayan</forenames></author></authors><title>Fast binary embeddings, and quantized compressed sensing with structured
  matrices</title><categories>cs.IT eess.SP math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with two related problems, namely distance-preserving binary
embeddings and quantization for compressed sensing . First, we propose fast
methods to replace points from a subset $\mathcal{X} \subset \mathbb{R}^n$,
associated with the Euclidean metric, with points in the cube $\{\pm 1\}^m$ and
we associate the cube with a pseudo-metric that approximates Euclidean distance
among points in $\mathcal{X}$. Our methods rely on quantizing fast
Johnson-Lindenstrauss embeddings based on bounded orthonormal systems and
partial circulant ensembles, both of which admit fast transforms. Our
quantization methods utilize noise-shaping, and include Sigma-Delta schemes and
distributed noise-shaping schemes. The resulting approximation errors decay
polynomially and exponentially fast in $m$, depending on the embedding method.
This dramatically outperforms the current decay rates associated with binary
embeddings and Hamming distances. Additionally, it is the first such binary
embedding result that applies to fast Johnson-Lindenstrauss maps while
preserving $\ell_2$ norms.
  Second, we again consider noise-shaping schemes, albeit this time to quantize
compressed sensing measurements arising from bounded orthonormal ensembles and
partial circulant matrices. We show that these methods yield a reconstruction
error that again decays with the number of measurements (and bits), when using
convex optimization for reconstruction. Specifically, for Sigma-Delta schemes,
the error decays polynomially in the number of measurements, and it decays
exponentially for distributed noise-shaping schemes based on beta encoding.
These results are near optimal and the first of their kind dealing with bounded
orthonormal systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09045</identifier>
 <datestamp>2018-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09045</id><created>2018-01-27</created><authors><author><keyname>Sircar</keyname><forenames>Pradip</forenames></author></authors><title>Parametric Modeling of Non-Stationary Signals</title><categories>eess.SP cs.NA</categories><comments>8 pages, 4 figures, 4 tables</comments><report-no>SciTopics, 2011, October 31</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parametric modeling of non-stationary signals is addressed in this article.
We present several models based on the characteristic features of the modeled
signal, together with the methods for accurate estimation of model parameters.
Non-stationary signals, viz. transient system response, speech phonemes, and
electrocardiograph signal are fitted by these feature-based models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09135</identifier>
 <datestamp>2019-11-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09135</id><created>2018-01-27</created><updated>2019-11-06</updated><authors><author><keyname>Keni</keyname><forenames>Nishant Deepak</forenames></author><author><keyname>Singbal</keyname><forenames>Amol Mangirish</forenames></author><author><keyname>Ahmed</keyname><forenames>Rizwan</forenames></author></authors><title>Reconstruction of Compressively Sensed Images using Convex Tikhonov
  Sparse Dictionary Learning and Adaptive Spectral Filtering</title><categories>eess.IV</categories><comments>This work is obsolete</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse representation using over-complete dictionaries have shown to produce
good quality results in various image processing tasks. Dictionary learning
algorithms have made it possible to engineer data adaptive dictionaries which
have promising applications in image compression and image enhancement. The
most common sparse dictionary learning algorithms use the techniques of
matching pursuit and K-SVD iteratively for sparse coding and dictionary
learning respectively. While this technique produces good results, it requires
a large number of iterations to converge to an optimal solution. In this
article, we use a closed form stabilized convex optimization technique for both
sparse coding and dictionary learning. The approach results in providing the
best possible dictionary and the sparsest representation resulting in minimum
reconstruction error. Once the image is reconstructed from the compressively
sensed samples, we use adaptive frequency and spatial filtering techniques to
move towards exact image recovery. It is clearly seen from the results that the
proposed algorithm provides much better reconstruction results than
conventional sparse dictionary techniques for a fixed number of iterations.
Depending inversely upon the number of details present in the image, the
proposed algorithm reaches the optimal solution with a significantly lower
number of iterations. Consequently, high PSNR and low MSE is obtained using the
proposed algorithm for our compressive sensing framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09161</identifier>
 <datestamp>2018-12-11</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09161</id><created>2018-01-27</created><updated>2018-12-08</updated><authors><author><keyname>Saidi</keyname><forenames>Pouria</forenames></author><author><keyname>Vosoughi</keyname><forenames>Azadeh</forenames></author><author><keyname>Atia</keyname><forenames>George</forenames></author></authors><title>Detection of Brain Stimuli Using Ramanujan Periodicity Transforms</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to efficiently match the frequency of the brain's response to
repetitive visual stimuli in real time is the basis for reliable SSVEP-based
Brain-Computer-Interfacing (BCI). The detection of different stimuli is posed
as a composite hypothesis test, where SSVEPs are assumed to admit a sparse
representation in a Ramanujan Periodicity Transform (RPT) dictionary. For the
binary case, we develop and analyze the performance of an RPT detector based on
a derived generalized likelihood ratio test. Our approach is extended to
multi-hypothesis multi-electrode settings, where we capture the spatial
correlation between the electrodes using pre-stimulus data. We also introduce a
new metric for evaluating SSVEP detection schemes based on their achievable
efficiency and discrimination rate tradeoff for given system resources. We
obtain exact distributions of the test statistic in terms of confluent
hypergeometric functions. Results based on extensive simulations with both
synthesized and real data indicate that the RPT detector substantially
outperforms spectral-based methods. Its performance also surpasses the
state-of-the-art Canonical Correlation Analysis (CCA) methods with respect to
accuracy and sample complexity in short data lengths regimes crucial for
real-time applications. The proposed approach is asymptotically optimal as it
closes the gap to a perfect measurement bound as the data length increases. In
contrast to existing supervised methods which are highly data-dependent, the
RPT detector only uses pre-stimulus data to estimate the per-subject spatial
correlation, thereby dispensing with considerable overhead associated with data
collection for a large number of subjects and stimuli. Our work advances the
theory and practice of emerging real-time BCI and affords a new framework for
comparing SSVEP detection schemes across a wider spectrum of operating regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09166</identifier>
 <datestamp>2018-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09166</id><created>2018-01-27</created><authors><author><keyname>Zhou</keyname><forenames>Jun</forenames></author><author><keyname>Dong</keyname><forenames>Xiaodai</forenames></author><author><keyname>Lu</keyname><forenames>Wu-Sheng</forenames></author></authors><title>Optimal Energy Management Strategies in Wireless Data and Energy
  Cooperative Communications</title><categories>eess.SP cs.IT math.IT</categories><comments>30pages, 12 figures, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new cooperative wireless communication network strategy
that incorporates energy cooperation and data cooperation. The model
establishment, design goal formulations, and algorithms for throughput
maximization of the proposed protocol are presented and illustrated using a
three-node network with two energy harvesting (EH) user nodes and a destination
node. Transmission models are established from the performance analysis for a
total of four scenarios. Based on the models, we seek to find optimal energy
management strategies by jointly optimizing time allocation for each user,
power allocations over these time intervals, and data throughputs at user nodes
so as to maximize the sum-throughput or, alternatively, the minimum throughput
of the two users in all scenarios. An accelerated Newton barrier algorithm and
an alternative algorithm based on local quadratic approximation of the
transmission models are developed to solve the aforementioned optimization
problems. Numerical experiments under practical settings provide supportive
observations to our performance analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09176</identifier>
 <datestamp>2018-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09176</id><created>2018-01-27</created><authors><author><keyname>Zhao</keyname><forenames>Lou</forenames></author><author><keyname>Wei</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Ng</keyname><forenames>Derrick Wing Kwan</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author><author><keyname>Reed</keyname><forenames>Mark C.</forenames></author></authors><title>Mitigating Pilot Contamination in Multi-cell Hybrid Millimeter Wave
  Systems</title><categories>eess.SP cs.IT math.IT</categories><comments>Accepted to appear in ICC 2018, Kansas City, MO, 7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the system performance of a multi-cell
multi-user (MU) hybrid millimeter wave (mmWave) multiple-input multiple-output
(MIMO) network adopting the channel estimation algorithm proposed in [1] for
channel estimation. Due to the reuse of orthogonal pilot symbols among
different cells, the channel estimation is expected to be affected by pilot
contamination, which is considered as a fundamental performance bottleneck of
conventional multicell MU massive MIMO networks. To analyze the impact of pilot
contamination on the system performance, we derive the closed-form
approximation expression of the normalized mean squared error (MSE) of the
channel estimation performance. Our analytical and simulation results show that
the channel estimation error incurred by the impact of pilot contamination and
noise vanishes asymptotically with an increasing number of antennas equipped at
each radio frequency (RF) chain deployed at the desired BS. Thus, pilot
contamination is no longer the fundamental problem for multi-cell hybrid mmWave
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09343</identifier>
 <datestamp>2019-10-23</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09343</id><created>2018-01-26</created><updated>2019-10-21</updated><authors><author><keyname>Saragadam</keyname><forenames>Vishwanath</forenames></author><author><keyname>Sankaranarayanan</keyname><forenames>Aswin C.</forenames></author></authors><title>KRISM --- Krylov Subspace-based Optical Computing of Hyperspectral
  Images</title><categories>eess.IV cs.CV</categories><comments>14 pages of main paper and 15 pages of supplementary material</comments><journal-ref>Vishwanath Saragadam and Aswin C. Sankaranarayanan, &quot;KRISM ---
  Krylov Subspace-based Optical Computing of Hyperspectral Images&quot;, ACM Trans.
  Graphics 38, 5 (2019), 148:1-14</journal-ref><doi>10.1145/3345553</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an adaptive imaging technique that optically computes a low-rank
approximation of a scene's hyperspectral image, conceptualized as a matrix.
Central to the proposed technique is the optical implementation of two
measurement operators: a spectrally-coded imager and a spatially-coded
spectrometer. By iterating between the two operators, we show that the top
singular vectors and singular values of a hyperspectral image can be adaptively
and optically computed with only a few iterations. We present an optical design
that uses pupil plane coding for implementing the two operations and show
several compelling results using a lab prototype to demonstrate the
effectiveness of the proposed hyperspectral imager.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09350</identifier>
 <datestamp>2018-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09350</id><created>2018-01-28</created><authors><author><keyname>Miao</keyname><forenames>Qing</forenames></author><author><keyname>Huang</keyname><forenames>Baoqi</forenames></author><author><keyname>Jia</keyname><forenames>Bing</forenames></author></authors><title>Estimating Distances via Received Signal Strength and Connectivity in
  Wireless Sensor Networks</title><categories>eess.SP cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distance estimation is vital for localization and many other applications in
wireless sensor networks (WSNs). Particularly, it is desirable to implement
distance estimation as well as localization without using specific hardware in
low-cost WSNs. As such, both the received signal strength (RSS) based approach
and the connectivity based approach have gained much attention. The RSS based
approach is suitable for estimating short distances, whereas the connectivity
based approach obtains relatively good performance for estimating long
distances. Considering the complementary features of these two approaches, we
propose a fusion method based on the maximum-likelihood estimator (MLE) to
estimate the distance between any pair of neighboring nodes in a WSN through
efficiently fusing the information from the RSS and local connectivity.
Additionally, the method is reported under the practical log-normal shadowing
model, and the associated Cramer-Rao lower bound (CRLB) is also derived for
performance analysis. Both simulations and experiments based on practical
measurements are carried out, and demonstrate that the proposed method
outperforms any single approach and approaches to the CRLB as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09353</identifier>
 <datestamp>2018-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09353</id><created>2018-01-28</created><authors><author><keyname>Zhang</keyname><forenames>Yuanying</forenames></author><author><keyname>Wang</keyname><forenames>Jikang</forenames></author><author><keyname>Zhang</keyname><forenames>Wuhong</forenames></author><author><keyname>Chen</keyname><forenames>Shuting</forenames></author><author><keyname>Chen</keyname><forenames>Lixiang</forenames></author></authors><title>A model of orbital angular momentum Li-Fi</title><categories>physics.app-ph eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Twisted light has recently gained enormous interest in communication systems.
Thus far, twisted light has not yet been utilized for visible light
communication to transmit data. Here, by exploiting the color and orbital
angular momentum (OAM) degrees of freedom simultaneously, we construct a much
higher-dimensional space spanned by their hybrid mode basis, which further
increases the information capacity of twisted light. We build a new visible
light communication system using a white light emitting diode, with red, green
and blue (RGB) colors serving as independent channels and with OAM
superposition states encoding the information. We connect our conceptually new
RGB-OAM hybrid coding with the specially designed two-dimensional holographic
gratings based on theta-modulation. After indoor free-space transmission, we
decode the color information with an Xcube prism and subsequently decode the
OAM superposition states with a pattern recognition method based on supervised
machine learning. We succeed in demonstrating the transmission of color images
and a piece of audio with the fidelity over 96%. Our point-to-point scheme with
hybrid RGB-OAM encoding, not only increases significantly the information
capacity of twisted light, but also offers additional security that supplements
the traditional broadcasting visible light communications, e.g., Li-Fi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09520</identifier>
 <datestamp>2018-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09520</id><created>2018-01-26</created><authors><author><keyname>Montoya</keyname><forenames>Juan C.</forenames></author><author><keyname>Li</keyname><forenames>Yinsheng</forenames></author><author><keyname>Strother</keyname><forenames>Charles</forenames></author><author><keyname>Chen</keyname><forenames>Guang-Hong</forenames></author></authors><title>Deep Learning Angiography (DLA): Three-dimensional C-arm Cone Beam CT
  Angiography Using Deep Learning</title><categories>eess.IV cs.LG physics.med-ph</categories><comments>26 pages, 4 figures, 2 tables. Accepted for publication at Americal
  Journal of Neuroradiology (AJNR), 2018 (in press)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background and Purpose: Our purpose was to develop a deep learning
angiography (DLA) method to generate 3D cerebral angiograms from a single
contrast-enhanced acquisition.
  Material and Methods: Under an approved IRB protocol 105 3D-DSA exams were
randomly selected from an internal database. All were acquired using a clinical
system (Axiom Artis zee, Siemens Healthineers) in conjunction with a standard
injection protocol. More than 150 million labeled voxels from 35 subjects were
used for training. A deep convolutional neural network was trained to classify
each image voxel into three tissue types (vasculature, bone and soft tissue).
The trained DLA model was then applied for tissue classification in a
validation cohort of 8 subjects and a final testing cohort consisting of the
remaining 62 subjects. The final vasculature tissue class was used to generate
the 3D-DLA images. To quantify the generalization error of the trained model,
accuracy, sensitivity, precision and F1-scores were calculated for vasculature
classification in relevant anatomy. The 3D-DLA and clinical 3D-DSA images were
subject to a qualitative assessment for the presence of inter-sweep motion
artifacts.
  Results: Vasculature classification accuracy and 95% CI in the testing
dataset was 98.7% ([98.3, 99.1] %). No residual signal from osseous structures
was observed for all 3D-DLA testing cases except for small regions in the otic
capsule and nasal cavity compared to 37% (23/62) of the 3D-DSAs.
  Conclusion: DLA accurately recreated the vascular anatomy of the 3D-DSA
reconstructions without mask. DLA reduced mis-registration artifacts induced by
inter-sweep motion. DLA reduces radiation exposure required to obtain
clinically useful 3D-DSA
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09522</identifier>
 <datestamp>2018-01-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09522</id><created>2018-01-29</created><authors><author><keyname>Adavanne</keyname><forenames>Sharath</forenames></author><author><keyname>Politis</keyname><forenames>Archontis</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author></authors><title>Multichannel Sound Event Detection Using 3D Convolutional Neural
  Networks for Learning Inter-channel Features</title><categories>cs.SD cs.LG eess.AS</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we propose a stacked convolutional and recurrent neural
network (CRNN) with a 3D convolutional neural network (CNN) in the first layer
for the multichannel sound event detection (SED) task. The 3D CNN enables the
network to simultaneously learn the inter- and intra-channel features from the
input multichannel audio. In order to evaluate the proposed method,
multichannel audio datasets with different number of overlapping sound sources
are synthesized. Each of this dataset has a four-channel first-order Ambisonic,
binaural, and single-channel versions, on which the performance of SED using
the proposed method are compared to study the potential of SED using
multichannel audio. A similar study is also done with the binaural and
single-channel versions of the real-life recording TUT-SED 2017 development
dataset. The proposed method learns to recognize overlapping sound events from
multichannel features faster and performs better SED with a fewer number of
training epochs. The results show that on using multichannel Ambisonic audio in
place of single-channel audio we improve the overall F-score by 7.5%, overall
error rate by 10% and recognize 15.6% more sound events in time frames with
four overlapping sound sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09651</identifier>
 <datestamp>2018-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09651</id><created>2018-01-29</created><updated>2018-03-23</updated><authors><author><keyname>Escudero</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Poblete</keyname><forenames>Victor</forenames></author><author><keyname>Novoa</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Wuth</keyname><forenames>Jorge</forenames></author><author><keyname>Fredes</keyname><forenames>Josu&#xe9;</forenames></author><author><keyname>Mahu</keyname><forenames>Rodrigo</forenames></author><author><keyname>Stern</keyname><forenames>Richard</forenames></author><author><keyname>Yoma</keyname><forenames>N&#xe9;stor Becerra</forenames></author></authors><title>Highly-Reverberant Real Environment database: HRRE</title><categories>eess.AS cs.SD</categories><comments>five pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Speech recognition in highly-reverberant real environments remains a major
challenge. An evaluation dataset for this task is needed. This report describes
the generation of the Highly-Reverberant Real Environment database (HRRE). This
database contains 13.4 hours of data recorded in real reverberant environments
and consists of 20 different testing conditions which consider a wide range of
reverberation times and speaker-to-microphone distances. These evaluation sets
were generated by re-recording the clean test set of the Aurora-4 database
which corresponds to five loudspeaker-microphone distances in four reverberant
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09678</identifier>
 <datestamp>2018-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09678</id><created>2018-01-29</created><updated>2018-06-20</updated><authors><author><keyname>Rusu</keyname><forenames>Cristian</forenames></author><author><keyname>Gonzalez-Prelcic</keyname><forenames>Nuria</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Algorithms for the Construction of Incoherent Frames Under Various
  Design Constraints</title><categories>eess.SP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unit norm finite frames are generalizations of orthonormal bases with many
applications in signal processing. An important property of a frame is its
coherence, a measure of how close any two vectors of the frame are to each
other. Low coherence frames are useful in compressed sensing applications. When
used as measurement matrices, they successfully recover highly sparse solutions
to linear inverse problems. This paper describes algorithms for the design of
various low coherence frame types: real, complex, unital (constant magnitude)
complex, sparse real and complex, nonnegative real and complex, and harmonic
(selection of rows from Fourier matrices). The proposed methods are based on
solving a sequence of convex optimization problems that update each vector of
the frame. This update reduces the coherence with the other frame vectors,
while other constraints on its entries are also imposed. Numerical experiments
show the effectiveness of the methods compared to the Welch bound, as well as
other competing algorithms, in compressed sensing applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09724</identifier>
 <datestamp>2018-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09724</id><created>2018-01-29</created><authors><author><keyname>Quadri</keyname><forenames>Adnan</forenames></author><author><keyname>Manesh</keyname><forenames>Mohsen Riahi</forenames></author><author><keyname>Kaabouch</keyname><forenames>Naima</forenames></author></authors><title>Denoising Signals in Cognitive Radio Systems Using An Evolutionary
  Algorithm Based Adaptive Filter</title><categories>eess.SP</categories><doi>10.1109/UEMCON.2016.7777854</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noise originating from several sources in a RF environment degrades the
performance of communication systems. In wideband systems, such as cognitive
radios, noise at the receiver can originate from non-linearity present in the
RF front end, time-varying thermal noise within the receiver radio system, and
noise from adjacent network nodes. Several denoising techniques have been
proposed for cognitive radios, some of which are applied during spectrum
sensing and others to received noisy signal during communication. Examples of
some of these techniques used for noise cancellation in received signals are
least mean square (LMS) and its variants. However, these algorithms have low
performance with non-linear signals and cannot locate a global optimum solution
for noise cancellation. Therefore, application of global search optimization
techniques, such as evolutionary algorithms, is considered for noise
cancellation. In this paper, particle swarm optimization (PSO) and LMS
algorithms are implemented and their performances are evaluated. Extensive
simulations were performed where Gaussian and non-linear random noise were
added to the transmitted signal. The performance comparison was done using two
metrics: bit error rate and mean square error. The results show that PSO
outperforms LMS under both Gaussian and nonlinear random noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09725</identifier>
 <datestamp>2018-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09725</id><created>2018-01-29</created><authors><author><keyname>Quadri</keyname><forenames>Adnan</forenames></author><author><keyname>Manesh</keyname><forenames>Mohsen Riahi</forenames></author><author><keyname>Kaabouch</keyname><forenames>Naima</forenames></author></authors><title>Noise Cancellation in Cognitive Radio Systems: A Performance Comparison
  of Evolutionary Algorithms</title><categories>eess.SP</categories><doi>10.1109/CCWC.2017.7868388</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noise cancellation is one of the important signal processing functions of any
communication system, as noise affects data integrity. In existing systems,
traditional filters are used to cancel the noise from the received signals.
These filters use fixed hardware which is capable of filtering specific
frequency or a range of frequencies. However, next generation communication
technologies, such as cognitive radio, will require the use of adaptive filters
that can dynamically reconfigure their filtering parameters for any frequency.
To this end, a few noise cancellation techniques have been proposed, including
least mean squares (LMS) and its variants. However, these algorithms are
susceptible to non-linear noise and fail to locate the global optimum solution
for de-noising. In this paper, we investigate the efficiency of two global
search optimization based algorithms, genetic algorithm and particle swarm
optimization in performing noise cancellation in cognitive radio systems. These
algorithms are implemented and their performances are compared to that of LMS
using bit error rate and mean square error as performance evaluation metrics.
Simulations are performed with additive white Gaussian noise and random
nonlinear noise. Results indicate that GA and PSO perform better than LMS for
the case of AWGN corrupted signal but for non-linear random noise PSO
outperforms the other two algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09744</identifier>
 <datestamp>2018-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09744</id><created>2018-01-29</created><authors><author><keyname>Arjoune</keyname><forenames>Youness</forenames></author><author><keyname>Kaabouch</keyname><forenames>Naima</forenames></author><author><keyname>Ghazi</keyname><forenames>Hassan El</forenames></author><author><keyname>Tamtaoui</keyname><forenames>Ahmed</forenames></author></authors><title>Compressive Sensing: Performance Comparison Of Sparse Recovery
  Algorithms</title><categories>eess.SP</categories><comments>CCWC 2017 Las Vegas, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing is an important process in cognitive radio. A number of
sensing techniques that have been proposed suffer from high processing time,
hardware cost and computational complexity. To address these problems,
compressive sensing has been proposed to decrease the processing time and
expedite the scanning process of the radio spectrum. Selection of a suitable
sparse recovery algorithm is necessary to achieve this goal. A number of sparse
recovery algorithms have been proposed. This paper surveys the sparse recovery
algorithms, classify them into categories, and compares their performances. For
the comparison, we used several metrics such as recovery error, recovery time,
covariance, and phase transition diagram. The results show that techniques
under Greedy category are faster, techniques of Convex and Relaxation category
perform better in term of recovery error, and Bayesian based techniques are
observed to have an advantageous balance of small recovery error and a short
recovery time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09773</identifier>
 <datestamp>2018-06-26</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09773</id><created>2018-01-29</created><updated>2018-04-08</updated><authors><author><keyname>Ling</keyname><forenames>Ruilong</forenames></author><author><keyname>Tahir</keyname><forenames>Waleed</forenames></author><author><keyname>Lin</keyname><forenames>Hsing-Ying</forenames></author><author><keyname>Lee</keyname><forenames>Hakho</forenames></author><author><keyname>Tian</keyname><forenames>Lei</forenames></author></authors><title>High-throughput intensity diffraction tomography with a computational
  microscope</title><categories>eess.IV physics.bio-ph physics.optics</categories><doi>10.1364/BOE.9.002130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate a motion-free intensity diffraction tomography technique that
enables direct inversion of 3D phase and absorption from intensity-only
measurements for weakly scattering samples. We derive a novel linear forward
model, featuring slice-wise phase and absorption transfer functions using
angled illumination. This new framework facilitates flexible and efficient data
acquisition, enabling arbitrary sampling of the illumination angles. The
reconstruction algorithm performs 3D synthetic aperture using a robust,
computation and memory efficient slice-wise deconvolution to achieve resolution
up to the incoherent limit. We demonstrate our technique with thick biological
samples having both sparse 3D structures and dense cell clusters. We further
investigate the limitation of our technique when imaging strongly scattering
samples. Imaging performance and the influence of multiple scattering is
evaluated using a 3D sample consisting of stacked phase and absorption
resolution targets. This computational microscopy system is directly built on a
standard commercial microscope with a simple LED array source add-on, and
promises broad applications by leveraging the ubiquitous microscopy platforms
with minimal hardware modifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09774</identifier>
 <datestamp>2018-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09774</id><created>2018-01-29</created><authors><author><keyname>Zhen</keyname><forenames>Kai</forenames></author><author><keyname>Sivaraman</keyname><forenames>Aswin</forenames></author><author><keyname>Sung</keyname><forenames>Jongmo</forenames></author><author><keyname>Kim</keyname><forenames>Minje</forenames></author></authors><title>On Psychoacoustically Weighted Cost Functions Towards Resource-Efficient
  Deep Neural Networks for Speech Denoising</title><categories>cs.SD eess.AS</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a psychoacoustically enhanced cost function to balance network
complexity and perceptual performance of deep neural networks for speech
denoising. While training the network, we utilize perceptual weights added to
the ordinary mean-squared error to emphasize contribution from frequency bins
which are most audible while ignoring error from inaudible bins. To generate
the weights, we employ psychoacoustic models to compute the global masking
threshold from the clean speech spectra. We then evaluate the speech denoising
performance of our perceptually guided neural network by using both objective
and perceptual sound quality metrics, testing on various network structures
ranging from shallow and narrow ones to deep and wide ones. The experimental
results showcase our method as a valid approach for infusing perceptual
significance to deep neural network operations. In particular, the more
perceptually sensible enhancement in performance seen by simple neural network
topologies proves that the proposed method can lead to resource-efficient
speech denoising implementations in small devices without degrading the
perceived signal fidelity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09775</identifier>
 <datestamp>2018-05-15</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09775</id><created>2017-12-07</created><authors><author><keyname>Hughes</keyname><forenames>R. R.</forenames></author><author><keyname>Drinkwater</keyname><forenames>B. W.</forenames></author><author><keyname>Smith</keyname><forenames>R. A.</forenames></author></authors><title>Characterisation of carbon fibre-reinforced polymer composites through
  complex Radon-transform analysis of eddy-current data</title><categories>physics.app-ph eess.SP physics.data-an</categories><doi>10.1016/j.compositesb.2018.05.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maintaining the correct fibre orientations and stacking sequence in
carbon-fibre reinforced polymers (CFRP) during manufacture is essential for
achieving the required mechanical properties of a component. This paper
presents and evaluates a method for the rapid characterisation of the fibre
orientations present in CFRP structures, and the differentiation of different
stacking sequences, through the Radon-transform analysis of complex-valued
eddy-current testing (ECT) inspection data. A high-frequency (20 MHz)
eddy-current inspection system was used to obtain 2D scans of a range of CFRP
samples of differing ply stacking sequences. The complex electrical impedance
scan data was analysed using Radon-transform techniques to quickly and simply
determine the dominant fibre orientations present in the structure. This method
is compared to 2D-fast Fourier transform (2D-FFT) analysis of the same data and
shown to give superior quantitative results with comparatively fewer
computational steps and corrections. Further analysis is presented
demonstrating and examining a method for preserving the complex information
inherent within the eddy-current scan data during Radon-transform analysis.
This investigation shows that the real and imaginary components of the ECT data
encode information about the sacking sequence allowing the distinction between
composites with different stacking structures. This new analysis technique
could be used for in-process analysis of CFRP structures as a more accurate
characterisation method, reducing the chance of costly manufacturing errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09923</identifier>
 <datestamp>2018-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09923</id><created>2018-01-30</created><authors><author><keyname>Moltchanov</keyname><forenames>Dmitri</forenames></author><author><keyname>Kustarev</keyname><forenames>Pavel</forenames></author><author><keyname>Kucharyavy</keyname><forenames>Yevgeni</forenames></author></authors><title>Analytical modeling and analysis of interleaving on correlated wireless
  channels</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>Accepted to Elsevier Computer Communications in 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interleaving is a mechanism universally used in wireless access technologies
to alleviate the effect of channel correlation. In spite of its wide adoption,
to the best of our knowledge, there are no analytical models proposed so far.
In this paper we fill this void proposing three different models of
interleaving. Two of these models are based on numerical algorithms while one
of them allows for closed-form expression for packet error probability.
Although we use block codes with hard decoding to specify the models our
modeling principles are applicable to all forward error correction codes as
long as there exists a functional relationship (possibly, probabilistic)
between the number of incorrectly received bits in a codeword and the codeword
error probability. We evaluate accuracy of our models showing that the worst
case prediction is limited by 50\% across a wide range of input parameters.
Finally, we study the effect of interleaving in detail demonstrating how it
varies with channel correlation, bit error rate and error correction
capability. Numerical results reported in this paper allows to identify the
optimal value of the interleaving depth that need to be used for a channel with
a given degree of correlation. The reference implementations of the models are
available [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09937</identifier>
 <datestamp>2018-07-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09937</id><created>2018-01-30</created><updated>2018-07-28</updated><authors><author><keyname>Liu</keyname><forenames>Tianlin</forenames></author><author><keyname>Lee</keyname><forenames>Dae Gwan</forenames></author></authors><title>Binary Compressive Sensing via Smoothed $\ell_0$ Gradient Descent</title><categories>eess.SP cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Compressive Sensing algorithm for reconstructing binary signals
from its linear measurements. The proposed algorithm minimizes a non-convex
cost function expressed as a weighted sum of smoothed $\ell_0$ norms which
takes into account the binariness of signals. We show that for binary signals
the proposed algorithm outperforms other existing algorithms in recovery rate
while requiring a short run time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.09986</identifier>
 <datestamp>2019-12-03</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.09986</id><created>2018-01-26</created><authors><author><keyname>Farooq</keyname><forenames>Muhammad Junaid</forenames></author><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author></authors><title>On the Secure and Reconfigurable Multi-Layer Network Design for Critical
  Information Dissemination in the Internet of Battlefield Things (IoBT)</title><categories>eess.SP cs.SY</categories><comments>to appear in IEEE Transactions on Wireless Communications. arXiv
  admin note: substantial text overlap with arXiv:1703.01224</comments><journal-ref>IEEE Transactions on Wireless Communications 2018</journal-ref><doi>10.1109/TWC.2018.2799860</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet of things (IoT) is revolutionizing the management and control of
automated systems leading to a paradigm shift in areas such as smart homes,
smart cities, health care, transportation, etc. The IoT technology is also
envisioned to play an important role in improving the effectiveness of military
operations in battlefields. The interconnection of combat equipment and other
battlefield resources for coordinated automated decisions is referred to as the
Internet of battlefield things (IoBT). IoBT networks are significantly
different from traditional IoT networks due to battlefield specific challenges
such as the absence of communication infrastructure, heterogeneity of devices,
and susceptibility to cyber-physical attacks. The combat efficiency and
coordinated decision-making in war scenarios depends highly on real-time data
collection, which in turn relies on the connectivity of the network and
information dissemination in the presence of adversaries. This work aims to
build the theoretical foundations of designing secure and reconfigurable IoBT
networks. Leveraging the theories of stochastic geometry and mathematical
epidemiology, we develop an integrated framework to quantify the information
dissemination among heterogeneous network devices. Consequently, a tractable
optimization problem is formulated that can assist commanders in cost
effectively planning the network and reconfiguring it according to the changing
mission requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.10031</identifier>
 <datestamp>2018-03-30</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.10031</id><created>2018-01-28</created><updated>2018-03-29</updated><authors><author><keyname>Kunwar</keyname><forenames>Suman</forenames></author></authors><title>Malaria Detection Using Image Processing and Machine Learning</title><categories>eess.IV cs.CV</categories><comments>This paper has been withdrawn by arXiv. arXiv admin note: author list
  truncated due to disputed authorship and content</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Malaria is mosquito-borne blood disease caused by parasites of the genus
Plasmodium. Conventional diagnostic tool for malaria is the examination of
stained blood cell of patient in microscope. The blood to be tested is placed
in a slide and is observed under a microscope to count the number of infected
RBC. An expert technician is involved in the examination of the slide with
intense visual and mental concentration. This is tiresome and time consuming
process.
  In this paper, we construct a new mage processing system for detection and
quantification of plasmodium parasites in blood smear slide, later we develop
Machine Learning algorithm to learn, detect and determine the types of infected
cells according to its features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.10033</identifier>
 <datestamp>2018-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.10033</id><created>2018-01-30</created><authors><author><keyname>Warrick</keyname><forenames>Philip</forenames><affiliation>PeriGen. Inc., Montreal, Canada</affiliation></author><author><keyname>Homsi</keyname><forenames>Masun Nabhan</forenames><affiliation>Simon Bolivar University, Caracas, Venezuela</affiliation></author></authors><title>Cardiac Arrhythmia Detection from ECG Combining Convolutional and Long
  Short-Term Memory Networks</title><categories>eess.SP cs.LG stat.ML</categories><comments>Computing in Cardiology 2017, 4 pages and 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objectives: Atrial fibrillation (AF) is a common heart rhythm disorder
associated with deadly and debilitating consequences including heart failure,
stroke, poor mental health, reduced quality of life and death. Having an
automatic system that diagnoses various types of cardiac arrhythmias would
assist cardiologists to initiate appropriate preventive measures and to improve
the analysis of cardiac disease. To this end, this paper introduces a new
approach to detect and classify automatically cardiac arrhythmias in
electrocardiograms (ECG) recordings.
  Methods: The proposed approach used a combination of Convolution Neural
Networks (CNNs) and a sequence of Long Short-Term Memory (LSTM) units, with
pooling, dropout and normalization techniques to improve their accuracy. The
network predicted a classification at every 18th input sample and we selected
the final prediction for classification. Results were cross-validated on the
Physionet Challenge 2017 training dataset, which contains 8,528 single lead ECG
recordings lasting from 9s to just over 60s.
  Results: Using the proposed structure and no explicit feature selection,
10-fold stratified cross-validation gave an overall F-measure of 0.83.10-0.015
on the held-out test data (mean-standard deviation over all folds) and 0.80 on
the hidden dataset of the Challenge entry server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.10128</identifier>
 <datestamp>2018-01-31</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.10128</id><created>2018-01-30</created><authors><author><keyname>Mansour</keyname><forenames>Mohamed F.</forenames></author></authors><title>Information Measures for Microphone Arrays</title><categories>cs.IT eess.AS math.IT</categories><comments>5 pages conference-style paper</comments><msc-class>62B10, 94A12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel information-theoretic approach for evaluating microphone
arrays that relies on the array physics and geometry rather than the underlying
beamforming algorithm. The analogy between Multiple-Input-Multiple-Output
(MIMO) wireless communication channel and the acoustic channel of microphone
arrays is exploited to define information measures of microphone arrays, which
provide upper bounds of the information rate of the microphone array system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.10240</identifier>
 <datestamp>2018-07-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.10240</id><created>2018-01-30</created><authors><author><keyname>Ji</keyname><forenames>Teng-Yu</forenames></author><author><keyname>Yokoya</keyname><forenames>Naoto</forenames></author><author><keyname>Zhu</keyname><forenames>Xiao Xiang</forenames></author><author><keyname>Huang</keyname><forenames>Ting-Zhu</forenames></author></authors><title>Non-local tensor completion for multitemporal remotely sensed images
  inpainting</title><categories>eess.SP eess.IV</categories><doi>10.1109/TGRS.2018.2790262</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Remotely sensed images may contain some missing areas because of poor weather
conditions and sensor failure. Information of those areas may play an important
role in the interpretation of multitemporal remotely sensed data. The paper
aims at reconstructing the missing information by a non-local low-rank tensor
completion method (NL-LRTC). First, nonlocal correlations in the spatial domain
are taken into account by searching and grouping similar image patches in a
large search window. Then low-rankness of the identified 4-order tensor groups
is promoted to consider their correlations in spatial, spectral, and temporal
domains, while reconstructing the underlying patterns. Experimental results on
simulated and real data demonstrate that the proposed method is effective both
qualitatively and quantitatively. In addition, the proposed method is
computationally efficient compared to other patch based methods such as the
recent proposed PM-MTGSR method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.10264</identifier>
 <datestamp>2018-06-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.10264</id><created>2018-01-30</created><updated>2018-06-19</updated><authors><author><keyname>Durgin</keyname><forenames>Natalie</forenames></author><author><keyname>Grotheer</keyname><forenames>Rachel</forenames></author><author><keyname>Huang</keyname><forenames>Chenxi</forenames></author><author><keyname>Li</keyname><forenames>Shuang</forenames></author><author><keyname>Ma</keyname><forenames>Anna</forenames></author><author><keyname>Needell</keyname><forenames>Deanna</forenames></author><author><keyname>Qin</keyname><forenames>Jing</forenames></author></authors><title>Compressed Anomaly Detection with Multiple Mixed Observations</title><categories>cs.IT cs.DS eess.SP math.IT math.NA math.OC</categories><comments>27 pages, 9 figures. Incorporates reviewer feedback, additional
  experiments, and additional figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a collection of independent random variables that are identically
distributed, except for a small subset which follows a different, anomalous
distribution. We study the problem of detecting which random variables in the
collection are governed by the anomalous distribution. Recent work proposes to
solve this problem by conducting hypothesis tests based on mixed observations
(e.g. linear combinations) of the random variables. Recognizing the connection
between taking mixed observations and compressed sensing, we view the problem
as recovering the &quot;support&quot; (index set) of the anomalous random variables from
multiple measurement vectors (MMVs). Many algorithms have been developed for
recovering jointly sparse signals and their support from MMVs. We establish the
theoretical and empirical effectiveness of these algorithms at detecting
anomalies. We also extend the LASSO algorithm to an MMV version for our
purpose. Further, we perform experiments on synthetic data, consisting of
samples from the random variables, to explore the trade-off between the number
of mixed observations per sample and the number of samples required to detect
anomalies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.10492</identifier>
 <datestamp>2018-12-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.10492</id><created>2018-01-31</created><updated>2018-12-19</updated><authors><author><keyname>Martin</keyname><forenames>Charles P.</forenames></author><author><keyname>Ellefsen</keyname><forenames>Kai Olav</forenames></author><author><keyname>Torresen</keyname><forenames>Jim</forenames></author></authors><title>Deep Predictive Models in Interactive Music</title><categories>cs.SD cs.AI cs.HC cs.NE eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Musical performance requires prediction to operate instruments, to perform in
groups and to improvise. In this paper, we investigate how a number of digital
musical instruments (DMIs), including two of our own, have applied predictive
machine learning models that assist users by predicting unknown states of
musical processes. We characterise these predictions as focussed within a
musical instrument, at the level of individual performers, and between members
of an ensemble. These models can connect to existing frameworks for DMI design
and have parallels in the cognitive predictions of human musicians.
  We discuss how recent advances in deep learning highlight the role of
prediction in DMIs, by allowing data-driven predictive models with a long
memory of past states. The systems we review are used to motivate musical
use-cases where prediction is a necessary component, and to highlight a number
of challenges for DMI designers seeking to apply deep predictive models in
interactive music systems of the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.10574</identifier>
 <datestamp>2018-02-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1801.10574</id><created>2018-01-31</created><authors><author><keyname>Eiselt</keyname><forenames>Nicklas</forenames></author><author><keyname>Muench</keyname><forenames>Daniel</forenames></author><author><keyname>Dochhan</keyname><forenames>Annika</forenames></author><author><keyname>Griesser</keyname><forenames>Helmut</forenames></author><author><keyname>Eiselt</keyname><forenames>Michael</forenames></author><author><keyname>Olmos</keyname><forenames>Juan Jose Vegas</forenames></author><author><keyname>Monroy</keyname><forenames>Idelfonso Tafur</forenames></author><author><keyname>Elbers</keyname><forenames>Joerg-Peter</forenames></author></authors><title>Performance Comparison of 112 Gb/s DMT, Nyquist PAM4 and
  Partial-Response PAM4 for Future 5G Ethernet-based Fronthaul Architecture</title><categories>eess.SP cs.NI</categories><comments>The work leading to these results has received funding from the
  European Union's Seventh Framework Programme under Grant Agreement No. 644526
  (ABACUS), the European Union's Horizon 2020 Research and Innovation Programme
  under Grant Agreement No. 644526 (iCIRRUS), and the German Ministry of
  Education and Research (BMBF) under contract numbers 16KIS0477K (SENDATE
  Secure-DCI) and 13N13744 (SPeeD)</comments><doi>10.1109/JLT.2018.2790579</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a future 5G Ethernet-based fronthaul architecture, 100G trunk lines of a
transmission distance up to 10 km standard single mode fiber (SSMF) in
combination with cheap grey optics to daisy chain cell site network interfaces
are a promising cost- and power-efficient solution. For such a scenario,
different intensity modulation and direct detect (IMDD) Formats at a data rate
of 112 Gb/s, namely Nyquist four-level pulse amplitude modulation (PAM4),
discrete multi-tone Transmission (DMT) and partial-response (PR) PAM4 are
experimentally investigated, using a low-cost electro-absorption modulated
laser (EML), a 25G driver and current state-of-the-art high Speed 84 GS/s CMOS
digital-to-analog converter (DAC) and analog-to-digital converter (ADC) test
chips. Each modulation Format is optimized independently for the desired
scenario and their digital signal processing (DSP) requirements are
investigated. The performance of Nyquist PAM4 and PR PAM4 depend very much on
the efficiency of pre- and post-equalization. We show the necessity for at
least 11 FFE-taps for pre-emphasis and up to 41 FFE coefficients at the
receiver side. In addition, PR PAM4 requires an MLSE with four states to decode
the signal back to a PAM4 signal. On the contrary, bit- and power-loading (BL,
PL) is crucial for DMT and an FFT length of at least 512 is necessary. With
optimized parameters, all Modulation formats result in a very similar
performances, demonstrating a transmission distance of up to 10 km over SSMF
with bit error rates (BERs) below a FEC threshold of 4.4E-3, allowing error
free transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00107</identifier>
 <datestamp>2018-02-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00107</id><created>2018-01-31</created><authors><author><keyname>Navabi</keyname><forenames>Shiva</forenames></author><author><keyname>Wang</keyname><forenames>Chenwei</forenames></author><author><keyname>Bursalioglu</keyname><forenames>Ozgun Y.</forenames></author><author><keyname>Papadopoulos</keyname><forenames>Haralabos</forenames></author></authors><title>Predicting Wireless Channel Features using Neural Networks</title><categories>eess.SP cs.IT math.IT</categories><comments>6 pages, 6 figures, to appear in 2018 IEEE International Conference
  on Communications (ICC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the viability of using machine-learning techniques for
estimating user-channel features at a large-array base station (BS). In the
scenario we consider, user-pilot broadcasts are observed and processed by the
BS to extract angle-of-arrival (AoA) specific information about
propagation-channel features, such as received signal strength and relative
path delay. The problem of interest involves using this information to predict
the angle-of-departure (AoD) of the dominant propagation paths in the user
channels, i.e., channel features not directly observable at the BS. To
accomplish this task, the data collected in the same propagation environment
are used to train neural networks. Our studies rely on ray-tracing channel data
that have been calibrated against measurements from Shinjuku Square, a famous
hotspot in Tokyo, Japan. We demonstrate that the observed features at the BS
side are correlated with the angular features at the user side. We train neural
networks that exploit different combinations of measured features at the BS to
infer the unknown parameters at the users. The evaluation based on standard
statistical performance metrics suggests that such data-driven methods have the
potential to predict unobserved channel features from observed ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00114</identifier>
 <datestamp>2018-02-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00114</id><created>2018-01-31</created><authors><author><keyname>Karami</keyname><forenames>Ebrahim</forenames></author><author><keyname>Juntti</keyname><forenames>Markku</forenames></author></authors><title>Low Complexity Time Domain Semi-Blind MIMO-OFDM Channel Estimation Using
  Adaptive Bussgang Algorithm</title><categories>eess.SP</categories><comments>6 pages, 9 figures, WPMC2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a low complexity time domain semi-blind algorithm is proposed
to estimate and track the time varying MIMO OFDM channels. First, the proposed
least mean squares (LMS) based algorithm is developed for the training mode and
then is extended for the blind mode of the operation by combining with the
decision direction (DD) or adaptive Bussgang algorithm (ABA) techniques. In the
blind mode, because of decision errors, a smaller step size is considered for
the LMS algorithm and the channel estimation is run a few times to improve its
precision. In each round of the estimation in the blind mode, the step size is
decreased to form some kind of annealing. Both DD LMS and ABA LMS techniques
are simulated and compared to the full training case and MSE of channel
estimation error is considered as comparison criterion. It is shown for 2x4 DD
LMS and for 4x4 ABA LMS algorithms present near full training case estimation
error. Of course in some scenarios the former proposed technique performs
better and in other scenarios the latter is better and therefore combine of it
can be very interesting in all channel conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00254</identifier>
 <datestamp>2018-02-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00254</id><created>2018-02-01</created><authors><author><keyname>Wang</keyname><forenames>Yu</forenames></author><author><keyname>Chen</keyname><forenames>Xie</forenames></author><author><keyname>Gales</keyname><forenames>Mark</forenames></author><author><keyname>Ragni</keyname><forenames>Anton</forenames></author><author><keyname>Wong</keyname><forenames>Jeremy</forenames></author></authors><title>Phonetic and Graphemic Systems for Multi-Genre Broadcast Transcription</title><categories>cs.SD cs.CL eess.AS</categories><comments>5 pages, 6 tables, to appear in 2018 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP 2018)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art English automatic speech recognition systems typically use
phonetic rather than graphemic lexicons. Graphemic systems are known to perform
less well for English as the mapping from the written form to the spoken form
is complicated. However, in recent years the representational power of
deep-learning based acoustic models has improved, raising interest in graphemic
acoustic models for English, due to the simplicity of generating the lexicon.
In this paper, phonetic and graphemic models are compared for an English
Multi-Genre Broadcast transcription task. A range of acoustic models based on
lattice-free MMI training are constructed using phonetic and graphemic
lexicons. For this task, it is found that having a long-span temporal history
reduces the difference in performance between the two forms of models. In
addition, system combination is examined, using parameter smoothing and
hypothesis combination. As the combination approaches become more complicated
the difference between the phonetic and graphemic systems further decreases.
Finally, for all configurations examined the combination of phonetic and
graphemic systems yields consistent gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00300</identifier>
 <datestamp>2018-02-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00300</id><created>2018-02-01</created><authors><author><keyname>Drossos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Mimilakis</keyname><forenames>Stylianos Ioannis</forenames></author><author><keyname>Serdyuk</keyname><forenames>Dmitriy</forenames></author><author><keyname>Schuller</keyname><forenames>Gerald</forenames></author><author><keyname>Virtanen</keyname><forenames>Tuomas</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>MaD TwinNet: Masker-Denoiser Architecture with Twin Networks for
  Monaural Sound Source Separation</title><categories>cs.SD eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monaural singing voice separation task focuses on the prediction of the
singing voice from a single channel music mixture signal. Current state of the
art (SOTA) results in monaural singing voice separation are obtained with deep
learning based methods. In this work we present a novel deep learning based
method that learns long-term temporal patterns and structures of a musical
piece. We build upon the recently proposed Masker-Denoiser (MaD) architecture
and we enhance it with the Twin Networks, a technique to regularize a recurrent
generative network using a backward running copy of the network. We evaluate
our method using the Demixing Secret Dataset and we obtain an increment to
signal-to-distortion ratio (SDR) of 0.37 dB and to signal-to-interference ratio
(SIR) of 0.23 dB, compared to previous SOTA results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00308</identifier>
 <datestamp>2018-05-21</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00308</id><created>2018-01-30</created><updated>2018-05-17</updated><authors><author><keyname>Roy</keyname><forenames>Subhrajit</forenames></author><author><keyname>Kiral-Kornek</keyname><forenames>Isabell</forenames></author><author><keyname>Harrer</keyname><forenames>Stefan</forenames></author></authors><title>ChronoNet: A Deep Recurrent Neural Network for Abnormal EEG
  Identification</title><categories>eess.SP cs.LG</categories><comments>8 pages, 2 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brain-related disorders such as epilepsy can be diagnosed by analyzing
electroencephalograms (EEG). However, manual analysis of EEG data requires
highly trained clinicians, and is a procedure that is known to have relatively
low inter-rater agreement (IRA). Moreover, the volume of the data and the rate
at which new data becomes available make manual interpretation a
time-consuming, resource-hungry, and expensive process. In contrast, automated
analysis of EEG data offers the potential to improve the quality of patient
care by shortening the time to diagnosis and reducing manual error. In this
paper, we focus on one of the first steps in interpreting an EEG session -
identifying whether the brain activity is abnormal or normal. To solve this
task, we propose a novel recurrent neural network (RNN) architecture termed
ChronoNet which is inspired by recent developments from the field of image
classification and designed to work efficiently with EEG data. ChronoNet is
formed by stacking multiple 1D convolution layers followed by deep gated
recurrent unit (GRU) layers where each 1D convolution layer uses multiple
filters of exponentially varying lengths and the stacked GRU layers are densely
connected in a feed-forward manner. We used the recently released TUH Abnormal
EEG Corpus dataset for evaluating the performance of ChronoNet. Unlike previous
studies using this dataset, ChronoNet directly takes time-series EEG as input
and learns meaningful representations of brain activity patterns. ChronoNet
outperforms the previously reported best results by 7.79% thereby setting a new
benchmark for this dataset. Furthermore, we demonstrate the domain-independent
nature of ChronoNet by successfully applying it to classify speech commands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00337</identifier>
 <datestamp>2018-02-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00337</id><created>2018-01-31</created><authors><author><keyname>Martinovic</keyname><forenames>Ivan</forenames></author><author><keyname>Mandic</keyname><forenames>Vesna</forenames></author></authors><title>Biomedical Signals Reconstruction Under the Compressive Sensing Approach</title><categories>eess.SP cs.MM</categories><comments>paper submitted to the 7th Mediterranean Conference on Embedded
  Computing - MECO'2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper analyses the possibility to recover different biomedical signals if
limited number of samples is available. Having in mind that monitoring of
health condition is done by measuring and observing key parameters such as
heart activity through electrocardiogram or anatomy and body processes through
magnetic resonance imaging, it is important to keep the quality of the
reconstructed signal as better as possible. To recover the signal from limited
set of available coefficients, the Compressive Sensing approach and
optimization algorithms are used. The theory is verified by the experimental
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00368</identifier>
 <datestamp>2018-02-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00368</id><created>2018-02-01</created><authors><author><keyname>Akbari</keyname><forenames>Mojtaba</forenames></author><author><keyname>Mohrekesh</keyname><forenames>Majid</forenames></author><author><keyname>Nasr-Esfahani</keyname><forenames>Ebrahim</forenames></author><author><keyname>Soroushmehr</keyname><forenames>S. M. Reza</forenames></author><author><keyname>Karimi</keyname><forenames>Nader</forenames></author><author><keyname>Samavi</keyname><forenames>Shadrokh</forenames></author><author><keyname>Najarian</keyname><forenames>Kayvan</forenames></author></authors><title>Polyp Segmentation in Colonoscopy Images Using Fully Convolutional
  Network</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colorectal cancer is a one of the highest causes of cancer-related death,
especially in men. Polyps are one of the main causes of colorectal cancer and
early diagnosis of polyps by colonoscopy could result in successful treatment.
Diagnosis of polyps in colonoscopy videos is a challenging task due to
variations in the size and shape of polyps. In this paper we proposed a polyp
segmentation method based on convolutional neural network. Performance of the
method is enhanced by two strategies. First, we perform a novel image patch
selection method in the training phase of the network. Second, in the test
phase, we perform an effective post processing on the probability map that is
produced by the network. Evaluation of the proposed method using the
CVC-ColonDB database shows that our proposed method achieves more accurate
results in comparison with previous colonoscopy video-segmentation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00380</identifier>
 <datestamp>2018-02-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00380</id><created>2018-02-01</created><authors><author><keyname>Iqbal</keyname><forenames>Turab</forenames></author><author><keyname>Wang</keyname><forenames>Wenwu</forenames></author></authors><title>Approximate Message Passing for Underdetermined Audio Source Separation</title><categories>cs.SD eess.AS</categories><comments>Paper accepted for 3rd International Conference on Intelligent Signal
  Processing (ISP 2017)</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Approximate message passing (AMP) algorithms have shown great promise in
sparse signal reconstruction due to their low computational requirements and
fast convergence to an exact solution. Moreover, they provide a probabilistic
framework that is often more intuitive than alternatives such as convex
optimisation. In this paper, AMP is used for audio source separation from
underdetermined instantaneous mixtures. In the time-frequency domain, it is
typical to assume a priori that the sources are sparse, so we solve the
corresponding sparse linear inverse problem using AMP. We present a block-based
approach that uses AMP to process multiple time-frequency points
simultaneously. Two algorithms known as AMP and vector AMP (VAMP) are evaluated
in particular. Results show that they are promising in terms of artefact
suppression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00390</identifier>
 <datestamp>2018-02-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00390</id><created>2018-02-01</created><authors><author><keyname>Bazrafkan</keyname><forenames>Shabab</forenames></author><author><keyname>Javidnia</keyname><forenames>Hossein</forenames></author><author><keyname>Corcoran</keyname><forenames>Peter</forenames></author></authors><title>Face Synthesis with Landmark Points from Generative Adversarial Networks
  and Inverse Latent Space Mapping</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Facial landmarks refer to the localization of fundamental facial points on
face images. There have been a tremendous amount of attempts to detect these
points from facial images however, there has never been an attempt to
synthesize a random face and generate its corresponding facial landmarks. This
paper presents a framework for augmenting a dataset in a latent Z-space and
applied to the regression problem of generating a corresponding set of
landmarks from a 2D facial dataset. The BEGAN framework has been used to train
a face generator from CelebA database. The inverse of the generator is
implemented using an Adam optimizer to generate the latent vector corresponding
to each facial image, and a lightweight deep neural network is trained to map
latent Z-space vectors to the landmark space. Initial results are promising and
provide a generic methodology to augment annotated image datasets with
additional intermediate samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00431</identifier>
 <datestamp>2018-02-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00431</id><created>2018-02-01</created><authors><author><keyname>Baknina</keyname><forenames>Abdulrahman</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Coded Status Updates in an Energy Harvesting Erasure Channel</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>To appear in CISS 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an energy harvesting transmitter sending status updates to a
receiver over an erasure channel, where each status update is of length $k$
symbols. The energy arrivals and the channel erasures are independent and
identically distributed (i.i.d.) and Bernoulli distributed in each slot. In
order to combat the effects of the erasures in the channel and the uncertainty
in the energy arrivals, we use channel coding to encode the status update
symbols. We consider two types of channel coding: maximum distance separable
(MDS) codes and rateless erasure codes. For each of these models, we study two
achievable schemes: best-effort and save-and-transmit. In the best-effort
scheme, the transmitter starts transmission right away, and sends a symbol if
it has energy. In the save-and-transmit scheme, the transmitter remains silent
in the beginning in order to save some energy to minimize energy outages in
future slots. We analyze the average age of information (AoI) under each of
these policies. We show through numerical results that as the average recharge
rate decreases, MDS coding with save-and-transmit outperforms all best-effort
schemes. We show that rateless coding with save-and-transmit outperforms all
the other schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00432</identifier>
 <datestamp>2018-02-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00432</id><created>2018-02-01</created><authors><author><keyname>Ghods</keyname><forenames>Ramina</forenames></author><author><keyname>Lan</keyname><forenames>Andrew S.</forenames></author><author><keyname>Goldstein</keyname><forenames>Tom</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author></authors><title>PhaseLin: Linear Phase Retrieval</title><categories>cs.IT eess.SP math.IT</categories><comments>To be presented at CISS 2018 (http://ee-ciss.princeton.edu/)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phase retrieval deals with the recovery of complex- or real-valued signals
from magnitude measurements. As shown recently, the method PhaseMax enables
phase retrieval via convex optimization and without lifting the problem to a
higher dimension. To succeed, PhaseMax requires an initial guess of the
solution, which can be calculated via spectral initializers. In this paper, we
show that with the availability of an initial guess, phase retrieval can be
carried out with an ever simpler, linear procedure. Our algorithm, called
PhaseLin, is the linear estimator that minimizes the mean squared error (MSE)
when applied to the magnitude measurements. The linear nature of PhaseLin
enables an exact and nonasymptotic MSE analysis for arbitrary measurement
matrices. We furthermore demonstrate that by iteratively using PhaseLin, one
arrives at an efficient phase retrieval algorithm that performs on par with
existing convex and nonconvex methods on synthetic and real-world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00535</identifier>
 <datestamp>2018-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00535</id><created>2018-02-01</created><authors><author><keyname>Brown</keyname><forenames>Alexander</forenames></author><author><keyname>Garg</keyname><forenames>Saurabh</forenames></author><author><keyname>Montgomery</keyname><forenames>James</forenames></author></authors><title>Scalable Preprocessing of High Volume Bird Acoustic Data</title><categories>cs.DC cs.SD eess.AS</categories><comments>28 pages, 20 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we examine the problem of efficiently preprocessing high volume
bird acoustic data. We combine several existing preprocessing steps including
noise reduction approaches into a single efficient pipeline by examining each
process individually. We then utilise a distributed computing architecture to
improve execution time. Using a master-slave model with data parallelisation,
we developed a near-linear automated scalable system, capable of preprocessing
bird acoustic recordings 21.76 times faster with 32 cores over 8 virtual
machines, compared to a serial process. This work contributes to the research
area of bioacoustic analysis, which is currently very active because of its
potential to monitor animals quickly at low cost. Overcoming noise interference
is a significant challenge in many bioacoustic studies, and the volume of data
in these studies is increasing. Our work makes large scale bird acoustic
analyses more feasible by parallelising important bird acoustic processing
tasks to significantly reduce execution times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00604</identifier>
 <datestamp>2018-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00604</id><created>2018-02-02</created><authors><author><keyname>Kolb&#xe6;k</keyname><forenames>Morten</forenames></author><author><keyname>Tan</keyname><forenames>Zheng-Hua</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author></authors><title>Monaural Speech Enhancement using Deep Neural Networks by Maximizing a
  Short-Time Objective Intelligibility Measure</title><categories>cs.SD eess.AS</categories><comments>To appear in ICASSP 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a Deep Neural Network (DNN) based Speech Enhancement
(SE) system that is designed to maximize an approximation of the Short-Time
Objective Intelligibility (STOI) measure. We formalize an approximate-STOI cost
function and derive analytical expressions for the gradients required for DNN
training and show that these gradients have desirable properties when used
together with gradient based optimization techniques. We show through
simulation experiments that the proposed SE system achieves large improvements
in estimated speech intelligibility, when tested on matched and unmatched
natural noise types, at multiple signal-to-noise ratios. Furthermore, we show
that the SE system, when trained using an approximate-STOI cost function
performs on par with a system trained with a mean square error cost applied to
short-time temporal envelopes. Finally, we show that the proposed SE system
performs on par with a traditional DNN based Short-Time Spectral Amplitude
(STSA) SE system in terms of estimated speech intelligibility. These results
are important because they suggest that traditional DNN based STSA SE systems
might be optimal in terms of estimated speech intelligibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00625</identifier>
 <datestamp>2018-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00625</id><created>2018-02-02</created><authors><author><keyname>Rothschedl</keyname><forenames>Christopher Josef</forenames></author><author><keyname>Ritt</keyname><forenames>Roland</forenames></author><author><keyname>O'Leary</keyname><forenames>Paul</forenames></author><author><keyname>Harker</keyname><forenames>Matthew</forenames></author><author><keyname>Habacher</keyname><forenames>Michael</forenames></author><author><keyname>Brandner</keyname><forenames>Michael</forenames></author></authors><title>Real-Time-Data Analytics in Raw Materials Handling</title><categories>eess.SP</categories><comments>Conference on Innovation on Raw Material Extraction - Real Time
  Mining - RTM2017</comments><journal-ref>Rothschedl, C.J. et al., 2017. Real-Time-Data Analytics in Raw
  Materials Handling. In Proceedings of Real-Time Mining, International Raw
  Materials Extraction Innovation Conference. Amsterdam: Prof. Dr.-Ing. J\&quot;org
  Benndorf, pp. 144-153</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a system for the ingestion and analysis of real-time
sensor and actor data of bulk materials handling plants and machinery. It
references issues that concern mining sensor data in cyber physical systems
(CPS). The advance of cyber physical systems has created a significant change
in the architecture of sensor and actor data. It affects the complexity of the
observed systems in general, the number of signals being processed, the spatial
distribution of the signal sources on a machine or plant and the global
availability of the data. There are different definitions for what constitutes
cyber physical systems: the most succinct and pertinent to the work shown in
this paper is the definition given by the IEEE: A CPS is a system with a
coupling of the cyber aspects of computing and communications with the physical
aspects of dynamics and engineering that must abide by the laws of physics.
This includes sensor networks, real-time and hybrid systems. Results computed
from sensor and actor data must obey the equations used for modelling the
physics of the observed system - this fundamentally poses an inverse problem.
Such problems are not covered sufficiently by literature addressing mining of
sensor data. Even available standard books on mining sensor data do not discuss
the special nature of sensor data. Typically, present approaches of mining data
rely on correlation as being a sole, reliable measure for significance. It is
not taken into account that the inverse solutions to the model-describing
equations are required to establish a semantic link between a sensor
observation and its precedent cause. Without this link - without causality -
there can be no physics based knowledge discovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00631</identifier>
 <datestamp>2018-07-13</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00631</id><created>2018-02-02</created><updated>2018-07-12</updated><authors><author><keyname>Zhou</keyname><forenames>Zhao</forenames></author><author><keyname>Zheng</keyname><forenames>Yingbin</forenames></author><author><keyname>Ye</keyname><forenames>Hao</forenames></author><author><keyname>Pu</keyname><forenames>Jian</forenames></author><author><keyname>Sun</keyname><forenames>Gufei</forenames></author></authors><title>Satellite Image Scene Classification via ConvNet with Context
  Aggregation</title><categories>eess.IV</categories><journal-ref>Pacific-Rim Conference on Multimedia (PCM), 2018</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scene classification is a fundamental problem to understand the
high-resolution remote sensing imagery. Recently, convolutional neural network
(ConvNet) has achieved remarkable performance in different tasks, and
significant efforts have been made to develop various representations for
satellite image scene classification. In this paper, we present a novel
representation based on a ConvNet with context aggregation. The proposed
two-pathway ResNet (ResNet-TP) architecture adopts the ResNet as backbone, and
the two pathways allow the network to model both local details and regional
context. The ResNet-TP based representation is generated by global average
pooling on the last convolutional layers from both pathways. Experiments on two
scene classification datasets, UCM Land Use and NWPU-RESISC45, show that the
proposed mechanism achieves promising improvements over state-of-the-art
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00664</identifier>
 <datestamp>2018-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00664</id><created>2018-02-02</created><authors><author><keyname>Shimobaba</keyname><forenames>Tomoyoshi</forenames></author><author><keyname>Kakue</keyname><forenames>Takashi</forenames></author><author><keyname>Ito</keyname><forenames>Tomoyoshi</forenames></author></authors><title>Convolutional neural network-based regression for depth prediction in
  digital holography</title><categories>cs.CV eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital holography enables us to reconstruct objects in three-dimensional
space from holograms captured by an imaging device. For the reconstruction, we
need to know the depth position of the recoded object in advance. In this
study, we propose depth prediction using convolutional neural network
(CNN)-based regression. In the previous researches, the depth of an object was
estimated through reconstructed images at different depth positions from a
hologram using a certain metric that indicates the most focused depth position;
however, such a depth search is time-consuming. The CNN of the proposed method
can directly predict the depth position with millimeter precision from
holograms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00680</identifier>
 <datestamp>2019-03-28</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00680</id><created>2018-02-02</created><updated>2019-03-27</updated><authors><author><keyname>Wilkinson</keyname><forenames>William J.</forenames></author><author><keyname>Reiss</keyname><forenames>Joshua D.</forenames></author><author><keyname>Stowell</keyname><forenames>Dan</forenames></author></authors><title>A Generative Model for Natural Sounds Based on Latent Force Modelling</title><categories>cs.LG cs.SD eess.AS stat.ML</categories><comments>10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in analysis of subband amplitude envelopes of natural sounds
have resulted in convincing synthesis, showing subband amplitudes to be a
crucial component of perception. Probabilistic latent variable analysis is
particularly revealing, but existing approaches don't incorporate prior
knowledge about the physical behaviour of amplitude envelopes, such as
exponential decay and feedback. We use latent force modelling, a probabilistic
learning paradigm that incorporates physical knowledge into Gaussian process
regression, to model correlation across spectral subband envelopes. We augment
the standard latent force model approach by explicitly modelling correlations
over multiple time steps. Incorporating this prior knowledge strengthens the
interpretation of the latent functions as the source that generated the signal.
We examine this interpretation via an experiment which shows that sounds
generated by sampling from our probabilistic model are perceived to be more
realistic than those generated by similar models based on nonnegative matrix
factorisation, even in cases where our model is outperformed from a
reconstruction error perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00700</identifier>
 <datestamp>2018-02-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00700</id><created>2018-02-02</created><authors><author><keyname>Barbarossa</keyname><forenames>Sergio</forenames></author><author><keyname>Sardellitti</keyname><forenames>Stefania</forenames></author><author><keyname>Ceci</keyname><forenames>Elena</forenames></author><author><keyname>Merluzzi</keyname><forenames>Mattia</forenames></author></authors><title>The edge cloud: A holistic view of communication, computation and
  caching</title><categories>eess.SP</categories><comments>to appear in the book &quot;Cooperative and Graph Signal Pocessing:
  Principles and Applications&quot;, P. Djuric and C. Richard Eds., Academic Press,
  Elsevier, 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of communication networks shows a clear shift of focus from
just improving the communications aspects to enabling new important services,
from Industry 4.0 to automated driving, virtual/augmented reality, Internet of
Things (IoT), and so on. This trend is evident in the roadmap planned for the
deployment of the fifth generation (5G) communication networks. This ambitious
goal requires a paradigm shift towards a vision that looks at communication,
computation and caching (3C) resources as three components of a single holistic
system. The further step is to bring these 3C resources closer to the mobile
user, at the edge of the network, to enable very low latency and high
reliability services. The scope of this chapter is to show that signal
processing techniques can play a key role in this new vision. In particular, we
motivate the joint optimization of 3C resources. Then we show how graph-based
representations can play a key role in building effective learning methods and
devising innovative resource allocation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00835</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00835</id><created>2018-02-02</created><authors><author><keyname>Wang</keyname><forenames>Heming</forenames></author><author><keyname>Mann</keyname><forenames>Richard</forenames></author><author><keyname>Vrscay</keyname><forenames>Edward R.</forenames></author></authors><title>A Novel Foward-PDE Approach as an Alternative to Empirical Mode
  Decomposition</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a mathematical model of the Empirical Mode
Decomposition (EMD). Although EMD is a powerful tool for signal processing, the
algorithm itself lacks an appropriate theoretical basis. The interpolation and
iteration processes involved in the EMD method have been obstacles for
mathematical modelling. Here, we propose a novel forward heat equation approach
to represent the mean envelope and sifting process. This new model can provide
a better mathematical analysis of classical EMD as well as identifying its
limitations. Our approach achieves a better performance for a &quot;mode-mixing&quot;
signal as compared to the classical EMD approach and is more robust to noise.
Furthermore, we discuss the ability of EMD to separate signals and possible
improvements by adjusting parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00847</identifier>
 <datestamp>2018-08-01</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00847</id><created>2018-01-31</created><updated>2018-07-30</updated><authors><author><keyname>Ball&#xe9;</keyname><forenames>Johannes</forenames></author></authors><title>Efficient Nonlinear Transforms for Lossy Image Compression</title><categories>eess.IV</categories><comments>accepted as a conference contribution to Picture Coding Symposium
  2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We assess the performance of two techniques in the context of nonlinear
transform coding with artificial neural networks, Sadam and GDN. Both
techniques have been successfully used in state-of-the-art image compression
methods, but their performance has not been individually assessed to this
point. Together, the techniques stabilize the training procedure of nonlinear
image transforms and increase their capacity to approximate the (unknown)
rate-distortion optimal transform functions. Besides comparing their
performance to established alternatives, we detail the implementation of both
methods and provide open-source code along with the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00957</identifier>
 <datestamp>2018-04-04</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00957</id><created>2018-02-03</created><authors><author><keyname>Liu</keyname><forenames>Shengheng</forenames></author><author><keyname>Zhang</keyname><forenames>Yimin Daniel</forenames></author><author><keyname>Shan</keyname><forenames>Tao</forenames></author><author><keyname>Tao</keyname><forenames>Ran</forenames></author></authors><title>Structure-Aware Bayesian Compressive Sensing for Frequency-Hopping
  Spectrum Estimation with Missing Observations</title><categories>eess.SP</categories><comments>14 pages, 11 figures, to appear in IEEE Transactions on Signal
  Processing</comments><doi>10.1109/TSP.2018.2806351</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of spectrum estimation of multiple
frequency-hopping (FH) signals in the presence of random missing observations.
The signals are analyzed within the bilinear time-frequency (TF) representation
framework, where a TF kernel is designed by exploiting the inherent FH signal
structures. The designed kernel permits effective suppression of cross-terms
and artifacts due to missing observations while preserving the FH signal
auto-terms. The kernelled results are represented in the instantaneous
autocorrelation function domain, which are then processed using a re-designed
structure-aware Bayesian compressive sensing algorithm to accurately estimate
the FH signal TF spectrum. The proposed method achieves high-resolution FH
signal spectrum estimation even when a large portion of data observations is
missing. Simulation results verify the effectiveness of the proposed method and
its superiority over existing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.00992</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.00992</id><created>2018-02-03</created><authors><author><keyname>Cogranne</keyname><forenames>R&#xe9;mi</forenames></author></authors><title>Determining JPEG Image Standard Quality Factor from the Quantization
  Tables</title><categories>eess.IV</categories><comments>6 pages, no figures, 3 tables, associated source code</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Identifying the quality factor of JPEG images is very useful for applications
in digital image forensics. Though several command-line tools exist and are
used in widely used software such as \emph{GIMP} (GNU Image Manipulation
Program), the well-known image editing software, or the \emph{ImageMagick}
suite, we have found that those may provide inaccurate or even wrong results.
This paper presents a simple method for determining the exact quality factor of
a JPEG image from its quantization tables. The method is presented briefly and
a sample program, written in Unix/Linux Shell bash language is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01049</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01049</id><created>2018-02-03</created><authors><author><keyname>Dean</keyname><forenames>Thomas R.</forenames></author><author><keyname>Wootters</keyname><forenames>Mary</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames></author></authors><title>Blind Joint MIMO Channel Estimation and Decoding</title><categories>eess.SP cs.IT math.IT math.OC</categories><comments>17 pages, 7 figures, submitted to IEEE Transactions on Information
  Theory, presented in part at IEEE Globecom 2017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for MIMO decoding when channel state information (CSI) is
unknown to both the transmitter and receiver. The proposed method requires some
structure in the transmitted signal for the decoding to be effective, in
particular that the underlying sources are drawn from a hypercubic space. Our
proposed technique fits a minimum volume parallelepiped to the received
samples. This problem can be expressed as a non-convex optimization problem
that can be solved with high probability by gradient descent. Our blind
decoding algorithm can be used when communicating over unknown MIMO wireless
channels using either BPSK or MPAM modulation. We apply our technique to
jointly estimate MIMO channel gain matrices and decode the underlying
transmissions with only knowledge of the transmitted constellation and without
the use of pilot symbols. Our results provide theoretical guarantees that the
proposed algorithm is correct when applied to small MIMO systems. Empirical
results show small sample size requirements, making this algorithm suitable for
block-fading channels with coherence times typically seen in practice. Our
approach has a loss of less than 3dB compared to zero-forcing with perfect CSI,
imposing a similar performance penalty as space-time coding techniques without
the loss of rate incurred by those techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01104</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01104</id><created>2018-02-04</created><authors><author><keyname>Pontois</keyname><forenames>Nicolas</forenames></author><author><keyname>Kaneko</keyname><forenames>Megumi</forenames></author><author><keyname>Dinh</keyname><forenames>Thi Ha Ly</forenames></author><author><keyname>Boukhatem</keyname><forenames>Lila</forenames></author></authors><title>User Pre-Scheduling and Beamforming with Imperfect CSI in 5G Fog Radio
  Access Networks</title><categories>eess.SP cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the user-to-cell association (or user-clustering) and
beamforming design for Cloud Radio Access Networks (CRANs) and Fog Radio Access
Networks (FogRANs) for 5G. CRAN enables cloud centralized resource and power
allocation optimization over all the small cells served by multiple Access
Points (APs). However, the fronthaul links connecting each AP to the cloud
introduce delays and cause outdated Channel State Information (CSI). By
contrast, FogRAN enables lower latencies and better CSI qualities, at the cost
of local optimization. To alleviate these issues, we propose a hybrid algorithm
exploiting both the centralized feature of the cloud for globally-optimized
pre-scheduling using outdated CSIs and the distributed nature of FogRAN for
accurate beamforming with high quality CSIs. The centralized phase enables to
consider the interference patterns over the global network, while the
distributed phase allows for latency reduction. Simulation results show that
our hybrid algorithm for FogRAN outperforms the centralized algorithm under
imperfect CSI, both in terms of throughput and delays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01346</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01346</id><created>2018-02-05</created><authors><author><keyname>Price</keyname><forenames>Eric</forenames></author><author><keyname>Lawless</keyname><forenames>Guilherme</forenames></author><author><keyname>B&#xfc;lthoff</keyname><forenames>Heinrich H.</forenames></author><author><keyname>Black</keyname><forenames>Michael</forenames></author><author><keyname>Ahmad</keyname><forenames>Aamir</forenames></author></authors><title>Deep Neural Network-based Cooperative Visual Tracking through Multiple
  Micro Aerial Vehicles</title><categories>cs.RO eess.IV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Multi-camera full-body pose capture of humans and animals in outdoor
environments is a highly challenging problem. Our approach to it involves a
team of cooperating micro aerial vehicles (MAVs) with on-board cameras only.
The key enabling-aspect of our approach is the on-board person detection and
tracking method. Recent state-of-the-art methods based on deep neural networks
(DNN) are highly promising in this context. However, real time DNNs are
severely constrained in input data dimensions, in contrast to available camera
resolutions. Therefore, DNNs often fail at objects with small scale or far away
from the camera, which are typical characteristics of a scenario with aerial
robots. Thus, the core problem addressed in this paper is how to achieve
on-board, real-time, continuous and accurate vision-based detections using DNNs
for visual person tracking through MAVs. Our solution leverages cooperation
among multiple MAVs. First, each MAV fuses its own detections with those
obtained by other MAVs to perform cooperative visual tracking. This allows for
predicting future poses of the tracked person, which are used to selectively
process only the relevant regions of future images, even at high resolutions.
Consequently, using our DNN-based detector we are able to continuously track
even distant humans with high accuracy and speed. We demonstrate the efficiency
of our approach through real robot experiments involving two aerial robots
tracking a person, while maintaining an active perception-driven formation. Our
solution runs fully on-board our MAV's CPU and GPU, with no remote processing.
ROS-based source code is provided for the benefit of the community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01358</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01358</id><created>2018-02-05</created><authors><author><keyname>Mohades</keyname><forenames>MohamadMahdi</forenames></author><author><keyname>Kahaei</keyname><forenames>Mohamad Hossein</forenames></author></authors><title>A General Approach for Construction of Deterministic Compressive Sensing
  Matrices</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, deterministic construction of measurement matrices in
Compressive Sensing (CS) is considered. First, by employing the column
replacement concept, a theorem for construction of large minimum distance
linear codes containing all-one codewords is proposed. Then, by applying an
existing theorem over these linear codes, deterministic sensing matrices are
constructed. To evaluate this procedure, two examples of constructed sensing
matrices are presented. The first example contains a matrix of size
${{p}^{2}}\times {{p}^{3}}$ and coherence ${1}/{p}\;$, and the second one
comprises a matrix with the size $p\left( p-1 \right)\times {{p}^{3}}$ and
coherence ${1}/{\left( p-1 \right)}\;$, where $p$ is a prime integer. Based on
the Welch bound, both examples asymptotically achieve optimal results.
Moreover, by presenting a new theorem, the column replacement is used for
resizing any sensing matrix to a greater-size sensing matrix whose coherence is
calculated. Then, using an example, the outperformance of the proposed method
is compared to a well-known method. Simulation results show the satisfying
performance of the column replacement method either in created or resized
sensing matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01381</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01381</id><created>2018-02-05</created><authors><author><keyname>Prater-Bennette</keyname><forenames>Ashley</forenames></author></authors><title>Randomness and isometries in echo state networks and compressed sensing</title><categories>cs.IT eess.SP math.IT</categories><comments>10 pages, 4 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although largely different concepts, echo state networks and compressed
sensing models both rely on collections of random weights; as the reservoir
dynamics for echo state networks, and the sensing coefficients in compressed
sensing. Several methods for generating the random matrices and metrics to
indicate desirable performance are well-studied in compressed sensing, but less
so for echo state networks. This work explores any overlap in these compressed
sensing methods and metrics for application to echo state networks. Several
methods for generating the random reservoir weights are considered, and a new
metric, inspired by the restricted isometry property for compressed sensing, is
proposed for echo state networks. The methods and metrics are investigated
theoretically and experimentally, with results suggesting that the same types
of random matrices work well for both echo state network and compressed sensing
scenarios, and that echo state network classification accuracy is improved when
the proposed restricted isometry-like constants are close to 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01387</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01387</id><created>2018-02-05</created><authors><author><keyname>Akbari</keyname><forenames>Mojtaba</forenames></author><author><keyname>Mohrekesh</keyname><forenames>Majid</forenames></author><author><keyname>Rafiei</keyname><forenames>Shima</forenames></author><author><keyname>Soroushmehr</keyname><forenames>S. M. Reza</forenames></author><author><keyname>Karimi</keyname><forenames>Nader</forenames></author><author><keyname>Samavi</keyname><forenames>Shadrokh</forenames></author><author><keyname>Najarian</keyname><forenames>Kayvan</forenames></author></authors><title>Classification of Informative Frames in Colonoscopy Videos Using
  Convolutional Neural Networks with Binarized Weights</title><categories>eess.IV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colorectal cancer is one of the common cancers in the United States. Polyp is
one of the main causes of the colonic cancer and early detection of polyps will
increase chance of cancer treatments. In this paper, we propose a novel
classification of informative frames based on a convolutional neural network
with binarized weights. The proposed CNN is trained with colonoscopy frames
along with the labels of the frames as input data. We also used binarized
weights and kernels to reduce the size of CNN and make it suitable for
implementation in medical hardware. We evaluate our proposed method using Asu
Mayo Test clinic database, which contains colonoscopy videos of different
patients. Our proposed method reaches a dice score of 71.20% and accuracy of
more than 90% using the mentioned dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01405</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01405</id><created>2018-01-31</created><authors><author><keyname>An</keyname><forenames>Guozhen</forenames></author><author><keyname>Levitan</keyname><forenames>Rivka</forenames></author></authors><title>Comparing approaches for mitigating intergroup variability in
  personality recognition</title><categories>cs.SD cs.CL eess.AS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Personality have been found to predict many life outcomes, and there have
been huge interests on automatic personality recognition from a speaker's
utterance. Previously, we achieved accuracies between 37%-44% for three-way
classification of high, medium or low for each of the Big Five personality
traits (Openness to Experience, Conscientiousness, Extraversion, Agreeableness,
Neuroticism). We show here that we can improve performance on this task by
accounting for heterogeneity of gender and L1 in our data, which has English
speech from female and male native speakers of Chinese and Standard American
English (SAE). We experiment with personalizing models by L1 and gender and
normalizing features by speaker, L1 group, and/or gender.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01436</identifier>
 <datestamp>2018-05-02</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01436</id><created>2018-01-31</created><updated>2018-05-01</updated><authors><author><keyname>Ball&#xe9;</keyname><forenames>Johannes</forenames></author><author><keyname>Minnen</keyname><forenames>David</forenames></author><author><keyname>Singh</keyname><forenames>Saurabh</forenames></author><author><keyname>Hwang</keyname><forenames>Sung Jin</forenames></author><author><keyname>Johnston</keyname><forenames>Nick</forenames></author></authors><title>Variational image compression with a scale hyperprior</title><categories>eess.IV cs.IT math.IT</categories><comments>accepted as a conference contribution to International Conference on
  Learning Representations 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an end-to-end trainable model for image compression based on
variational autoencoders. The model incorporates a hyperprior to effectively
capture spatial dependencies in the latent representation. This hyperprior
relates to side information, a concept universal to virtually all modern image
codecs, but largely unexplored in image compression using artificial neural
networks (ANNs). Unlike existing autoencoder compression methods, our model
trains a complex prior jointly with the underlying autoencoder. We demonstrate
that this model leads to state-of-the-art image compression when measuring
visual quality using the popular MS-SSIM index, and yields rate-distortion
performance surpassing published ANN-based methods when evaluated using a more
traditional metric based on squared error (PSNR). Furthermore, we provide a
qualitative comparison of models trained for different distortion metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01458</identifier>
 <datestamp>2018-06-12</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01458</id><created>2018-02-05</created><updated>2018-06-11</updated><authors><author><keyname>Deledalle</keyname><forenames>Charles-Alban</forenames><affiliation>IMB, UCSD</affiliation></author><author><keyname>Parameswaran</keyname><forenames>Shibin</forenames><affiliation>UCSD</affiliation></author><author><keyname>Nguyen</keyname><forenames>Truong Q.</forenames><affiliation>UCSD</affiliation></author></authors><title>Image denoising with generalized Gaussian mixture model patch priors</title><categories>eess.IV cs.CV math.ST stat.ML stat.TH</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Patch priors have become an important component of image restoration. A
powerful approach in this category of restoration algorithms is the popular
Expected Patch Log-Likelihood (EPLL) algorithm. EPLL uses a Gaussian mixture
model (GMM) prior learned on clean image patches as a way to regularize
degraded patches. In this paper, we show that a generalized Gaussian mixture
model (GGMM) captures the underlying distribution of patches better than a GMM.
Even though GGMM is a powerful prior to combine with EPLL, the non-Gaussianity
of its components presents major challenges to be applied to a computationally
intensive process of image restoration. Specifically, each patch has to undergo
a patch classification step and a shrinkage step. These two steps can be
efficiently solved with a GMM prior but are computationally impractical when
using a GGMM prior. In this paper, we provide approximations and computational
recipes for fast evaluation of these two steps, so that EPLL can embed a GGMM
prior on an image with more than tens of thousands of patches. Our main
contribution is to analyze the accuracy of our approximations based on thorough
theoretical analysis. Our evaluations indicate that the GGMM prior is
consistently a better fit formodeling image patch distribution and performs
better on average in image denoising task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01464</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01464</id><created>2018-02-02</created><authors><author><keyname>Woolfson</keyname><forenames>Malcolm</forenames></author></authors><title>Extraction of Uncorrelated Sparse Sources from Signal Mixtures using a
  Clustering Method</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A blind source separation method is described to extract sources from data
mixtures where the underlying sources are assumed to be sparse and
uncorrelated. The approach used is to detect and analyse segments of time where
one source exists on its own. Information from these segments is combined to
counteract the effects of noise and small random correlations between the
sources that would occur in practice. This combined information can then be
used to estimate the sources one at a time using a deflationary method.
Probability density functions are not assumed for any of the sources. A
comparison is made between the proposed method, the Minimum Heading Change
method, Fast-ICA and Clusterwise PCA. It is shown, for the dataset used in this
paper, that the proposed method has the best performance for clean signals if
the input parameters are chosen correctly. However the performance of this
method can be very sensitive to these input parameters and can also be more
sensitive to noise than the Fast-ICA and Clusterwise methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01512</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01512</id><created>2018-02-01</created><authors><author><keyname>Wang</keyname><forenames>Bin</forenames></author><author><keyname>Wang</keyname><forenames>Dai</forenames></author><author><keyname>Chan</keyname><forenames>Cy</forenames></author><author><keyname>Yin</keyname><forenames>Rongxin</forenames></author><author><keyname>Black</keyname><forenames>Doug</forenames></author></authors><title>Predictive Management of Electric Vehicles in a Community Microgrid</title><categories>eess.SP math.OC</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The charging load from Electric vehicles (EVs) is modeled as deferrable load,
meaning that the power consumption can be shifted to different time windows to
achieve various grid objectives. In local community scenarios, EVs are
considered as controllable storage devices in a global optimization problem
together with other microgrid components, such as the building load, renewable
generations, and battery energy storage system, etc. However, the uncertainties
in the driver behaviors have tremendous impact on the cost effectiveness of
microgrid operations, which has not been fully explored in previous literature.
In this paper, we propose a predictive EV management strategy in a community
microgrid, and evaluate it using real-world datasets of system baseload, solar
generation and EV charging behaviors. A two-stage operation model is
established for cost-effective EV management, i.e. wholesale market
participation in the first stage and load profile following in the second
stage. Predictive control strategies, including receding horizon control, are
adapted to solve the energy allocation problem in a decentralized fashion. The
experimental results indicate the proposed approach can considerably reduce the
total energy cost and decrease the ramping index of total system load up to
56.3%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01522</identifier>
 <datestamp>2019-04-16</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01522</id><created>2018-02-05</created><authors><author><keyname>Lee</keyname><forenames>Soonam</forenames></author><author><keyname>Kim</keyname><forenames>Daekeun</forenames></author></authors><title>Background subtraction using the factored 3-way restricted Boltzmann
  machines</title><categories>cs.CV cs.LG eess.IV</categories><comments>EECS545 (2011 Winter) class project report at the University of
  Michigan. This is for archiving purpose</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we proposed a method for reconstructing the 3D model based on
continuous sensory input. The robot can draw on extremely large data from the
real world using various sensors. However, the sensory inputs are usually too
noisy and high-dimensional data. It is very difficult and time consuming for
robot to process using such raw data when the robot tries to construct 3D
model. Hence, there needs to be a method that can extract useful information
from such sensory inputs. To address this problem our method utilizes the
concept of Object Semantic Hierarchy (OSH). Different from the previous work
that used this hierarchy framework, we extract the motion information using the
Deep Belief Network technique instead of applying classical computer vision
approaches. We have trained on two large sets of random dot images (10,000)
which are translated and rotated, respectively, and have successfully extracted
several bases that explain the translation and rotation motion. Based on this
translation and rotation bases, background subtraction have become possible
using Object Semantic Hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01563</identifier>
 <datestamp>2018-02-06</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01563</id><created>2018-02-05</created><authors><author><keyname>Arafa</keyname><forenames>Ahmed</forenames></author><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Age-Minimal Online Policies for Energy Harvesting Sensors with Random
  Battery Recharges</title><categories>cs.IT cs.NI eess.SP math.IT</categories><comments>To appear in ICC 2018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an energy harvesting sensor that is sending measurement updates
regarding some physical phenomenon to a destination. The sensor relies on
energy harvested from nature to measure and send its updates, and is equipped
with a battery of finite size to collect its harvested energy. The energy
harvesting process is Poisson with unit rate, and arrives in amounts that fully
recharge the battery. Our setting is online in the sense that the times of
energy arrivals are revealed causally to the sensor after the energy is
harvested; only the statistics of the arrival process is known a priori.
Updates need to be sent in a timely manner to the destination, namely, such
that the long term average age of information is minimized over the course of
communication. The age of information is defined as the time elapsed since the
freshest update has reached the destination. We first show that the optimal
scheduling update policy is a renewal policy, and then show that it has a multi
threshold structure: the sensor sends an update only if the age of information
grows above a certain threshold that depends on the available energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01570</identifier>
 <datestamp>2019-11-05</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01570</id><created>2018-02-03</created><updated>2019-11-01</updated><authors><author><keyname>Liu</keyname><forenames>Mingqing</forenames></author><author><keyname>Xiong</keyname><forenames>Mingliang</forenames></author><author><keyname>Deng</keyname><forenames>Hao</forenames></author><author><keyname>Liu</keyname><forenames>Qingwen</forenames></author></authors><title>Mobile Power Network for Ultimate Mobility without Battery Life Anxiety</title><categories>eess.SP cs.NI</categories><comments>10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similar to the evolution from the wired Internet to mobile Internet (MI), the
growing demand for power delivery anywhere and anytime appeals for power grid
transformation from wired to mobile domain. We propose here the next generation
of power delivery network -- mobile power network (MPN) for wireless power
transfer within a mobile range from several meters to tens of meters. At first,
we present the MPN's concept evolution and application scenarios. Then, we
introduce the MPN's supporting technology, namely resonant beam charging (RBC).
As a long-range wireless power transfer (WPT) method, RBC can safely deliver
multi-Watt power to multiple devices concurrently. Meanwhile, the recent
progress in RBC research has been summarized. Next, we specify the MPN's
architecture to provide the wide-area WPT coverage. Finally, we discuss the
MPN's features and challenges. MPN can enable the ultimate mobility by cutting
the final cord of mobile devices, realizing the &quot;last-mile&quot; mobile power
delivery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01649</identifier>
 <datestamp>2018-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01649</id><created>2018-02-05</created><authors><author><keyname>Khalajmehrabadi</keyname><forenames>Ali</forenames></author><author><keyname>Gatsis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Akopian</keyname><forenames>David</forenames></author><author><keyname>Taha</keyname><forenames>Ahmad F.</forenames></author></authors><title>Real-Time Rejection and Mitigation of Time Synchronization Attacks on
  the Global Positioning System</title><categories>cs.SY cs.CR eess.SP math.OC</categories><doi>10.1109/TIE.2017.2787581</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the Time Synchronization Attack Rejection and
Mitigation (TSARM) technique for Time Synchronization Attacks (TSAs) over the
Global Positioning System (GPS). The technique estimates the clock bias and
drift of the GPS receiver along with the possible attack contrary to previous
approaches. Having estimated the time instants of the attack, the clock bias
and drift of the receiver are corrected. The proposed technique is
computationally efficient and can be easily implemented in real time, in a
fashion complementary to standard algorithms for position, velocity, and time
estimation in off-the-shelf receivers. The performance of this technique is
evaluated on a set of collected data from a real GPS receiver. Our method
renders excellent time recovery consistent with the application requirements.
The numerical results demonstrate that the TSARM technique outperforms
competing approaches in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01709</identifier>
 <datestamp>2018-05-09</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01709</id><created>2018-02-05</created><authors><author><keyname>You</keyname><forenames>Zeyu</forenames></author><author><keyname>Raich</keyname><forenames>Raviv</forenames></author><author><keyname>Fern</keyname><forenames>Xiaoli Z.</forenames></author><author><keyname>Kim</keyname><forenames>Jinsub</forenames></author></authors><title>Weakly-supervised Dictionary Learning</title><categories>eess.SP cs.LG stat.ML</categories><doi>10.1109/TSP.2018.2807422</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a probabilistic modeling and inference framework for
discriminative analysis dictionary learning under a weak supervision setting.
Dictionary learning approaches have been widely used for tasks such as
low-level signal denoising and restoration as well as high-level classification
tasks, which can be applied to audio and image analysis. Synthesis dictionary
learning aims at jointly learning a dictionary and corresponding sparse
coefficients to provide accurate data representation. This approach is useful
for denoising and signal restoration, but may lead to sub-optimal
classification performance. By contrast, analysis dictionary learning provides
a transform that maps data to a sparse discriminative representation suitable
for classification. We consider the problem of analysis dictionary learning for
time-series data under a weak supervision setting in which signals are assigned
with a global label instead of an instantaneous label signal. We propose a
discriminative probabilistic model that incorporates both label information and
sparsity constraints on the underlying latent instantaneous label signal using
cardinality control. We present the expectation maximization (EM) procedure for
maximum likelihood estimation (MLE) of the proposed model. To facilitate a
computationally efficient E-step, we propose both a chain and a novel tree
graph reformulation of the graphical model. The performance of the proposed
model is demonstrated on both synthetic and real-world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01803</identifier>
 <datestamp>2018-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01803</id><created>2018-02-06</created><authors><author><keyname>Gu</keyname><forenames>Yu</forenames></author><author><keyname>Cui</keyname><forenames>Qimei</forenames></author><author><keyname>Wang</keyname><forenames>Yue</forenames></author><author><keyname>Soleimani</keyname><forenames>Somayeh</forenames></author></authors><title>Energy-aware Adaptive Spectrum Access and Power Allocation in LAA
  Networks via Lyapunov Optimization</title><categories>eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To relieve the traffic burden and improve the system capacity,
licensed-assisted access (LAA) has been becoming a promising technology to the
supplementary utilization of the unlicensed spectrum. However, due to the
densification of small base stations (SBSs) and the dynamic variety of the
number of Wi-Fi nodes in the overlapping areas, the licensed channel
interference and the unlicensed channel collision could seriously influence the
Quality of Service (QoS) and the energy consumption. In this paper, jointly
considering time-variant wireless channel conditions, dynamic traffic loads,
and random numbers of Wi-Fi nodes, we address an adaptive spectrum access and
power allocation problem that enables minimizing the system power consumption
under a certain queue stability constraint in the LAA-enabled SBSs and Wi-Fi
networks. The complex stochastic optimization problem is rewritten as the
difference of two convex (D.C.) program in the framework of Lyapunov
optimization, thus developing an online energy-aware optimal algorithm. We also
characterize the performance bounds of the proposed algorithm with a tradeoff
of [O(1=V ); O(V )] between power consumption and delay theoretically. The
numerical results verify the tradeoff and show that our scheme can reduce the
power consumption over the existing scheme by up to 72.1% under the same
traffic delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01861</identifier>
 <datestamp>2018-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01861</id><created>2018-02-06</created><authors><author><keyname>Franco-Pedroso</keyname><forenames>Javier</forenames></author><author><keyname>Gonzalez-Rodriguez</keyname><forenames>Joaquin</forenames></author><author><keyname>Cubero</keyname><forenames>Jorge</forenames></author><author><keyname>Planas</keyname><forenames>Maria</forenames></author><author><keyname>Cobo</keyname><forenames>Rafael</forenames></author><author><keyname>Pablos</keyname><forenames>Fernando</forenames></author></authors><title>Generating virtual scenarios of multivariate financial data for
  quantitative trading applications</title><categories>q-fin.CP cs.CE eess.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel approach to the generation of virtual
scenarios of multivariate financial data of arbitrary length and composition of
assets. With this approach, decades of realistic time-synchronized data can be
simulated for a large number of assets, producing diverse scenarios to test and
improve quantitative investment strategies. Our approach is based on the
analysis and synthesis of the time-dependent individual and joint
characteristics of real financial time series, using stochastic sequences of
market trends to draw multivariate returns from time-dependent probability
functions preserving both distributional properties of asset returns and
time-dependent correlation among time series. Moreover, new time-synchronized
assets can be arbitrarily generated through a PCA-based procedure to obtain any
number of assets in the final virtual scenario. For the validation of such
simulated data, they are tested with an extensive set of measurements showing a
significant degree of agreement with the reference performance of real
financial series, better than that obtained with other classical and
state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01911</identifier>
 <datestamp>2018-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01911</id><created>2018-02-06</created><authors><author><keyname>Sidorenko</keyname><forenames>Juri</forenames></author><author><keyname>Scherer-Negenborn</keyname><forenames>Norbert</forenames></author><author><keyname>Michaelsen</keyname><forenames>Eckart</forenames></author><author><keyname>Arens</keyname><forenames>Michael</forenames></author></authors><title>Multilateration of the Local Position Measurement</title><categories>eess.SP</categories><journal-ref>IEEE, IPIN2016</journal-ref><doi>10.1109/IPIN.2016.7743625</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Local Position Measurement system (LPM) is one of the most precise
systems for 3D position estimation. It is able to operate in- and outdoor and
updates at a rate up to 1000 measurements per second. Previous scientific
publications focused on the time of arrival equation (TOA) provided by the LPM
and filtering after the numerical position estimation. This paper investigates
the advantages of the TOA over the time difference of arrival equation
transformation (TDOA) and the signal smoothing prior to its fitting. The LPM
was designed under the general assumption that the position of the base station
and position of the reference station are known. The information resulting from
this research can prove vital for the systems self-calibration, providing data
aiding in locating the relative position of the base station without prior
knowledge of the transponder and reference station positions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.01955</identifier>
 <datestamp>2018-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.01955</id><created>2018-02-05</created><authors><author><keyname>Ayo</keyname><forenames>Babatope S.</forenames></author></authors><title>Development of a Home Automation System Using Wireless Sensor/Actuator
  Nodes</title><categories>eess.SP cs.NI</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents the design and implementation of a wireless home
monitoring and automation system consisting of wireless sensor/actuator nodes,
wireless camera, and a home server. The low-cost wireless sensor/actuator node
features temperature, light intensity and motion sensors, and actuator driver
circuits for the control of motors, heaters, and lights. Server and client
programs used to monitor and control the home were also developed. The home
server receives and processes sensor readings, such as temperature and light
intensity readings, and also transmits user commands to wireless nodes. The
system provides ambient condition monitoring, graphing of sensor data,
intrusion detection, automated device control, and video monitoring in order to
achieve improved security and comfort in the home. In addition, users have the
flexibility of determining sensor-actuator interaction at run-time. The
developed system could also put the home in various configurable modes based on
user requests, time or environmental cues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.02011</identifier>
 <datestamp>2018-02-07</datestamp>
 <setSpec>eess</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1802.02011</id><created>2018-02-06</created><authors><author><keyname>Katkovnik</keyname><forenames>Vladimir</forenames></author><author><keyname>Egiazarian</keyname><forenames>Karen</forenames></author></authors><title>Multi-frequency phase retrieval from noisy data</title><categories>eess.SP</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The phase retrieval from multi-frequency intensity (power) observations is
considered. The object to be reconstructed is complex-valued. A novel algorithm
is presented that accomplishes both the object phase (absolute phase) retrieval
and denoising for Poissonian and Gaussian measurements. The algorithm is
derived from the maximum likelihood formulation with Block Matching 3D (BM3D)
sparsity priors. These priors result in two filtering: one is in the complex
domain for complex-valued multi-frequency object images and another one in the
real domain for the object phase. The algorithm is iterative with alternating
projections between the object and measurement variables. The simulation
experiments are produced for Fourier transform image formation and random phase
modulations of the object, then the observations are random object diffraction
patterns. The results demonstrate the success of the algorithm for
reconstruction of the complex phase objects with the high-accuracy performance
even for very noisy data.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="0" completeListSize="16166">4250076|1001</resumptionToken>
</ListRecords>
</OAI-PMH>
